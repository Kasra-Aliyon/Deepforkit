{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 'FR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:45:46,345]\u001b[0m A new study created in RDB with name: FR_2018\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:46:30,663]\u001b[0m Trial 1 finished with value: 6.316788691275613 and parameters: {'n_hidden': 4, 'learning_rate': 0.009862343839062003, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12802607860441026, 'dropout_rate_Layer_2': 0.3900572556905417, 'dropout_rate_Layer_3': 0.23354040742011734, 'dropout_rate_Layer_4': 0.2810383829868222, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001471016821413063, 'l1_Layer_2': 0.05109575815293941, 'l1_Layer_3': 0.0047740033066476185, 'l1_Layer_4': 0.0021677636278963483, 'n_units_Layer_1': 235, 'n_units_Layer_2': 195, 'n_units_Layer_3': 55, 'n_units_Layer_4': 195}. Best is trial 1 with value: 6.316788691275613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 15.79% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:46:33,418]\u001b[0m Trial 0 finished with value: 5.885069683952261 and parameters: {'n_hidden': 3, 'learning_rate': 0.01886844792165352, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38969073993513537, 'dropout_rate_Layer_2': 0.20769030043307032, 'dropout_rate_Layer_3': 0.2490640377354427, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.335603950217306e-05, 'l1_Layer_2': 0.04642417792444791, 'l1_Layer_3': 3.434816025314811e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 250, 'n_units_Layer_3': 195}. Best is trial 0 with value: 5.885069683952261.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 14.22% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 14.98% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:46:36,108]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:46:36,381]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:46:40,920]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:46:44,087]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:46:51,245]\u001b[0m Trial 3 finished with value: 6.377572896049897 and parameters: {'n_hidden': 3, 'learning_rate': 0.009319960449451228, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29612002868975024, 'dropout_rate_Layer_2': 0.3578196931766545, 'dropout_rate_Layer_3': 0.22022602137411007, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.014997071331166284, 'l1_Layer_2': 0.07921965956366368, 'l1_Layer_3': 5.6028987478078324e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 50, 'n_units_Layer_3': 60}. Best is trial 0 with value: 5.885069683952261.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 15.45% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:47:04,478]\u001b[0m Trial 9 finished with value: 6.2363329862660315 and parameters: {'n_hidden': 3, 'learning_rate': 0.005578715059047903, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.126480466696295, 'dropout_rate_Layer_2': 0.049658084274548035, 'dropout_rate_Layer_3': 0.27602905561173546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005747262224602416, 'l1_Layer_2': 0.04355727495433196, 'l1_Layer_3': 9.612987668162451e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 280, 'n_units_Layer_3': 65}. Best is trial 0 with value: 5.885069683952261.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 15.39% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.82 | sMAPE for Test Set is: 15.72% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:47:07,461]\u001b[0m Trial 2 finished with value: 6.281853545773184 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011194529484910844, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22382662932879116, 'dropout_rate_Layer_2': 0.058441807822610464, 'dropout_rate_Layer_3': 0.18691119501927936, 'dropout_rate_Layer_4': 0.35530115892388453, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.01697330889359122, 'l1_Layer_2': 2.2359934781686624e-05, 'l1_Layer_3': 0.0035197884416761755, 'l1_Layer_4': 0.006612671555460288, 'n_units_Layer_1': 165, 'n_units_Layer_2': 155, 'n_units_Layer_3': 130, 'n_units_Layer_4': 235}. Best is trial 0 with value: 5.885069683952261.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 15.21% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 15.16% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:47:10,083]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:10,261]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:10,552]\u001b[0m Trial 7 finished with value: 6.41833602563407 and parameters: {'n_hidden': 4, 'learning_rate': 0.003944746191601967, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3409352462932293, 'dropout_rate_Layer_2': 0.10563347953100069, 'dropout_rate_Layer_3': 0.31978591213214735, 'dropout_rate_Layer_4': 0.1766186718629443, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0014170792280199741, 'l1_Layer_2': 0.014059185295553363, 'l1_Layer_3': 0.004449926044458515, 'l1_Layer_4': 0.019605602570374275, 'n_units_Layer_1': 260, 'n_units_Layer_2': 300, 'n_units_Layer_3': 270, 'n_units_Layer_4': 255}. Best is trial 0 with value: 5.885069683952261.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 15.41% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.77 | sMAPE for Test Set is: 15.52% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:47:17,178]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:19,747]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:23,459]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:24,825]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:30,179]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:30,621]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:35,197]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:37,682]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:40,883]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:41,249]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:45,031]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:49,122]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:53,133]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:47:56,714]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:00,464]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:03,051]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:12,236]\u001b[0m Trial 10 finished with value: 5.83403757448747 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006795007086812174, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004484750513674341, 'dropout_rate_Layer_2': 0.3425416089066262, 'dropout_rate_Layer_3': 0.01685573086491652, 'dropout_rate_Layer_4': 0.24310342939325436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05959000141891188, 'l1_Layer_2': 5.597283423262539e-05, 'l1_Layer_3': 0.0004337505956519735, 'l1_Layer_4': 0.013607390877617483, 'n_units_Layer_1': 260, 'n_units_Layer_2': 205, 'n_units_Layer_3': 100, 'n_units_Layer_4': 260}. Best is trial 10 with value: 5.83403757448747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 14.35% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 14.75% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:48:16,166]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:16,808]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:21,792]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:23,699]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:28,370]\u001b[0m Trial 24 finished with value: 6.399595190604084 and parameters: {'n_hidden': 4, 'learning_rate': 0.004284007622051929, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20802689819201448, 'dropout_rate_Layer_2': 0.019769471396765104, 'dropout_rate_Layer_3': 0.15777890604063047, 'dropout_rate_Layer_4': 0.3153931989464363, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.091517982896874e-05, 'l1_Layer_2': 0.00035096471840060826, 'l1_Layer_3': 0.09321278344649007, 'l1_Layer_4': 7.992782545773143e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 185, 'n_units_Layer_3': 290, 'n_units_Layer_4': 285}. Best is trial 10 with value: 5.83403757448747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 14.99% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 15.17% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:48:28,974]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:29,103]\u001b[0m Trial 31 finished with value: 5.86270696604274 and parameters: {'n_hidden': 3, 'learning_rate': 0.007248780312896281, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0028166550757208865, 'dropout_rate_Layer_2': 0.1487793679551246, 'dropout_rate_Layer_3': 0.05226793976484667, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.0078596896581511e-05, 'l1_Layer_2': 1.2243506517411874e-05, 'l1_Layer_3': 0.0004906856105254181, 'n_units_Layer_1': 255, 'n_units_Layer_2': 225, 'n_units_Layer_3': 210}. Best is trial 10 with value: 5.83403757448747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 14.29% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.34 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:48:29,666]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:37,757]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:37,846]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:37,877]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:46,158]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:47,873]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:48,314]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:51,662]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:55,958]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:48:58,990]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:01,458]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:04,938]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:05,255]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:06,473]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:08,881]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:14,073]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:15,145]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:17,971]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:21,774]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:24,003]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:26,004]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:28,353]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:31,575]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:33,450]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:35,225]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:36,899]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:41,279]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:45,928]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:46,265]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:55,270]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:58,482]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:49:58,670]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:50:04,356]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:50:04,722]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:50:09,174]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:50:09,635]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 13.88% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 15.85% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:50:11,358]\u001b[0m Trial 67 finished with value: 5.642842017108059 and parameters: {'n_hidden': 3, 'learning_rate': 0.007402716952594969, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23490736837683124, 'dropout_rate_Layer_2': 0.299320593652046, 'dropout_rate_Layer_3': 0.2480224897620383, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024472212569072145, 'l1_Layer_2': 0.0029705786300504057, 'l1_Layer_3': 2.5824112086789366e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 200, 'n_units_Layer_3': 165}. Best is trial 67 with value: 5.642842017108059.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:50:15,777]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:50:20,858]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:50:25,377]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:00,587]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:07,319]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:13,717]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:14,174]\u001b[0m Trial 75 finished with value: 5.216224408726897 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005826263345664477, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21512410859865133, 'dropout_rate_Layer_2': 0.24191902630959813, 'dropout_rate_Layer_3': 0.2073043612582563, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006747971725645049, 'l1_Layer_2': 0.000957236243700385, 'l1_Layer_3': 1.9685278639348467e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170}. Best is trial 75 with value: 5.216224408726897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 15.32% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:51:21,796]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:23,866]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:27,051]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:27,322]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:39,609]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:40,163]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:42,213]\u001b[0m Trial 53 finished with value: 5.4133771537402495 and parameters: {'n_hidden': 4, 'learning_rate': 0.00130230731128301, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15581294299347861, 'dropout_rate_Layer_2': 0.24538511490799275, 'dropout_rate_Layer_3': 0.09000152064183231, 'dropout_rate_Layer_4': 0.19147210522442049, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009442360710536188, 'l1_Layer_2': 6.02843558343648e-05, 'l1_Layer_3': 1.4641954962386823e-05, 'l1_Layer_4': 2.8048895096737198e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 90, 'n_units_Layer_3': 225, 'n_units_Layer_4': 145}. Best is trial 75 with value: 5.216224408726897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.32 | sMAPE for Test Set is: 14.38% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:51:46,660]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:47,094]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:47,512]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:51,591]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:55,462]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:51:59,457]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:05,133]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:19,349]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:23,515]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:27,114]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 14.22% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:52:28,925]\u001b[0m Trial 86 finished with value: 5.207402280602376 and parameters: {'n_hidden': 4, 'learning_rate': 0.001025325658744073, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3172902899106981, 'dropout_rate_Layer_2': 0.36427221576075075, 'dropout_rate_Layer_3': 0.2825878908851031, 'dropout_rate_Layer_4': 0.30756640421157855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.346295702744725e-05, 'l1_Layer_2': 0.0005855401906166436, 'l1_Layer_3': 0.002651641231483365, 'l1_Layer_4': 0.000534656185848432, 'n_units_Layer_1': 120, 'n_units_Layer_2': 55, 'n_units_Layer_3': 300, 'n_units_Layer_4': 240}. Best is trial 86 with value: 5.207402280602376.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:33,056]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:35,078]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:38,469]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:40,846]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:43,119]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:47,161]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:50,804]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:52:56,293]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:53:00,496]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:53:04,661]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:53:09,876]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:53:15,707]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:54:03,083]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:54:06,102]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:54:06,544]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:54:10,605]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:54:15,538]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:54:20,632]\u001b[0m Trial 116 finished with value: 8.761931947383134 and parameters: {'n_hidden': 4, 'learning_rate': 0.05667138687800783, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16310753596558492, 'dropout_rate_Layer_2': 0.3745058341436629, 'dropout_rate_Layer_3': 0.1750419994160545, 'dropout_rate_Layer_4': 0.052737138615593704, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.482881610264207e-05, 'l1_Layer_2': 3.8554940568650624e-05, 'l1_Layer_3': 0.032314762219815614, 'l1_Layer_4': 0.00035044511502396996, 'n_units_Layer_1': 255, 'n_units_Layer_2': 230, 'n_units_Layer_3': 195, 'n_units_Layer_4': 280}. Best is trial 86 with value: 5.207402280602376.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.76 | sMAPE for Validation Set is: 19.98% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 9.97 | sMAPE for Test Set is: 21.65% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:54:23,395]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:54:27,925]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:54:39,192]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:54:43,738]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:02,304]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:07,182]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:09,608]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:14,563]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:19,187]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:19,698]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:21,538]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:27,074]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:29,816]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:32,829]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:34,727]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:36,525]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:44,746]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:44,880]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:51,143]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:53,091]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:55:58,825]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:01,656]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:04,365]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:07,497]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:10,896]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:16,904]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:18,927]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:24,450]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:30,150]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:30,480]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:39,638]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:46,238]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:50,796]\u001b[0m Trial 149 finished with value: 5.0456689061310485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015335955840165103, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22131363403118676, 'dropout_rate_Layer_2': 0.1846757163507201, 'dropout_rate_Layer_3': 0.24076094404664655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.422800070811115e-05, 'l1_Layer_2': 1.4793710547867618e-05, 'l1_Layer_3': 6.991624293533038e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 220, 'n_units_Layer_3': 150}. Best is trial 149 with value: 5.0456689061310485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 13.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 15.02% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:56:55,950]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:56:59,068]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:57:06,293]\u001b[0m Trial 140 finished with value: 5.151642152011061 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033571867984359396, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3616000850865062, 'dropout_rate_Layer_2': 0.08198649072071984, 'dropout_rate_Layer_3': 0.26299737275340346, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.1567981656909545e-05, 'l1_Layer_2': 0.037812223162104294, 'l1_Layer_3': 0.00015025269321529338, 'n_units_Layer_1': 175, 'n_units_Layer_2': 195, 'n_units_Layer_3': 200}. Best is trial 149 with value: 5.0456689061310485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 14.50% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:57:10,481]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:57:13,833]\u001b[0m Trial 154 finished with value: 4.963975184665268 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013329471609177046, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15875995269669912, 'dropout_rate_Layer_2': 0.2089820291344806, 'dropout_rate_Layer_3': 0.23753805723398694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8655413953634595e-05, 'l1_Layer_2': 1.8768660518490137e-05, 'l1_Layer_3': 7.842555347085297e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 210, 'n_units_Layer_3': 135}. Best is trial 154 with value: 4.963975184665268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 14.31% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:57:15,620]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:57:18,824]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:57:31,416]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:57:36,091]\u001b[0m Trial 159 finished with value: 5.15340961860323 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012198564838777333, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15710044150374708, 'dropout_rate_Layer_2': 0.21013748791810022, 'dropout_rate_Layer_3': 0.2213712301813927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1585288876425583e-05, 'l1_Layer_2': 2.9145780355621975e-05, 'l1_Layer_3': 5.194591152275403e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 205, 'n_units_Layer_3': 140}. Best is trial 154 with value: 4.963975184665268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 13.17% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.40 | sMAPE for Test Set is: 14.72% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:57:40,406]\u001b[0m Trial 158 finished with value: 4.838405981561103 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013428314272086986, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1447448511499256, 'dropout_rate_Layer_2': 0.1487263674247094, 'dropout_rate_Layer_3': 0.2263339963975004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2377075193466854e-05, 'l1_Layer_2': 1.4371155658409561e-05, 'l1_Layer_3': 0.00024175733994572638, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 135}. Best is trial 158 with value: 4.838405981561103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 12.28% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.02 | sMAPE for Test Set is: 15.87% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:57:44,669]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:57:50,533]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:57:58,623]\u001b[0m Trial 162 finished with value: 4.777981494654046 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012632735140028933, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1253218025620728, 'dropout_rate_Layer_2': 0.17786291758160488, 'dropout_rate_Layer_3': 0.24137351807628232, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.26821836237642e-05, 'l1_Layer_2': 3.133497775766277e-05, 'l1_Layer_3': 0.00011508876565058473, 'n_units_Layer_1': 240, 'n_units_Layer_2': 205, 'n_units_Layer_3': 140}. Best is trial 162 with value: 4.777981494654046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 12.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 15.54% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:58:02,291]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:58:07,239]\u001b[0m Trial 164 finished with value: 4.937685409546787 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012902390801527053, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12940658668923224, 'dropout_rate_Layer_2': 0.15052491513743385, 'dropout_rate_Layer_3': 0.22189360840617087, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2760155222940846e-05, 'l1_Layer_2': 3.011026219229887e-05, 'l1_Layer_3': 5.886604975160207e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 205, 'n_units_Layer_3': 125}. Best is trial 162 with value: 4.777981494654046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 12.52% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 15.64% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:58:15,414]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:58:19,327]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:58:21,512]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:58:30,814]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:58:33,683]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:58:36,336]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:58:48,829]\u001b[0m Trial 145 finished with value: 5.030099249120309 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031750611239022355, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3583379294358079, 'dropout_rate_Layer_2': 0.09118811267175782, 'dropout_rate_Layer_3': 0.28755396319254856, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.862436416307031e-05, 'l1_Layer_2': 0.0391279890588223, 'l1_Layer_3': 0.00015803074130101987, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 200}. Best is trial 162 with value: 4.777981494654046.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 14.97% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:58:51,572]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:58:54,089]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:03,530]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:03,710]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:07,925]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:08,377]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:16,346]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:21,615]\u001b[0m Trial 177 finished with value: 4.711809427267569 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010876941409777442, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10577715520507257, 'dropout_rate_Layer_2': 0.18773062121241896, 'dropout_rate_Layer_3': 0.26590865452994117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0275464184705299e-05, 'l1_Layer_2': 5.1889003614432386e-05, 'l1_Layer_3': 0.00012917604841952753, 'n_units_Layer_1': 245, 'n_units_Layer_2': 210, 'n_units_Layer_3': 115}. Best is trial 177 with value: 4.711809427267569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 13.69% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:59:24,500]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:26,597]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:32,090]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:35,605]\u001b[0m Trial 180 finished with value: 4.6561128899949 and parameters: {'n_hidden': 3, 'learning_rate': 0.001068774123289633, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10516677680595946, 'dropout_rate_Layer_2': 0.19221825223187972, 'dropout_rate_Layer_3': 0.2640784598983397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0957567711107047e-05, 'l1_Layer_2': 2.56136041775047e-05, 'l1_Layer_3': 8.847421771388547e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 190, 'n_units_Layer_3': 140}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 13.71% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:59:39,022]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:39,448]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:39,532]\u001b[0m Trial 160 finished with value: 5.555948399982417 and parameters: {'n_hidden': 3, 'learning_rate': 0.002522537335081917, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18356119698517703, 'dropout_rate_Layer_2': 0.020884348498054983, 'dropout_rate_Layer_3': 0.1918784153903074, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001233526756944922, 'l1_Layer_2': 0.08914247679934745, 'l1_Layer_3': 0.0024758830816003687, 'n_units_Layer_1': 210, 'n_units_Layer_2': 250, 'n_units_Layer_3': 200}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 13.59% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 14.75% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:59:47,044]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:50,415]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:51,032]\u001b[0m Trial 185 finished with value: 4.915817356034142 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008302538784527915, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18408473137776823, 'dropout_rate_Layer_2': 0.17284111851328166, 'dropout_rate_Layer_3': 0.2489187149214671, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9583628361394393e-05, 'l1_Layer_2': 1.8667853689170793e-05, 'l1_Layer_3': 9.356885667909796e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 12.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.72 | sMAPE for Test Set is: 13.41% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 09:59:56,687]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:59,055]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 09:59:59,637]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:04,483]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:09,328]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:12,905]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:16,220]\u001b[0m Trial 188 finished with value: 4.779524047558978 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013294325635437073, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09011940182512104, 'dropout_rate_Layer_2': 0.21001751477321462, 'dropout_rate_Layer_3': 0.25032661407783235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.643731904424963e-05, 'l1_Layer_2': 1.2088374231400043e-05, 'l1_Layer_3': 6.096601777845097e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 220, 'n_units_Layer_3': 85}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 12.10% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 14.12% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:00:18,843]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:22,413]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:25,130]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:25,392]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:29,655]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:29,968]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:36,207]\u001b[0m Trial 197 finished with value: 4.97895924223202 and parameters: {'n_hidden': 3, 'learning_rate': 0.024784759248607513, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11076935225735891, 'dropout_rate_Layer_2': 0.012402318177120808, 'dropout_rate_Layer_3': 0.21326688561191776, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.84391176332032e-05, 'l1_Layer_2': 0.01841304562443699, 'l1_Layer_3': 8.926222176886468e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 12.38% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 12.95% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:00:36,559]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:36,786]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:50,552]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:56,152]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:00:59,533]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:02,491]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:06,094]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:09,042]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:16,093]\u001b[0m Trial 196 finished with value: 4.904559725187789 and parameters: {'n_hidden': 3, 'learning_rate': 0.001692759870886631, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2589609972853272, 'dropout_rate_Layer_2': 0.025698493979027345, 'dropout_rate_Layer_3': 0.12533689446584398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002926820964095253, 'l1_Layer_2': 6.932338756287052e-05, 'l1_Layer_3': 9.99768405498064e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 13.99% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:01:16,522]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:21,624]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:25,340]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:25,443]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:29,968]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:30,470]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:38,307]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:38,348]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:44,128]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:47,348]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:49,378]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:52,725]\u001b[0m Trial 222 finished with value: 7.391389681049787 and parameters: {'n_hidden': 3, 'learning_rate': 0.022107964872339955, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3660495335223985, 'dropout_rate_Layer_2': 0.155353766724553, 'dropout_rate_Layer_3': 0.186452760082356, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1122608048545573e-05, 'l1_Layer_2': 0.003542183244726567, 'l1_Layer_3': 0.0007800812916074664, 'n_units_Layer_1': 165, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.39 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 7.72 | sMAPE for Test Set is: 17.54% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:01:53,017]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:01:58,459]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:01,656]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:05,114]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:08,263]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:11,241]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:13,697]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:17,767]\u001b[0m Trial 225 finished with value: 7.447383328096827 and parameters: {'n_hidden': 3, 'learning_rate': 0.025344953429447193, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3696071166656236, 'dropout_rate_Layer_2': 0.2199512323122078, 'dropout_rate_Layer_3': 0.23491607255806884, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.624582683066306e-05, 'l1_Layer_2': 0.00476319995485164, 'l1_Layer_3': 1.8082912760315786e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 190, 'n_units_Layer_3': 205}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:17,855]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:17,855]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.45 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 19.00% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:02:24,913]\u001b[0m Trial 207 finished with value: 4.685433514899604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005248650737932074, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2603617104020023, 'dropout_rate_Layer_2': 0.03224035987513019, 'dropout_rate_Layer_3': 0.13561052777200694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00030219544898659357, 'l1_Layer_2': 8.723302475547569e-05, 'l1_Layer_3': 7.537299401396425e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.33 | sMAPE for Test Set is: 12.56% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:02:30,088]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:30,589]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:36,853]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:39,362]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:41,927]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:44,080]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:47,182]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:51,186]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:55,101]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:02:55,513]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:03:02,407]\u001b[0m Trial 237 finished with value: 58.98213842429984 and parameters: {'n_hidden': 3, 'learning_rate': 0.08946745962005406, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005226970894366412, 'dropout_rate_Layer_2': 0.30344075657936703, 'dropout_rate_Layer_3': 0.11233637366470269, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08903647228678416, 'l1_Layer_2': 0.08764804908965376, 'l1_Layer_3': 0.000830572635252561, 'n_units_Layer_1': 50, 'n_units_Layer_2': 115, 'n_units_Layer_3': 130}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.98 | sMAPE for Validation Set is: 136.73% | rMAE for Validation Set is: 6.92\n",
      "MAE for Test Set is: 55.00 | sMAPE for Test Set is: 141.48% | rMAE for Test Set is: 5.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:03:06,126]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:03:10,336]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:03:17,031]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:03:29,583]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:03:32,996]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:03:33,754]\u001b[0m Trial 238 finished with value: 4.716295576979106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017903794844576421, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28839293783671827, 'dropout_rate_Layer_2': 0.014176365960907239, 'dropout_rate_Layer_3': 0.1321489328785626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042167141711550667, 'l1_Layer_2': 0.00012339873976830134, 'l1_Layer_3': 2.082923392586514e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 120, 'n_units_Layer_3': 55}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 12.51% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:03:37,029]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:03:38,998]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:03:40,723]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:03:42,947]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:03:50,371]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:03:53,078]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:04:15,154]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:04:19,305]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:04:31,701]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:04:35,736]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:04:49,012]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:04:57,042]\u001b[0m Trial 248 finished with value: 5.7484358057052285 and parameters: {'n_hidden': 3, 'learning_rate': 0.005750155122724313, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3315714943564077, 'dropout_rate_Layer_2': 0.3585221962076841, 'dropout_rate_Layer_3': 0.3310438113284014, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9702244978346476e-05, 'l1_Layer_2': 1.8943675434482306e-05, 'l1_Layer_3': 0.005623812048923899, 'n_units_Layer_1': 65, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 14.10% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.30 | sMAPE for Test Set is: 16.63% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:05:00,511]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:03,015]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:05,432]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:09,043]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:09,740]\u001b[0m Trial 260 finished with value: 4.94956628660028 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005856362541973542, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25464492325224564, 'dropout_rate_Layer_2': 0.3779930994238738, 'dropout_rate_Layer_3': 0.32362537305006434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002773234544513384, 'l1_Layer_2': 0.0004401386578699752, 'l1_Layer_3': 0.003555843236546682, 'n_units_Layer_1': 95, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 12.48% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 13.33% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:05:13,745]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:15,203]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:19,210]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:19,638]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:23,383]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:27,596]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:30,524]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:30,668]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:37,668]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:43,808]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:51,000]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:05:56,284]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:06:05,735]\u001b[0m Trial 281 finished with value: 4.678417161616533 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008538861641777496, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12569659343400497, 'dropout_rate_Layer_2': 0.17471544065524458, 'dropout_rate_Layer_3': 0.2619021805473639, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.563048897081925e-05, 'l1_Layer_2': 5.209026507808704e-05, 'l1_Layer_3': 9.66844670150055e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 13.48% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:06:09,594]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:06:25,679]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:06:28,100]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:06:33,191]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:06:36,248]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:06:39,724]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:06:45,669]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:06:54,730]\u001b[0m Trial 291 finished with value: 4.940136354227085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010527601340725979, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11354572946933435, 'dropout_rate_Layer_2': 0.229258179328804, 'dropout_rate_Layer_3': 0.24706817306529705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.919312841553652e-05, 'l1_Layer_2': 3.092016983681137e-05, 'l1_Layer_3': 0.00017946224928687925, 'n_units_Layer_1': 220, 'n_units_Layer_2': 215, 'n_units_Layer_3': 160}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 12.61% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 14.64% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:06:59,590]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:07:03,088]\u001b[0m Trial 261 finished with value: 5.192640002399851 and parameters: {'n_hidden': 3, 'learning_rate': 0.003986166586254474, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33897815260190284, 'dropout_rate_Layer_2': 0.32694146544322833, 'dropout_rate_Layer_3': 0.33554572975620467, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013266906102226068, 'l1_Layer_2': 2.2444653349721872e-05, 'l1_Layer_3': 0.004736533593617338, 'n_units_Layer_1': 75, 'n_units_Layer_2': 145, 'n_units_Layer_3': 225}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 12.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 14.86% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:07:08,988]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:07:11,946]\u001b[0m Trial 282 finished with value: 4.867696801288613 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005927901780395399, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2517291061834647, 'dropout_rate_Layer_2': 0.1439114150414626, 'dropout_rate_Layer_3': 0.3689118963326875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003307873638061092, 'l1_Layer_2': 0.00014225888666313035, 'l1_Layer_3': 0.009444999993486643, 'n_units_Layer_1': 80, 'n_units_Layer_2': 65, 'n_units_Layer_3': 250}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 13.68% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:07:18,799]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:07:21,590]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:07:25,517]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:07:37,399]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:07:42,817]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:07:46,117]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:08,643]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:12,068]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:16,479]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:20,113]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:25,544]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:28,274]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:31,489]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:32,641]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:35,927]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:38,410]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:42,433]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:45,518]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:45,529]\u001b[0m Trial 296 finished with value: 5.110369527712881 and parameters: {'n_hidden': 3, 'learning_rate': 0.00468261500183775, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3382002351189623, 'dropout_rate_Layer_2': 0.3319603825450864, 'dropout_rate_Layer_3': 0.3475111950423724, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009620394433104518, 'l1_Layer_2': 2.353390253478143e-05, 'l1_Layer_3': 0.0023653041548523774, 'n_units_Layer_1': 75, 'n_units_Layer_2': 100, 'n_units_Layer_3': 230}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 13.40% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:08:50,869]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:52,734]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:56,618]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:08:59,431]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:05,809]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:09,544]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:12,080]\u001b[0m Trial 300 finished with value: 4.740389171130609 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005344222017007842, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2962128300721659, 'dropout_rate_Layer_2': 0.010956287102528816, 'dropout_rate_Layer_3': 0.136700037461965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006644521021379457, 'l1_Layer_2': 0.00017280353875279706, 'l1_Layer_3': 1.4091432557577286e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 115, 'n_units_Layer_3': 50}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 12.88% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:09:16,077]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:16,480]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:21,059]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:24,674]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:28,404]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:28,999]\u001b[0m Trial 314 finished with value: 5.0068748793166895 and parameters: {'n_hidden': 3, 'learning_rate': 0.002675842334479807, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2379806278116966, 'dropout_rate_Layer_2': 0.06957865300367058, 'dropout_rate_Layer_3': 0.08907882234910308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007609837136358482, 'l1_Layer_2': 4.621431606590397e-05, 'l1_Layer_3': 1.0014962280257003e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 155}. Best is trial 180 with value: 4.6561128899949.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 13.70% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:09:30,283]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:38,810]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:44,436]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:46,340]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:48,903]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:52,415]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:52,997]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:53,326]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:09:57,566]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:02,612]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:04,538]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:05,958]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:11,210]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:14,293]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:22,414]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:32,213]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:37,699]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:42,248]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:47,275]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:53,001]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:56,561]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:10:59,515]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:05,601]\u001b[0m Trial 340 finished with value: 4.6325933617897315 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008876388360544715, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3417856127322253, 'dropout_rate_Layer_2': 0.053131137767313916, 'dropout_rate_Layer_3': 0.0792489993908189, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002973253725009055, 'l1_Layer_2': 0.0001325949283105741, 'l1_Layer_3': 3.6442724193168305e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 95, 'n_units_Layer_3': 70}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 13.80% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:11:07,375]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:10,783]\u001b[0m Trial 339 finished with value: 5.519030502299802 and parameters: {'n_hidden': 3, 'learning_rate': 0.00899173874028671, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3848229703248722, 'dropout_rate_Layer_2': 0.34902153748778275, 'dropout_rate_Layer_3': 0.3844859272778441, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006442588474421182, 'l1_Layer_2': 0.057671274365100236, 'l1_Layer_3': 0.009083677309385188, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 185}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 13.72% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 15.12% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:11:11,392]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:16,540]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:19,836]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:20,708]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:21,569]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:22,649]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:31,221]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:32,126]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:36,742]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:38,643]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:41,039]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:43,168]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:44,559]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:49,977]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:50,249]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:53,624]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:55,272]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:59,254]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:11:59,554]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:03,724]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:06,436]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:10,331]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:14,039]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:17,163]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:21,106]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:23,642]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:25,976]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:29,237]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:32,874]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:36,603]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:39,219]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:42,028]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:45,594]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:49,144]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:53,269]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:12:58,812]\u001b[0m Trial 365 finished with value: 5.165749056601214 and parameters: {'n_hidden': 3, 'learning_rate': 0.002995001025695446, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35090328345768085, 'dropout_rate_Layer_2': 0.3281648982817667, 'dropout_rate_Layer_3': 0.2644108581494156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.122581661655468e-05, 'l1_Layer_2': 0.05344771417958129, 'l1_Layer_3': 0.00016345310958737773, 'n_units_Layer_1': 185, 'n_units_Layer_2': 150, 'n_units_Layer_3': 200}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 13.95% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:13:03,878]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:06,819]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:11,677]\u001b[0m Trial 376 finished with value: 5.126356803926898 and parameters: {'n_hidden': 3, 'learning_rate': 0.002845351626515249, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35295034824429133, 'dropout_rate_Layer_2': 0.33525986475105946, 'dropout_rate_Layer_3': 0.2668680989145545, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.322110260401927e-05, 'l1_Layer_2': 0.04472240746879485, 'l1_Layer_3': 0.00014633631651451168, 'n_units_Layer_1': 185, 'n_units_Layer_2': 155, 'n_units_Layer_3': 200}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.30 | sMAPE for Test Set is: 14.38% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:13:15,461]\u001b[0m Trial 384 finished with value: 4.755845443127986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009785982714766459, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3335149351328221, 'dropout_rate_Layer_2': 0.06318839353213614, 'dropout_rate_Layer_3': 0.075942357726143, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00032482869904677976, 'l1_Layer_2': 0.00011354803075857725, 'l1_Layer_3': 3.598463483406924e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 90, 'n_units_Layer_3': 75}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 12.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 15.28% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:13:18,170]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:18,740]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:24,305]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:28,210]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:31,700]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:35,964]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:41,406]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:44,939]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:45,489]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:50,612]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:50,712]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:51,326]\u001b[0m Trial 392 finished with value: 4.751858906830267 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011216005688797486, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07738063906223387, 'dropout_rate_Layer_2': 0.15157478295808471, 'dropout_rate_Layer_3': 0.2496060624433672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008570915707159023, 'l1_Layer_2': 3.596013177902888e-05, 'l1_Layer_3': 0.00014896038331879948, 'n_units_Layer_1': 230, 'n_units_Layer_2': 215, 'n_units_Layer_3': 135}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 14.04% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:13:58,159]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:13:58,616]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:05,497]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:10,570]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:19,302]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:25,391]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:31,127]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:36,490]\u001b[0m Trial 408 finished with value: 4.817993418646481 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010242206559234186, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05844343705836389, 'dropout_rate_Layer_2': 0.18237380013138801, 'dropout_rate_Layer_3': 0.2584404856251389, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007591773484058253, 'l1_Layer_2': 3.1222781819076594e-05, 'l1_Layer_3': 0.00015118013432096098, 'n_units_Layer_1': 230, 'n_units_Layer_2': 220, 'n_units_Layer_3': 135}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 12.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 14.85% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:14:40,082]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:42,193]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:47,164]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:50,013]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:50,042]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:50,289]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:57,263]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:14:57,452]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:09,310]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:12,830]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:18,016]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:18,225]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:23,508]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:33,014]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:41,271]\u001b[0m Trial 425 finished with value: 4.7817044676704334 and parameters: {'n_hidden': 3, 'learning_rate': 0.001238278373608157, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03831621088845818, 'dropout_rate_Layer_2': 0.15318141514003664, 'dropout_rate_Layer_3': 0.23305791273416518, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0014834225653293e-05, 'l1_Layer_2': 2.4894860866663188e-05, 'l1_Layer_3': 0.0002080043026261268, 'n_units_Layer_1': 235, 'n_units_Layer_2': 150, 'n_units_Layer_3': 130}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 12.19% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 15.64% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:15:41,920]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:47,146]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:47,725]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:49,536]\u001b[0m Trial 428 finished with value: 4.819587425843741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011047341050585292, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031152449767470697, 'dropout_rate_Layer_2': 0.18585155629554226, 'dropout_rate_Layer_3': 0.23652235078342393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7184751901957804e-05, 'l1_Layer_2': 2.643728489516465e-05, 'l1_Layer_3': 0.00013031115841267117, 'n_units_Layer_1': 245, 'n_units_Layer_2': 295, 'n_units_Layer_3': 155}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 12.25% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 14.64% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:15:53,045]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:55,919]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:15:57,703]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:00,542]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:04,441]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:07,503]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:12,343]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:12,730]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:13,209]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:17,724]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:22,992]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:23,810]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:26,894]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:27,022]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:33,935]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:37,801]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:39,955]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:40,693]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:41,866]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:47,869]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:51,982]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:54,784]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:16:55,167]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:17:00,256]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:17:01,652]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:17:07,142]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:17:07,360]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:17:19,335]\u001b[0m Trial 445 finished with value: 4.691953366704049 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018381299548918715, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27406945205741207, 'dropout_rate_Layer_2': 0.0013983846906159263, 'dropout_rate_Layer_3': 0.16088306965066235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.8312106464564744e-05, 'l1_Layer_2': 0.006111377095070465, 'l1_Layer_3': 6.070947404223835e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 105, 'n_units_Layer_3': 165}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 12.02% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 13.33% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:17:19,595]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:17:24,820]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:17:58,991]\u001b[0m Trial 453 finished with value: 4.7635349357549925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005270183286728437, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2736331268445677, 'dropout_rate_Layer_2': 0.09723584907048173, 'dropout_rate_Layer_3': 0.3937326756162531, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018547604084358609, 'l1_Layer_2': 0.0002642826894734996, 'l1_Layer_3': 2.6630227654700654e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 160}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 12.14% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 13.45% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:18:08,479]\u001b[0m Trial 463 finished with value: 5.427305390850349 and parameters: {'n_hidden': 3, 'learning_rate': 0.000614171260561537, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20906740064006046, 'dropout_rate_Layer_2': 0.10293760927214607, 'dropout_rate_Layer_3': 0.26946438454360455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.015746043224814824, 'l1_Layer_2': 0.0016630624470475898, 'l1_Layer_3': 0.0006078337114632108, 'n_units_Layer_1': 140, 'n_units_Layer_2': 130, 'n_units_Layer_3': 300}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 13.16% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.31 | sMAPE for Test Set is: 14.52% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:18:08,689]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:18:13,905]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:18:17,225]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:18:17,791]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:18:23,881]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:18:23,968]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:18:31,989]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:18:35,336]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:18:37,223]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:18:44,488]\u001b[0m Trial 461 finished with value: 5.061823749300267 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005244062667219604, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21988531326445587, 'dropout_rate_Layer_2': 0.09362920865470964, 'dropout_rate_Layer_3': 0.26497826661002977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.007117403815473685, 'l1_Layer_2': 0.0022797045798783762, 'l1_Layer_3': 0.0006684237734923045, 'n_units_Layer_1': 210, 'n_units_Layer_2': 50, 'n_units_Layer_3': 170}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 13.30% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:18:44,899]\u001b[0m Trial 459 finished with value: 5.136401405272316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005006401847506425, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21268151203791064, 'dropout_rate_Layer_2': 0.09401242918181371, 'dropout_rate_Layer_3': 0.2681883821633826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.017822784918516778, 'l1_Layer_2': 0.0016605206009103434, 'l1_Layer_3': 0.0006711519348726799, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 160}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 14.52% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:18:45,162]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:18:45,643]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:18:59,101]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:10,276]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:21,481]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:23,589]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:24,831]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:26,392]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:29,476]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:33,058]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:34,652]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:37,091]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:38,805]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:43,079]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:45,213]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:47,692]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:51,751]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:19:59,408]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:02,712]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:13,143]\u001b[0m Trial 486 finished with value: 5.1349241489005495 and parameters: {'n_hidden': 3, 'learning_rate': 0.004263991959277577, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3497164020938126, 'dropout_rate_Layer_2': 0.044642508160931904, 'dropout_rate_Layer_3': 0.07544197763288085, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.265774873019926e-05, 'l1_Layer_2': 0.059700459898752264, 'l1_Layer_3': 1.0617891602470755e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 180, 'n_units_Layer_3': 225}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 13.96% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:20:16,609]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:18,316]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:20,472]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:25,942]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:28,023]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:30,268]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:32,421]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:33,363]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:36,907]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:46,223]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:50,252]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:54,138]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:20:58,119]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:02,076]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:05,931]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:06,173]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:06,630]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:13,965]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:17,224]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:25,282]\u001b[0m Trial 504 finished with value: 4.889871281476438 and parameters: {'n_hidden': 3, 'learning_rate': 0.001976447959687254, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22540101328999135, 'dropout_rate_Layer_2': 0.04037289598494089, 'dropout_rate_Layer_3': 0.20105923116959745, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016048214790386028, 'l1_Layer_2': 6.354699829763797e-05, 'l1_Layer_3': 1.771436773168441e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 90, 'n_units_Layer_3': 65}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 12.33% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 13.57% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:21:28,103]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:31,213]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:33,870]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:42,593]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:46,364]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:50,947]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:21:54,430]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:22:08,299]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:22:11,177]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:22:33,486]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:22:40,276]\u001b[0m Trial 518 finished with value: 5.873753523733363 and parameters: {'n_hidden': 3, 'learning_rate': 0.00847261798868001, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34757993116229147, 'dropout_rate_Layer_2': 0.37662636125677423, 'dropout_rate_Layer_3': 0.3897849744806643, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010337222501627991, 'l1_Layer_2': 1.694667331211071e-05, 'l1_Layer_3': 0.0033665401344285476, 'n_units_Layer_1': 55, 'n_units_Layer_2': 135, 'n_units_Layer_3': 230}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.18 | sMAPE for Test Set is: 16.45% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:22:45,623]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:22:49,589]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:22:55,528]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:22:58,974]\u001b[0m Trial 526 finished with value: 4.8580237667842505 and parameters: {'n_hidden': 3, 'learning_rate': 0.009279964303259747, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1175660765695348, 'dropout_rate_Layer_2': 0.19507002747590013, 'dropout_rate_Layer_3': 0.20851660572307545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1861360352844581e-05, 'l1_Layer_2': 0.0007079501969131345, 'l1_Layer_3': 4.9860389235844294e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 75, 'n_units_Layer_3': 235}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.60 | sMAPE for Test Set is: 12.95% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:22:59,189]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:04,478]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:04,766]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:09,187]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:12,817]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:16,190]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:20,059]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:24,806]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:30,451]\u001b[0m Trial 537 finished with value: 5.4565428530193145 and parameters: {'n_hidden': 3, 'learning_rate': 0.010444122561491858, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17482371555821957, 'dropout_rate_Layer_2': 0.19242069472957915, 'dropout_rate_Layer_3': 0.12868036990642948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0129587553161385e-05, 'l1_Layer_2': 0.0006952211699986906, 'l1_Layer_3': 2.7966977226807616e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 75, 'n_units_Layer_3': 230}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 13.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 14.57% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:23:30,941]\u001b[0m Trial 514 finished with value: 4.893765026124497 and parameters: {'n_hidden': 3, 'learning_rate': 0.004089046257925037, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31772030388876965, 'dropout_rate_Layer_2': 0.06289761337289206, 'dropout_rate_Layer_3': 0.07346781861265693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1497870869375678e-05, 'l1_Layer_2': 0.05593731682518704, 'l1_Layer_3': 3.7623193402349706e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 215, 'n_units_Layer_3': 190}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 12.33% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 12.97% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:23:35,860]\u001b[0m Trial 525 finished with value: 4.6330197612688755 and parameters: {'n_hidden': 3, 'learning_rate': 0.000868764321403531, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11087866732093271, 'dropout_rate_Layer_2': 0.19530681526276558, 'dropout_rate_Layer_3': 0.26191076150217363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5327486432883258e-05, 'l1_Layer_2': 2.7108655490272733e-05, 'l1_Layer_3': 0.00020204384522610024, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 135}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 13.21% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:23:39,263]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:42,610]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:42,710]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:46,085]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:50,609]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:53,495]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:55,570]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:58,539]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:23:58,817]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:00,039]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:06,615]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:07,758]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:09,195]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:11,807]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:13,936]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:15,364]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:18,978]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:21,907]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:22,200]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:30,463]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:35,443]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:39,192]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:42,660]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:45,613]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:51,356]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:54,310]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:24:57,921]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:25:03,437]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:25:09,351]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:25:15,177]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:25:20,528]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:25:26,039]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:25:33,119]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:25:37,816]\u001b[0m Trial 572 finished with value: 5.201950026801623 and parameters: {'n_hidden': 3, 'learning_rate': 0.008156187008064891, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3959229011750859, 'dropout_rate_Layer_2': 0.25309885303535645, 'dropout_rate_Layer_3': 0.046808193084238836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006350233542334631, 'l1_Layer_2': 0.00019722968359483435, 'l1_Layer_3': 0.0016404416718150457, 'n_units_Layer_1': 85, 'n_units_Layer_2': 70, 'n_units_Layer_3': 275}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 13.49% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:25:44,093]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:25:48,262]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:25:52,785]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:25:56,533]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:26:04,794]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:26:20,412]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:26:22,740]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:26:26,007]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:26:38,772]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:26:44,696]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:26:48,404]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:26:52,006]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:26:52,095]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:26:56,210]\u001b[0m Trial 560 finished with value: 5.053504268188495 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024903863923147356, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3197533709952019, 'dropout_rate_Layer_2': 0.08619015158863198, 'dropout_rate_Layer_3': 0.11610134620961393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.521156724998453e-05, 'l1_Layer_2': 0.02975445053512848, 'l1_Layer_3': 0.00010277329814301459, 'n_units_Layer_1': 145, 'n_units_Layer_2': 210, 'n_units_Layer_3': 225}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 13.96% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:26:57,915]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:26:58,888]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:03,730]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:06,173]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:08,881]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:09,667]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:14,543]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:17,530]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:19,693]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:23,461]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:23,988]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:30,554]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:31,037]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:32,503]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:37,445]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:40,883]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:45,890]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:47,734]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:50,009]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:50,173]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:56,730]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:27:57,127]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:28:00,605]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:28:01,251]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:28:03,072]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:28:08,330]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:28:12,281]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:28:47,371]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:29:02,462]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:29:16,615]\u001b[0m Trial 581 finished with value: 5.064946707658041 and parameters: {'n_hidden': 3, 'learning_rate': 0.002108886794571896, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3887019948060705, 'dropout_rate_Layer_2': 0.12695076167832847, 'dropout_rate_Layer_3': 0.25027035884929266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.926111824707453e-05, 'l1_Layer_2': 0.09503394014800726, 'l1_Layer_3': 9.372544485171829e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 185, 'n_units_Layer_3': 210}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 13.99% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:29:23,226]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 13.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 15.70% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:29:25,599]\u001b[0m Trial 616 finished with value: 5.712504941342708 and parameters: {'n_hidden': 3, 'learning_rate': 0.003716178035922325, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35349670257748744, 'dropout_rate_Layer_2': 0.3672104519817721, 'dropout_rate_Layer_3': 0.36578238131088076, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013774608989250848, 'l1_Layer_2': 3.656754510064116e-05, 'l1_Layer_3': 0.00266903584150675, 'n_units_Layer_1': 75, 'n_units_Layer_2': 155, 'n_units_Layer_3': 235}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:29:30,975]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:29:37,658]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:29:42,731]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:29:45,265]\u001b[0m Trial 622 finished with value: 4.740542762172955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013723084664639539, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07076040554414481, 'dropout_rate_Layer_2': 0.12453800500299175, 'dropout_rate_Layer_3': 0.2824435868107146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7402348275791152e-05, 'l1_Layer_2': 2.5139572426140073e-05, 'l1_Layer_3': 2.596198526794857e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 140, 'n_units_Layer_3': 160}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 11.94% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 13.17% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:29:48,855]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:29:53,734]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:30:18,579]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:30:31,693]\u001b[0m Trial 625 finished with value: 5.033090576250905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009303446347840807, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2477622154456035, 'dropout_rate_Layer_2': 0.20138035205957613, 'dropout_rate_Layer_3': 0.22861668988958173, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.4775234650982045e-05, 'l1_Layer_2': 0.0004991845382160179, 'l1_Layer_3': 0.009344387225547847, 'n_units_Layer_1': 70, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 12.71% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 13.59% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:30:35,473]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:31:18,843]\u001b[0m Trial 617 finished with value: 4.900536702567195 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032830096189047967, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28835769794085864, 'dropout_rate_Layer_2': 0.127097735936202, 'dropout_rate_Layer_3': 0.11835236586254419, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.022507423562738e-05, 'l1_Layer_2': 0.017674360905256405, 'l1_Layer_3': 0.00019099287273459744, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 220}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 14.03% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:31:23,561]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:31:59,139]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:32:02,237]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:32:06,087]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:32:51,228]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:33:00,185]\u001b[0m Trial 636 finished with value: 5.951782756109256 and parameters: {'n_hidden': 3, 'learning_rate': 0.013225455499357625, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15406096151915089, 'dropout_rate_Layer_2': 0.34034262578376145, 'dropout_rate_Layer_3': 0.32684948509146805, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015943762562867315, 'l1_Layer_2': 4.749396927005226e-05, 'l1_Layer_3': 0.0024100964709288953, 'n_units_Layer_1': 220, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 14.10% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 15.29% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:33:04,196]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:33:24,737]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:33:31,171]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:33:52,835]\u001b[0m Trial 627 finished with value: 4.966297234691943 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019476727361675379, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3587184817632312, 'dropout_rate_Layer_2': 0.06942058089610112, 'dropout_rate_Layer_3': 0.10418358466884492, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.152038930141928e-05, 'l1_Layer_2': 0.054286129181845305, 'l1_Layer_3': 0.0001520260980351238, 'n_units_Layer_1': 100, 'n_units_Layer_2': 235, 'n_units_Layer_3': 235}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 12.36% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 13.85% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:33:56,381]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:01,833]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:05,417]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:13,466]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:16,694]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:24,196]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:29,537]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:34,615]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:41,335]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:44,320]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:47,467]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:50,212]\u001b[0m Trial 629 finished with value: 4.994330658914879 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018550915004577307, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35995421799776545, 'dropout_rate_Layer_2': 0.06539786695720132, 'dropout_rate_Layer_3': 0.0858033195273235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.9067234207983306e-05, 'l1_Layer_2': 0.05347649872583154, 'l1_Layer_3': 0.00014221429897680215, 'n_units_Layer_1': 100, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 12.37% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 14.11% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:34:53,253]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:34:54,697]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:35:00,225]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:35:02,388]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:35:04,322]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:35:15,534]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:35:18,590]\u001b[0m Trial 657 finished with value: 6.249235702972837 and parameters: {'n_hidden': 3, 'learning_rate': 0.011117245490461542, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02589006785273898, 'dropout_rate_Layer_2': 0.2658223413914555, 'dropout_rate_Layer_3': 0.18532733111279381, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00013521303252703594, 'l1_Layer_2': 0.0001189070676235404, 'l1_Layer_3': 0.04821808975762599, 'n_units_Layer_1': 125, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 15.35% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:35:20,706]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:35:30,663]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:35:31,391]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:36:19,213]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:36:22,301]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:36:26,155]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:36:36,721]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:37:05,375]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:37:13,373]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:37:17,079]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:37:20,242]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:37:27,483]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:37:32,912]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:37:37,204]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:38:24,120]\u001b[0m Trial 675 finished with value: 5.887584217789009 and parameters: {'n_hidden': 3, 'learning_rate': 0.009515085211704478, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14929636903890303, 'dropout_rate_Layer_2': 0.30872609537790285, 'dropout_rate_Layer_3': 0.14230171558998564, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001271270648917312, 'l1_Layer_2': 3.575351028062484e-05, 'l1_Layer_3': 2.809255479513852e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 150, 'n_units_Layer_3': 240}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 15.33% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:38:27,147]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:38:30,540]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:39:01,495]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:39:09,479]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:39:13,052]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:39:16,942]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:39:29,525]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:39:32,766]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:39:37,955]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:39:44,497]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:39:49,593]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:39:52,957]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:39:56,418]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:40:02,693]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:40:06,236]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:40:09,131]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:40:12,233]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:40:15,919]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:40:24,187]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:40:27,721]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:40:32,270]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:40:36,196]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:41:01,189]\u001b[0m Trial 641 finished with value: 4.891778964099494 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024158953697858043, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3862646810587618, 'dropout_rate_Layer_2': 0.13153206787745542, 'dropout_rate_Layer_3': 0.11822044571590042, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7914540883974926e-05, 'l1_Layer_2': 0.00949421634089298, 'l1_Layer_3': 7.912566999919921e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 225}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 12.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.27 | sMAPE for Test Set is: 14.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:41:06,472]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:41:11,447]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:41:30,286]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:42:35,055]\u001b[0m Trial 702 finished with value: 5.206611003489468 and parameters: {'n_hidden': 3, 'learning_rate': 0.003953444156032511, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15064135554199892, 'dropout_rate_Layer_2': 0.35980787438212214, 'dropout_rate_Layer_3': 0.11466298077121953, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017786762266540964, 'l1_Layer_2': 0.00013079893849380486, 'l1_Layer_3': 1.97615694093109e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 13.92% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:42:38,708]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:44:08,907]\u001b[0m Trial 661 finished with value: 5.029951387930184 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010486575264386769, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21494861479476793, 'dropout_rate_Layer_2': 0.11023788237648866, 'dropout_rate_Layer_3': 0.15293094532175477, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.455953763380872e-05, 'l1_Layer_2': 0.024657646273498358, 'l1_Layer_3': 8.008478884328652e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 220, 'n_units_Layer_3': 245}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 14.06% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:45:05,757]\u001b[0m Trial 705 finished with value: 5.460486652984301 and parameters: {'n_hidden': 3, 'learning_rate': 0.004136271058658432, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15366440411095048, 'dropout_rate_Layer_2': 0.35950444927826314, 'dropout_rate_Layer_3': 0.10280606281406723, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00036385007427658947, 'l1_Layer_2': 3.046692281986944e-05, 'l1_Layer_3': 2.393323667511381e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 13.22% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 14.68% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:45:12,856]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:45:19,570]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:45:38,733]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:45:44,784]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:45:56,998]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:46:00,398]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:46:04,669]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:46:08,521]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:46:15,281]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:46:33,058]\u001b[0m Trial 663 finished with value: 4.85063701521751 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008238399022964016, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1982904212202602, 'dropout_rate_Layer_2': 0.147887212589113, 'dropout_rate_Layer_3': 0.1307840156494789, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.78142820578507e-05, 'l1_Layer_2': 0.02543671524325485, 'l1_Layer_3': 7.908230796408326e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 220, 'n_units_Layer_3': 265}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 13.44% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:46:39,156]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:46:46,112]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:46:49,613]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:46:51,901]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:46:54,426]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:46:56,881]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:47:02,551]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:47:06,652]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:47:13,080]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:47:16,127]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:47:20,180]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:47:25,554]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:47:33,812]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:47:37,460]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:47:50,084]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:47:59,264]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:48:26,275]\u001b[0m Trial 704 finished with value: 4.908727000501126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020733271464045766, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37277066017324956, 'dropout_rate_Layer_2': 0.11590876794786474, 'dropout_rate_Layer_3': 0.067145741728073, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.720855825930547e-05, 'l1_Layer_2': 0.019272283184180134, 'l1_Layer_3': 0.00011225913660963758, 'n_units_Layer_1': 105, 'n_units_Layer_2': 205, 'n_units_Layer_3': 215}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 13.13% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:48:37,718]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:48:43,962]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:48:51,116]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:48:54,976]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:48:58,883]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:49:00,588]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:49:04,671]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:49:05,270]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:49:10,599]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:49:12,601]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:49:19,460]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:49:23,117]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:49:26,195]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:49:45,520]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:49:54,459]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:50:28,522]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:50:32,691]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:50:33,181]\u001b[0m Trial 747 finished with value: 5.60150347984037 and parameters: {'n_hidden': 3, 'learning_rate': 0.004957684073614055, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09071934681161423, 'dropout_rate_Layer_2': 0.33819868196179104, 'dropout_rate_Layer_3': 0.185650096349988, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000735201119896596, 'l1_Layer_2': 0.05894500274309812, 'l1_Layer_3': 1.618977203529016e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 205, 'n_units_Layer_3': 255}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 15.34% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:50:39,532]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:51:04,256]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:51:07,119]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:51:56,689]\u001b[0m Trial 752 finished with value: 4.990430525143942 and parameters: {'n_hidden': 3, 'learning_rate': 0.003753615237969083, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08773909708384194, 'dropout_rate_Layer_2': 0.33813621425851864, 'dropout_rate_Layer_3': 0.1759932060356781, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009668710811000042, 'l1_Layer_2': 0.06135380325904743, 'l1_Layer_3': 1.2217097724841587e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 195, 'n_units_Layer_3': 255}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 12.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 13.96% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:52:04,221]\u001b[0m Trial 754 finished with value: 5.155306798839037 and parameters: {'n_hidden': 3, 'learning_rate': 0.00500850225279262, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10461095349812868, 'dropout_rate_Layer_2': 0.34799561704859866, 'dropout_rate_Layer_3': 0.331608285839377, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007034435617954227, 'l1_Layer_2': 0.0553854289573338, 'l1_Layer_3': 1.569870384958954e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 260}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 13.02% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.07 | sMAPE for Test Set is: 14.10% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:52:04,882]\u001b[0m Trial 716 finished with value: 4.910038052710742 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008665037153640156, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19530005303282658, 'dropout_rate_Layer_2': 0.07078359258466088, 'dropout_rate_Layer_3': 0.12951835994262761, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5955962855370573e-05, 'l1_Layer_2': 0.01172214083768314, 'l1_Layer_3': 3.3567169584231896e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 220, 'n_units_Layer_3': 285}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 13.72% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:52:09,229]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:52:11,043]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:52:22,269]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:52:25,469]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:53:19,996]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:53:20,360]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:53:25,216]\u001b[0m Trial 761 finished with value: 5.138008604617981 and parameters: {'n_hidden': 3, 'learning_rate': 0.0048873694596026215, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07342418738423717, 'dropout_rate_Layer_2': 0.3688556050491591, 'dropout_rate_Layer_3': 0.20077851638828006, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009106138348482441, 'l1_Layer_2': 0.0674402803455031, 'l1_Layer_3': 1.7292701612738522e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 255}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 13.00% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 14.16% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:53:30,584]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:53:32,940]\u001b[0m Trial 759 finished with value: 5.070371618475106 and parameters: {'n_hidden': 3, 'learning_rate': 0.002340648382255584, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07530391053620226, 'dropout_rate_Layer_2': 0.37001144898895094, 'dropout_rate_Layer_3': 0.1969196834645269, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011451911278141924, 'l1_Layer_2': 0.06321342727771526, 'l1_Layer_3': 1.68024961885392e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 50, 'n_units_Layer_3': 255}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 12.74% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 13.51% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:53:38,017]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:53:41,067]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:53:42,504]\u001b[0m Trial 765 finished with value: 9.78649507424907 and parameters: {'n_hidden': 4, 'learning_rate': 0.03931645976424414, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29705439906928993, 'dropout_rate_Layer_2': 0.17663580164439976, 'dropout_rate_Layer_3': 0.30086416162305457, 'dropout_rate_Layer_4': 0.002313380884628402, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.1214805717527346e-05, 'l1_Layer_2': 0.0003332993463516515, 'l1_Layer_3': 4.367132738129297e-05, 'l1_Layer_4': 0.006054925634296332, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 280, 'n_units_Layer_4': 75}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.79 | sMAPE for Validation Set is: 22.46% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 11.96 | sMAPE for Test Set is: 26.06% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:53:55,402]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:53:59,312]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:54:03,405]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:54:06,954]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:54:10,249]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:54:13,089]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:54:22,459]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:54:43,132]\u001b[0m Trial 769 finished with value: 5.15856538217605 and parameters: {'n_hidden': 3, 'learning_rate': 0.005075083411435104, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07285418678271292, 'dropout_rate_Layer_2': 0.3681996309530156, 'dropout_rate_Layer_3': 0.214162865236851, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001436879312774665, 'l1_Layer_2': 0.07170241272919921, 'l1_Layer_3': 1.0339253387532958e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 55, 'n_units_Layer_3': 255}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 14.06% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:54:47,773]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:54:51,556]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:55:47,079]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:56:05,648]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:56:10,670]\u001b[0m Trial 779 finished with value: 5.264863459730948 and parameters: {'n_hidden': 3, 'learning_rate': 0.004932955529371779, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06852907090851888, 'dropout_rate_Layer_2': 0.38540740268771884, 'dropout_rate_Layer_3': 0.18417023332313853, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009351028180474233, 'l1_Layer_2': 0.06515469678830432, 'l1_Layer_3': 1.751919874907861e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 205, 'n_units_Layer_3': 260}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 13.25% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 14.04% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:56:22,179]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:57:02,687]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:57:05,729]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:57:09,773]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:57:13,718]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:57:51,515]\u001b[0m Trial 781 finished with value: 5.028611856481439 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013792377652629233, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2010630527146927, 'dropout_rate_Layer_2': 0.09659959175028104, 'dropout_rate_Layer_3': 0.10030584504182545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0528563356658357e-05, 'l1_Layer_2': 0.005283704164921666, 'l1_Layer_3': 3.8698195224348495e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 12.64% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 14.52% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:58:04,244]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:58:09,857]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:58:14,358]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:58:36,791]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:58:41,761]\u001b[0m Trial 767 finished with value: 5.032718593739044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014061891842935038, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1552804506927623, 'dropout_rate_Layer_2': 0.13840674800696381, 'dropout_rate_Layer_3': 0.07143835540944768, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1610210171469772e-05, 'l1_Layer_2': 0.020392576223516614, 'l1_Layer_3': 0.0002184169670424499, 'n_units_Layer_1': 90, 'n_units_Layer_2': 200, 'n_units_Layer_3': 275}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 12.57% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 13.76% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:58:45,122]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:58:48,351]\u001b[0m Trial 787 finished with value: 4.929670491871222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012115596403934055, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23034402749772567, 'dropout_rate_Layer_2': 0.13717766167120687, 'dropout_rate_Layer_3': 0.07051704140866258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1102888039870112e-05, 'l1_Layer_2': 0.004986686405081744, 'l1_Layer_3': 3.280622719473669e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 240, 'n_units_Layer_3': 275}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 12.40% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 13.55% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 10:58:50,373]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:58:54,197]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:58:58,697]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:59:02,854]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:59:14,845]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:59:17,633]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:59:20,613]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 10:59:35,971]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:13,266]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:16,956]\u001b[0m Trial 799 finished with value: 5.320206680701876 and parameters: {'n_hidden': 3, 'learning_rate': 0.005132806233571642, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.046056627205250986, 'dropout_rate_Layer_2': 0.3722399752801344, 'dropout_rate_Layer_3': 0.17696628188347577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008817281176939226, 'l1_Layer_2': 0.0679035036232716, 'l1_Layer_3': 1.1216677131063149e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 60, 'n_units_Layer_3': 260}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 13.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.32 | sMAPE for Test Set is: 14.74% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:00:17,912]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:22,287]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:26,544]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 12.41% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 14.79% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:00:29,801]\u001b[0m Trial 792 finished with value: 4.960720643679745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013418675896806186, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22444448808190387, 'dropout_rate_Layer_2': 0.13615842385007376, 'dropout_rate_Layer_3': 0.0698370330887706, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0984763546737264e-05, 'l1_Layer_2': 0.004773892782562134, 'l1_Layer_3': 3.8293193885731384e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:32,792]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:36,411]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:39,438]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:43,840]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:46,535]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:50,653]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:55,275]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:00:57,872]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:04,028]\u001b[0m Trial 763 finished with value: 4.883385706826963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013574838097957214, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22709254318139838, 'dropout_rate_Layer_2': 0.15701835438662465, 'dropout_rate_Layer_3': 0.06533316071138369, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0505747435783161e-05, 'l1_Layer_2': 0.019170202378718998, 'l1_Layer_3': 7.091440062019329e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 220, 'n_units_Layer_3': 275}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 13.20% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:01:08,016]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:13,590]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:16,727]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:19,280]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:20,127]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:24,374]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:27,585]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:30,742]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:33,993]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:38,494]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:43,442]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:47,778]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:51,410]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:01:55,889]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:02:02,019]\u001b[0m Trial 807 finished with value: 5.252117241698714 and parameters: {'n_hidden': 3, 'learning_rate': 0.005380712923850022, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04677198844067057, 'dropout_rate_Layer_2': 0.37333889340064463, 'dropout_rate_Layer_3': 0.17878985532643743, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016394101112654667, 'l1_Layer_2': 0.06719664495628283, 'l1_Layer_3': 1.0262481223359539e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 65, 'n_units_Layer_3': 250}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 13.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 13.91% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:02:07,771]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:02:25,965]\u001b[0m Trial 814 finished with value: 4.99190772046812 and parameters: {'n_hidden': 3, 'learning_rate': 0.003282856967019766, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2416971875098477, 'dropout_rate_Layer_2': 0.12049187458702763, 'dropout_rate_Layer_3': 0.3625980164721928, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002412127264318619, 'l1_Layer_2': 0.005556914562395913, 'l1_Layer_3': 0.0047982849477668415, 'n_units_Layer_1': 65, 'n_units_Layer_2': 265, 'n_units_Layer_3': 255}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 12.45% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 13.73% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:03:03,238]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:03:07,568]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:03:13,608]\u001b[0m Trial 832 finished with value: 5.342652734893218 and parameters: {'n_hidden': 3, 'learning_rate': 0.004808420491619418, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10085588294108197, 'dropout_rate_Layer_2': 0.392634243393736, 'dropout_rate_Layer_3': 0.19592192741328796, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017753554364115162, 'l1_Layer_2': 0.03629305010770227, 'l1_Layer_3': 1.1175784544148673e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 13.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 14.21% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:03:17,996]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:03:22,671]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:04:22,718]\u001b[0m Trial 837 finished with value: 4.936108455735657 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008940940237181166, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17589709402582349, 'dropout_rate_Layer_2': 0.14935229340994488, 'dropout_rate_Layer_3': 0.052363588698597016, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0896791455215098e-05, 'l1_Layer_2': 0.006382321054599029, 'l1_Layer_3': 2.5653949640971708e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 12.29% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 14.26% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:04:52,692]\u001b[0m Trial 840 finished with value: 5.43414859859637 and parameters: {'n_hidden': 3, 'learning_rate': 0.004916082346000289, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08401947248838329, 'dropout_rate_Layer_2': 0.39729147967665884, 'dropout_rate_Layer_3': 0.18154621469957374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017757215676097921, 'l1_Layer_2': 0.03454569138417195, 'l1_Layer_3': 1.1229241589640942e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 14.97% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:04:58,196]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:05:02,905]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:05:06,872]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:05:10,869]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:05:27,555]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:05:32,125]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:05:35,870]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:05:43,367]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:05:48,696]\u001b[0m Trial 834 finished with value: 5.122295612947014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008793466961127241, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2560773820275444, 'dropout_rate_Layer_2': 0.15502414862118896, 'dropout_rate_Layer_3': 0.06920334809575586, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.636087254855223e-05, 'l1_Layer_2': 0.006973274799720364, 'l1_Layer_3': 5.2203379354302204e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 14.77% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:05:49,466]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:05:50,087]\u001b[0m Trial 841 finished with value: 4.8599967009750396 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008251529538378814, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17899435226521562, 'dropout_rate_Layer_2': 0.1521905249270799, 'dropout_rate_Layer_3': 0.07372146126876347, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9501846319663817e-05, 'l1_Layer_2': 0.00907819996708621, 'l1_Layer_3': 2.52691512578048e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 290, 'n_units_Layer_3': 275}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 12.16% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 14.13% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:05:55,448]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:06:29,728]\u001b[0m Trial 835 finished with value: 5.10772734790985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007464105244125312, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23042086267839862, 'dropout_rate_Layer_2': 0.1676713731594217, 'dropout_rate_Layer_3': 0.023390370269160077, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.565094453217183e-05, 'l1_Layer_2': 0.007030042597408205, 'l1_Layer_3': 4.8992076375102255e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 12.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 14.88% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:06:34,513]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:06:46,053]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:06:52,828]\u001b[0m Trial 852 finished with value: 5.043073914752827 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011630101369538186, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1300362727399117, 'dropout_rate_Layer_2': 0.19175853408318538, 'dropout_rate_Layer_3': 0.05690662734705991, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2833034877061038e-05, 'l1_Layer_2': 0.0016571055305401447, 'l1_Layer_3': 1.921141923945266e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 12.65% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 15.43% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:06:56,206]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:01,512]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:05,921]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:10,827]\u001b[0m Trial 853 finished with value: 5.548402677372626 and parameters: {'n_hidden': 3, 'learning_rate': 0.0047663229373221235, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08458622939092857, 'dropout_rate_Layer_2': 0.389162576200007, 'dropout_rate_Layer_3': 0.178291374800907, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002804233032849522, 'l1_Layer_2': 0.03325690624186578, 'l1_Layer_3': 1.014824860533524e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 265}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 13.79% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 15.02% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:07:11,094]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:17,028]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:22,045]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:22,240]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:28,059]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:44,099]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:47,537]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:50,195]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:55,620]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:07:59,978]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:08:03,052]\u001b[0m Trial 854 finished with value: 5.41238477660735 and parameters: {'n_hidden': 3, 'learning_rate': 0.005573799429432428, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10418382511548564, 'dropout_rate_Layer_2': 0.39329208927862047, 'dropout_rate_Layer_3': 0.17851887721187973, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018180329923478873, 'l1_Layer_2': 0.031324256897458186, 'l1_Layer_3': 1.0342300339703057e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 260}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.32 | sMAPE for Test Set is: 14.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:08:06,984]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:08:09,872]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:08:20,641]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:08:51,186]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:08:52,094]\u001b[0m Trial 866 finished with value: 5.232870877184237 and parameters: {'n_hidden': 3, 'learning_rate': 0.004854675684428398, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10352439676736654, 'dropout_rate_Layer_2': 0.3927796012651102, 'dropout_rate_Layer_3': 0.1809540881336275, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018944813835331774, 'l1_Layer_2': 0.043789358032648065, 'l1_Layer_3': 1.0139593256441006e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260}. Best is trial 340 with value: 4.6325933617897315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 13.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 14.05% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:08:56,897]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:09:38,773]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:09:41,841]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:09:46,677]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:09:49,860]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:09:52,874]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:09:57,554]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:01,725]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 11.66% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 12.65% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:10:03,864]\u001b[0m Trial 876 finished with value: 4.58346652688483 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006621217929724429, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2157502937764565, 'dropout_rate_Layer_2': 0.02356851909608452, 'dropout_rate_Layer_3': 0.09872444187070796, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006326490223641152, 'l1_Layer_2': 0.000352151724348348, 'l1_Layer_3': 2.606141754366918e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 60}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:07,064]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:09,844]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:14,176]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:17,545]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:22,214]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:25,441]\u001b[0m Trial 878 finished with value: 5.255851415060531 and parameters: {'n_hidden': 3, 'learning_rate': 0.005567880530901617, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07905707434438322, 'dropout_rate_Layer_2': 0.39090644876656433, 'dropout_rate_Layer_3': 0.1956810298973023, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018942427609773614, 'l1_Layer_2': 0.04418343883759587, 'l1_Layer_3': 1.1997626192299166e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 60, 'n_units_Layer_3': 260}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 13.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 15.05% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:10:29,220]\u001b[0m Trial 887 finished with value: 5.2689967046902835 and parameters: {'n_hidden': 3, 'learning_rate': 0.030977523297537418, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11522183182851453, 'dropout_rate_Layer_2': 0.22034289881670255, 'dropout_rate_Layer_3': 0.22419966693563662, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.5745145940070545e-05, 'l1_Layer_2': 0.010716285153970943, 'l1_Layer_3': 6.536558346951716e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 13.05% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 13.72% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:10:36,855]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:46,207]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:49,808]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:50,311]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:56,159]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:10:56,789]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:11:33,119]\u001b[0m Trial 899 finished with value: 4.732010569667906 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006674409316416648, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18990820768123493, 'dropout_rate_Layer_2': 0.11686141362077705, 'dropout_rate_Layer_3': 0.10192493420067408, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.369465305278558e-05, 'l1_Layer_2': 0.000309197657440767, 'l1_Layer_3': 2.324293464690435e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 135, 'n_units_Layer_3': 105}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 12.10% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 14.38% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:11:36,520]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:11:49,985]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:11:58,593]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:12:26,978]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:13:20,652]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:13:25,061]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:13:28,933]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:13:33,603]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:13:37,246]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:13:41,142]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:14:04,383]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:14:58,764]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:15:29,173]\u001b[0m Trial 913 finished with value: 4.7217497597237985 and parameters: {'n_hidden': 3, 'learning_rate': 0.001392426132504817, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08092559141089306, 'dropout_rate_Layer_2': 0.06168859174284325, 'dropout_rate_Layer_3': 0.2644701242842181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005373816289900191, 'l1_Layer_2': 2.295100734722024e-05, 'l1_Layer_3': 1.7161968690532892e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 220, 'n_units_Layer_3': 130}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.91% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.64 | sMAPE for Test Set is: 13.05% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:15:36,472]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:15:50,242]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:15:54,759]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:15:59,674]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:16:05,710]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:16:09,343]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:16:27,611]\u001b[0m Trial 920 finished with value: 4.897089341978787 and parameters: {'n_hidden': 3, 'learning_rate': 0.016074628595853423, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08632748109941879, 'dropout_rate_Layer_2': 0.06038306716244643, 'dropout_rate_Layer_3': 0.2050435824862296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.4393318225586134e-05, 'l1_Layer_2': 0.013737801903054292, 'l1_Layer_3': 0.0002939184282931697, 'n_units_Layer_1': 65, 'n_units_Layer_2': 50, 'n_units_Layer_3': 265}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 12.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 13.05% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:16:34,668]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:16:39,669]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:17:20,972]\u001b[0m Trial 886 finished with value: 4.896414668738732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007611851812880332, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11065067779332066, 'dropout_rate_Layer_2': 0.12098557377671419, 'dropout_rate_Layer_3': 0.037379091149071036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.4190812509521154e-05, 'l1_Layer_2': 0.014992568394085156, 'l1_Layer_3': 2.248225652683284e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 225, 'n_units_Layer_3': 290}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 12.19% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 13.77% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:17:25,931]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:17:31,665]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:17:49,216]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:18:11,091]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:18:13,800]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:18:17,450]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:18:17,737]\u001b[0m Trial 893 finished with value: 4.893268660551121 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007680270520135041, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14798384203121145, 'dropout_rate_Layer_2': 0.13080735560398865, 'dropout_rate_Layer_3': 0.0396711979501036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.110438238237513e-05, 'l1_Layer_2': 0.01243081507925927, 'l1_Layer_3': 2.9505937301671183e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 225, 'n_units_Layer_3': 290}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 14.74% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:18:18,066]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:18:26,390]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:18:33,754]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:18:39,289]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:18:45,607]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:18:50,690]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:18:55,046]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:19:28,428]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:19:29,218]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:19:35,672]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:19:36,580]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:19:39,279]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:19:41,517]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:19:44,517]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:19:47,332]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:19:52,012]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:19:52,700]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:19:57,204]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:20:01,310]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:20:01,428]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:20:13,555]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:20:18,560]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:20:26,013]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:20:26,793]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:20:31,903]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:20:32,820]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:20:40,435]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:04,989]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:15,593]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:20,800]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:24,262]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:27,919]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:31,120]\u001b[0m Trial 953 finished with value: 5.149105859166862 and parameters: {'n_hidden': 3, 'learning_rate': 0.004942426019947875, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0989384279603959, 'dropout_rate_Layer_2': 0.3879379101511785, 'dropout_rate_Layer_3': 0.1762830049991199, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027570534515411063, 'l1_Layer_2': 0.03832493573584907, 'l1_Layer_3': 1.3087035594200644e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 13.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 13.59% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:21:31,269]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:37,760]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:41,620]\u001b[0m Trial 958 finished with value: 5.205272736376226 and parameters: {'n_hidden': 3, 'learning_rate': 0.004047531697779926, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07039836784878639, 'dropout_rate_Layer_2': 0.3999481398555757, 'dropout_rate_Layer_3': 0.2215227104880088, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001894914843068039, 'l1_Layer_2': 0.041445610325020775, 'l1_Layer_3': 1.2331103031778097e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 13.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 14.30% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:21:44,824]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:48,367]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:49,177]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:54,486]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:21:57,193]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:22:22,229]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:22:39,700]\u001b[0m Trial 904 finished with value: 4.764873967932147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007931788073711624, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14268209633907872, 'dropout_rate_Layer_2': 0.13220978818627546, 'dropout_rate_Layer_3': 0.04187606190070625, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.2645502791536436e-05, 'l1_Layer_2': 0.014017026210974693, 'l1_Layer_3': 2.3497711877687446e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 13.48% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:23:02,776]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:23:07,649]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:23:26,850]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:23:30,779]\u001b[0m Trial 971 finished with value: 4.85529330788156 and parameters: {'n_hidden': 3, 'learning_rate': 0.003311501599937593, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0733344562298588, 'dropout_rate_Layer_2': 0.39980079517048744, 'dropout_rate_Layer_3': 0.21925484167584255, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012484969087742507, 'l1_Layer_2': 0.04839238604450344, 'l1_Layer_3': 2.180955346506842e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 13.64% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:23:36,939]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:23:48,649]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:24:18,048]\u001b[0m Trial 976 finished with value: 5.061900775437027 and parameters: {'n_hidden': 3, 'learning_rate': 0.004185578979299469, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07957866452311224, 'dropout_rate_Layer_2': 0.3898963076969854, 'dropout_rate_Layer_3': 0.22166202818655706, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0036656282516034705, 'l1_Layer_2': 0.03627057632540008, 'l1_Layer_3': 1.2540239212605462e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 55, 'n_units_Layer_3': 260}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 12.80% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 13.99% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:24:18,889]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:24:23,640]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:24:31,141]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:24:35,191]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:24:49,617]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:24:54,374]\u001b[0m Trial 978 finished with value: 5.095653033012341 and parameters: {'n_hidden': 3, 'learning_rate': 0.004046021722744294, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07736156380047861, 'dropout_rate_Layer_2': 0.3959770622279362, 'dropout_rate_Layer_3': 0.20065329579890318, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012588846203067652, 'l1_Layer_2': 0.018692645953298444, 'l1_Layer_3': 2.264012863781725e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 13.93% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:24:59,365]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:25:08,139]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:25:14,278]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:25:16,220]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:25:18,841]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:25:20,965]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:25:24,453]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:25:41,214]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:25:47,023]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:25:50,254]\u001b[0m Trial 982 finished with value: 5.076067259533668 and parameters: {'n_hidden': 3, 'learning_rate': 0.003960391084349642, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07881895789779879, 'dropout_rate_Layer_2': 0.39830535262138594, 'dropout_rate_Layer_3': 0.2286968696165498, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003885671006094034, 'l1_Layer_2': 0.018175685750023124, 'l1_Layer_3': 1.2170115771959662e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 260}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 13.84% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:26:02,682]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:26:06,498]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:26:11,286]\u001b[0m Trial 993 finished with value: 5.042855491380675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035214379886491618, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06329447002518587, 'dropout_rate_Layer_2': 0.3992990877146275, 'dropout_rate_Layer_3': 0.20328655527060113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014324935182154935, 'l1_Layer_2': 0.026036811108453593, 'l1_Layer_3': 1.2646164377479294e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 65, 'n_units_Layer_3': 250}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 12.74% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 13.72% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:26:20,756]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:26:25,549]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:26:29,771]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:26:57,358]\u001b[0m Trial 1000 finished with value: 4.738503236406564 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006548852303859695, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19022598486852277, 'dropout_rate_Layer_2': 0.12248283482610343, 'dropout_rate_Layer_3': 0.1023113221223737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.893313352406761e-05, 'l1_Layer_2': 0.000241698197765232, 'l1_Layer_3': 2.543337742661137e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 13.37% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:27:01,542]\u001b[0m Trial 999 finished with value: 5.309924144664958 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029824906514206774, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07857437356921855, 'dropout_rate_Layer_2': 0.3845958631656081, 'dropout_rate_Layer_3': 0.2155889691157675, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005560919523760516, 'l1_Layer_2': 0.02648175831536662, 'l1_Layer_3': 1.7419549565900376e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 55, 'n_units_Layer_3': 275}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 13.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 14.30% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:27:07,033]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:27:10,688]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:27:21,376]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:27:21,493]\u001b[0m Trial 1003 finished with value: 5.039443969335857 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035316655163040297, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07632414222961409, 'dropout_rate_Layer_2': 0.3995147176044557, 'dropout_rate_Layer_3': 0.22206250737317257, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00133979312274063, 'l1_Layer_2': 0.013278421463186202, 'l1_Layer_3': 1.725890657709426e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 260}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 12.70% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.65 | sMAPE for Test Set is: 13.13% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:27:29,360]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:27:32,496]\u001b[0m Trial 1007 finished with value: 5.044623818752709 and parameters: {'n_hidden': 3, 'learning_rate': 0.015661660377009647, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14175482332649703, 'dropout_rate_Layer_2': 0.04446690452874495, 'dropout_rate_Layer_3': 0.09197813519406134, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.1353542637491956e-05, 'l1_Layer_2': 0.024324873768036655, 'l1_Layer_3': 0.01803132091410465, 'n_units_Layer_1': 70, 'n_units_Layer_2': 65, 'n_units_Layer_3': 265}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 12.71% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 13.42% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:27:42,426]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:27:48,194]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:27:54,869]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:28:06,884]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:28:10,124]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:28:14,135]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:28:17,553]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:28:21,213]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:28:22,072]\u001b[0m Trial 1012 finished with value: 13.72408084050681 and parameters: {'n_hidden': 4, 'learning_rate': 0.005474364989404211, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22972958229597867, 'dropout_rate_Layer_2': 0.0781646331321238, 'dropout_rate_Layer_3': 0.16522458334326717, 'dropout_rate_Layer_4': 0.37811711139652826, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0010928501257738573, 'l1_Layer_2': 0.006033995012750098, 'l1_Layer_3': 0.005823158887661493, 'l1_Layer_4': 1.2245833616237144e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 85, 'n_units_Layer_3': 290, 'n_units_Layer_4': 65}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.72 | sMAPE for Validation Set is: 31.00% | rMAE for Validation Set is: 1.61\n",
      "MAE for Test Set is: 17.86 | sMAPE for Test Set is: 39.71% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:28:34,803]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:28:38,813]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:28:50,421]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:28:54,130]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:28:58,202]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:29:01,354]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:29:08,904]\u001b[0m Trial 1010 finished with value: 4.995223411008633 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031197862659747494, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05199746314056476, 'dropout_rate_Layer_2': 0.38277859750104737, 'dropout_rate_Layer_3': 0.23486917580416725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001388743403678191, 'l1_Layer_2': 0.04851462945249412, 'l1_Layer_3': 2.218156567935143e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 280}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 12.58% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 13.75% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:29:12,664]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:29:14,702]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:29:19,669]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:29:23,590]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:29:26,394]\u001b[0m Trial 1028 finished with value: 21.164770096308615 and parameters: {'n_hidden': 3, 'learning_rate': 0.07682549535735717, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20454367958489694, 'dropout_rate_Layer_2': 0.0005683830876662792, 'dropout_rate_Layer_3': 0.1541850004610314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.707689842501892e-05, 'l1_Layer_2': 0.00034299855303895893, 'l1_Layer_3': 1.0088268931220853e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 80}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.16 | sMAPE for Validation Set is: 75.01% | rMAE for Validation Set is: 2.48\n",
      "MAE for Test Set is: 26.12 | sMAPE for Test Set is: 86.98% | rMAE for Test Set is: 2.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:29:30,639]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:29:35,718]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:29:39,856]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:29:43,583]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:29:48,252]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:29:56,121]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:30:00,170]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:30:03,645]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:30:07,353]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:30:12,823]\u001b[0m Trial 1019 finished with value: 4.6211225106396485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007612703348544251, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20866433711393936, 'dropout_rate_Layer_2': 0.07322943705657899, 'dropout_rate_Layer_3': 0.043244743984543456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.903972643944059e-05, 'l1_Layer_2': 0.0010449733528277911, 'l1_Layer_3': 1.0198955868726352e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 80}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 12.79% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:30:13,625]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:30:22,985]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:30:27,431]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:30:31,607]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:30:32,163]\u001b[0m Trial 1037 finished with value: 4.621837822773825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010308476132868526, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09929212970399784, 'dropout_rate_Layer_2': 0.0501368897864434, 'dropout_rate_Layer_3': 0.11987651407926037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0024383336784347e-05, 'l1_Layer_2': 1.439552417759371e-05, 'l1_Layer_3': 0.00024460764178612005, 'n_units_Layer_1': 220, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 876 with value: 4.58346652688483.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 13.09% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:30:40,281]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:30:44,135]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:31:31,064]\u001b[0m Trial 1046 finished with value: 4.5773112415901105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012034253373820237, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09665560604291779, 'dropout_rate_Layer_2': 0.04693147611119754, 'dropout_rate_Layer_3': 0.04526165791174572, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0191069721150348e-05, 'l1_Layer_2': 1.2137451981010139e-05, 'l1_Layer_3': 0.00024319647741031828, 'n_units_Layer_1': 215, 'n_units_Layer_2': 260, 'n_units_Layer_3': 155}. Best is trial 1046 with value: 4.5773112415901105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 11.49% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.50 | sMAPE for Test Set is: 12.78% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:31:41,916]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:31:46,624]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:32:08,648]\u001b[0m Trial 1052 finished with value: 4.626277491571295 and parameters: {'n_hidden': 3, 'learning_rate': 0.000871845656858647, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09237420111920983, 'dropout_rate_Layer_2': 0.04757522797628518, 'dropout_rate_Layer_3': 0.07249114381155064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.160062555260689e-05, 'l1_Layer_2': 1.2239481498175457e-05, 'l1_Layer_3': 0.0003324300094001994, 'n_units_Layer_1': 215, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 1046 with value: 4.5773112415901105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 11.69% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.55 | sMAPE for Test Set is: 12.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:32:12,524]\u001b[0m Trial 1026 finished with value: 5.039449342074119 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008377288092600693, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15841319846761243, 'dropout_rate_Layer_2': 0.14796538984101001, 'dropout_rate_Layer_3': 0.08826156928670263, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.358671324517799e-05, 'l1_Layer_2': 0.008074366179985174, 'l1_Layer_3': 4.1924319737129785e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 230, 'n_units_Layer_3': 300}. Best is trial 1046 with value: 4.5773112415901105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 12.65% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 14.18% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:32:13,657]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:32:18,798]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:32:29,397]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:32:34,532]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:32:40,128]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:32:56,037]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:33:03,248]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:33:34,808]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:33:38,943]\u001b[0m Trial 1059 finished with value: 5.053132337040965 and parameters: {'n_hidden': 3, 'learning_rate': 0.003626798095569805, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05984418783179407, 'dropout_rate_Layer_2': 0.3780752743463005, 'dropout_rate_Layer_3': 0.20673458757154403, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005774953962015163, 'l1_Layer_2': 0.04622264130592215, 'l1_Layer_3': 1.4915918801818362e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270}. Best is trial 1046 with value: 4.5773112415901105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 12.83% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 13.45% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:33:44,717]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:33:55,849]\u001b[0m Trial 1049 finished with value: 4.987696276856535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008767085560506706, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16194897025307595, 'dropout_rate_Layer_2': 0.1504725057717925, 'dropout_rate_Layer_3': 0.08005520654508856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.3953172340663045e-05, 'l1_Layer_2': 0.008785669526057362, 'l1_Layer_3': 4.27087359210411e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 215, 'n_units_Layer_3': 300}. Best is trial 1046 with value: 4.5773112415901105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 12.48% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 13.28% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:34:00,680]\u001b[0m Trial 1060 finished with value: 5.191530006770982 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021517728212783085, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07529327644128371, 'dropout_rate_Layer_2': 0.398422108049741, 'dropout_rate_Layer_3': 0.2257696923031957, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034233597738976104, 'l1_Layer_2': 0.04972129429860004, 'l1_Layer_3': 1.4484869755559409e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 1046 with value: 4.5773112415901105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 13.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 14.19% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:34:19,037]\u001b[0m Trial 1066 finished with value: 4.639250424611945 and parameters: {'n_hidden': 3, 'learning_rate': 0.000951704377092695, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07944602075796248, 'dropout_rate_Layer_2': 0.06476930322023695, 'dropout_rate_Layer_3': 0.04291911921704164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2472375396878683e-05, 'l1_Layer_2': 1.2983091463096273e-05, 'l1_Layer_3': 0.00030614594811541627, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 160}. Best is trial 1046 with value: 4.5773112415901105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.65 | sMAPE for Test Set is: 12.99% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:34:30,418]\u001b[0m Trial 1064 finished with value: 5.122318339831781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035252371764696883, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05815024577426267, 'dropout_rate_Layer_2': 0.3751033097429746, 'dropout_rate_Layer_3': 0.24043923138617526, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022585876598105415, 'l1_Layer_2': 0.05122934481659929, 'l1_Layer_3': 1.4561202975008703e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270}. Best is trial 1046 with value: 4.5773112415901105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 13.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 14.15% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:34:34,978]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:34:37,385]\u001b[0m Trial 1065 finished with value: 4.684406310211124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010728592130124213, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2628230716501344, 'dropout_rate_Layer_2': 0.015483948448750583, 'dropout_rate_Layer_3': 0.015078054890895688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5869479141563826e-05, 'l1_Layer_2': 0.0032239547869343083, 'l1_Layer_3': 1.3429250624306969e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 85, 'n_units_Layer_3': 215}. Best is trial 1046 with value: 4.5773112415901105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 13.99% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:34:50,537]\u001b[0m Trial 1062 finished with value: 5.087111799992219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038143854221407516, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07891620009725522, 'dropout_rate_Layer_2': 0.3772174580114972, 'dropout_rate_Layer_3': 0.2049454060064612, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0037612923447992064, 'l1_Layer_2': 0.04622266902183402, 'l1_Layer_3': 1.4904390079628609e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270}. Best is trial 1046 with value: 4.5773112415901105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 13.82% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:35:08,302]\u001b[0m Trial 1070 finished with value: 4.5345885955887795 and parameters: {'n_hidden': 3, 'learning_rate': 0.000705130858357191, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07683482779868732, 'dropout_rate_Layer_2': 0.06367962384465686, 'dropout_rate_Layer_3': 0.04104280379198917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2539634086245417e-05, 'l1_Layer_2': 1.231797761423347e-05, 'l1_Layer_3': 0.0003896986787441133, 'n_units_Layer_1': 210, 'n_units_Layer_2': 280, 'n_units_Layer_3': 160}. Best is trial 1070 with value: 4.5345885955887795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 11.52% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 12.79% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:35:25,269]\u001b[0m Trial 1068 finished with value: 5.188495631302314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036485601970703842, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05977173560651774, 'dropout_rate_Layer_2': 0.3991735846310767, 'dropout_rate_Layer_3': 0.2615503633422733, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0037340469162246933, 'l1_Layer_2': 0.04798901769509521, 'l1_Layer_3': 1.4311686797684044e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270}. Best is trial 1070 with value: 4.5345885955887795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 13.06% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 14.06% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:35:37,131]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:35:41,610]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:35:45,569]\u001b[0m Trial 1069 finished with value: 5.1232445314965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036390298545463285, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.058669116530681006, 'dropout_rate_Layer_2': 0.39928904448354463, 'dropout_rate_Layer_3': 0.24093381868709224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003922743059760304, 'l1_Layer_2': 0.04847406465761041, 'l1_Layer_3': 1.4476343482507726e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270}. Best is trial 1070 with value: 4.5345885955887795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 14.20% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:35:46,686]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:35:55,025]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:35:55,979]\u001b[0m Trial 1071 finished with value: 5.086700607993307 and parameters: {'n_hidden': 3, 'learning_rate': 0.002121714431075086, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.057382664618876915, 'dropout_rate_Layer_2': 0.3751625040632525, 'dropout_rate_Layer_3': 0.23892038272339813, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032996165804392427, 'l1_Layer_2': 0.05135300306363821, 'l1_Layer_3': 1.4462603093582227e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 1070 with value: 4.5345885955887795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 12.65% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 13.42% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:36:09,434]\u001b[0m Trial 1074 finished with value: 4.587380550444903 and parameters: {'n_hidden': 3, 'learning_rate': 0.000627483135790486, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07900212463195747, 'dropout_rate_Layer_2': 0.05933095618330879, 'dropout_rate_Layer_3': 0.012122585726304837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2579873937446066e-05, 'l1_Layer_2': 1.1707250564222823e-05, 'l1_Layer_3': 0.00038926973948145635, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 155}. Best is trial 1070 with value: 4.5345885955887795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 12.84% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:36:23,725]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:36:29,007]\u001b[0m Trial 1076 finished with value: 4.611291492387125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007546240604997124, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07960911383359034, 'dropout_rate_Layer_2': 0.06172188167962187, 'dropout_rate_Layer_3': 0.05440187820912962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2101740997212376e-05, 'l1_Layer_2': 1.3205306122650364e-05, 'l1_Layer_3': 0.0005300295057039204, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165}. Best is trial 1070 with value: 4.5345885955887795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 12.73% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:36:49,574]\u001b[0m Trial 1078 finished with value: 4.607374847932013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006678028930186317, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.079030499513963, 'dropout_rate_Layer_2': 0.05040851190915288, 'dropout_rate_Layer_3': 0.04275728099207777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4255809619003366e-05, 'l1_Layer_2': 1.0479435131988119e-05, 'l1_Layer_3': 0.0005180239974643825, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 160}. Best is trial 1070 with value: 4.5345885955887795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 12.36% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:37:08,013]\u001b[0m Trial 1081 finished with value: 5.194925665779931 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021790237456796725, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06096463293398514, 'dropout_rate_Layer_2': 0.3980031320862054, 'dropout_rate_Layer_3': 0.23933009111752135, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0038180449446502604, 'l1_Layer_2': 0.04929712443319892, 'l1_Layer_3': 1.477877597028387e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 1070 with value: 4.5345885955887795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 13.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 14.45% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:37:14,211]\u001b[0m Trial 1082 finished with value: 4.6023584540418625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007907832414606453, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06416526481027592, 'dropout_rate_Layer_2': 0.0646750798410686, 'dropout_rate_Layer_3': 0.02238261695595528, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1798301920091224e-05, 'l1_Layer_2': 1.1121702821656256e-05, 'l1_Layer_3': 0.00039850950348255075, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 1070 with value: 4.5345885955887795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 11.58% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 12.33% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:37:29,013]\u001b[0m Trial 1083 finished with value: 4.479189865646859 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006681648332829197, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06496771604919843, 'dropout_rate_Layer_2': 0.05220533897602075, 'dropout_rate_Layer_3': 0.041884774119879974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4714312164990155e-05, 'l1_Layer_2': 1.0323767649071877e-05, 'l1_Layer_3': 0.0005498750711035268, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 11.31% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 12.43% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:38:18,346]\u001b[0m Trial 1080 finished with value: 4.959376107629673 and parameters: {'n_hidden': 3, 'learning_rate': 0.001980275444448308, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05351676678950388, 'dropout_rate_Layer_2': 0.3997461826133916, 'dropout_rate_Layer_3': 0.2633858781103634, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003973967789456985, 'l1_Layer_2': 0.04943819747002836, 'l1_Layer_3': 1.4541846851557561e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 13.35% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:38:28,391]\u001b[0m Trial 1084 finished with value: 4.861970564055933 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012230686397469467, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17878550279784108, 'dropout_rate_Layer_2': 0.11657434938369188, 'dropout_rate_Layer_3': 0.072162247498379, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.171308714080586e-05, 'l1_Layer_2': 0.0028507616462142785, 'l1_Layer_3': 3.136967397366581e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 12.19% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 14.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:38:32,645]\u001b[0m Trial 1086 finished with value: 4.579203919505274 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006459660410046207, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05873130002610342, 'dropout_rate_Layer_2': 0.052820278693814865, 'dropout_rate_Layer_3': 0.0087528911539261, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2458121180668732e-05, 'l1_Layer_2': 1.0426083396154457e-05, 'l1_Layer_3': 0.0005619841627943719, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 11.52% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 12.01% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:38:35,659]\u001b[0m Trial 1085 finished with value: 4.802948560039036 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012666579341932918, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12769974568172698, 'dropout_rate_Layer_2': 0.12982076837830842, 'dropout_rate_Layer_3': 0.07130560128703346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1575152333407499e-05, 'l1_Layer_2': 0.0002472098950594753, 'l1_Layer_3': 2.9884983155889644e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 14.46% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:39:20,322]\u001b[0m Trial 1088 finished with value: 5.0891311829227766 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018857737244129822, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.036811791017470355, 'dropout_rate_Layer_2': 0.3769228643082867, 'dropout_rate_Layer_3': 0.26753701095313764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006642005346180918, 'l1_Layer_2': 0.049864820984455084, 'l1_Layer_3': 1.4995784568818395e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 12.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 14.34% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 13.22% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:39:28,053]\u001b[0m Trial 1090 finished with value: 4.6491913089183905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006738771250683437, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06056767365878952, 'dropout_rate_Layer_2': 0.065056603625021, 'dropout_rate_Layer_3': 0.02101564454084392, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2603558325365703e-05, 'l1_Layer_2': 1.0095974901932141e-05, 'l1_Layer_3': 0.0005277277003859477, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:39:28,654]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:39:58,214]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:40:22,496]\u001b[0m Trial 1089 finished with value: 4.987180967561804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018490460800145618, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03783596422443479, 'dropout_rate_Layer_2': 0.3779696623603927, 'dropout_rate_Layer_3': 0.26653183732134106, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033770933206242293, 'l1_Layer_2': 0.053514562772075884, 'l1_Layer_3': 1.557041296750888e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 13.47% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:40:35,182]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:40:39,760]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:40:44,657]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:40:52,297]\u001b[0m Trial 1091 finished with value: 4.91498450732764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015361845909339707, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1270508209082214, 'dropout_rate_Layer_2': 0.11592264354199751, 'dropout_rate_Layer_3': 0.07755927741873955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1482257819668858e-05, 'l1_Layer_2': 0.0005229358358987961, 'l1_Layer_3': 3.2549526603797274e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 110}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 12.18% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 13.56% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:40:56,241]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:41:03,393]\u001b[0m Trial 1094 finished with value: 5.086958341305483 and parameters: {'n_hidden': 3, 'learning_rate': 0.002010839644095654, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023569937400622187, 'dropout_rate_Layer_2': 0.37553318993623175, 'dropout_rate_Layer_3': 0.2626749918298445, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0075078374855968326, 'l1_Layer_2': 0.05261550325389489, 'l1_Layer_3': 2.173923713686237e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 13.66% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:41:21,354]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:41:22,005]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:41:30,207]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:41:33,902]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:41:37,641]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:41:38,097]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:41:41,580]\u001b[0m Trial 1098 finished with value: 4.588773064475707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006744388363548454, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06494156262647609, 'dropout_rate_Layer_2': 0.07031941226214831, 'dropout_rate_Layer_3': 0.022722095676078052, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0168176094325594e-05, 'l1_Layer_2': 1.0352828718243394e-05, 'l1_Layer_3': 0.0009513183743700643, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 11.60% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 12.64% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:41:43,851]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:41:53,100]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:42:07,639]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:42:13,438]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:42:18,611]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:42:24,368]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:42:32,139]\u001b[0m Trial 1108 finished with value: 5.1364395249045325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019720413014669, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026123574338795197, 'dropout_rate_Layer_2': 0.3668458336201695, 'dropout_rate_Layer_3': 0.25685209179725904, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004642043136257745, 'l1_Layer_2': 0.0387056762752898, 'l1_Layer_3': 2.0397412402268857e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 50, 'n_units_Layer_3': 285}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 14.11% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:42:43,192]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:42:49,939]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:42:55,169]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:42:57,747]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:43:03,935]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:43:08,919]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:43:11,930]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:43:19,298]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:43:28,490]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:43:48,723]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:44:35,935]\u001b[0m Trial 1121 finished with value: 5.046800286996298 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023388946398753196, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011688915454004328, 'dropout_rate_Layer_2': 0.37432007932880695, 'dropout_rate_Layer_3': 0.25587653974911384, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009214398674227589, 'l1_Layer_2': 0.03683479679453626, 'l1_Layer_3': 2.8211062881556005e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 13.49% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:44:52,928]\u001b[0m Trial 1123 finished with value: 5.097081490664065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013219044781043131, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014686717708951594, 'dropout_rate_Layer_2': 0.38705015071808385, 'dropout_rate_Layer_3': 0.27541275914113106, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002890176117994493, 'l1_Layer_2': 0.03153362416184751, 'l1_Layer_3': 2.8313752616170108e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 55, 'n_units_Layer_3': 280}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 13.53% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:45:03,237]\u001b[0m Trial 1124 finished with value: 5.03191970959278 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013063048787504711, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041624035612603624, 'dropout_rate_Layer_2': 0.3845765362257626, 'dropout_rate_Layer_3': 0.2806501834602438, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002770642665332397, 'l1_Layer_2': 0.051185703828798015, 'l1_Layer_3': 2.150105162433986e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 55, 'n_units_Layer_3': 280}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 12.72% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 13.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:45:07,981]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:45:14,310]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:45:22,926]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:45:22,959]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:45:54,685]\u001b[0m Trial 1126 finished with value: 5.01507400826147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021911868136123684, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015424460664194489, 'dropout_rate_Layer_2': 0.3855332893229416, 'dropout_rate_Layer_3': 0.25480429986425296, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0043853982708559405, 'l1_Layer_2': 0.031269678018848904, 'l1_Layer_3': 3.017024712630441e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 14.18% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:45:59,857]\u001b[0m Trial 1125 finished with value: 4.84561464175693 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014632748663518087, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1093929517164337, 'dropout_rate_Layer_2': 0.11731509509441905, 'dropout_rate_Layer_3': 0.07834448134430641, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0121130008032873e-05, 'l1_Layer_2': 0.00016930657169077226, 'l1_Layer_3': 1.9373194287454508e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 300, 'n_units_Layer_3': 100}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 15.38% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:46:04,764]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:46:22,160]\u001b[0m Trial 1132 finished with value: 5.118916102812055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014568780781947256, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11106986158224803, 'dropout_rate_Layer_2': 0.11047055804420913, 'dropout_rate_Layer_3': 0.07949054969794553, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2583239039984773e-05, 'l1_Layer_2': 0.00020414774935602196, 'l1_Layer_3': 7.081766037866241e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 300, 'n_units_Layer_3': 105}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 12.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 14.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:46:28,756]\u001b[0m Trial 1131 finished with value: 4.716248877288243 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008379445874559602, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3062744823778557, 'dropout_rate_Layer_2': 0.015430509797896378, 'dropout_rate_Layer_3': 0.04611294651560679, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029777783486137956, 'l1_Layer_2': 0.004139455279515916, 'l1_Layer_3': 3.062114057972224e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 110, 'n_units_Layer_3': 55}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 13.51% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:46:29,044]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:46:50,540]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:46:54,579]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:46:54,702]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:46:58,077]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:47:06,079]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:47:11,045]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:47:14,213]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:47:17,471]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:47:31,906]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:47:46,193]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:47:51,544]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:48:03,274]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:48:22,627]\u001b[0m Trial 1142 finished with value: 4.9761773500540185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023557386306234393, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006229618392531763, 'dropout_rate_Layer_2': 0.3782608060350565, 'dropout_rate_Layer_3': 0.25538091402811935, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004649559333787084, 'l1_Layer_2': 0.021493941567591747, 'l1_Layer_3': 3.2220206645927536e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 12.50% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 13.53% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:48:28,517]\u001b[0m Trial 1148 finished with value: 4.5169223036579575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006241712346035646, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.085434511646702, 'dropout_rate_Layer_2': 0.079282342816979, 'dropout_rate_Layer_3': 0.042308182820739254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3881188870489845e-05, 'l1_Layer_2': 1.3853297425352038e-05, 'l1_Layer_3': 0.0005262563529382187, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 11.38% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 12.52% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:48:29,164]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:48:34,127]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:48:38,221]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:48:46,531]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:48:51,044]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:48:51,551]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:48:56,219]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:49:03,429]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:49:08,356]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:49:29,137]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:49:38,479]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:49:43,915]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:49:53,255]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:50:08,072]\u001b[0m Trial 1158 finished with value: 4.958615083716658 and parameters: {'n_hidden': 3, 'learning_rate': 0.002491377521917777, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009908000580023984, 'dropout_rate_Layer_2': 0.38062799125290175, 'dropout_rate_Layer_3': 0.25735344147379485, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008014340457337657, 'l1_Layer_2': 0.024418384765983847, 'l1_Layer_3': 3.8230249631686245e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 12.56% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 13.61% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:50:13,881]\u001b[0m Trial 1150 finished with value: 4.917646257102601 and parameters: {'n_hidden': 3, 'learning_rate': 0.001316026659086097, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14782574937465598, 'dropout_rate_Layer_2': 0.11832672887899261, 'dropout_rate_Layer_3': 0.11283313166262521, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.8302777652795387e-05, 'l1_Layer_2': 0.00035350849618722444, 'l1_Layer_3': 5.831224783919008e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 12.34% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 14.61% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:50:15,439]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:50:20,296]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:50:37,251]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:50:47,068]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:51:09,275]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:51:26,738]\u001b[0m Trial 1169 finished with value: 4.97048783736522 and parameters: {'n_hidden': 3, 'learning_rate': 0.002467123500689986, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014082097389055572, 'dropout_rate_Layer_2': 0.3905912088607049, 'dropout_rate_Layer_3': 0.27075231928163424, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008205716557246202, 'l1_Layer_2': 0.01622990591032829, 'l1_Layer_3': 3.251903374249895e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 12.52% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 13.57% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:51:31,361]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:51:35,932]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:51:40,791]\u001b[0m Trial 1170 finished with value: 5.092312467626576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017455597301757964, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010096517901724927, 'dropout_rate_Layer_2': 0.3835207235157166, 'dropout_rate_Layer_3': 0.29078533121364286, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00941443065571731, 'l1_Layer_2': 0.029652946058991422, 'l1_Layer_3': 3.025979677395135e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 13.64% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:51:44,757]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:51:49,638]\u001b[0m Trial 1165 finished with value: 4.683140177965387 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012990729390114102, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1505681373081771, 'dropout_rate_Layer_2': 0.09315266791103223, 'dropout_rate_Layer_3': 0.028329644391273195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9991453156809744e-05, 'l1_Layer_2': 0.00011853087965239439, 'l1_Layer_3': 0.00012146531944396691, 'n_units_Layer_1': 90, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 11.89% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 13.91% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:51:58,779]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:51:59,727]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:52:14,484]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:52:30,290]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:52:35,224]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:52:57,145]\u001b[0m Trial 1181 finished with value: 4.559726028309188 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006333872049464732, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06655767378888201, 'dropout_rate_Layer_2': 0.0871442677035143, 'dropout_rate_Layer_3': 0.01425169952298889, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.739883659137422e-05, 'l1_Layer_2': 1.5647432662678963e-05, 'l1_Layer_3': 0.000330259511659439, 'n_units_Layer_1': 200, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 11.52% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.38 | sMAPE for Test Set is: 12.49% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:53:01,064]\u001b[0m Trial 1175 finished with value: 5.086887475081219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017885775135414747, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013597687851829863, 'dropout_rate_Layer_2': 0.3818780417878809, 'dropout_rate_Layer_3': 0.2907616374572654, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009369388855259545, 'l1_Layer_2': 0.03031222459340018, 'l1_Layer_3': 2.7871841345454685e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 55, 'n_units_Layer_3': 290}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 13.69% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:53:03,600]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:53:11,271]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:53:15,872]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:53:18,670]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:53:22,943]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:53:33,394]\u001b[0m Trial 1180 finished with value: 4.846659650870321 and parameters: {'n_hidden': 3, 'learning_rate': 0.001767900159174333, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13493147822812426, 'dropout_rate_Layer_2': 0.09231121180454574, 'dropout_rate_Layer_3': 0.044822549440794016, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0030347457054128e-05, 'l1_Layer_2': 7.131370800772944e-05, 'l1_Layer_3': 8.412015375498925e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 12.17% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 13.32% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:53:40,115]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:53:48,113]\u001b[0m Trial 1183 finished with value: 4.991004952509755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016813224246501135, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00018562525511599433, 'dropout_rate_Layer_2': 0.3838287353230695, 'dropout_rate_Layer_3': 0.2888700091816715, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009124577581289515, 'l1_Layer_2': 0.01587252996147222, 'l1_Layer_3': 3.145250396653049e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 55, 'n_units_Layer_3': 280}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 12.60% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 13.49% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:53:51,387]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:53:53,739]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:53:57,812]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:54:45,879]\u001b[0m Trial 1189 finished with value: 4.651487865708837 and parameters: {'n_hidden': 3, 'learning_rate': 0.001804179479666735, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1303712830358672, 'dropout_rate_Layer_2': 0.09198015872337673, 'dropout_rate_Layer_3': 0.0488705628337604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9354697452863707e-05, 'l1_Layer_2': 8.04543105985663e-05, 'l1_Layer_3': 9.651397001815882e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 11.68% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 13.85% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:54:51,198]\u001b[0m Trial 1195 finished with value: 4.634420058485294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007050596101916764, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06585696927795673, 'dropout_rate_Layer_2': 0.08352885350784006, 'dropout_rate_Layer_3': 5.5479187191793955e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.432894733984432e-05, 'l1_Layer_2': 1.4754473592735091e-05, 'l1_Layer_3': 0.00046446259246553373, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 160}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 11.67% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 12.39% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:54:59,560]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:55:05,428]\u001b[0m Trial 1190 finished with value: 4.889955833770711 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018355608292856694, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019084778124520065, 'dropout_rate_Layer_2': 0.07673272422371331, 'dropout_rate_Layer_3': 0.28216701140361206, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013863097952109464, 'l1_Layer_2': 0.0297284145302979, 'l1_Layer_3': 2.621606485991808e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 60, 'n_units_Layer_3': 280}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 12.40% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.64 | sMAPE for Test Set is: 13.24% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:55:12,075]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:55:15,563]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:55:21,191]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:55:32,316]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:55:55,547]\u001b[0m Trial 1201 finished with value: 4.5581733591596505 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007014298075469935, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07088633769224464, 'dropout_rate_Layer_2': 0.08721954381247968, 'dropout_rate_Layer_3': 0.003036759782827511, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8409110656822148e-05, 'l1_Layer_2': 1.563404993774582e-05, 'l1_Layer_3': 0.0006228489498300789, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 11.55% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 12.59% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:56:02,597]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 14.26% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:56:05,303]\u001b[0m Trial 1198 finished with value: 4.776887056891923 and parameters: {'n_hidden': 3, 'learning_rate': 0.00180287474646832, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12822514654572517, 'dropout_rate_Layer_2': 0.09071305974016977, 'dropout_rate_Layer_3': 0.034712231933210644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0145775447341701e-05, 'l1_Layer_2': 4.0529616342491026e-05, 'l1_Layer_3': 9.053740282309587e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:56:10,338]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:56:15,266]\u001b[0m Trial 1196 finished with value: 5.05170492533865 and parameters: {'n_hidden': 3, 'learning_rate': 0.001809664695638365, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0013065805211274623, 'dropout_rate_Layer_2': 0.37629581993831407, 'dropout_rate_Layer_3': 0.2890743745020086, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007123782643478792, 'l1_Layer_2': 0.013683212441573368, 'l1_Layer_3': 4.977219486906056e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 290}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 12.85% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 13.46% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:56:20,584]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:57:06,128]\u001b[0m Trial 1204 finished with value: 4.737031879618182 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017133545751310483, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1329693929606007, 'dropout_rate_Layer_2': 0.09419702550281994, 'dropout_rate_Layer_3': 0.04572540704126084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0204074398637524e-05, 'l1_Layer_2': 7.243571497186979e-05, 'l1_Layer_3': 9.764541097412704e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 12.02% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.72 | sMAPE for Test Set is: 13.36% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:57:15,654]\u001b[0m Trial 1210 finished with value: 4.582679202658726 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006373205160339687, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0522128582670698, 'dropout_rate_Layer_2': 0.08481639241974669, 'dropout_rate_Layer_3': 0.018564541027818855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3768084165680743e-05, 'l1_Layer_2': 1.665757197733481e-05, 'l1_Layer_3': 0.0010898748877367372, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 175}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 11.58% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 12.48% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:57:19,947]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:57:32,097]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:57:51,280]\u001b[0m Trial 1211 finished with value: 4.933776069588724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022321448003889766, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03925704113719655, 'dropout_rate_Layer_2': 0.1116557800475585, 'dropout_rate_Layer_3': 0.27208949667644644, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0060227448426142345, 'l1_Layer_2': 0.01675835610468623, 'l1_Layer_3': 5.855595929317719e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 12.42% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.64 | sMAPE for Test Set is: 13.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:57:56,308]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:58:01,311]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:58:05,205]\u001b[0m Trial 1208 finished with value: 4.723414290107272 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016247406428367198, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12233812677246494, 'dropout_rate_Layer_2': 0.09312743645941127, 'dropout_rate_Layer_3': 0.01830437947847486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3211103539626321e-05, 'l1_Layer_2': 6.479498439467243e-05, 'l1_Layer_3': 8.636303246745753e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.97% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 13.38% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:58:09,969]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:58:18,976]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:58:31,916]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:58:36,656]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:58:37,098]\u001b[0m Trial 1219 finished with value: 5.14924667749547 and parameters: {'n_hidden': 4, 'learning_rate': 0.004073351496291241, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06498627952847322, 'dropout_rate_Layer_2': 0.039467024157188016, 'dropout_rate_Layer_3': 0.3753483849904832, 'dropout_rate_Layer_4': 0.2702251134069145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.516718466671567e-05, 'l1_Layer_2': 0.001160606457023255, 'l1_Layer_3': 1.0293206215534743e-05, 'l1_Layer_4': 0.003397230477920822, 'n_units_Layer_1': 90, 'n_units_Layer_2': 95, 'n_units_Layer_3': 50, 'n_units_Layer_4': 150}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.51 | sMAPE for Test Set is: 16.86% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:58:37,760]\u001b[0m Trial 1206 finished with value: 4.95365119912771 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023486796270079952, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038762527496092054, 'dropout_rate_Layer_2': 0.17082027905713615, 'dropout_rate_Layer_3': 0.2665469335530739, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01373520712822577, 'l1_Layer_2': 0.02246193878021042, 'l1_Layer_3': 4.187108197884953e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 65, 'n_units_Layer_3': 285}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 12.42% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 13.59% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:58:52,982]\u001b[0m Trial 1214 finished with value: 5.020670139976055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023727640606478495, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041415869065242875, 'dropout_rate_Layer_2': 0.14825954930447, 'dropout_rate_Layer_3': 0.2697529859526004, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006719816504421723, 'l1_Layer_2': 0.014380170212027277, 'l1_Layer_3': 4.5130536407403254e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 65, 'n_units_Layer_3': 290}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 13.52% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 11:59:04,273]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 11:59:10,501]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:00:02,931]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:00:08,383]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:00:08,401]\u001b[0m Trial 1224 finished with value: 4.657087087326265 and parameters: {'n_hidden': 3, 'learning_rate': 0.001693508992384862, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13484026182204745, 'dropout_rate_Layer_2': 0.09198073798183862, 'dropout_rate_Layer_3': 0.02000070798033032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.018909764585309e-05, 'l1_Layer_2': 4.76608273371611e-05, 'l1_Layer_3': 0.00012626969908770703, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 160}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 11.71% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 13.60% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:00:18,812]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:00:20,282]\u001b[0m Trial 1227 finished with value: 4.970725412781679 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027340255711933315, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0432872275450454, 'dropout_rate_Layer_2': 0.08967690267839622, 'dropout_rate_Layer_3': 0.2734942003525327, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01962215367309554, 'l1_Layer_2': 0.010118854826760067, 'l1_Layer_3': 4.788406568574528e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 285, 'n_units_Layer_3': 300}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 13.93% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:00:27,705]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:00:45,260]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 12.68% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:00:51,792]\u001b[0m Trial 1226 finished with value: 4.734088776173761 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018131127417912354, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13022142535924106, 'dropout_rate_Layer_2': 0.08902902448876858, 'dropout_rate_Layer_3': 0.01913386344848774, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3662062006990326e-05, 'l1_Layer_2': 4.940476140126304e-05, 'l1_Layer_3': 0.0001232843143968653, 'n_units_Layer_1': 75, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:01:00,088]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:01:00,375]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:01:22,160]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:02:03,841]\u001b[0m Trial 1233 finished with value: 4.804756562314664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017294108112006848, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1327601563662648, 'dropout_rate_Layer_2': 0.09161449123067772, 'dropout_rate_Layer_3': 0.01675858427482793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2718668081427008e-05, 'l1_Layer_2': 5.663484617055801e-05, 'l1_Layer_3': 0.00012605929884839577, 'n_units_Layer_1': 60, 'n_units_Layer_2': 265, 'n_units_Layer_3': 145}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 12.85% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:02:11,970]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:02:19,306]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:02:57,329]\u001b[0m Trial 1236 finished with value: 4.612569549838479 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006474422726197922, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05465336955292456, 'dropout_rate_Layer_2': 0.08937773517294502, 'dropout_rate_Layer_3': 0.012066621283096915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7653107397890133e-05, 'l1_Layer_2': 1.6206634016785995e-05, 'l1_Layer_3': 0.0007564289980674426, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 11.63% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.24 | sMAPE for Test Set is: 12.23% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:03:06,551]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 12.71% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 13.09% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:03:11,259]\u001b[0m Trial 1241 finished with value: 5.0597470314853465 and parameters: {'n_hidden': 3, 'learning_rate': 0.01919633618833213, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10238455861006152, 'dropout_rate_Layer_2': 0.021584389319871333, 'dropout_rate_Layer_3': 0.2058615295067527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.7259442222115536e-05, 'l1_Layer_2': 0.01668676517323236, 'l1_Layer_3': 7.211156987680939e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 280, 'n_units_Layer_3': 245}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:03:21,350]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:03:22,070]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:03:44,283]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:04:06,816]\u001b[0m Trial 1240 finished with value: 4.998177635913899 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023305802855566123, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03097527744506804, 'dropout_rate_Layer_2': 0.06398640296735097, 'dropout_rate_Layer_3': 0.2658451665374451, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.021403551410968193, 'l1_Layer_2': 0.007436485538623792, 'l1_Layer_3': 8.559434399333668e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 12.60% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 13.08% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:04:10,990]\u001b[0m Trial 1239 finished with value: 4.578012030335556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006776532918750457, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.054762156829424445, 'dropout_rate_Layer_2': 0.08826962456677204, 'dropout_rate_Layer_3': 0.01549182825336673, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.734620858779906e-05, 'l1_Layer_2': 1.6869309590425355e-05, 'l1_Layer_3': 0.0007779713319566339, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 12.92% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:04:14,061]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:04:21,748]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:04:29,887]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:04:37,710]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:04:40,047]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:04:47,476]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:05:33,172]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:05:56,154]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:06:03,359]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:06:26,386]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:06:53,500]\u001b[0m Trial 1259 finished with value: 40.30341139717919 and parameters: {'n_hidden': 3, 'learning_rate': 0.05833802276807822, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2498455061301768, 'dropout_rate_Layer_2': 0.03565850182684385, 'dropout_rate_Layer_3': 0.17054138623624004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011297493674290067, 'l1_Layer_2': 9.509977748538069e-05, 'l1_Layer_3': 3.567881461223732e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 100, 'n_units_Layer_3': 75}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.30 | sMAPE for Validation Set is: 159.08% | rMAE for Validation Set is: 4.73\n",
      "MAE for Test Set is: 46.41 | sMAPE for Test Set is: 164.15% | rMAE for Test Set is: 4.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:07:01,388]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:07:09,399]\u001b[0m Trial 1254 finished with value: 5.026480128902741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023481353933685486, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0007052333626945542, 'dropout_rate_Layer_2': 0.06238752389699593, 'dropout_rate_Layer_3': 0.25595420573044836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.021694965912917145, 'l1_Layer_2': 0.007053195197091366, 'l1_Layer_3': 4.2920992181301144e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 12.70% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.65 | sMAPE for Test Set is: 13.20% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:07:29,022]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:07:36,864]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:07:44,387]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:07:59,740]\u001b[0m Trial 1251 finished with value: 4.7866816456446655 and parameters: {'n_hidden': 3, 'learning_rate': 0.002329081582900341, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0007123220302085058, 'dropout_rate_Layer_2': 0.056706220472143944, 'dropout_rate_Layer_3': 0.26693148142891265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0173306823213283, 'l1_Layer_2': 0.01143345404223307, 'l1_Layer_3': 5.506662603924118e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 11.98% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 12.94% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:08:17,489]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:08:27,442]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:08:27,968]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:08:38,306]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:08:41,050]\u001b[0m Trial 1261 finished with value: 4.552223017133592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007313789067153543, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06406141359060298, 'dropout_rate_Layer_2': 0.066091418898675, 'dropout_rate_Layer_3': 0.013407017968174522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1899698432635109e-05, 'l1_Layer_2': 1.1666889777921054e-05, 'l1_Layer_3': 0.0004764496943732373, 'n_units_Layer_1': 205, 'n_units_Layer_2': 285, 'n_units_Layer_3': 185}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 12.37% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:08:43,675]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:09:03,470]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:09:28,469]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:09:43,527]\u001b[0m Trial 1271 finished with value: 4.570561248532442 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007415175962042935, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05310801421064262, 'dropout_rate_Layer_2': 0.04855005045320261, 'dropout_rate_Layer_3': 0.028559449597230314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0111934242736871e-05, 'l1_Layer_2': 1.2317523172254853e-05, 'l1_Layer_3': 0.00037635893385646983, 'n_units_Layer_1': 195, 'n_units_Layer_2': 275, 'n_units_Layer_3': 185}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 11.52% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 12.37% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:10:06,850]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:10:16,939]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:10:29,230]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:10:39,234]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:10:47,240]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:10:54,822]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:11:14,810]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:11:22,546]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:11:39,827]\u001b[0m Trial 1272 finished with value: 4.726481603122068 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015577145522196903, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12174777810482545, 'dropout_rate_Layer_2': 0.09450322571920482, 'dropout_rate_Layer_3': 0.01832442172374886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2799163162011563e-05, 'l1_Layer_2': 2.9711546105712698e-05, 'l1_Layer_3': 0.0001272562244713645, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 155}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 11.88% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.64 | sMAPE for Test Set is: 12.98% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:11:43,240]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:11:52,908]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:11:55,632]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:12:05,495]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:12:10,976]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:12:19,179]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:12:28,902]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:12:36,678]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:12:46,611]\u001b[0m Trial 1275 finished with value: 4.673515397974011 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015433876937153844, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13889259156039988, 'dropout_rate_Layer_2': 0.097371073845018, 'dropout_rate_Layer_3': 0.023372356535375595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.225027915997624e-05, 'l1_Layer_2': 2.7897893998540104e-05, 'l1_Layer_3': 0.00011819843724914092, 'n_units_Layer_1': 55, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 11.72% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 12.71% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:13:17,508]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:13:24,004]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:13:29,902]\u001b[0m Trial 1283 finished with value: 4.767734101293695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014393033175259429, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12218958163891579, 'dropout_rate_Layer_2': 0.09999603551816488, 'dropout_rate_Layer_3': 0.027378337815847538, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2846646015642809e-05, 'l1_Layer_2': 2.9114855123995928e-05, 'l1_Layer_3': 0.00011097455150911112, 'n_units_Layer_1': 55, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 11.95% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 13.05% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:13:35,541]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:13:47,777]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:13:52,676]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:13:56,090]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:14:02,666]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:14:12,990]\u001b[0m Trial 1293 finished with value: 4.728971676200461 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015575364228729094, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12141204832965932, 'dropout_rate_Layer_2': 0.09120174175202383, 'dropout_rate_Layer_3': 0.024853799482081485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.272006511738199e-05, 'l1_Layer_2': 2.3183658816047125e-05, 'l1_Layer_3': 0.00012759227661639382, 'n_units_Layer_1': 55, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 12.24% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:14:17,038]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:14:25,341]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:14:30,163]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:14:30,572]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:14:32,128]\u001b[0m Trial 1295 finished with value: 4.748794424942308 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015380903136349372, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12451341560119251, 'dropout_rate_Layer_2': 0.09519704747965371, 'dropout_rate_Layer_3': 0.021047432205270503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2984186887108748e-05, 'l1_Layer_2': 3.0162852415399358e-05, 'l1_Layer_3': 0.00011700306406254316, 'n_units_Layer_1': 55, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 13.35% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:14:40,216]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:14:45,376]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:14:51,008]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:14:55,349]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:15:00,286]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:15:03,260]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:15:05,514]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:15:11,715]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:15:16,446]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:15:26,207]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:15:36,430]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:15:41,352]\u001b[0m Trial 1299 finished with value: 4.718726923110544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014979221512768804, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041641959934837415, 'dropout_rate_Layer_2': 0.0732553671866239, 'dropout_rate_Layer_3': 0.28517050255515963, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006098115365659314, 'l1_Layer_2': 0.006802485724141947, 'l1_Layer_3': 5.359548087129594e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 75, 'n_units_Layer_3': 290}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 12.58% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:15:48,088]\u001b[0m Trial 1312 finished with value: 4.755154664056927 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015387323760527435, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12095014461457095, 'dropout_rate_Layer_2': 0.09904854119111975, 'dropout_rate_Layer_3': 0.021246426363044493, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3356428222685748e-05, 'l1_Layer_2': 2.300317572532327e-05, 'l1_Layer_3': 0.0001811521450426531, 'n_units_Layer_1': 60, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 11.96% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 13.01% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:15:48,871]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:15:49,694]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:15:56,673]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:15:58,368]\u001b[0m Trial 1317 finished with value: 4.539756021819301 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007664229227749954, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04448283070541047, 'dropout_rate_Layer_2': 0.09966253939616414, 'dropout_rate_Layer_3': 0.02342832113115457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5420699292846094e-05, 'l1_Layer_2': 1.4603131743496768e-05, 'l1_Layer_3': 0.00047747729512296445, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 155}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 12.34% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:16:06,743]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:16:09,916]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:16:15,298]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:16:22,932]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:16:23,038]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:16:36,316]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:16:41,046]\u001b[0m Trial 1328 finished with value: 5.725765253227738 and parameters: {'n_hidden': 3, 'learning_rate': 0.047411135776337765, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.136429433870414, 'dropout_rate_Layer_2': 0.0018107794666779083, 'dropout_rate_Layer_3': 0.20184376577279992, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.355987610774832e-05, 'l1_Layer_2': 0.036408529348004225, 'l1_Layer_3': 3.4270292132529466e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 250}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 13.82% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 14.77% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:16:43,367]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:16:48,854]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:17:12,328]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:17:23,792]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:17:41,650]\u001b[0m Trial 1321 finished with value: 4.606015483911254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005010325053880829, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06641692569682046, 'dropout_rate_Layer_2': 0.06824764151512468, 'dropout_rate_Layer_3': 0.0272935571252386, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1674514429353011e-05, 'l1_Layer_2': 1.5193046807774979e-05, 'l1_Layer_3': 0.0009084504550953083, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 11.58% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 12.09% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:18:09,891]\u001b[0m Trial 1331 finished with value: 4.780905500825779 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014011398700392555, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03359322386557405, 'dropout_rate_Layer_2': 0.05577187688920249, 'dropout_rate_Layer_3': 0.2747349899832718, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005755296370902912, 'l1_Layer_2': 0.010842400271726052, 'l1_Layer_3': 4.550756154661925e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 70, 'n_units_Layer_3': 295}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 11.94% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 12.75% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:18:14,185]\u001b[0m Trial 1330 finished with value: 4.746885509138001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014302332031421703, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10116097542410424, 'dropout_rate_Layer_2': 0.08635687347344946, 'dropout_rate_Layer_3': 0.014142626484974751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5424749071560625e-05, 'l1_Layer_2': 3.721437191613071e-05, 'l1_Layer_3': 0.00027075197890104585, 'n_units_Layer_1': 65, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 13.14% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:18:14,871]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:18:21,889]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:18:22,357]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:18:49,718]\u001b[0m Trial 1335 finished with value: 4.989604208367275 and parameters: {'n_hidden': 3, 'learning_rate': 0.002266619917771705, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04842361388094704, 'dropout_rate_Layer_2': 0.06391890921767315, 'dropout_rate_Layer_3': 0.26024155796831816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014016597100837011, 'l1_Layer_2': 0.016628419516879357, 'l1_Layer_3': 3.507230729432863e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 65, 'n_units_Layer_3': 285}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.65 | sMAPE for Test Set is: 13.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:19:00,431]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:19:10,447]\u001b[0m Trial 1340 finished with value: 4.695557462765074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015723207098826944, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10002373566407978, 'dropout_rate_Layer_2': 0.08643222944118874, 'dropout_rate_Layer_3': 0.012402520513514509, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6301697669807107e-05, 'l1_Layer_2': 3.927780067341809e-05, 'l1_Layer_3': 0.00027214213154022864, 'n_units_Layer_1': 65, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.35 | sMAPE for Test Set is: 12.48% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:19:10,813]\u001b[0m Trial 1336 finished with value: 4.739297765686525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014766956039683457, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1018801778997428, 'dropout_rate_Layer_2': 0.0870220329472089, 'dropout_rate_Layer_3': 0.011191534840557918, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5378228179915427e-05, 'l1_Layer_2': 3.488544091803194e-05, 'l1_Layer_3': 0.00011581018778607806, 'n_units_Layer_1': 60, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 13.17% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:19:17,887]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:19:59,141]\u001b[0m Trial 1343 finished with value: 4.970642881047127 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023913707026834248, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027433761027247906, 'dropout_rate_Layer_2': 0.1770173077964205, 'dropout_rate_Layer_3': 0.25777947808000523, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011832053703854355, 'l1_Layer_2': 0.020900805611384018, 'l1_Layer_3': 3.684075658207761e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 70, 'n_units_Layer_3': 295}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 12.54% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 13.02% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:19:59,560]\u001b[0m Trial 1341 finished with value: 4.793400688686407 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016335738317471045, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020728165218833926, 'dropout_rate_Layer_2': 0.06547916056558042, 'dropout_rate_Layer_3': 0.2797104624828447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011999727453650601, 'l1_Layer_2': 0.006217832851182321, 'l1_Layer_3': 7.487204833891372e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 80, 'n_units_Layer_3': 295}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 12.69% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:20:08,022]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:20:08,212]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:20:21,741]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:20:26,874]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:20:35,226]\u001b[0m Trial 1345 finished with value: 4.9229967539936474 and parameters: {'n_hidden': 3, 'learning_rate': 0.001286954439624326, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028981971918432207, 'dropout_rate_Layer_2': 0.05019031225969453, 'dropout_rate_Layer_3': 0.2577711501436802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012272043277420472, 'l1_Layer_2': 0.020900869930794062, 'l1_Layer_3': 3.556583373439065e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 70, 'n_units_Layer_3': 295}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 13.10% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:20:42,296]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:20:47,966]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:20:53,624]\u001b[0m Trial 1348 finished with value: 4.767762867762834 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015193063458282248, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10279918201031019, 'dropout_rate_Layer_2': 0.07688858086004396, 'dropout_rate_Layer_3': 0.008740726514862462, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6357801354153248e-05, 'l1_Layer_2': 3.4094807770439346e-05, 'l1_Layer_3': 0.00025627877468823715, 'n_units_Layer_1': 65, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 12.99% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:20:58,011]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:21:02,625]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:21:03,228]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:21:13,011]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:21:17,159]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:21:19,299]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:21:19,368]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:21:29,503]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:21:29,643]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:21:35,926]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:21:38,522]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:21:51,189]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:22:06,522]\u001b[0m Trial 1368 finished with value: 5.194881260332893 and parameters: {'n_hidden': 3, 'learning_rate': 0.02685530660216474, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05235760859319089, 'dropout_rate_Layer_2': 0.0011991195048512357, 'dropout_rate_Layer_3': 0.15453499619032518, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003746661010570185, 'l1_Layer_2': 0.09898514789251389, 'l1_Layer_3': 5.097944241643375e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 245, 'n_units_Layer_3': 220}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 12.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 13.57% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:22:33,770]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:22:39,522]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:22:40,256]\u001b[0m Trial 1365 finished with value: 4.71834582643136 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009323179291420147, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30225578027971256, 'dropout_rate_Layer_2': 0.026463562653278747, 'dropout_rate_Layer_3': 0.11672864884310197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006912343371557913, 'l1_Layer_2': 6.265232040620215e-05, 'l1_Layer_3': 4.428327277172488e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 130, 'n_units_Layer_3': 175}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 12.01% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 12.53% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:22:47,274]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:22:51,557]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:22:52,150]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:01,801]\u001b[0m Trial 1366 finished with value: 4.738063548090738 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015617024177394675, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10193008431591069, 'dropout_rate_Layer_2': 0.057470106040158356, 'dropout_rate_Layer_3': 0.01131857939923573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.636983289851388e-05, 'l1_Layer_2': 3.6132578774120026e-05, 'l1_Layer_3': 0.0002786183998029402, 'n_units_Layer_1': 65, 'n_units_Layer_2': 275, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 12.00% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 12.72% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:23:05,365]\u001b[0m Trial 1362 finished with value: 4.951520629635071 and parameters: {'n_hidden': 3, 'learning_rate': 0.000936017579878011, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02242518487386844, 'dropout_rate_Layer_2': 0.052144110633976476, 'dropout_rate_Layer_3': 0.25003517426486704, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016532434738123318, 'l1_Layer_2': 0.016294103689984872, 'l1_Layer_3': 9.6195720418108e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 80, 'n_units_Layer_3': 295}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 12.45% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 12.88% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:23:06,935]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:09,434]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:12,666]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:21,523]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:24,552]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:29,599]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:29,968]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:35,840]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:41,503]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:45,780]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:54,134]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:23:59,229]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:24:05,763]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:24:23,623]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:24:48,819]\u001b[0m Trial 1390 finished with value: 4.881973862243987 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019541963071035475, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018908683635654653, 'dropout_rate_Layer_2': 0.04191654920686416, 'dropout_rate_Layer_3': 0.2638650915472879, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015070780103734027, 'l1_Layer_2': 0.021614764362997984, 'l1_Layer_3': 0.00012025562718973223, 'n_units_Layer_1': 105, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 12.82% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:24:54,364]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:24:54,990]\u001b[0m Trial 1386 finished with value: 4.95458735806982 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019082688544118113, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017800118477658763, 'dropout_rate_Layer_2': 0.03819784035164015, 'dropout_rate_Layer_3': 0.266262184117978, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011471098601933518, 'l1_Layer_2': 0.020068152977727016, 'l1_Layer_3': 0.00011930222060150205, 'n_units_Layer_1': 155, 'n_units_Layer_2': 90, 'n_units_Layer_3': 300}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 13.04% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:25:03,103]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:25:16,552]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:25:18,108]\u001b[0m Trial 1384 finished with value: 4.74995777104376 and parameters: {'n_hidden': 3, 'learning_rate': 0.001401284840104607, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06455422182109607, 'dropout_rate_Layer_2': 0.0841678020908915, 'dropout_rate_Layer_3': 0.024433276742334333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9097743900447105e-05, 'l1_Layer_2': 5.216730405030056e-05, 'l1_Layer_3': 0.00021057949086029777, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 12.49% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:25:20,530]\u001b[0m Trial 1391 finished with value: 4.964328191848662 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019600512350480986, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02052578833650935, 'dropout_rate_Layer_2': 0.043418594547045525, 'dropout_rate_Layer_3': 0.26193945674647356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0148680997260099, 'l1_Layer_2': 0.02024405501875592, 'l1_Layer_3': 0.00011902992144993434, 'n_units_Layer_1': 105, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 12.40% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 13.20% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:25:24,044]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:25:28,911]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:25:34,382]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:25:39,695]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:25:43,633]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:25:48,498]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:25:52,277]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:25:58,904]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:26:14,195]\u001b[0m Trial 1399 finished with value: 4.962489379389104 and parameters: {'n_hidden': 3, 'learning_rate': 0.001902770299865877, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029774093804349117, 'dropout_rate_Layer_2': 0.01917805404973848, 'dropout_rate_Layer_3': 0.2435835053771011, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01214941158343576, 'l1_Layer_2': 0.023970028790650685, 'l1_Layer_3': 0.00010232233942814598, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 295}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:26:14,316]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 12.42% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 13.10% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:26:16,479]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:26:18,167]\u001b[0m Trial 1406 finished with value: 4.564023136151348 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007110911241555608, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04644047233400195, 'dropout_rate_Layer_2': 0.06308247383036844, 'dropout_rate_Layer_3': 0.02708364879438942, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.171083765340822e-05, 'l1_Layer_2': 1.1763348582791535e-05, 'l1_Layer_3': 0.00040995024674414965, 'n_units_Layer_1': 220, 'n_units_Layer_2': 280, 'n_units_Layer_3': 175}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 11.50% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 12.49% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:26:23,484]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:26:23,594]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:26:31,313]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:26:33,546]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:26:44,765]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:26:46,681]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:26:52,901]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:27:04,713]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:27:08,948]\u001b[0m Trial 1411 finished with value: 4.822586904264695 and parameters: {'n_hidden': 3, 'learning_rate': 0.002088987241033363, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05317879228473696, 'dropout_rate_Layer_2': 0.08249969759530532, 'dropout_rate_Layer_3': 0.010709381397168228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5673533854681125e-05, 'l1_Layer_2': 0.00010033999955867794, 'l1_Layer_3': 0.0003660461591500365, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 13.63% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:27:14,396]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:27:19,901]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:27:29,505]\u001b[0m Trial 1412 finished with value: 4.582461048262523 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008059748577786658, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03169200642032345, 'dropout_rate_Layer_2': 0.09306583315992575, 'dropout_rate_Layer_3': 0.04791958234192199, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1874384138038529e-05, 'l1_Layer_2': 1.5581592668026274e-05, 'l1_Layer_3': 0.00031208303143388024, 'n_units_Layer_1': 220, 'n_units_Layer_2': 255, 'n_units_Layer_3': 180}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 11.62% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 12.31% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:27:39,864]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 11.91% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.55 | sMAPE for Test Set is: 12.99% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:27:43,186]\u001b[0m Trial 1417 finished with value: 4.711986246526352 and parameters: {'n_hidden': 3, 'learning_rate': 0.002137952577503055, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049891779169773214, 'dropout_rate_Layer_2': 0.064843218159668, 'dropout_rate_Layer_3': 0.014121059937520997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6350553281891112e-05, 'l1_Layer_2': 8.375199242614912e-05, 'l1_Layer_3': 0.00021387494233381663, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:27:47,763]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:27:49,881]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:27:52,867]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:27:57,049]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:28:37,724]\u001b[0m Trial 1421 finished with value: 4.929323416764066 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016956619764458784, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009822382313469819, 'dropout_rate_Layer_2': 0.02816767769737135, 'dropout_rate_Layer_3': 0.24666057492533988, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011630516775335617, 'l1_Layer_2': 0.022768070577806644, 'l1_Layer_3': 0.00011171098353482502, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 300}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 13.17% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:28:44,745]\u001b[0m Trial 1425 finished with value: 4.879846827415559 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016490316286305368, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03200852968878155, 'dropout_rate_Layer_2': 0.05666890727088122, 'dropout_rate_Layer_3': 0.0004349631288756029, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8063744592527446e-05, 'l1_Layer_2': 3.636838950568377e-05, 'l1_Layer_3': 0.00015692103864189236, 'n_units_Layer_1': 65, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 13.36% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:29:05,318]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:29:27,711]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:29:35,241]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:30:15,682]\u001b[0m Trial 1430 finished with value: 5.016871000042175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016047415039777426, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016028854396463503, 'dropout_rate_Layer_2': 0.03213545832562004, 'dropout_rate_Layer_3': 0.24592438608293896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011143029452155704, 'l1_Layer_2': 0.022062933728416126, 'l1_Layer_3': 0.000148786203790178, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 300}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 12.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 13.20% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:30:17,792]\u001b[0m Trial 1427 finished with value: 4.698562321698421 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016546338527755754, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03058618837961058, 'dropout_rate_Layer_2': 0.061052105430144776, 'dropout_rate_Layer_3': 0.0002756465983887995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7573168102757848e-05, 'l1_Layer_2': 3.441325794608847e-05, 'l1_Layer_3': 0.00014614851518295058, 'n_units_Layer_1': 65, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 12.97% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:30:33,116]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:30:43,813]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:31:06,104]\u001b[0m Trial 1429 finished with value: 4.849686555813588 and parameters: {'n_hidden': 3, 'learning_rate': 0.001607873879439383, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01092246906868757, 'dropout_rate_Layer_2': 0.00018098594864018186, 'dropout_rate_Layer_3': 0.2457631832022616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01204924904077609, 'l1_Layer_2': 0.02365209008133148, 'l1_Layer_3': 0.0001622340839643481, 'n_units_Layer_1': 155, 'n_units_Layer_2': 100, 'n_units_Layer_3': 300}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 12.70% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:31:08,197]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:31:34,086]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:31:44,125]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:31:54,441]\u001b[0m Trial 1436 finished with value: 5.059691391577268 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018470526257380177, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0210448780416998, 'dropout_rate_Layer_2': 0.025212406536206686, 'dropout_rate_Layer_3': 0.27474154337970746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01372301351245554, 'l1_Layer_2': 0.024372270962641888, 'l1_Layer_3': 0.00017873934788734236, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 295}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 13.29% | rMAE for Test Set is: 0.58\n",
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 13.22% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:31:57,266]\u001b[0m Trial 1438 finished with value: 4.676348667715293 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007957704452100685, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04480261541326468, 'dropout_rate_Layer_2': 0.08298038115713058, 'dropout_rate_Layer_3': 0.06166721443042912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3761086995741229e-05, 'l1_Layer_2': 1.4210686489706455e-05, 'l1_Layer_3': 0.00026946044027810706, 'n_units_Layer_1': 215, 'n_units_Layer_2': 285, 'n_units_Layer_3': 180}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:31:59,642]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:32:14,372]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:32:20,035]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:32:26,724]\u001b[0m Trial 1434 finished with value: 4.812702813463726 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016384062835323636, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04828962531321475, 'dropout_rate_Layer_2': 0.029475476115378776, 'dropout_rate_Layer_3': 0.015184857380665944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1112835243829585e-05, 'l1_Layer_2': 2.17091371565301e-05, 'l1_Layer_3': 0.00021521079596344858, 'n_units_Layer_1': 50, 'n_units_Layer_2': 270, 'n_units_Layer_3': 165}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 12.66% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:32:31,777]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:32:44,786]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:32:57,295]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:33:05,182]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:33:12,854]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:33:18,507]\u001b[0m Trial 1442 finished with value: 5.014793129673218 and parameters: {'n_hidden': 3, 'learning_rate': 0.001981261228712307, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03347373547287578, 'dropout_rate_Layer_2': 0.014501325301877782, 'dropout_rate_Layer_3': 0.25399627483105364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012650947316076327, 'l1_Layer_2': 0.024879608973142484, 'l1_Layer_3': 0.00010087442190784462, 'n_units_Layer_1': 165, 'n_units_Layer_2': 100, 'n_units_Layer_3': 300}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 12.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 13.33% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:33:25,574]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:33:32,980]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:33:43,325]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:33:45,309]\u001b[0m Trial 1454 finished with value: 10.103032476773253 and parameters: {'n_hidden': 3, 'learning_rate': 0.0709069228714845, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29130216089801453, 'dropout_rate_Layer_2': 0.1560523362627704, 'dropout_rate_Layer_3': 0.24871866639509488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.6722496938831046e-05, 'l1_Layer_2': 0.03722493061254386, 'l1_Layer_3': 0.00044459910455999706, 'n_units_Layer_1': 50, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.10 | sMAPE for Validation Set is: 23.40% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 25.01% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:34:02,969]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:34:05,912]\u001b[0m Trial 1445 finished with value: 4.668360006436289 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009204900534299258, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30661984757718785, 'dropout_rate_Layer_2': 0.025565315428896, 'dropout_rate_Layer_3': 0.11872191622480585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005867892587161117, 'l1_Layer_2': 7.412173882695496e-05, 'l1_Layer_3': 3.998335252647373e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 135, 'n_units_Layer_3': 175}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 12.64% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:34:18,075]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:34:23,667]\u001b[0m Trial 1452 finished with value: 4.7743381599030235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009173736843092779, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30680115312668443, 'dropout_rate_Layer_2': 0.0260833296286082, 'dropout_rate_Layer_3': 0.11762543259990266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001368522913863596, 'l1_Layer_2': 3.102851818256997e-05, 'l1_Layer_3': 4.284294413365428e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 135, 'n_units_Layer_3': 170}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 12.09% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.43 | sMAPE for Test Set is: 12.75% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:34:30,818]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:34:34,298]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:34:56,428]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:35:03,654]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:35:11,221]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:35:18,933]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:35:19,428]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:35:36,320]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:35:49,441]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:36:01,761]\u001b[0m Trial 1462 finished with value: 5.00282922972514 and parameters: {'n_hidden': 3, 'learning_rate': 0.019189433091424426, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32750082834536964, 'dropout_rate_Layer_2': 0.0710778053727463, 'dropout_rate_Layer_3': 0.21663839462688902, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007762645017895157, 'l1_Layer_2': 0.013025482058325533, 'l1_Layer_3': 0.00010752515254283502, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 285}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 12.42% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 13.60% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:36:09,978]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:36:47,448]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:36:54,427]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:36:55,254]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 13.63% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 14.50% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:37:02,958]\u001b[0m Trial 1472 finished with value: 5.282321413215979 and parameters: {'n_hidden': 3, 'learning_rate': 0.008581181472892179, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32653160921485314, 'dropout_rate_Layer_2': 0.000815439407577747, 'dropout_rate_Layer_3': 0.10777066989853124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005684115737039647, 'l1_Layer_2': 8.072842126742087e-05, 'l1_Layer_3': 2.0407324704413056e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 210}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:37:17,428]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:37:22,165]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:37:25,606]\u001b[0m Trial 1469 finished with value: 4.810650501504291 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013411697748626327, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010899375442743608, 'dropout_rate_Layer_2': 0.0708902775923426, 'dropout_rate_Layer_3': 0.02431489552905873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3455199025804107e-05, 'l1_Layer_2': 5.3800207821190724e-05, 'l1_Layer_3': 0.00019853556920627286, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 155}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 12.66% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:37:40,305]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:37:47,700]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:37:48,084]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:37:52,684]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:38:07,640]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:38:22,726]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:38:33,316]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:38:48,617]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:38:53,339]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:39:05,994]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:39:11,092]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:39:16,685]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:39:22,521]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:39:23,938]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:39:24,231]\u001b[0m Trial 1481 finished with value: 9.501037688779208 and parameters: {'n_hidden': 3, 'learning_rate': 0.04111124083033486, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1941151030792062, 'dropout_rate_Layer_2': 0.35078134942291683, 'dropout_rate_Layer_3': 0.24947496932374405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00019946918647094803, 'l1_Layer_2': 0.0033822293894586047, 'l1_Layer_3': 0.0015081981345753655, 'n_units_Layer_1': 175, 'n_units_Layer_2': 60, 'n_units_Layer_3': 210}. Best is trial 1083 with value: 4.479189865646859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.50 | sMAPE for Validation Set is: 21.82% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 10.31 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 12:39:48,461]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:39:49,205]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:40:01,084]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:40:08,745]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:40:11,511]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:40:19,742]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:40:21,459]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:40:21,979]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 12:40:38,906]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-01-01, MAE is:6.63 & sMAPE is:77.46% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 77.46% & 0.26\n",
      "for 2018-01-02, MAE is:10.05 & sMAPE is:43.64% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.34 & 60.55% & 0.68\n",
      "for 2018-01-03, MAE is:7.01 & sMAPE is:44.45% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 55.18% & 0.56\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F0142FB4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:13.58 & sMAPE is:62.59% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 57.04% & 0.63\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F018C930D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:8.35 & sMAPE is:37.17% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.12 & 53.06% & 0.63\n",
      "for 2018-01-06, MAE is:6.76 & sMAPE is:21.37% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :8.73 & 47.78% & 0.60\n",
      "for 2018-01-07, MAE is:3.48 & sMAPE is:16.29% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 43.28% & 0.56\n",
      "for 2018-01-08, MAE is:10.35 & sMAPE is:35.13% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 42.26% & 0.52\n",
      "for 2018-01-09, MAE is:4.00 & sMAPE is:9.40% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 38.61% & 0.50\n",
      "for 2018-01-10, MAE is:4.68 & sMAPE is:12.37% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 35.99% & 0.47\n",
      "for 2018-01-11, MAE is:9.69 & sMAPE is:23.80% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 34.88% & 0.47\n",
      "for 2018-01-12, MAE is:3.55 & sMAPE is:8.00% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 32.64% & 0.46\n",
      "for 2018-01-13, MAE is:6.98 & sMAPE is:19.14% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 31.60% & 0.54\n",
      "for 2018-01-14, MAE is:3.67 & sMAPE is:10.59% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 30.10% & 0.52\n",
      "for 2018-01-15, MAE is:4.47 & sMAPE is:10.99% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 28.83% & 0.53\n",
      "for 2018-01-16, MAE is:4.26 & sMAPE is:19.62% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 28.25% & 0.52\n",
      "for 2018-01-17, MAE is:6.75 & sMAPE is:22.37% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 27.90% & 0.56\n",
      "for 2018-01-18, MAE is:5.74 & sMAPE is:22.06% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 27.58% & 0.56\n",
      "for 2018-01-19, MAE is:7.77 & sMAPE is:23.19% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 27.35% & 0.63\n",
      "for 2018-01-20, MAE is:8.69 & sMAPE is:25.77% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 27.27% & 0.70\n",
      "for 2018-01-21, MAE is:7.16 & sMAPE is:24.71% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 27.15% & 0.78\n",
      "for 2018-01-22, MAE is:4.78 & sMAPE is:16.96% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 26.68% & 0.78\n",
      "for 2018-01-23, MAE is:5.29 & sMAPE is:16.33% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 26.23% & 0.78\n",
      "for 2018-01-24, MAE is:3.86 & sMAPE is:15.57% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 25.79% & 0.77\n",
      "for 2018-01-25, MAE is:8.36 & sMAPE is:27.42% & rMAE is:2.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 25.86% & 0.84\n",
      "for 2018-01-26, MAE is:9.41 & sMAPE is:24.85% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 25.82% & 0.88\n",
      "for 2018-01-27, MAE is:4.36 & sMAPE is:12.34% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 25.32% & 0.88\n",
      "for 2018-01-28, MAE is:4.86 & sMAPE is:22.30% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 25.21% & 0.87\n",
      "for 2018-01-29, MAE is:4.11 & sMAPE is:13.56% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 24.81% & 0.87\n",
      "for 2018-01-30, MAE is:3.92 & sMAPE is:10.66% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 24.34% & 0.87\n",
      "for 2018-01-31, MAE is:6.53 & sMAPE is:17.88% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 24.13% & 0.87\n",
      "for 2018-02-01, MAE is:3.51 & sMAPE is:10.22% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 23.69% & 0.86\n",
      "for 2018-02-02, MAE is:4.06 & sMAPE is:11.22% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 23.32% & 0.86\n",
      "for 2018-02-03, MAE is:8.33 & sMAPE is:22.92% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 23.30% & 0.89\n",
      "for 2018-02-04, MAE is:5.70 & sMAPE is:16.16% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 23.10% & 0.88\n",
      "for 2018-02-05, MAE is:3.88 & sMAPE is:8.75% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 22.70% & 0.86\n",
      "for 2018-02-06, MAE is:8.86 & sMAPE is:19.45% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 22.61% & 0.86\n",
      "for 2018-02-07, MAE is:3.54 & sMAPE is:7.00% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 22.20% & 0.85\n",
      "for 2018-02-08, MAE is:5.97 & sMAPE is:11.26% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 21.92% & 0.83\n",
      "for 2018-02-09, MAE is:2.53 & sMAPE is:5.50% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 21.51% & 0.82\n",
      "for 2018-02-10, MAE is:8.21 & sMAPE is:21.67% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 21.52% & 0.87\n",
      "for 2018-02-11, MAE is:8.05 & sMAPE is:27.24% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 21.65% & 0.88\n",
      "for 2018-02-12, MAE is:4.68 & sMAPE is:11.22% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 21.41% & 0.88\n",
      "for 2018-02-13, MAE is:3.94 & sMAPE is:9.17% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 21.13% & 0.87\n",
      "for 2018-02-14, MAE is:4.90 & sMAPE is:11.04% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 20.91% & 0.87\n",
      "for 2018-02-15, MAE is:3.17 & sMAPE is:8.25% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 20.63% & 0.85\n",
      "for 2018-02-16, MAE is:3.04 & sMAPE is:7.32% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 20.35% & 0.85\n",
      "for 2018-02-17, MAE is:8.52 & sMAPE is:22.90% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 20.40% & 0.89\n",
      "for 2018-02-18, MAE is:4.95 & sMAPE is:13.51% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 20.26% & 0.88\n",
      "for 2018-02-19, MAE is:6.20 & sMAPE is:12.63% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 20.11% & 0.90\n",
      "for 2018-02-20, MAE is:4.31 & sMAPE is:8.82% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 19.89% & 0.89\n",
      "for 2018-02-21, MAE is:6.33 & sMAPE is:14.12% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 19.78% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-22, MAE is:3.91 & sMAPE is:7.94% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 19.55% & 0.90\n",
      "for 2018-02-23, MAE is:4.49 & sMAPE is:8.93% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 19.36% & 0.89\n",
      "for 2018-02-24, MAE is:10.21 & sMAPE is:21.04% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 19.39% & 0.89\n",
      "for 2018-02-25, MAE is:5.46 & sMAPE is:12.26% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 19.26% & 0.89\n",
      "for 2018-02-26, MAE is:4.59 & sMAPE is:7.56% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 19.05% & 0.88\n",
      "for 2018-02-27, MAE is:21.20 & sMAPE is:24.58% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.15% & 0.88\n",
      "for 2018-02-28, MAE is:9.82 & sMAPE is:12.20% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 19.03% & 0.87\n",
      "for 2018-03-01, MAE is:21.46 & sMAPE is:28.08% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 19.18% & 0.86\n",
      "for 2018-03-02, MAE is:25.12 & sMAPE is:31.93% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 19.39% & 0.86\n",
      "for 2018-03-03, MAE is:15.39 & sMAPE is:28.84% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 19.54% & 0.88\n",
      "for 2018-03-04, MAE is:3.91 & sMAPE is:9.27% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 19.38% & 0.88\n",
      "for 2018-03-05, MAE is:6.49 & sMAPE is:11.61% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 19.26% & 0.88\n",
      "for 2018-03-06, MAE is:4.45 & sMAPE is:8.81% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 19.10% & 0.87\n",
      "for 2018-03-07, MAE is:3.41 & sMAPE is:7.10% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 18.92% & 0.86\n",
      "for 2018-03-08, MAE is:3.29 & sMAPE is:7.46% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 18.75% & 0.85\n",
      "for 2018-03-09, MAE is:4.81 & sMAPE is:10.08% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 18.62% & 0.84\n",
      "for 2018-03-10, MAE is:7.08 & sMAPE is:22.95% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 18.68% & 0.83\n",
      "for 2018-03-11, MAE is:3.26 & sMAPE is:13.61% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 18.61% & 0.82\n",
      "for 2018-03-12, MAE is:6.35 & sMAPE is:19.47% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 18.62% & 0.82\n",
      "for 2018-03-13, MAE is:11.89 & sMAPE is:28.84% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 18.76% & 0.84\n",
      "for 2018-03-14, MAE is:6.76 & sMAPE is:14.02% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 18.70% & 0.85\n",
      "for 2018-03-15, MAE is:6.73 & sMAPE is:21.64% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 18.74% & 0.85\n",
      "for 2018-03-16, MAE is:9.31 & sMAPE is:22.50% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 18.79% & 0.86\n",
      "for 2018-03-17, MAE is:13.41 & sMAPE is:28.86% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 18.92% & 0.86\n",
      "for 2018-03-18, MAE is:3.81 & sMAPE is:10.10% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 18.81% & 0.85\n",
      "for 2018-03-19, MAE is:6.99 & sMAPE is:12.47% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 18.72% & 0.85\n",
      "for 2018-03-20, MAE is:7.50 & sMAPE is:15.01% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 18.68% & 0.85\n",
      "for 2018-03-21, MAE is:6.19 & sMAPE is:11.07% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 18.58% & 0.85\n",
      "for 2018-03-22, MAE is:11.05 & sMAPE is:18.70% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 18.58% & 0.84\n",
      "for 2018-03-23, MAE is:7.35 & sMAPE is:13.77% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 18.53% & 0.84\n",
      "for 2018-03-24, MAE is:6.20 & sMAPE is:13.93% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 18.47% & 0.84\n",
      "for 2018-03-25, MAE is:7.89 & sMAPE is:20.55% & rMAE is:2.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 18.49% & 0.86\n",
      "for 2018-03-26, MAE is:6.07 & sMAPE is:11.14% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 18.41% & 0.86\n",
      "for 2018-03-27, MAE is:3.35 & sMAPE is:7.07% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 18.28% & 0.86\n",
      "for 2018-03-28, MAE is:3.90 & sMAPE is:9.82% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 18.18% & 0.85\n",
      "for 2018-03-29, MAE is:6.23 & sMAPE is:14.18% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 18.13% & 0.85\n",
      "for 2018-03-30, MAE is:4.49 & sMAPE is:10.86% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 18.05% & 0.84\n",
      "for 2018-03-31, MAE is:2.55 & sMAPE is:7.52% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 17.94% & 0.84\n",
      "for 2018-04-01, MAE is:3.56 & sMAPE is:13.54% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 17.89% & 0.83\n",
      "for 2018-04-02, MAE is:2.36 & sMAPE is:8.32% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 17.78% & 0.82\n",
      "for 2018-04-03, MAE is:5.87 & sMAPE is:18.36% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 17.79% & 0.82\n",
      "for 2018-04-04, MAE is:4.29 & sMAPE is:13.40% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 17.74% & 0.82\n",
      "for 2018-04-05, MAE is:8.15 & sMAPE is:21.52% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 17.78% & 0.82\n",
      "for 2018-04-06, MAE is:4.59 & sMAPE is:12.34% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 17.73% & 0.82\n",
      "for 2018-04-07, MAE is:6.34 & sMAPE is:25.62% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 17.81% & 0.82\n",
      "for 2018-04-08, MAE is:3.70 & sMAPE is:15.76% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 17.79% & 0.82\n",
      "for 2018-04-09, MAE is:5.99 & sMAPE is:14.17% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 17.75% & 0.82\n",
      "for 2018-04-10, MAE is:3.46 & sMAPE is:8.51% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.66% & 0.82\n",
      "for 2018-04-11, MAE is:3.50 & sMAPE is:9.70% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 17.58% & 0.81\n",
      "for 2018-04-12, MAE is:7.01 & sMAPE is:17.02% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.57% & 0.82\n",
      "for 2018-04-13, MAE is:4.78 & sMAPE is:10.64% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 17.51% & 0.82\n",
      "for 2018-04-14, MAE is:4.89 & sMAPE is:13.95% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.47% & 0.82\n",
      "for 2018-04-15, MAE is:3.50 & sMAPE is:15.69% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 17.45% & 0.82\n",
      "for 2018-04-16, MAE is:11.98 & sMAPE is:29.43% & rMAE is:4.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 17.57% & 0.85\n",
      "for 2018-04-17, MAE is:5.58 & sMAPE is:12.93% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 17.52% & 0.85\n",
      "for 2018-04-18, MAE is:3.89 & sMAPE is:9.46% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 17.45% & 0.85\n",
      "for 2018-04-19, MAE is:4.97 & sMAPE is:12.91% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 17.41% & 0.85\n",
      "for 2018-04-20, MAE is:4.59 & sMAPE is:12.18% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 17.36% & 0.85\n",
      "for 2018-04-21, MAE is:5.82 & sMAPE is:23.99% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 17.42% & 0.84\n",
      "for 2018-04-22, MAE is:5.80 & sMAPE is:44.43% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 17.66% & 0.84\n",
      "for 2018-04-23, MAE is:8.20 & sMAPE is:26.88% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 17.74% & 0.84\n",
      "for 2018-04-24, MAE is:4.56 & sMAPE is:12.61% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 17.70% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-25, MAE is:6.56 & sMAPE is:22.02% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 17.73% & 0.83\n",
      "for 2018-04-26, MAE is:4.68 & sMAPE is:16.23% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 17.72% & 0.83\n",
      "for 2018-04-27, MAE is:5.28 & sMAPE is:15.40% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 17.70% & 0.84\n",
      "for 2018-04-28, MAE is:5.01 & sMAPE is:23.86% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 17.75% & 0.84\n",
      "for 2018-04-29, MAE is:10.42 & sMAPE is:64.21% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 18.14% & 0.84\n",
      "for 2018-04-30, MAE is:7.95 & sMAPE is:45.90% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 18.38% & 0.84\n",
      "for 2018-05-01, MAE is:9.01 & sMAPE is:80.48% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 18.89% & 0.84\n",
      "for 2018-05-02, MAE is:10.95 & sMAPE is:32.98% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 19.00% & 0.84\n",
      "for 2018-05-03, MAE is:3.20 & sMAPE is:8.00% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 18.92% & 0.83\n",
      "for 2018-05-04, MAE is:5.42 & sMAPE is:15.67% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 18.89% & 0.84\n",
      "for 2018-05-05, MAE is:6.09 & sMAPE is:23.68% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 18.93% & 0.84\n",
      "for 2018-05-06, MAE is:4.25 & sMAPE is:23.58% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 18.96% & 0.83\n",
      "for 2018-05-07, MAE is:12.61 & sMAPE is:35.86% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 19.10% & 0.83\n",
      "for 2018-05-08, MAE is:4.21 & sMAPE is:14.59% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 19.06% & 0.83\n",
      "for 2018-05-09, MAE is:6.23 & sMAPE is:16.43% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 19.04% & 0.84\n",
      "for 2018-05-10, MAE is:6.87 & sMAPE is:27.35% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 19.11% & 0.84\n",
      "for 2018-05-11, MAE is:15.37 & sMAPE is:43.39% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 19.29% & 0.84\n",
      "for 2018-05-12, MAE is:4.04 & sMAPE is:12.16% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 19.24% & 0.84\n",
      "for 2018-05-13, MAE is:5.77 & sMAPE is:35.98% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 19.36% & 0.84\n",
      "for 2018-05-14, MAE is:5.53 & sMAPE is:16.49% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 19.34% & 0.84\n",
      "for 2018-05-15, MAE is:12.87 & sMAPE is:34.63% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 19.45% & 0.84\n",
      "for 2018-05-16, MAE is:5.99 & sMAPE is:16.40% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 19.43% & 0.84\n",
      "for 2018-05-17, MAE is:7.66 & sMAPE is:23.61% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 19.46% & 0.84\n",
      "for 2018-05-18, MAE is:6.18 & sMAPE is:15.62% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 19.43% & 0.84\n",
      "for 2018-05-19, MAE is:7.17 & sMAPE is:30.71% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 19.52% & 0.84\n",
      "for 2018-05-20, MAE is:6.26 & sMAPE is:61.96% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 19.82% & 0.84\n",
      "for 2018-05-21, MAE is:7.85 & sMAPE is:74.46% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 20.21% & 0.84\n",
      "for 2018-05-22, MAE is:20.23 & sMAPE is:55.76% & rMAE is:4.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 20.46% & 0.86\n",
      "for 2018-05-23, MAE is:7.52 & sMAPE is:17.81% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 20.44% & 0.86\n",
      "for 2018-05-24, MAE is:8.05 & sMAPE is:20.32% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 20.44% & 0.86\n",
      "for 2018-05-25, MAE is:8.49 & sMAPE is:21.65% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 20.45% & 0.87\n",
      "for 2018-05-26, MAE is:7.46 & sMAPE is:24.40% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 20.47% & 0.87\n",
      "for 2018-05-27, MAE is:8.84 & sMAPE is:28.42% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.53% & 0.86\n",
      "for 2018-05-28, MAE is:11.04 & sMAPE is:23.70% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 20.55% & 0.86\n",
      "for 2018-05-29, MAE is:6.69 & sMAPE is:14.86% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 20.51% & 0.87\n",
      "for 2018-05-30, MAE is:9.91 & sMAPE is:20.95% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 20.51% & 0.87\n",
      "for 2018-05-31, MAE is:4.50 & sMAPE is:10.49% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.45% & 0.87\n",
      "for 2018-06-01, MAE is:8.88 & sMAPE is:19.97% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 20.44% & 0.87\n",
      "for 2018-06-02, MAE is:8.76 & sMAPE is:29.78% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 20.51% & 0.87\n",
      "for 2018-06-03, MAE is:4.17 & sMAPE is:21.25% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 20.51% & 0.87\n",
      "for 2018-06-04, MAE is:12.52 & sMAPE is:29.93% & rMAE is:2.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 20.57% & 0.88\n",
      "for 2018-06-05, MAE is:9.13 & sMAPE is:20.19% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 20.57% & 0.89\n",
      "for 2018-06-06, MAE is:7.72 & sMAPE is:16.37% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 20.54% & 0.89\n",
      "for 2018-06-07, MAE is:9.35 & sMAPE is:19.67% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 20.54% & 0.89\n",
      "for 2018-06-08, MAE is:5.86 & sMAPE is:12.38% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 20.48% & 0.89\n",
      "for 2018-06-09, MAE is:5.86 & sMAPE is:15.73% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 20.45% & 0.89\n",
      "for 2018-06-10, MAE is:4.43 & sMAPE is:12.34% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 20.40% & 0.89\n",
      "for 2018-06-11, MAE is:3.68 & sMAPE is:8.70% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 20.33% & 0.89\n",
      "for 2018-06-12, MAE is:5.74 & sMAPE is:12.56% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 20.28% & 0.89\n",
      "for 2018-06-13, MAE is:5.94 & sMAPE is:13.81% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 20.25% & 0.90\n",
      "for 2018-06-14, MAE is:4.03 & sMAPE is:8.77% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.18% & 0.89\n",
      "for 2018-06-15, MAE is:7.11 & sMAPE is:14.67% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 20.14% & 0.90\n",
      "for 2018-06-16, MAE is:2.54 & sMAPE is:6.49% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 20.06% & 0.90\n",
      "for 2018-06-17, MAE is:9.14 & sMAPE is:39.94% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.18% & 0.90\n",
      "for 2018-06-18, MAE is:5.08 & sMAPE is:12.71% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 20.13% & 0.90\n",
      "for 2018-06-19, MAE is:6.19 & sMAPE is:12.98% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 20.09% & 0.91\n",
      "for 2018-06-20, MAE is:3.42 & sMAPE is:7.44% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.02% & 0.91\n",
      "for 2018-06-21, MAE is:9.53 & sMAPE is:24.17% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 20.04% & 0.91\n",
      "for 2018-06-22, MAE is:7.52 & sMAPE is:28.61% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 20.09% & 0.90\n",
      "for 2018-06-23, MAE is:5.07 & sMAPE is:18.65% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 20.08% & 0.90\n",
      "for 2018-06-24, MAE is:4.43 & sMAPE is:15.72% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 20.06% & 0.90\n",
      "for 2018-06-25, MAE is:11.40 & sMAPE is:28.01% & rMAE is:5.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 20.10% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-26, MAE is:7.32 & sMAPE is:16.88% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 20.09% & 0.93\n",
      "for 2018-06-27, MAE is:6.17 & sMAPE is:13.28% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 20.05% & 0.94\n",
      "for 2018-06-28, MAE is:5.11 & sMAPE is:11.38% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 20.00% & 0.94\n",
      "for 2018-06-29, MAE is:9.29 & sMAPE is:22.45% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 20.01% & 0.93\n",
      "for 2018-06-30, MAE is:8.58 & sMAPE is:22.84% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.03% & 0.93\n",
      "for 2018-07-01, MAE is:6.98 & sMAPE is:22.63% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.04% & 0.93\n",
      "for 2018-07-02, MAE is:10.85 & sMAPE is:23.80% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 20.06% & 0.94\n",
      "for 2018-07-03, MAE is:8.80 & sMAPE is:16.50% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 20.04% & 0.94\n",
      "for 2018-07-04, MAE is:4.24 & sMAPE is:7.83% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 19.98% & 0.93\n",
      "for 2018-07-05, MAE is:6.26 & sMAPE is:11.78% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 19.93% & 0.93\n",
      "for 2018-07-06, MAE is:3.35 & sMAPE is:6.53% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 19.86% & 0.93\n",
      "for 2018-07-07, MAE is:3.45 & sMAPE is:7.74% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 19.80% & 0.93\n",
      "for 2018-07-08, MAE is:4.66 & sMAPE is:12.97% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 19.76% & 0.93\n",
      "for 2018-07-09, MAE is:4.46 & sMAPE is:9.41% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 19.71% & 0.93\n",
      "for 2018-07-10, MAE is:6.36 & sMAPE is:13.12% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 19.67% & 0.93\n",
      "for 2018-07-11, MAE is:6.47 & sMAPE is:13.47% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 19.64% & 0.94\n",
      "for 2018-07-12, MAE is:4.35 & sMAPE is:8.89% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 19.58% & 0.94\n",
      "for 2018-07-13, MAE is:6.59 & sMAPE is:13.81% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 19.55% & 0.95\n",
      "for 2018-07-14, MAE is:9.42 & sMAPE is:21.15% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 19.56% & 0.95\n",
      "for 2018-07-15, MAE is:4.91 & sMAPE is:11.35% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 19.52% & 0.95\n",
      "for 2018-07-16, MAE is:2.52 & sMAPE is:4.82% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 19.45% & 0.95\n",
      "for 2018-07-17, MAE is:3.45 & sMAPE is:6.97% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 19.38% & 0.95\n",
      "for 2018-07-18, MAE is:2.90 & sMAPE is:5.92% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 19.32% & 0.95\n",
      "for 2018-07-19, MAE is:5.22 & sMAPE is:10.84% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 19.27% & 0.96\n",
      "for 2018-07-20, MAE is:5.93 & sMAPE is:11.81% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 19.24% & 0.97\n",
      "for 2018-07-21, MAE is:8.32 & sMAPE is:17.96% & rMAE is:2.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 19.23% & 0.98\n",
      "for 2018-07-22, MAE is:6.05 & sMAPE is:13.69% & rMAE is:5.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 19.20% & 1.00\n",
      "for 2018-07-23, MAE is:3.18 & sMAPE is:6.20% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 19.14% & 1.00\n",
      "for 2018-07-24, MAE is:7.85 & sMAPE is:14.61% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 19.12% & 1.01\n",
      "for 2018-07-25, MAE is:6.31 & sMAPE is:11.52% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 19.08% & 1.00\n",
      "for 2018-07-26, MAE is:8.16 & sMAPE is:14.39% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 19.06% & 1.00\n",
      "for 2018-07-27, MAE is:2.81 & sMAPE is:5.19% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 18.99% & 1.00\n",
      "for 2018-07-28, MAE is:3.12 & sMAPE is:6.77% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.93% & 1.00\n",
      "for 2018-07-29, MAE is:4.56 & sMAPE is:10.23% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.89% & 1.01\n",
      "for 2018-07-30, MAE is:4.91 & sMAPE is:9.63% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 18.85% & 1.02\n",
      "for 2018-07-31, MAE is:5.54 & sMAPE is:10.03% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 18.81% & 1.02\n",
      "for 2018-08-01, MAE is:6.06 & sMAPE is:11.47% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 18.77% & 1.03\n",
      "for 2018-08-02, MAE is:8.35 & sMAPE is:14.96% & rMAE is:6.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 18.75% & 1.05\n",
      "for 2018-08-03, MAE is:12.65 & sMAPE is:21.82% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 18.77% & 1.06\n",
      "for 2018-08-04, MAE is:3.85 & sMAPE is:7.90% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.72% & 1.05\n",
      "for 2018-08-05, MAE is:11.03 & sMAPE is:23.97% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 18.74% & 1.06\n",
      "for 2018-08-06, MAE is:7.75 & sMAPE is:12.61% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 18.71% & 1.06\n",
      "for 2018-08-07, MAE is:4.97 & sMAPE is:8.12% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 18.66% & 1.06\n",
      "for 2018-08-08, MAE is:5.03 & sMAPE is:8.89% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.62% & 1.06\n",
      "for 2018-08-09, MAE is:4.84 & sMAPE is:8.83% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.58% & 1.06\n",
      "for 2018-08-10, MAE is:6.82 & sMAPE is:15.45% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.56% & 1.06\n",
      "for 2018-08-11, MAE is:5.42 & sMAPE is:11.83% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.53% & 1.06\n",
      "for 2018-08-12, MAE is:6.74 & sMAPE is:16.25% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.52% & 1.06\n",
      "for 2018-08-13, MAE is:7.78 & sMAPE is:15.31% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.51% & 1.06\n",
      "for 2018-08-14, MAE is:6.54 & sMAPE is:12.51% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.48% & 1.06\n",
      "for 2018-08-15, MAE is:7.63 & sMAPE is:15.52% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.47% & 1.06\n",
      "for 2018-08-16, MAE is:7.80 & sMAPE is:14.81% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 18.45% & 1.06\n",
      "for 2018-08-17, MAE is:7.69 & sMAPE is:14.37% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 18.43% & 1.06\n",
      "for 2018-08-18, MAE is:7.36 & sMAPE is:14.34% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 18.42% & 1.06\n",
      "for 2018-08-19, MAE is:3.50 & sMAPE is:7.12% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.37% & 1.06\n",
      "for 2018-08-20, MAE is:6.21 & sMAPE is:10.79% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.33% & 1.06\n",
      "for 2018-08-21, MAE is:11.73 & sMAPE is:18.72% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 18.34% & 1.06\n",
      "for 2018-08-22, MAE is:9.24 & sMAPE is:14.20% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 18.32% & 1.05\n",
      "for 2018-08-23, MAE is:5.89 & sMAPE is:9.48% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 18.28% & 1.05\n",
      "for 2018-08-24, MAE is:2.90 & sMAPE is:4.87% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 18.22% & 1.05\n",
      "for 2018-08-25, MAE is:7.14 & sMAPE is:13.02% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 18.20% & 1.05\n",
      "for 2018-08-26, MAE is:3.70 & sMAPE is:7.07% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.16% & 1.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-27, MAE is:7.35 & sMAPE is:13.56% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 18.14% & 1.05\n",
      "for 2018-08-28, MAE is:4.47 & sMAPE is:7.30% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.09% & 1.05\n",
      "for 2018-08-29, MAE is:3.75 & sMAPE is:5.70% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.04% & 1.05\n",
      "for 2018-08-30, MAE is:5.83 & sMAPE is:9.08% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 18.00% & 1.06\n",
      "for 2018-08-31, MAE is:4.10 & sMAPE is:6.45% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 17.96% & 1.06\n",
      "for 2018-09-01, MAE is:5.14 & sMAPE is:8.88% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 17.92% & 1.06\n",
      "for 2018-09-02, MAE is:2.54 & sMAPE is:4.63% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 17.86% & 1.06\n",
      "for 2018-09-03, MAE is:5.57 & sMAPE is:9.32% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.83% & 1.06\n",
      "for 2018-09-04, MAE is:5.26 & sMAPE is:8.12% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.79% & 1.06\n",
      "for 2018-09-05, MAE is:6.54 & sMAPE is:9.88% & rMAE is:2.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.76% & 1.07\n",
      "for 2018-09-06, MAE is:3.36 & sMAPE is:5.21% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 17.71% & 1.07\n",
      "for 2018-09-07, MAE is:4.30 & sMAPE is:6.93% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.66% & 1.07\n",
      "for 2018-09-08, MAE is:4.37 & sMAPE is:7.22% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 17.62% & 1.07\n",
      "for 2018-09-09, MAE is:8.71 & sMAPE is:17.21% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.62% & 1.07\n",
      "for 2018-09-10, MAE is:5.02 & sMAPE is:8.01% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 17.58% & 1.07\n",
      "for 2018-09-11, MAE is:4.36 & sMAPE is:7.05% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 17.54% & 1.07\n",
      "for 2018-09-12, MAE is:3.95 & sMAPE is:6.03% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.50% & 1.07\n",
      "for 2018-09-13, MAE is:7.15 & sMAPE is:10.67% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 17.47% & 1.08\n",
      "for 2018-09-14, MAE is:5.14 & sMAPE is:7.88% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.43% & 1.08\n",
      "for 2018-09-15, MAE is:5.11 & sMAPE is:9.23% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 17.40% & 1.08\n",
      "for 2018-09-16, MAE is:7.68 & sMAPE is:16.95% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.40% & 1.08\n",
      "for 2018-09-17, MAE is:7.08 & sMAPE is:11.40% & rMAE is:2.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.38% & 1.09\n",
      "for 2018-09-18, MAE is:6.62 & sMAPE is:10.72% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.35% & 1.10\n",
      "for 2018-09-19, MAE is:5.49 & sMAPE is:9.16% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.32% & 1.09\n",
      "for 2018-09-20, MAE is:5.20 & sMAPE is:8.66% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 17.29% & 1.09\n",
      "for 2018-09-21, MAE is:8.82 & sMAPE is:16.10% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.28% & 1.09\n",
      "for 2018-09-22, MAE is:8.92 & sMAPE is:14.31% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 17.27% & 1.09\n",
      "for 2018-09-23, MAE is:5.51 & sMAPE is:11.66% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 17.25% & 1.09\n",
      "for 2018-09-24, MAE is:4.83 & sMAPE is:7.96% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.21% & 1.09\n",
      "for 2018-09-25, MAE is:5.48 & sMAPE is:8.66% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.18% & 1.09\n",
      "for 2018-09-26, MAE is:8.48 & sMAPE is:14.26% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.17% & 1.09\n",
      "for 2018-09-27, MAE is:4.58 & sMAPE is:7.28% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.14% & 1.09\n",
      "for 2018-09-28, MAE is:5.98 & sMAPE is:9.42% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.11% & 1.09\n",
      "for 2018-09-29, MAE is:8.37 & sMAPE is:14.83% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.10% & 1.09\n",
      "for 2018-09-30, MAE is:3.81 & sMAPE is:6.91% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 17.06% & 1.09\n",
      "for 2018-10-01, MAE is:5.07 & sMAPE is:8.16% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 17.03% & 1.09\n",
      "for 2018-10-02, MAE is:4.13 & sMAPE is:6.50% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.99% & 1.09\n",
      "for 2018-10-03, MAE is:5.63 & sMAPE is:8.91% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.96% & 1.09\n",
      "for 2018-10-04, MAE is:6.91 & sMAPE is:9.87% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.94% & 1.09\n",
      "for 2018-10-05, MAE is:4.27 & sMAPE is:6.57% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.90% & 1.09\n",
      "for 2018-10-06, MAE is:5.15 & sMAPE is:8.63% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.87% & 1.09\n",
      "for 2018-10-07, MAE is:4.14 & sMAPE is:7.19% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.83% & 1.09\n",
      "for 2018-10-08, MAE is:6.69 & sMAPE is:9.47% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.81% & 1.09\n",
      "for 2018-10-09, MAE is:8.33 & sMAPE is:10.82% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.79% & 1.09\n",
      "for 2018-10-10, MAE is:6.21 & sMAPE is:9.11% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.76% & 1.09\n",
      "for 2018-10-11, MAE is:4.60 & sMAPE is:7.19% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.73% & 1.09\n",
      "for 2018-10-12, MAE is:6.36 & sMAPE is:9.88% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.70% & 1.09\n",
      "for 2018-10-13, MAE is:4.22 & sMAPE is:7.27% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.67% & 1.09\n",
      "for 2018-10-14, MAE is:14.09 & sMAPE is:33.72% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.73% & 1.09\n",
      "for 2018-10-15, MAE is:12.24 & sMAPE is:18.62% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.73% & 1.09\n",
      "for 2018-10-16, MAE is:8.44 & sMAPE is:12.01% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.72% & 1.09\n",
      "for 2018-10-17, MAE is:5.44 & sMAPE is:7.09% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.69% & 1.09\n",
      "for 2018-10-18, MAE is:3.75 & sMAPE is:5.70% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.65% & 1.09\n",
      "for 2018-10-19, MAE is:6.69 & sMAPE is:10.12% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.62% & 1.09\n",
      "for 2018-10-20, MAE is:6.07 & sMAPE is:10.39% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.60% & 1.09\n",
      "for 2018-10-21, MAE is:6.17 & sMAPE is:11.36% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.59% & 1.09\n",
      "for 2018-10-22, MAE is:4.74 & sMAPE is:7.70% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.56% & 1.09\n",
      "for 2018-10-23, MAE is:4.23 & sMAPE is:6.75% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.52% & 1.09\n",
      "for 2018-10-24, MAE is:3.69 & sMAPE is:5.80% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.49% & 1.08\n",
      "for 2018-10-25, MAE is:5.78 & sMAPE is:8.43% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.46% & 1.08\n",
      "for 2018-10-26, MAE is:4.64 & sMAPE is:6.70% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.43% & 1.08\n",
      "for 2018-10-27, MAE is:4.03 & sMAPE is:6.19% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.39% & 1.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-28, MAE is:5.91 & sMAPE is:10.62% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 16.37% & 1.08\n",
      "for 2018-10-29, MAE is:10.51 & sMAPE is:14.19% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.37% & 1.08\n",
      "for 2018-10-30, MAE is:6.75 & sMAPE is:9.17% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.34% & 1.08\n",
      "for 2018-10-31, MAE is:6.95 & sMAPE is:9.73% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.32% & 1.08\n",
      "for 2018-11-01, MAE is:6.46 & sMAPE is:11.44% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.30% & 1.08\n",
      "for 2018-11-02, MAE is:8.64 & sMAPE is:13.63% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.30% & 1.08\n",
      "for 2018-11-03, MAE is:3.96 & sMAPE is:6.51% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.26% & 1.08\n",
      "for 2018-11-04, MAE is:2.95 & sMAPE is:5.44% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.23% & 1.07\n",
      "for 2018-11-05, MAE is:6.41 & sMAPE is:10.73% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.21% & 1.07\n",
      "for 2018-11-06, MAE is:3.94 & sMAPE is:6.79% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 16.18% & 1.07\n",
      "for 2018-11-07, MAE is:5.53 & sMAPE is:10.38% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 16.16% & 1.07\n",
      "for 2018-11-08, MAE is:10.87 & sMAPE is:18.13% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.17% & 1.07\n",
      "for 2018-11-09, MAE is:5.60 & sMAPE is:9.78% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.15% & 1.07\n",
      "for 2018-11-10, MAE is:6.92 & sMAPE is:14.07% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.14% & 1.07\n",
      "for 2018-11-11, MAE is:6.69 & sMAPE is:13.76% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.13% & 1.07\n",
      "for 2018-11-12, MAE is:9.05 & sMAPE is:16.54% & rMAE is:3.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.14% & 1.07\n",
      "for 2018-11-13, MAE is:8.22 & sMAPE is:13.54% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.13% & 1.08\n",
      "for 2018-11-14, MAE is:5.03 & sMAPE is:7.95% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.10% & 1.08\n",
      "for 2018-11-15, MAE is:9.12 & sMAPE is:15.24% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.10% & 1.08\n",
      "for 2018-11-16, MAE is:4.36 & sMAPE is:6.54% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.07% & 1.08\n",
      "for 2018-11-17, MAE is:5.42 & sMAPE is:9.52% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.05% & 1.08\n",
      "for 2018-11-18, MAE is:3.51 & sMAPE is:6.39% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.02% & 1.07\n",
      "for 2018-11-19, MAE is:7.25 & sMAPE is:10.71% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.00% & 1.07\n",
      "for 2018-11-20, MAE is:21.90 & sMAPE is:20.49% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.02% & 1.07\n",
      "for 2018-11-21, MAE is:29.42 & sMAPE is:23.41% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.04% & 1.07\n",
      "for 2018-11-22, MAE is:20.98 & sMAPE is:20.20% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 16.05% & 1.07\n",
      "for 2018-11-23, MAE is:8.55 & sMAPE is:10.58% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 16.03% & 1.07\n",
      "for 2018-11-24, MAE is:5.48 & sMAPE is:8.16% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 16.01% & 1.07\n",
      "for 2018-11-25, MAE is:4.24 & sMAPE is:7.27% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 15.98% & 1.07\n",
      "for 2018-11-26, MAE is:24.94 & sMAPE is:26.77% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.02% & 1.07\n",
      "for 2018-11-27, MAE is:10.36 & sMAPE is:13.20% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 16.01% & 1.07\n",
      "for 2018-11-28, MAE is:5.37 & sMAPE is:9.12% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 15.99% & 1.06\n",
      "for 2018-11-29, MAE is:4.47 & sMAPE is:7.62% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 15.96% & 1.06\n",
      "for 2018-11-30, MAE is:4.36 & sMAPE is:7.22% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 15.94% & 1.06\n",
      "for 2018-12-01, MAE is:7.58 & sMAPE is:14.24% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 15.93% & 1.06\n",
      "for 2018-12-02, MAE is:4.58 & sMAPE is:10.27% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 15.91% & 1.05\n",
      "for 2018-12-03, MAE is:6.15 & sMAPE is:12.88% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 15.91% & 1.05\n",
      "for 2018-12-04, MAE is:8.35 & sMAPE is:15.37% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 15.90% & 1.05\n",
      "for 2018-12-05, MAE is:4.69 & sMAPE is:8.49% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 15.88% & 1.05\n",
      "for 2018-12-06, MAE is:8.55 & sMAPE is:16.55% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 15.88% & 1.05\n",
      "for 2018-12-07, MAE is:6.13 & sMAPE is:12.50% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 15.87% & 1.05\n",
      "for 2018-12-08, MAE is:7.16 & sMAPE is:26.50% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 15.90% & 1.05\n",
      "for 2018-12-09, MAE is:6.66 & sMAPE is:40.48% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 15.98% & 1.05\n",
      "for 2018-12-10, MAE is:7.83 & sMAPE is:20.44% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 15.99% & 1.05\n",
      "for 2018-12-11, MAE is:8.18 & sMAPE is:14.71% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 15.99% & 1.05\n",
      "for 2018-12-12, MAE is:12.41 & sMAPE is:18.31% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 15.99% & 1.05\n",
      "for 2018-12-13, MAE is:9.56 & sMAPE is:14.98% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 15.99% & 1.05\n",
      "for 2018-12-14, MAE is:10.07 & sMAPE is:14.12% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 15.98% & 1.05\n",
      "for 2018-12-15, MAE is:5.74 & sMAPE is:9.08% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 15.96% & 1.05\n",
      "for 2018-12-16, MAE is:8.41 & sMAPE is:16.14% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 15.96% & 1.04\n",
      "for 2018-12-17, MAE is:7.19 & sMAPE is:11.04% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 15.95% & 1.04\n",
      "for 2018-12-18, MAE is:3.76 & sMAPE is:6.18% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 15.92% & 1.04\n",
      "for 2018-12-19, MAE is:8.47 & sMAPE is:16.18% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 15.92% & 1.04\n",
      "for 2018-12-20, MAE is:5.04 & sMAPE is:9.47% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 15.91% & 1.04\n",
      "for 2018-12-21, MAE is:5.35 & sMAPE is:11.22% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 15.89% & 1.04\n",
      "for 2018-12-22, MAE is:14.00 & sMAPE is:39.56% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 15.96% & 1.04\n",
      "for 2018-12-23, MAE is:5.84 & sMAPE is:13.97% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 15.95% & 1.04\n",
      "for 2018-12-24, MAE is:5.14 & sMAPE is:11.16% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 15.94% & 1.03\n",
      "for 2018-12-25, MAE is:7.80 & sMAPE is:21.30% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 15.95% & 1.03\n",
      "for 2018-12-26, MAE is:5.70 & sMAPE is:11.55% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 15.94% & 1.03\n",
      "for 2018-12-27, MAE is:5.97 & sMAPE is:10.26% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 15.93% & 1.03\n",
      "for 2018-12-28, MAE is:3.29 & sMAPE is:5.61% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 15.90% & 1.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-29, MAE is:4.24 & sMAPE is:8.36% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 15.88% & 1.03\n",
      "for 2018-12-30, MAE is:4.91 & sMAPE is:11.37% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 15.87% & 1.03\n",
      "for 2018-12-31, MAE is:10.12 & sMAPE is:20.08% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 15.88% & 1.03\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:29:06,202]\u001b[0m A new study created in RDB with name: FR_2019\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:29:19,804]\u001b[0m Trial 2 finished with value: 9.830232178485593 and parameters: {'n_hidden': 3, 'learning_rate': 0.03195668082498955, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3490816193726296, 'dropout_rate_Layer_2': 0.16904033689296366, 'dropout_rate_Layer_3': 0.19374312005858144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001001138507378004, 'l1_Layer_2': 0.0006356435219999917, 'l1_Layer_3': 7.492199551523959e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 185}. Best is trial 2 with value: 9.830232178485593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.83 | sMAPE for Validation Set is: 21.89% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 7.51 | sMAPE for Test Set is: 21.70% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:29:36,131]\u001b[0m Trial 4 finished with value: 16.909185453171613 and parameters: {'n_hidden': 4, 'learning_rate': 0.005212517268307888, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21148196214352155, 'dropout_rate_Layer_2': 0.24564209887219846, 'dropout_rate_Layer_3': 0.36361467162207917, 'dropout_rate_Layer_4': 0.1260732267791318, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.02822536203125412, 'l1_Layer_2': 0.006953240618877333, 'l1_Layer_3': 0.016502712156818113, 'l1_Layer_4': 0.0004234175590204429, 'n_units_Layer_1': 220, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290, 'n_units_Layer_4': 90}. Best is trial 2 with value: 9.830232178485593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.91 | sMAPE for Validation Set is: 36.96% | rMAE for Validation Set is: 1.74\n",
      "MAE for Test Set is: 9.24 | sMAPE for Test Set is: 25.57% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:29:42,081]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:29:44,496]\u001b[0m Trial 3 finished with value: 6.444100093734998 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005175597079451705, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060014405457148895, 'dropout_rate_Layer_2': 0.3237682391269859, 'dropout_rate_Layer_3': 0.15632123263097328, 'dropout_rate_Layer_4': 0.25758061055468906, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004165149233953827, 'l1_Layer_2': 4.581051728643851e-05, 'l1_Layer_3': 5.8525511329297195e-05, 'l1_Layer_4': 0.00016713186586602872, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 95, 'n_units_Layer_4': 290}. Best is trial 3 with value: 6.444100093734998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 17.86% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:29:46,235]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:29:46,779]\u001b[0m Trial 1 finished with value: 7.245283483926144 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006034361350738794, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1407327976642676, 'dropout_rate_Layer_2': 0.1678288508872722, 'dropout_rate_Layer_3': 0.1220909282732011, 'dropout_rate_Layer_4': 0.20041499836028787, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.004228177180612031, 'l1_Layer_2': 0.0007722724713126101, 'l1_Layer_3': 0.00021102757888599242, 'l1_Layer_4': 1.895282081750801e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 120, 'n_units_Layer_3': 90, 'n_units_Layer_4': 195}. Best is trial 3 with value: 6.444100093734998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.25 | sMAPE for Validation Set is: 16.33% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 17.49% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:29:52,030]\u001b[0m Trial 0 finished with value: 6.854456642149103 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032861561694542863, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3153311638351844, 'dropout_rate_Layer_2': 0.2971497522040107, 'dropout_rate_Layer_3': 0.18199340913417955, 'dropout_rate_Layer_4': 0.16074942492467695, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.531562013821718e-05, 'l1_Layer_2': 1.2200098717411519e-05, 'l1_Layer_3': 0.03651608084296163, 'l1_Layer_4': 0.003922228911066821, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 145, 'n_units_Layer_4': 200}. Best is trial 3 with value: 6.444100093734998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 15.49% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 16.67% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:29:52,463]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:29:59,844]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:30:00,652]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:30:07,245]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:30:23,427]\u001b[0m Trial 11 finished with value: 6.571938489970769 and parameters: {'n_hidden': 4, 'learning_rate': 0.011287146758650382, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15597765535033103, 'dropout_rate_Layer_2': 0.2719540716532245, 'dropout_rate_Layer_3': 0.33688268478453814, 'dropout_rate_Layer_4': 0.3820529377026362, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.9923277295254566e-05, 'l1_Layer_2': 0.000255014233240592, 'l1_Layer_3': 0.0005599524365999099, 'l1_Layer_4': 0.005820575160945692, 'n_units_Layer_1': 130, 'n_units_Layer_2': 235, 'n_units_Layer_3': 55, 'n_units_Layer_4': 280}. Best is trial 3 with value: 6.444100093734998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 15.04% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 17.42% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:30:28,113]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:30:31,736]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:30:39,742]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:30:44,074]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:30:48,925]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:30:54,499]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:30:58,383]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:10,765]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:11,238]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:15,899]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:17,643]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:21,187]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:24,235]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:25,983]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:32,155]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:35,158]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:38,514]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:42,374]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:31:47,241]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:32:03,269]\u001b[0m Trial 30 finished with value: 6.346407956322255 and parameters: {'n_hidden': 3, 'learning_rate': 0.007711699896034133, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24385040398545985, 'dropout_rate_Layer_2': 0.1455959927331128, 'dropout_rate_Layer_3': 0.26043723637494925, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.866457344986618e-05, 'l1_Layer_2': 0.0001726486028934173, 'l1_Layer_3': 0.002802605706000246, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230}. Best is trial 30 with value: 6.346407956322255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 14.66% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:32:15,635]\u001b[0m Trial 34 finished with value: 6.721835943733514 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027267546394112623, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16863173580286017, 'dropout_rate_Layer_2': 0.2569109169454191, 'dropout_rate_Layer_3': 0.1659150863732563, 'dropout_rate_Layer_4': 0.20319265645572743, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.044393425996155575, 'l1_Layer_2': 0.0004204021719269608, 'l1_Layer_3': 9.870658265924834e-05, 'l1_Layer_4': 5.78513637313975e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 135, 'n_units_Layer_3': 125, 'n_units_Layer_4': 265}. Best is trial 30 with value: 6.346407956322255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.72 | sMAPE for Validation Set is: 15.75% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:32:17,560]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:32:22,452]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:32:25,884]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:32:29,275]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:32:31,810]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:32:37,892]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:32:38,309]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:32:43,843]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:32:48,587]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:32:50,413]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:32:55,764]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:16,524]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:16,930]\u001b[0m Trial 7 finished with value: 6.702076516169186 and parameters: {'n_hidden': 3, 'learning_rate': 0.00129558967494295, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006095923655283242, 'dropout_rate_Layer_2': 0.3296093984574971, 'dropout_rate_Layer_3': 0.24235275436940926, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.014214553540948562, 'l1_Layer_2': 0.026167752536551046, 'l1_Layer_3': 1.1398898896845955e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 30 with value: 6.346407956322255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.70 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 19.67% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:33:17,710]\u001b[0m Trial 12 finished with value: 7.146228274491023 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031566271620996574, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2693141864951749, 'dropout_rate_Layer_2': 0.34904434188630423, 'dropout_rate_Layer_3': 0.29955411633501067, 'dropout_rate_Layer_4': 0.3201346327342794, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07273284092726451, 'l1_Layer_2': 0.005715664672800311, 'l1_Layer_3': 0.006251689804617276, 'l1_Layer_4': 0.0002263858594276247, 'n_units_Layer_1': 75, 'n_units_Layer_2': 165, 'n_units_Layer_3': 175, 'n_units_Layer_4': 235}. Best is trial 30 with value: 6.346407956322255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 16.42% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 19.30% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:33:17,945]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:23,657]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:25,515]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:28,548]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:29,547]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:36,294]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:36,576]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:36,955]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:44,817]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:47,283]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:47,525]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:47,724]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:49,360]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:57,397]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:59,728]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:33:59,915]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:00,731]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:03,294]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:10,391]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:12,883]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:17,686]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:17,925]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:25,589]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:35,798]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:39,163]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:44,642]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:45,285]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:34:53,421]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:35:01,652]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:35:05,272]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:35:08,462]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:35:11,060]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:35:12,505]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:35:13,345]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:35:17,137]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:35:22,231]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:35:30,278]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:35:40,591]\u001b[0m Trial 84 finished with value: 6.572799024670705 and parameters: {'n_hidden': 4, 'learning_rate': 0.002594062943002346, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2306449565222503, 'dropout_rate_Layer_2': 0.2496511223352527, 'dropout_rate_Layer_3': 0.007185939623238602, 'dropout_rate_Layer_4': 0.20416481771326753, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03516889912352071, 'l1_Layer_2': 0.0008775089224530322, 'l1_Layer_3': 7.890267283499949e-05, 'l1_Layer_4': 6.635329330165683e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 55, 'n_units_Layer_3': 125, 'n_units_Layer_4': 260}. Best is trial 30 with value: 6.346407956322255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 15.13% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 17.80% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:35:46,652]\u001b[0m Trial 85 finished with value: 6.5836909365875975 and parameters: {'n_hidden': 4, 'learning_rate': 0.002814437705820412, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23135484693976513, 'dropout_rate_Layer_2': 0.2465905666773211, 'dropout_rate_Layer_3': 0.00808084689503765, 'dropout_rate_Layer_4': 0.20857560817706006, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03318907965617509, 'l1_Layer_2': 0.0010330385502055088, 'l1_Layer_3': 7.611814604835805e-05, 'l1_Layer_4': 7.536841610760012e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 50, 'n_units_Layer_3': 140, 'n_units_Layer_4': 260}. Best is trial 30 with value: 6.346407956322255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 15.21% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 16.90% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:35:52,696]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:35:59,282]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:06,544]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:07,074]\u001b[0m Trial 87 finished with value: 6.498453620354778 and parameters: {'n_hidden': 4, 'learning_rate': 0.002376429143575358, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36692503381719943, 'dropout_rate_Layer_2': 0.26997735112469295, 'dropout_rate_Layer_3': 0.005557784620756567, 'dropout_rate_Layer_4': 0.19610904126943024, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.018063896899039325, 'l1_Layer_2': 0.00019508328579948136, 'l1_Layer_3': 0.00039732537497095443, 'l1_Layer_4': 5.504311612622454e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 140, 'n_units_Layer_4': 200}. Best is trial 30 with value: 6.346407956322255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.53 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:36:11,239]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:11,334]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:11,586]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:19,532]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:20,230]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:26,839]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:32,602]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:39,660]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:44,832]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:50,457]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 15.85% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 17.52% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:36:51,997]\u001b[0m Trial 95 finished with value: 6.882847805014315 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028072140583377814, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19059124091597712, 'dropout_rate_Layer_2': 0.29109230947641845, 'dropout_rate_Layer_3': 0.23700346712160594, 'dropout_rate_Layer_4': 0.25437961348472066, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.766099428880493e-05, 'l1_Layer_2': 0.0003245502541348461, 'l1_Layer_3': 5.7483379961033074e-05, 'l1_Layer_4': 0.00012117195295140019, 'n_units_Layer_1': 200, 'n_units_Layer_2': 235, 'n_units_Layer_3': 120, 'n_units_Layer_4': 55}. Best is trial 30 with value: 6.346407956322255.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:36:56,914]\u001b[0m Trial 99 finished with value: 6.540919861882315 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031369034700668152, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3749653931393143, 'dropout_rate_Layer_2': 0.3178010533014764, 'dropout_rate_Layer_3': 0.008950876760168983, 'dropout_rate_Layer_4': 0.19387340503430217, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.027807754832854845, 'l1_Layer_2': 0.0005922477477144969, 'l1_Layer_3': 0.0003587053053512813, 'l1_Layer_4': 1.5460313980644863e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140, 'n_units_Layer_4': 275}. Best is trial 30 with value: 6.346407956322255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 15.27% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.55 | sMAPE for Test Set is: 17.21% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:37:04,200]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:14,887]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:17,161]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:21,931]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:25,012]\u001b[0m Trial 105 finished with value: 6.3118530075687715 and parameters: {'n_hidden': 4, 'learning_rate': 0.004417526943153284, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.370463405215949, 'dropout_rate_Layer_2': 0.26612446278977653, 'dropout_rate_Layer_3': 0.042751387869190235, 'dropout_rate_Layer_4': 0.14124369300185663, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01590480755235942, 'l1_Layer_2': 0.00037762140374795084, 'l1_Layer_3': 0.00033584209072093477, 'l1_Layer_4': 1.2690650191873939e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 165, 'n_units_Layer_4': 270}. Best is trial 105 with value: 6.3118530075687715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 17.34% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:37:25,184]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:30,979]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:32,989]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:33,082]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:38,569]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:41,821]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:41,880]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:48,081]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:52,476]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:37:58,273]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:02,871]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:18,822]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:22,561]\u001b[0m Trial 89 finished with value: 6.8280522727167146 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014650357152629551, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10323117232949491, 'dropout_rate_Layer_2': 0.0015523818818414248, 'dropout_rate_Layer_3': 0.13512776167178833, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.009020137685437944, 'l1_Layer_2': 1.1488682505106473e-05, 'l1_Layer_3': 9.435651286669527e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 140, 'n_units_Layer_3': 165}. Best is trial 105 with value: 6.3118530075687715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 15.85% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 21.30% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:38:23,735]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:28,098]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:28,823]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:32,836]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:36,030]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:38,657]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:40,020]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:48,428]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:48,460]\u001b[0m Trial 117 finished with value: 6.433781308745982 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023438477294030697, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13469660419126217, 'dropout_rate_Layer_2': 0.3411824000615509, 'dropout_rate_Layer_3': 0.137104111504409, 'dropout_rate_Layer_4': 0.1963204142516206, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0035540374170015482, 'l1_Layer_2': 0.011853473875328938, 'l1_Layer_3': 0.002667279438253313, 'l1_Layer_4': 0.00025017489244284974, 'n_units_Layer_1': 150, 'n_units_Layer_2': 150, 'n_units_Layer_3': 140, 'n_units_Layer_4': 300}. Best is trial 105 with value: 6.3118530075687715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:38:54,375]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:38:56,088]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:01,086]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:01,240]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 15.24% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 17.22% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:39:05,952]\u001b[0m Trial 128 finished with value: 6.637650138492691 and parameters: {'n_hidden': 3, 'learning_rate': 0.008541165349097728, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2881744040497451, 'dropout_rate_Layer_2': 0.1582461118867207, 'dropout_rate_Layer_3': 0.17231440193034572, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.011178900819509372, 'l1_Layer_2': 0.0004544001788362392, 'l1_Layer_3': 0.008922822693292469, 'n_units_Layer_1': 130, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 105 with value: 6.3118530075687715.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:09,264]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:09,650]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:10,976]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:17,481]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:20,218]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:22,147]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:25,349]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:25,975]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 15.14% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 17.11% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:39:26,903]\u001b[0m Trial 132 finished with value: 6.462322836233028 and parameters: {'n_hidden': 3, 'learning_rate': 0.004428546981083314, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20651047164815384, 'dropout_rate_Layer_2': 0.14539728201563182, 'dropout_rate_Layer_3': 0.3664486280182177, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.021981097540981445, 'l1_Layer_2': 0.00826323047716904, 'l1_Layer_3': 0.0028970247425770864, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 105 with value: 6.3118530075687715.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:28,633]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:32,055]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:35,386]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:36,566]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:37,050]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:43,789]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:39:48,449]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:02,792]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:07,132]\u001b[0m Trial 153 finished with value: 6.60402617175708 and parameters: {'n_hidden': 4, 'learning_rate': 0.01001716511125275, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18106512236590872, 'dropout_rate_Layer_2': 0.36040910268038934, 'dropout_rate_Layer_3': 0.018987137439736457, 'dropout_rate_Layer_4': 0.12623123569036113, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02181571215153283, 'l1_Layer_2': 0.005923692387985865, 'l1_Layer_3': 2.289774561813682e-05, 'l1_Layer_4': 5.805432858768435e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155, 'n_units_Layer_4': 215}. Best is trial 105 with value: 6.3118530075687715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 15.34% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.42 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:40:08,796]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:13,822]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:17,912]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:21,018]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:25,265]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:30,491]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:33,523]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:38,340]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:44,021]\u001b[0m Trial 158 finished with value: 6.418226475990906 and parameters: {'n_hidden': 4, 'learning_rate': 0.007877922569304934, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19637863785420503, 'dropout_rate_Layer_2': 0.3663925383430547, 'dropout_rate_Layer_3': 0.0027798755786212215, 'dropout_rate_Layer_4': 0.11466848837313658, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002243526271993328, 'l1_Layer_2': 0.005183909493940496, 'l1_Layer_3': 0.0017123317197547782, 'l1_Layer_4': 5.837079860864674e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 150, 'n_units_Layer_4': 210}. Best is trial 105 with value: 6.3118530075687715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.53 | sMAPE for Test Set is: 17.05% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:40:44,929]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:49,594]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:51,739]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:40:56,092]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:00,716]\u001b[0m Trial 148 finished with value: 6.322078280226921 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010262854370192657, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17629886648527932, 'dropout_rate_Layer_2': 0.3589544226926609, 'dropout_rate_Layer_3': 0.006554936803354505, 'dropout_rate_Layer_4': 0.1109995230195282, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0022973017300468523, 'l1_Layer_2': 0.00558586330483155, 'l1_Layer_3': 0.0018562990499770408, 'l1_Layer_4': 8.141612452248085e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 80, 'n_units_Layer_3': 145, 'n_units_Layer_4': 205}. Best is trial 105 with value: 6.3118530075687715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 14.85% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.24 | sMAPE for Test Set is: 16.44% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:41:04,934]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:09,618]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:09,911]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:10,302]\u001b[0m Trial 165 finished with value: 6.644923647253651 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023596983449439444, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2257288687059167, 'dropout_rate_Layer_2': 0.30425392538202245, 'dropout_rate_Layer_3': 0.023745730087595864, 'dropout_rate_Layer_4': 0.20542246597817698, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.051894885760050524, 'l1_Layer_2': 0.004148247875596527, 'l1_Layer_3': 4.534976714778e-05, 'l1_Layer_4': 4.5020585650053924e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 115, 'n_units_Layer_4': 210}. Best is trial 105 with value: 6.3118530075687715.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 15.46% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 17.23% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:41:18,401]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:18,665]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:22,378]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:25,453]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:29,692]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:30,122]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:32,382]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:38,859]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:45,748]\u001b[0m Trial 172 finished with value: 6.005698082709 and parameters: {'n_hidden': 4, 'learning_rate': 0.004236044134690225, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22639506077364305, 'dropout_rate_Layer_2': 0.38976139737329824, 'dropout_rate_Layer_3': 0.0008380376247387694, 'dropout_rate_Layer_4': 0.0883183453209265, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0021257942923132464, 'l1_Layer_2': 0.0007890170860968944, 'l1_Layer_3': 0.0020527440091079397, 'l1_Layer_4': 3.8527904081350425e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 130, 'n_units_Layer_3': 145, 'n_units_Layer_4': 195}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 17.58% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:41:51,113]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:41:57,529]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:42:02,653]\u001b[0m Trial 178 finished with value: 6.361866016561092 and parameters: {'n_hidden': 3, 'learning_rate': 0.005945681989721199, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06796215633829525, 'dropout_rate_Layer_2': 0.2176943039320293, 'dropout_rate_Layer_3': 0.08465267941251486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.029985377608473023, 'l1_Layer_2': 0.018183829584081438, 'l1_Layer_3': 0.004696438271106716, 'n_units_Layer_1': 220, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 14.81% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:42:03,379]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:42:06,360]\u001b[0m Trial 179 finished with value: 6.512261841203913 and parameters: {'n_hidden': 3, 'learning_rate': 0.005886500221036558, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27369141246852685, 'dropout_rate_Layer_2': 0.39675622300372715, 'dropout_rate_Layer_3': 0.2880666437136422, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.026894882003307807, 'l1_Layer_2': 0.0015630934022012113, 'l1_Layer_3': 0.011334713681269495, 'n_units_Layer_1': 225, 'n_units_Layer_2': 115, 'n_units_Layer_3': 255}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 15.15% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 17.30% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:42:09,640]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:42:11,739]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:42:17,947]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:42:18,077]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 14.79% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 16.41% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:42:23,298]\u001b[0m Trial 181 finished with value: 6.413875888463949 and parameters: {'n_hidden': 3, 'learning_rate': 0.006223304579840686, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2831272324539509, 'dropout_rate_Layer_2': 0.3916065588339828, 'dropout_rate_Layer_3': 0.28312403453113955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.026621116015928065, 'l1_Layer_2': 0.0003391801609906483, 'l1_Layer_3': 0.00482817858541861, 'n_units_Layer_1': 160, 'n_units_Layer_2': 70, 'n_units_Layer_3': 245}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:42:42,191]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:42:42,524]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:42:47,672]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:42:51,331]\u001b[0m Trial 192 finished with value: 6.267047971111879 and parameters: {'n_hidden': 3, 'learning_rate': 0.006494124067416076, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00890542380717671, 'dropout_rate_Layer_2': 0.37850178776849985, 'dropout_rate_Layer_3': 0.28213539293731127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.026242637938828715, 'l1_Layer_2': 0.00023126838078349967, 'l1_Layer_3': 0.0053724011049090725, 'n_units_Layer_1': 185, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 16.29% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:42:51,985]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:03,947]\u001b[0m Trial 188 finished with value: 6.310415547813116 and parameters: {'n_hidden': 3, 'learning_rate': 0.00938866231625057, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18387363581825458, 'dropout_rate_Layer_2': 0.1451142409192823, 'dropout_rate_Layer_3': 0.06727673567452072, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.016691651272480096, 'l1_Layer_2': 0.014450457516503265, 'l1_Layer_3': 0.02361359016719519, 'n_units_Layer_1': 210, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:43:06,691]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:08,871]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:11,960]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:16,835]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:21,250]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:31,156]\u001b[0m Trial 194 finished with value: 6.403733264765037 and parameters: {'n_hidden': 3, 'learning_rate': 0.00691405288953549, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06452990113544066, 'dropout_rate_Layer_2': 0.35913719606193395, 'dropout_rate_Layer_3': 0.2803794486639795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.025123819896652785, 'l1_Layer_2': 0.0002801873608593256, 'l1_Layer_3': 0.005370855637839835, 'n_units_Layer_1': 215, 'n_units_Layer_2': 75, 'n_units_Layer_3': 225}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 17.24% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:43:32,563]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:33,432]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:41,609]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:41,929]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:45,856]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:52,634]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:43:55,809]\u001b[0m Trial 200 finished with value: 6.319906461096786 and parameters: {'n_hidden': 3, 'learning_rate': 0.0067357246993121475, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0608229672240353, 'dropout_rate_Layer_2': 0.32866293902121935, 'dropout_rate_Layer_3': 0.07429562224197182, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.005791540561281833, 'l1_Layer_2': 4.46990116213837e-05, 'l1_Layer_3': 0.01910587689460761, 'n_units_Layer_1': 185, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 16.37% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:43:56,133]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:03,205]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:07,293]\u001b[0m Trial 207 finished with value: 6.579437389054111 and parameters: {'n_hidden': 4, 'learning_rate': 0.003606799304522871, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26354360724351694, 'dropout_rate_Layer_2': 0.2453445237382535, 'dropout_rate_Layer_3': 0.0026540415778642593, 'dropout_rate_Layer_4': 0.19796352571663117, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.032065385613901466, 'l1_Layer_2': 0.0005126896532675629, 'l1_Layer_3': 5.01647868749223e-05, 'l1_Layer_4': 3.277724002662756e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 150, 'n_units_Layer_4': 240}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 15.34% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.67 | sMAPE for Test Set is: 17.44% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:44:10,544]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:10,777]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:20,351]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:24,620]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:24,775]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:24,975]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:30,025]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:33,874]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:34,150]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:38,519]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:42,451]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:45,676]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:48,581]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:51,924]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:53,575]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:44:56,979]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:01,885]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:06,355]\u001b[0m Trial 225 finished with value: 8.30039755188997 and parameters: {'n_hidden': 3, 'learning_rate': 0.010129872233196955, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015292608224689926, 'dropout_rate_Layer_2': 0.36307844446715326, 'dropout_rate_Layer_3': 0.10524396160700555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0007505216474407675, 'l1_Layer_2': 4.0200455412155505e-05, 'l1_Layer_3': 0.00681389787099773, 'n_units_Layer_1': 195, 'n_units_Layer_2': 105, 'n_units_Layer_3': 180}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 18.92% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 6.29 | sMAPE for Test Set is: 19.13% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:45:06,601]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:11,017]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:14,431]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:15,918]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:17,841]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:24,361]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:24,753]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:35,863]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:47,193]\u001b[0m Trial 235 finished with value: 6.338085286612838 and parameters: {'n_hidden': 4, 'learning_rate': 0.008745968791592802, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32204531227801375, 'dropout_rate_Layer_2': 0.3497758292166334, 'dropout_rate_Layer_3': 0.0026903936961856115, 'dropout_rate_Layer_4': 0.04077924489507685, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005467092943227852, 'l1_Layer_2': 0.0011078506481869718, 'l1_Layer_3': 0.0019338632631023638, 'l1_Layer_4': 1.9112463088053953e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 225, 'n_units_Layer_3': 105, 'n_units_Layer_4': 190}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 15.85% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:45:48,057]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:48,099]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:45:57,539]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:01,087]\u001b[0m Trial 241 finished with value: 7.163231024724368 and parameters: {'n_hidden': 4, 'learning_rate': 0.017062221254751212, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33519440920349003, 'dropout_rate_Layer_2': 0.2423478372766409, 'dropout_rate_Layer_3': 0.015808556311514628, 'dropout_rate_Layer_4': 0.04318143255244967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.73169697218559e-05, 'l1_Layer_2': 0.001281204092172953, 'l1_Layer_3': 0.0004416134259114202, 'l1_Layer_4': 1.8467682004877104e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 220, 'n_units_Layer_3': 100, 'n_units_Layer_4': 160}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.16 | sMAPE for Validation Set is: 16.26% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 18.33% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:46:02,203]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:03,495]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:09,143]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:09,552]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 15.76% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:46:11,590]\u001b[0m Trial 224 finished with value: 6.023672735131652 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026166904468572995, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0025045119429866203, 'dropout_rate_Layer_2': 0.2504194296896722, 'dropout_rate_Layer_3': 0.10493799160067542, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0007035360775798482, 'l1_Layer_2': 3.509615682852497e-05, 'l1_Layer_3': 0.0014904013229248456, 'n_units_Layer_1': 195, 'n_units_Layer_2': 100, 'n_units_Layer_3': 170}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:14,806]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:16,526]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:18,005]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:18,469]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:24,550]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:28,139]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:29,810]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:32,207]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:34,194]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:36,502]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:41,322]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:44,580]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:46,722]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:49,340]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:51,882]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:52,455]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:46:53,636]\u001b[0m Trial 254 finished with value: 6.184791739488669 and parameters: {'n_hidden': 4, 'learning_rate': 0.00536951431988324, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2407700416190463, 'dropout_rate_Layer_2': 0.3464454694057489, 'dropout_rate_Layer_3': 0.022424884794528567, 'dropout_rate_Layer_4': 0.131821661209782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005477567390733142, 'l1_Layer_2': 0.0025551917926846654, 'l1_Layer_3': 0.0019453702026428852, 'l1_Layer_4': 5.672178153969543e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125, 'n_units_Layer_4': 200}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 15.75% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:46:57,823]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:02,610]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:03,851]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:06,192]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:15,447]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:17,035]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:22,180]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:24,366]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:25,245]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:29,932]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:32,456]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:33,894]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:40,033]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:40,563]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.38 | sMAPE for Test Set is: 16.79% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:47:43,904]\u001b[0m Trial 271 finished with value: 6.370411487646829 and parameters: {'n_hidden': 3, 'learning_rate': 0.004808552962276615, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23734007061516485, 'dropout_rate_Layer_2': 0.31828656614706036, 'dropout_rate_Layer_3': 0.22701639977566943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.011813224986088057, 'l1_Layer_2': 0.042408495739876095, 'l1_Layer_3': 0.00519322190933959, 'n_units_Layer_1': 165, 'n_units_Layer_2': 55, 'n_units_Layer_3': 240}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:44,803]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:46,256]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:46,872]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:53,054]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:56,948]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:47:58,619]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:48:01,356]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:48:05,180]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:48:06,809]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:48:11,046]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:48:16,764]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:48:23,613]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:48:26,162]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:48:27,032]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:48:41,229]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:48:46,220]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:48:49,156]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:00,465]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:08,281]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:08,963]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:22,380]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:29,026]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:32,579]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:33,153]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:35,960]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:38,581]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:43,799]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:45,944]\u001b[0m Trial 302 finished with value: 6.548922735135204 and parameters: {'n_hidden': 3, 'learning_rate': 0.006165294385343525, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30309733561656055, 'dropout_rate_Layer_2': 0.3461779730491422, 'dropout_rate_Layer_3': 0.3310401222194732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02650829549277938, 'l1_Layer_2': 0.0919896859328212, 'l1_Layer_3': 0.0027288894157866043, 'n_units_Layer_1': 165, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.42 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:49:46,753]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:53,003]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:53,615]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:49:54,282]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:02,640]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:02,960]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:03,072]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:12,024]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:15,635]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:16,583]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:21,151]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:22,333]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:26,701]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:29,986]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:34,157]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:36,462]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:41,672]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:43,715]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:50:52,202]\u001b[0m Trial 317 finished with value: 6.607885468472316 and parameters: {'n_hidden': 4, 'learning_rate': 0.012663316707010371, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2538793551100381, 'dropout_rate_Layer_2': 0.39704404878955124, 'dropout_rate_Layer_3': 0.05922734064858388, 'dropout_rate_Layer_4': 0.22801522252929016, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002091134177981764, 'l1_Layer_2': 0.001896633121236457, 'l1_Layer_3': 0.0016865991239061555, 'l1_Layer_4': 0.0003008836934205901, 'n_units_Layer_1': 200, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 110}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 15.38% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:50:52,977]\u001b[0m Trial 322 finished with value: 6.6321009523420145 and parameters: {'n_hidden': 3, 'learning_rate': 0.011362865847828106, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32917745417638794, 'dropout_rate_Layer_2': 0.3983699437310257, 'dropout_rate_Layer_3': 0.05674764342948816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.015871347727639516, 'l1_Layer_2': 0.06833178553545553, 'l1_Layer_3': 0.005766362712202787, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 255}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 15.20% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:50:59,768]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:00,951]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:02,219]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:03,098]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:09,963]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:10,107]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:10,778]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:20,566]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:25,117]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:25,492]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:26,068]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:28,554]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:34,343]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:37,094]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:39,168]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:41,935]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:46,685]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:51,105]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:54,129]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:57,179]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:51:57,529]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:52:02,166]\u001b[0m Trial 342 finished with value: 6.0391349694537935 and parameters: {'n_hidden': 4, 'learning_rate': 0.00427416938043398, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1898805062821232, 'dropout_rate_Layer_2': 0.24119387438967, 'dropout_rate_Layer_3': 0.030384077110809243, 'dropout_rate_Layer_4': 0.05945551348075946, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006157407937591392, 'l1_Layer_2': 0.0008988869705505628, 'l1_Layer_3': 2.7916225294166022e-05, 'l1_Layer_4': 4.2904503373686546e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 60, 'n_units_Layer_3': 135, 'n_units_Layer_4': 290}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:04,980]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:08,050]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:08,183]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:14,197]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:15,207]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:19,876]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:25,370]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:26,941]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:28,501]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:33,282]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:37,690]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:39,974]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:44,336]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:45,723]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:49,806]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:52:52,703]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:01,321]\u001b[0m Trial 356 finished with value: 6.301539412246292 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009832860662756676, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20536598055293537, 'dropout_rate_Layer_2': 0.1425076992496599, 'dropout_rate_Layer_3': 0.14475483849414425, 'dropout_rate_Layer_4': 0.05375129750426764, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010733925851078536, 'l1_Layer_2': 0.00039739584147275783, 'l1_Layer_3': 0.0005226919827018304, 'l1_Layer_4': 7.784856886948132e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 120, 'n_units_Layer_4': 65}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 14.77% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.33 | sMAPE for Test Set is: 16.64% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:53:03,368]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:04,807]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:07,109]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:07,647]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:15,423]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:15,779]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:19,593]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:24,924]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:28,417]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:28,975]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:31,342]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:34,765]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:36,867]\u001b[0m Trial 372 finished with value: 7.788831830948202 and parameters: {'n_hidden': 3, 'learning_rate': 0.005417933718371882, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.054552650176441474, 'dropout_rate_Layer_2': 0.3536497689499522, 'dropout_rate_Layer_3': 0.2610807089160649, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.090825212967194e-05, 'l1_Layer_2': 0.00029613569914637263, 'l1_Layer_3': 0.004940260654424663, 'n_units_Layer_1': 220, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220}. Best is trial 172 with value: 6.005698082709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.79 | sMAPE for Validation Set is: 17.46% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 17.84% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:53:39,997]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:40,795]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:40,968]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:41,641]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:49,778]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:50,916]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:51,523]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:53:56,099]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:54:01,357]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:54:01,470]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:54:06,223]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:54:23,117]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:54:36,922]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:54:39,275]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:54:45,501]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:54:45,722]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:54:51,253]\u001b[0m Trial 394 finished with value: 5.976624697626636 and parameters: {'n_hidden': 4, 'learning_rate': 0.0038929033334048333, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26359248773047783, 'dropout_rate_Layer_2': 0.22781478290713222, 'dropout_rate_Layer_3': 1.3533745280741236e-05, 'dropout_rate_Layer_4': 0.07152837542712176, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04445339023135899, 'l1_Layer_2': 0.0003315683937108925, 'l1_Layer_3': 6.546233845267958e-05, 'l1_Layer_4': 7.021966924859839e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 70, 'n_units_Layer_3': 140, 'n_units_Layer_4': 235}. Best is trial 394 with value: 5.976624697626636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 16.06% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:54:53,868]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:54:56,116]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:02,093]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:05,615]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:06,265]\u001b[0m Trial 390 finished with value: 6.220023990503236 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006236921822210396, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11931248228371996, 'dropout_rate_Layer_2': 0.08031513275104561, 'dropout_rate_Layer_3': 0.20950442287711477, 'dropout_rate_Layer_4': 0.13965719563278503, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004409697909430472, 'l1_Layer_2': 0.0013436072566424242, 'l1_Layer_3': 0.0005569085982276615, 'l1_Layer_4': 2.067456949033377e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 60, 'n_units_Layer_3': 100, 'n_units_Layer_4': 75}. Best is trial 394 with value: 5.976624697626636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 16.28% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:55:09,436]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:17,823]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:17,958]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:18,241]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:19,764]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:27,069]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:27,280]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:27,669]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:31,193]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:35,238]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:36,537]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:37,082]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:37,609]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:50,862]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:54,194]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:55:56,103]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:56:00,172]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:56:04,926]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:56:07,333]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:56:09,722]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:56:14,918]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:56:17,906]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:56:23,183]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:56:28,598]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:56:37,229]\u001b[0m Trial 415 finished with value: 6.495736520956349 and parameters: {'n_hidden': 3, 'learning_rate': 0.006147205555715309, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23366793059659074, 'dropout_rate_Layer_2': 0.2958651014018157, 'dropout_rate_Layer_3': 0.04698552466783136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.008807565293643814, 'l1_Layer_2': 0.06276651013663083, 'l1_Layer_3': 0.001024361301276839, 'n_units_Layer_1': 170, 'n_units_Layer_2': 60, 'n_units_Layer_3': 215}. Best is trial 394 with value: 5.976624697626636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 15.09% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 16.73% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:56:43,030]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:56:57,616]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:57:05,616]\u001b[0m Trial 428 finished with value: 6.489601071489145 and parameters: {'n_hidden': 3, 'learning_rate': 0.006038392136881625, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31851646990667837, 'dropout_rate_Layer_2': 0.3643940943371138, 'dropout_rate_Layer_3': 0.04846724573761198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.006781008071750339, 'l1_Layer_2': 0.07415080172818647, 'l1_Layer_3': 0.002303640612742869, 'n_units_Layer_1': 170, 'n_units_Layer_2': 60, 'n_units_Layer_3': 135}. Best is trial 394 with value: 5.976624697626636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 14.99% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:57:11,238]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:57:16,850]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:57:21,241]\u001b[0m Trial 414 finished with value: 6.260749792839562 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005802835229876544, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09544558636308677, 'dropout_rate_Layer_2': 0.02913359076139562, 'dropout_rate_Layer_3': 0.25223189349237524, 'dropout_rate_Layer_4': 0.11658956519956519, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0033131286780962816, 'l1_Layer_2': 0.003401008855212237, 'l1_Layer_3': 0.0007986074851681008, 'l1_Layer_4': 4.173089399080217e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150, 'n_units_Layer_4': 60}. Best is trial 394 with value: 5.976624697626636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 16.22% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:57:22,051]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:57:22,549]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:57:27,500]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:57:31,481]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:57:34,510]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:57:35,037]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:57:35,238]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:57:37,821]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:57:57,552]\u001b[0m Trial 440 finished with value: 5.597512645397328 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031067120868247633, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20143015120029167, 'dropout_rate_Layer_2': 0.11248510413706435, 'dropout_rate_Layer_3': 0.02461602829628597, 'dropout_rate_Layer_4': 0.1925163227644283, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.5625150267753993e-05, 'l1_Layer_2': 0.00022889249679417504, 'l1_Layer_3': 0.000114866388336929, 'l1_Layer_4': 0.0009038277412793449, 'n_units_Layer_1': 70, 'n_units_Layer_2': 50, 'n_units_Layer_3': 110, 'n_units_Layer_4': 245}. Best is trial 440 with value: 5.597512645397328.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 13.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 15.74% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:58:04,243]\u001b[0m Trial 441 finished with value: 5.493362801780914 and parameters: {'n_hidden': 4, 'learning_rate': 0.003910136572984048, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20474907747972193, 'dropout_rate_Layer_2': 0.11931561526952213, 'dropout_rate_Layer_3': 0.03355828927425957, 'dropout_rate_Layer_4': 0.18689747349464222, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.5239235215571585e-05, 'l1_Layer_2': 0.00021341447288347114, 'l1_Layer_3': 5.714491749488849e-05, 'l1_Layer_4': 0.0006054993836787703, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 120, 'n_units_Layer_4': 245}. Best is trial 441 with value: 5.493362801780914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 16.35% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:58:11,123]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:58:14,485]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:58:31,459]\u001b[0m Trial 444 finished with value: 5.371338132750832 and parameters: {'n_hidden': 4, 'learning_rate': 0.001806559599790361, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.204204911057287, 'dropout_rate_Layer_2': 0.107614419273003, 'dropout_rate_Layer_3': 0.023760357052358596, 'dropout_rate_Layer_4': 0.18745829172654216, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.6221688512538845e-05, 'l1_Layer_2': 0.00015574365932837634, 'l1_Layer_3': 7.136260861361407e-05, 'l1_Layer_4': 0.0007052256596937069, 'n_units_Layer_1': 70, 'n_units_Layer_2': 50, 'n_units_Layer_3': 120, 'n_units_Layer_4': 245}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 15.23% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:58:38,830]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:58:45,042]\u001b[0m Trial 447 finished with value: 5.6299263253025496 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018266103035385482, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1973358772141996, 'dropout_rate_Layer_2': 0.1381966624262558, 'dropout_rate_Layer_3': 0.035159933337680874, 'dropout_rate_Layer_4': 0.18995360683343945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.6263603999534026e-05, 'l1_Layer_2': 0.0001753638630940008, 'l1_Layer_3': 5.526663319864717e-05, 'l1_Layer_4': 0.0005855903073455886, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 120, 'n_units_Layer_4': 245}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 13.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.24 | sMAPE for Test Set is: 15.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:58:45,422]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:58:52,923]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:02,404]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:08,280]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:12,927]\u001b[0m Trial 442 finished with value: 5.815297012568851 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009489837727359017, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09572644330914858, 'dropout_rate_Layer_2': 0.03842998764239784, 'dropout_rate_Layer_3': 0.28290480698666043, 'dropout_rate_Layer_4': 0.06427413119666109, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005968939706133264, 'l1_Layer_2': 0.005786120851316213, 'l1_Layer_3': 0.0002840636894929585, 'l1_Layer_4': 1.0389160365416233e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 95, 'n_units_Layer_4': 60}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 13.58% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 15.87% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:59:14,055]\u001b[0m Trial 451 finished with value: 5.6233761128455795 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016651568376298543, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2065725799393163, 'dropout_rate_Layer_2': 0.1160328961501605, 'dropout_rate_Layer_3': 0.032722581370280085, 'dropout_rate_Layer_4': 0.18088145892431093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.5601453227744077e-05, 'l1_Layer_2': 0.00013967016537309718, 'l1_Layer_3': 6.272885396840921e-05, 'l1_Layer_4': 0.0007899811842323836, 'n_units_Layer_1': 75, 'n_units_Layer_2': 50, 'n_units_Layer_3': 115, 'n_units_Layer_4': 250}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 13.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 15.72% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:59:19,638]\u001b[0m Trial 449 finished with value: 6.450716102749276 and parameters: {'n_hidden': 3, 'learning_rate': 0.005960498379693667, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.296986271431288, 'dropout_rate_Layer_2': 0.36332364781565135, 'dropout_rate_Layer_3': 0.0489678921211246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02110939444448385, 'l1_Layer_2': 0.04804561626531549, 'l1_Layer_3': 0.0027308244265108975, 'n_units_Layer_1': 165, 'n_units_Layer_2': 70, 'n_units_Layer_3': 135}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 14.93% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 16.73% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:59:20,780]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:22,444]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:28,822]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:30,057]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:32,015]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:34,861]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:40,695]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:42,723]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:47,152]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:51,512]\u001b[0m Trial 454 finished with value: 6.244028979244622 and parameters: {'n_hidden': 3, 'learning_rate': 0.005911091799650878, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00044680631218341205, 'dropout_rate_Layer_2': 0.27997719755975803, 'dropout_rate_Layer_3': 0.05077508375250926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0204586505914889, 'l1_Layer_2': 0.03271009540803886, 'l1_Layer_3': 0.001700754546726529, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 185}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 14.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 16.20% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 14:59:54,045]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 14:59:57,431]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:02,077]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:06,713]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:11,736]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:14,611]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:17,801]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:23,010]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:28,337]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:31,412]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:35,409]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:38,245]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:45,808]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:53,152]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:00:53,900]\u001b[0m Trial 473 finished with value: 6.271497924203534 and parameters: {'n_hidden': 3, 'learning_rate': 0.007813366232992312, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004661727101122274, 'dropout_rate_Layer_2': 0.2502216720535924, 'dropout_rate_Layer_3': 0.19511457328516613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.05186850467276328, 'l1_Layer_2': 1.4409483794294995e-05, 'l1_Layer_3': 0.0045120062183453945, 'n_units_Layer_1': 150, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 16.28% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:00:59,197]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:00,389]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:07,381]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:08,709]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:12,305]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:15,665]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:19,117]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:21,334]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:25,678]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:30,271]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:34,314]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:39,916]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:44,124]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:47,408]\u001b[0m Trial 482 finished with value: 5.438324612594406 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016654659227151544, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19858235580101585, 'dropout_rate_Layer_2': 0.10874974614883696, 'dropout_rate_Layer_3': 0.0016596024458669367, 'dropout_rate_Layer_4': 0.17320365988737405, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.5374820290586418e-05, 'l1_Layer_2': 0.0001692556856585568, 'l1_Layer_3': 7.506689892410594e-05, 'l1_Layer_4': 0.0005814909464651436, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 110, 'n_units_Layer_4': 235}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 15.40% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:01:50,273]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:50,567]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:51,932]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:59,719]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:01:59,781]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:02:08,210]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:02:08,328]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:02:08,783]\u001b[0m Trial 489 finished with value: 6.199956671618882 and parameters: {'n_hidden': 3, 'learning_rate': 0.005297250521045395, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012151711440605818, 'dropout_rate_Layer_2': 0.010687123082769284, 'dropout_rate_Layer_3': 0.16675210547007888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005540707411705747, 'l1_Layer_2': 0.05937013605394175, 'l1_Layer_3': 0.0023534296257899335, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 205}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 15.99% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:02:30,940]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 13.43% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 15.75% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:02:32,599]\u001b[0m Trial 503 finished with value: 5.706648085095139 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021627981659370936, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1842114438573517, 'dropout_rate_Layer_2': 0.17369819555903748, 'dropout_rate_Layer_3': 0.014315989451547058, 'dropout_rate_Layer_4': 0.1539743023547292, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.82078233994e-05, 'l1_Layer_2': 0.00020613319898029752, 'l1_Layer_3': 4.4900586024705596e-05, 'l1_Layer_4': 0.0008576747691787078, 'n_units_Layer_1': 85, 'n_units_Layer_2': 70, 'n_units_Layer_3': 100, 'n_units_Layer_4': 245}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:02:38,069]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:02:41,013]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:02:41,320]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:02:45,047]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:02:48,688]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:02:53,672]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:02:54,019]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:03:00,291]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:03:17,826]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:03:18,651]\u001b[0m Trial 509 finished with value: 6.235120327850072 and parameters: {'n_hidden': 3, 'learning_rate': 0.006963601995852049, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01649377548757864, 'dropout_rate_Layer_2': 0.013276074750468297, 'dropout_rate_Layer_3': 0.043976971557344646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00044407045828507414, 'l1_Layer_2': 0.09961944937900125, 'l1_Layer_3': 0.0019118179632096085, 'n_units_Layer_1': 135, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 15.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:03:19,361]\u001b[0m Trial 508 finished with value: 6.195521137967456 and parameters: {'n_hidden': 3, 'learning_rate': 0.005211296886866235, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01673690252545523, 'dropout_rate_Layer_2': 0.005873969263069038, 'dropout_rate_Layer_3': 0.04767070903904818, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000544561889802309, 'l1_Layer_2': 0.04112353944464425, 'l1_Layer_3': 0.0019322591742645095, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 220}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 15.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:03:27,497]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:03:28,500]\u001b[0m Trial 513 finished with value: 6.4337869987629865 and parameters: {'n_hidden': 3, 'learning_rate': 0.0053310844888844935, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00866922387555113, 'dropout_rate_Layer_2': 0.20616407442763535, 'dropout_rate_Layer_3': 0.04522117330833983, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006410583345180556, 'l1_Layer_2': 0.06411562473986657, 'l1_Layer_3': 0.0018148096539936385, 'n_units_Layer_1': 130, 'n_units_Layer_2': 240, 'n_units_Layer_3': 210}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 15.04% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 16.12% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:03:31,017]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:03:33,287]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:03:40,862]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:03:42,142]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:03:46,755]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:03:55,844]\u001b[0m Trial 517 finished with value: 6.277390519444946 and parameters: {'n_hidden': 4, 'learning_rate': 0.004283172335959878, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01392027325240049, 'dropout_rate_Layer_2': 0.006881072509878062, 'dropout_rate_Layer_3': 0.13911551524324445, 'dropout_rate_Layer_4': 0.1698749012074266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005527639396117469, 'l1_Layer_2': 0.04206358929741018, 'l1_Layer_3': 0.0015095100007552977, 'l1_Layer_4': 0.016444743295341055, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 225, 'n_units_Layer_4': 50}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 14.62% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 17.59% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:04:01,959]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:05,155]\u001b[0m Trial 522 finished with value: 6.2751886832025905 and parameters: {'n_hidden': 3, 'learning_rate': 0.009069222854977809, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015569651614402297, 'dropout_rate_Layer_2': 0.009488594270624382, 'dropout_rate_Layer_3': 0.11104314488037959, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005785732459590649, 'l1_Layer_2': 0.09664991034236452, 'l1_Layer_3': 0.0028947204972277927, 'n_units_Layer_1': 120, 'n_units_Layer_2': 250, 'n_units_Layer_3': 210}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 14.78% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 16.05% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:04:08,744]\u001b[0m Trial 524 finished with value: 6.301170077341673 and parameters: {'n_hidden': 3, 'learning_rate': 0.009806567913912097, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012639229123801806, 'dropout_rate_Layer_2': 0.03375506699491172, 'dropout_rate_Layer_3': 0.03424521536157037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005823262163687829, 'l1_Layer_2': 0.04120487353305905, 'l1_Layer_3': 0.0015348076803328723, 'n_units_Layer_1': 115, 'n_units_Layer_2': 260, 'n_units_Layer_3': 210}. Best is trial 444 with value: 5.371338132750832.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 14.79% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 16.19% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:04:13,158]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:13,534]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:19,164]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:20,671]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:21,301]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:26,005]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:31,595]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:34,479]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:37,412]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:41,188]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:43,751]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:49,807]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:55,321]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:04:58,171]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:01,229]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:05,901]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:17,505]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:21,678]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:25,559]\u001b[0m Trial 542 finished with value: 5.337342595099514 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026755339265963278, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19594698003934644, 'dropout_rate_Layer_2': 0.16444134340190467, 'dropout_rate_Layer_3': 0.006730322480528828, 'dropout_rate_Layer_4': 0.1742058776696722, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0011820373210511019, 'l1_Layer_2': 9.022191223649942e-05, 'l1_Layer_3': 5.473408470964665e-05, 'l1_Layer_4': 0.000515914755498202, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 125, 'n_units_Layer_4': 245}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 12.58% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.85 | sMAPE for Test Set is: 15.20% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:05:25,773]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:26,697]\u001b[0m Trial 527 finished with value: 6.084036490060318 and parameters: {'n_hidden': 4, 'learning_rate': 0.000891305505850664, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16883135851123765, 'dropout_rate_Layer_2': 0.08725247546971629, 'dropout_rate_Layer_3': 0.209065573809578, 'dropout_rate_Layer_4': 0.06670215736894446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009005436705379631, 'l1_Layer_2': 0.002397374168703361, 'l1_Layer_3': 0.00033872728364079183, 'l1_Layer_4': 1.1894339358867508e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 120, 'n_units_Layer_3': 275, 'n_units_Layer_4': 50}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 15.55% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:05:36,897]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:37,882]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:40,447]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:42,812]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:50,715]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:50,933]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:52,293]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:05:59,899]\u001b[0m Trial 541 finished with value: 5.836916809428338 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005176226542495693, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2851122969147094, 'dropout_rate_Layer_2': 0.38587652392267846, 'dropout_rate_Layer_3': 0.01298881823015692, 'dropout_rate_Layer_4': 0.1330475926883707, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013113503736621377, 'l1_Layer_2': 0.01258166304528905, 'l1_Layer_3': 0.000544957381115533, 'l1_Layer_4': 2.932750700323714e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 125, 'n_units_Layer_3': 160, 'n_units_Layer_4': 105}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 13.69% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 15.51% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:06:00,692]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:04,767]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:06,324]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:07,220]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:07,290]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:11,430]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:16,503]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:19,276]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:24,276]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:27,273]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:30,922]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:34,033]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:37,756]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:40,682]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:44,951]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:47,053]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:50,154]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:52,400]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:06:56,464]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:01,606]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:01,781]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:08,275]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:08,561]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:15,516]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:19,139]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:19,724]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:24,723]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:29,396]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:34,900]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:37,221]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:41,047]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:42,606]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:43,995]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:47,290]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:54,692]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:07:58,761]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:04,220]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:10,114]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:10,188]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:19,013]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:19,138]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:21,294]\u001b[0m Trial 563 finished with value: 5.617537091515362 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005687410791818179, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.278399030599448, 'dropout_rate_Layer_2': 0.08793585269602525, 'dropout_rate_Layer_3': 0.20789610755886104, 'dropout_rate_Layer_4': 0.16401880733669325, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0028392916758378664, 'l1_Layer_2': 0.011692297033717668, 'l1_Layer_3': 0.0003101568988382916, 'l1_Layer_4': 1.3609155427610987e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 130, 'n_units_Layer_3': 270, 'n_units_Layer_4': 105}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 13.15% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 15.07% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:08:30,084]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:30,177]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:32,108]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 15.84% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:08:34,903]\u001b[0m Trial 589 finished with value: 5.999165779429885 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013788797952535414, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3062432769539612, 'dropout_rate_Layer_2': 0.10311709463041017, 'dropout_rate_Layer_3': 0.022284544993541645, 'dropout_rate_Layer_4': 0.12925722067910927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009235729742214483, 'l1_Layer_2': 0.0011194401103373842, 'l1_Layer_3': 0.0001750107968678939, 'l1_Layer_4': 2.587075996403665e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 100, 'n_units_Layer_3': 170, 'n_units_Layer_4': 125}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:36,905]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:45,478]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:45,680]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:46,058]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:54,196]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:08:54,693]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:07,887]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:09,705]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:15,543]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:16,258]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:22,427]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:22,521]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:28,492]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:29,215]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:30,076]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:30,111]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:33,878]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:44,591]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:44,627]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:44,975]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:47,046]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:55,114]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:56,330]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:09:58,588]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:03,542]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:04,241]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:04,367]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:14,992]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:18,599]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:19,596]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:22,996]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:26,878]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:31,328]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:35,825]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:41,911]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:45,976]\u001b[0m Trial 627 finished with value: 6.22718611259922 and parameters: {'n_hidden': 3, 'learning_rate': 0.005097732470147896, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026034211128155977, 'dropout_rate_Layer_2': 0.007341899986248401, 'dropout_rate_Layer_3': 0.29607603041973035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00043707997569615174, 'l1_Layer_2': 0.024687984514410236, 'l1_Layer_3': 0.0018692654647272638, 'n_units_Layer_1': 165, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 16.00% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:10:48,150]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:52,444]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:57,316]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:10:57,892]\u001b[0m Trial 632 finished with value: 6.181612082042729 and parameters: {'n_hidden': 3, 'learning_rate': 0.005692551642696592, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015142786513165822, 'dropout_rate_Layer_2': 0.23364816849584907, 'dropout_rate_Layer_3': 0.17616541078154718, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0016065522325882963, 'l1_Layer_2': 0.09847613945332513, 'l1_Layer_3': 0.005446128364488979, 'n_units_Layer_1': 135, 'n_units_Layer_2': 65, 'n_units_Layer_3': 205}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 15.95% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:10:58,298]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:02,055]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:05,235]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:05,271]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:06,837]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:09,941]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:14,360]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:15,316]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:16,196]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:18,995]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:23,276]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:26,393]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:29,241]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:31,560]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:35,865]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:37,081]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:43,482]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:46,460]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:51,238]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:55,198]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:57,784]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:11:57,934]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:08,155]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:08,409]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:13,743]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:15,760]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:18,752]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:22,620]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:26,118]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:28,671]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:33,965]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:34,724]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:40,784]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:41,051]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:47,170]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:52,093]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:52,521]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:12:58,984]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:13:00,481]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:13:05,659]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:13:09,997]\u001b[0m Trial 664 finished with value: 5.849031861978314 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015903156753275837, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1659850107693731, 'dropout_rate_Layer_2': 0.0838276003701269, 'dropout_rate_Layer_3': 0.2709712621362744, 'dropout_rate_Layer_4': 0.08861928460898157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001856292073499429, 'l1_Layer_2': 0.006943701044698194, 'l1_Layer_3': 0.00011670383589243402, 'l1_Layer_4': 5.652434149556426e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 65, 'n_units_Layer_3': 185, 'n_units_Layer_4': 65}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 13.59% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 15.45% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:13:11,020]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:13:18,009]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:13:23,385]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:13:28,426]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:13:49,355]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:13:49,984]\u001b[0m Trial 681 finished with value: 6.289247848397082 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009383084107594919, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2442324167394907, 'dropout_rate_Layer_2': 0.057380804910215036, 'dropout_rate_Layer_3': 0.2525405074898496, 'dropout_rate_Layer_4': 0.09118555295789006, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0018562332726024902, 'l1_Layer_2': 0.00807549440766118, 'l1_Layer_3': 0.0006756909109219791, 'l1_Layer_4': 4.0225838474614435e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280, 'n_units_Layer_4': 145}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 16.27% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:13:57,096]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:01,931]\u001b[0m Trial 688 finished with value: 5.94154272171816 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019926970123049646, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28506628478422635, 'dropout_rate_Layer_2': 0.09666856427132846, 'dropout_rate_Layer_3': 0.2626366932029561, 'dropout_rate_Layer_4': 0.09350902692041252, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001927389694940407, 'l1_Layer_2': 0.0004275538623158747, 'l1_Layer_3': 0.00014495550485565551, 'l1_Layer_4': 0.00011180337166667751, 'n_units_Layer_1': 220, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260, 'n_units_Layer_4': 85}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 13.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 15.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:14:02,167]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:02,774]\u001b[0m Trial 676 finished with value: 5.894188923755837 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007632182139085868, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21656001537277939, 'dropout_rate_Layer_2': 0.0555924975448346, 'dropout_rate_Layer_3': 0.23498727558904534, 'dropout_rate_Layer_4': 0.0882966653490355, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0018149393328829807, 'l1_Layer_2': 0.00040409277885724925, 'l1_Layer_3': 0.00037834251510983954, 'l1_Layer_4': 0.00016093985801382858, 'n_units_Layer_1': 65, 'n_units_Layer_2': 65, 'n_units_Layer_3': 285, 'n_units_Layer_4': 85}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 13.75% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 15.45% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:14:11,834]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:12,552]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:23,754]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:24,163]\u001b[0m Trial 690 finished with value: 6.133486250357033 and parameters: {'n_hidden': 3, 'learning_rate': 0.0057405465461042755, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00036807293470940937, 'dropout_rate_Layer_2': 0.015493674298216301, 'dropout_rate_Layer_3': 0.0523591824926443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.030709769936914575, 'l1_Layer_2': 0.05607085164828204, 'l1_Layer_3': 0.002561670662921802, 'n_units_Layer_1': 165, 'n_units_Layer_2': 70, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 15.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:14:29,190]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:30,229]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:34,627]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:38,575]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:39,651]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:41,137]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:48,544]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:48,927]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:49,114]\u001b[0m Trial 692 finished with value: 6.216697361882173 and parameters: {'n_hidden': 3, 'learning_rate': 0.005799989843246155, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012131667345452563, 'dropout_rate_Layer_2': 0.0111826059994622, 'dropout_rate_Layer_3': 0.053953303368253325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.029847034877959824, 'l1_Layer_2': 0.0515336436611986, 'l1_Layer_3': 0.004285187530190374, 'n_units_Layer_1': 165, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 15.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:14:49,222]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:14:57,828]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:15:01,781]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:15:02,281]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:15:04,645]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:15:11,775]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:15:31,487]\u001b[0m Trial 712 finished with value: 5.496452622706664 and parameters: {'n_hidden': 4, 'learning_rate': 0.004516801449206091, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17663228530720843, 'dropout_rate_Layer_2': 0.13692224321761176, 'dropout_rate_Layer_3': 0.045318835107490234, 'dropout_rate_Layer_4': 0.1766462320044115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.21374691571997e-05, 'l1_Layer_2': 0.00014619870440413723, 'l1_Layer_3': 0.000277510377433888, 'l1_Layer_4': 0.0006163784856553643, 'n_units_Layer_1': 100, 'n_units_Layer_2': 125, 'n_units_Layer_3': 90, 'n_units_Layer_4': 245}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 15.25% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:15:32,481]\u001b[0m Trial 707 finished with value: 6.173986500708085 and parameters: {'n_hidden': 3, 'learning_rate': 0.005682770825421637, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0009247862102140108, 'dropout_rate_Layer_2': 0.014746743779617748, 'dropout_rate_Layer_3': 0.06413149499466121, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02913619065249962, 'l1_Layer_2': 0.034178202324895476, 'l1_Layer_3': 0.004339405041813215, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 15.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:15:38,747]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:15:43,484]\u001b[0m Trial 713 finished with value: 6.189036861744673 and parameters: {'n_hidden': 3, 'learning_rate': 0.00582964458294805, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0001958663904953221, 'dropout_rate_Layer_2': 0.01902751761602858, 'dropout_rate_Layer_3': 0.06325578810468056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.030256182579113933, 'l1_Layer_2': 0.036625144593847775, 'l1_Layer_3': 0.004493952365958001, 'n_units_Layer_1': 165, 'n_units_Layer_2': 55, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 14.51% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 15.95% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:15:47,800]\u001b[0m Trial 711 finished with value: 5.657678914158926 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007294608414434117, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25605450901922877, 'dropout_rate_Layer_2': 0.01821239170562156, 'dropout_rate_Layer_3': 0.2472175835711529, 'dropout_rate_Layer_4': 0.14760076911984818, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004900136848244326, 'l1_Layer_2': 0.0006367750829745609, 'l1_Layer_3': 0.00027061467152431523, 'l1_Layer_4': 1.281211258443075e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 60, 'n_units_Layer_3': 265, 'n_units_Layer_4': 75}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 13.24% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 15.32% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:15:52,426]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:15:57,173]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:16:02,650]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:16:21,688]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:16:30,706]\u001b[0m Trial 719 finished with value: 6.168725806019604 and parameters: {'n_hidden': 3, 'learning_rate': 0.005686422033046964, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0019445817670025048, 'dropout_rate_Layer_2': 0.016662006349524673, 'dropout_rate_Layer_3': 0.06829867817852411, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.030077729356197947, 'l1_Layer_2': 0.037856552466722065, 'l1_Layer_3': 0.004652686671620046, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 15.94% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 15.91% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:16:36,605]\u001b[0m Trial 714 finished with value: 6.1800081826677085 and parameters: {'n_hidden': 3, 'learning_rate': 0.005809911203652054, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.003450834628893799, 'dropout_rate_Layer_2': 0.01716428153680122, 'dropout_rate_Layer_3': 0.06590988861136106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.030448707902677934, 'l1_Layer_2': 0.03685223401495465, 'l1_Layer_3': 0.004441188448203177, 'n_units_Layer_1': 185, 'n_units_Layer_2': 150, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:16:38,235]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:16:45,012]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:16:58,771]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:17:04,911]\u001b[0m Trial 716 finished with value: 5.685103645813086 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007535202909639559, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12576605483037387, 'dropout_rate_Layer_2': 0.019331619975850967, 'dropout_rate_Layer_3': 0.2472637246669978, 'dropout_rate_Layer_4': 0.121837139906622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0047421987480993945, 'l1_Layer_2': 0.0007002564826006102, 'l1_Layer_3': 0.00021402251464878514, 'l1_Layer_4': 0.00012886093278541996, 'n_units_Layer_1': 230, 'n_units_Layer_2': 60, 'n_units_Layer_3': 265, 'n_units_Layer_4': 75}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 13.31% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 15.26% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:17:10,791]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:17:15,522]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:17:15,778]\u001b[0m Trial 722 finished with value: 6.235730892826058 and parameters: {'n_hidden': 3, 'learning_rate': 0.005516023060508011, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008782052322344226, 'dropout_rate_Layer_2': 0.027999710735558285, 'dropout_rate_Layer_3': 0.0776200957540539, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03468027763863414, 'l1_Layer_2': 0.03370542405967788, 'l1_Layer_3': 0.003605516146140195, 'n_units_Layer_1': 185, 'n_units_Layer_2': 180, 'n_units_Layer_3': 255}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 16.10% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:17:16,055]\u001b[0m Trial 725 finished with value: 6.184574945456933 and parameters: {'n_hidden': 3, 'learning_rate': 0.006547962291927956, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00022791838061086804, 'dropout_rate_Layer_2': 0.0320276177611627, 'dropout_rate_Layer_3': 0.05705343285061077, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.046000106549771096, 'l1_Layer_2': 0.03557975285866601, 'l1_Layer_3': 0.003620468786878726, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 16.04% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:17:27,320]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:17:33,062]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:17:36,732]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:17:39,402]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:17:47,036]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:17:51,416]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:17:56,632]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:02,464]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:08,520]\u001b[0m Trial 735 finished with value: 6.166052139404765 and parameters: {'n_hidden': 3, 'learning_rate': 0.005644013021788926, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0016970288300208972, 'dropout_rate_Layer_2': 0.03273325520603212, 'dropout_rate_Layer_3': 0.06070490403051334, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.046807349341711386, 'l1_Layer_2': 0.03477447931793992, 'l1_Layer_3': 0.0036589790271874326, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 260}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 16.10% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 16.12% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:18:08,573]\u001b[0m Trial 731 finished with value: 6.218738470663571 and parameters: {'n_hidden': 3, 'learning_rate': 0.0056147722605733134, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0018462691366091237, 'dropout_rate_Layer_2': 0.02910632202618188, 'dropout_rate_Layer_3': 0.06025721167965971, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04851669168029274, 'l1_Layer_2': 0.034586217159470266, 'l1_Layer_3': 0.003575036310079869, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:09,305]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:18,151]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:25,167]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:26,122]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:32,700]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:35,403]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:41,484]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:44,479]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:48,951]\u001b[0m Trial 739 finished with value: 5.727847510161124 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011279547020210654, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18282200453458458, 'dropout_rate_Layer_2': 0.24756948567514864, 'dropout_rate_Layer_3': 0.03724745463395074, 'dropout_rate_Layer_4': 0.21594169879005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.029079418239472625, 'l1_Layer_2': 0.0009655487894329766, 'l1_Layer_3': 8.027511207578156e-05, 'l1_Layer_4': 0.0026256974047384855, 'n_units_Layer_1': 95, 'n_units_Layer_2': 125, 'n_units_Layer_3': 115, 'n_units_Layer_4': 240}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 13.36% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 16.16% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:18:52,851]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:18:56,610]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:19:03,517]\u001b[0m Trial 743 finished with value: 6.2102414881583705 and parameters: {'n_hidden': 3, 'learning_rate': 0.004525828212314117, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005293068810946506, 'dropout_rate_Layer_2': 0.025409249507980763, 'dropout_rate_Layer_3': 0.05371225128154433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0459620824781177, 'l1_Layer_2': 0.03869476783891127, 'l1_Layer_3': 0.0034862885674396622, 'n_units_Layer_1': 190, 'n_units_Layer_2': 175, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 16.03% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:19:08,208]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:19:08,667]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:19:16,665]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:19:21,981]\u001b[0m Trial 752 finished with value: 6.268700840015874 and parameters: {'n_hidden': 3, 'learning_rate': 0.004613574677081806, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004139342439568988, 'dropout_rate_Layer_2': 0.025989371469276937, 'dropout_rate_Layer_3': 0.05306839739847208, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07391463957884291, 'l1_Layer_2': 0.03491389711136559, 'l1_Layer_3': 0.004218517381596557, 'n_units_Layer_1': 190, 'n_units_Layer_2': 170, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 16.02% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:19:25,612]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:19:27,302]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:19:29,088]\u001b[0m Trial 750 finished with value: 6.213210749501844 and parameters: {'n_hidden': 3, 'learning_rate': 0.004385332266900747, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0003319556525603138, 'dropout_rate_Layer_2': 0.02487806349372359, 'dropout_rate_Layer_3': 0.0528495778916313, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.045957166377949304, 'l1_Layer_2': 0.03312583743872588, 'l1_Layer_3': 0.0043228893198989935, 'n_units_Layer_1': 190, 'n_units_Layer_2': 170, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 16.08% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:19:35,078]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:19:35,762]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:19:39,505]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:19:54,840]\u001b[0m Trial 757 finished with value: 6.195719504942441 and parameters: {'n_hidden': 3, 'learning_rate': 0.004723342269632066, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0011030224986238702, 'dropout_rate_Layer_2': 0.019985544722984694, 'dropout_rate_Layer_3': 0.05361417948124246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07303610082426439, 'l1_Layer_2': 0.034326917154534925, 'l1_Layer_3': 0.0035161749511430506, 'n_units_Layer_1': 195, 'n_units_Layer_2': 170, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 16.18% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:19:59,817]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:20:00,498]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:20:07,432]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:20:07,758]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:20:15,701]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:20:18,391]\u001b[0m Trial 764 finished with value: 6.224820471165121 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046139278883265515, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008419824050840026, 'dropout_rate_Layer_2': 0.02235577713665142, 'dropout_rate_Layer_3': 0.0675057288401436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08400424377326296, 'l1_Layer_2': 0.034638643508834, 'l1_Layer_3': 0.004034292380664788, 'n_units_Layer_1': 190, 'n_units_Layer_2': 175, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 16.07% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:20:22,805]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:20:36,838]\u001b[0m Trial 762 finished with value: 5.904687279731424 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008769775343354727, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23983207816867322, 'dropout_rate_Layer_2': 0.12159515955424373, 'dropout_rate_Layer_3': 0.2287395859449715, 'dropout_rate_Layer_4': 0.06456152933762427, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002079820112626934, 'l1_Layer_2': 0.0004165125631932542, 'l1_Layer_3': 0.00010487787844614003, 'l1_Layer_4': 2.569283948135507e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260, 'n_units_Layer_4': 65}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 13.55% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 15.29% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:20:43,322]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:20:49,484]\u001b[0m Trial 768 finished with value: 6.20964803815554 and parameters: {'n_hidden': 3, 'learning_rate': 0.004856893626814921, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00033476756613050784, 'dropout_rate_Layer_2': 0.02840131515190324, 'dropout_rate_Layer_3': 0.053746046763671125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04286753183442971, 'l1_Layer_2': 0.033958652257450074, 'l1_Layer_3': 0.003620027646266339, 'n_units_Layer_1': 190, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 16.21% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:20:58,732]\u001b[0m Trial 772 finished with value: 6.184605521400992 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037642499070546617, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002020367664230125, 'dropout_rate_Layer_2': 0.03525816127327751, 'dropout_rate_Layer_3': 0.07213964283675683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04717884966171897, 'l1_Layer_2': 0.033460139365431116, 'l1_Layer_3': 0.003508184583172668, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 245}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 16.13% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:21:00,166]\u001b[0m Trial 771 finished with value: 6.243007148000338 and parameters: {'n_hidden': 3, 'learning_rate': 0.003768305727830569, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006503935413012182, 'dropout_rate_Layer_2': 0.018750037757489853, 'dropout_rate_Layer_3': 0.07435138753489198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04349209270232553, 'l1_Layer_2': 0.030617853979272747, 'l1_Layer_3': 0.0053519082226819465, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 245}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 16.17% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:21:04,247]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:21:04,961]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:21:09,852]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:21:16,061]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:21:16,609]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:21:39,415]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:21:45,098]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:21:51,704]\u001b[0m Trial 776 finished with value: 6.2473389755636175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038125993285606855, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005162149594140804, 'dropout_rate_Layer_2': 0.01875859226515606, 'dropout_rate_Layer_3': 0.061336107726486615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04430848945886627, 'l1_Layer_2': 0.030653916168305356, 'l1_Layer_3': 0.003592097645967587, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 245}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 16.09% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:21:52,140]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:21:59,480]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:22:03,870]\u001b[0m Trial 781 finished with value: 6.288062321265095 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010246770506595643, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.248730598778736, 'dropout_rate_Layer_2': 0.12158531008249379, 'dropout_rate_Layer_3': 0.2346100352268618, 'dropout_rate_Layer_4': 0.08379814336621631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005132961511208853, 'l1_Layer_2': 0.010555360149082559, 'l1_Layer_3': 0.00015330583351542084, 'l1_Layer_4': 1.3206446758701655e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 145, 'n_units_Layer_3': 260, 'n_units_Layer_4': 70}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:22:05,116]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:22:12,153]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:22:12,429]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:22:20,016]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:22:20,444]\u001b[0m Trial 778 finished with value: 5.586452759821765 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005072626703554512, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2508740810198488, 'dropout_rate_Layer_2': 0.12259396649835407, 'dropout_rate_Layer_3': 0.23372919438282574, 'dropout_rate_Layer_4': 0.07493709004223893, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007289571255439756, 'l1_Layer_2': 0.031331954245021956, 'l1_Layer_3': 3.764388256149648e-05, 'l1_Layer_4': 5.810804061127589e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 285, 'n_units_Layer_4': 65}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 13.08% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 15.26% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:23:08,775]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:23:12,418]\u001b[0m Trial 791 finished with value: 6.2078395698146 and parameters: {'n_hidden': 3, 'learning_rate': 0.004207733790511616, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011006670910570211, 'dropout_rate_Layer_2': 0.048033440285752724, 'dropout_rate_Layer_3': 0.07877223464326266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.035153012396054506, 'l1_Layer_2': 0.0525531175837453, 'l1_Layer_3': 0.005411129603513398, 'n_units_Layer_1': 190, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:23:16,276]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:23:16,337]\u001b[0m Trial 788 finished with value: 6.256355451711728 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026954822468156043, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01045176254998035, 'dropout_rate_Layer_2': 0.027812460171870335, 'dropout_rate_Layer_3': 0.07528150709406778, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.034741928113785056, 'l1_Layer_2': 0.051937780443616605, 'l1_Layer_3': 0.005488091254796381, 'n_units_Layer_1': 190, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 15.95% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:23:26,833]\u001b[0m Trial 793 finished with value: 5.612714103293818 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005794299715717049, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23286962708074788, 'dropout_rate_Layer_2': 0.3790228324634328, 'dropout_rate_Layer_3': 0.2900411409221625, 'dropout_rate_Layer_4': 0.06566182965629547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007532887953350768, 'l1_Layer_2': 0.04596612730960779, 'l1_Layer_3': 9.943386600772353e-05, 'l1_Layer_4': 5.952609850030565e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 180, 'n_units_Layer_3': 295, 'n_units_Layer_4': 115}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.77 | sMAPE for Test Set is: 15.24% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:23:27,007]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:23:27,182]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:23:36,467]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:23:38,629]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:23:40,734]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:23:51,682]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:23:58,810]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:03,987]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:04,423]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:12,123]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 16.18% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:24:13,673]\u001b[0m Trial 800 finished with value: 6.195447963522799 and parameters: {'n_hidden': 3, 'learning_rate': 0.003944678258719321, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00023534889608032607, 'dropout_rate_Layer_2': 0.016005764322052824, 'dropout_rate_Layer_3': 0.064798814295356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.06330525761145489, 'l1_Layer_2': 0.038802293896354284, 'l1_Layer_3': 0.004122747253234114, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:15,486]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:21,659]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:22,311]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:27,938]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:28,995]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:34,088]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:37,302]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:41,073]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:42,229]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:43,556]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:52,789]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:53,066]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:24:53,232]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 16.21% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:24:59,277]\u001b[0m Trial 808 finished with value: 6.188560211503084 and parameters: {'n_hidden': 3, 'learning_rate': 0.005057256898583198, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008447277774634119, 'dropout_rate_Layer_2': 0.014377311529595654, 'dropout_rate_Layer_3': 0.08125521429020627, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03896362758422914, 'l1_Layer_2': 0.043035197862844946, 'l1_Layer_3': 0.004771227407396399, 'n_units_Layer_1': 180, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:03,712]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:03,998]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:07,475]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:15,133]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:19,389]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:20,282]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:22,058]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:27,807]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:32,150]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:32,374]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:39,238]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:45,159]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:25:51,122]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:04,102]\u001b[0m Trial 830 finished with value: 6.157685446588242 and parameters: {'n_hidden': 3, 'learning_rate': 0.004788202486576567, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0076296779586794705, 'dropout_rate_Layer_2': 0.009312531645234632, 'dropout_rate_Layer_3': 0.0895148919384732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03547684433924923, 'l1_Layer_2': 0.045918603435298376, 'l1_Layer_3': 0.004574519346707329, 'n_units_Layer_1': 195, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:04,112]\u001b[0m Trial 828 finished with value: 6.182004170524341 and parameters: {'n_hidden': 3, 'learning_rate': 0.004797013019317025, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017530580170440055, 'dropout_rate_Layer_2': 0.021395840267831076, 'dropout_rate_Layer_3': 0.06855560189256364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04952761905296708, 'l1_Layer_2': 0.04557484815786579, 'l1_Layer_3': 0.0045693944294892055, 'n_units_Layer_1': 195, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 14.52% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 16.00% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 16.03% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:26:12,014]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:12,538]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:12,961]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:24,353]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:24,800]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:24,930]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:34,371]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:34,468]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:38,684]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:45,014]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:45,281]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:54,767]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:26:58,634]\u001b[0m Trial 832 finished with value: 5.656153962465638 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009373728855452381, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31766054942836336, 'dropout_rate_Layer_2': 0.3710063551658397, 'dropout_rate_Layer_3': 0.25605531881484367, 'dropout_rate_Layer_4': 0.033465356196370366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005029623772383231, 'l1_Layer_2': 0.07612616122806193, 'l1_Layer_3': 1.7993064972042756e-05, 'l1_Layer_4': 3.113957681683025e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 275, 'n_units_Layer_4': 55}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 13.19% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 14.59% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:27:03,300]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:09,578]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:14,502]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:17,257]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:18,484]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:23,147]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:25,691]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:30,234]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:31,822]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:36,916]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:39,423]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:42,224]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:47,902]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:48,403]\u001b[0m Trial 845 finished with value: 6.23788270703463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032329262338868787, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02274725393722036, 'dropout_rate_Layer_2': 0.021186161820041995, 'dropout_rate_Layer_3': 0.06181583156631081, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04765449733694452, 'l1_Layer_2': 0.04347700084804277, 'l1_Layer_3': 0.0048558954977380945, 'n_units_Layer_1': 200, 'n_units_Layer_2': 160, 'n_units_Layer_3': 240}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 16.07% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:27:56,915]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:57,434]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:57,987]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:27:58,731]\u001b[0m Trial 853 finished with value: 6.171534192264635 and parameters: {'n_hidden': 3, 'learning_rate': 0.004263101747599006, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0002710198268792443, 'dropout_rate_Layer_2': 0.005196272679693312, 'dropout_rate_Layer_3': 0.07927313653722803, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03429779912225011, 'l1_Layer_2': 0.037230368462086556, 'l1_Layer_3': 0.0052265825662280154, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 240}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 15.96% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:28:07,024]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:10,470]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:11,247]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:14,488]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:21,975]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:22,132]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:30,493]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:31,639]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:39,382]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:42,805]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:46,063]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:49,165]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:53,986]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:28:54,588]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:29:06,727]\u001b[0m Trial 869 finished with value: 5.747333986079892 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008145067519450298, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3021918145056153, 'dropout_rate_Layer_2': 0.11804682546681457, 'dropout_rate_Layer_3': 0.24221314052850132, 'dropout_rate_Layer_4': 0.0036094777374218456, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001956932195598661, 'l1_Layer_2': 0.09695165239998349, 'l1_Layer_3': 1.4883284321016417e-05, 'l1_Layer_4': 2.8452158152408556e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 285, 'n_units_Layer_4': 110}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.94 | sMAPE for Test Set is: 15.46% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:29:07,157]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:29:12,263]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:29:15,411]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:29:15,978]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:29:23,574]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:29:24,639]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:29:26,888]\u001b[0m Trial 873 finished with value: 6.286859312501477 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036971369349678633, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0067498435494752025, 'dropout_rate_Layer_2': 0.03441599803724057, 'dropout_rate_Layer_3': 0.09592136205970404, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02848564067518064, 'l1_Layer_2': 0.03639762270499016, 'l1_Layer_3': 0.005569535839903228, 'n_units_Layer_1': 195, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 14.75% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 16.03% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:29:33,084]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:29:41,642]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:30:03,686]\u001b[0m Trial 892 finished with value: 5.863176611526497 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010193013717239724, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3160757378307049, 'dropout_rate_Layer_2': 0.10469883697557852, 'dropout_rate_Layer_3': 0.2675865133340479, 'dropout_rate_Layer_4': 0.002232954860442322, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005709387947880798, 'l1_Layer_2': 0.04220846044155859, 'l1_Layer_3': 1.4249269246816176e-05, 'l1_Layer_4': 1.5917314680531074e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 290, 'n_units_Layer_4': 110}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 13.58% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 15.49% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:30:17,093]\u001b[0m Trial 891 finished with value: 6.198701153574043 and parameters: {'n_hidden': 3, 'learning_rate': 0.005995097920900613, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01622937582960356, 'dropout_rate_Layer_2': 0.0063313775086031015, 'dropout_rate_Layer_3': 0.0832337286700621, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03641042326341896, 'l1_Layer_2': 0.05233653876274032, 'l1_Layer_3': 0.0030592626374247433, 'n_units_Layer_1': 185, 'n_units_Layer_2': 165, 'n_units_Layer_3': 255}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 14.53% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 16.03% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:30:23,910]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:30:31,050]\u001b[0m Trial 887 finished with value: 5.617145613727178 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006564436938871918, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31869302620672924, 'dropout_rate_Layer_2': 0.36552158949629, 'dropout_rate_Layer_3': 0.2546125182806689, 'dropout_rate_Layer_4': 0.020892387632058092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0024539576643520682, 'l1_Layer_2': 0.05360176200896053, 'l1_Layer_3': 1.8029176866270463e-05, 'l1_Layer_4': 0.0001526683771766274, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265, 'n_units_Layer_4': 95}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 13.09% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.84 | sMAPE for Test Set is: 15.22% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:30:31,639]\u001b[0m Trial 893 finished with value: 5.844749137058827 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010766553057013756, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3164075832296311, 'dropout_rate_Layer_2': 0.3667689542178571, 'dropout_rate_Layer_3': 0.25702210247448043, 'dropout_rate_Layer_4': 0.07818680884110803, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001242884611990968, 'l1_Layer_2': 0.04592115563884368, 'l1_Layer_3': 1.3101297125703097e-05, 'l1_Layer_4': 2.7838853402510355e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 290, 'n_units_Layer_4': 125}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 13.61% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 15.76% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:30:40,284]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:30:40,820]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:30:48,269]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:30:50,114]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:00,470]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:04,846]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:05,235]\u001b[0m Trial 896 finished with value: 5.380906533546732 and parameters: {'n_hidden': 4, 'learning_rate': 0.002387460778112218, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1953322467508443, 'dropout_rate_Layer_2': 0.2498072900611952, 'dropout_rate_Layer_3': 0.04935980616484846, 'dropout_rate_Layer_4': 0.16509045036470096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.3578610944416714e-05, 'l1_Layer_2': 0.000256326043713206, 'l1_Layer_3': 0.00010195143675816834, 'l1_Layer_4': 0.0005726766097352672, 'n_units_Layer_1': 180, 'n_units_Layer_2': 105, 'n_units_Layer_3': 150, 'n_units_Layer_4': 195}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 14.56% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:31:13,485]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:18,443]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:20,240]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:26,424]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:32,107]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:35,497]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:38,636]\u001b[0m Trial 899 finished with value: 6.235492807260439 and parameters: {'n_hidden': 3, 'learning_rate': 0.005994946169937927, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016569388484718332, 'dropout_rate_Layer_2': 0.007575537499463547, 'dropout_rate_Layer_3': 0.07842297371508938, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.053219694571514986, 'l1_Layer_2': 0.048317907607221565, 'l1_Layer_3': 0.0025799533502763243, 'n_units_Layer_1': 175, 'n_units_Layer_2': 160, 'n_units_Layer_3': 255}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 16.06% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:31:38,730]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:43,803]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:47,060]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:48,680]\u001b[0m Trial 902 finished with value: 6.187851105615413 and parameters: {'n_hidden': 3, 'learning_rate': 0.005064600884332661, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010413100859543497, 'dropout_rate_Layer_2': 8.659883879248969e-05, 'dropout_rate_Layer_3': 0.08892259986490574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.05500186657225191, 'l1_Layer_2': 0.047960319425290096, 'l1_Layer_3': 0.002445398292355738, 'n_units_Layer_1': 185, 'n_units_Layer_2': 165, 'n_units_Layer_3': 255}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 16.08% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:31:48,854]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:53,831]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:31:59,587]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:05,565]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:05,704]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:06,823]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:09,907]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:13,967]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:15,723]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:16,904]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:20,500]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:26,645]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:30,549]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:30,607]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:38,034]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:43,546]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:47,767]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:32:48,553]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:33:03,060]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:33:16,190]\u001b[0m Trial 924 finished with value: 5.71343903464756 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008214549575275498, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32472702329099234, 'dropout_rate_Layer_2': 0.024729360949919836, 'dropout_rate_Layer_3': 0.22865419380096344, 'dropout_rate_Layer_4': 0.038856186443987466, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014568987281498873, 'l1_Layer_2': 0.06613358065987875, 'l1_Layer_3': 1.5716916283715873e-05, 'l1_Layer_4': 2.8473909984425303e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 270, 'n_units_Layer_4': 110}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 13.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 16.00% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:33:23,456]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:33:31,832]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:33:37,510]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:33:43,843]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:33:49,105]\u001b[0m Trial 928 finished with value: 5.718083071233617 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006035382489569955, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3355664618188319, 'dropout_rate_Layer_2': 0.02524185323113156, 'dropout_rate_Layer_3': 0.22933689059163997, 'dropout_rate_Layer_4': 0.001654408276971418, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001992172701666636, 'l1_Layer_2': 0.021905556633509127, 'l1_Layer_3': 1.957710498391174e-05, 'l1_Layer_4': 0.00025933793767908493, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 270, 'n_units_Layer_4': 90}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 13.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 15.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:33:54,839]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:33:59,456]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:05,531]\u001b[0m Trial 935 finished with value: 5.487106143682364 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011744960773798574, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2742337149204802, 'dropout_rate_Layer_2': 0.09904760309123721, 'dropout_rate_Layer_3': 0.2645076740640477, 'dropout_rate_Layer_4': 0.001686874572040857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001081443444217437, 'l1_Layer_2': 0.02093371790142386, 'l1_Layer_3': 2.0012246221386505e-05, 'l1_Layer_4': 2.5321774360494797e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245, 'n_units_Layer_4': 125}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 12.81% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.77 | sMAPE for Test Set is: 14.80% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:34:10,349]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:14,030]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:14,401]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:18,924]\u001b[0m Trial 933 finished with value: 6.2056842087101005 and parameters: {'n_hidden': 3, 'learning_rate': 0.003987477431316165, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009345316907198427, 'dropout_rate_Layer_2': 0.0007856328451962095, 'dropout_rate_Layer_3': 0.07937923050217646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07234750544085687, 'l1_Layer_2': 0.0465088617359796, 'l1_Layer_3': 0.002532010435826892, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 16.08% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:34:24,582]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:24,780]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:25,078]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:33,397]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:34,305]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:39,851]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:43,035]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:43,579]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:50,845]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 16.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:34:54,415]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:34:54,534]\u001b[0m Trial 944 finished with value: 6.223796679525179 and parameters: {'n_hidden': 3, 'learning_rate': 0.004060116427614169, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0076062223727082195, 'dropout_rate_Layer_2': 0.0001645744102603788, 'dropout_rate_Layer_3': 0.09039332953927308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.029749745862640304, 'l1_Layer_2': 0.07190055096904992, 'l1_Layer_3': 0.004065549980486491, 'n_units_Layer_1': 190, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:04,451]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:04,551]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:18,100]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:18,490]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:24,919]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:25,982]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:31,454]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:32,580]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:36,970]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:39,225]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:42,475]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:47,570]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:51,922]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:54,856]\u001b[0m Trial 957 finished with value: 6.204864984979399 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033848775015809, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008568322038345547, 'dropout_rate_Layer_2': 0.0004031844751757963, 'dropout_rate_Layer_3': 0.0747365918444049, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.047410310641471005, 'l1_Layer_2': 0.03911354250844477, 'l1_Layer_3': 0.002336528084586249, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 260}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 16.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:35:56,154]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:35:58,695]\u001b[0m Trial 954 finished with value: 6.216515638513049 and parameters: {'n_hidden': 3, 'learning_rate': 0.003135272882940628, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023157394113246712, 'dropout_rate_Layer_2': 0.0006679767299583916, 'dropout_rate_Layer_3': 0.08191292502934532, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04310326852305775, 'l1_Layer_2': 0.03002487840348492, 'l1_Layer_3': 0.0029190551418533006, 'n_units_Layer_1': 180, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 16.07% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:35:59,526]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:07,591]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:11,519]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:12,261]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:15,961]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:18,437]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:19,258]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:26,989]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:33,318]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:38,082]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:41,100]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:43,737]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:49,256]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:49,513]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:36:57,449]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:02,574]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:04,893]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 13.48% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 15.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:37:06,971]\u001b[0m Trial 980 finished with value: 5.80148737517149 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009126541087414548, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27361573895393554, 'dropout_rate_Layer_2': 0.01888298579245311, 'dropout_rate_Layer_3': 0.22908264400912984, 'dropout_rate_Layer_4': 0.029645495003687364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002458335625764823, 'l1_Layer_2': 0.021254625413337107, 'l1_Layer_3': 1.9991943208097237e-05, 'l1_Layer_4': 2.6254530221678246e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 255, 'n_units_Layer_4': 95}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:10,389]\u001b[0m Trial 974 finished with value: 5.7820510219994885 and parameters: {'n_hidden': 4, 'learning_rate': 0.000679937128422911, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3216413833495573, 'dropout_rate_Layer_2': 0.008863810595903573, 'dropout_rate_Layer_3': 0.29169240773229255, 'dropout_rate_Layer_4': 0.012994903096122383, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013667042724125591, 'l1_Layer_2': 0.03417966361906816, 'l1_Layer_3': 2.0988170822946594e-05, 'l1_Layer_4': 1.4583538590248515e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 215, 'n_units_Layer_3': 245, 'n_units_Layer_4': 110}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 13.41% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 16.36% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:37:24,668]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:28,105]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:29,164]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:29,692]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:34,863]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:41,527]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:44,279]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:48,939]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:49,013]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:37:57,801]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:38:02,997]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:38:03,718]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:38:12,681]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:38:17,794]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:38:23,053]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:38:24,245]\u001b[0m Trial 998 finished with value: 5.776772433943367 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009279029126975231, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3367784792413067, 'dropout_rate_Layer_2': 0.004790266286545386, 'dropout_rate_Layer_3': 0.2789139128253761, 'dropout_rate_Layer_4': 0.00038724475131579877, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002520813518466768, 'l1_Layer_2': 0.027561274913235963, 'l1_Layer_3': 1.9411227892589888e-05, 'l1_Layer_4': 2.277690399969659e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 230, 'n_units_Layer_4': 120}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 13.40% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 16.37% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:38:30,701]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:38:44,523]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:38:48,192]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:38:48,565]\u001b[0m Trial 1003 finished with value: 5.849897362790737 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009423936798360194, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33638970175297017, 'dropout_rate_Layer_2': 0.006349774662315611, 'dropout_rate_Layer_3': 0.278456273434174, 'dropout_rate_Layer_4': 0.024638387770321773, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0025133078406171243, 'l1_Layer_2': 0.022973601149788744, 'l1_Layer_3': 2.2351655537812526e-05, 'l1_Layer_4': 2.2781697270814672e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 235, 'n_units_Layer_3': 235, 'n_units_Layer_4': 115}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 13.53% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 16.06% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:38:50,656]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:38:57,512]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:38:58,716]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:03,980]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:04,641]\u001b[0m Trial 1005 finished with value: 5.872495757055016 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009627143264171982, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2754523247697888, 'dropout_rate_Layer_2': 0.007749139898185578, 'dropout_rate_Layer_3': 0.2867982197874775, 'dropout_rate_Layer_4': 0.00013897065820462143, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0025569460548695556, 'l1_Layer_2': 0.021557927801201276, 'l1_Layer_3': 2.1924040263069763e-05, 'l1_Layer_4': 2.359418965358614e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235, 'n_units_Layer_4': 120}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 13.60% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 16.28% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:39:06,434]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:14,466]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:16,616]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:23,006]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:24,442]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:27,153]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:29,344]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:37,548]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:38,308]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:45,238]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:51,666]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:39:56,208]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:00,670]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:03,981]\u001b[0m Trial 1024 finished with value: 6.22157884023265 and parameters: {'n_hidden': 3, 'learning_rate': 0.006483800303698863, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007956280010885216, 'dropout_rate_Layer_2': 0.015605165256557583, 'dropout_rate_Layer_3': 0.03078142964228511, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03867541147773476, 'l1_Layer_2': 0.03238912226760273, 'l1_Layer_3': 0.003721242828626909, 'n_units_Layer_1': 285, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 16.14% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:40:08,117]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:13,224]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 13.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 15.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:40:16,702]\u001b[0m Trial 1016 finished with value: 5.771159580442048 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005779286688038937, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27515776360530375, 'dropout_rate_Layer_2': 0.0005121602814412568, 'dropout_rate_Layer_3': 0.28455758696391076, 'dropout_rate_Layer_4': 0.0364041299470685, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0038810560051399674, 'l1_Layer_2': 0.015439611446377333, 'l1_Layer_3': 2.0421055213683763e-05, 'l1_Layer_4': 3.550910551214783e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 110, 'n_units_Layer_3': 245, 'n_units_Layer_4': 130}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:21,392]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:22,817]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:27,453]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:33,914]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:38,567]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:43,681]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:49,110]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:54,055]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:40:55,505]\u001b[0m Trial 1029 finished with value: 5.842368672244819 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008069796570820537, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32962457316485094, 'dropout_rate_Layer_2': 0.02467603200144446, 'dropout_rate_Layer_3': 0.2582511847167515, 'dropout_rate_Layer_4': 0.016266878237391487, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005299182988485701, 'l1_Layer_2': 0.04864435561579061, 'l1_Layer_3': 1.858938270534462e-05, 'l1_Layer_4': 2.0718930811692247e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245, 'n_units_Layer_4': 115}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 13.65% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.82 | sMAPE for Test Set is: 15.21% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:41:07,225]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:41:11,358]\u001b[0m Trial 1039 finished with value: 6.203410915040881 and parameters: {'n_hidden': 3, 'learning_rate': 0.005086472159434986, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022130772994131447, 'dropout_rate_Layer_2': 2.7611772259815426e-05, 'dropout_rate_Layer_3': 0.07054259319013645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.024858312409918586, 'l1_Layer_2': 0.06248129859825291, 'l1_Layer_3': 0.0020617699643645055, 'n_units_Layer_1': 190, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 16.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:41:17,588]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:41:21,964]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:41:26,994]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:41:31,954]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:41:32,191]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:41:37,553]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:41:41,092]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:41:45,891]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:41:46,636]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:41:47,723]\u001b[0m Trial 1038 finished with value: 5.7725696036003145 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006195010617115028, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33133442624246884, 'dropout_rate_Layer_2': 0.0006029304140004309, 'dropout_rate_Layer_3': 0.2591920600183477, 'dropout_rate_Layer_4': 0.042397537407343436, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004199692266010625, 'l1_Layer_2': 0.015268264537687624, 'l1_Layer_3': 2.6431038798145975e-05, 'l1_Layer_4': 1.9083885667532182e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 215, 'n_units_Layer_3': 255, 'n_units_Layer_4': 125}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 13.46% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 15.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:41:55,427]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:00,271]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:02,940]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:05,791]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:13,554]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:16,671]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:17,022]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:18,688]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:27,468]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:33,254]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:35,769]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:39,843]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:40,296]\u001b[0m Trial 1054 finished with value: 6.191875970430215 and parameters: {'n_hidden': 3, 'learning_rate': 0.006534704041353623, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012601798976782787, 'dropout_rate_Layer_2': 0.0002297837213241635, 'dropout_rate_Layer_3': 0.07539423353577211, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02396194829801967, 'l1_Layer_2': 0.06073704160153642, 'l1_Layer_3': 0.0025794810743495354, 'n_units_Layer_1': 200, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 16.03% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:42:46,240]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:51,485]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:53,097]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:42:59,059]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:43:03,090]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:43:10,527]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:43:10,932]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:43:19,404]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:43:21,644]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:43:29,549]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:43:32,527]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:43:38,007]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:43:43,148]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:43:43,762]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:43:51,417]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:07,886]\u001b[0m Trial 1077 finished with value: 5.8525581891399066 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008506900501142404, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3426610983833928, 'dropout_rate_Layer_2': 0.00016045557733224136, 'dropout_rate_Layer_3': 0.23814710176503076, 'dropout_rate_Layer_4': 0.007716584415997015, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005350466562389795, 'l1_Layer_2': 0.04963149137655291, 'l1_Layer_3': 1.3258532725306301e-05, 'l1_Layer_4': 1.7652979977551388e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 225, 'n_units_Layer_3': 250, 'n_units_Layer_4': 130}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 13.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 16.10% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:44:08,082]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:18,755]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:19,039]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 13.55% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 16.14% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:44:21,562]\u001b[0m Trial 1070 finished with value: 5.817115756479722 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005650454847305195, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.269149470801528, 'dropout_rate_Layer_2': 0.01832358159840322, 'dropout_rate_Layer_3': 0.2570765511360283, 'dropout_rate_Layer_4': 0.019300737169117614, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005146205473090499, 'l1_Layer_2': 0.07586430780767381, 'l1_Layer_3': 1.984158692181109e-05, 'l1_Layer_4': 1.67703501810658e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 225, 'n_units_Layer_3': 245, 'n_units_Layer_4': 125}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:31,902]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:32,588]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:40,362]\u001b[0m Trial 1085 finished with value: 6.208633417799042 and parameters: {'n_hidden': 3, 'learning_rate': 0.004170363948636096, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006034804636448029, 'dropout_rate_Layer_2': 0.017327055535676723, 'dropout_rate_Layer_3': 0.08010075097578795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.017980989934341055, 'l1_Layer_2': 0.05746604364420843, 'l1_Layer_3': 0.0044754217838464515, 'n_units_Layer_1': 170, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 15.98% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:44:40,695]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:42,857]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:51,276]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:54,803]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:58,273]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:58,638]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:44:58,747]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:08,070]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:10,511]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:14,167]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:17,863]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:18,135]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:26,069]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:30,020]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:34,619]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:37,955]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:43,394]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:46,449]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:51,538]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:52,028]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.51% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 16.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:45:56,300]\u001b[0m Trial 1101 finished with value: 6.205235259954712 and parameters: {'n_hidden': 3, 'learning_rate': 0.00704892748827721, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007255290498795606, 'dropout_rate_Layer_2': 0.02521384519451541, 'dropout_rate_Layer_3': 0.09467868279755176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.05007744464314186, 'l1_Layer_2': 0.06790289412801244, 'l1_Layer_3': 0.004108558549087078, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 240}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:45:58,993]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:03,494]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:09,502]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:10,736]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:11,937]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:12,652]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:20,476]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:26,358]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:27,066]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:31,459]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:35,763]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:36,234]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:40,536]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:47,917]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:49,430]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:51,180]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:46:58,608]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:01,540]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:04,002]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:11,099]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:12,633]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:17,143]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:26,184]\u001b[0m Trial 1129 finished with value: 6.246494359455073 and parameters: {'n_hidden': 3, 'learning_rate': 0.007253437535653973, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008549877321527705, 'dropout_rate_Layer_2': 0.01947231905215388, 'dropout_rate_Layer_3': 0.06054365961759777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.042646998144053275, 'l1_Layer_2': 0.03664077588708894, 'l1_Layer_3': 0.001532080168838228, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 14.67% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 16.47% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:47:27,334]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:32,455]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:38,328]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:44,141]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:46,658]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:51,655]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:47:57,282]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:02,977]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:08,524]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:09,126]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:10,309]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:18,574]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:18,822]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:19,941]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:24,586]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:32,851]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:37,353]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:42,120]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:45,516]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:46,882]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:52,346]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:54,782]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:48:55,728]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:07,980]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:10,580]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:14,629]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:14,783]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:17,402]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:25,272]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:29,843]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:30,031]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:38,012]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:42,156]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:44,011]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:45,554]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:55,802]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:57,043]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:58,736]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:49:59,455]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:06,552]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:12,317]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:15,118]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:18,036]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:23,080]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:26,006]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:27,771]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:29,555]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:32,191]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:39,242]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:42,126]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:43,350]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:48,415]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:51,372]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:54,752]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:50:59,097]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:04,707]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:04,906]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:10,022]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:13,294]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:17,620]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:20,257]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:21,612]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:25,586]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:29,416]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:31,356]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:34,794]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:40,245]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:40,973]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:44,176]\u001b[0m Trial 1174 finished with value: 5.444370842406204 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005987693042914596, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28120677673113453, 'dropout_rate_Layer_2': 0.027094851387831874, 'dropout_rate_Layer_3': 0.27793386493233957, 'dropout_rate_Layer_4': 0.0003249226148166215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017202119548671967, 'l1_Layer_2': 0.02280724694084298, 'l1_Layer_3': 1.1186870658329778e-05, 'l1_Layer_4': 3.89752302368249e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 105, 'n_units_Layer_3': 265, 'n_units_Layer_4': 110}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 14.71% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:51:45,060]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:46,607]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:51:59,813]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:00,349]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:00,682]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:04,087]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:08,022]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:12,982]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:14,492]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:15,112]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:19,830]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:26,719]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:29,566]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:36,409]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:42,012]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:48,606]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:58,879]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:52:59,137]\u001b[0m Trial 1218 finished with value: 6.205345090558853 and parameters: {'n_hidden': 3, 'learning_rate': 0.003439288283196606, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034105576522855986, 'dropout_rate_Layer_2': 0.007562495551436346, 'dropout_rate_Layer_3': 0.08896391917378067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0471683162224957, 'l1_Layer_2': 0.0433181247986771, 'l1_Layer_3': 4.6223052197863105e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 15.98% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:53:02,492]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:09,821]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:10,186]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:16,388]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:19,565]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:22,371]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:26,499]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:30,571]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:31,499]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 14.65% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:53:36,442]\u001b[0m Trial 1214 finished with value: 5.467635446416154 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007007525871426919, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2865732216215158, 'dropout_rate_Layer_2': 0.017868186314733997, 'dropout_rate_Layer_3': 0.24708787768542823, 'dropout_rate_Layer_4': 0.01000942497663289, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000965040375679472, 'l1_Layer_2': 0.028374692953637162, 'l1_Layer_3': 1.0489412565730067e-05, 'l1_Layer_4': 2.1163733609552606e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 230, 'n_units_Layer_4': 140}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:46,105]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:51,122]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:51,832]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:53:52,272]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:02,818]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:04,814]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:09,347]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:11,723]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:16,837]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:16,973]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:17,053]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:26,934]\u001b[0m Trial 1232 finished with value: 6.192071801972344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034683399671359303, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00035539588151984605, 'dropout_rate_Layer_2': 0.03471974916083054, 'dropout_rate_Layer_3': 0.055272929288177966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.041878111222678045, 'l1_Layer_2': 0.056936442000457485, 'l1_Layer_3': 0.005685707245831638, 'n_units_Layer_1': 175, 'n_units_Layer_2': 170, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 16.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:54:28,045]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:28,330]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:38,772]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:38,774]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:39,704]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:49,935]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:50,660]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:51,971]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:54:58,182]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:01,781]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:06,881]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:10,293]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:11,335]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:13,292]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:15,772]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:19,712]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:30,155]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:33,758]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:34,106]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:40,218]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:43,369]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:44,781]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:49,233]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:52,685]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:55:55,895]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:01,803]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:05,308]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:07,428]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:14,160]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:15,391]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:15,592]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:16,714]\u001b[0m Trial 1259 finished with value: 6.244152013771583 and parameters: {'n_hidden': 3, 'learning_rate': 0.004472118890125328, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007380389666425084, 'dropout_rate_Layer_2': 0.02972353634280224, 'dropout_rate_Layer_3': 0.02224420740455886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.018649387529627897, 'l1_Layer_2': 0.052036144339978996, 'l1_Layer_3': 0.004455466252257135, 'n_units_Layer_1': 190, 'n_units_Layer_2': 170, 'n_units_Layer_3': 265}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 14.67% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 15.92% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:56:22,340]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:29,851]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:32,312]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:33,029]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:38,386]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:41,138]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:41,932]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:43,824]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:45,952]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:49,810]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:56:59,090]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:02,313]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:06,538]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:13,104]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:18,700]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:18,993]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 16.29% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:57:23,734]\u001b[0m Trial 1288 finished with value: 6.2208710715713 and parameters: {'n_hidden': 3, 'learning_rate': 0.006740444089418239, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007183065767103714, 'dropout_rate_Layer_2': 0.045717471095072224, 'dropout_rate_Layer_3': 0.1749555532534265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.025716016744255995, 'l1_Layer_2': 0.039229280267902324, 'l1_Layer_3': 0.0018630274429328334, 'n_units_Layer_1': 195, 'n_units_Layer_2': 185, 'n_units_Layer_3': 235}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:27,835]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:33,183]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:33,501]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:35,205]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:42,605]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:45,367]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:46,329]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:46,791]\u001b[0m Trial 1291 finished with value: 6.178254540459403 and parameters: {'n_hidden': 3, 'learning_rate': 0.006897646894461849, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020403740877198845, 'dropout_rate_Layer_2': 0.014988754235262362, 'dropout_rate_Layer_3': 0.04409582854569778, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.026924926553960265, 'l1_Layer_2': 0.037840793146783396, 'l1_Layer_3': 0.0021284961452061836, 'n_units_Layer_1': 195, 'n_units_Layer_2': 200, 'n_units_Layer_3': 285}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 16.11% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 15:57:48,251]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:53,780]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:57:54,292]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:00,156]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:04,908]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:12,963]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:13,573]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:14,111]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:19,098]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:26,014]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:27,908]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:31,280]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:31,926]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:40,248]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:42,770]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:45,279]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:45,607]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:51,395]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:58:53,268]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:02,149]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:03,710]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:04,160]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:07,349]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:17,669]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:17,932]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:19,574]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:26,861]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:30,036]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:33,743]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:34,571]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:38,697]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:45,105]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:45,723]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:53,638]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 15:59:57,553]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:02,349]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:04,891]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:09,181]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:12,508]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:16,523]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:20,533]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:24,388]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:27,465]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:32,119]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:37,001]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:45,121]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:50,388]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:00:55,585]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:00,522]\u001b[0m Trial 1339 finished with value: 6.20551560337983 and parameters: {'n_hidden': 3, 'learning_rate': 0.003643441565155383, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013901748898203545, 'dropout_rate_Layer_2': 0.014202723820175244, 'dropout_rate_Layer_3': 0.05595685760425957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.030467283843508323, 'l1_Layer_2': 0.04955179894161716, 'l1_Layer_3': 0.0026149357541623407, 'n_units_Layer_1': 210, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 15.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 16:01:08,414]\u001b[0m Trial 1343 finished with value: 6.209199497535464 and parameters: {'n_hidden': 3, 'learning_rate': 0.004014970391384757, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012324740160371338, 'dropout_rate_Layer_2': 0.00010586330865314936, 'dropout_rate_Layer_3': 0.056375072160677595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.029344587213733727, 'l1_Layer_2': 0.04898133709064383, 'l1_Layer_3': 0.0026983635143834604, 'n_units_Layer_1': 185, 'n_units_Layer_2': 210, 'n_units_Layer_3': 245}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 15.90% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 16:01:12,906]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:17,336]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:17,620]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:19,820]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:27,239]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:32,968]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:33,686]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:36,062]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:43,980]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:49,050]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:49,788]\u001b[0m Trial 1348 finished with value: 5.590798437404454 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035763201286366443, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006853122467431172, 'dropout_rate_Layer_2': 0.030254135160452375, 'dropout_rate_Layer_3': 0.05550764081753803, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0008566895508998903, 'l1_Layer_2': 0.028634861280878273, 'l1_Layer_3': 0.002226598779019547, 'n_units_Layer_1': 200, 'n_units_Layer_2': 230, 'n_units_Layer_3': 285}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 13.15% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 14.89% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 16:01:53,731]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:57,946]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:01:59,908]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:08,889]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:11,669]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:14,251]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:14,955]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:21,326]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:21,518]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:26,160]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:27,046]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:38,432]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:40,330]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:40,530]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:44,535]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:53,295]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:54,329]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:02:56,735]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:03:03,550]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:03:04,746]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:03:04,758]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:03:12,187]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:03:16,396]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:03:18,538]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:03:19,436]\u001b[0m Trial 1373 finished with value: 5.898058293678241 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022546012325230513, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09988490326044726, 'dropout_rate_Layer_2': 0.1723038239151531, 'dropout_rate_Layer_3': 0.047709690171756844, 'dropout_rate_Layer_4': 0.18976751264815964, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.036949724590054404, 'l1_Layer_2': 0.0004721863109758091, 'l1_Layer_3': 8.27806523975125e-05, 'l1_Layer_4': 0.0006063541293282366, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 95, 'n_units_Layer_4': 275}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 16.08% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 16:03:28,523]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:03:29,091]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:03:38,498]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:03:54,552]\u001b[0m Trial 1384 finished with value: 5.807151049093605 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008068782086055365, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33988960234483573, 'dropout_rate_Layer_2': 0.07806439693026056, 'dropout_rate_Layer_3': 0.297734403293512, 'dropout_rate_Layer_4': 0.14645581953312414, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003616874451520202, 'l1_Layer_2': 0.029039247384870067, 'l1_Layer_3': 2.0213079132589127e-05, 'l1_Layer_4': 1.6532240681166515e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270, 'n_units_Layer_4': 115}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 13.53% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 16.02% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 16:04:01,096]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:04:01,329]\u001b[0m Trial 1387 finished with value: 6.218626565418208 and parameters: {'n_hidden': 3, 'learning_rate': 0.004523658323735083, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017676478199999457, 'dropout_rate_Layer_2': 0.016588353993176846, 'dropout_rate_Layer_3': 0.050050917968961384, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.018288686895847416, 'l1_Layer_2': 0.053319367445497194, 'l1_Layer_3': 0.005008844025234531, 'n_units_Layer_1': 200, 'n_units_Layer_2': 145, 'n_units_Layer_3': 255}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 15.97% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 16:04:11,590]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:04:17,068]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:04:18,328]\u001b[0m Trial 1390 finished with value: 5.8905106604698645 and parameters: {'n_hidden': 4, 'learning_rate': 0.000814327336314354, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3172433024342097, 'dropout_rate_Layer_2': 0.007356995270605815, 'dropout_rate_Layer_3': 0.2617068405290112, 'dropout_rate_Layer_4': 2.9946990403786477e-05, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004031271079738928, 'l1_Layer_2': 0.057134975186021966, 'l1_Layer_3': 1.756899127714945e-05, 'l1_Layer_4': 1.2263786027974372e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 220, 'n_units_Layer_3': 270, 'n_units_Layer_4': 120}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 13.72% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 15.80% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 16:04:25,369]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:04:31,749]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:04:37,473]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:04:38,884]\u001b[0m Trial 1392 finished with value: 6.228773292882482 and parameters: {'n_hidden': 3, 'learning_rate': 0.004520783063825888, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018236316283710214, 'dropout_rate_Layer_2': 0.01672335819409043, 'dropout_rate_Layer_3': 0.05149957555427584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.021679412013675424, 'l1_Layer_2': 0.05589162192052123, 'l1_Layer_3': 0.004778944608939202, 'n_units_Layer_1': 200, 'n_units_Layer_2': 60, 'n_units_Layer_3': 255}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 16.08% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 16:04:43,599]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:04:47,427]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:04:48,302]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:04:54,099]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:04:57,760]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:00,933]\u001b[0m Trial 1398 finished with value: 6.172167941223087 and parameters: {'n_hidden': 3, 'learning_rate': 0.005672738380815532, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008198998620207688, 'dropout_rate_Layer_2': 0.02734377534566572, 'dropout_rate_Layer_3': 0.07062715334969494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0009652098612443354, 'l1_Layer_2': 0.03345257403788958, 'l1_Layer_3': 0.001991724174873475, 'n_units_Layer_1': 185, 'n_units_Layer_2': 55, 'n_units_Layer_3': 250}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 16.06% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 16:05:05,382]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:05,548]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:05,626]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:05,763]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:16,555]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:21,188]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:21,199]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:24,927]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:25,375]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:31,734]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:39,111]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:42,801]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:44,453]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:44,700]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:54,796]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:05:58,454]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:02,272]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:03,147]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:04,939]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:12,101]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:12,492]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:17,597]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:19,876]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:27,050]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:29,106]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:33,311]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:39,175]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:39,731]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:45,850]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:48,120]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:52,197]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:54,743]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:55,303]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:06:57,371]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:06,914]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:08,093]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:08,518]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:18,429]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:20,120]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:23,238]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:27,625]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:30,699]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:38,448]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:43,070]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:46,899]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:47,592]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:49,374]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:07:59,840]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:01,125]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:01,644]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:10,039]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:10,969]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:11,491]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:17,972]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:20,605]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:22,525]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 13.06% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 15.79% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 16:08:26,971]\u001b[0m Trial 1442 finished with value: 5.582161939370565 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006063147258071167, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27883398329051623, 'dropout_rate_Layer_2': 0.07275941271053518, 'dropout_rate_Layer_3': 0.2538321186002029, 'dropout_rate_Layer_4': 0.08415688452368231, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0034658218494487596, 'l1_Layer_2': 0.03339883885385419, 'l1_Layer_3': 2.848623841151348e-05, 'l1_Layer_4': 5.9813774580917864e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 125, 'n_units_Layer_3': 270, 'n_units_Layer_4': 90}. Best is trial 542 with value: 5.337342595099514.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:33,138]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:35,977]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:41,327]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:42,953]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:44,630]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:51,678]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:54,792]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:57,323]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:59,163]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:08:59,570]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:12,209]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:14,420]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:16,104]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:21,773]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:23,987]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:26,236]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:28,769]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:31,001]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:35,563]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:47,610]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:48,545]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:48,596]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:48,722]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:56,981]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:58,416]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:59,176]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:09:59,842]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:10:09,668]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:10:10,424]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:10:11,361]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:10:12,967]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:10:17,724]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:10:21,741]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:10:24,784]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:10:26,565]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:10:27,086]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:10:33,121]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 16:10:33,273]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-01-01, MAE is:8.80 & sMAPE is:22.40% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 22.40% & 1.71\n",
      "for 2019-01-02, MAE is:4.98 & sMAPE is:9.98% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 16.19% & 1.56\n",
      "for 2019-01-03, MAE is:4.52 & sMAPE is:7.75% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 13.38% & 1.80\n",
      "for 2019-01-04, MAE is:6.29 & sMAPE is:10.15% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 12.57% & 1.71\n",
      "for 2019-01-05, MAE is:5.43 & sMAPE is:9.18% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 11.89% & 1.48\n",
      "for 2019-01-06, MAE is:3.83 & sMAPE is:7.17% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 11.11% & 1.31\n",
      "for 2019-01-07, MAE is:5.91 & sMAPE is:8.84% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 10.78% & 1.24\n",
      "for 2019-01-08, MAE is:6.68 & sMAPE is:12.55% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 11.00% & 1.13\n",
      "for 2019-01-09, MAE is:3.83 & sMAPE is:7.67% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 10.63% & 1.11\n",
      "for 2019-01-10, MAE is:6.43 & sMAPE is:9.85% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 10.55% & 1.08\n",
      "for 2019-01-11, MAE is:5.37 & sMAPE is:7.78% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 10.30% & 1.16\n",
      "for 2019-01-12, MAE is:5.46 & sMAPE is:9.76% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 10.26% & 1.11\n",
      "for 2019-01-13, MAE is:8.23 & sMAPE is:18.28% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 10.87% & 1.09\n",
      "for 2019-01-14, MAE is:5.25 & sMAPE is:11.38% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 10.91% & 1.07\n",
      "for 2019-01-15, MAE is:3.45 & sMAPE is:5.95% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 10.58% & 1.05\n",
      "for 2019-01-16, MAE is:5.81 & sMAPE is:9.80% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 10.53% & 1.04\n",
      "for 2019-01-17, MAE is:5.83 & sMAPE is:11.05% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 10.56% & 1.02\n",
      "for 2019-01-18, MAE is:5.40 & sMAPE is:8.77% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 10.46% & 1.10\n",
      "for 2019-01-19, MAE is:7.47 & sMAPE is:12.79% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 10.58% & 1.08\n",
      "for 2019-01-20, MAE is:5.51 & sMAPE is:9.68% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 10.54% & 1.04\n",
      "for 2019-01-21, MAE is:6.41 & sMAPE is:9.11% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 10.47% & 1.01\n",
      "for 2019-01-22, MAE is:6.07 & sMAPE is:8.32% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 10.37% & 0.99\n",
      "for 2019-01-23, MAE is:9.13 & sMAPE is:12.04% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 10.45% & 0.98\n",
      "for 2019-01-24, MAE is:17.34 & sMAPE is:21.07% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 10.89% & 0.97\n",
      "for 2019-01-25, MAE is:13.09 & sMAPE is:17.32% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 11.15% & 1.03\n",
      "for 2019-01-26, MAE is:6.42 & sMAPE is:11.84% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 11.17% & 1.01\n",
      "for 2019-01-27, MAE is:4.83 & sMAPE is:13.75% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 11.27% & 0.98\n",
      "for 2019-01-28, MAE is:8.19 & sMAPE is:18.85% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 11.54% & 0.97\n",
      "for 2019-01-29, MAE is:4.64 & sMAPE is:7.35% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 11.39% & 0.95\n",
      "for 2019-01-30, MAE is:4.28 & sMAPE is:7.82% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 11.28% & 0.93\n",
      "for 2019-01-31, MAE is:6.89 & sMAPE is:11.98% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 11.30% & 0.91\n",
      "for 2019-02-01, MAE is:9.15 & sMAPE is:16.28% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 11.45% & 0.91\n",
      "for 2019-02-02, MAE is:5.84 & sMAPE is:11.11% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 11.44% & 0.92\n",
      "for 2019-02-03, MAE is:7.36 & sMAPE is:16.65% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 11.60% & 0.92\n",
      "for 2019-02-04, MAE is:6.64 & sMAPE is:10.95% & rMAE is:2.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 11.58% & 0.97\n",
      "for 2019-02-05, MAE is:5.16 & sMAPE is:9.18% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 11.51% & 0.97\n",
      "for 2019-02-06, MAE is:6.33 & sMAPE is:13.05% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 11.55% & 0.98\n",
      "for 2019-02-07, MAE is:3.53 & sMAPE is:7.55% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 11.45% & 0.96\n",
      "for 2019-02-08, MAE is:4.69 & sMAPE is:10.28% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 11.42% & 0.94\n",
      "for 2019-02-09, MAE is:4.87 & sMAPE is:14.61% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 11.50% & 0.93\n",
      "for 2019-02-10, MAE is:4.51 & sMAPE is:14.49% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 11.57% & 0.91\n",
      "for 2019-02-11, MAE is:7.29 & sMAPE is:17.93% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 11.72% & 0.91\n",
      "for 2019-02-12, MAE is:4.69 & sMAPE is:8.73% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 11.65% & 0.90\n",
      "for 2019-02-13, MAE is:6.04 & sMAPE is:12.94% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 11.68% & 0.92\n",
      "for 2019-02-14, MAE is:5.95 & sMAPE is:12.56% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 11.70% & 0.94\n",
      "for 2019-02-15, MAE is:4.93 & sMAPE is:10.33% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 11.67% & 0.95\n",
      "for 2019-02-16, MAE is:5.92 & sMAPE is:14.15% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 11.72% & 0.94\n",
      "for 2019-02-17, MAE is:7.15 & sMAPE is:20.16% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 11.90% & 0.94\n",
      "for 2019-02-18, MAE is:7.14 & sMAPE is:17.39% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 12.01% & 0.93\n",
      "for 2019-02-19, MAE is:15.31 & sMAPE is:26.60% & rMAE is:3.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 12.30% & 0.98\n",
      "for 2019-02-20, MAE is:4.90 & sMAPE is:10.19% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 12.26% & 0.99\n",
      "for 2019-02-21, MAE is:7.59 & sMAPE is:17.55% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 12.36% & 1.01\n",
      "for 2019-02-22, MAE is:5.52 & sMAPE is:12.54% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 12.37% & 1.03\n",
      "for 2019-02-23, MAE is:4.13 & sMAPE is:10.35% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 12.33% & 1.03\n",
      "for 2019-02-24, MAE is:4.22 & sMAPE is:11.16% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 12.31% & 1.04\n",
      "for 2019-02-25, MAE is:10.98 & sMAPE is:21.95% & rMAE is:4.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 12.48% & 1.10\n",
      "for 2019-02-26, MAE is:6.32 & sMAPE is:15.37% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 12.53% & 1.11\n",
      "for 2019-02-27, MAE is:6.81 & sMAPE is:17.02% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 12.61% & 1.12\n",
      "for 2019-02-28, MAE is:4.94 & sMAPE is:12.05% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 12.60% & 1.11\n",
      "for 2019-03-01, MAE is:8.14 & sMAPE is:21.18% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 12.74% & 1.13\n",
      "for 2019-03-02, MAE is:6.42 & sMAPE is:16.52% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 12.80% & 1.13\n",
      "for 2019-03-03, MAE is:6.72 & sMAPE is:37.09% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 13.20% & 1.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-04, MAE is:9.28 & sMAPE is:34.48% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 13.53% & 1.11\n",
      "for 2019-03-05, MAE is:4.82 & sMAPE is:12.35% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 13.52% & 1.11\n",
      "for 2019-03-06, MAE is:5.39 & sMAPE is:16.32% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 13.56% & 1.10\n",
      "for 2019-03-07, MAE is:6.19 & sMAPE is:18.91% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 13.64% & 1.10\n",
      "for 2019-03-08, MAE is:4.54 & sMAPE is:12.20% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 13.62% & 1.09\n",
      "for 2019-03-09, MAE is:12.93 & sMAPE is:45.85% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 14.09% & 1.09\n",
      "for 2019-03-10, MAE is:9.87 & sMAPE is:46.10% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 14.56% & 1.11\n",
      "for 2019-03-11, MAE is:6.53 & sMAPE is:22.65% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 14.67% & 1.11\n",
      "for 2019-03-12, MAE is:8.75 & sMAPE is:22.24% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 14.78% & 1.11\n",
      "for 2019-03-13, MAE is:8.42 & sMAPE is:26.51% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 14.94% & 1.11\n",
      "for 2019-03-14, MAE is:4.59 & sMAPE is:14.76% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 14.94% & 1.11\n",
      "for 2019-03-15, MAE is:8.34 & sMAPE is:27.42% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 15.11% & 1.10\n",
      "for 2019-03-16, MAE is:5.97 & sMAPE is:33.18% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 15.35% & 1.10\n",
      "for 2019-03-17, MAE is:10.05 & sMAPE is:104.45% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.52% & 1.10\n",
      "for 2019-03-18, MAE is:7.98 & sMAPE is:26.07% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 16.64% & 1.11\n",
      "for 2019-03-19, MAE is:6.90 & sMAPE is:17.46% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 16.66% & 1.11\n",
      "for 2019-03-20, MAE is:5.31 & sMAPE is:13.19% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.61% & 1.10\n",
      "for 2019-03-21, MAE is:5.10 & sMAPE is:13.05% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 16.57% & 1.10\n",
      "for 2019-03-22, MAE is:6.46 & sMAPE is:17.13% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 16.57% & 1.09\n",
      "for 2019-03-23, MAE is:4.22 & sMAPE is:12.47% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 16.52% & 1.08\n",
      "for 2019-03-24, MAE is:7.27 & sMAPE is:24.47% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 16.62% & 1.07\n",
      "for 2019-03-25, MAE is:4.82 & sMAPE is:14.39% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 16.59% & 1.07\n",
      "for 2019-03-26, MAE is:5.25 & sMAPE is:15.46% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 16.58% & 1.07\n",
      "for 2019-03-27, MAE is:6.45 & sMAPE is:18.04% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 16.60% & 1.08\n",
      "for 2019-03-28, MAE is:8.62 & sMAPE is:23.63% & rMAE is:3.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 16.68% & 1.11\n",
      "for 2019-03-29, MAE is:5.36 & sMAPE is:14.03% & rMAE is:2.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 16.65% & 1.13\n",
      "for 2019-03-30, MAE is:3.92 & sMAPE is:11.95% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 16.59% & 1.13\n",
      "for 2019-03-31, MAE is:9.24 & sMAPE is:49.09% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 16.96% & 1.13\n",
      "for 2019-04-01, MAE is:5.38 & sMAPE is:15.31% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.94% & 1.14\n",
      "for 2019-04-02, MAE is:3.74 & sMAPE is:10.82% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 16.87% & 1.14\n",
      "for 2019-04-03, MAE is:6.07 & sMAPE is:15.34% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 16.85% & 1.14\n",
      "for 2019-04-04, MAE is:3.82 & sMAPE is:8.83% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 16.77% & 1.14\n",
      "for 2019-04-05, MAE is:8.36 & sMAPE is:20.93% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 16.81% & 1.15\n",
      "for 2019-04-06, MAE is:5.75 & sMAPE is:15.98% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 16.80% & 1.15\n",
      "for 2019-04-07, MAE is:11.63 & sMAPE is:36.79% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.01% & 1.14\n",
      "for 2019-04-08, MAE is:4.85 & sMAPE is:10.81% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 16.95% & 1.14\n",
      "for 2019-04-09, MAE is:3.48 & sMAPE is:8.33% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 16.86% & 1.13\n",
      "for 2019-04-10, MAE is:6.92 & sMAPE is:17.03% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 16.86% & 1.14\n",
      "for 2019-04-11, MAE is:7.01 & sMAPE is:17.20% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 16.87% & 1.15\n",
      "for 2019-04-12, MAE is:4.55 & sMAPE is:10.84% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 16.81% & 1.16\n",
      "for 2019-04-13, MAE is:6.58 & sMAPE is:16.85% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 16.81% & 1.16\n",
      "for 2019-04-14, MAE is:4.54 & sMAPE is:11.05% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.75% & 1.16\n",
      "for 2019-04-15, MAE is:6.54 & sMAPE is:14.36% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.73% & 1.17\n",
      "for 2019-04-16, MAE is:3.29 & sMAPE is:7.84% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.64% & 1.17\n",
      "for 2019-04-17, MAE is:5.12 & sMAPE is:11.94% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.60% & 1.18\n",
      "for 2019-04-18, MAE is:6.94 & sMAPE is:18.09% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.61% & 1.18\n",
      "for 2019-04-19, MAE is:5.01 & sMAPE is:13.75% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 16.59% & 1.18\n",
      "for 2019-04-20, MAE is:3.15 & sMAPE is:10.59% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 16.53% & 1.17\n",
      "for 2019-04-21, MAE is:7.82 & sMAPE is:31.99% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 16.67% & 1.17\n",
      "for 2019-04-22, MAE is:21.49 & sMAPE is:107.84% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 17.49% & 1.16\n",
      "for 2019-04-23, MAE is:7.59 & sMAPE is:41.34% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.70% & 1.16\n",
      "for 2019-04-24, MAE is:3.66 & sMAPE is:11.44% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 17.64% & 1.15\n",
      "for 2019-04-25, MAE is:5.55 & sMAPE is:29.27% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.74% & 1.14\n",
      "for 2019-04-26, MAE is:6.19 & sMAPE is:16.52% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.73% & 1.14\n",
      "for 2019-04-27, MAE is:7.71 & sMAPE is:32.07% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 17.86% & 1.14\n",
      "for 2019-04-28, MAE is:7.81 & sMAPE is:28.79% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.95% & 1.14\n",
      "for 2019-04-29, MAE is:5.55 & sMAPE is:14.76% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 17.92% & 1.14\n",
      "for 2019-04-30, MAE is:8.65 & sMAPE is:22.04% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 17.96% & 1.13\n",
      "for 2019-05-01, MAE is:5.93 & sMAPE is:24.00% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 18.01% & 1.13\n",
      "for 2019-05-02, MAE is:3.80 & sMAPE is:9.79% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.94% & 1.12\n",
      "for 2019-05-03, MAE is:2.92 & sMAPE is:7.63% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 17.86% & 1.12\n",
      "for 2019-05-04, MAE is:2.51 & sMAPE is:6.82% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 17.77% & 1.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-05, MAE is:3.28 & sMAPE is:11.34% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 17.72% & 1.11\n",
      "for 2019-05-06, MAE is:5.09 & sMAPE is:12.67% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 17.67% & 1.11\n",
      "for 2019-05-07, MAE is:7.39 & sMAPE is:15.81% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 17.66% & 1.11\n",
      "for 2019-05-08, MAE is:4.15 & sMAPE is:11.28% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 17.61% & 1.11\n",
      "for 2019-05-09, MAE is:8.17 & sMAPE is:20.46% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 17.63% & 1.11\n",
      "for 2019-05-10, MAE is:4.77 & sMAPE is:10.59% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 17.58% & 1.11\n",
      "for 2019-05-11, MAE is:4.82 & sMAPE is:14.17% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 17.55% & 1.11\n",
      "for 2019-05-12, MAE is:8.56 & sMAPE is:44.07% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 17.75% & 1.11\n",
      "for 2019-05-13, MAE is:6.45 & sMAPE is:17.55% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 17.75% & 1.10\n",
      "for 2019-05-14, MAE is:6.06 & sMAPE is:15.73% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 17.74% & 1.10\n",
      "for 2019-05-15, MAE is:4.88 & sMAPE is:12.72% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 17.70% & 1.10\n",
      "for 2019-05-16, MAE is:3.14 & sMAPE is:8.49% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 17.63% & 1.10\n",
      "for 2019-05-17, MAE is:3.42 & sMAPE is:8.67% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 17.57% & 1.10\n",
      "for 2019-05-18, MAE is:2.65 & sMAPE is:7.38% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 17.49% & 1.09\n",
      "for 2019-05-19, MAE is:4.59 & sMAPE is:14.51% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 17.47% & 1.09\n",
      "for 2019-05-20, MAE is:5.59 & sMAPE is:12.92% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 17.44% & 1.09\n",
      "for 2019-05-21, MAE is:3.28 & sMAPE is:7.68% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 17.37% & 1.08\n",
      "for 2019-05-22, MAE is:3.48 & sMAPE is:8.83% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 17.31% & 1.08\n",
      "for 2019-05-23, MAE is:5.21 & sMAPE is:12.66% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 17.28% & 1.08\n",
      "for 2019-05-24, MAE is:3.96 & sMAPE is:9.85% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 17.23% & 1.08\n",
      "for 2019-05-25, MAE is:4.20 & sMAPE is:12.38% & rMAE is:4.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 17.19% & 1.10\n",
      "for 2019-05-26, MAE is:10.24 & sMAPE is:51.43% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 17.43% & 1.10\n",
      "for 2019-05-27, MAE is:5.10 & sMAPE is:18.11% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 17.43% & 1.10\n",
      "for 2019-05-28, MAE is:3.31 & sMAPE is:9.87% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 17.38% & 1.09\n",
      "for 2019-05-29, MAE is:6.27 & sMAPE is:18.23% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 17.39% & 1.10\n",
      "for 2019-05-30, MAE is:11.06 & sMAPE is:56.29% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 17.64% & 1.09\n",
      "for 2019-05-31, MAE is:3.64 & sMAPE is:11.27% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 17.60% & 1.09\n",
      "for 2019-06-01, MAE is:5.01 & sMAPE is:17.01% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 17.60% & 1.09\n",
      "for 2019-06-02, MAE is:9.84 & sMAPE is:60.25% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 17.88% & 1.09\n",
      "for 2019-06-03, MAE is:4.65 & sMAPE is:14.54% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 17.86% & 1.09\n",
      "for 2019-06-04, MAE is:3.13 & sMAPE is:8.58% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 17.80% & 1.09\n",
      "for 2019-06-05, MAE is:4.79 & sMAPE is:14.23% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 17.77% & 1.09\n",
      "for 2019-06-06, MAE is:4.16 & sMAPE is:12.08% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 17.74% & 1.09\n",
      "for 2019-06-07, MAE is:6.44 & sMAPE is:27.26% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 17.80% & 1.09\n",
      "for 2019-06-08, MAE is:6.90 & sMAPE is:77.74% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 18.17% & 1.08\n",
      "for 2019-06-09, MAE is:7.07 & sMAPE is:32.72% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 18.26% & 1.08\n",
      "for 2019-06-10, MAE is:4.41 & sMAPE is:16.26% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 18.25% & 1.08\n",
      "for 2019-06-11, MAE is:3.18 & sMAPE is:8.35% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 18.19% & 1.07\n",
      "for 2019-06-12, MAE is:4.42 & sMAPE is:11.80% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 18.15% & 1.07\n",
      "for 2019-06-13, MAE is:7.74 & sMAPE is:22.97% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 18.18% & 1.08\n",
      "for 2019-06-14, MAE is:5.65 & sMAPE is:16.07% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 18.17% & 1.08\n",
      "for 2019-06-15, MAE is:4.70 & sMAPE is:15.68% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 18.15% & 1.07\n",
      "for 2019-06-16, MAE is:4.53 & sMAPE is:20.90% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 18.17% & 1.07\n",
      "for 2019-06-17, MAE is:3.85 & sMAPE is:12.35% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 18.14% & 1.07\n",
      "for 2019-06-18, MAE is:3.20 & sMAPE is:10.85% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 18.09% & 1.06\n",
      "for 2019-06-19, MAE is:3.66 & sMAPE is:11.45% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 18.05% & 1.06\n",
      "for 2019-06-20, MAE is:2.60 & sMAPE is:7.51% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 17.99% & 1.06\n",
      "for 2019-06-21, MAE is:3.46 & sMAPE is:10.63% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 17.95% & 1.06\n",
      "for 2019-06-22, MAE is:4.29 & sMAPE is:18.59% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 17.95% & 1.06\n",
      "for 2019-06-23, MAE is:9.71 & sMAPE is:83.81% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 18.33% & 1.06\n",
      "for 2019-06-24, MAE is:5.74 & sMAPE is:17.94% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 18.33% & 1.06\n",
      "for 2019-06-25, MAE is:3.97 & sMAPE is:12.81% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 18.30% & 1.06\n",
      "for 2019-06-26, MAE is:5.24 & sMAPE is:17.65% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 18.29% & 1.06\n",
      "for 2019-06-27, MAE is:4.69 & sMAPE is:15.42% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 18.28% & 1.06\n",
      "for 2019-06-28, MAE is:4.31 & sMAPE is:13.17% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 18.25% & 1.06\n",
      "for 2019-06-29, MAE is:4.89 & sMAPE is:15.93% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 18.24% & 1.06\n",
      "for 2019-06-30, MAE is:7.64 & sMAPE is:51.42% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 18.42% & 1.06\n",
      "for 2019-07-01, MAE is:7.83 & sMAPE is:23.51% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 18.45% & 1.06\n",
      "for 2019-07-02, MAE is:2.24 & sMAPE is:7.01% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 18.38% & 1.06\n",
      "for 2019-07-03, MAE is:2.91 & sMAPE is:9.10% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 18.33% & 1.06\n",
      "for 2019-07-04, MAE is:3.28 & sMAPE is:10.62% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 18.29% & 1.06\n",
      "for 2019-07-05, MAE is:3.25 & sMAPE is:9.93% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 18.25% & 1.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-06, MAE is:2.43 & sMAPE is:8.04% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 18.19% & 1.06\n",
      "for 2019-07-07, MAE is:3.61 & sMAPE is:16.62% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 18.18% & 1.05\n",
      "for 2019-07-08, MAE is:2.33 & sMAPE is:6.85% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 18.12% & 1.05\n",
      "for 2019-07-09, MAE is:3.17 & sMAPE is:9.23% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 18.08% & 1.05\n",
      "for 2019-07-10, MAE is:6.30 & sMAPE is:16.72% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 18.07% & 1.05\n",
      "for 2019-07-11, MAE is:6.80 & sMAPE is:16.31% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 18.06% & 1.05\n",
      "for 2019-07-12, MAE is:3.07 & sMAPE is:7.32% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 18.01% & 1.04\n",
      "for 2019-07-13, MAE is:3.33 & sMAPE is:9.75% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 17.96% & 1.04\n",
      "for 2019-07-14, MAE is:5.92 & sMAPE is:20.74% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 17.98% & 1.04\n",
      "for 2019-07-15, MAE is:2.61 & sMAPE is:7.01% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 17.92% & 1.04\n",
      "for 2019-07-16, MAE is:5.64 & sMAPE is:14.51% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 17.90% & 1.04\n",
      "for 2019-07-17, MAE is:3.95 & sMAPE is:9.51% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 17.86% & 1.04\n",
      "for 2019-07-18, MAE is:3.51 & sMAPE is:8.26% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 17.81% & 1.03\n",
      "for 2019-07-19, MAE is:3.26 & sMAPE is:7.87% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 17.76% & 1.03\n",
      "for 2019-07-20, MAE is:4.83 & sMAPE is:13.79% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 17.74% & 1.04\n",
      "for 2019-07-21, MAE is:5.84 & sMAPE is:20.39% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 17.76% & 1.04\n",
      "for 2019-07-22, MAE is:2.91 & sMAPE is:7.13% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 17.71% & 1.04\n",
      "for 2019-07-23, MAE is:5.45 & sMAPE is:12.31% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 17.68% & 1.04\n",
      "for 2019-07-24, MAE is:9.49 & sMAPE is:18.78% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 17.68% & 1.04\n",
      "for 2019-07-25, MAE is:4.59 & sMAPE is:8.90% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 17.64% & 1.04\n",
      "for 2019-07-26, MAE is:2.79 & sMAPE is:6.27% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 17.59% & 1.04\n",
      "for 2019-07-27, MAE is:3.87 & sMAPE is:10.88% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 17.55% & 1.03\n",
      "for 2019-07-28, MAE is:2.69 & sMAPE is:9.11% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 17.51% & 1.03\n",
      "for 2019-07-29, MAE is:4.10 & sMAPE is:10.40% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 17.48% & 1.03\n",
      "for 2019-07-30, MAE is:6.53 & sMAPE is:19.38% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 17.49% & 1.03\n",
      "for 2019-07-31, MAE is:3.49 & sMAPE is:11.18% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 17.46% & 1.03\n",
      "for 2019-08-01, MAE is:4.75 & sMAPE is:12.33% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 17.44% & 1.03\n",
      "for 2019-08-02, MAE is:2.43 & sMAPE is:6.02% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 17.38% & 1.02\n",
      "for 2019-08-03, MAE is:2.36 & sMAPE is:7.03% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 17.33% & 1.02\n",
      "for 2019-08-04, MAE is:3.96 & sMAPE is:12.31% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 17.31% & 1.02\n",
      "for 2019-08-05, MAE is:3.87 & sMAPE is:11.27% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 17.28% & 1.02\n",
      "for 2019-08-06, MAE is:3.62 & sMAPE is:9.29% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 17.25% & 1.02\n",
      "for 2019-08-07, MAE is:2.92 & sMAPE is:8.16% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 17.20% & 1.02\n",
      "for 2019-08-08, MAE is:3.86 & sMAPE is:11.21% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 17.18% & 1.01\n",
      "for 2019-08-09, MAE is:4.06 & sMAPE is:14.50% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 17.17% & 1.01\n",
      "for 2019-08-10, MAE is:6.76 & sMAPE is:47.37% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 17.30% & 1.01\n",
      "for 2019-08-11, MAE is:4.84 & sMAPE is:29.46% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 17.36% & 1.00\n",
      "for 2019-08-12, MAE is:2.84 & sMAPE is:9.72% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 17.32% & 1.00\n",
      "for 2019-08-13, MAE is:7.98 & sMAPE is:27.90% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 17.37% & 1.00\n",
      "for 2019-08-14, MAE is:2.99 & sMAPE is:9.82% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 17.34% & 1.00\n",
      "for 2019-08-15, MAE is:2.90 & sMAPE is:13.78% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 17.32% & 1.00\n",
      "for 2019-08-16, MAE is:4.48 & sMAPE is:14.30% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 17.31% & 1.00\n",
      "for 2019-08-17, MAE is:4.94 & sMAPE is:22.41% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 17.33% & 1.00\n",
      "for 2019-08-18, MAE is:5.23 & sMAPE is:25.44% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 17.36% & 1.00\n",
      "for 2019-08-19, MAE is:3.62 & sMAPE is:11.84% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 17.34% & 1.00\n",
      "for 2019-08-20, MAE is:1.69 & sMAPE is:4.98% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 17.29% & 1.00\n",
      "for 2019-08-21, MAE is:2.84 & sMAPE is:8.16% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 17.25% & 1.00\n",
      "for 2019-08-22, MAE is:3.54 & sMAPE is:10.46% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 17.22% & 0.99\n",
      "for 2019-08-23, MAE is:4.61 & sMAPE is:13.63% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 17.20% & 1.00\n",
      "for 2019-08-24, MAE is:3.84 & sMAPE is:12.83% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 17.18% & 1.00\n",
      "for 2019-08-25, MAE is:3.43 & sMAPE is:13.08% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 17.17% & 1.00\n",
      "for 2019-08-26, MAE is:3.73 & sMAPE is:9.75% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 17.14% & 0.99\n",
      "for 2019-08-27, MAE is:5.01 & sMAPE is:11.42% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 17.11% & 0.99\n",
      "for 2019-08-28, MAE is:5.79 & sMAPE is:12.50% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 17.09% & 0.99\n",
      "for 2019-08-29, MAE is:4.20 & sMAPE is:9.97% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 17.06% & 0.99\n",
      "for 2019-08-30, MAE is:5.55 & sMAPE is:13.86% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 17.05% & 0.98\n",
      "for 2019-08-31, MAE is:3.90 & sMAPE is:11.89% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 17.03% & 0.99\n",
      "for 2019-09-01, MAE is:3.98 & sMAPE is:14.72% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 17.02% & 0.99\n",
      "for 2019-09-02, MAE is:3.73 & sMAPE is:9.97% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 16.99% & 0.99\n",
      "for 2019-09-03, MAE is:4.29 & sMAPE is:11.82% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 16.97% & 0.99\n",
      "for 2019-09-04, MAE is:5.72 & sMAPE is:16.56% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 16.97% & 0.99\n",
      "for 2019-09-05, MAE is:3.02 & sMAPE is:9.51% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 16.94% & 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-06, MAE is:3.72 & sMAPE is:11.74% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 16.92% & 0.98\n",
      "for 2019-09-07, MAE is:4.46 & sMAPE is:15.02% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 16.91% & 0.98\n",
      "for 2019-09-08, MAE is:3.62 & sMAPE is:12.15% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 16.89% & 0.98\n",
      "for 2019-09-09, MAE is:5.23 & sMAPE is:13.04% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 16.88% & 0.98\n",
      "for 2019-09-10, MAE is:4.41 & sMAPE is:11.81% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 16.86% & 0.98\n",
      "for 2019-09-11, MAE is:3.91 & sMAPE is:11.98% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.84% & 0.99\n",
      "for 2019-09-12, MAE is:4.20 & sMAPE is:11.86% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.82% & 0.99\n",
      "for 2019-09-13, MAE is:4.11 & sMAPE is:10.94% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.79% & 0.99\n",
      "for 2019-09-14, MAE is:3.93 & sMAPE is:11.54% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.77% & 0.99\n",
      "for 2019-09-15, MAE is:6.93 & sMAPE is:25.88% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.81% & 0.99\n",
      "for 2019-09-16, MAE is:6.66 & sMAPE is:15.17% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.80% & 0.99\n",
      "for 2019-09-17, MAE is:3.96 & sMAPE is:9.44% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.77% & 0.99\n",
      "for 2019-09-18, MAE is:5.13 & sMAPE is:13.44% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.76% & 0.99\n",
      "for 2019-09-19, MAE is:7.15 & sMAPE is:17.73% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.76% & 0.99\n",
      "for 2019-09-20, MAE is:5.54 & sMAPE is:14.27% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.76% & 0.99\n",
      "for 2019-09-21, MAE is:4.24 & sMAPE is:15.22% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.75% & 0.99\n",
      "for 2019-09-22, MAE is:4.14 & sMAPE is:15.90% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.75% & 0.99\n",
      "for 2019-09-23, MAE is:3.57 & sMAPE is:9.42% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.72% & 0.99\n",
      "for 2019-09-24, MAE is:3.38 & sMAPE is:9.51% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.69% & 0.99\n",
      "for 2019-09-25, MAE is:2.50 & sMAPE is:7.35% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 16.66% & 0.99\n",
      "for 2019-09-26, MAE is:4.33 & sMAPE is:11.73% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 16.64% & 0.99\n",
      "for 2019-09-27, MAE is:5.43 & sMAPE is:15.36% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 16.63% & 0.99\n",
      "for 2019-09-28, MAE is:4.41 & sMAPE is:16.68% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 16.63% & 0.99\n",
      "for 2019-09-29, MAE is:13.02 & sMAPE is:60.51% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.80% & 0.99\n",
      "for 2019-09-30, MAE is:11.40 & sMAPE is:39.43% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.88% & 0.99\n",
      "for 2019-10-01, MAE is:4.41 & sMAPE is:12.65% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.86% & 1.00\n",
      "for 2019-10-02, MAE is:4.07 & sMAPE is:12.30% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.85% & 1.00\n",
      "for 2019-10-03, MAE is:4.86 & sMAPE is:12.37% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.83% & 1.00\n",
      "for 2019-10-04, MAE is:6.59 & sMAPE is:19.50% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.84% & 1.00\n",
      "for 2019-10-05, MAE is:3.51 & sMAPE is:9.55% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.81% & 1.00\n",
      "for 2019-10-06, MAE is:3.15 & sMAPE is:9.53% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.79% & 1.00\n",
      "for 2019-10-07, MAE is:7.12 & sMAPE is:19.71% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.80% & 1.00\n",
      "for 2019-10-08, MAE is:3.47 & sMAPE is:9.56% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.77% & 1.00\n",
      "for 2019-10-09, MAE is:4.66 & sMAPE is:13.35% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.76% & 1.00\n",
      "for 2019-10-10, MAE is:4.75 & sMAPE is:14.11% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.75% & 1.00\n",
      "for 2019-10-11, MAE is:6.79 & sMAPE is:23.86% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.78% & 0.99\n",
      "for 2019-10-12, MAE is:5.78 & sMAPE is:27.38% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.81% & 0.99\n",
      "for 2019-10-13, MAE is:7.76 & sMAPE is:42.87% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.90% & 0.99\n",
      "for 2019-10-14, MAE is:5.83 & sMAPE is:18.44% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.91% & 0.99\n",
      "for 2019-10-15, MAE is:9.68 & sMAPE is:25.01% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.94% & 0.99\n",
      "for 2019-10-16, MAE is:4.58 & sMAPE is:12.10% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.92% & 0.99\n",
      "for 2019-10-17, MAE is:8.01 & sMAPE is:18.87% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.93% & 0.99\n",
      "for 2019-10-18, MAE is:3.46 & sMAPE is:9.24% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.90% & 0.99\n",
      "for 2019-10-19, MAE is:3.81 & sMAPE is:11.05% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.88% & 0.99\n",
      "for 2019-10-20, MAE is:5.64 & sMAPE is:17.02% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.88% & 0.99\n",
      "for 2019-10-21, MAE is:4.50 & sMAPE is:10.68% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.86% & 0.99\n",
      "for 2019-10-22, MAE is:4.72 & sMAPE is:10.44% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.84% & 0.99\n",
      "for 2019-10-23, MAE is:4.88 & sMAPE is:11.11% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.82% & 0.99\n",
      "for 2019-10-24, MAE is:4.92 & sMAPE is:12.64% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.81% & 0.99\n",
      "for 2019-10-25, MAE is:4.08 & sMAPE is:10.92% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.79% & 0.99\n",
      "for 2019-10-26, MAE is:6.62 & sMAPE is:23.82% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.81% & 0.99\n",
      "for 2019-10-27, MAE is:9.48 & sMAPE is:33.87% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.87% & 0.99\n",
      "for 2019-10-28, MAE is:4.90 & sMAPE is:11.01% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.85% & 0.99\n",
      "for 2019-10-29, MAE is:5.13 & sMAPE is:10.74% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.83% & 0.99\n",
      "for 2019-10-30, MAE is:8.75 & sMAPE is:19.06% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.83% & 1.00\n",
      "for 2019-10-31, MAE is:4.71 & sMAPE is:10.31% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.81% & 0.99\n",
      "for 2019-11-01, MAE is:6.28 & sMAPE is:17.89% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.82% & 0.99\n",
      "for 2019-11-02, MAE is:4.51 & sMAPE is:14.99% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.81% & 1.00\n",
      "for 2019-11-03, MAE is:5.66 & sMAPE is:25.74% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.84% & 1.00\n",
      "for 2019-11-04, MAE is:5.41 & sMAPE is:16.56% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.84% & 0.99\n",
      "for 2019-11-05, MAE is:5.28 & sMAPE is:13.13% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.83% & 0.99\n",
      "for 2019-11-06, MAE is:8.69 & sMAPE is:16.98% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.83% & 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-07, MAE is:4.93 & sMAPE is:10.82% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.81% & 1.00\n",
      "for 2019-11-08, MAE is:7.68 & sMAPE is:16.23% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 16.81% & 1.00\n",
      "for 2019-11-09, MAE is:4.42 & sMAPE is:10.04% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.78% & 1.00\n",
      "for 2019-11-10, MAE is:4.69 & sMAPE is:12.18% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.77% & 1.00\n",
      "for 2019-11-11, MAE is:2.55 & sMAPE is:5.96% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.73% & 0.99\n",
      "for 2019-11-12, MAE is:3.40 & sMAPE is:7.37% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.70% & 0.99\n",
      "for 2019-11-13, MAE is:6.26 & sMAPE is:11.18% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.69% & 0.99\n",
      "for 2019-11-14, MAE is:5.13 & sMAPE is:9.69% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.67% & 0.99\n",
      "for 2019-11-15, MAE is:5.92 & sMAPE is:10.10% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.64% & 0.99\n",
      "for 2019-11-16, MAE is:2.90 & sMAPE is:6.06% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.61% & 0.99\n",
      "for 2019-11-17, MAE is:2.23 & sMAPE is:5.10% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.58% & 0.99\n",
      "for 2019-11-18, MAE is:5.75 & sMAPE is:10.43% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.56% & 0.99\n",
      "for 2019-11-19, MAE is:6.42 & sMAPE is:10.08% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.54% & 0.98\n",
      "for 2019-11-20, MAE is:5.65 & sMAPE is:9.19% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.51% & 0.99\n",
      "for 2019-11-21, MAE is:4.68 & sMAPE is:8.47% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.49% & 0.98\n",
      "for 2019-11-22, MAE is:5.66 & sMAPE is:11.09% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.47% & 0.98\n",
      "for 2019-11-23, MAE is:4.52 & sMAPE is:11.07% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.46% & 0.98\n",
      "for 2019-11-24, MAE is:2.53 & sMAPE is:6.06% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 16.42% & 0.98\n",
      "for 2019-11-25, MAE is:5.30 & sMAPE is:10.87% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 16.41% & 0.98\n",
      "for 2019-11-26, MAE is:4.17 & sMAPE is:9.03% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 16.39% & 0.98\n",
      "for 2019-11-27, MAE is:3.93 & sMAPE is:9.50% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 16.36% & 0.98\n",
      "for 2019-11-28, MAE is:5.74 & sMAPE is:16.78% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 16.37% & 0.98\n",
      "for 2019-11-29, MAE is:3.66 & sMAPE is:8.39% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 16.34% & 0.98\n",
      "for 2019-11-30, MAE is:3.40 & sMAPE is:7.57% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 16.32% & 0.98\n",
      "for 2019-12-01, MAE is:3.03 & sMAPE is:7.28% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 16.29% & 0.98\n",
      "for 2019-12-02, MAE is:6.30 & sMAPE is:11.79% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 16.28% & 0.98\n",
      "for 2019-12-03, MAE is:5.32 & sMAPE is:9.37% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 16.25% & 0.98\n",
      "for 2019-12-04, MAE is:7.26 & sMAPE is:11.91% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 16.24% & 0.98\n",
      "for 2019-12-05, MAE is:7.05 & sMAPE is:11.69% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 16.23% & 0.98\n",
      "for 2019-12-06, MAE is:4.14 & sMAPE is:8.09% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 16.20% & 0.98\n",
      "for 2019-12-07, MAE is:5.29 & sMAPE is:12.37% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 16.19% & 0.98\n",
      "for 2019-12-08, MAE is:8.88 & sMAPE is:30.70% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 16.24% & 0.98\n",
      "for 2019-12-09, MAE is:4.84 & sMAPE is:26.27% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 16.26% & 0.97\n",
      "for 2019-12-10, MAE is:8.43 & sMAPE is:17.28% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 16.27% & 0.97\n",
      "for 2019-12-11, MAE is:8.37 & sMAPE is:20.35% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 16.28% & 0.97\n",
      "for 2019-12-12, MAE is:6.29 & sMAPE is:13.59% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.27% & 0.97\n",
      "for 2019-12-13, MAE is:5.90 & sMAPE is:18.02% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.28% & 0.97\n",
      "for 2019-12-14, MAE is:5.74 & sMAPE is:16.94% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.28% & 0.97\n",
      "for 2019-12-15, MAE is:7.19 & sMAPE is:35.11% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.33% & 0.97\n",
      "for 2019-12-16, MAE is:4.76 & sMAPE is:12.70% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.32% & 0.97\n",
      "for 2019-12-17, MAE is:2.70 & sMAPE is:6.59% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 16.29% & 0.97\n",
      "for 2019-12-18, MAE is:3.66 & sMAPE is:8.88% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 16.27% & 0.97\n",
      "for 2019-12-19, MAE is:7.06 & sMAPE is:37.06% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 16.33% & 0.96\n",
      "for 2019-12-20, MAE is:9.48 & sMAPE is:42.42% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 16.41% & 0.96\n",
      "for 2019-12-21, MAE is:9.67 & sMAPE is:44.02% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.48% & 0.96\n",
      "for 2019-12-22, MAE is:5.42 & sMAPE is:48.54% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.57% & 0.96\n",
      "for 2019-12-23, MAE is:6.52 & sMAPE is:45.75% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.66% & 0.96\n",
      "for 2019-12-24, MAE is:7.50 & sMAPE is:52.94% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.76% & 0.96\n",
      "for 2019-12-25, MAE is:6.47 & sMAPE is:83.27% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 16.94% & 0.96\n",
      "for 2019-12-26, MAE is:7.92 & sMAPE is:38.31% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 17.00% & 0.96\n",
      "for 2019-12-27, MAE is:2.21 & sMAPE is:6.92% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.97% & 0.96\n",
      "for 2019-12-28, MAE is:4.62 & sMAPE is:14.87% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.97% & 0.96\n",
      "for 2019-12-29, MAE is:3.87 & sMAPE is:12.71% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 16.96% & 0.95\n",
      "for 2019-12-30, MAE is:3.80 & sMAPE is:12.59% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.94% & 0.95\n",
      "for 2019-12-31, MAE is:4.40 & sMAPE is:10.24% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 16.93% & 0.95\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:35:22,990]\u001b[0m A new study created in RDB with name: FR_2020\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:35:44,949]\u001b[0m Trial 2 finished with value: 9.524181279905239 and parameters: {'n_hidden': 4, 'learning_rate': 0.008213517314019826, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08557840802756599, 'dropout_rate_Layer_2': 0.14922071277208843, 'dropout_rate_Layer_3': 0.11409302136139475, 'dropout_rate_Layer_4': 0.3931275594668149, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.005133094987162072, 'l1_Layer_2': 0.022756200004948535, 'l1_Layer_3': 0.05046092161542398, 'l1_Layer_4': 0.004255658376142762, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 170, 'n_units_Layer_4': 50}. Best is trial 2 with value: 9.524181279905239.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.52 | sMAPE for Validation Set is: 25.99% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 13.83 | sMAPE for Test Set is: 43.64% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:35:46,283]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 14.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:06,075]\u001b[0m Trial 5 finished with value: 6.4385857844752294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0361498887638824, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08695424050024912, 'dropout_rate_Layer_2': 0.2779735636945224, 'dropout_rate_Layer_3': 0.013528422890104475, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010337451573229334, 'l1_Layer_2': 2.2772842652499693e-05, 'l1_Layer_3': 5.404702405078047e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 275, 'n_units_Layer_3': 120}. Best is trial 5 with value: 6.4385857844752294.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 9.96 | sMAPE for Test Set is: 35.39% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:36:21,123]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:23,801]\u001b[0m Trial 1 finished with value: 4.942565187124789 and parameters: {'n_hidden': 3, 'learning_rate': 0.005547179083355671, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2924390310470559, 'dropout_rate_Layer_2': 0.04520785328237196, 'dropout_rate_Layer_3': 0.2851597773115548, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020484542365531737, 'l1_Layer_2': 0.006229770003407742, 'l1_Layer_3': 5.657076814300985e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 190, 'n_units_Layer_3': 300}. Best is trial 1 with value: 4.942565187124789.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 15.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.16 | sMAPE for Test Set is: 28.12% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:36:24,517]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:29,138]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:32,204]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:37,270]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:41,236]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:41,543]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:46,575]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:47,061]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 16.49% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 27.60% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:36:49,431]\u001b[0m Trial 4 finished with value: 5.276186156015379 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005372604480463084, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3354300613371455, 'dropout_rate_Layer_2': 0.1475901902277415, 'dropout_rate_Layer_3': 0.005929786208879895, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.5704836970126754e-05, 'l1_Layer_2': 5.953834260745383e-05, 'l1_Layer_3': 0.00011124753749991015, 'n_units_Layer_1': 90, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 1 with value: 4.942565187124789.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:54,184]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:54,643]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:36:56,900]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:03,542]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:03,639]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:08,902]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:09,477]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:12,386]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:15,683]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:16,762]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:17,417]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:22,007]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:22,754]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:22,829]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:26,393]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:34,064]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:34,193]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:39,437]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:41,947]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:42,491]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:47,152]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:48,269]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:49,477]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:37:58,865]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:38:01,058]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:38:17,432]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:38:21,209]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:38:25,301]\u001b[0m Trial 42 finished with value: 5.462216177976775 and parameters: {'n_hidden': 3, 'learning_rate': 0.020152581432689963, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011900711636423056, 'dropout_rate_Layer_2': 0.1425455256621941, 'dropout_rate_Layer_3': 0.3935454091890573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.05127667722549595, 'l1_Layer_2': 0.011260716991314678, 'l1_Layer_3': 0.000627229367863953, 'n_units_Layer_1': 50, 'n_units_Layer_2': 225, 'n_units_Layer_3': 225}. Best is trial 1 with value: 4.942565187124789.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 16.90% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 24.35% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:38:33,031]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:38:34,555]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:38:36,578]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:38:48,111]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:38:48,630]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:38:54,520]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:38:58,950]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:38:59,692]\u001b[0m Trial 0 finished with value: 4.867870244864424 and parameters: {'n_hidden': 3, 'learning_rate': 0.00870147824500161, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2300520573062173, 'dropout_rate_Layer_2': 0.3380236907734303, 'dropout_rate_Layer_3': 0.01452206976486461, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002052970716585816, 'l1_Layer_2': 0.08738157122632795, 'l1_Layer_3': 0.0012593730654593149, 'n_units_Layer_1': 145, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60}. Best is trial 0 with value: 4.867870244864424.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 15.46% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 24.63% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:39:06,654]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:11,898]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:15,953]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:20,945]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:25,031]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:29,309]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:30,918]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:32,208]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:32,758]\u001b[0m Trial 49 finished with value: 4.864209007053624 and parameters: {'n_hidden': 3, 'learning_rate': 0.005967163826922244, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04426569659970592, 'dropout_rate_Layer_2': 0.04223988654278337, 'dropout_rate_Layer_3': 0.16996921872403936, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037635297945437307, 'l1_Layer_2': 0.0014605749716431586, 'l1_Layer_3': 0.052340419053569884, 'n_units_Layer_1': 200, 'n_units_Layer_2': 115, 'n_units_Layer_3': 210}. Best is trial 49 with value: 4.864209007053624.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 15.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 27.94% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:39:35,259]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:40,093]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:40,929]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:42,619]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:47,098]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:50,738]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:39:57,609]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:00,716]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:03,283]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:04,808]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:08,544]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:08,680]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:14,703]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:18,079]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:18,251]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:20,067]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:29,029]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:30,429]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:30,996]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:37,308]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:37,997]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:44,075]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:44,583]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:49,013]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:52,496]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:59,104]\u001b[0m Trial 66 finished with value: 4.805807500434987 and parameters: {'n_hidden': 3, 'learning_rate': 0.010941626057498878, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2326320259254591, 'dropout_rate_Layer_2': 0.1310195800492188, 'dropout_rate_Layer_3': 0.2162860995299582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.492682348133734e-05, 'l1_Layer_2': 0.00014523244555678027, 'l1_Layer_3': 6.466681395200494e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140}. Best is trial 66 with value: 4.805807500434987.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:40:59,186]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 15.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 22.73% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:41:02,186]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:41:08,313]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:41:08,364]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:41:08,817]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:41:15,233]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:41:15,662]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:41:29,498]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:41:34,362]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:41:40,185]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:41:44,709]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:41:48,540]\u001b[0m Trial 96 finished with value: 5.468204642394402 and parameters: {'n_hidden': 3, 'learning_rate': 0.008857306495058129, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0021561838143778576, 'dropout_rate_Layer_2': 0.24610262547684564, 'dropout_rate_Layer_3': 0.3856444588748189, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00023997235591383044, 'l1_Layer_2': 0.004697010883563078, 'l1_Layer_3': 0.003410541934103416, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 215}. Best is trial 66 with value: 4.805807500434987.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:41:51,779]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:41:56,898]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:01,479]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:01,554]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:08,223]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:12,761]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:16,442]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:19,631]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:24,923]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:32,357]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:35,622]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:39,177]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:47,709]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:54,136]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:42:54,660]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:01,206]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:02,874]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:06,026]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:10,460]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:15,716]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:16,447]\u001b[0m Trial 79 finished with value: 5.25581158626457 and parameters: {'n_hidden': 3, 'learning_rate': 0.001118917112891877, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02393972643068909, 'dropout_rate_Layer_2': 0.31105501535637503, 'dropout_rate_Layer_3': 0.04964581548643263, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06292295434939549, 'l1_Layer_2': 0.03527134295488402, 'l1_Layer_3': 0.0025635035622310507, 'n_units_Layer_1': 125, 'n_units_Layer_2': 190, 'n_units_Layer_3': 120}. Best is trial 66 with value: 4.805807500434987.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 16.53% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.46 | sMAPE for Test Set is: 28.98% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:43:17,714]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:25,801]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:26,049]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:32,346]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:35,998]\u001b[0m Trial 94 finished with value: 4.7327415834725235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015154573079392962, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17529108256699563, 'dropout_rate_Layer_2': 0.09227508514227059, 'dropout_rate_Layer_3': 0.1633525229118818, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.5701260728012887e-05, 'l1_Layer_2': 0.00015276003613042257, 'l1_Layer_3': 0.0007366990495436032, 'n_units_Layer_1': 145, 'n_units_Layer_2': 120, 'n_units_Layer_3': 280}. Best is trial 94 with value: 4.7327415834725235.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:36,091]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 15.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:43:40,168]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:42,492]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:44,830]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:46,981]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:48,971]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:51,198]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:51,806]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:56,436]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:58,757]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:43:59,095]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:05,978]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:06,249]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:06,349]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:06,658]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:15,554]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:15,932]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:17,317]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:26,739]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:31,756]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:32,010]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:36,173]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:38,221]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:40,029]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:45,928]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:46,233]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:49,431]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:44:54,651]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:01,689]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:05,014]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:05,425]\u001b[0m Trial 146 finished with value: 5.419771765206335 and parameters: {'n_hidden': 3, 'learning_rate': 0.013119550075360203, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19083664053604765, 'dropout_rate_Layer_2': 0.10120906293434444, 'dropout_rate_Layer_3': 0.10738316272589839, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0008031398038901949, 'l1_Layer_2': 0.01549396468248826, 'l1_Layer_3': 0.00034612327099194703, 'n_units_Layer_1': 265, 'n_units_Layer_2': 200, 'n_units_Layer_3': 260}. Best is trial 94 with value: 4.7327415834725235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 16.77% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.00 | sMAPE for Test Set is: 30.57% | rMAE for Test Set is: 1.10\n",
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 16.72% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 21.40% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:45:08,077]\u001b[0m Trial 151 finished with value: 5.33434337840178 and parameters: {'n_hidden': 3, 'learning_rate': 0.011072109587128842, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1343769030184348, 'dropout_rate_Layer_2': 0.2558807590178437, 'dropout_rate_Layer_3': 0.3950966825738722, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015866209195944437, 'l1_Layer_2': 0.09473641323883526, 'l1_Layer_3': 0.00011255483464415451, 'n_units_Layer_1': 100, 'n_units_Layer_2': 250, 'n_units_Layer_3': 155}. Best is trial 94 with value: 4.7327415834725235.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:13,344]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:15,409]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:17,173]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:23,343]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:23,725]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:29,463]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:29,530]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:40,588]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:41,011]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:45,775]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:50,815]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:51,303]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:54,547]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:57,135]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:45:57,630]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:03,928]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:07,021]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:09,498]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:13,531]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:17,561]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:21,584]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:25,551]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:30,436]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:35,160]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:38,735]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:42,491]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:46,615]\u001b[0m Trial 176 finished with value: 5.402274052324241 and parameters: {'n_hidden': 3, 'learning_rate': 0.022999181227561484, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1532834272826983, 'dropout_rate_Layer_2': 0.0978268476383943, 'dropout_rate_Layer_3': 0.18495274315969615, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006070598092450274, 'l1_Layer_2': 0.01238646060328339, 'l1_Layer_3': 0.0592383476033328, 'n_units_Layer_1': 265, 'n_units_Layer_2': 180, 'n_units_Layer_3': 225}. Best is trial 94 with value: 4.7327415834725235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 16.71% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 25.66% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:46:53,868]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:55,732]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:46:56,122]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:01,556]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:01,769]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:08,399]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:09,062]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:11,909]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:15,223]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:16,470]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:22,514]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:22,783]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:27,313]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:30,349]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:30,530]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:32,694]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:38,966]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:39,158]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:39,706]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:45,562]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:46,126]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:49,233]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:52,503]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:52,699]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:47:54,552]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:00,282]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:03,674]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:03,819]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:07,009]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:12,410]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:13,725]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:19,330]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:27,900]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:31,672]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:34,924]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:34,971]\u001b[0m Trial 186 finished with value: 4.819706973581119 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028108794943904726, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10275720546221262, 'dropout_rate_Layer_2': 0.11316545009850575, 'dropout_rate_Layer_3': 0.17833333118094127, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00040858984182975407, 'l1_Layer_2': 0.018628333326891268, 'l1_Layer_3': 0.02179381543062217, 'n_units_Layer_1': 255, 'n_units_Layer_2': 175, 'n_units_Layer_3': 250}. Best is trial 94 with value: 4.7327415834725235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 15.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 25.75% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:48:38,410]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:42,758]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:47,426]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:50,810]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:55,094]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:48:59,431]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:49:00,243]\u001b[0m Trial 214 finished with value: 4.569754867054786 and parameters: {'n_hidden': 3, 'learning_rate': 0.0074954968442907475, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12592527451304963, 'dropout_rate_Layer_2': 0.1845433231173753, 'dropout_rate_Layer_3': 0.35781953516698667, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.531903178657612e-05, 'l1_Layer_2': 0.05216972414989219, 'l1_Layer_3': 0.0004966926148573957, 'n_units_Layer_1': 170, 'n_units_Layer_2': 245, 'n_units_Layer_3': 230}. Best is trial 214 with value: 4.569754867054786.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 14.52% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 20.91% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:49:06,017]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:49:09,569]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:49:16,715]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:49:26,988]\u001b[0m Trial 230 finished with value: 5.194258333082749 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024313598233815007, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39706974879159507, 'dropout_rate_Layer_2': 0.14746120693287607, 'dropout_rate_Layer_3': 0.33815376175506423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02256971684207631, 'l1_Layer_2': 0.013413439042233322, 'l1_Layer_3': 0.00013120711380530995, 'n_units_Layer_1': 95, 'n_units_Layer_2': 265, 'n_units_Layer_3': 300}. Best is trial 214 with value: 4.569754867054786.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 16.32% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.33 | sMAPE for Test Set is: 21.52% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:49:28,691]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:49:39,314]\u001b[0m Trial 224 finished with value: 4.816936880525486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017856304469167428, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10156729690098769, 'dropout_rate_Layer_2': 0.10880272890251289, 'dropout_rate_Layer_3': 0.166394798500303, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042269430873956927, 'l1_Layer_2': 0.04498901476804325, 'l1_Layer_3': 5.5953099617996175e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 165, 'n_units_Layer_3': 230}. Best is trial 214 with value: 4.569754867054786.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 15.40% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 27.84% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:49:48,512]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:49:50,671]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:49:58,219]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:00,546]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:05,540]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:08,146]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:09,135]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:15,490]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:18,845]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:20,922]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:23,257]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:28,059]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:32,976]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:35,907]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:36,857]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:38,927]\u001b[0m Trial 222 finished with value: 4.611051682548205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008560187251501425, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.187469355321327, 'dropout_rate_Layer_2': 0.30941990164443484, 'dropout_rate_Layer_3': 0.227434740635306, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0518484857222156e-05, 'l1_Layer_2': 0.0013932382528976535, 'l1_Layer_3': 1.7188575541723904e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 260, 'n_units_Layer_3': 175}. Best is trial 214 with value: 4.569754867054786.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.94 | sMAPE for Test Set is: 20.75% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:50:43,376]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:45,198]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:50,566]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:53,352]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:57,173]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:50:57,686]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:01,626]\u001b[0m Trial 243 finished with value: 4.7097456089033995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038367301302025506, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39723421278017074, 'dropout_rate_Layer_2': 0.14965388810944794, 'dropout_rate_Layer_3': 0.3259221061109533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010964980761784672, 'l1_Layer_2': 0.09967400507767346, 'l1_Layer_3': 6.900032723314123e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 285, 'n_units_Layer_3': 265}. Best is trial 214 with value: 4.569754867054786.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 21.00% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:51:01,792]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:02,996]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:08,313]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:10,146]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:16,487]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:19,929]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:21,911]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:24,316]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:26,114]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:29,452]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:32,221]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:35,154]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:39,111]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:41,926]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:43,272]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:48,572]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:51,453]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:54,989]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:59,065]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:51:59,434]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:00,185]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:07,578]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:09,413]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:09,764]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:15,860]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:17,743]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:21,289]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:21,821]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:25,398]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:28,860]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:33,511]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:35,861]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:40,171]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:42,633]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:43,379]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:44,821]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:49,542]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:51,724]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:51,984]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:54,515]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:52:56,672]\u001b[0m Trial 275 finished with value: 4.380305619580079 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011230180544122349, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09079084233475085, 'dropout_rate_Layer_2': 0.23738883717651726, 'dropout_rate_Layer_3': 0.08542389235270136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006707413016874864, 'l1_Layer_2': 0.0038828942676020386, 'l1_Layer_3': 6.879237440577033e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 180, 'n_units_Layer_3': 230}. Best is trial 275 with value: 4.380305619580079.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 14.35% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 20.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:52:57,600]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:53:03,728]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:53:06,253]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:53:08,224]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:53:13,580]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:53:28,019]\u001b[0m Trial 299 finished with value: 4.610012086729764 and parameters: {'n_hidden': 3, 'learning_rate': 0.00614659438668041, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13284569536817395, 'dropout_rate_Layer_2': 0.01187561267971202, 'dropout_rate_Layer_3': 0.018028433623039616, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005742282864234951, 'l1_Layer_2': 0.03425042918774024, 'l1_Layer_3': 0.004993510652849557, 'n_units_Layer_1': 95, 'n_units_Layer_2': 105, 'n_units_Layer_3': 135}. Best is trial 275 with value: 4.380305619580079.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 25.64% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:53:41,511]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:53:49,197]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:53:53,318]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:53:59,264]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:54:19,055]\u001b[0m Trial 300 finished with value: 4.333853435127733 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011816955395940606, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0699939472290459, 'dropout_rate_Layer_2': 0.23646619683141545, 'dropout_rate_Layer_3': 0.08250856774101056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003293382219980483, 'l1_Layer_2': 0.0024838470959515717, 'l1_Layer_3': 0.00016730823576537412, 'n_units_Layer_1': 250, 'n_units_Layer_2': 185, 'n_units_Layer_3': 225}. Best is trial 300 with value: 4.333853435127733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 14.24% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 19.89% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:54:25,776]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:54:28,554]\u001b[0m Trial 303 finished with value: 4.372526189075502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008658033753645118, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00916200173779746, 'dropout_rate_Layer_2': 0.24002620325993065, 'dropout_rate_Layer_3': 0.08673413720352971, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00035818476008954794, 'l1_Layer_2': 0.005938713407254814, 'l1_Layer_3': 0.00015811115040529066, 'n_units_Layer_1': 250, 'n_units_Layer_2': 185, 'n_units_Layer_3': 220}. Best is trial 300 with value: 4.333853435127733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 20.69% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:54:40,659]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:54:44,036]\u001b[0m Trial 308 finished with value: 4.7005911869243535 and parameters: {'n_hidden': 3, 'learning_rate': 0.006980693288216386, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12733660884651526, 'dropout_rate_Layer_2': 0.011957770682442477, 'dropout_rate_Layer_3': 0.20947995269634084, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004483270292814069, 'l1_Layer_2': 0.0038256504975868752, 'l1_Layer_3': 0.021329283512960286, 'n_units_Layer_1': 90, 'n_units_Layer_2': 100, 'n_units_Layer_3': 175}. Best is trial 300 with value: 4.333853435127733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 15.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 21.20% | rMAE for Test Set is: 0.69\n",
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 14.22% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 21.76% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:54:44,296]\u001b[0m Trial 301 finished with value: 4.2979821640368225 and parameters: {'n_hidden': 3, 'learning_rate': 0.000858210542495895, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.048571579880038185, 'dropout_rate_Layer_2': 0.2461317298631967, 'dropout_rate_Layer_3': 0.0923377858455509, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033378895083624395, 'l1_Layer_2': 0.0024811947225287963, 'l1_Layer_3': 8.253995904605311e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 185, 'n_units_Layer_3': 225}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:54:50,795]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:54:53,590]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:54:58,223]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:02,561]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:08,838]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:11,584]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:13,069]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:15,626]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:20,440]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:20,579]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:27,395]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:31,065]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:35,047]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:36,930]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:37,268]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:40,229]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:44,731]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:47,323]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:52,451]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:55:58,388]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:56:02,312]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:56:09,014]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:56:12,597]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:56:13,747]\u001b[0m Trial 332 finished with value: 5.6902221524326935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036705245294373127, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23901561447021794, 'dropout_rate_Layer_2': 0.09597663727594961, 'dropout_rate_Layer_3': 0.157204619901447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.44750458385231e-05, 'l1_Layer_2': 0.00418623821563967, 'l1_Layer_3': 0.0013203251395970288, 'n_units_Layer_1': 180, 'n_units_Layer_2': 250, 'n_units_Layer_3': 105}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 17.59% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 26.83% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:56:20,509]\u001b[0m Trial 333 finished with value: 4.674536933663616 and parameters: {'n_hidden': 4, 'learning_rate': 0.01190145240112281, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13133648402765957, 'dropout_rate_Layer_2': 0.0011464735981286112, 'dropout_rate_Layer_3': 0.20908023035365775, 'dropout_rate_Layer_4': 0.006264837619202712, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.797096538386158e-05, 'l1_Layer_2': 0.004232306768571185, 'l1_Layer_3': 0.005060801532538007, 'l1_Layer_4': 0.0005012423704304945, 'n_units_Layer_1': 80, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170, 'n_units_Layer_4': 295}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 15.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 24.51% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:56:24,835]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:56:30,140]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:56:32,811]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:56:36,891]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:56:41,163]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:56:44,862]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:56:54,177]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:56:54,691]\u001b[0m Trial 338 finished with value: 4.617019885291989 and parameters: {'n_hidden': 4, 'learning_rate': 0.009149550070851019, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13879257950195906, 'dropout_rate_Layer_2': 0.0034449561032914994, 'dropout_rate_Layer_3': 0.21447655942563082, 'dropout_rate_Layer_4': 0.006332836950570686, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.898375506662631e-05, 'l1_Layer_2': 0.004637152737822219, 'l1_Layer_3': 0.005787215044539617, 'l1_Layer_4': 0.0005572257970704236, 'n_units_Layer_1': 90, 'n_units_Layer_2': 75, 'n_units_Layer_3': 170, 'n_units_Layer_4': 295}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 14.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 25.11% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:57:00,612]\u001b[0m Trial 339 finished with value: 4.577232317049854 and parameters: {'n_hidden': 4, 'learning_rate': 0.008868307215307123, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14004233058649987, 'dropout_rate_Layer_2': 0.002634170773062575, 'dropout_rate_Layer_3': 0.21299242738320684, 'dropout_rate_Layer_4': 0.011543136295283196, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.668720987576968e-05, 'l1_Layer_2': 0.003969105092420306, 'l1_Layer_3': 0.0050705427724658, 'l1_Layer_4': 0.0005101748168827156, 'n_units_Layer_1': 75, 'n_units_Layer_2': 75, 'n_units_Layer_3': 175, 'n_units_Layer_4': 295}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 14.75% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 23.71% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:57:00,985]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:05,783]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:06,149]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:06,809]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:11,874]\u001b[0m Trial 345 finished with value: 4.592432093935529 and parameters: {'n_hidden': 4, 'learning_rate': 0.010624596052926809, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1353368490199021, 'dropout_rate_Layer_2': 0.007713582578281442, 'dropout_rate_Layer_3': 0.22438380355652565, 'dropout_rate_Layer_4': 0.001241256520881473, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.441085642013059e-05, 'l1_Layer_2': 0.004095771443947284, 'l1_Layer_3': 0.003908382897279511, 'l1_Layer_4': 0.0005734117996015121, 'n_units_Layer_1': 85, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170, 'n_units_Layer_4': 295}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 14.80% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 23.53% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:57:13,512]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:14,734]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:14,769]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:20,598]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:22,774]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:23,665]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:28,213]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:28,804]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:35,853]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:40,813]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:43,697]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:57:48,917]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:58:01,230]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:58:05,042]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:58:08,559]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:58:20,208]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:58:23,513]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:58:29,231]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:58:33,012]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:58:37,653]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:58:52,114]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:58:56,700]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:58:57,012]\u001b[0m Trial 372 finished with value: 5.222599976342484 and parameters: {'n_hidden': 4, 'learning_rate': 0.047101500945228, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20391672021880258, 'dropout_rate_Layer_2': 0.11202148383149539, 'dropout_rate_Layer_3': 0.09705537946870105, 'dropout_rate_Layer_4': 0.1039990379817165, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005434148381579339, 'l1_Layer_2': 0.0006136018208934641, 'l1_Layer_3': 0.0005844839145802207, 'l1_Layer_4': 9.781448788812394e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 190, 'n_units_Layer_4': 185}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 16.42% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.55 | sMAPE for Test Set is: 29.26% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:59:03,785]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:59:03,984]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:59:09,697]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:59:14,871]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:59:17,485]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:59:17,989]\u001b[0m Trial 366 finished with value: 4.567354205089797 and parameters: {'n_hidden': 3, 'learning_rate': 0.000860733572894878, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012798658961662138, 'dropout_rate_Layer_2': 0.2542336592246568, 'dropout_rate_Layer_3': 0.0627757252125587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.028863731781531864, 'l1_Layer_2': 0.0020779770507375716, 'l1_Layer_3': 0.00012287176411090976, 'n_units_Layer_1': 250, 'n_units_Layer_2': 190, 'n_units_Layer_3': 235}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.47 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:59:22,745]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:59:34,082]\u001b[0m Trial 364 finished with value: 4.51934938383724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007287609340335998, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012185878332951443, 'dropout_rate_Layer_2': 0.25396801599339075, 'dropout_rate_Layer_3': 0.0611589688239805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02638473702027938, 'l1_Layer_2': 0.0021335942211476167, 'l1_Layer_3': 0.00012317807624175406, 'n_units_Layer_1': 250, 'n_units_Layer_2': 190, 'n_units_Layer_3': 205}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 18.76% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 17:59:34,789]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:59:40,349]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:59:50,719]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 17:59:55,774]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:00,874]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:07,257]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:13,012]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:18,668]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:19,446]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:27,902]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:33,165]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:42,104]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:44,424]\u001b[0m Trial 383 finished with value: 4.510902744365138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008312703730332285, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01762291210800906, 'dropout_rate_Layer_2': 0.25553394574820154, 'dropout_rate_Layer_3': 0.09510118910119494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.019235803471907443, 'l1_Layer_2': 0.0029630522100971444, 'l1_Layer_3': 8.559581796815264e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 225}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 18.69% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:00:47,834]\u001b[0m Trial 380 finished with value: 4.574030413077086 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008192498282301165, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006127111377080342, 'dropout_rate_Layer_2': 0.2601473758268814, 'dropout_rate_Layer_3': 0.0641488788986928, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028114625816221817, 'l1_Layer_2': 0.0020611442716686914, 'l1_Layer_3': 8.735357704419813e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 195, 'n_units_Layer_3': 175}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 18.80% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:00:51,349]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:51,767]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:51,853]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:00:59,167]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:01:01,784]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:01:02,601]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:01:06,566]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:01:12,628]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:01:21,266]\u001b[0m Trial 401 finished with value: 5.0419595755056745 and parameters: {'n_hidden': 4, 'learning_rate': 0.0068854764609750695, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1510995787913075, 'dropout_rate_Layer_2': 0.10250314162438276, 'dropout_rate_Layer_3': 0.014844034181869026, 'dropout_rate_Layer_4': 0.07493474343147598, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.000797435971424288, 'l1_Layer_2': 0.05223632762169086, 'l1_Layer_3': 0.009039550551166996, 'l1_Layer_4': 0.00019461356507645644, 'n_units_Layer_1': 100, 'n_units_Layer_2': 50, 'n_units_Layer_3': 125, 'n_units_Layer_4': 210}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 15.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.20 | sMAPE for Test Set is: 28.31% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:01:23,837]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:01:32,087]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:01:44,268]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:01:48,603]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:01:52,327]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:02:05,090]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:02:12,203]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:02:16,906]\u001b[0m Trial 394 finished with value: 4.298237673103171 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007858006577461034, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0267902606792796, 'dropout_rate_Layer_2': 0.24947290125416904, 'dropout_rate_Layer_3': 0.047859827466496474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033240203616043444, 'l1_Layer_2': 0.0013722144357443328, 'l1_Layer_3': 7.859180817793386e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 175, 'n_units_Layer_3': 190}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 21.75% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:02:21,815]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:02:25,127]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:02:28,839]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:02:36,283]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:02:41,848]\u001b[0m Trial 407 finished with value: 4.375793844943162 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008230669432159888, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015930093094119677, 'dropout_rate_Layer_2': 0.2655866102111083, 'dropout_rate_Layer_3': 0.021039686595276913, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00030403201130750396, 'l1_Layer_2': 0.0029387371948167715, 'l1_Layer_3': 9.44636483687157e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 165}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 22.58% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:02:45,688]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:02:52,796]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:02:56,441]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:03:01,985]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:03:15,267]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:03:19,558]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:03:26,678]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:03:30,453]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:03:34,739]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:03:44,836]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:03:49,606]\u001b[0m Trial 418 finished with value: 4.313589922914098 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008108980754729334, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03276832381859977, 'dropout_rate_Layer_2': 0.24511753117459992, 'dropout_rate_Layer_3': 0.07751850048432894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001784593017058987, 'l1_Layer_2': 0.0009479923547672014, 'l1_Layer_3': 9.334348974557788e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 14.21% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.37 | sMAPE for Test Set is: 20.33% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:03:50,052]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:03:58,353]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:04:04,219]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:04:04,654]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:04:10,886]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:04:16,856]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:04:19,857]\u001b[0m Trial 417 finished with value: 4.313457018701945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008059075885126215, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03991434488068073, 'dropout_rate_Layer_2': 0.22447796148268956, 'dropout_rate_Layer_3': 0.015285889582150824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002652535695111812, 'l1_Layer_2': 0.001787558728480313, 'l1_Layer_3': 9.481067387868444e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 180, 'n_units_Layer_3': 195}. Best is trial 301 with value: 4.2979821640368225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 22.36% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:04:26,381]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:04:29,271]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:04:32,041]\u001b[0m Trial 419 finished with value: 4.281207156575648 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008020005978041206, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.033003064007534326, 'dropout_rate_Layer_2': 0.22437268914588276, 'dropout_rate_Layer_3': 0.1978659711921252, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002695345578457104, 'l1_Layer_2': 0.0016821606728970135, 'l1_Layer_3': 9.319707390517475e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190}. Best is trial 419 with value: 4.281207156575648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 21.53% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:04:38,099]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:04:42,153]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:04:54,006]\u001b[0m Trial 440 finished with value: 5.206114775188809 and parameters: {'n_hidden': 3, 'learning_rate': 0.009493807840740087, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020709976946717192, 'dropout_rate_Layer_2': 0.2540837991533352, 'dropout_rate_Layer_3': 0.38801828916194075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00027721993186284176, 'l1_Layer_2': 0.0015825019054027528, 'l1_Layer_3': 0.015610500190695131, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 230}. Best is trial 419 with value: 4.281207156575648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 16.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.65 | sMAPE for Test Set is: 29.46% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:05:02,203]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:05:11,779]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:05:27,213]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:05:30,529]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:05:35,843]\u001b[0m Trial 435 finished with value: 4.360998196125003 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007633611565012695, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.043201208571183675, 'dropout_rate_Layer_2': 0.2566414287985748, 'dropout_rate_Layer_3': 0.07871742829553363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002246048951188557, 'l1_Layer_2': 0.0019262776644906221, 'l1_Layer_3': 7.027667827108093e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 190, 'n_units_Layer_3': 165}. Best is trial 419 with value: 4.281207156575648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 22.98% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:05:41,066]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:05:45,773]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:05:54,162]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:06:01,252]\u001b[0m Trial 443 finished with value: 4.291788356604411 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007620901752211816, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03674636859644351, 'dropout_rate_Layer_2': 0.23586479073563218, 'dropout_rate_Layer_3': 0.015290054125872237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018528768187222575, 'l1_Layer_2': 0.001592263816334977, 'l1_Layer_3': 8.235366309584413e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190}. Best is trial 419 with value: 4.281207156575648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 14.18% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 21.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:06:05,367]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:06:18,305]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:06:20,567]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:06:25,633]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:06:29,421]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:06:33,120]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:06:37,194]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:06:44,214]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:06:54,232]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:07:05,062]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:07:09,173]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:07:12,905]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:07:13,336]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:07:18,314]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:07:20,573]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:07:25,574]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:07:26,395]\u001b[0m Trial 448 finished with value: 4.308215377742575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006005867336894384, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04065577408522436, 'dropout_rate_Layer_2': 0.2409627075485373, 'dropout_rate_Layer_3': 0.009680227566881382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001685197743378923, 'l1_Layer_2': 0.0010641842653152367, 'l1_Layer_3': 6.663118092713083e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190}. Best is trial 419 with value: 4.281207156575648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 14.00% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:07:32,805]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:07:35,019]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:08:21,806]\u001b[0m Trial 452 finished with value: 4.345620347263788 and parameters: {'n_hidden': 3, 'learning_rate': 0.000652602451428198, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04031238003636269, 'dropout_rate_Layer_2': 0.23019454505164588, 'dropout_rate_Layer_3': 0.009861374067979666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018573311045756285, 'l1_Layer_2': 0.015856671174955508, 'l1_Layer_3': 8.300237308018343e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190}. Best is trial 419 with value: 4.281207156575648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 14.27% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.60 | sMAPE for Test Set is: 22.73% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:08:24,101]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:08:31,756]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:08:36,898]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:08:40,238]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:08:42,152]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:08:43,390]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:08:49,052]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:08:49,328]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:08:49,692]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:08:56,756]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:08:59,181]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:09:02,893]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:09:06,656]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:09:08,694]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:09:13,906]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:09:16,385]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:09:20,322]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:09:25,510]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:09:30,844]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:09:33,862]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:09:38,188]\u001b[0m Trial 469 finished with value: 5.094558438304638 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025425352402327593, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23077037188807178, 'dropout_rate_Layer_2': 0.08326374982647873, 'dropout_rate_Layer_3': 0.16951092172949667, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001487116912025343, 'l1_Layer_2': 0.0036316878831129155, 'l1_Layer_3': 0.0022057673958927903, 'n_units_Layer_1': 195, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 419 with value: 4.281207156575648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 15.89% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 27.09% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:09:38,896]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:09:47,960]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:10:03,326]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:10:08,979]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:10:24,132]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:10:29,723]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:10:39,362]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:10:49,756]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:10:53,429]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:11:16,718]\u001b[0m Trial 496 finished with value: 4.868778939482443 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018206590932612844, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21441635151780752, 'dropout_rate_Layer_2': 0.08977985053421154, 'dropout_rate_Layer_3': 0.20218618236191882, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001753756577674448, 'l1_Layer_2': 0.0034350170736908107, 'l1_Layer_3': 0.0007655197396613734, 'n_units_Layer_1': 145, 'n_units_Layer_2': 245, 'n_units_Layer_3': 245}. Best is trial 419 with value: 4.281207156575648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 15.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 23.75% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:11:20,991]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:11:25,079]\u001b[0m Trial 503 finished with value: 4.669723812339471 and parameters: {'n_hidden': 4, 'learning_rate': 0.03930691448443488, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11446816674692156, 'dropout_rate_Layer_2': 0.026308028248927418, 'dropout_rate_Layer_3': 0.13806384668596794, 'dropout_rate_Layer_4': 0.1413704000434846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.66867068182088e-05, 'l1_Layer_2': 0.0006902290605456193, 'l1_Layer_3': 0.006193208996905217, 'l1_Layer_4': 0.0014431195463785235, 'n_units_Layer_1': 135, 'n_units_Layer_2': 65, 'n_units_Layer_3': 220, 'n_units_Layer_4': 280}. Best is trial 419 with value: 4.281207156575648.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 14.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 21.20% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:11:27,116]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:11:30,908]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:11:33,437]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:11:39,063]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:11:41,505]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:11:52,021]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 24.74% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:11:53,889]\u001b[0m Trial 498 finished with value: 4.292397717345138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007302421309508376, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027900723839948446, 'dropout_rate_Layer_2': 0.011276448201116958, 'dropout_rate_Layer_3': 0.08806705651637962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000403658813775074, 'l1_Layer_2': 0.006842576377520475, 'l1_Layer_3': 0.00011389641884780106, 'n_units_Layer_1': 225, 'n_units_Layer_2': 65, 'n_units_Layer_3': 165}. Best is trial 419 with value: 4.281207156575648.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:11:59,763]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:12:08,205]\u001b[0m Trial 493 finished with value: 4.225406229564819 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007627489588620764, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04897603553601593, 'dropout_rate_Layer_2': 0.07303879222782593, 'dropout_rate_Layer_3': 0.005607488621571522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026911785994472955, 'l1_Layer_2': 0.007110846204005114, 'l1_Layer_3': 8.355609396515548e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 185, 'n_units_Layer_3': 240}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 13.96% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.34 | sMAPE for Test Set is: 21.31% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:12:10,690]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:12:14,771]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:12:18,202]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:12:27,325]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:12:27,583]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:12:30,252]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:12:34,285]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:12:37,381]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:12:46,406]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:12:59,452]\u001b[0m Trial 523 finished with value: 5.288687498902476 and parameters: {'n_hidden': 3, 'learning_rate': 0.012687545953520387, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0430239598256369, 'dropout_rate_Layer_2': 0.2807203740219034, 'dropout_rate_Layer_3': 0.3905526289387198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00037576520391066414, 'l1_Layer_2': 0.002569493714505215, 'l1_Layer_3': 0.01398671960720665, 'n_units_Layer_1': 280, 'n_units_Layer_2': 275, 'n_units_Layer_3': 205}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 16.55% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.38 | sMAPE for Test Set is: 28.55% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:13:03,707]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:13:07,511]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:13:12,719]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:13:21,616]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:13:26,520]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:13:34,396]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:13:53,893]\u001b[0m Trial 531 finished with value: 4.817363413057291 and parameters: {'n_hidden': 4, 'learning_rate': 0.033737128092778304, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17040761403266863, 'dropout_rate_Layer_2': 0.043498814777183384, 'dropout_rate_Layer_3': 0.19270496032270118, 'dropout_rate_Layer_4': 0.029343096899640306, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.972696853210371e-05, 'l1_Layer_2': 0.000496549660606574, 'l1_Layer_3': 0.003291150130917194, 'l1_Layer_4': 0.0007725451700652032, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 205, 'n_units_Layer_4': 285}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 15.41% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.75 | sMAPE for Test Set is: 19.80% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:13:56,872]\u001b[0m Trial 518 finished with value: 4.382165993196782 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009041285831295148, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.051024883281971606, 'dropout_rate_Layer_2': 0.07622007955258897, 'dropout_rate_Layer_3': 0.0892719082598667, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00041685340965739147, 'l1_Layer_2': 0.008614447400019976, 'l1_Layer_3': 0.0001234207212842896, 'n_units_Layer_1': 230, 'n_units_Layer_2': 195, 'n_units_Layer_3': 155}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 21.95% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:14:01,740]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:14:05,722]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:14:10,904]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:14:16,787]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:14:20,235]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:14:45,859]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:14:54,316]\u001b[0m Trial 528 finished with value: 4.781625897484784 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014188935787039394, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3250317605809448, 'dropout_rate_Layer_2': 0.050969531010743495, 'dropout_rate_Layer_3': 0.017967503045847405, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023380690689826032, 'l1_Layer_2': 0.0009712884865413327, 'l1_Layer_3': 0.001171723780872825, 'n_units_Layer_1': 210, 'n_units_Layer_2': 240, 'n_units_Layer_3': 255}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.36 | sMAPE for Test Set is: 25.84% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:14:58,969]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:15:04,446]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:15:06,790]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:15:09,339]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:15:10,335]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:15:12,592]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:15:17,553]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:15:23,791]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:15:27,708]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:15:31,471]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:16:05,335]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:16:08,915]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:16:12,333]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:16:15,118]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:16:29,223]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:16:50,933]\u001b[0m Trial 546 finished with value: 4.821944140770804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013727683299993687, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23094686979173715, 'dropout_rate_Layer_2': 0.04686689928695221, 'dropout_rate_Layer_3': 0.01162003921292723, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002982153050967041, 'l1_Layer_2': 0.0003654543479472317, 'l1_Layer_3': 0.0031614087838008017, 'n_units_Layer_1': 200, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 15.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 26.22% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:16:56,056]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:17:04,539]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:17:09,829]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:17:12,921]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:17:19,789]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:17:23,414]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:17:29,822]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:17:34,577]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:17:40,152]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:17:47,263]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:18:05,269]\u001b[0m Trial 559 finished with value: 4.396294897337491 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008470285123626574, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.046859599163483236, 'dropout_rate_Layer_2': 0.2339171750791696, 'dropout_rate_Layer_3': 0.019128384558580364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00031020787642534127, 'l1_Layer_2': 1.0160856630632093e-05, 'l1_Layer_3': 7.159385659813023e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 190, 'n_units_Layer_3': 195}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 15.00% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 25.51% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:18:08,822]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:18:41,102]\u001b[0m Trial 567 finished with value: 5.211802965511379 and parameters: {'n_hidden': 3, 'learning_rate': 0.005859245323658265, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008572786131559212, 'dropout_rate_Layer_2': 0.2253600661248133, 'dropout_rate_Layer_3': 0.39935338890530814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.008233808250949753, 'l1_Layer_2': 0.002168623840608112, 'l1_Layer_3': 0.014849820535319561, 'n_units_Layer_1': 290, 'n_units_Layer_2': 295, 'n_units_Layer_3': 180}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 16.28% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 24.53% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:18:44,486]\u001b[0m Trial 555 finished with value: 4.227317873050825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010257606748436847, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019527932262518012, 'dropout_rate_Layer_2': 0.2501703994603668, 'dropout_rate_Layer_3': 0.0970545037218566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00047302112417078266, 'l1_Layer_2': 0.0020172413264010107, 'l1_Layer_3': 9.659401992931624e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 130, 'n_units_Layer_3': 235}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 22.75% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:18:46,772]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:18:49,619]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:18:54,003]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:18:56,135]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:18:59,248]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:19:03,196]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:19:15,975]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:19:16,382]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:19:27,490]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:19:31,849]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:19:35,418]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:19:39,065]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:19:49,494]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:19:51,994]\u001b[0m Trial 578 finished with value: 5.3005903603111575 and parameters: {'n_hidden': 3, 'learning_rate': 0.005441247362392333, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06561955808020165, 'dropout_rate_Layer_2': 0.22259164917239732, 'dropout_rate_Layer_3': 0.38928068086819273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.022956900583197416, 'l1_Layer_2': 0.0014391551121255158, 'l1_Layer_3': 0.014775901234618286, 'n_units_Layer_1': 295, 'n_units_Layer_2': 295, 'n_units_Layer_3': 180}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 16.52% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 24.10% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:19:55,057]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:20:04,239]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:20:07,773]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:20:24,655]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:20:31,229]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:20:33,310]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:20:41,846]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:20:42,055]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:20:47,548]\u001b[0m Trial 589 finished with value: 6.4108418423725455 and parameters: {'n_hidden': 4, 'learning_rate': 0.01253993297789575, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1475301101165912, 'dropout_rate_Layer_2': 0.0695713595056628, 'dropout_rate_Layer_3': 0.002123437397662978, 'dropout_rate_Layer_4': 0.038982702506072935, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.0985419359299978e-05, 'l1_Layer_2': 0.0031483706250988288, 'l1_Layer_3': 0.0012916277124158087, 'l1_Layer_4': 0.005073843020488184, 'n_units_Layer_1': 90, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200, 'n_units_Layer_4': 250}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 19.08% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 8.47 | sMAPE for Test Set is: 31.55% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:20:53,685]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:20:56,605]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:00,660]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:04,696]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:11,024]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:14,354]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:14,922]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:19,484]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:21,672]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:26,866]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:29,644]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:33,237]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:39,397]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:41,768]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:50,458]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:59,051]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:21:59,423]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:22:06,320]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:22:15,413]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:22:31,874]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:22:50,396]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:22:51,118]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:22:56,290]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:23:00,147]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:23:05,325]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:23:11,369]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:23:14,315]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:23:21,438]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:23:24,917]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:23:28,348]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:23:32,304]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:23:37,213]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:23:43,202]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:23:53,613]\u001b[0m Trial 625 finished with value: 5.088441169958985 and parameters: {'n_hidden': 3, 'learning_rate': 0.010533241479167642, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03396192207005778, 'dropout_rate_Layer_2': 0.16349246192183933, 'dropout_rate_Layer_3': 0.35567135239533915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.029601145480122364, 'l1_Layer_2': 0.047216599646176895, 'l1_Layer_3': 5.913057542218866e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 16.03% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:23:58,878]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:24:29,951]\u001b[0m Trial 603 finished with value: 4.836951939020743 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013409811940599359, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20901304494463108, 'dropout_rate_Layer_2': 0.010979186890955714, 'dropout_rate_Layer_3': 0.03661218040205605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004030194354848749, 'l1_Layer_2': 0.00024248974759376587, 'l1_Layer_3': 0.003558554234381233, 'n_units_Layer_1': 215, 'n_units_Layer_2': 250, 'n_units_Layer_3': 300}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 15.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 26.57% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:25:11,783]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:25:18,574]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:25:24,263]\u001b[0m Trial 626 finished with value: 4.705694198763792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011014591868065621, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2311825564390267, 'dropout_rate_Layer_2': 0.024607087409686007, 'dropout_rate_Layer_3': 0.05990013972152486, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006529682428138325, 'l1_Layer_2': 0.0004210887983604762, 'l1_Layer_3': 0.0014823551671880202, 'n_units_Layer_1': 210, 'n_units_Layer_2': 245, 'n_units_Layer_3': 265}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 14.90% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 24.39% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:25:32,260]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:25:40,962]\u001b[0m Trial 628 finished with value: 4.758465242612296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010347176908259291, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2298170435122563, 'dropout_rate_Layer_2': 0.022689718517353224, 'dropout_rate_Layer_3': 0.009959992278379539, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007318004422092943, 'l1_Layer_2': 0.00032426535769661274, 'l1_Layer_3': 0.0029551296417533795, 'n_units_Layer_1': 220, 'n_units_Layer_2': 245, 'n_units_Layer_3': 265}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 15.02% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 24.97% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:25:55,351]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:25:58,954]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:25:59,225]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:08,436]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:09,152]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:12,398]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:14,952]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:15,721]\u001b[0m Trial 629 finished with value: 4.7677503530450815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014641872686055259, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19882511021944319, 'dropout_rate_Layer_2': 0.021227966807450472, 'dropout_rate_Layer_3': 0.056428199596189846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021811457029636327, 'l1_Layer_2': 0.0012282849486880628, 'l1_Layer_3': 0.0017260668107765263, 'n_units_Layer_1': 220, 'n_units_Layer_2': 245, 'n_units_Layer_3': 285}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 15.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 25.27% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:26:20,344]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:20,861]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:21,419]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:27,625]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:27,880]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:27,912]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:30,695]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:38,984]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:26:42,211]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:27:37,332]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:27:42,250]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:27:45,713]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:27:46,377]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:27:47,798]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:27:54,446]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:27:55,596]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:28:01,085]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:28:09,082]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:28:12,650]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:28:14,739]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:28:17,538]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:28:20,071]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:28:24,877]\u001b[0m Trial 649 finished with value: 4.477934350345833 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010761660011560138, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19549447485867413, 'dropout_rate_Layer_2': 0.022072146287267037, 'dropout_rate_Layer_3': 0.003660915803448836, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011261118604909076, 'l1_Layer_2': 0.0003732069536293221, 'l1_Layer_3': 0.000992577722635643, 'n_units_Layer_1': 220, 'n_units_Layer_2': 240, 'n_units_Layer_3': 270}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.64 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:28:27,000]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:28:35,536]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:28:46,514]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:28:52,483]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:29:01,949]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:29:17,599]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:29:22,721]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:29:26,038]\u001b[0m Trial 657 finished with value: 4.53835837131106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010650999593325731, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1978449224777606, 'dropout_rate_Layer_2': 0.01540492196185325, 'dropout_rate_Layer_3': 0.08517671552567058, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011626490013255729, 'l1_Layer_2': 1.0963454120148429e-05, 'l1_Layer_3': 0.000977538015397176, 'n_units_Layer_1': 210, 'n_units_Layer_2': 245, 'n_units_Layer_3': 255}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 14.50% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 25.73% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:29:26,351]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:29:34,641]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:29:40,080]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:29:51,060]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:29:56,774]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:29:57,540]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:01,758]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:05,091]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:10,849]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:14,087]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:16,782]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:19,056]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:19,825]\u001b[0m Trial 670 finished with value: 4.264988674034176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006159985627060102, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.046005811912442, 'dropout_rate_Layer_2': 0.26430986962264347, 'dropout_rate_Layer_3': 0.07805215152694499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013296434294746815, 'l1_Layer_2': 0.001865310260472288, 'l1_Layer_3': 9.220828316267204e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.47 | sMAPE for Test Set is: 19.97% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:30:22,134]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:24,911]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:28,948]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:33,345]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:36,471]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:44,000]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:47,307]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:55,379]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:30:56,051]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:01,729]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:05,612]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:08,285]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:10,924]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:13,731]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:14,581]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:19,021]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:19,892]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:22,162]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:22,593]\u001b[0m Trial 665 finished with value: 4.5898993671806165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007994526877587744, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1981417521906283, 'dropout_rate_Layer_2': 0.012702122589296573, 'dropout_rate_Layer_3': 0.09181029086525512, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010975811040091889, 'l1_Layer_2': 0.00067355824882533, 'l1_Layer_3': 0.0008070557004172949, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 260}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 14.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 24.09% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:31:24,818]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:31,326]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:31,820]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:35,878]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:36,221]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:42,297]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:43,153]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:46,626]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:50,408]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:55,418]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:31:58,496]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:32:18,130]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:32:59,267]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:33:02,787]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:33:57,126]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:34:11,134]\u001b[0m Trial 717 finished with value: 4.406992918621451 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008612729068635949, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21129825357182613, 'dropout_rate_Layer_2': 0.019421288270081775, 'dropout_rate_Layer_3': 0.07633219552169403, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006748406290818939, 'l1_Layer_2': 0.000816042824643972, 'l1_Layer_3': 0.0013421639634911857, 'n_units_Layer_1': 230, 'n_units_Layer_2': 235, 'n_units_Layer_3': 255}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 20.58% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:34:15,559]\u001b[0m Trial 720 finished with value: 4.994588588949022 and parameters: {'n_hidden': 3, 'learning_rate': 0.006338633383155388, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0046486907005017265, 'dropout_rate_Layer_2': 0.14636558223710056, 'dropout_rate_Layer_3': 0.3263903436790403, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.001210034341916305, 'l1_Layer_2': 0.020279664936374283, 'l1_Layer_3': 0.001208539907508061, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 245}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 15.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 23.70% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:34:17,635]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:34:20,995]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:34:24,317]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:34:33,452]\u001b[0m Trial 719 finished with value: 4.637597735909332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008630713572550243, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21398914945181202, 'dropout_rate_Layer_2': 0.0019667148280781664, 'dropout_rate_Layer_3': 0.05497010028365366, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006552958252919962, 'l1_Layer_2': 0.0007985076930027418, 'l1_Layer_3': 0.0008627051966742512, 'n_units_Layer_1': 230, 'n_units_Layer_2': 255, 'n_units_Layer_3': 255}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 22.91% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:34:38,680]\u001b[0m Trial 713 finished with value: 4.37267122160137 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005965287594188356, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20550968084413637, 'dropout_rate_Layer_2': 0.01754451403791929, 'dropout_rate_Layer_3': 0.0928377373202523, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006504108327209091, 'l1_Layer_2': 0.0007148099868004057, 'l1_Layer_3': 0.0010595848948718187, 'n_units_Layer_1': 200, 'n_units_Layer_2': 245, 'n_units_Layer_3': 265}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 14.10% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 21.77% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:34:48,342]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:34:50,492]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:34:58,541]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:02,361]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:07,952]\u001b[0m Trial 728 finished with value: 5.068702704227171 and parameters: {'n_hidden': 4, 'learning_rate': 0.01039469766952284, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11734907069420802, 'dropout_rate_Layer_2': 0.00024979634714837953, 'dropout_rate_Layer_3': 0.15970116553727387, 'dropout_rate_Layer_4': 0.01969513675521852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.6136955950196642e-05, 'l1_Layer_2': 0.0037418124935774755, 'l1_Layer_3': 0.0016021788890986548, 'l1_Layer_4': 0.0010220850120298724, 'n_units_Layer_1': 105, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195, 'n_units_Layer_4': 285}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 15.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 26.62% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:35:11,571]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:11,873]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:17,240]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:17,611]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:22,224]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:24,855]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:27,517]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:31,246]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:33,045]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:39,912]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:50,197]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:35:56,015]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:36:00,095]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:36:12,652]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:36:16,197]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:36:20,650]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:36:21,601]\u001b[0m Trial 745 finished with value: 5.1136560674397415 and parameters: {'n_hidden': 3, 'learning_rate': 0.008511549090055541, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00014777022671310681, 'dropout_rate_Layer_2': 0.1298472473371175, 'dropout_rate_Layer_3': 0.37772964276911286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02435880092126738, 'l1_Layer_2': 0.01125003268993664, 'l1_Layer_3': 9.087228365348891e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 240}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 16.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 21.88% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:36:26,825]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:36:30,320]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:36:31,003]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:36:31,114]\u001b[0m Trial 726 finished with value: 4.479168409229824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008264294528632622, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2124735786884111, 'dropout_rate_Layer_2': 0.001463897798944229, 'dropout_rate_Layer_3': 0.06214433665024197, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006903911599709907, 'l1_Layer_2': 0.0009056439540676139, 'l1_Layer_3': 0.0013345152963092767, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 250}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 21.01% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:36:41,555]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:36:43,930]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:37:03,759]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:37:12,569]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:37:16,050]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:37:27,424]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:37:31,378]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:37:35,048]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:37:44,361]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:38:03,307]\u001b[0m Trial 742 finished with value: 4.3777403077044745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007317384863967479, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2056845573046194, 'dropout_rate_Layer_2': 0.02273125082607008, 'dropout_rate_Layer_3': 0.07476746356072536, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008712952525854972, 'l1_Layer_2': 0.0010604748246143057, 'l1_Layer_3': 0.00147332896487864, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 255}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 21.22% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:38:12,029]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:38:23,345]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:38:30,086]\u001b[0m Trial 755 finished with value: 4.462559390951579 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007845988992846626, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20970728165685648, 'dropout_rate_Layer_2': 0.018546886117468814, 'dropout_rate_Layer_3': 0.06441708618549646, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009004161690003379, 'l1_Layer_2': 0.00098665237682934, 'l1_Layer_3': 0.0021127320760603897, 'n_units_Layer_1': 250, 'n_units_Layer_2': 245, 'n_units_Layer_3': 250}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 21.30% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:39:31,235]\u001b[0m Trial 762 finished with value: 4.3130911502133875 and parameters: {'n_hidden': 3, 'learning_rate': 0.000617650478727968, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05015061949658393, 'dropout_rate_Layer_2': 0.21275263541898398, 'dropout_rate_Layer_3': 0.12628173465512688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004514445333927777, 'l1_Layer_2': 0.0018620605337562606, 'l1_Layer_3': 8.942722512074417e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 170}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 21.61% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:39:39,289]\u001b[0m Trial 764 finished with value: 4.509073357411298 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008269250744189867, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21371430688172072, 'dropout_rate_Layer_2': 0.018380840941221933, 'dropout_rate_Layer_3': 0.058036099928127624, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048772205099080474, 'l1_Layer_2': 0.0007291957184454964, 'l1_Layer_3': 0.0008227435833985475, 'n_units_Layer_1': 245, 'n_units_Layer_2': 245, 'n_units_Layer_3': 240}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 14.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 20.94% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:39:55,476]\u001b[0m Trial 766 finished with value: 4.253585629446547 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006188380221790501, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050592624927828234, 'dropout_rate_Layer_2': 0.08492743864800391, 'dropout_rate_Layer_3': 0.03677334937177883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.839339589356416e-05, 'l1_Layer_2': 0.00187522304770557, 'l1_Layer_3': 5.7263963655890515e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 155, 'n_units_Layer_3': 170}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 13.94% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 21.58% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:40:00,120]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:40:05,070]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:40:23,200]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:40:37,261]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:40:42,245]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:40:47,811]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:40:52,380]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:40:56,007]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:41:15,141]\u001b[0m Trial 777 finished with value: 5.029046866485305 and parameters: {'n_hidden': 3, 'learning_rate': 0.008613441838545385, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0052994270655105724, 'dropout_rate_Layer_2': 0.14575221129367796, 'dropout_rate_Layer_3': 0.3568110717751915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.023084459259386268, 'l1_Layer_2': 0.03700339870392213, 'l1_Layer_3': 7.181214498041378e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 235}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 15.91% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 24.01% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:41:21,692]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:41:26,539]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:41:30,436]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:41:35,631]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:41:38,887]\u001b[0m Trial 765 finished with value: 4.4431673786515855 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006440090474860916, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21714232227500813, 'dropout_rate_Layer_2': 0.014804082610000211, 'dropout_rate_Layer_3': 0.05913977511840453, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007936894530711495, 'l1_Layer_2': 0.0012935665569962858, 'l1_Layer_3': 0.0005947117557782055, 'n_units_Layer_1': 245, 'n_units_Layer_2': 235, 'n_units_Layer_3': 240}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.28% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 22.45% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:41:49,711]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:41:53,662]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:41:58,429]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:41:58,806]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:42:17,695]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:42:22,978]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:42:39,651]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:42:44,559]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:42:48,268]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:42:48,312]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:42:49,236]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:42:51,670]\u001b[0m Trial 782 finished with value: 4.386044081456169 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007086175015909648, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021268227718361777, 'dropout_rate_Layer_2': 0.2398955834810049, 'dropout_rate_Layer_3': 0.020674031564190565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020023914574858275, 'l1_Layer_2': 0.002823726331693636, 'l1_Layer_3': 7.723889947517504e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 185, 'n_units_Layer_3': 145}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 21.69% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:42:58,907]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:42:59,359]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:04,649]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:07,995]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:15,136]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:17,419]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:20,519]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:25,803]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:32,678]\u001b[0m Trial 798 finished with value: 4.839063499688659 and parameters: {'n_hidden': 3, 'learning_rate': 0.008339545324757688, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0011386488634054313, 'dropout_rate_Layer_2': 0.13346212887897774, 'dropout_rate_Layer_3': 0.35562978409116797, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02488477441098556, 'l1_Layer_2': 0.008095519015445642, 'l1_Layer_3': 4.951280428404959e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 15.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.35 | sMAPE for Test Set is: 22.14% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:43:38,163]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:38,803]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:45,281]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:45,415]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:54,767]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:43:57,246]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:44:00,028]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:44:02,476]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:44:15,384]\u001b[0m Trial 807 finished with value: 4.6933154152047925 and parameters: {'n_hidden': 3, 'learning_rate': 0.005618658931265948, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14008891299155374, 'dropout_rate_Layer_2': 0.05372998048102583, 'dropout_rate_Layer_3': 0.2558803110759627, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.252274029542855e-05, 'l1_Layer_2': 0.007742354232719872, 'l1_Layer_3': 0.00377972409405112, 'n_units_Layer_1': 65, 'n_units_Layer_2': 100, 'n_units_Layer_3': 175}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 14.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 26.99% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:44:19,098]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:44:24,115]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:44:35,573]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:44:49,388]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:44:55,234]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:44:56,260]\u001b[0m Trial 793 finished with value: 4.448705867109076 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009078615207519266, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2178051733539009, 'dropout_rate_Layer_2': 0.0075820177722877545, 'dropout_rate_Layer_3': 0.08060368693650503, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004377290637819386, 'l1_Layer_2': 0.0006876670519170718, 'l1_Layer_3': 0.0008159531064416607, 'n_units_Layer_1': 235, 'n_units_Layer_2': 245, 'n_units_Layer_3': 250}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 20.74% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:45:14,342]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:45:40,010]\u001b[0m Trial 820 finished with value: 5.138778780061661 and parameters: {'n_hidden': 3, 'learning_rate': 0.007328290749182173, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008749462677115587, 'dropout_rate_Layer_2': 0.13421649434549948, 'dropout_rate_Layer_3': 0.3162299139375971, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03465366281523889, 'l1_Layer_2': 0.015369146454843712, 'l1_Layer_3': 6.25462293973183e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 16.24% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 21.74% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:45:46,640]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 20.70% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:45:48,138]\u001b[0m Trial 812 finished with value: 4.287906697161038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007085760284236296, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03263200073288501, 'dropout_rate_Layer_2': 0.24628956483681153, 'dropout_rate_Layer_3': 0.0004917863007874636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002365541776870573, 'l1_Layer_2': 0.00190421166160466, 'l1_Layer_3': 9.662557860296226e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 200, 'n_units_Layer_3': 150}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:45:53,200]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:46:21,354]\u001b[0m Trial 824 finished with value: 4.815323595165985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032538544681385783, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1914977285939121, 'dropout_rate_Layer_2': 0.19390605390142687, 'dropout_rate_Layer_3': 0.25468813108688365, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.348960587636922e-05, 'l1_Layer_2': 0.008632795692691842, 'l1_Layer_3': 0.0035916170734726287, 'n_units_Layer_1': 60, 'n_units_Layer_2': 90, 'n_units_Layer_3': 160}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 15.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.32 | sMAPE for Test Set is: 25.85% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:46:34,362]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:46:39,254]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:46:45,774]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:46:52,310]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:47:03,898]\u001b[0m Trial 816 finished with value: 4.474684050136438 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006386040403896052, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1985374473962041, 'dropout_rate_Layer_2': 0.023324641446556396, 'dropout_rate_Layer_3': 0.06625925773382764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006004862035761125, 'l1_Layer_2': 0.0016452621934926483, 'l1_Layer_3': 0.0013222412809792952, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 230}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 21.21% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:47:12,072]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:47:19,102]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:47:29,411]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:47:42,622]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:48:14,574]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:48:17,503]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:48:19,761]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:48:24,214]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:48:26,542]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:48:31,582]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:48:35,012]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:48:40,063]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:48:46,725]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:48:51,366]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:48:57,722]\u001b[0m Trial 842 finished with value: 5.134810547366933 and parameters: {'n_hidden': 3, 'learning_rate': 0.00716098009783001, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008607199613694196, 'dropout_rate_Layer_2': 0.13147109709455623, 'dropout_rate_Layer_3': 0.29623901137404873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03732626556494246, 'l1_Layer_2': 0.020802559981295838, 'l1_Layer_3': 1.4662797310283943e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 16.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.27 | sMAPE for Test Set is: 25.29% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:49:01,540]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:49:07,403]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:49:18,508]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:49:25,808]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:49:31,392]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:49:35,943]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 16.04% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 21.92% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:49:38,374]\u001b[0m Trial 848 finished with value: 5.097412388764281 and parameters: {'n_hidden': 3, 'learning_rate': 0.007367280129508066, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01824230210169226, 'dropout_rate_Layer_2': 0.12937186659047692, 'dropout_rate_Layer_3': 0.27753763270764537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.028394051194483207, 'l1_Layer_2': 0.02180181478255557, 'l1_Layer_3': 1.4028084202757443e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:49:42,848]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:01,894]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:06,030]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:09,129]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:13,481]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:15,926]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:17,113]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:22,825]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:27,146]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:30,712]\u001b[0m Trial 834 finished with value: 4.257135372673278 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006773812248260182, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048149150857946035, 'dropout_rate_Layer_2': 0.2430465214897532, 'dropout_rate_Layer_3': 0.009320832601969371, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022359436637495886, 'l1_Layer_2': 0.0013442351046622808, 'l1_Layer_3': 8.09102915651995e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 200, 'n_units_Layer_3': 185}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 14.04% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 22.14% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:50:31,146]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:37,152]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:40,138]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:40,771]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:44,877]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:49,870]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:50:58,960]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:00,467]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:03,319]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:03,951]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:09,082]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:09,865]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:11,742]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:20,482]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:24,685]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:29,808]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:34,678]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:39,783]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:42,024]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:46,532]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:47,054]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:51:53,562]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:00,138]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:07,911]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:13,713]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:17,865]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:21,340]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:24,934]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:27,897]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:29,660]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:34,676]\u001b[0m Trial 868 finished with value: 4.465171092878369 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009808921820761614, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20754619182451756, 'dropout_rate_Layer_2': 0.03063094717501478, 'dropout_rate_Layer_3': 0.1203321415107376, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005073061203831862, 'l1_Layer_2': 0.0008608150515664681, 'l1_Layer_3': 0.0008508184167324948, 'n_units_Layer_1': 245, 'n_units_Layer_2': 225, 'n_units_Layer_3': 245}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 21.27% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:52:43,013]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:45,755]\u001b[0m Trial 891 finished with value: 4.976075516159974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0067309086767859, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02734326851032407, 'dropout_rate_Layer_2': 0.1550583551648445, 'dropout_rate_Layer_3': 0.3137195066566614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.05187622469100193, 'l1_Layer_2': 0.020856801174014006, 'l1_Layer_3': 1.4479150093217008e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 300}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 15.67% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 21.11% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:52:47,798]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:52,634]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:55,773]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:52:56,897]\u001b[0m Trial 893 finished with value: 4.807487005370512 and parameters: {'n_hidden': 3, 'learning_rate': 0.006311348608282273, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027756126361277077, 'dropout_rate_Layer_2': 0.15360731958294813, 'dropout_rate_Layer_3': 0.31503216457011984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.050857209457398404, 'l1_Layer_2': 0.019240030667033402, 'l1_Layer_3': 1.3026730173590796e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 22.82% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:53:05,057]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:53:13,408]\u001b[0m Trial 897 finished with value: 4.931227580595284 and parameters: {'n_hidden': 3, 'learning_rate': 0.00628692550441837, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02903693223482365, 'dropout_rate_Layer_2': 0.15414579507427395, 'dropout_rate_Layer_3': 0.31258828008347667, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.030035860415996263, 'l1_Layer_2': 0.020291899696683737, 'l1_Layer_3': 1.41584573925794e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 15.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 21.87% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:53:21,254]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:53:33,469]\u001b[0m Trial 898 finished with value: 4.798132208672317 and parameters: {'n_hidden': 3, 'learning_rate': 0.007794082322786673, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07450114507336855, 'dropout_rate_Layer_2': 0.011286839164395837, 'dropout_rate_Layer_3': 0.20881419535338136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010789319165264982, 'l1_Layer_2': 0.00484198340098024, 'l1_Layer_3': 0.02068965627319603, 'n_units_Layer_1': 100, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 15.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 24.80% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:53:41,005]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:53:47,242]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:53:54,464]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:53:57,293]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:54:05,484]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:54:23,128]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:54:30,755]\u001b[0m Trial 902 finished with value: 4.337700235872934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010070737612509406, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03694032773976391, 'dropout_rate_Layer_2': 0.22559008589832424, 'dropout_rate_Layer_3': 0.0863512507836552, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004173051839441114, 'l1_Layer_2': 0.0019662841882894942, 'l1_Layer_3': 2.4328461755523562e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 14.18% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 21.48% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:54:31,015]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:54:38,709]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:54:39,115]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:54:45,409]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:54:48,133]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:54:49,619]\u001b[0m Trial 910 finished with value: 5.313862194690846 and parameters: {'n_hidden': 3, 'learning_rate': 0.006297170162984039, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02805343913018507, 'dropout_rate_Layer_2': 0.09852750380686172, 'dropout_rate_Layer_3': 0.29793957927224224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.08374006025408336, 'l1_Layer_2': 0.040531983671726515, 'l1_Layer_3': 1.4439252345772369e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 230, 'n_units_Layer_3': 300}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 16.62% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 23.69% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:54:56,262]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:54:59,426]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:15,628]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:16,513]\u001b[0m Trial 914 finished with value: 5.111678867957778 and parameters: {'n_hidden': 3, 'learning_rate': 0.006430116843496077, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02810464964349156, 'dropout_rate_Layer_2': 0.1492391864831931, 'dropout_rate_Layer_3': 0.29031115280887554, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.07574462737935035, 'l1_Layer_2': 0.04262186782904511, 'l1_Layer_3': 1.5441059890851962e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 250, 'n_units_Layer_3': 300}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:16,547]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 24.87% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:55:25,010]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:25,532]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:27,642]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:35,444]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:39,575]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:45,188]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:45,733]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:49,978]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:53,766]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:55:57,531]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:09,495]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:14,777]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:19,153]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:23,023]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:24,129]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:28,379]\u001b[0m Trial 917 finished with value: 4.26949068605886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009256691839087978, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05247136342637778, 'dropout_rate_Layer_2': 0.2131627468427308, 'dropout_rate_Layer_3': 0.03900808086999588, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003383484561999856, 'l1_Layer_2': 0.0016452536456341125, 'l1_Layer_3': 2.9403989316085738e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 200, 'n_units_Layer_3': 170}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 14.03% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 20.14% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:56:31,330]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:32,035]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:38,636]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:44,470]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:48,904]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:55,283]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:56:59,544]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:02,369]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:06,327]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:08,803]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:14,190]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:17,122]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:21,503]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:22,164]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:26,345]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:27,374]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:34,458]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:34,914]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:35,062]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:42,770]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:43,134]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:50,694]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:57:50,985]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:58:02,415]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:58:03,067]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:58:13,653]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:58:18,782]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:58:28,202]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:58:34,468]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:58:35,706]\u001b[0m Trial 964 finished with value: 5.0648871787744305 and parameters: {'n_hidden': 3, 'learning_rate': 0.006361112134535782, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018431548523225733, 'dropout_rate_Layer_2': 0.18140716619195627, 'dropout_rate_Layer_3': 0.3103254328583033, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.024644780810809425, 'l1_Layer_2': 0.027846845072318074, 'l1_Layer_3': 2.291140384259938e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 16.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 20.51% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:58:40,398]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:58:43,930]\u001b[0m Trial 937 finished with value: 4.404518672161262 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009693060223416534, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2430292530208103, 'dropout_rate_Layer_2': 0.01773384268587352, 'dropout_rate_Layer_3': 0.0418390642223596, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004063795124521267, 'l1_Layer_2': 0.0009940143912355666, 'l1_Layer_3': 0.0007920580695316787, 'n_units_Layer_1': 220, 'n_units_Layer_2': 240, 'n_units_Layer_3': 260}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.21% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.85 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:58:49,565]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:58:52,619]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:58:55,309]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:58:58,698]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:59:03,747]\u001b[0m Trial 967 finished with value: 5.110038373163959 and parameters: {'n_hidden': 3, 'learning_rate': 0.003906274666720089, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024180258907497934, 'dropout_rate_Layer_2': 0.17870416286680432, 'dropout_rate_Layer_3': 0.30885506036397165, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.018186355762467892, 'l1_Layer_2': 0.026365820110606588, 'l1_Layer_3': 2.2911897365897916e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 16.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.64 | sMAPE for Test Set is: 22.72% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 18:59:04,638]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:59:08,597]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:59:09,487]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:59:10,348]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:59:17,063]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:59:21,685]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:59:26,811]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:59:31,827]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:59:33,172]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:59:39,495]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 18:59:55,753]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:00:42,747]\u001b[0m Trial 971 finished with value: 4.264967817973546 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005407794115612764, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027980620666045068, 'dropout_rate_Layer_2': 0.0009353800645811455, 'dropout_rate_Layer_3': 0.03748024445538772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002607248237827927, 'l1_Layer_2': 0.0011108004751589121, 'l1_Layer_3': 0.00010199974294191376, 'n_units_Layer_1': 200, 'n_units_Layer_2': 190, 'n_units_Layer_3': 165}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 18.94% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:01:10,111]\u001b[0m Trial 984 finished with value: 4.403067215261236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014037118086743655, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22684096150360608, 'dropout_rate_Layer_2': 0.029294949974475158, 'dropout_rate_Layer_3': 0.06217989168622206, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009141276297153781, 'l1_Layer_2': 0.0013143280066034951, 'l1_Layer_3': 0.0006392334280835049, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 260}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:01:21,302]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:01:25,427]\u001b[0m Trial 979 finished with value: 4.2481888396265175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006292912231277458, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01123853806931471, 'dropout_rate_Layer_2': 0.19270287868360755, 'dropout_rate_Layer_3': 0.02049662283240552, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00038152356632161014, 'l1_Layer_2': 0.0014573340423870444, 'l1_Layer_3': 0.00011557954028468971, 'n_units_Layer_1': 220, 'n_units_Layer_2': 210, 'n_units_Layer_3': 165}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 14.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 21.82% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:01:26,440]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:01:34,284]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:01:37,189]\u001b[0m Trial 985 finished with value: 4.314909928240145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006097526932975286, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04011564592820677, 'dropout_rate_Layer_2': 0.24090987113557955, 'dropout_rate_Layer_3': 0.0003870880781622014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003150224927024567, 'l1_Layer_2': 0.0008016858887158726, 'l1_Layer_3': 0.00014428571718813477, 'n_units_Layer_1': 220, 'n_units_Layer_2': 185, 'n_units_Layer_3': 165}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 14.26% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 23.66% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:01:38,031]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:02:55,622]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:03:04,747]\u001b[0m Trial 991 finished with value: 4.295448937068314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005455150556820425, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006995946323405142, 'dropout_rate_Layer_2': 0.004394112599522665, 'dropout_rate_Layer_3': 0.03855776843064643, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033805460608498126, 'l1_Layer_2': 0.0010309939637360415, 'l1_Layer_3': 1.8239609919754153e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 180, 'n_units_Layer_3': 165}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 21.21% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:03:07,488]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:03:13,771]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:03:18,118]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:03:25,486]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:03:46,508]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:04:00,536]\u001b[0m Trial 1000 finished with value: 5.22804075315678 and parameters: {'n_hidden': 3, 'learning_rate': 0.011703925347089921, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010927603109151956, 'dropout_rate_Layer_2': 0.15220804133109925, 'dropout_rate_Layer_3': 0.3185185477556511, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.024017368345923846, 'l1_Layer_2': 0.017569995972921946, 'l1_Layer_3': 1.9233395520206373e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 16.53% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 23.21% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:04:29,276]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:04:47,149]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:04:48,495]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:06:17,659]\u001b[0m Trial 1002 finished with value: 4.424001911441263 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008085530289063039, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21365652278399025, 'dropout_rate_Layer_2': 0.01034214601699638, 'dropout_rate_Layer_3': 0.07783857124793496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013665150982360048, 'l1_Layer_2': 0.0009747821545511374, 'l1_Layer_3': 0.0005363522776694123, 'n_units_Layer_1': 255, 'n_units_Layer_2': 250, 'n_units_Layer_3': 250}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 14.34% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 22.01% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:06:57,158]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:07:01,397]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:07:06,860]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:07:07,486]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:07:08,784]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:07:40,068]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:08:03,525]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:08:29,209]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:08:38,065]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:08:51,841]\u001b[0m Trial 1006 finished with value: 4.280957533239596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006238449660605223, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026229428591702044, 'dropout_rate_Layer_2': 0.012092824771988878, 'dropout_rate_Layer_3': 0.05020360270897899, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00040971539776630265, 'l1_Layer_2': 0.0010179006600776507, 'l1_Layer_3': 1.8274171082857237e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 205, 'n_units_Layer_3': 175}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 13.96% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 18.83% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:09:01,853]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:09:05,665]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:09:13,043]\u001b[0m Trial 1009 finished with value: 4.2397818653594905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005205250436520387, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02966020140491875, 'dropout_rate_Layer_2': 0.009738333905561645, 'dropout_rate_Layer_3': 0.02904902019265862, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017983646791355236, 'l1_Layer_2': 0.001060495348663638, 'l1_Layer_3': 2.0170086679399046e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 190, 'n_units_Layer_3': 115}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 13.93% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:09:17,053]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:09:22,645]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:09:29,241]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:10:05,548]\u001b[0m Trial 1012 finished with value: 4.278376649999628 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006323092437764853, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03804318129107914, 'dropout_rate_Layer_2': 0.004373982755041693, 'dropout_rate_Layer_3': 0.013919845094473119, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00043258098256923096, 'l1_Layer_2': 0.0006837399469503779, 'l1_Layer_3': 1.7504372571166373e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 190, 'n_units_Layer_3': 160}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 24.10% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:10:14,174]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:10:24,636]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:10:31,257]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:10:49,092]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:11:03,823]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:11:07,946]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:11:13,606]\u001b[0m Trial 1020 finished with value: 4.269317923049743 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005935123865256674, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03705002676835034, 'dropout_rate_Layer_2': 0.026716593259341486, 'dropout_rate_Layer_3': 0.035780772237385294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001377268786039962, 'l1_Layer_2': 0.0007837024854357446, 'l1_Layer_3': 1.9662645513114846e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 210, 'n_units_Layer_3': 185}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 14.03% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:11:19,018]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:11:22,567]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:11:29,437]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:11:42,829]\u001b[0m Trial 1021 finished with value: 4.425094001813197 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008065037651229704, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22063070243217794, 'dropout_rate_Layer_2': 0.007459921013414169, 'dropout_rate_Layer_3': 0.07766475155720909, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007357050417464923, 'l1_Layer_2': 0.0011622740116861061, 'l1_Layer_3': 0.0007866721026331268, 'n_units_Layer_1': 240, 'n_units_Layer_2': 245, 'n_units_Layer_3': 245}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 14.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 19.93% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:11:48,093]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:11:57,643]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:11:58,936]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:12:05,965]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:12:42,508]\u001b[0m Trial 1036 finished with value: 4.680266227913081 and parameters: {'n_hidden': 3, 'learning_rate': 0.007877083933613435, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035325112886410534, 'dropout_rate_Layer_2': 0.00990998955692127, 'dropout_rate_Layer_3': 0.20784110490419522, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010008629149327443, 'l1_Layer_2': 0.00428456915834877, 'l1_Layer_3': 0.022753286802497694, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 185}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 14.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 24.75% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:13:05,492]\u001b[0m Trial 1032 finished with value: 4.385224728599829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008522012504642722, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2107065410559222, 'dropout_rate_Layer_2': 0.037116247224265424, 'dropout_rate_Layer_3': 0.06471104069469064, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006254353170740342, 'l1_Layer_2': 0.001050293241932281, 'l1_Layer_3': 0.0013486148957158792, 'n_units_Layer_1': 235, 'n_units_Layer_2': 255, 'n_units_Layer_3': 250}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 21.18% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:13:09,603]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:13:13,366]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:13:20,015]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:13:23,658]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:13:26,485]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:13:35,550]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:13:42,508]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:13:56,266]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:14:03,174]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:14:07,887]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:14:08,179]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:14:20,003]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:14:23,725]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:14:35,812]\u001b[0m Trial 1049 finished with value: 4.863670081093326 and parameters: {'n_hidden': 3, 'learning_rate': 0.007476790986949285, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.037221607179438766, 'dropout_rate_Layer_2': 0.03532081531418561, 'dropout_rate_Layer_3': 0.20656964234549627, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.644888327148804e-05, 'l1_Layer_2': 0.007846993757739893, 'l1_Layer_3': 0.036070991002690664, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 200}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 15.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 24.83% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:15:01,984]\u001b[0m Trial 1053 finished with value: 4.884925350543508 and parameters: {'n_hidden': 3, 'learning_rate': 0.008837197557677381, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00657159611985117, 'dropout_rate_Layer_2': 0.02325785515382769, 'dropout_rate_Layer_3': 0.2697807882200077, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.943460681528201e-05, 'l1_Layer_2': 0.003967820032809106, 'l1_Layer_3': 0.06542691292394463, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 185}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 15.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 24.47% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:15:06,386]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:15:14,941]\u001b[0m Trial 1037 finished with value: 4.442504270711647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005899825590271677, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22836072914203853, 'dropout_rate_Layer_2': 0.012270243234380694, 'dropout_rate_Layer_3': 0.08859879517587406, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006803564084292335, 'l1_Layer_2': 0.0017121404516927913, 'l1_Layer_3': 0.0012405216398603367, 'n_units_Layer_1': 235, 'n_units_Layer_2': 245, 'n_units_Layer_3': 250}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 21.52% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:15:24,676]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:15:27,862]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:15:34,422]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:15:41,179]\u001b[0m Trial 1043 finished with value: 4.508136484926806 and parameters: {'n_hidden': 3, 'learning_rate': 0.000584815754645046, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045442517515474956, 'dropout_rate_Layer_2': 0.0139349358745181, 'dropout_rate_Layer_3': 0.027889609731009533, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002048738545161338, 'l1_Layer_2': 0.0010054981990328031, 'l1_Layer_3': 2.1433286891945675e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 220, 'n_units_Layer_3': 100}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 14.58% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 22.32% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:15:46,761]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:15:47,734]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:15:55,081]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:15:56,386]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:16:04,326]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:16:10,909]\u001b[0m Trial 1052 finished with value: 4.253447574405364 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006593533333136387, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01616172120112473, 'dropout_rate_Layer_2': 0.02692718606471823, 'dropout_rate_Layer_3': 0.011531677561137755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002714536685452973, 'l1_Layer_2': 0.0011905600976177448, 'l1_Layer_3': 1.9974733304759697e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 190, 'n_units_Layer_3': 175}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.16 | sMAPE for Test Set is: 18.80% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:16:23,101]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:16:29,853]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:16:34,324]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:16:45,088]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:17:20,407]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:17:26,734]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:17:40,190]\u001b[0m Trial 1067 finished with value: 4.368993155406008 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006060971223953879, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014241010981981328, 'dropout_rate_Layer_2': 0.040457583813551176, 'dropout_rate_Layer_3': 0.017308099114457867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002555294300818394, 'l1_Layer_2': 0.0009792771188810005, 'l1_Layer_3': 1.56336247466985e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 22.15% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:17:46,275]\u001b[0m Trial 1072 finished with value: 4.906983656408179 and parameters: {'n_hidden': 3, 'learning_rate': 0.006446264391323573, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031127860798393546, 'dropout_rate_Layer_2': 0.14341466602961678, 'dropout_rate_Layer_3': 0.3570732654730463, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.049459454208970396, 'l1_Layer_2': 0.033046814728965535, 'l1_Layer_3': 4.741494918174293e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 250, 'n_units_Layer_3': 290}. Best is trial 493 with value: 4.225406229564819.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 15.60% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 20.69% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:17:53,432]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:17:56,811]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:18:44,593]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:19:18,813]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:19:19,843]\u001b[0m Trial 1074 finished with value: 4.205292755085247 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006946104330346984, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02331132259836583, 'dropout_rate_Layer_2': 0.035207761001586596, 'dropout_rate_Layer_3': 0.011052819105575915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001707725131336776, 'l1_Layer_2': 0.001204622731039339, 'l1_Layer_3': 2.4444934276843883e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 185}. Best is trial 1074 with value: 4.205292755085247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 13.80% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 18.74% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:19:46,825]\u001b[0m Trial 1075 finished with value: 4.256329033336772 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006761117449195717, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021659029375587346, 'dropout_rate_Layer_2': 0.03438385321985211, 'dropout_rate_Layer_3': 0.007828507993500095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016618125676853094, 'l1_Layer_2': 0.0012078073203429511, 'l1_Layer_3': 2.3793162824465317e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 185}. Best is trial 1074 with value: 4.205292755085247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 13.92% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 19.23% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:20:09,656]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:21:12,625]\u001b[0m Trial 1077 finished with value: 4.364290143321763 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006996887178862647, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2080059607146471, 'dropout_rate_Layer_2': 0.02856862388457528, 'dropout_rate_Layer_3': 0.06364848009040093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009991642973975817, 'l1_Layer_2': 0.0010029624594360615, 'l1_Layer_3': 0.0006027525634625243, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245}. Best is trial 1074 with value: 4.205292755085247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 14.10% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 22.24% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:21:19,005]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:21:35,103]\u001b[0m Trial 1080 finished with value: 4.2179229448384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006850380452135316, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005129291728273415, 'dropout_rate_Layer_2': 0.048586509777047995, 'dropout_rate_Layer_3': 0.022753166936867027, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014275863148025325, 'l1_Layer_2': 0.0014598398112897254, 'l1_Layer_3': 2.6584543660930688e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 90, 'n_units_Layer_3': 185}. Best is trial 1074 with value: 4.205292755085247.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 13.80% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 18.60% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:21:38,612]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:21:41,231]\u001b[0m Trial 1078 finished with value: 4.186746796151377 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005632645831497545, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019938621345080634, 'dropout_rate_Layer_2': 0.036992000983262045, 'dropout_rate_Layer_3': 0.02391578001311129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011688001472554876, 'l1_Layer_2': 0.0013338389443998111, 'l1_Layer_3': 2.858058673847006e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 110, 'n_units_Layer_3': 185}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 19.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:21:45,074]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:21:48,869]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:21:54,887]\u001b[0m Trial 1081 finished with value: 4.298366358777998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005500359501085992, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011135627343693874, 'dropout_rate_Layer_2': 0.04373908556849199, 'dropout_rate_Layer_3': 0.013742928399443983, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014740289323345536, 'l1_Layer_2': 0.0012845156870773557, 'l1_Layer_3': 2.2277862709083767e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 55, 'n_units_Layer_3': 180}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 19.37% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:22:00,453]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:22:06,970]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:22:10,134]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:22:46,896]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:22:51,650]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:22:57,289]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:23:02,650]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:23:16,576]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:24:01,330]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:24:10,261]\u001b[0m Trial 1090 finished with value: 4.253514178738247 and parameters: {'n_hidden': 3, 'learning_rate': 0.000539913774626252, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0008509887856992283, 'dropout_rate_Layer_2': 0.04606764098091215, 'dropout_rate_Layer_3': 0.016831652695962648, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011636973044855576, 'l1_Layer_2': 0.0014225499971127573, 'l1_Layer_3': 2.402641559229866e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 50, 'n_units_Layer_3': 180}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 19.39% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:24:41,761]\u001b[0m Trial 1094 finished with value: 4.208375427769827 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005050680475485649, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0012061339830974488, 'dropout_rate_Layer_2': 0.03691107814112325, 'dropout_rate_Layer_3': 0.017085179727360067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001023151329840331, 'l1_Layer_2': 0.001189976364261936, 'l1_Layer_3': 2.4342979921712898e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 19.12% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:24:56,972]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:25:12,587]\u001b[0m Trial 1098 finished with value: 4.608288718046867 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007513156909210209, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2040833863155195, 'dropout_rate_Layer_2': 0.02321236592832767, 'dropout_rate_Layer_3': 0.05290074149943659, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011877967928607027, 'l1_Layer_2': 0.0007714436586231981, 'l1_Layer_3': 0.0006618342741147126, 'n_units_Layer_1': 245, 'n_units_Layer_2': 260, 'n_units_Layer_3': 235}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 14.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 22.29% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:25:13,091]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:25:26,530]\u001b[0m Trial 1103 finished with value: 5.200037993931904 and parameters: {'n_hidden': 3, 'learning_rate': 0.005150970195834248, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01554531988485764, 'dropout_rate_Layer_2': 0.1728575852805603, 'dropout_rate_Layer_3': 0.3454678053498836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.052886751321782145, 'l1_Layer_2': 0.03697352115874264, 'l1_Layer_3': 3.497962217580463e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 240, 'n_units_Layer_3': 300}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 16.34% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.29 | sMAPE for Test Set is: 25.30% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:25:32,664]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:25:34,933]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:25:44,463]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:26:11,903]\u001b[0m Trial 1099 finished with value: 4.273679955994617 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007130729962890476, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01550482250013649, 'dropout_rate_Layer_2': 0.03620970084048146, 'dropout_rate_Layer_3': 0.02549134489483669, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.765484068562815e-05, 'l1_Layer_2': 0.0015558702459720786, 'l1_Layer_3': 3.2371796074255594e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 110, 'n_units_Layer_3': 190}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 19.37% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:26:24,626]\u001b[0m Trial 1100 finished with value: 4.535596125587627 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007389533304897069, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20541055677729914, 'dropout_rate_Layer_2': 0.022785727722431353, 'dropout_rate_Layer_3': 0.10353487549976365, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011807658832731769, 'l1_Layer_2': 0.0007514607696529635, 'l1_Layer_3': 0.0006795132934312919, 'n_units_Layer_1': 245, 'n_units_Layer_2': 260, 'n_units_Layer_3': 235}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 22.62% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:26:40,698]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:26:46,334]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:26:48,613]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:26:53,133]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:26:54,413]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:27:02,195]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:27:09,520]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:27:17,428]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:27:30,060]\u001b[0m Trial 1109 finished with value: 4.463049100191234 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006273563836540512, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.062444423879378756, 'dropout_rate_Layer_2': 0.0006767752677661514, 'dropout_rate_Layer_3': 0.1996777561934484, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009177028376316668, 'l1_Layer_2': 0.0030297922316822193, 'l1_Layer_3': 0.0029564504202800445, 'n_units_Layer_1': 75, 'n_units_Layer_2': 55, 'n_units_Layer_3': 250}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 20.43% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:28:21,531]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:28:25,827]\u001b[0m Trial 1113 finished with value: 4.6420126635579875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006538027073697518, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20842289629350316, 'dropout_rate_Layer_2': 0.01343477198823587, 'dropout_rate_Layer_3': 0.11985870938646101, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019260825038639705, 'l1_Layer_2': 0.0007721219264425559, 'l1_Layer_3': 0.0004484380189689937, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 240}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 14.89% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.43 | sMAPE for Test Set is: 22.84% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:28:27,613]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 21.20% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:28:28,813]\u001b[0m Trial 1118 finished with value: 4.551801692435251 and parameters: {'n_hidden': 3, 'learning_rate': 0.005709383120378482, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08654359111743698, 'dropout_rate_Layer_2': 0.18221131371324306, 'dropout_rate_Layer_3': 0.32743662771874676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0014569483681359928, 'l1_Layer_2': 0.018544907105945568, 'l1_Layer_3': 1.3628154674395217e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 270, 'n_units_Layer_3': 270}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:28:35,318]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:28:39,823]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:28:39,962]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:28:47,490]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:28:52,029]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:29:03,684]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:29:16,872]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:29:24,837]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:29:30,263]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:29:42,976]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:29:47,034]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:29:50,293]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:29:54,097]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:29:58,927]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:29:59,250]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:05,794]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:06,462]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 13.68% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 4.13 | sMAPE for Test Set is: 18.55% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:30:10,782]\u001b[0m Trial 1116 finished with value: 4.189654947981599 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005753249598805482, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00043960785699825866, 'dropout_rate_Layer_2': 0.0264973617707956, 'dropout_rate_Layer_3': 0.02406311978948231, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.710145425918813e-05, 'l1_Layer_2': 0.0008834325576121029, 'l1_Layer_3': 2.1003484390431525e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 190}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:13,647]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:14,091]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:18,367]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:24,276]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:25,476]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:28,517]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:32,000]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:38,343]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:38,776]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:46,262]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:30:55,151]\u001b[0m Trial 1127 finished with value: 4.240370769920296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006208554821982229, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01755870010336247, 'dropout_rate_Layer_2': 0.034744013001278704, 'dropout_rate_Layer_3': 0.01451546752398427, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012309002300671374, 'l1_Layer_2': 0.001435272130125839, 'l1_Layer_3': 1.7916791975369782e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 110, 'n_units_Layer_3': 170}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 13.86% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 20.07% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:30:55,653]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:31:02,540]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:31:03,249]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:31:06,238]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:31:11,391]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:32:09,601]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:32:10,229]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:32:12,408]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:32:16,256]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:32:21,799]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:32:24,190]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:32:27,104]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:32:28,028]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:32:34,779]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:32:37,848]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:32:45,339]\u001b[0m Trial 1153 finished with value: 4.679824430400878 and parameters: {'n_hidden': 3, 'learning_rate': 0.000689886720230672, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22016999465545806, 'dropout_rate_Layer_2': 0.009301749630989231, 'dropout_rate_Layer_3': 0.09117049533716613, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015731860050241563, 'l1_Layer_2': 0.0011208946973032337, 'l1_Layer_3': 0.0008205092473654272, 'n_units_Layer_1': 255, 'n_units_Layer_2': 255, 'n_units_Layer_3': 185}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 15.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 21.93% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:33:00,771]\u001b[0m Trial 1167 finished with value: 5.18434903055818 and parameters: {'n_hidden': 3, 'learning_rate': 0.008516267433097469, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00763863108316995, 'dropout_rate_Layer_2': 0.13278943843532992, 'dropout_rate_Layer_3': 0.36460372805009567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.02302199940163628, 'l1_Layer_2': 0.02390589477955846, 'l1_Layer_3': 7.447319586119078e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 16.30% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 21.49% | rMAE for Test Set is: 0.72\n",
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 21.93% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:33:54,120]\u001b[0m Trial 1165 finished with value: 4.551709497125899 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007675710419733719, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21064037269432534, 'dropout_rate_Layer_2': 0.03807391790689063, 'dropout_rate_Layer_3': 0.04702784199381088, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009195518026062106, 'l1_Layer_2': 0.001414093701915506, 'l1_Layer_3': 0.00042098292350131885, 'n_units_Layer_1': 255, 'n_units_Layer_2': 255, 'n_units_Layer_3': 250}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:34:00,446]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:34:10,153]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:34:13,391]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:34:23,020]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:34:30,355]\u001b[0m Trial 1171 finished with value: 4.933854143481903 and parameters: {'n_hidden': 3, 'learning_rate': 0.007884739581896245, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006016716830277496, 'dropout_rate_Layer_2': 0.13311671228712355, 'dropout_rate_Layer_3': 0.2760071442427544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.028702749095925476, 'l1_Layer_2': 0.011174331104921215, 'l1_Layer_3': 8.996936387848066e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 15.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 21.53% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:34:38,064]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:34:38,098]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:34:44,267]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:34:50,992]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:35:00,937]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:35:07,993]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:35:10,499]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:35:15,339]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:35:22,363]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:35:25,778]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:35:30,351]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:35:30,759]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:36:05,685]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:36:09,437]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:36:23,256]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:36:26,952]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:36:30,317]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:36:33,870]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:36:44,775]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:37:03,379]\u001b[0m Trial 1186 finished with value: 4.24253464411077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005781657377649727, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020983330735349956, 'dropout_rate_Layer_2': 0.029108340405097285, 'dropout_rate_Layer_3': 0.019377825471285696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017410737552100487, 'l1_Layer_2': 0.0007891281719702901, 'l1_Layer_3': 3.016243322830041e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 105, 'n_units_Layer_3': 190}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:37:07,584]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:37:20,179]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:38:36,355]\u001b[0m Trial 1193 finished with value: 4.43713275019905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005419448492038785, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17975463225872276, 'dropout_rate_Layer_2': 0.033922587935562534, 'dropout_rate_Layer_3': 0.07573916461872095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007729480845919524, 'l1_Layer_2': 0.0015116181551423598, 'l1_Layer_3': 0.0007045849657629293, 'n_units_Layer_1': 235, 'n_units_Layer_2': 250, 'n_units_Layer_3': 170}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.26% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 21.21% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:38:38,171]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:38:45,930]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:38:50,201]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:39:11,218]\u001b[0m Trial 1200 finished with value: 5.304980362052135 and parameters: {'n_hidden': 3, 'learning_rate': 0.007136305484039087, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0071126241951984664, 'dropout_rate_Layer_2': 0.1358217384745568, 'dropout_rate_Layer_3': 0.3104660925528878, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.03853625922983592, 'l1_Layer_2': 0.03537076945572865, 'l1_Layer_3': 5.429623720852983e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 240, 'n_units_Layer_3': 265}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 16.46% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.06 | sMAPE for Test Set is: 30.76% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:39:14,204]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:39:24,915]\u001b[0m Trial 1195 finished with value: 4.24810118952277 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005618832079113772, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0218287036706246, 'dropout_rate_Layer_2': 0.03281005065154015, 'dropout_rate_Layer_3': 0.022245177788103157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012548166844517043, 'l1_Layer_2': 0.0007359877485132475, 'l1_Layer_3': 3.884920838125389e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 105, 'n_units_Layer_3': 190}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 13.87% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 19.21% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:39:30,963]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:39:36,437]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:39:43,046]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:39:51,924]\u001b[0m Trial 1196 finished with value: 4.237315864286054 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005642758780864517, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02246852125972895, 'dropout_rate_Layer_2': 0.04995964150604652, 'dropout_rate_Layer_3': 0.2775244191173435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001363929939369096, 'l1_Layer_2': 0.0005852493841729576, 'l1_Layer_3': 3.995355022116267e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 185}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 13.86% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 19.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:39:55,784]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:40:01,518]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:40:07,598]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:40:27,635]\u001b[0m Trial 1199 finished with value: 4.2649592958426785 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005482886776386523, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0007373320468127761, 'dropout_rate_Layer_2': 0.03177855898230495, 'dropout_rate_Layer_3': 0.27504221323545364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012720335719305795, 'l1_Layer_2': 0.0005550715182404227, 'l1_Layer_3': 2.8153931414283408e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 190}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 18.72% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:40:48,645]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:40:55,608]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:40:58,564]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:41:05,391]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:41:11,132]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:41:15,351]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:41:21,204]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:41:24,864]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:41:30,477]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:41:34,221]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:41:39,708]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:41:41,088]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:41:51,087]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:41:56,478]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:01,898]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:07,876]\u001b[0m Trial 1223 finished with value: 5.106133089442937 and parameters: {'n_hidden': 3, 'learning_rate': 0.007841383858693717, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1256165361202573, 'dropout_rate_Layer_2': 0.17123619158190745, 'dropout_rate_Layer_3': 0.33377770778912835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.012710806777853415, 'l1_Layer_2': 0.058087333329535265, 'l1_Layer_3': 1.8098089623794055e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 16.02% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 26.73% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:42:08,554]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:17,040]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:20,630]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:21,672]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:22,029]\u001b[0m Trial 1205 finished with value: 4.419191532348122 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005208525257295646, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1799413417862531, 'dropout_rate_Layer_2': 0.032448304003463255, 'dropout_rate_Layer_3': 0.08185181919133629, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012736194053170147, 'l1_Layer_2': 0.0022012883250381227, 'l1_Layer_3': 0.0006477780223643793, 'n_units_Layer_1': 250, 'n_units_Layer_2': 230, 'n_units_Layer_3': 235}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 14.28% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 23.02% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:42:25,306]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:34,854]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:38,595]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:41,651]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:45,350]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:53,559]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:42:57,694]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:43:06,721]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:43:13,614]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:43:18,950]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:44:18,545]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:44:28,040]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:44:35,756]\u001b[0m Trial 1231 finished with value: 4.237412642456134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006156545084110306, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005542762217865434, 'dropout_rate_Layer_2': 0.025375844036199805, 'dropout_rate_Layer_3': 0.010126255910674422, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015901527635200701, 'l1_Layer_2': 0.000606780005828916, 'l1_Layer_3': 2.1647998337489976e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 110, 'n_units_Layer_3': 185}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.12 | sMAPE for Test Set is: 18.89% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:44:52,468]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:45:06,940]\u001b[0m Trial 1236 finished with value: 4.392152025424485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005011131213488084, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17211313542439832, 'dropout_rate_Layer_2': 0.01970744669313364, 'dropout_rate_Layer_3': 0.07407841110016643, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014318873092861446, 'l1_Layer_2': 0.000991511706036657, 'l1_Layer_3': 0.000369783994958533, 'n_units_Layer_1': 245, 'n_units_Layer_2': 225, 'n_units_Layer_3': 240}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 21.10% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:45:14,444]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:45:19,778]\u001b[0m Trial 1232 finished with value: 4.34688961784378 and parameters: {'n_hidden': 3, 'learning_rate': 0.000507543752596901, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15983611171844098, 'dropout_rate_Layer_2': 0.020977968635125823, 'dropout_rate_Layer_3': 0.0770944298433077, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010377192048980075, 'l1_Layer_2': 0.0015320829693572784, 'l1_Layer_3': 0.0004974524039160147, 'n_units_Layer_1': 245, 'n_units_Layer_2': 230, 'n_units_Layer_3': 245}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 14.03% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 23.28% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:45:20,035]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:45:25,576]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:45:35,922]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:45:52,579]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:46:03,475]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:46:08,231]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:46:16,822]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:46:19,529]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:46:24,042]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:47:04,903]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:47:11,564]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:47:14,751]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:47:25,602]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:47:37,916]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:47:43,783]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:47:49,624]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:48:08,263]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:48:09,030]\u001b[0m Trial 1250 finished with value: 4.252101207566994 and parameters: {'n_hidden': 3, 'learning_rate': 0.000500767003136684, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009069015418087599, 'dropout_rate_Layer_2': 0.0466673068073829, 'dropout_rate_Layer_3': 0.01953399774143094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013701652398480143, 'l1_Layer_2': 0.0007942010457892075, 'l1_Layer_3': 2.074919641339094e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 110, 'n_units_Layer_3': 185}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 19.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:48:19,516]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:48:27,138]\u001b[0m Trial 1266 finished with value: 5.208175080115569 and parameters: {'n_hidden': 3, 'learning_rate': 0.00909757246250571, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17042707858944267, 'dropout_rate_Layer_2': 0.18347697943772642, 'dropout_rate_Layer_3': 0.24072364630672505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.01939015101055777, 'l1_Layer_2': 0.025334915860991698, 'l1_Layer_3': 1.2691105403401401e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 260, 'n_units_Layer_3': 300}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 16.16% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 24.44% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:48:29,252]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:48:33,761]\u001b[0m Trial 1256 finished with value: 4.3792709336263345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005131006460335382, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15815176403376918, 'dropout_rate_Layer_2': 0.02991398899809993, 'dropout_rate_Layer_3': 0.07751598706598956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000599193360139257, 'l1_Layer_2': 0.0021766816713472224, 'l1_Layer_3': 0.00033993351093141247, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 225}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 20.28% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:48:35,610]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:48:39,902]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:48:42,202]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:48:52,344]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:49:01,336]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:49:47,612]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:50:32,264]\u001b[0m Trial 1272 finished with value: 4.434045783009943 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005065598960653196, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012895064763666794, 'dropout_rate_Layer_2': 0.1516184531471445, 'dropout_rate_Layer_3': 0.00765912153667557, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001418093692603791, 'l1_Layer_2': 0.0007458681093332366, 'l1_Layer_3': 1.631748648733779e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 115, 'n_units_Layer_3': 185}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 21.36% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:50:38,570]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:50:42,725]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:50:47,451]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:50:50,458]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:50:53,585]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:50:57,550]\u001b[0m Trial 1269 finished with value: 4.199333722665767 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005094493270271153, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00621827437829151, 'dropout_rate_Layer_2': 0.06724104589895935, 'dropout_rate_Layer_3': 0.007078016573596346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001396101848224974, 'l1_Layer_2': 0.0008097488101071428, 'l1_Layer_3': 1.8696529607894044e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 13.72% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.24 | sMAPE for Test Set is: 19.09% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:51:02,057]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:51:07,591]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:51:13,084]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:51:17,444]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:51:22,635]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:51:31,900]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:51:54,575]\u001b[0m Trial 1277 finished with value: 4.396061619305689 and parameters: {'n_hidden': 3, 'learning_rate': 0.000589828312153978, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12827636273937026, 'dropout_rate_Layer_2': 0.01580123745127903, 'dropout_rate_Layer_3': 0.0856738382403157, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007615530093051253, 'l1_Layer_2': 0.002641058395606189, 'l1_Layer_3': 0.00030735255889069744, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 230}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:52:29,489]\u001b[0m Trial 1283 finished with value: 4.427713842885621 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006031400335638628, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15924848564245533, 'dropout_rate_Layer_2': 0.01585074454148795, 'dropout_rate_Layer_3': 0.0847659324228386, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037824174153325063, 'l1_Layer_2': 0.0023605248920888756, 'l1_Layer_3': 0.00030886262857421446, 'n_units_Layer_1': 250, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:52:29,992]\u001b[0m Trial 1291 finished with value: 4.892285956426263 and parameters: {'n_hidden': 3, 'learning_rate': 0.007681211772204737, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1187824607161439, 'dropout_rate_Layer_2': 0.011202887209723102, 'dropout_rate_Layer_3': 0.21546115378154754, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.144500119194827e-05, 'l1_Layer_2': 0.005065523613111006, 'l1_Layer_3': 0.016556548021847063, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 180}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 15.45% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 27.49% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:53:18,051]\u001b[0m Trial 1289 finished with value: 4.289352685044653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006057738424293186, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017613390250612662, 'dropout_rate_Layer_2': 0.05215875796232411, 'dropout_rate_Layer_3': 0.012492583931137634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6884868350542706e-05, 'l1_Layer_2': 0.0007898147611482985, 'l1_Layer_3': 1.9474598312106318e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 50, 'n_units_Layer_3': 190}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 14.18% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 25.52% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:53:33,814]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:53:40,946]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:53:57,271]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:54:05,615]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:54:10,228]\u001b[0m Trial 1292 finished with value: 4.265453881592503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005016667404691901, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017562896579973543, 'dropout_rate_Layer_2': 0.059583995756160496, 'dropout_rate_Layer_3': 0.012277732362283056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011592943036124938, 'l1_Layer_2': 0.0008114842002209101, 'l1_Layer_3': 1.8642956154126736e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 50, 'n_units_Layer_3': 190}. Best is trial 1078 with value: 4.186746796151377.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:54:48,343]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:54:52,057]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:55:22,183]\u001b[0m Trial 1293 finished with value: 4.176056813473086 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005033954133289658, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0004995953211609436, 'dropout_rate_Layer_2': 0.0297627034588607, 'dropout_rate_Layer_3': 0.01253357854455699, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6301199344822386e-05, 'l1_Layer_2': 0.0008375842120008872, 'l1_Layer_3': 1.8320985687832002e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 55, 'n_units_Layer_3': 190}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 13.76% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 19.50% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:55:24,681]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:55:31,545]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:55:34,677]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:55:38,683]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:55:48,428]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:55:52,142]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:55:57,645]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:56:10,530]\u001b[0m Trial 1308 finished with value: 5.048674665229947 and parameters: {'n_hidden': 3, 'learning_rate': 0.008272799015855854, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.059973606237234856, 'dropout_rate_Layer_2': 0.16125820821511003, 'dropout_rate_Layer_3': 0.32171391512617437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.03129943587328001, 'l1_Layer_2': 0.03765835223599794, 'l1_Layer_3': 3.0729980660039065e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 260, 'n_units_Layer_3': 295}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 22.20% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:56:16,771]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:56:23,714]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:56:28,580]\u001b[0m Trial 1303 finished with value: 4.3526367299960755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005011836793177864, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005959581152672035, 'dropout_rate_Layer_2': 0.03287177989278857, 'dropout_rate_Layer_3': 0.0018739080029429424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0582953369690082e-05, 'l1_Layer_2': 0.0010696642098145799, 'l1_Layer_3': 1.1950774015929418e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 55, 'n_units_Layer_3': 200}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 14.08% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 19.49% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:57:59,352]\u001b[0m Trial 1304 finished with value: 4.198661517757208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005030877832750836, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008954467978146913, 'dropout_rate_Layer_2': 0.043446451837537065, 'dropout_rate_Layer_3': 0.00020210722839715187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019357204808233532, 'l1_Layer_2': 0.0004197437987791677, 'l1_Layer_3': 2.341455671201258e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 65, 'n_units_Layer_3': 200}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 13.96% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 20.13% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:58:15,735]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:58:19,182]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:58:23,019]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:58:31,576]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:58:40,729]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:58:49,875]\u001b[0m Trial 1313 finished with value: 4.347646384861883 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005002598333303189, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1584529651506997, 'dropout_rate_Layer_2': 0.028406509261752654, 'dropout_rate_Layer_3': 0.06887372864678738, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007275967232893948, 'l1_Layer_2': 0.0034066802109229788, 'l1_Layer_3': 0.00032321227126278754, 'n_units_Layer_1': 260, 'n_units_Layer_2': 225, 'n_units_Layer_3': 245}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 14.04% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 21.92% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:58:53,340]\u001b[0m Trial 1309 finished with value: 4.367458857043024 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005516609500319527, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15896168379094067, 'dropout_rate_Layer_2': 0.028531031645097273, 'dropout_rate_Layer_3': 0.06820129524379231, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007226709451169272, 'l1_Layer_2': 0.002275068406708352, 'l1_Layer_3': 0.0002730063860635544, 'n_units_Layer_1': 250, 'n_units_Layer_2': 225, 'n_units_Layer_3': 220}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 21.82% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:59:03,256]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:59:03,924]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:59:15,017]\u001b[0m Trial 1319 finished with value: 4.759476219706474 and parameters: {'n_hidden': 3, 'learning_rate': 0.005961770627850654, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10687361373688142, 'dropout_rate_Layer_2': 0.023969679579819627, 'dropout_rate_Layer_3': 0.18397742751097756, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012307222707567795, 'l1_Layer_2': 0.003706285901054843, 'l1_Layer_3': 0.020901559480022838, 'n_units_Layer_1': 120, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 24.46% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 19:59:22,978]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 19:59:35,729]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:00:01,544]\u001b[0m Trial 1326 finished with value: 4.987034237842098 and parameters: {'n_hidden': 3, 'learning_rate': 0.006818531208100311, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02474171138557258, 'dropout_rate_Layer_2': 0.14131744610946678, 'dropout_rate_Layer_3': 0.31383135471820245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0213500409665594, 'l1_Layer_2': 0.03873118566252285, 'l1_Layer_3': 0.0013410165952107865, 'n_units_Layer_1': 110, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 15.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.27 | sMAPE for Test Set is: 25.31% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:00:07,807]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:00:08,783]\u001b[0m Trial 1324 finished with value: 4.331123879518589 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005534109422050253, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008045151568305929, 'dropout_rate_Layer_2': 0.041215492400869, 'dropout_rate_Layer_3': 0.01059582942820004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7447789029884005e-05, 'l1_Layer_2': 0.00032979590268588814, 'l1_Layer_3': 2.630529639630181e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 70, 'n_units_Layer_3': 195}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.60 | sMAPE for Test Set is: 20.46% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:00:15,681]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:00:18,650]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:00:21,948]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:00:28,577]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:00:33,949]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:01:13,431]\u001b[0m Trial 1323 finished with value: 4.425541261001673 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005091795926105645, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13164972931675292, 'dropout_rate_Layer_2': 0.04437244951045199, 'dropout_rate_Layer_3': 0.07887773037595652, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007682540889229089, 'l1_Layer_2': 0.0032903736043726176, 'l1_Layer_3': 0.00025369533204866397, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 220}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 14.29% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:01:15,749]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:01:35,654]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:02:19,998]\u001b[0m Trial 1331 finished with value: 4.361684664162344 and parameters: {'n_hidden': 3, 'learning_rate': 0.000575283384704802, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1267346471061805, 'dropout_rate_Layer_2': 0.029521207008619807, 'dropout_rate_Layer_3': 0.0867871788527338, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007721980571219093, 'l1_Layer_2': 0.0023613810502437923, 'l1_Layer_3': 0.0002725287732570872, 'n_units_Layer_1': 265, 'n_units_Layer_2': 215, 'n_units_Layer_3': 220}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 20.20% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:02:23,442]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:02:30,142]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:02:37,117]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:02:46,613]\u001b[0m Trial 1337 finished with value: 4.296063106929679 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005059672379596473, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014648316923843859, 'dropout_rate_Layer_2': 0.0523058170866478, 'dropout_rate_Layer_3': 0.012621454311000943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019787298258646708, 'l1_Layer_2': 0.000581834535287188, 'l1_Layer_3': 4.297277361115991e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 75}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 19.89% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:02:53,252]\u001b[0m Trial 1336 finished with value: 4.232193428705442 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005017954220999444, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013721205824349728, 'dropout_rate_Layer_2': 0.027131175839067642, 'dropout_rate_Layer_3': 0.011644168856794535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016890288953770239, 'l1_Layer_2': 0.0005714021694370453, 'l1_Layer_3': 4.122278737424404e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 245}. Best is trial 1293 with value: 4.176056813473086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.75 | sMAPE for Test Set is: 25.30% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:02:59,177]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:03:41,570]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:04:47,600]\u001b[0m Trial 1342 finished with value: 4.137716552616484 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006002546097868924, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023621174471269726, 'dropout_rate_Layer_2': 0.027489989977595275, 'dropout_rate_Layer_3': 0.008202685860806583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015206264626565631, 'l1_Layer_2': 0.0007206918248820718, 'l1_Layer_3': 2.4388707056762712e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 190}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 13.67% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 21.67% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:04:58,216]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:05:03,147]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:05:10,455]\u001b[0m Trial 1345 finished with value: 4.299024591627853 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006409262010522691, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014023428951667145, 'dropout_rate_Layer_2': 0.03832599335088052, 'dropout_rate_Layer_3': 0.008160870748914128, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015515566258323714, 'l1_Layer_2': 0.00046220554713574663, 'l1_Layer_3': 2.948833459661767e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 250}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 14.08% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 27.48% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:05:18,676]\u001b[0m Trial 1338 finished with value: 4.222095982063236 and parameters: {'n_hidden': 3, 'learning_rate': 0.000602600647089235, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014218027713639185, 'dropout_rate_Layer_2': 0.028290037452550494, 'dropout_rate_Layer_3': 0.010623092330882591, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019857422074057222, 'l1_Layer_2': 0.0005798061032257219, 'l1_Layer_3': 4.513590373509231e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 55, 'n_units_Layer_3': 190}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:05:21,070]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:05:32,985]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:05:38,643]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:06:03,346]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:06:12,611]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:06:18,883]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:07:02,888]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:07:10,533]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:07:16,347]\u001b[0m Trial 1353 finished with value: 4.233390654048552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005020583231725218, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021749604050360728, 'dropout_rate_Layer_2': 0.027448480935929265, 'dropout_rate_Layer_3': 0.019098756450806366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001969695418912324, 'l1_Layer_2': 0.0005811257101522471, 'l1_Layer_3': 3.957361649143701e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 55, 'n_units_Layer_3': 245}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 14.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.55 | sMAPE for Test Set is: 21.34% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:07:28,793]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:07:38,195]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:07:59,438]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:08:08,339]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:08:08,848]\u001b[0m Trial 1349 finished with value: 4.2394460723174525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006687702092333089, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023360177710015122, 'dropout_rate_Layer_2': 0.017426946370539098, 'dropout_rate_Layer_3': 0.0004611227477567068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7094868419904722e-05, 'l1_Layer_2': 0.0006839093235860604, 'l1_Layer_3': 2.2696571595214354e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 26.34% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:08:25,339]\u001b[0m Trial 1359 finished with value: 4.354602016822871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005055121544019264, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013629431440506627, 'dropout_rate_Layer_2': 0.014536804125336667, 'dropout_rate_Layer_3': 0.023593097652561082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020671332060196105, 'l1_Layer_2': 0.000450762010544322, 'l1_Layer_3': 4.621534080416044e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 55, 'n_units_Layer_3': 240}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.54 | sMAPE for Test Set is: 21.05% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:08:28,692]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:08:36,732]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:08:37,140]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:08:57,361]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:09:05,317]\u001b[0m Trial 1361 finished with value: 4.235444051048527 and parameters: {'n_hidden': 3, 'learning_rate': 0.000510625087452532, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008468886441550241, 'dropout_rate_Layer_2': 0.014911124805874554, 'dropout_rate_Layer_3': 0.026458473614998753, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021403294145258626, 'l1_Layer_2': 0.00046210992116127447, 'l1_Layer_3': 4.525366810235853e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 250}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 13.95% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 20.62% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:09:45,296]\u001b[0m Trial 1368 finished with value: 4.313452985679221 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005049256741344697, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015838823423096563, 'dropout_rate_Layer_2': 0.013981334397868543, 'dropout_rate_Layer_3': 0.012219807937920199, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5591075227583718e-05, 'l1_Layer_2': 0.0003143731552695092, 'l1_Layer_3': 3.6667989794560176e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 250}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 14.34% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 22.49% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:09:46,115]\u001b[0m Trial 1367 finished with value: 4.2899258248035546 and parameters: {'n_hidden': 3, 'learning_rate': 0.000557094918811259, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01632687814829959, 'dropout_rate_Layer_2': 0.014670671447963636, 'dropout_rate_Layer_3': 0.006429492981184396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.551658879382466e-05, 'l1_Layer_2': 0.0005372456450235269, 'l1_Layer_3': 3.5263970040453505e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 250}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.59 | sMAPE for Test Set is: 20.94% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:09:56,025]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:10:01,422]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:10:30,404]\u001b[0m Trial 1369 finished with value: 4.247945436018916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005524421833272443, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015496659780310756, 'dropout_rate_Layer_2': 0.015743458905666828, 'dropout_rate_Layer_3': 0.000409364136406817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4615120165724862e-05, 'l1_Layer_2': 0.0003834440008359069, 'l1_Layer_3': 3.4103768201892535e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 250}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 14.13% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.60 | sMAPE for Test Set is: 21.45% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.57 | sMAPE for Test Set is: 21.21% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:10:44,501]\u001b[0m Trial 1370 finished with value: 4.253313701028904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005006683813142378, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015946338376347992, 'dropout_rate_Layer_2': 0.01852867265124314, 'dropout_rate_Layer_3': 0.012275282140475787, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5072962624499822e-05, 'l1_Layer_2': 0.0003697243891999452, 'l1_Layer_3': 3.8400961834704275e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 250}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:10:55,392]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:11:13,375]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:11:16,594]\u001b[0m Trial 1374 finished with value: 4.327240710546795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005032452147065073, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026333732701306095, 'dropout_rate_Layer_2': 0.012290589505939503, 'dropout_rate_Layer_3': 0.014224240339460119, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022237743850256965, 'l1_Layer_2': 0.00043181563305649346, 'l1_Layer_3': 3.0818676858696555e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.54 | sMAPE for Test Set is: 21.46% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:11:19,956]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:11:27,751]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:11:33,719]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:11:40,996]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:11:57,825]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:12:05,806]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:12:13,664]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:12:21,528]\u001b[0m Trial 1380 finished with value: 4.346479266984614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005675256276430119, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008367111270396011, 'dropout_rate_Layer_2': 0.01055259533110868, 'dropout_rate_Layer_3': 0.0032108837648162723, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0504414747569379e-05, 'l1_Layer_2': 0.0003155335977092367, 'l1_Layer_3': 4.748008751210694e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 260}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.73 | sMAPE for Test Set is: 21.54% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:12:23,605]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:12:29,484]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:12:33,188]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:12:41,096]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:12:46,473]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:12:53,874]\u001b[0m Trial 1389 finished with value: 4.536040630358336 and parameters: {'n_hidden': 3, 'learning_rate': 0.004226442794358613, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1409989044353936, 'dropout_rate_Layer_2': 6.372039376421022e-05, 'dropout_rate_Layer_3': 0.19895399228407165, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013063068717715596, 'l1_Layer_2': 0.0166106119646901, 'l1_Layer_3': 0.0029580605185486643, 'n_units_Layer_1': 115, 'n_units_Layer_2': 100, 'n_units_Layer_3': 155}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 21.21% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:13:05,348]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:13:11,376]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:13:12,154]\u001b[0m Trial 1382 finished with value: 4.2941641818881875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005830976763694725, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007147093017079122, 'dropout_rate_Layer_2': 0.023832198486843488, 'dropout_rate_Layer_3': 0.00041271151865106964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4605668728038015e-05, 'l1_Layer_2': 0.0003637589800543398, 'l1_Layer_3': 3.40706112423873e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 95, 'n_units_Layer_3': 265}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 25.22% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:13:22,740]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:13:24,906]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:13:35,080]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:13:38,034]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:13:38,393]\u001b[0m Trial 1390 finished with value: 4.3279991770839565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006204375019284919, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007117016341467393, 'dropout_rate_Layer_2': 0.015654901564762912, 'dropout_rate_Layer_3': 0.00037419119301626905, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7752748752978044e-05, 'l1_Layer_2': 0.0005000802001948841, 'l1_Layer_3': 3.8445295598776375e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 110, 'n_units_Layer_3': 260}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.75 | sMAPE for Test Set is: 20.83% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:13:46,875]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:13:50,740]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:14:03,550]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:14:26,965]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:14:57,353]\u001b[0m Trial 1404 finished with value: 4.2504307399260055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005604107286752752, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014266919771864138, 'dropout_rate_Layer_2': 0.02891075799429723, 'dropout_rate_Layer_3': 0.01020021845480329, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001446407319436164, 'l1_Layer_2': 0.0005172775702675502, 'l1_Layer_3': 1.6203679948835823e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 100, 'n_units_Layer_3': 250}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:15:25,529]\u001b[0m Trial 1392 finished with value: 4.400497128752025 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005623476492403529, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13868473121451017, 'dropout_rate_Layer_2': 0.021913021790087014, 'dropout_rate_Layer_3': 0.08275687815422626, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008879061359244134, 'l1_Layer_2': 0.002613635214347106, 'l1_Layer_3': 0.0003464289365757725, 'n_units_Layer_1': 275, 'n_units_Layer_2': 220, 'n_units_Layer_3': 240}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 21.48% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:15:47,370]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:16:02,860]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:16:09,082]\u001b[0m Trial 1406 finished with value: 4.492537819130462 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006466779305962018, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1366183360929146, 'dropout_rate_Layer_2': 0.025614587548985823, 'dropout_rate_Layer_3': 0.08112078753310917, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032475203380249995, 'l1_Layer_2': 0.003024038290766732, 'l1_Layer_3': 0.00031900535454704556, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 205}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 21.60% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:16:24,550]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:16:25,446]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:16:51,902]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:17:11,741]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:17:21,626]\u001b[0m Trial 1411 finished with value: 4.285931034818278 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007163373832044759, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00013069249617301653, 'dropout_rate_Layer_2': 0.008984976515997086, 'dropout_rate_Layer_3': 0.008265913276062437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020149497839273977, 'l1_Layer_2': 0.00037254369759559454, 'l1_Layer_3': 1.3349536547265516e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 60, 'n_units_Layer_3': 250}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 20.62% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:17:29,746]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:17:32,337]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:17:33,098]\u001b[0m Trial 1407 finished with value: 4.416403956366998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005604088139843054, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13187589078148265, 'dropout_rate_Layer_2': 0.016649598660300916, 'dropout_rate_Layer_3': 0.08260474482013432, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009370263790512527, 'l1_Layer_2': 0.0028552265397599986, 'l1_Layer_3': 0.000335573886217621, 'n_units_Layer_1': 275, 'n_units_Layer_2': 220, 'n_units_Layer_3': 235}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 14.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 20.57% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:17:40,121]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:17:44,570]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:17:50,050]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:18:07,284]\u001b[0m Trial 1419 finished with value: 4.736138103256901 and parameters: {'n_hidden': 3, 'learning_rate': 0.006962849847830884, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11441281350155103, 'dropout_rate_Layer_2': 0.01913802494793549, 'dropout_rate_Layer_3': 0.19487897362881, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012729491052133614, 'l1_Layer_2': 0.00678556124470466, 'l1_Layer_3': 0.006266546428021538, 'n_units_Layer_1': 125, 'n_units_Layer_2': 80, 'n_units_Layer_3': 160}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 15.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 22.84% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:18:16,128]\u001b[0m Trial 1412 finished with value: 4.272840595557814 and parameters: {'n_hidden': 4, 'learning_rate': 0.00062743169594157, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005063648409143039, 'dropout_rate_Layer_2': 0.009100443007778722, 'dropout_rate_Layer_3': 0.008364797123029873, 'dropout_rate_Layer_4': 0.029056818595598444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017876817647602929, 'l1_Layer_2': 0.0002825091678881782, 'l1_Layer_3': 1.4686587636912942e-05, 'l1_Layer_4': 4.9014813519111974e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 60, 'n_units_Layer_3': 250, 'n_units_Layer_4': 250}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 14.43% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 29.07% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:18:26,051]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:19:14,912]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:19:20,062]\u001b[0m Trial 1421 finished with value: 4.270676345486104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006300139273520664, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00782918979112292, 'dropout_rate_Layer_2': 0.03593888085481644, 'dropout_rate_Layer_3': 0.0151887573944667, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001257108505001395, 'l1_Layer_2': 0.0004918024376071663, 'l1_Layer_3': 1.5234515530763426e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 250}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 14.04% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 21.39% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:19:20,755]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:19:28,809]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:20:13,797]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:21:07,319]\u001b[0m Trial 1423 finished with value: 4.245940917715001 and parameters: {'n_hidden': 3, 'learning_rate': 0.000561000538768693, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015023829391964229, 'dropout_rate_Layer_2': 0.03492425568887296, 'dropout_rate_Layer_3': 0.018012421408314362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012822754432687838, 'l1_Layer_2': 0.00047730113788326873, 'l1_Layer_3': 1.5728753597794233e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 240}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 25.21% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:21:20,839]\u001b[0m Trial 1426 finished with value: 4.20822864973269 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005543906530234377, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019245622900651443, 'dropout_rate_Layer_2': 0.019156329327168584, 'dropout_rate_Layer_3': 0.02471118088018115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015250150932129983, 'l1_Layer_2': 0.0006827667691711835, 'l1_Layer_3': 2.472131833753147e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 13.79% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 20.91% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:21:30,598]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:21:38,646]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:21:50,877]\u001b[0m Trial 1429 finished with value: 4.295464473129207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005498568381916461, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01903969308403738, 'dropout_rate_Layer_2': 0.019705830559523692, 'dropout_rate_Layer_3': 0.01729210901743571, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010676412820026427, 'l1_Layer_2': 0.0004275051969217812, 'l1_Layer_3': 1.0116647509336889e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 240}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 22.59% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:22:08,499]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:22:13,138]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:22:15,702]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:22:26,458]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:22:36,550]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:22:52,098]\u001b[0m Trial 1439 finished with value: 4.9538352452576495 and parameters: {'n_hidden': 3, 'learning_rate': 0.006521462886538154, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02799847203930193, 'dropout_rate_Layer_2': 0.14615520156390008, 'dropout_rate_Layer_3': 0.08233005108094425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0725837878744867, 'l1_Layer_2': 0.042957136311158314, 'l1_Layer_3': 2.0474502812405618e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 15.70% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 20.51% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:23:05,479]\u001b[0m Trial 1432 finished with value: 4.306834445907847 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005418507987040559, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027499881052840944, 'dropout_rate_Layer_2': 0.017592278513822356, 'dropout_rate_Layer_3': 0.03108669344127666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010832513666550892, 'l1_Layer_2': 0.00040689846308484965, 'l1_Layer_3': 2.8971027715345533e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 21.51% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:23:21,625]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:23:33,390]\u001b[0m Trial 1436 finished with value: 4.356900394527759 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005596418275521903, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028433645470233658, 'dropout_rate_Layer_2': 0.008888853135694423, 'dropout_rate_Layer_3': 0.028730435692335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.956229873231164e-05, 'l1_Layer_2': 0.0005964901330538066, 'l1_Layer_3': 3.0475673449996024e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 50, 'n_units_Layer_3': 235}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:23:33,479]\u001b[0m Trial 1442 finished with value: 5.15069543811862 and parameters: {'n_hidden': 3, 'learning_rate': 0.00659780781241222, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01351943457126541, 'dropout_rate_Layer_2': 0.14214639401359647, 'dropout_rate_Layer_3': 0.1968330137015006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.05883344720811307, 'l1_Layer_2': 0.06494599701125932, 'l1_Layer_3': 2.016416390137468e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 21.10% | rMAE for Test Set is: 0.62\n",
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 16.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 21.88% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:23:39,022]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:23:41,953]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:23:49,472]\u001b[0m Trial 1438 finished with value: 4.44188837522013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012802303150214708, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16345555176235296, 'dropout_rate_Layer_2': 0.016828732156188075, 'dropout_rate_Layer_3': 0.16371513427591455, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014225845493211076, 'l1_Layer_2': 0.010292519145477628, 'l1_Layer_3': 0.003641819820554605, 'n_units_Layer_1': 105, 'n_units_Layer_2': 75, 'n_units_Layer_3': 160}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 24.21% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:24:08,001]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:24:17,441]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:24:23,005]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:24:30,577]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:24:30,927]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:24:39,595]\u001b[0m Trial 1444 finished with value: 4.317648269111773 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006753131452501023, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 9.186788818133645e-06, 'dropout_rate_Layer_2': 0.03079205467783512, 'dropout_rate_Layer_3': 0.01630081051141865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001601887444659101, 'l1_Layer_2': 0.0007591387292077427, 'l1_Layer_3': 2.184126717988212e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 20.19% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:24:39,867]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:24:47,649]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:24:47,994]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:24:54,883]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:25:29,449]\u001b[0m Trial 1452 finished with value: 4.499993586682297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012440954945561143, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15033923241845668, 'dropout_rate_Layer_2': 0.0492137643104173, 'dropout_rate_Layer_3': 0.2200764944475849, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.96026664319627e-05, 'l1_Layer_2': 0.019872744285327027, 'l1_Layer_3': 0.0012185082054727418, 'n_units_Layer_1': 90, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 14.54% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 24.76% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:25:47,151]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:25:53,502]\u001b[0m Trial 1456 finished with value: 4.586017568764075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013907792103502105, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15021297390026095, 'dropout_rate_Layer_2': 0.04727887195359376, 'dropout_rate_Layer_3': 0.220082513280718, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.939472482406159e-05, 'l1_Layer_2': 0.026128120516758006, 'l1_Layer_3': 0.002052049807816385, 'n_units_Layer_1': 90, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 14.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 25.65% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:25:59,730]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:26:08,252]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:26:30,803]\u001b[0m Trial 1457 finished with value: 4.282456860440321 and parameters: {'n_hidden': 3, 'learning_rate': 0.000612183144696618, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02908377171560124, 'dropout_rate_Layer_2': 0.0074069460814900675, 'dropout_rate_Layer_3': 0.0245080123914491, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001362703735262924, 'l1_Layer_2': 0.0005979304051368283, 'l1_Layer_3': 1.8663422039244048e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 260}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.97 | sMAPE for Test Set is: 25.85% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:26:33,593]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:26:48,192]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:26:51,692]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:27:00,435]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:27:07,484]\u001b[0m Trial 1465 finished with value: 5.0728639681157235 and parameters: {'n_hidden': 3, 'learning_rate': 0.00758952315021122, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024833535086512565, 'dropout_rate_Layer_2': 0.39790194169979587, 'dropout_rate_Layer_3': 0.0697521553493162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.02926487980220066, 'l1_Layer_2': 0.038517083886172705, 'l1_Layer_3': 3.325844702964225e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 275}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 15.97% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 22.59% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:27:10,705]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:27:19,949]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:27:25,879]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:27:26,550]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:27:34,192]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:27:42,193]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:27:47,534]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:28:01,395]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:28:27,737]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:28:30,896]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:28:33,956]\u001b[0m Trial 1472 finished with value: 4.338362415314165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005541379513495898, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008763947121611512, 'dropout_rate_Layer_2': 0.017045165320645015, 'dropout_rate_Layer_3': 0.007329994757499299, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.63456655201122e-05, 'l1_Layer_2': 0.000492159932366429, 'l1_Layer_3': 2.680429163988004e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 255}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 20.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:28:36,282]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:28:41,786]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:28:47,340]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:28:54,969]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:29:03,194]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:29:25,666]\u001b[0m Trial 1474 finished with value: 4.268385016713604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007385078842095541, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012501103837604569, 'dropout_rate_Layer_2': 0.026885698598594597, 'dropout_rate_Layer_3': 0.2204385094930954, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.296566639053689e-05, 'l1_Layer_2': 0.000671847228254603, 'l1_Layer_3': 2.6323249594446133e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 120, 'n_units_Layer_3': 235}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 21.16% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:29:35,419]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:29:42,212]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:29:47,462]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:30:20,734]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:30:28,350]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:30:40,048]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:30:49,437]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:31:05,010]\u001b[0m Trial 1484 finished with value: 4.345620782045471 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006305146534272374, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02285098699412877, 'dropout_rate_Layer_2': 0.025499678722148263, 'dropout_rate_Layer_3': 0.013176580019363544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017527378212621323, 'l1_Layer_2': 0.0003994260280649299, 'l1_Layer_3': 4.000282486638607e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 120, 'n_units_Layer_3': 235}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 14.34% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 24.02% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:31:12,714]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:31:13,070]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:31:22,530]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:31:33,616]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:31:34,711]\u001b[0m Trial 1495 finished with value: 5.030348178110532 and parameters: {'n_hidden': 3, 'learning_rate': 0.00625604271832284, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014494770773516394, 'dropout_rate_Layer_2': 0.3449397769397331, 'dropout_rate_Layer_3': 0.04967617987242823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.027744093792601728, 'l1_Layer_2': 0.03647435633806378, 'l1_Layer_3': 0.0013970876711182276, 'n_units_Layer_1': 75, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 15.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 20.41% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:32:19,234]\u001b[0m Trial 1496 finished with value: 4.311681343361431 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007273244421572209, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030118672147407592, 'dropout_rate_Layer_2': 0.03233665505051085, 'dropout_rate_Layer_3': 0.024659683298503706, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021955415360997124, 'l1_Layer_2': 0.0007906286977333396, 'l1_Layer_3': 3.143497413773878e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 280}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 13.96% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 20.63% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:32:25,680]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:32:36,236]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 20:32:44,327]\u001b[0m Trial 1480 finished with value: 4.29813300825489 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007192350954679938, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021010078231085225, 'dropout_rate_Layer_2': 0.054772133735911374, 'dropout_rate_Layer_3': 0.011302961807121172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018460570556118723, 'l1_Layer_2': 0.000893190457915522, 'l1_Layer_3': 3.3046284158796586e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 105, 'n_units_Layer_3': 240}. Best is trial 1342 with value: 4.137716552616484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 22.61% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 20:33:10,027]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-01-01, MAE is:3.95 & sMAPE is:11.58% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 11.58% & 0.19\n",
      "for 2020-01-02, MAE is:3.16 & sMAPE is:8.48% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 10.03% & 0.21\n",
      "for 2020-01-03, MAE is:2.97 & sMAPE is:8.71% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 9.59% & 0.36\n",
      "for 2020-01-04, MAE is:3.21 & sMAPE is:9.92% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 9.67% & 0.53\n",
      "for 2020-01-05, MAE is:3.72 & sMAPE is:11.31% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 10.00% & 0.57\n",
      "for 2020-01-06, MAE is:4.00 & sMAPE is:9.91% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 9.98% & 0.62\n",
      "for 2020-01-07, MAE is:4.05 & sMAPE is:9.74% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 9.95% & 0.64\n",
      "for 2020-01-08, MAE is:5.31 & sMAPE is:14.30% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 10.49% & 0.62\n",
      "for 2020-01-09, MAE is:3.92 & sMAPE is:10.95% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 10.54% & 0.66\n",
      "for 2020-01-10, MAE is:6.19 & sMAPE is:18.34% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 11.32% & 0.78\n",
      "for 2020-01-11, MAE is:4.67 & sMAPE is:14.31% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 11.60% & 0.95\n",
      "for 2020-01-12, MAE is:5.13 & sMAPE is:17.32% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 12.07% & 0.93\n",
      "for 2020-01-13, MAE is:5.66 & sMAPE is:14.60% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 12.27% & 0.95\n",
      "for 2020-01-14, MAE is:3.69 & sMAPE is:15.94% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 12.53% & 0.90\n",
      "for 2020-01-15, MAE is:4.28 & sMAPE is:16.13% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 12.77% & 0.88\n",
      "for 2020-01-16, MAE is:6.22 & sMAPE is:18.65% & rMAE is:3.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 13.14% & 1.03\n",
      "for 2020-01-17, MAE is:4.17 & sMAPE is:11.42% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 13.04% & 1.07\n",
      "for 2020-01-18, MAE is:5.84 & sMAPE is:18.65% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 13.35% & 1.15\n",
      "for 2020-01-19, MAE is:3.20 & sMAPE is:9.84% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 13.16% & 1.13\n",
      "for 2020-01-20, MAE is:3.63 & sMAPE is:8.11% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 12.91% & 1.10\n",
      "for 2020-01-21, MAE is:3.04 & sMAPE is:6.29% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 12.60% & 1.05\n",
      "for 2020-01-22, MAE is:3.98 & sMAPE is:8.19% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 12.40% & 1.02\n",
      "for 2020-01-23, MAE is:5.23 & sMAPE is:10.08% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 12.30% & 0.99\n",
      "for 2020-01-24, MAE is:5.07 & sMAPE is:9.71% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 12.19% & 0.96\n",
      "for 2020-01-25, MAE is:2.29 & sMAPE is:5.58% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 11.92% & 0.94\n",
      "for 2020-01-26, MAE is:2.46 & sMAPE is:6.79% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 11.73% & 0.93\n",
      "for 2020-01-27, MAE is:2.38 & sMAPE is:6.43% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 11.53% & 0.91\n",
      "for 2020-01-28, MAE is:3.90 & sMAPE is:10.71% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 11.50% & 0.89\n",
      "for 2020-01-29, MAE is:3.05 & sMAPE is:9.15% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 11.42% & 0.86\n",
      "for 2020-01-30, MAE is:4.18 & sMAPE is:12.29% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 11.45% & 0.84\n",
      "for 2020-01-31, MAE is:3.28 & sMAPE is:11.69% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 11.46% & 0.82\n",
      "for 2020-02-01, MAE is:4.36 & sMAPE is:34.23% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 12.17% & 0.80\n",
      "for 2020-02-02, MAE is:8.18 & sMAPE is:66.73% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 13.82% & 0.80\n",
      "for 2020-02-03, MAE is:5.66 & sMAPE is:44.43% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 14.72% & 0.79\n",
      "for 2020-02-04, MAE is:3.70 & sMAPE is:13.99% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.70% & 0.78\n",
      "for 2020-02-05, MAE is:4.16 & sMAPE is:12.17% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.63% & 0.81\n",
      "for 2020-02-06, MAE is:2.21 & sMAPE is:6.37% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 14.41% & 0.80\n",
      "for 2020-02-07, MAE is:5.06 & sMAPE is:13.96% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 14.40% & 0.81\n",
      "for 2020-02-08, MAE is:2.78 & sMAPE is:9.76% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 14.28% & 0.79\n",
      "for 2020-02-09, MAE is:6.93 & sMAPE is:44.18% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 15.02% & 0.80\n",
      "for 2020-02-10, MAE is:7.32 & sMAPE is:37.97% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 15.58% & 0.81\n",
      "for 2020-02-11, MAE is:2.40 & sMAPE is:11.34% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 15.48% & 0.80\n",
      "for 2020-02-12, MAE is:4.05 & sMAPE is:14.26% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 15.45% & 0.80\n",
      "for 2020-02-13, MAE is:2.57 & sMAPE is:8.43% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 15.29% & 0.79\n",
      "for 2020-02-14, MAE is:3.68 & sMAPE is:11.52% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 15.21% & 0.79\n",
      "for 2020-02-15, MAE is:5.50 & sMAPE is:24.73% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 15.42% & 0.79\n",
      "for 2020-02-16, MAE is:3.83 & sMAPE is:67.48% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 16.53% & 0.78\n",
      "for 2020-02-17, MAE is:3.14 & sMAPE is:14.21% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 16.48% & 0.78\n",
      "for 2020-02-18, MAE is:3.87 & sMAPE is:15.09% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 16.45% & 0.79\n",
      "for 2020-02-19, MAE is:4.18 & sMAPE is:14.31% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 16.41% & 0.80\n",
      "for 2020-02-20, MAE is:2.51 & sMAPE is:8.33% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 16.25% & 0.81\n",
      "for 2020-02-21, MAE is:2.49 & sMAPE is:8.26% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 16.09% & 0.81\n",
      "for 2020-02-22, MAE is:3.32 & sMAPE is:14.02% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 16.06% & 0.81\n",
      "for 2020-02-23, MAE is:3.20 & sMAPE is:16.63% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 16.07% & 0.80\n",
      "for 2020-02-24, MAE is:4.74 & sMAPE is:17.24% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 16.09% & 0.80\n",
      "for 2020-02-25, MAE is:3.62 & sMAPE is:15.56% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 16.08% & 0.81\n",
      "for 2020-02-26, MAE is:2.58 & sMAPE is:9.03% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 15.95% & 0.82\n",
      "for 2020-02-27, MAE is:3.20 & sMAPE is:9.40% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 15.84% & 0.81\n",
      "for 2020-02-28, MAE is:4.70 & sMAPE is:14.35% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 15.82% & 0.83\n",
      "for 2020-02-29, MAE is:7.31 & sMAPE is:38.73% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 16.20% & 0.83\n",
      "for 2020-03-01, MAE is:3.59 & sMAPE is:22.28% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 16.30% & 0.83\n",
      "for 2020-03-02, MAE is:2.91 & sMAPE is:8.67% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 16.17% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-03, MAE is:4.38 & sMAPE is:11.51% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 16.10% & 0.81\n",
      "for 2020-03-04, MAE is:4.58 & sMAPE is:10.49% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 16.01% & 0.81\n",
      "for 2020-03-05, MAE is:4.96 & sMAPE is:14.63% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 15.99% & 0.81\n",
      "for 2020-03-06, MAE is:2.48 & sMAPE is:7.76% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 15.87% & 0.81\n",
      "for 2020-03-07, MAE is:2.59 & sMAPE is:8.74% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 15.76% & 0.80\n",
      "for 2020-03-08, MAE is:8.36 & sMAPE is:45.46% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 16.20% & 0.83\n",
      "for 2020-03-09, MAE is:4.71 & sMAPE is:13.63% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 16.16% & 0.83\n",
      "for 2020-03-10, MAE is:4.90 & sMAPE is:18.37% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 16.19% & 0.83\n",
      "for 2020-03-11, MAE is:4.34 & sMAPE is:18.62% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 16.23% & 0.82\n",
      "for 2020-03-12, MAE is:4.69 & sMAPE is:27.45% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 16.38% & 0.82\n",
      "for 2020-03-13, MAE is:4.17 & sMAPE is:15.15% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 16.36% & 0.82\n",
      "for 2020-03-14, MAE is:4.22 & sMAPE is:14.37% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 16.34% & 0.83\n",
      "for 2020-03-15, MAE is:10.33 & sMAPE is:70.44% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 17.06% & 0.85\n",
      "for 2020-03-16, MAE is:9.39 & sMAPE is:34.50% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 17.29% & 0.86\n",
      "for 2020-03-17, MAE is:3.89 & sMAPE is:14.29% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 17.25% & 0.86\n",
      "for 2020-03-18, MAE is:3.70 & sMAPE is:13.53% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 17.20% & 0.86\n",
      "for 2020-03-19, MAE is:3.50 & sMAPE is:14.47% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 17.17% & 0.85\n",
      "for 2020-03-20, MAE is:3.88 & sMAPE is:17.49% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 17.17% & 0.85\n",
      "for 2020-03-21, MAE is:5.07 & sMAPE is:40.01% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 17.45% & 0.84\n",
      "for 2020-03-22, MAE is:6.99 & sMAPE is:76.63% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 18.17% & 0.84\n",
      "for 2020-03-23, MAE is:4.64 & sMAPE is:26.08% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 18.27% & 0.84\n",
      "for 2020-03-24, MAE is:4.12 & sMAPE is:21.40% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 18.31% & 0.83\n",
      "for 2020-03-25, MAE is:2.54 & sMAPE is:10.49% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 18.22% & 0.83\n",
      "for 2020-03-26, MAE is:2.06 & sMAPE is:9.31% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 18.11% & 0.83\n",
      "for 2020-03-27, MAE is:3.22 & sMAPE is:15.42% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 18.08% & 0.83\n",
      "for 2020-03-28, MAE is:5.65 & sMAPE is:52.45% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 18.47% & 0.83\n",
      "for 2020-03-29, MAE is:3.66 & sMAPE is:67.83% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 19.03% & 0.83\n",
      "for 2020-03-30, MAE is:2.54 & sMAPE is:13.45% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 18.96% & 0.83\n",
      "for 2020-03-31, MAE is:1.82 & sMAPE is:7.88% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 18.84% & 0.82\n",
      "for 2020-04-01, MAE is:1.64 & sMAPE is:7.33% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 18.72% & 0.83\n",
      "for 2020-04-02, MAE is:3.19 & sMAPE is:14.75% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 18.67% & 0.83\n",
      "for 2020-04-03, MAE is:3.46 & sMAPE is:18.07% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 18.67% & 0.84\n",
      "for 2020-04-04, MAE is:5.50 & sMAPE is:39.46% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 18.89% & 0.85\n",
      "for 2020-04-05, MAE is:5.75 & sMAPE is:71.72% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 19.44% & 0.85\n",
      "for 2020-04-06, MAE is:3.61 & sMAPE is:47.16% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 19.72% & 0.85\n",
      "for 2020-04-07, MAE is:4.72 & sMAPE is:33.11% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 19.86% & 0.85\n",
      "for 2020-04-08, MAE is:3.11 & sMAPE is:22.86% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 19.89% & 0.84\n",
      "for 2020-04-09, MAE is:5.42 & sMAPE is:36.62% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 20.06% & 0.85\n",
      "for 2020-04-10, MAE is:2.35 & sMAPE is:16.21% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 20.02% & 0.84\n",
      "for 2020-04-11, MAE is:5.12 & sMAPE is:52.38% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 20.34% & 0.84\n",
      "for 2020-04-12, MAE is:7.15 & sMAPE is:107.78% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 21.19% & 0.85\n",
      "for 2020-04-13, MAE is:14.74 & sMAPE is:146.40% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 22.39% & 0.85\n",
      "for 2020-04-14, MAE is:6.77 & sMAPE is:79.63% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 22.93% & 0.85\n",
      "for 2020-04-15, MAE is:3.99 & sMAPE is:29.54% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 23.00% & 0.86\n",
      "for 2020-04-16, MAE is:3.04 & sMAPE is:28.44% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 23.05% & 0.86\n",
      "for 2020-04-17, MAE is:4.30 & sMAPE is:44.47% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 23.25% & 0.87\n",
      "for 2020-04-18, MAE is:8.89 & sMAPE is:102.60% & rMAE is:2.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 23.97% & 0.89\n",
      "for 2020-04-19, MAE is:8.56 & sMAPE is:121.71% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 24.86% & 0.90\n",
      "for 2020-04-20, MAE is:7.27 & sMAPE is:80.75% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 25.37% & 0.89\n",
      "for 2020-04-21, MAE is:5.89 & sMAPE is:117.02% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 26.18% & 0.89\n",
      "for 2020-04-22, MAE is:4.55 & sMAPE is:70.09% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 26.57% & 0.89\n",
      "for 2020-04-23, MAE is:3.94 & sMAPE is:28.96% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 26.59% & 0.89\n",
      "for 2020-04-24, MAE is:3.28 & sMAPE is:20.08% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 26.54% & 0.89\n",
      "for 2020-04-25, MAE is:8.25 & sMAPE is:95.77% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 27.13% & 0.90\n",
      "for 2020-04-26, MAE is:3.76 & sMAPE is:37.75% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 27.22% & 0.90\n",
      "for 2020-04-27, MAE is:3.22 & sMAPE is:15.63% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 27.13% & 0.90\n",
      "for 2020-04-28, MAE is:3.03 & sMAPE is:16.13% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 27.03% & 0.89\n",
      "for 2020-04-29, MAE is:7.87 & sMAPE is:48.31% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 27.21% & 0.89\n",
      "for 2020-04-30, MAE is:7.69 & sMAPE is:61.33% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 27.49% & 0.89\n",
      "for 2020-05-01, MAE is:3.33 & sMAPE is:59.55% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 27.76% & 0.89\n",
      "for 2020-05-02, MAE is:2.24 & sMAPE is:22.14% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 27.71% & 0.88\n",
      "for 2020-05-03, MAE is:3.69 & sMAPE is:57.40% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 27.95% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-04, MAE is:4.63 & sMAPE is:25.10% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 27.93% & 0.89\n",
      "for 2020-05-05, MAE is:2.01 & sMAPE is:11.95% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 27.80% & 0.89\n",
      "for 2020-05-06, MAE is:2.06 & sMAPE is:10.48% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 27.66% & 0.89\n",
      "for 2020-05-07, MAE is:1.89 & sMAPE is:9.91% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 27.53% & 0.88\n",
      "for 2020-05-08, MAE is:7.45 & sMAPE is:60.25% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 27.78% & 0.88\n",
      "for 2020-05-09, MAE is:5.27 & sMAPE is:38.41% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 27.86% & 0.88\n",
      "for 2020-05-10, MAE is:3.59 & sMAPE is:34.36% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 27.91% & 0.88\n",
      "for 2020-05-11, MAE is:9.86 & sMAPE is:90.24% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 28.38% & 0.88\n",
      "for 2020-05-12, MAE is:3.21 & sMAPE is:18.42% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 28.31% & 0.88\n",
      "for 2020-05-13, MAE is:3.16 & sMAPE is:14.36% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 28.20% & 0.88\n",
      "for 2020-05-14, MAE is:2.85 & sMAPE is:15.56% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 28.11% & 0.88\n",
      "for 2020-05-15, MAE is:2.65 & sMAPE is:13.19% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 28.00% & 0.88\n",
      "for 2020-05-16, MAE is:4.22 & sMAPE is:33.98% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 28.04% & 0.88\n",
      "for 2020-05-17, MAE is:5.76 & sMAPE is:64.52% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 28.31% & 0.88\n",
      "for 2020-05-18, MAE is:5.19 & sMAPE is:26.75% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 28.30% & 0.88\n",
      "for 2020-05-19, MAE is:2.42 & sMAPE is:11.67% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 28.18% & 0.89\n",
      "for 2020-05-20, MAE is:3.37 & sMAPE is:15.74% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 28.09% & 0.89\n",
      "for 2020-05-21, MAE is:4.03 & sMAPE is:27.31% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 28.08% & 0.89\n",
      "for 2020-05-22, MAE is:6.64 & sMAPE is:40.31% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 28.17% & 0.89\n",
      "for 2020-05-23, MAE is:3.41 & sMAPE is:27.77% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 28.17% & 0.89\n",
      "for 2020-05-24, MAE is:21.29 & sMAPE is:155.26% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 29.04% & 0.89\n",
      "for 2020-05-25, MAE is:3.68 & sMAPE is:32.39% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 29.07% & 0.90\n",
      "for 2020-05-26, MAE is:3.48 & sMAPE is:20.12% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 29.01% & 0.90\n",
      "for 2020-05-27, MAE is:2.65 & sMAPE is:14.03% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 28.90% & 0.90\n",
      "for 2020-05-28, MAE is:2.63 & sMAPE is:14.42% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 28.81% & 0.90\n",
      "for 2020-05-29, MAE is:2.46 & sMAPE is:15.18% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 28.72% & 0.90\n",
      "for 2020-05-30, MAE is:3.93 & sMAPE is:36.69% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 28.77% & 0.90\n",
      "for 2020-05-31, MAE is:12.10 & sMAPE is:101.01% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 29.24% & 0.90\n",
      "for 2020-06-01, MAE is:5.30 & sMAPE is:67.28% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 29.49% & 0.90\n",
      "for 2020-06-02, MAE is:3.56 & sMAPE is:15.80% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 29.40% & 0.90\n",
      "for 2020-06-03, MAE is:3.00 & sMAPE is:12.69% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 29.30% & 0.89\n",
      "for 2020-06-04, MAE is:3.54 & sMAPE is:15.48% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 29.21% & 0.89\n",
      "for 2020-06-05, MAE is:4.14 & sMAPE is:26.22% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 29.19% & 0.89\n",
      "for 2020-06-06, MAE is:9.35 & sMAPE is:110.82% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 29.71% & 0.90\n",
      "for 2020-06-07, MAE is:4.39 & sMAPE is:27.86% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 29.69% & 0.89\n",
      "for 2020-06-08, MAE is:3.05 & sMAPE is:10.89% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 29.58% & 0.89\n",
      "for 2020-06-09, MAE is:2.92 & sMAPE is:10.15% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 29.46% & 0.88\n",
      "for 2020-06-10, MAE is:2.79 & sMAPE is:9.70% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 29.33% & 0.88\n",
      "for 2020-06-11, MAE is:5.77 & sMAPE is:21.08% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 29.28% & 0.89\n",
      "for 2020-06-12, MAE is:4.04 & sMAPE is:17.85% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 29.21% & 0.89\n",
      "for 2020-06-13, MAE is:3.34 & sMAPE is:18.20% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 29.15% & 0.88\n",
      "for 2020-06-14, MAE is:2.27 & sMAPE is:12.46% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 29.05% & 0.88\n",
      "for 2020-06-15, MAE is:3.86 & sMAPE is:13.65% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 28.95% & 0.89\n",
      "for 2020-06-16, MAE is:2.10 & sMAPE is:6.59% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 28.82% & 0.88\n",
      "for 2020-06-17, MAE is:3.18 & sMAPE is:9.82% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 28.71% & 0.88\n",
      "for 2020-06-18, MAE is:2.18 & sMAPE is:7.20% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 28.58% & 0.88\n",
      "for 2020-06-19, MAE is:2.44 & sMAPE is:8.25% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 28.46% & 0.88\n",
      "for 2020-06-20, MAE is:3.10 & sMAPE is:13.01% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 28.37% & 0.88\n",
      "for 2020-06-21, MAE is:5.09 & sMAPE is:29.19% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 28.38% & 0.88\n",
      "for 2020-06-22, MAE is:3.30 & sMAPE is:11.55% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 28.28% & 0.88\n",
      "for 2020-06-23, MAE is:3.94 & sMAPE is:12.02% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 28.19% & 0.88\n",
      "for 2020-06-24, MAE is:3.21 & sMAPE is:9.58% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 28.08% & 0.89\n",
      "for 2020-06-25, MAE is:3.11 & sMAPE is:9.01% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 27.97% & 0.89\n",
      "for 2020-06-26, MAE is:3.32 & sMAPE is:9.57% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 27.87% & 0.89\n",
      "for 2020-06-27, MAE is:4.41 & sMAPE is:16.19% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 27.81% & 0.89\n",
      "for 2020-06-28, MAE is:6.14 & sMAPE is:37.32% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 27.86% & 0.90\n",
      "for 2020-06-29, MAE is:3.22 & sMAPE is:11.15% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 27.77% & 0.90\n",
      "for 2020-06-30, MAE is:6.34 & sMAPE is:19.86% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 27.72% & 0.90\n",
      "for 2020-07-01, MAE is:2.68 & sMAPE is:8.14% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 27.62% & 0.91\n",
      "for 2020-07-02, MAE is:5.02 & sMAPE is:13.35% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 27.54% & 0.91\n",
      "for 2020-07-03, MAE is:3.71 & sMAPE is:10.05% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 27.44% & 0.91\n",
      "for 2020-07-04, MAE is:6.29 & sMAPE is:27.58% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 27.45% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-05, MAE is:17.71 & sMAPE is:133.91% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 28.01% & 0.91\n",
      "for 2020-07-06, MAE is:4.62 & sMAPE is:17.81% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 27.96% & 0.91\n",
      "for 2020-07-07, MAE is:5.51 & sMAPE is:18.12% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 27.91% & 0.92\n",
      "for 2020-07-08, MAE is:5.94 & sMAPE is:15.09% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 27.84% & 0.92\n",
      "for 2020-07-09, MAE is:2.33 & sMAPE is:5.88% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 27.73% & 0.92\n",
      "for 2020-07-10, MAE is:3.13 & sMAPE is:7.95% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 27.62% & 0.92\n",
      "for 2020-07-11, MAE is:1.98 & sMAPE is:6.58% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 27.51% & 0.92\n",
      "for 2020-07-12, MAE is:6.02 & sMAPE is:24.76% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 27.50% & 0.91\n",
      "for 2020-07-13, MAE is:4.94 & sMAPE is:15.01% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 27.44% & 0.91\n",
      "for 2020-07-14, MAE is:7.18 & sMAPE is:22.15% & rMAE is:3.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 27.41% & 0.92\n",
      "for 2020-07-15, MAE is:2.98 & sMAPE is:7.71% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 27.31% & 0.92\n",
      "for 2020-07-16, MAE is:3.71 & sMAPE is:8.91% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 27.22% & 0.93\n",
      "for 2020-07-17, MAE is:1.87 & sMAPE is:5.13% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 27.10% & 0.92\n",
      "for 2020-07-18, MAE is:2.10 & sMAPE is:6.76% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 27.00% & 0.93\n",
      "for 2020-07-19, MAE is:2.40 & sMAPE is:8.91% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 26.91% & 0.93\n",
      "for 2020-07-20, MAE is:3.57 & sMAPE is:9.60% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 26.83% & 0.93\n",
      "for 2020-07-21, MAE is:2.66 & sMAPE is:7.53% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 26.73% & 0.94\n",
      "for 2020-07-22, MAE is:2.72 & sMAPE is:7.42% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 26.64% & 0.94\n",
      "for 2020-07-23, MAE is:2.61 & sMAPE is:6.72% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 26.54% & 0.94\n",
      "for 2020-07-24, MAE is:4.18 & sMAPE is:11.91% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 26.47% & 0.94\n",
      "for 2020-07-25, MAE is:2.14 & sMAPE is:7.91% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 26.38% & 0.94\n",
      "for 2020-07-26, MAE is:6.62 & sMAPE is:34.32% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 26.42% & 0.94\n",
      "for 2020-07-27, MAE is:3.91 & sMAPE is:11.90% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 26.35% & 0.94\n",
      "for 2020-07-28, MAE is:3.47 & sMAPE is:11.87% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 26.28% & 0.94\n",
      "for 2020-07-29, MAE is:4.59 & sMAPE is:12.64% & rMAE is:5.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 26.21% & 0.96\n",
      "for 2020-07-30, MAE is:3.32 & sMAPE is:8.02% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 26.13% & 0.96\n",
      "for 2020-07-31, MAE is:3.09 & sMAPE is:7.51% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 26.04% & 0.96\n",
      "for 2020-08-01, MAE is:3.94 & sMAPE is:11.49% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 25.97% & 0.96\n",
      "for 2020-08-02, MAE is:1.48 & sMAPE is:5.35% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 25.88% & 0.95\n",
      "for 2020-08-03, MAE is:5.97 & sMAPE is:17.28% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 25.84% & 0.96\n",
      "for 2020-08-04, MAE is:2.91 & sMAPE is:8.64% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 25.76% & 0.96\n",
      "for 2020-08-05, MAE is:2.98 & sMAPE is:9.08% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 25.68% & 0.96\n",
      "for 2020-08-06, MAE is:3.47 & sMAPE is:9.21% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 25.61% & 0.96\n",
      "for 2020-08-07, MAE is:3.23 & sMAPE is:8.67% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 25.53% & 0.96\n",
      "for 2020-08-08, MAE is:2.71 & sMAPE is:8.14% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 25.45% & 0.96\n",
      "for 2020-08-09, MAE is:3.17 & sMAPE is:10.16% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 25.38% & 0.96\n",
      "for 2020-08-10, MAE is:3.40 & sMAPE is:8.73% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 25.31% & 0.97\n",
      "for 2020-08-11, MAE is:2.61 & sMAPE is:6.61% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 25.22% & 0.97\n",
      "for 2020-08-12, MAE is:3.64 & sMAPE is:9.10% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 25.15% & 0.96\n",
      "for 2020-08-13, MAE is:3.24 & sMAPE is:8.35% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 25.08% & 0.96\n",
      "for 2020-08-14, MAE is:2.45 & sMAPE is:6.97% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 25.00% & 0.96\n",
      "for 2020-08-15, MAE is:2.57 & sMAPE is:8.23% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 24.92% & 0.97\n",
      "for 2020-08-16, MAE is:3.32 & sMAPE is:12.00% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 24.87% & 0.97\n",
      "for 2020-08-17, MAE is:6.53 & sMAPE is:17.71% & rMAE is:2.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 24.84% & 0.98\n",
      "for 2020-08-18, MAE is:3.63 & sMAPE is:8.42% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 24.77% & 0.98\n",
      "for 2020-08-19, MAE is:4.06 & sMAPE is:10.48% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 24.70% & 0.98\n",
      "for 2020-08-20, MAE is:3.58 & sMAPE is:8.97% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 24.64% & 0.98\n",
      "for 2020-08-21, MAE is:4.57 & sMAPE is:13.10% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 24.59% & 0.98\n",
      "for 2020-08-22, MAE is:4.77 & sMAPE is:21.39% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 24.57% & 0.98\n",
      "for 2020-08-23, MAE is:4.21 & sMAPE is:22.09% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 24.56% & 0.98\n",
      "for 2020-08-24, MAE is:13.16 & sMAPE is:33.65% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 24.60% & 0.98\n",
      "for 2020-08-25, MAE is:6.10 & sMAPE is:14.02% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 24.56% & 0.98\n",
      "for 2020-08-26, MAE is:7.32 & sMAPE is:23.66% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 24.55% & 0.98\n",
      "for 2020-08-27, MAE is:11.51 & sMAPE is:23.02% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 24.55% & 0.98\n",
      "for 2020-08-28, MAE is:5.84 & sMAPE is:12.49% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 24.50% & 0.98\n",
      "for 2020-08-29, MAE is:4.82 & sMAPE is:13.77% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 24.45% & 0.98\n",
      "for 2020-08-30, MAE is:4.64 & sMAPE is:15.37% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 24.42% & 0.98\n",
      "for 2020-08-31, MAE is:14.10 & sMAPE is:27.53% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 24.43% & 0.98\n",
      "for 2020-09-01, MAE is:4.34 & sMAPE is:8.88% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 24.36% & 0.98\n",
      "for 2020-09-02, MAE is:6.21 & sMAPE is:12.88% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 24.32% & 0.97\n",
      "for 2020-09-03, MAE is:4.17 & sMAPE is:9.22% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 24.26% & 0.97\n",
      "for 2020-09-04, MAE is:2.10 & sMAPE is:4.96% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 24.18% & 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-05, MAE is:2.27 & sMAPE is:6.35% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 24.11% & 0.97\n",
      "for 2020-09-06, MAE is:4.05 & sMAPE is:12.16% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 24.06% & 0.98\n",
      "for 2020-09-07, MAE is:5.32 & sMAPE is:11.93% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 24.01% & 0.97\n",
      "for 2020-09-08, MAE is:5.17 & sMAPE is:11.00% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 23.96% & 0.97\n",
      "for 2020-09-09, MAE is:4.21 & sMAPE is:8.94% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 23.90% & 0.97\n",
      "for 2020-09-10, MAE is:5.00 & sMAPE is:9.30% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 23.84% & 0.97\n",
      "for 2020-09-11, MAE is:6.12 & sMAPE is:12.08% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 23.80% & 0.97\n",
      "for 2020-09-12, MAE is:4.30 & sMAPE is:10.39% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 23.74% & 0.97\n",
      "for 2020-09-13, MAE is:3.08 & sMAPE is:8.59% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 23.69% & 0.98\n",
      "for 2020-09-14, MAE is:12.57 & sMAPE is:22.40% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 23.68% & 0.98\n",
      "for 2020-09-15, MAE is:19.35 & sMAPE is:23.50% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 23.68% & 0.98\n",
      "for 2020-09-16, MAE is:11.82 & sMAPE is:18.43% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 23.66% & 0.98\n",
      "for 2020-09-17, MAE is:3.86 & sMAPE is:7.21% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 23.60% & 0.98\n",
      "for 2020-09-18, MAE is:4.94 & sMAPE is:10.73% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 23.55% & 0.98\n",
      "for 2020-09-19, MAE is:4.48 & sMAPE is:11.91% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 23.50% & 0.99\n",
      "for 2020-09-20, MAE is:4.45 & sMAPE is:12.55% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 23.46% & 0.99\n",
      "for 2020-09-21, MAE is:21.41 & sMAPE is:33.18% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 23.50% & 0.99\n",
      "for 2020-09-22, MAE is:7.66 & sMAPE is:13.54% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 23.46% & 0.99\n",
      "for 2020-09-23, MAE is:3.25 & sMAPE is:6.94% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 23.40% & 0.99\n",
      "for 2020-09-24, MAE is:4.14 & sMAPE is:9.46% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 23.35% & 0.98\n",
      "for 2020-09-25, MAE is:4.99 & sMAPE is:11.98% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 23.30% & 0.99\n",
      "for 2020-09-26, MAE is:2.27 & sMAPE is:6.74% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 23.24% & 0.98\n",
      "for 2020-09-27, MAE is:5.67 & sMAPE is:21.13% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 23.24% & 0.98\n",
      "for 2020-09-28, MAE is:6.48 & sMAPE is:14.93% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 23.20% & 0.98\n",
      "for 2020-09-29, MAE is:11.43 & sMAPE is:19.07% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 23.19% & 0.98\n",
      "for 2020-09-30, MAE is:6.94 & sMAPE is:13.38% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 23.15% & 0.99\n",
      "for 2020-10-01, MAE is:3.83 & sMAPE is:8.90% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 23.10% & 0.99\n",
      "for 2020-10-02, MAE is:4.60 & sMAPE is:12.68% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 23.06% & 0.99\n",
      "for 2020-10-03, MAE is:4.08 & sMAPE is:15.56% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 23.04% & 0.99\n",
      "for 2020-10-04, MAE is:11.46 & sMAPE is:65.39% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 23.19% & 0.99\n",
      "for 2020-10-05, MAE is:6.23 & sMAPE is:26.48% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 23.20% & 0.99\n",
      "for 2020-10-06, MAE is:4.00 & sMAPE is:13.70% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 23.17% & 0.98\n",
      "for 2020-10-07, MAE is:3.94 & sMAPE is:10.75% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 23.12% & 0.98\n",
      "for 2020-10-08, MAE is:4.24 & sMAPE is:11.56% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 23.08% & 0.98\n",
      "for 2020-10-09, MAE is:7.95 & sMAPE is:20.89% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 23.07% & 0.98\n",
      "for 2020-10-10, MAE is:2.81 & sMAPE is:8.57% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 23.02% & 0.98\n",
      "for 2020-10-11, MAE is:2.79 & sMAPE is:8.62% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 22.97% & 0.98\n",
      "for 2020-10-12, MAE is:6.13 & sMAPE is:13.49% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 22.94% & 0.98\n",
      "for 2020-10-13, MAE is:4.81 & sMAPE is:10.13% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 22.90% & 0.97\n",
      "for 2020-10-14, MAE is:3.93 & sMAPE is:8.80% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 22.85% & 0.97\n",
      "for 2020-10-15, MAE is:3.25 & sMAPE is:7.84% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 22.79% & 0.97\n",
      "for 2020-10-16, MAE is:3.34 & sMAPE is:6.88% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 22.74% & 0.97\n",
      "for 2020-10-17, MAE is:5.19 & sMAPE is:13.55% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 22.71% & 0.97\n",
      "for 2020-10-18, MAE is:3.07 & sMAPE is:8.33% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 22.66% & 0.97\n",
      "for 2020-10-19, MAE is:6.92 & sMAPE is:14.97% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 22.63% & 0.97\n",
      "for 2020-10-20, MAE is:3.32 & sMAPE is:8.57% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 22.58% & 0.97\n",
      "for 2020-10-21, MAE is:4.86 & sMAPE is:12.69% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 22.55% & 0.97\n",
      "for 2020-10-22, MAE is:9.33 & sMAPE is:22.60% & rMAE is:4.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 22.55% & 0.98\n",
      "for 2020-10-23, MAE is:5.43 & sMAPE is:12.52% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 22.52% & 0.98\n",
      "for 2020-10-24, MAE is:5.09 & sMAPE is:16.56% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 22.50% & 0.98\n",
      "for 2020-10-25, MAE is:10.84 & sMAPE is:81.02% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 22.69% & 0.98\n",
      "for 2020-10-26, MAE is:4.06 & sMAPE is:11.99% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 22.66% & 0.97\n",
      "for 2020-10-27, MAE is:4.28 & sMAPE is:10.71% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 22.62% & 0.98\n",
      "for 2020-10-28, MAE is:5.75 & sMAPE is:16.00% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 22.60% & 0.97\n",
      "for 2020-10-29, MAE is:5.63 & sMAPE is:19.48% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 22.59% & 0.97\n",
      "for 2020-10-30, MAE is:5.35 & sMAPE is:24.44% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 22.59% & 0.97\n",
      "for 2020-10-31, MAE is:5.27 & sMAPE is:17.54% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 22.58% & 0.97\n",
      "for 2020-11-01, MAE is:7.75 & sMAPE is:48.74% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 22.66% & 0.97\n",
      "for 2020-11-02, MAE is:6.77 & sMAPE is:56.11% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 22.77% & 0.97\n",
      "for 2020-11-03, MAE is:4.64 & sMAPE is:14.29% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 22.74% & 0.97\n",
      "for 2020-11-04, MAE is:4.07 & sMAPE is:9.99% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 22.70% & 0.97\n",
      "for 2020-11-05, MAE is:4.10 & sMAPE is:10.18% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 22.66% & 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-06, MAE is:5.12 & sMAPE is:13.25% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 22.63% & 0.97\n",
      "for 2020-11-07, MAE is:6.51 & sMAPE is:20.07% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 22.62% & 0.97\n",
      "for 2020-11-08, MAE is:7.26 & sMAPE is:23.06% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 22.62% & 0.97\n",
      "for 2020-11-09, MAE is:6.19 & sMAPE is:15.95% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 22.60% & 0.97\n",
      "for 2020-11-10, MAE is:5.28 & sMAPE is:12.05% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 22.57% & 0.97\n",
      "for 2020-11-11, MAE is:4.82 & sMAPE is:12.86% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 22.54% & 0.97\n",
      "for 2020-11-12, MAE is:4.48 & sMAPE is:11.94% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 22.50% & 0.97\n",
      "for 2020-11-13, MAE is:5.51 & sMAPE is:14.19% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 22.48% & 0.97\n",
      "for 2020-11-14, MAE is:5.84 & sMAPE is:17.05% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 22.46% & 0.97\n",
      "for 2020-11-15, MAE is:11.95 & sMAPE is:83.68% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 22.65% & 0.97\n",
      "for 2020-11-16, MAE is:7.41 & sMAPE is:58.30% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.76% & 0.97\n",
      "for 2020-11-17, MAE is:4.96 & sMAPE is:15.21% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.74% & 0.97\n",
      "for 2020-11-18, MAE is:3.58 & sMAPE is:9.10% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.70% & 0.97\n",
      "for 2020-11-19, MAE is:6.63 & sMAPE is:26.66% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.71% & 0.97\n",
      "for 2020-11-20, MAE is:5.43 & sMAPE is:13.32% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.68% & 0.97\n",
      "for 2020-11-21, MAE is:3.63 & sMAPE is:9.39% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.64% & 0.97\n",
      "for 2020-11-22, MAE is:2.83 & sMAPE is:7.51% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.59% & 0.97\n",
      "for 2020-11-23, MAE is:4.75 & sMAPE is:10.99% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.56% & 0.97\n",
      "for 2020-11-24, MAE is:3.29 & sMAPE is:7.13% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 22.51% & 0.96\n",
      "for 2020-11-25, MAE is:4.38 & sMAPE is:9.16% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 22.47% & 0.96\n",
      "for 2020-11-26, MAE is:9.70 & sMAPE is:18.30% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.46% & 0.96\n",
      "for 2020-11-27, MAE is:7.70 & sMAPE is:12.47% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 22.43% & 0.96\n",
      "for 2020-11-28, MAE is:1.94 & sMAPE is:4.17% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.37% & 0.96\n",
      "for 2020-11-29, MAE is:2.28 & sMAPE is:4.91% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.32% & 0.96\n",
      "for 2020-11-30, MAE is:5.34 & sMAPE is:9.63% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.28% & 0.96\n",
      "for 2020-12-01, MAE is:5.53 & sMAPE is:9.72% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 22.25% & 0.96\n",
      "for 2020-12-02, MAE is:19.21 & sMAPE is:25.67% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 22.26% & 0.95\n",
      "for 2020-12-03, MAE is:8.75 & sMAPE is:15.03% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 22.24% & 0.96\n",
      "for 2020-12-04, MAE is:3.97 & sMAPE is:9.05% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 22.20% & 0.95\n",
      "for 2020-12-05, MAE is:3.87 & sMAPE is:7.58% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 22.15% & 0.95\n",
      "for 2020-12-06, MAE is:3.06 & sMAPE is:6.94% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 22.11% & 0.95\n",
      "for 2020-12-07, MAE is:11.24 & sMAPE is:18.20% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 22.10% & 0.95\n",
      "for 2020-12-08, MAE is:11.11 & sMAPE is:15.85% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 22.08% & 0.95\n",
      "for 2020-12-09, MAE is:20.63 & sMAPE is:26.44% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 22.09% & 0.96\n",
      "for 2020-12-10, MAE is:14.64 & sMAPE is:20.46% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 22.09% & 0.96\n",
      "for 2020-12-11, MAE is:4.06 & sMAPE is:8.18% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 22.05% & 0.96\n",
      "for 2020-12-12, MAE is:4.94 & sMAPE is:10.69% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 22.01% & 0.96\n",
      "for 2020-12-13, MAE is:3.72 & sMAPE is:8.95% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 21.98% & 0.96\n",
      "for 2020-12-14, MAE is:10.80 & sMAPE is:24.70% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 21.98% & 0.96\n",
      "for 2020-12-15, MAE is:6.16 & sMAPE is:12.09% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 21.96% & 0.96\n",
      "for 2020-12-16, MAE is:3.67 & sMAPE is:7.62% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 21.92% & 0.96\n",
      "for 2020-12-17, MAE is:4.99 & sMAPE is:9.47% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 21.88% & 0.95\n",
      "for 2020-12-18, MAE is:3.56 & sMAPE is:7.57% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.84% & 0.95\n",
      "for 2020-12-19, MAE is:4.81 & sMAPE is:12.07% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.81% & 0.95\n",
      "for 2020-12-20, MAE is:4.03 & sMAPE is:10.31% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.78% & 0.95\n",
      "for 2020-12-21, MAE is:4.39 & sMAPE is:10.43% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 21.75% & 0.95\n",
      "for 2020-12-22, MAE is:10.11 & sMAPE is:48.13% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 21.82% & 0.95\n",
      "for 2020-12-23, MAE is:8.57 & sMAPE is:23.17% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 21.83% & 0.95\n",
      "for 2020-12-24, MAE is:7.43 & sMAPE is:43.55% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 21.89% & 0.95\n",
      "for 2020-12-25, MAE is:8.95 & sMAPE is:34.92% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 21.92% & 0.95\n",
      "for 2020-12-26, MAE is:10.84 & sMAPE is:30.98% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 21.95% & 0.95\n",
      "for 2020-12-27, MAE is:11.34 & sMAPE is:76.40% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 22.10% & 0.95\n",
      "for 2020-12-28, MAE is:8.64 & sMAPE is:23.05% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 22.10% & 0.95\n",
      "for 2020-12-29, MAE is:6.20 & sMAPE is:13.83% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 22.08% & 0.95\n",
      "for 2020-12-30, MAE is:3.51 & sMAPE is:7.31% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 22.04% & 0.95\n",
      "for 2020-12-31, MAE is:3.66 & sMAPE is:7.57% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 22.00% & 0.94\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:52:10,626]\u001b[0m A new study created in RDB with name: FR_2021\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:52:22,914]\u001b[0m Trial 0 finished with value: 5.675469365861534 and parameters: {'n_hidden': 3, 'learning_rate': 0.004926086458382427, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35316427871704775, 'dropout_rate_Layer_2': 0.013713256364063531, 'dropout_rate_Layer_3': 0.11270596608767254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1275046247568737e-05, 'l1_Layer_2': 0.0018083474822182999, 'l1_Layer_3': 3.633293637582716e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 175, 'n_units_Layer_3': 105}. Best is trial 0 with value: 5.675469365861534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 23.09% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 59.16 | sMAPE for Test Set is: 53.42% | rMAE for Test Set is: 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:52:26,184]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:52:29,775]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:52:33,875]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:52:39,546]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:52:42,835]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:52:45,690]\u001b[0m Trial 6 finished with value: 9.063594668909921 and parameters: {'n_hidden': 3, 'learning_rate': 0.03510834064203484, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38498609973728387, 'dropout_rate_Layer_2': 0.3020138970358753, 'dropout_rate_Layer_3': 0.09934929060826336, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.024740783749675057, 'l1_Layer_2': 0.0006884934718702364, 'l1_Layer_3': 0.00043006415694555727, 'n_units_Layer_1': 295, 'n_units_Layer_2': 80, 'n_units_Layer_3': 220}. Best is trial 0 with value: 5.675469365861534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.06 | sMAPE for Validation Set is: 33.15% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 59.21 | sMAPE for Test Set is: 54.48% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:52:46,545]\u001b[0m Trial 1 finished with value: 14.994053797750363 and parameters: {'n_hidden': 3, 'learning_rate': 0.07114088631469183, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27824210627171625, 'dropout_rate_Layer_2': 0.34989895088943324, 'dropout_rate_Layer_3': 0.28076680609722554, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.01999142946695123, 'l1_Layer_2': 0.0044463719565385265, 'l1_Layer_3': 0.0002519063021912796, 'n_units_Layer_1': 50, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180}. Best is trial 0 with value: 5.675469365861534.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.99 | sMAPE for Validation Set is: 47.29% | rMAE for Validation Set is: 2.05\n",
      "MAE for Test Set is: 65.78 | sMAPE for Test Set is: 65.05% | rMAE for Test Set is: 2.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:52:47,493]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:52:53,851]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.81 | sMAPE for Validation Set is: 37.44% | rMAE for Validation Set is: 1.48\n",
      "MAE for Test Set is: 65.84 | sMAPE for Test Set is: 65.58% | rMAE for Test Set is: 2.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:52:54,921]\u001b[0m Trial 10 finished with value: 10.807155237321844 and parameters: {'n_hidden': 3, 'learning_rate': 0.08133102441370227, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3273503524227974, 'dropout_rate_Layer_2': 0.043665957773768055, 'dropout_rate_Layer_3': 0.08767206082282702, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.682866173711364e-05, 'l1_Layer_2': 0.0008703422102990078, 'l1_Layer_3': 0.0013980508749610121, 'n_units_Layer_1': 275, 'n_units_Layer_2': 180, 'n_units_Layer_3': 90}. Best is trial 0 with value: 5.675469365861534.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:52:58,266]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:00,015]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 21.24% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 52.60 | sMAPE for Test Set is: 45.68% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:53:00,535]\u001b[0m Trial 3 finished with value: 5.19703356567753 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005439902236049147, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35625348559839026, 'dropout_rate_Layer_2': 0.16056103663428578, 'dropout_rate_Layer_3': 0.042339999070162816, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.016829503754739e-05, 'l1_Layer_2': 0.05061561061492895, 'l1_Layer_3': 0.0014887242058949281, 'n_units_Layer_1': 235, 'n_units_Layer_2': 190, 'n_units_Layer_3': 110}. Best is trial 3 with value: 5.19703356567753.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:02,533]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:04,220]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:05,346]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:09,444]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:12,873]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:13,305]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:14,606]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:18,166]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:22,989]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:25,173]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:28,699]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:32,525]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:35,060]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:37,844]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:43,723]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:46,088]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:48,299]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:51,666]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:53,672]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:56,934]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:53:57,484]\u001b[0m Trial 24 finished with value: 6.786159811108447 and parameters: {'n_hidden': 3, 'learning_rate': 0.01068806639264701, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1220864574684779, 'dropout_rate_Layer_2': 0.24463618836780532, 'dropout_rate_Layer_3': 0.28437083439962874, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.07015336956078252, 'l1_Layer_2': 0.02201252692510704, 'l1_Layer_3': 0.012034820077235294, 'n_units_Layer_1': 145, 'n_units_Layer_2': 110, 'n_units_Layer_3': 155}. Best is trial 3 with value: 5.19703356567753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.79 | sMAPE for Validation Set is: 26.63% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 52.55 | sMAPE for Test Set is: 45.85% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:54:02,062]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:02,445]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:02,552]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:08,487]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:09,010]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:10,582]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:16,657]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:17,220]\u001b[0m Trial 25 finished with value: 6.093494280803614 and parameters: {'n_hidden': 4, 'learning_rate': 0.001502305959354784, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3512596552130739, 'dropout_rate_Layer_2': 0.1265694001078572, 'dropout_rate_Layer_3': 0.3492745275914907, 'dropout_rate_Layer_4': 0.02235700344579246, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00955270362324479, 'l1_Layer_2': 0.0005246409340393569, 'l1_Layer_3': 0.00036657767491561074, 'l1_Layer_4': 0.046706169427534895, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 85, 'n_units_Layer_4': 285}. Best is trial 3 with value: 5.19703356567753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 24.57% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 53.56 | sMAPE for Test Set is: 47.08% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:54:22,704]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:22,873]\u001b[0m Trial 42 finished with value: 8.732256865434989 and parameters: {'n_hidden': 4, 'learning_rate': 0.026131503157153103, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0024107562457766907, 'dropout_rate_Layer_2': 0.29683036677605296, 'dropout_rate_Layer_3': 0.14876787240628805, 'dropout_rate_Layer_4': 0.30352417533294773, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.4047170850200007e-05, 'l1_Layer_2': 0.0008056139541744528, 'l1_Layer_3': 0.0012739031972219947, 'l1_Layer_4': 0.0016297189554734196, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 265, 'n_units_Layer_4': 240}. Best is trial 3 with value: 5.19703356567753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.73 | sMAPE for Validation Set is: 32.38% | rMAE for Validation Set is: 1.20\n",
      "MAE for Test Set is: 58.34 | sMAPE for Test Set is: 53.20% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:54:23,468]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:31,422]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:34,818]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:38,313]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:38,438]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:44,396]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:49,861]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:53,814]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:54,185]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:54:58,472]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:00,187]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:02,880]\u001b[0m Trial 50 finished with value: 4.754292929647223 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023618357261471577, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20036763201108296, 'dropout_rate_Layer_2': 0.348497562652226, 'dropout_rate_Layer_3': 0.16672231175632934, 'dropout_rate_Layer_4': 0.2883049505653551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004340205831464275, 'l1_Layer_2': 0.0013705806529767364, 'l1_Layer_3': 0.0008517505471815199, 'l1_Layer_4': 4.2729159371958776e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 230, 'n_units_Layer_3': 105, 'n_units_Layer_4': 170}. Best is trial 50 with value: 4.754292929647223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 20.37% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 53.14 | sMAPE for Test Set is: 46.25% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:55:03,045]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:06,108]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:08,564]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:09,254]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:10,641]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:12,425]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:12,839]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:15,633]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:19,544]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:24,208]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:25,082]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:27,446]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:32,338]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:32,751]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:35,343]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:38,814]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:39,200]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:40,977]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:46,085]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:51,167]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:55,029]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:55:56,797]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:00,413]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:01,459]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:02,727]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:06,767]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:10,424]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:15,460]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:18,593]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:20,412]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:22,673]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:29,224]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:31,732]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:31,829]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:35,778]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:38,910]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:41,006]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:43,326]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:46,707]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:50,073]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:56:55,176]\u001b[0m Trial 97 finished with value: 6.009448885979648 and parameters: {'n_hidden': 3, 'learning_rate': 0.001941306031326736, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0069116939076646405, 'dropout_rate_Layer_2': 0.17786903135308507, 'dropout_rate_Layer_3': 0.10121234919255145, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.2523862690692329e-05, 'l1_Layer_2': 0.00792011293551217, 'l1_Layer_3': 0.006703528457921696, 'n_units_Layer_1': 65, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 50 with value: 4.754292929647223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 23.94% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 59.12 | sMAPE for Test Set is: 54.44% | rMAE for Test Set is: 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:56:55,714]\u001b[0m Trial 94 finished with value: 4.6063394480623385 and parameters: {'n_hidden': 3, 'learning_rate': 0.005707014106460509, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2175230682076807, 'dropout_rate_Layer_2': 0.16267757419130074, 'dropout_rate_Layer_3': 0.1375114263458817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018144326931828048, 'l1_Layer_2': 0.0005931951701133526, 'l1_Layer_3': 0.004023714814727209, 'n_units_Layer_1': 155, 'n_units_Layer_2': 215, 'n_units_Layer_3': 170}. Best is trial 94 with value: 4.6063394480623385.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 19.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 17.61 | sMAPE for Test Set is: 19.26% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:57:04,552]\u001b[0m Trial 100 finished with value: 13.096483885703975 and parameters: {'n_hidden': 4, 'learning_rate': 0.025956562881426275, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02320701011244415, 'dropout_rate_Layer_2': 0.08949425381558834, 'dropout_rate_Layer_3': 0.2713347913944068, 'dropout_rate_Layer_4': 0.28307591010059907, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.007894370377454685, 'l1_Layer_2': 0.006375476943259803, 'l1_Layer_3': 0.045501059590040756, 'l1_Layer_4': 0.014900804330256449, 'n_units_Layer_1': 180, 'n_units_Layer_2': 145, 'n_units_Layer_3': 160, 'n_units_Layer_4': 240}. Best is trial 94 with value: 4.6063394480623385.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.10 | sMAPE for Validation Set is: 42.12% | rMAE for Validation Set is: 1.79\n",
      "MAE for Test Set is: 73.04 | sMAPE for Test Set is: 77.83% | rMAE for Test Set is: 2.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:57:07,313]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:07,526]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:15,744]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:16,022]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:23,142]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:26,789]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:27,389]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:33,665]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:36,724]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:45,543]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:48,654]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:53,847]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:57:57,508]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:01,604]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:05,389]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:10,464]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:14,572]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:21,653]\u001b[0m Trial 117 finished with value: 5.076699863999889 and parameters: {'n_hidden': 4, 'learning_rate': 0.014857711920790172, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01608000286114352, 'dropout_rate_Layer_2': 0.27643599843515193, 'dropout_rate_Layer_3': 0.3109527309898885, 'dropout_rate_Layer_4': 0.36940832649686584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007851470427431257, 'l1_Layer_2': 0.03785379675158227, 'l1_Layer_3': 0.023745305547364863, 'l1_Layer_4': 0.000522986304129341, 'n_units_Layer_1': 260, 'n_units_Layer_2': 215, 'n_units_Layer_3': 300, 'n_units_Layer_4': 225}. Best is trial 94 with value: 4.6063394480623385.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 21.10% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 55.16 | sMAPE for Test Set is: 48.90% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:58:23,611]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:33,607]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:33,949]\u001b[0m Trial 105 finished with value: 4.9547430582047065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023206332282706002, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23975627335334662, 'dropout_rate_Layer_2': 0.18689402434190122, 'dropout_rate_Layer_3': 0.3783206336747424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013954768857824956, 'l1_Layer_2': 0.025032566871505624, 'l1_Layer_3': 0.013372759017495604, 'n_units_Layer_1': 90, 'n_units_Layer_2': 210, 'n_units_Layer_3': 175}. Best is trial 94 with value: 4.6063394480623385.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 20.90% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 18.57 | sMAPE for Test Set is: 21.00% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:58:40,223]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:43,542]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:43,943]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:50,408]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:50,953]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:57,095]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:58:57,678]\u001b[0m Trial 106 finished with value: 4.5099109205526124 and parameters: {'n_hidden': 3, 'learning_rate': 0.002088402035336678, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1547837467697665, 'dropout_rate_Layer_2': 0.16910691218459026, 'dropout_rate_Layer_3': 0.23726887246643502, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012129806641074023, 'l1_Layer_2': 0.023843793897161344, 'l1_Layer_3': 0.013460220729809801, 'n_units_Layer_1': 100, 'n_units_Layer_2': 225, 'n_units_Layer_3': 180}. Best is trial 106 with value: 4.5099109205526124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 19.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 18.24 | sMAPE for Test Set is: 20.29% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:59:02,594]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:07,969]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:11,209]\u001b[0m Trial 130 finished with value: 5.193887406152602 and parameters: {'n_hidden': 4, 'learning_rate': 0.012938275020308452, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22101126161044016, 'dropout_rate_Layer_2': 0.2612457611664822, 'dropout_rate_Layer_3': 0.33759182425036266, 'dropout_rate_Layer_4': 0.3985221740017381, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006324561198563646, 'l1_Layer_2': 0.08129243277107467, 'l1_Layer_3': 0.03679690118106742, 'l1_Layer_4': 1.8760017712116265e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295, 'n_units_Layer_4': 170}. Best is trial 106 with value: 4.5099109205526124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 21.69% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 55.75 | sMAPE for Test Set is: 50.75% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:59:12,962]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:13,886]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:23,384]\u001b[0m Trial 131 finished with value: 5.958687041830775 and parameters: {'n_hidden': 3, 'learning_rate': 0.009806209923474776, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13067495816193672, 'dropout_rate_Layer_2': 0.014710488255748472, 'dropout_rate_Layer_3': 0.012214554454260673, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0137750077253816e-05, 'l1_Layer_2': 1.1054737184589229e-05, 'l1_Layer_3': 0.00384269684237521, 'n_units_Layer_1': 60, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 106 with value: 4.5099109205526124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 24.39% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 51.85 | sMAPE for Test Set is: 44.96% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:59:25,402]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:27,606]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:34,936]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:35,330]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:40,247]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:44,042]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:47,152]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:50,318]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:50,741]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-24 23:59:56,356]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 20.56% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 18.85 | sMAPE for Test Set is: 21.14% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-24 23:59:57,563]\u001b[0m Trial 137 finished with value: 4.868890716990278 and parameters: {'n_hidden': 4, 'learning_rate': 0.00394808971613006, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2737450498663918, 'dropout_rate_Layer_2': 0.11006780072130623, 'dropout_rate_Layer_3': 0.15628017324852989, 'dropout_rate_Layer_4': 0.36832847810427644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001983546147143604, 'l1_Layer_2': 0.0022971114545753857, 'l1_Layer_3': 0.06859637957075533, 'l1_Layer_4': 1.1962675447690797e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 210, 'n_units_Layer_3': 125, 'n_units_Layer_4': 300}. Best is trial 106 with value: 4.5099109205526124.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:02,629]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:05,504]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:09,076]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:11,110]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:12,562]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:17,465]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:18,869]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:20,023]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:31,310]\u001b[0m Trial 154 finished with value: 5.20435892517963 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034440712379665045, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09921969765441231, 'dropout_rate_Layer_2': 0.34264937323969646, 'dropout_rate_Layer_3': 0.30458637937117133, 'dropout_rate_Layer_4': 0.1310941468570006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007575819563493922, 'l1_Layer_2': 0.023131580260992827, 'l1_Layer_3': 0.02148476083365246, 'l1_Layer_4': 0.00022332470625814147, 'n_units_Layer_1': 255, 'n_units_Layer_2': 295, 'n_units_Layer_3': 110, 'n_units_Layer_4': 125}. Best is trial 106 with value: 4.5099109205526124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 21.67% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 53.75 | sMAPE for Test Set is: 47.59% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:00:33,796]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:34,136]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:36,679]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:37,707]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:42,466]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:46,592]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:46,958]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:51,834]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:54,351]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:00:56,183]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:00,673]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:04,210]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:09,329]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:09,629]\u001b[0m Trial 160 finished with value: 5.913566325897406 and parameters: {'n_hidden': 3, 'learning_rate': 0.007698655599208946, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12224590730878482, 'dropout_rate_Layer_2': 0.007419590116471225, 'dropout_rate_Layer_3': 0.07515932960428567, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0726802356053978e-05, 'l1_Layer_2': 1.7663826881743188e-05, 'l1_Layer_3': 0.0028433788396593426, 'n_units_Layer_1': 115, 'n_units_Layer_2': 230, 'n_units_Layer_3': 230}. Best is trial 106 with value: 4.5099109205526124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 24.22% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 49.03 | sMAPE for Test Set is: 41.75% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:01:15,699]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:16,974]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:21,817]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:21,925]\u001b[0m Trial 166 finished with value: 5.677129582006177 and parameters: {'n_hidden': 3, 'learning_rate': 0.010197545466948968, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10658316132092427, 'dropout_rate_Layer_2': 0.00857906407359385, 'dropout_rate_Layer_3': 0.07650184957302478, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0404045836445639e-05, 'l1_Layer_2': 1.9587824017669786e-05, 'l1_Layer_3': 0.0035315854614589664, 'n_units_Layer_1': 115, 'n_units_Layer_2': 235, 'n_units_Layer_3': 230}. Best is trial 106 with value: 4.5099109205526124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 23.38% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 49.15 | sMAPE for Test Set is: 42.19% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:01:23,120]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:30,506]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:33,988]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:39,181]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:40,742]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:41,306]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:45,787]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:49,549]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:52,059]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:55,698]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:01:56,995]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:00,327]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:03,704]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:08,242]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:10,949]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:15,116]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:19,527]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:23,329]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:26,986]\u001b[0m Trial 177 finished with value: 4.85333163079611 and parameters: {'n_hidden': 3, 'learning_rate': 0.004232747860095804, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33437561529625115, 'dropout_rate_Layer_2': 0.062281058132016905, 'dropout_rate_Layer_3': 0.07584117877543282, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.73892101458148e-05, 'l1_Layer_2': 0.0018925445779300022, 'l1_Layer_3': 0.056613384505701456, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 106 with value: 4.5099109205526124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 21.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.41 | sMAPE for Test Set is: 21.48% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:02:30,009]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:30,590]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:37,985]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:42,029]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:46,821]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:50,050]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:58,032]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:02:58,163]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:06,630]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:11,131]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:13,257]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:17,768]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:22,616]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:23,140]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:28,868]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:30,401]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:34,229]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:37,555]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:39,744]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:41,806]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:44,436]\u001b[0m Trial 205 finished with value: 4.48295598739037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035665874730122565, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33880759077969436, 'dropout_rate_Layer_2': 0.1982151600817227, 'dropout_rate_Layer_3': 0.07765287196770705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022289565051240861, 'l1_Layer_2': 0.0020850953920762325, 'l1_Layer_3': 0.009695293194094939, 'n_units_Layer_1': 300, 'n_units_Layer_2': 165, 'n_units_Layer_3': 90}. Best is trial 205 with value: 4.48295598739037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.31 | sMAPE for Test Set is: 20.90% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:03:47,174]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:49,004]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:53,527]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:03:58,374]\u001b[0m Trial 213 finished with value: 5.6476058392538 and parameters: {'n_hidden': 3, 'learning_rate': 0.004822686114811994, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10725162689174958, 'dropout_rate_Layer_2': 0.056693139406296264, 'dropout_rate_Layer_3': 0.05456220330558313, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.911736767958957e-05, 'l1_Layer_2': 3.215773807456981e-05, 'l1_Layer_3': 8.6993523443545e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 235}. Best is trial 205 with value: 4.48295598739037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 23.21% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 49.70 | sMAPE for Test Set is: 42.61% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:04:03,782]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:04:11,327]\u001b[0m Trial 219 finished with value: 5.514342868686718 and parameters: {'n_hidden': 3, 'learning_rate': 0.004231087845051138, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07807776240306469, 'dropout_rate_Layer_2': 0.06627795722586859, 'dropout_rate_Layer_3': 0.07006779306127342, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.37988740290712e-05, 'l1_Layer_2': 0.0002980662352698249, 'l1_Layer_3': 7.341893311387239e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195}. Best is trial 205 with value: 4.48295598739037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 52.23 | sMAPE for Test Set is: 45.47% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:04:15,235]\u001b[0m Trial 216 finished with value: 4.376190932843014 and parameters: {'n_hidden': 3, 'learning_rate': 0.004903592845230586, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32298099273132524, 'dropout_rate_Layer_2': 0.19954722723871143, 'dropout_rate_Layer_3': 0.07267507821504901, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005142660671482087, 'l1_Layer_2': 0.004143672924327258, 'l1_Layer_3': 0.0017214456723785563, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 100}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 18.89% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.56 | sMAPE for Test Set is: 19.65% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:04:16,190]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 22.66% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 51.78 | sMAPE for Test Set is: 44.60% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:04:20,915]\u001b[0m Trial 220 finished with value: 5.49861639885296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0043001187977086295, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08377942765094454, 'dropout_rate_Layer_2': 0.06352812755291676, 'dropout_rate_Layer_3': 0.05792263729069283, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.513161161547613e-05, 'l1_Layer_2': 0.0002782703358316038, 'l1_Layer_3': 7.690715527942415e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 300, 'n_units_Layer_3': 195}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:04:22,723]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:04:26,703]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:04:30,845]\u001b[0m Trial 194 finished with value: 5.402651191466145 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017851010455610524, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3235103768875278, 'dropout_rate_Layer_2': 0.23843907942216505, 'dropout_rate_Layer_3': 0.20911689048705343, 'dropout_rate_Layer_4': 0.3998726466229481, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014223740311732801, 'l1_Layer_2': 0.014577641185702973, 'l1_Layer_3': 0.007064680251571781, 'l1_Layer_4': 2.858078039425581e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 190, 'n_units_Layer_3': 300, 'n_units_Layer_4': 190}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 22.36% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 47.68 | sMAPE for Test Set is: 41.04% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:04:31,821]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:04:36,756]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:04:39,459]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:04:42,502]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:04:44,762]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:04:47,452]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:04:53,865]\u001b[0m Trial 225 finished with value: 5.308589715181661 and parameters: {'n_hidden': 3, 'learning_rate': 0.0045939737287993485, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06034184619335217, 'dropout_rate_Layer_2': 0.05587095675070802, 'dropout_rate_Layer_3': 0.1301113437362964, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003277612598715175, 'l1_Layer_2': 0.00037251343132002737, 'l1_Layer_3': 5.950331697500458e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 22.58% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 50.88 | sMAPE for Test Set is: 43.59% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:04:57,185]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:04:57,905]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:01,882]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:05,454]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:08,647]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:10,558]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:11,538]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:12,263]\u001b[0m Trial 232 finished with value: 4.957664315474731 and parameters: {'n_hidden': 3, 'learning_rate': 0.004780104966893052, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.058318533659979646, 'dropout_rate_Layer_2': 0.06013354232450231, 'dropout_rate_Layer_3': 0.1284321197220105, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018709398534796596, 'l1_Layer_2': 0.00032296435409376496, 'l1_Layer_3': 7.603784152907437e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 300, 'n_units_Layer_3': 195}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 20.63% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 49.86 | sMAPE for Test Set is: 42.45% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:05:12,542]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:17,568]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:19,141]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:21,561]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:23,624]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:23,772]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:24,295]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:27,435]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:33,378]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:33,984]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:38,238]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:41,133]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:42,280]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:45,917]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:51,571]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:05:54,870]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 23.00% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 52.24 | sMAPE for Test Set is: 45.25% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:05:57,069]\u001b[0m Trial 250 finished with value: 5.434369424393222 and parameters: {'n_hidden': 3, 'learning_rate': 0.004980461873372711, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06334179541167273, 'dropout_rate_Layer_2': 0.1154812742299039, 'dropout_rate_Layer_3': 0.13503173076411207, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00028061220209885, 'l1_Layer_2': 0.0003023967512040456, 'l1_Layer_3': 8.601542404668319e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 200}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:02,756]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:07,441]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:11,131]\u001b[0m Trial 256 finished with value: 5.265345274359404 and parameters: {'n_hidden': 4, 'learning_rate': 0.00308011628007723, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0072837311587925675, 'dropout_rate_Layer_2': 0.3542796896132024, 'dropout_rate_Layer_3': 0.30736262385543567, 'dropout_rate_Layer_4': 0.08464433388006731, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005664760916325117, 'l1_Layer_2': 0.05313623490263459, 'l1_Layer_3': 0.0172590615506352, 'l1_Layer_4': 0.0002551861502806973, 'n_units_Layer_1': 255, 'n_units_Layer_2': 280, 'n_units_Layer_3': 120, 'n_units_Layer_4': 110}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 21.59% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 49.74 | sMAPE for Test Set is: 42.76% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:06:13,971]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:19,017]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 21.39% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 49.13 | sMAPE for Test Set is: 42.03% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:06:21,949]\u001b[0m Trial 255 finished with value: 5.251603154848324 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030139790164700857, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014546894114637176, 'dropout_rate_Layer_2': 0.34126344907438044, 'dropout_rate_Layer_3': 0.2981405359833198, 'dropout_rate_Layer_4': 0.11072856751894081, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000625546492059008, 'l1_Layer_2': 0.03536946469716233, 'l1_Layer_3': 0.01811368211193182, 'l1_Layer_4': 0.0002170116060900401, 'n_units_Layer_1': 260, 'n_units_Layer_2': 275, 'n_units_Layer_3': 105, 'n_units_Layer_4': 105}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:22,681]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:25,192]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:31,949]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:32,152]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:36,202]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:40,273]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:42,677]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:45,709]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:49,420]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:06:53,256]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 23.88% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 53.06 | sMAPE for Test Set is: 46.34% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:06:55,756]\u001b[0m Trial 270 finished with value: 5.835323819618261 and parameters: {'n_hidden': 3, 'learning_rate': 0.0062817688546006716, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05669830872421669, 'dropout_rate_Layer_2': 0.12487934751864387, 'dropout_rate_Layer_3': 0.14578190906578392, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012805308952715225, 'l1_Layer_2': 0.0016167069584933167, 'l1_Layer_3': 3.553010173701008e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 180}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:00,538]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:00,708]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:07,628]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:07,690]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 19.32% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 45.44 | sMAPE for Test Set is: 38.35% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:07:12,807]\u001b[0m Trial 265 finished with value: 4.608635821214072 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012389733891592777, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052007177286171546, 'dropout_rate_Layer_2': 0.27630380637886637, 'dropout_rate_Layer_3': 0.36051128343224076, 'dropout_rate_Layer_4': 0.2896168259983205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009672779837405586, 'l1_Layer_2': 0.025508541064466372, 'l1_Layer_3': 0.003099679717675121, 'l1_Layer_4': 9.691173993446642e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 140, 'n_units_Layer_3': 125, 'n_units_Layer_4': 140}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:15,888]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:16,020]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:21,204]\u001b[0m Trial 275 finished with value: 5.439344881619141 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008069892485939535, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05062438941617222, 'dropout_rate_Layer_2': 0.27830710476274323, 'dropout_rate_Layer_3': 0.3607806701640012, 'dropout_rate_Layer_4': 0.21727920923488664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007910951773733546, 'l1_Layer_2': 0.0033390345926664713, 'l1_Layer_3': 0.06035987203813519, 'l1_Layer_4': 8.446036487556306e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 140, 'n_units_Layer_3': 130, 'n_units_Layer_4': 155}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 22.01% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 52.01 | sMAPE for Test Set is: 44.94% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:07:21,375]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:22,033]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:22,441]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:27,752]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:28,781]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:30,041]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:37,332]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:37,600]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:38,813]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:45,209]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:49,000]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:50,610]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:51,439]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:51,825]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:07:59,022]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:02,478]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:04,964]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:07,724]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:10,321]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:10,783]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:11,390]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:17,707]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:20,600]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:23,533]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:25,816]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:26,154]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:26,448]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:28,490]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:34,586]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:37,017]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:38,008]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:41,961]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:45,120]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:48,221]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:52,862]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:56,095]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:08:56,540]\u001b[0m Trial 315 finished with value: 5.289674830711209 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029484127855900905, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17140705575059365, 'dropout_rate_Layer_2': 0.041733426337257226, 'dropout_rate_Layer_3': 0.21259716586669442, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00039572662442593435, 'l1_Layer_2': 0.0002379412014445742, 'l1_Layer_3': 0.00022915920561072324, 'n_units_Layer_1': 150, 'n_units_Layer_2': 255, 'n_units_Layer_3': 210}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 21.85% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 53.50 | sMAPE for Test Set is: 46.83% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:09:03,073]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:05,401]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:06,444]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:10,938]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:15,823]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:21,024]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:24,420]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:28,537]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:29,172]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:31,519]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:34,744]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:36,733]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:39,030]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:41,163]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:45,410]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:50,064]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:53,777]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:58,054]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:09:58,438]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:10:05,048]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:10:09,025]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:10:13,068]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:10:18,101]\u001b[0m Trial 339 finished with value: 5.643373521890703 and parameters: {'n_hidden': 4, 'learning_rate': 0.004425528498692466, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09738292727428208, 'dropout_rate_Layer_2': 0.33436041785505327, 'dropout_rate_Layer_3': 0.32059273533610355, 'dropout_rate_Layer_4': 0.06222895976813206, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001122689992509115, 'l1_Layer_2': 0.027509147103133725, 'l1_Layer_3': 0.02635402096749548, 'l1_Layer_4': 0.0010997186971421428, 'n_units_Layer_1': 255, 'n_units_Layer_2': 150, 'n_units_Layer_3': 105, 'n_units_Layer_4': 130}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 22.98% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 52.03 | sMAPE for Test Set is: 45.09% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:10:21,116]\u001b[0m Trial 334 finished with value: 5.59417602558986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014780111348326784, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3247365056533473, 'dropout_rate_Layer_2': 0.23325884903743924, 'dropout_rate_Layer_3': 0.12772207872947935, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010327523513008845, 'l1_Layer_2': 0.003696368931627026, 'l1_Layer_3': 0.008911051362270975, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 100}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 22.83% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 55.41 | sMAPE for Test Set is: 49.26% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:10:25,178]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:10:29,302]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:10:33,222]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:10:33,947]\u001b[0m Trial 343 finished with value: 5.5911743344215745 and parameters: {'n_hidden': 4, 'learning_rate': 0.004407891070282413, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11022620188127671, 'dropout_rate_Layer_2': 0.33064794332680364, 'dropout_rate_Layer_3': 0.14969010883216038, 'dropout_rate_Layer_4': 0.1901238825582298, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000777356878869178, 'l1_Layer_2': 0.024056731363692335, 'l1_Layer_3': 0.019328362809120966, 'l1_Layer_4': 0.0007587653190981725, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 115, 'n_units_Layer_4': 140}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 22.23% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 50.74 | sMAPE for Test Set is: 43.58% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:10:40,643]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:10:40,949]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:10:46,614]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:10:56,273]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:01,005]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:04,064]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:10,090]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:10,263]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:17,849]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:18,368]\u001b[0m Trial 352 finished with value: 5.2564160778329905 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014086878792175747, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03304679690623814, 'dropout_rate_Layer_2': 0.29396418733101143, 'dropout_rate_Layer_3': 0.23853975086580453, 'dropout_rate_Layer_4': 0.23260525537249205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009266911343595523, 'l1_Layer_2': 0.010444235376504187, 'l1_Layer_3': 0.0013954081876096514, 'l1_Layer_4': 0.0003065593357508149, 'n_units_Layer_1': 265, 'n_units_Layer_2': 200, 'n_units_Layer_3': 85, 'n_units_Layer_4': 170}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 22.03% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 51.98 | sMAPE for Test Set is: 45.54% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:11:22,854]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:26,664]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:30,343]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:31,033]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:40,514]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:41,711]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:45,802]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:48,364]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:50,780]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:54,642]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:11:59,737]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:07,602]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:10,695]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 19.39% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 15.96 | sMAPE for Test Set is: 18.49% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:12:12,229]\u001b[0m Trial 322 finished with value: 4.471402416016731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006194672900512932, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.293979456658976, 'dropout_rate_Layer_2': 0.07157391319757617, 'dropout_rate_Layer_3': 0.06934502306708122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.96447316295606e-05, 'l1_Layer_2': 0.003295229730977107, 'l1_Layer_3': 0.001419393633387862, 'n_units_Layer_1': 285, 'n_units_Layer_2': 185, 'n_units_Layer_3': 60}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:15,816]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:18,015]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:18,497]\u001b[0m Trial 362 finished with value: 5.44154382394881 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007619182196774028, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08536828437557534, 'dropout_rate_Layer_2': 0.18270272665970885, 'dropout_rate_Layer_3': 0.23377075466707084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7935031817096507e-05, 'l1_Layer_2': 0.007294155852817477, 'l1_Layer_3': 0.0066373396734523415, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 165}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 22.21% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 54.96 | sMAPE for Test Set is: 48.71% | rMAE for Test Set is: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:12:21,431]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:26,732]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:30,892]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:34,748]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:35,380]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:40,118]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:45,356]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:12:48,127]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:13:06,835]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:13:11,931]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:13:12,199]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:13:19,703]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:13:23,400]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:13:30,967]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:14:25,450]\u001b[0m Trial 390 finished with value: 4.47684270481988 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015167582215925921, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16350594141204072, 'dropout_rate_Layer_2': 0.08778924682974017, 'dropout_rate_Layer_3': 0.20869950839345308, 'dropout_rate_Layer_4': 0.3035762846354689, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.049934731214622e-05, 'l1_Layer_2': 0.00138624548732703, 'l1_Layer_3': 0.025000223809018757, 'l1_Layer_4': 0.00047831781592008564, 'n_units_Layer_1': 60, 'n_units_Layer_2': 210, 'n_units_Layer_3': 80, 'n_units_Layer_4': 160}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 19.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.35 | sMAPE for Test Set is: 19.58% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:14:43,279]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:14:53,069]\u001b[0m Trial 388 finished with value: 4.660897797749292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006796073570305685, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3020547809652889, 'dropout_rate_Layer_2': 0.05697503710375745, 'dropout_rate_Layer_3': 0.05541364926932825, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.2177054671047515e-05, 'l1_Layer_2': 0.000976321947821853, 'l1_Layer_3': 0.00020436765247196389, 'n_units_Layer_1': 270, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 20.83% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 18.39 | sMAPE for Test Set is: 21.18% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:15:03,651]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:15:06,916]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:15:32,943]\u001b[0m Trial 383 finished with value: 4.532078850033832 and parameters: {'n_hidden': 3, 'learning_rate': 0.000541231869530873, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29019286120110643, 'dropout_rate_Layer_2': 0.07230690325279436, 'dropout_rate_Layer_3': 0.07868991476653117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5677127251876427e-05, 'l1_Layer_2': 0.0028123884105788247, 'l1_Layer_3': 0.0009723760661502443, 'n_units_Layer_1': 120, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 15.94 | sMAPE for Test Set is: 18.54% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:16:04,462]\u001b[0m Trial 395 finished with value: 4.614390188290314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006836026740082413, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30281769414857734, 'dropout_rate_Layer_2': 0.047914024132297506, 'dropout_rate_Layer_3': 0.06993828747774312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2586080722150342e-05, 'l1_Layer_2': 0.0006962099678294239, 'l1_Layer_3': 0.00018394747938924453, 'n_units_Layer_1': 300, 'n_units_Layer_2': 195, 'n_units_Layer_3': 70}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 19.94% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 16.17 | sMAPE for Test Set is: 18.93% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:16:10,702]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:16:15,484]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:16:33,998]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:16:44,562]\u001b[0m Trial 391 finished with value: 4.378990364831111 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005697180991035141, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2891148368735936, 'dropout_rate_Layer_2': 0.04561605860518897, 'dropout_rate_Layer_3': 0.06997082110253793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9442433040157404e-05, 'l1_Layer_2': 0.00199289295048733, 'l1_Layer_3': 0.0002313050453288075, 'n_units_Layer_1': 290, 'n_units_Layer_2': 255, 'n_units_Layer_3': 65}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 19.21% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 16.79 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:16:50,129]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:17:02,747]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:17:07,896]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:17:19,052]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:17:29,243]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:17:34,580]\u001b[0m Trial 396 finished with value: 4.665126193204173 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006521712815671927, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2522758292517963, 'dropout_rate_Layer_2': 0.05375153314948622, 'dropout_rate_Layer_3': 0.06992456682266157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.022991393711996e-05, 'l1_Layer_2': 0.0007392600147605527, 'l1_Layer_3': 0.0009716400059952472, 'n_units_Layer_1': 125, 'n_units_Layer_2': 240, 'n_units_Layer_3': 60}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 20.17% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 17.26 | sMAPE for Test Set is: 20.15% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:17:43,003]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:17:47,310]\u001b[0m Trial 406 finished with value: 5.224789056893068 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030525703789534226, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018841352531738416, 'dropout_rate_Layer_2': 0.3412437485795712, 'dropout_rate_Layer_3': 0.2969331856607464, 'dropout_rate_Layer_4': 0.1012879971625806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006774114187493447, 'l1_Layer_2': 0.03462777090170235, 'l1_Layer_3': 0.014772547070103819, 'l1_Layer_4': 0.00022321098496337727, 'n_units_Layer_1': 265, 'n_units_Layer_2': 285, 'n_units_Layer_3': 100, 'n_units_Layer_4': 100}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 21.30% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 48.72 | sMAPE for Test Set is: 41.62% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:17:59,273]\u001b[0m Trial 402 finished with value: 4.508050654207321 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005901718484035295, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3112827626643531, 'dropout_rate_Layer_2': 0.04240374652333523, 'dropout_rate_Layer_3': 0.054371533029196645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3381096152754963e-05, 'l1_Layer_2': 0.0004534195386536986, 'l1_Layer_3': 0.0009194314325768685, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 19.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 17.49 | sMAPE for Test Set is: 20.25% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:18:13,969]\u001b[0m Trial 408 finished with value: 4.428342536078522 and parameters: {'n_hidden': 3, 'learning_rate': 0.005551740187213461, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1476740459413573, 'dropout_rate_Layer_2': 0.13770065361716785, 'dropout_rate_Layer_3': 0.16895598813762547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4072458570922834e-05, 'l1_Layer_2': 0.013601658643336487, 'l1_Layer_3': 0.005842892470517039, 'n_units_Layer_1': 80, 'n_units_Layer_2': 210, 'n_units_Layer_3': 70}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 18.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 18.05 | sMAPE for Test Set is: 19.85% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:18:33,338]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:18:37,162]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:18:45,815]\u001b[0m Trial 404 finished with value: 4.596993427547516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006914971988583293, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3068346646557665, 'dropout_rate_Layer_2': 0.04173502539106616, 'dropout_rate_Layer_3': 0.0743985285613658, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2884239658573734e-05, 'l1_Layer_2': 0.00098268400556202, 'l1_Layer_3': 0.001012328268732516, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 20.07% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 16.65 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:19:02,397]\u001b[0m Trial 410 finished with value: 4.7276554465470975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006138761788916929, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24924046328404834, 'dropout_rate_Layer_2': 0.042909567250166834, 'dropout_rate_Layer_3': 0.06793011927294171, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3564483194712313e-05, 'l1_Layer_2': 0.00040547915626457657, 'l1_Layer_3': 0.0009566418718107116, 'n_units_Layer_1': 120, 'n_units_Layer_2': 185, 'n_units_Layer_3': 50}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 19.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 18.34 | sMAPE for Test Set is: 21.04% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:19:13,148]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:19:18,095]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:19:25,567]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:19:26,243]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:19:34,514]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:19:51,224]\u001b[0m Trial 409 finished with value: 4.845044316585239 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007129037241742779, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30576124369426705, 'dropout_rate_Layer_2': 0.040727432597032785, 'dropout_rate_Layer_3': 0.0748023118622243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.342641585647585e-05, 'l1_Layer_2': 0.0007244351199663513, 'l1_Layer_3': 0.0009180161831178621, 'n_units_Layer_1': 120, 'n_units_Layer_2': 255, 'n_units_Layer_3': 60}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 20.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 17.28 | sMAPE for Test Set is: 20.53% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:20:08,359]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:20:11,945]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:20:16,236]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:20:21,272]\u001b[0m Trial 416 finished with value: 4.582184410497008 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005981743028761118, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3077544903949539, 'dropout_rate_Layer_2': 0.02548394719153514, 'dropout_rate_Layer_3': 0.076956413152521, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0162293132107388e-05, 'l1_Layer_2': 0.00044171646170670833, 'l1_Layer_3': 0.0008704916726353302, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 19.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 16.13 | sMAPE for Test Set is: 18.84% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:20:29,351]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:20:45,217]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:20:47,924]\u001b[0m Trial 420 finished with value: 4.457462093276676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006159569665245521, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2538183044287166, 'dropout_rate_Layer_2': 0.027914209989432538, 'dropout_rate_Layer_3': 0.0774583112837193, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8989714466088604e-05, 'l1_Layer_2': 0.0002528908614478602, 'l1_Layer_3': 0.0008766443954294565, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 60}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 18.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.24 | sMAPE for Test Set is: 19.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:20:50,450]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:20:54,198]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:21:03,385]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:21:07,407]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:21:11,657]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:21:12,322]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:21:17,017]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:21:24,972]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:21:30,805]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:21:33,678]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:21:34,778]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:21:37,878]\u001b[0m Trial 425 finished with value: 4.626918658754039 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006813455705734278, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2471422467572612, 'dropout_rate_Layer_2': 0.026210968777618138, 'dropout_rate_Layer_3': 0.08077799067031793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.077541557419091e-05, 'l1_Layer_2': 0.00041198369179870024, 'l1_Layer_3': 0.0009429153621041492, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 19.70% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 16.65 | sMAPE for Test Set is: 19.36% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:21:46,265]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:21:53,458]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:22:02,009]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:22:08,026]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:22:24,951]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:22:33,433]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:22:39,582]\u001b[0m Trial 431 finished with value: 4.602044839225675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006722155434891079, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2479420547219788, 'dropout_rate_Layer_2': 0.021741375189625288, 'dropout_rate_Layer_3': 0.08433065411932938, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.600466495101661e-05, 'l1_Layer_2': 0.0002959484612860862, 'l1_Layer_3': 0.0010511178716702872, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 55}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 19.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 16.33 | sMAPE for Test Set is: 19.05% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:22:49,537]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:22:53,069]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:23:06,835]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:23:09,640]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:23:23,047]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:23:26,973]\u001b[0m Trial 444 finished with value: 4.480882516576249 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005761749106907841, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2615131751013345, 'dropout_rate_Layer_2': 0.0030380568206098447, 'dropout_rate_Layer_3': 0.06478825771597092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.68779672492631e-05, 'l1_Layer_2': 0.0002936643301761455, 'l1_Layer_3': 0.0006839766273418046, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 50}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 19.46% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 18.22 | sMAPE for Test Set is: 20.72% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:23:32,971]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:23:37,689]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:23:41,274]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:23:56,893]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:23:57,981]\u001b[0m Trial 456 finished with value: 5.1014207041047746 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032515448555653845, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1006396007776018, 'dropout_rate_Layer_2': 0.10129214599115394, 'dropout_rate_Layer_3': 0.12656386140468898, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025628779244090896, 'l1_Layer_2': 0.0002566140246780292, 'l1_Layer_3': 3.331632295394092e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 285, 'n_units_Layer_3': 205}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 52.20 | sMAPE for Test Set is: 45.18% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:24:07,143]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:24:17,669]\u001b[0m Trial 450 finished with value: 4.510496607105159 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007668750236186572, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2364874220041753, 'dropout_rate_Layer_2': 0.028890620062911827, 'dropout_rate_Layer_3': 0.087884509212293, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3450434882471407e-05, 'l1_Layer_2': 0.0004933461082716347, 'l1_Layer_3': 0.0012809350111572684, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 55}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 19.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 17.40 | sMAPE for Test Set is: 20.59% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:24:31,863]\u001b[0m Trial 460 finished with value: 5.28603124422726 and parameters: {'n_hidden': 3, 'learning_rate': 0.003486856170625672, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08598062227571576, 'dropout_rate_Layer_2': 0.03447683082607517, 'dropout_rate_Layer_3': 0.11772542274171768, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009071386611249306, 'l1_Layer_2': 6.937474262674587e-05, 'l1_Layer_3': 2.2697962433794688e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 51.87 | sMAPE for Test Set is: 44.84% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:25:16,198]\u001b[0m Trial 454 finished with value: 4.463079989136178 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007275421478598555, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.270147069270475, 'dropout_rate_Layer_2': 0.006987313756716252, 'dropout_rate_Layer_3': 0.0578006480935156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.858059905709297e-05, 'l1_Layer_2': 0.0006710527773282034, 'l1_Layer_3': 0.0005321940704503969, 'n_units_Layer_1': 290, 'n_units_Layer_2': 195, 'n_units_Layer_3': 50}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.00 | sMAPE for Test Set is: 18.65% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:25:25,163]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:25:29,624]\u001b[0m Trial 458 finished with value: 4.491280219960568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006872338664372825, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2774203862712104, 'dropout_rate_Layer_2': 0.010321568211562496, 'dropout_rate_Layer_3': 0.06263938237604252, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.558578505106506e-05, 'l1_Layer_2': 0.0005730370825718725, 'l1_Layer_3': 0.0005452515538047919, 'n_units_Layer_1': 290, 'n_units_Layer_2': 195, 'n_units_Layer_3': 50}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 19.86% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 17.95 | sMAPE for Test Set is: 20.26% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:25:32,300]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:25:36,000]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:25:42,885]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:25:46,025]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:25:54,721]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:26:02,910]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:26:09,962]\u001b[0m Trial 459 finished with value: 4.5387443968291175 and parameters: {'n_hidden': 3, 'learning_rate': 0.000703023800389452, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3066833921838824, 'dropout_rate_Layer_2': 0.007480407444473439, 'dropout_rate_Layer_3': 0.06446136134460664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.192448270854477e-05, 'l1_Layer_2': 0.0006921971286400271, 'l1_Layer_3': 0.0006544670412828922, 'n_units_Layer_1': 295, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 20.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.02 | sMAPE for Test Set is: 21.46% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:26:18,336]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:26:23,910]\u001b[0m Trial 461 finished with value: 4.602305964077914 and parameters: {'n_hidden': 3, 'learning_rate': 0.000666850490517094, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23018479718819188, 'dropout_rate_Layer_2': 0.03470943697601264, 'dropout_rate_Layer_3': 0.062039961123204354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1657685412160676e-05, 'l1_Layer_2': 0.0005841865163132959, 'l1_Layer_3': 0.0014285123583370326, 'n_units_Layer_1': 125, 'n_units_Layer_2': 190, 'n_units_Layer_3': 55}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 20.88% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 15.79 | sMAPE for Test Set is: 18.34% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:26:27,641]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:26:30,588]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:26:35,822]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:26:40,508]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:26:44,601]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:27:00,134]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:27:08,851]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:27:13,070]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:27:30,623]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:27:34,350]\u001b[0m Trial 474 finished with value: 4.588867157178143 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007294591599883017, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22611921376411254, 'dropout_rate_Layer_2': 0.03025108901630725, 'dropout_rate_Layer_3': 0.04130055674153259, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.026131969371145e-05, 'l1_Layer_2': 0.000600631453882869, 'l1_Layer_3': 0.001593027937906901, 'n_units_Layer_1': 135, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 216 with value: 4.376190932843014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 19.43% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 16.58 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:27:41,015]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:27:44,416]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:27:48,563]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:27:52,829]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:27:55,160]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:27:59,491]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:28:03,523]\u001b[0m Trial 467 finished with value: 4.3163796874788085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006481310703362182, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28086254783369274, 'dropout_rate_Layer_2': 0.01703238426113317, 'dropout_rate_Layer_3': 0.06111662688284389, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.006513012517082e-05, 'l1_Layer_2': 0.0005318146962102922, 'l1_Layer_3': 0.0007185781539590098, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 55}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 19.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 17.07 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:28:03,651]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:28:04,358]\u001b[0m Trial 472 finished with value: 4.432955223560996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007098454132655476, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22229505074823883, 'dropout_rate_Layer_2': 0.023193792769655372, 'dropout_rate_Layer_3': 0.058671729093842176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0018683211343348e-05, 'l1_Layer_2': 0.0005873119588615484, 'l1_Layer_3': 0.0005937920278459979, 'n_units_Layer_1': 285, 'n_units_Layer_2': 190, 'n_units_Layer_3': 55}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 19.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.16 | sMAPE for Test Set is: 18.58% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:28:12,718]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:28:15,516]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:28:20,626]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:28:30,052]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:28:48,070]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:28:55,872]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:29:00,350]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:29:13,695]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:29:15,849]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:29:24,175]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:29:26,435]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:29:34,833]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:29:44,672]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:29:59,859]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:30:07,660]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:30:13,870]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:30:17,673]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:30:17,969]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:30:25,116]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:30:28,994]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:30:33,119]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:30:43,637]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:30:49,815]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:30:52,992]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:30:57,153]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:31:05,142]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:31:11,138]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:31:13,973]\u001b[0m Trial 495 finished with value: 4.337988134625895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006187256890557325, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20995877682237168, 'dropout_rate_Layer_2': 0.03726119881920254, 'dropout_rate_Layer_3': 0.06749305245686657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.581908696379523e-05, 'l1_Layer_2': 0.0006117295800927344, 'l1_Layer_3': 0.0005771545641906201, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 60}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 19.22% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 15.58 | sMAPE for Test Set is: 18.34% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:31:17,819]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:31:22,589]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:31:38,131]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:31:41,882]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:31:50,083]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:31:58,622]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:32:01,627]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:32:09,553]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:32:13,837]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:32:17,639]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:32:23,341]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:32:28,338]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:32:33,829]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:32:38,435]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:33:06,281]\u001b[0m Trial 523 finished with value: 4.523488800864158 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005158402823055385, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21163903361499778, 'dropout_rate_Layer_2': 0.049282410509380106, 'dropout_rate_Layer_3': 0.06980554481867463, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.552310358133415e-05, 'l1_Layer_2': 0.00032524312612090963, 'l1_Layer_3': 0.0004349741399807994, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 20.00% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 15.69 | sMAPE for Test Set is: 18.29% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:33:10,865]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:33:23,313]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:33:41,167]\u001b[0m Trial 533 finished with value: 4.344681510156023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006768721973707202, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22634773485221693, 'dropout_rate_Layer_2': 0.015286819884975612, 'dropout_rate_Layer_3': 0.07033506907735765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2151162667692736e-05, 'l1_Layer_2': 0.0006893788541405285, 'l1_Layer_3': 0.0011028959150841513, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 18.57% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 18.57 | sMAPE for Test Set is: 21.04% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:33:46,372]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:33:51,870]\u001b[0m Trial 537 finished with value: 5.40387742464257 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022342056532242026, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09809857447657395, 'dropout_rate_Layer_2': 0.07920885917821396, 'dropout_rate_Layer_3': 0.20670736724759334, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011476889093932034, 'l1_Layer_2': 0.0009548355642105728, 'l1_Layer_3': 0.0003198415682605508, 'n_units_Layer_1': 195, 'n_units_Layer_2': 255, 'n_units_Layer_3': 215}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 22.02% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 52.24 | sMAPE for Test Set is: 45.67% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:33:57,351]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:34:02,709]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:34:03,171]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:34:10,926]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:34:11,190]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:34:17,836]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:34:24,000]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:34:41,862]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:34:47,282]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:34:52,886]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:34:55,184]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:34:58,543]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:02,159]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:04,651]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:07,695]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 19.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 15.52 | sMAPE for Test Set is: 18.05% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:35:08,186]\u001b[0m Trial 539 finished with value: 4.489529604608523 and parameters: {'n_hidden': 3, 'learning_rate': 0.000781935741656727, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19554741415785568, 'dropout_rate_Layer_2': 0.01035804214659002, 'dropout_rate_Layer_3': 0.038991208561168854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0261956845086647e-05, 'l1_Layer_2': 0.0002726712265493641, 'l1_Layer_3': 0.0005824103780809292, 'n_units_Layer_1': 290, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:10,628]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:14,441]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:18,931]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:20,866]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:21,219]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:21,327]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:23,006]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:29,532]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:32,016]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:32,051]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:32,926]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:38,205]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:41,581]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:44,081]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:46,590]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:35:48,286]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:36:02,726]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:36:04,973]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:36:05,586]\u001b[0m Trial 565 finished with value: 4.779243092771581 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010062779658480206, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20908415473912614, 'dropout_rate_Layer_2': 0.14438508654208165, 'dropout_rate_Layer_3': 0.1206466830322487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.000659884431097219, 'l1_Layer_2': 3.917573880819202e-05, 'l1_Layer_3': 0.00012914902658558956, 'n_units_Layer_1': 180, 'n_units_Layer_2': 60, 'n_units_Layer_3': 210}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 19.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.82 | sMAPE for Test Set is: 41.14% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:36:10,833]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:36:12,887]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:36:14,986]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:36:17,962]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:36:24,838]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:36:30,458]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:36:42,094]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:36:59,826]\u001b[0m Trial 567 finished with value: 4.449360053046168 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006932392355681536, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22938940145664688, 'dropout_rate_Layer_2': 0.000641753491186549, 'dropout_rate_Layer_3': 0.0688493249217223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7223878484495283e-05, 'l1_Layer_2': 0.0002882988230720968, 'l1_Layer_3': 0.0013704200528757093, 'n_units_Layer_1': 285, 'n_units_Layer_2': 185, 'n_units_Layer_3': 60}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 19.51% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.15 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:37:07,405]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:37:11,151]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:37:13,681]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:37:20,251]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:37:23,288]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:37:26,887]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:37:29,863]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:37:40,049]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:37:43,394]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:37:43,536]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:37:50,355]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:37:54,613]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:38:00,995]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:38:05,762]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:38:13,410]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:38:17,053]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:38:21,838]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:38:22,095]\u001b[0m Trial 581 finished with value: 4.61960999051128 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005382515234011779, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2055597684858711, 'dropout_rate_Layer_2': 0.025581714351755165, 'dropout_rate_Layer_3': 0.050285424392392974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4478727664630117e-05, 'l1_Layer_2': 0.00028451217228838083, 'l1_Layer_3': 0.0011692695428500586, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 20.59% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 15.94 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:38:29,303]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:38:43,304]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:38:56,048]\u001b[0m Trial 582 finished with value: 4.615009760260929 and parameters: {'n_hidden': 3, 'learning_rate': 0.000504921461450458, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20637817565944816, 'dropout_rate_Layer_2': 0.025001904012511116, 'dropout_rate_Layer_3': 0.0490369506079158, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4612794599487311e-05, 'l1_Layer_2': 0.0002924765306909207, 'l1_Layer_3': 0.0011458540647025877, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 20.88% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 16.85 | sMAPE for Test Set is: 20.01% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:39:00,672]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:02,376]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:07,950]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:13,794]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:17,809]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:18,863]\u001b[0m Trial 600 finished with value: 5.722567461703593 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008793889280543129, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15613986087438597, 'dropout_rate_Layer_2': 0.19567791752730698, 'dropout_rate_Layer_3': 0.21207471797797295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009002129162235601, 'l1_Layer_2': 0.03322226510111383, 'l1_Layer_3': 0.01238773981404896, 'n_units_Layer_1': 60, 'n_units_Layer_2': 95, 'n_units_Layer_3': 70}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 23.46% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 55.66 | sMAPE for Test Set is: 49.65% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:39:22,547]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:25,284]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:28,367]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:31,108]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:35,514]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:36,068]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:42,606]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:45,518]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:50,716]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:39:59,086]\u001b[0m Trial 607 finished with value: 4.426432788362631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005812761653725096, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28731059974637363, 'dropout_rate_Layer_2': 0.045815530698270816, 'dropout_rate_Layer_3': 0.060945232262903465, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1339371908248626e-05, 'l1_Layer_2': 0.0002108967771213249, 'l1_Layer_3': 0.0006839781729792433, 'n_units_Layer_1': 285, 'n_units_Layer_2': 145, 'n_units_Layer_3': 70}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.45 | sMAPE for Test Set is: 18.75% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:40:05,702]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:40:07,854]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:40:12,970]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:40:13,490]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:40:20,272]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:40:25,114]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:40:29,448]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:40:31,678]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:40:36,911]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:40:39,503]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:40:42,830]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:40:47,189]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:03,962]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:07,627]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:13,838]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:17,156]\u001b[0m Trial 622 finished with value: 4.366775969557444 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007615004770473151, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25205750407762056, 'dropout_rate_Layer_2': 0.2082008682431728, 'dropout_rate_Layer_3': 0.3013597498154888, 'dropout_rate_Layer_4': 0.08476741353057173, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010296991806934415, 'l1_Layer_2': 0.003969583200379167, 'l1_Layer_3': 0.0017913182464884276, 'l1_Layer_4': 7.510673456474477e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 205, 'n_units_Layer_4': 135}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 18.74% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.87 | sMAPE for Test Set is: 28.90% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:41:17,564]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:22,953]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:28,413]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:28,582]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:42,015]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:44,938]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:48,319]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:53,564]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:56,832]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:41:58,991]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:42:07,029]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:42:15,617]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:42:17,767]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:42:21,554]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:42:22,919]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:42:33,216]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:42:39,849]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:42:46,963]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:42:47,650]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:42:53,813]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:42:57,407]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:43:00,905]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:43:06,399]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:43:14,657]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:43:19,270]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:43:22,777]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:43:32,535]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:43:47,040]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:43:50,538]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:43:55,501]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:43:58,408]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:43:59,226]\u001b[0m Trial 655 finished with value: 5.001270875904221 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005751202864993156, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010444305961296783, 'dropout_rate_Layer_2': 0.22681039412391069, 'dropout_rate_Layer_3': 0.32224827093917496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005680719211506495, 'l1_Layer_2': 0.002911781187512125, 'l1_Layer_3': 0.032711677095992264, 'n_units_Layer_1': 245, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 21.07% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 17.28 | sMAPE for Test Set is: 19.83% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:44:05,914]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:44:06,309]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:44:16,607]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:44:20,943]\u001b[0m Trial 661 finished with value: 4.3836128167301665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012390668804301767, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18605872992265288, 'dropout_rate_Layer_2': 0.19671076271920057, 'dropout_rate_Layer_3': 0.19539451482275383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011944303025956785, 'l1_Layer_2': 0.015619759588108812, 'l1_Layer_3': 0.0007642260823144735, 'n_units_Layer_1': 50, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 19.34% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 45.28 | sMAPE for Test Set is: 38.23% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:44:32,565]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:44:36,790]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:44:39,015]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:44:43,179]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:44:43,313]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:44:50,225]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:02,157]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:03,239]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:10,638]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:17,222]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:25,027]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:29,494]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:30,293]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:30,735]\u001b[0m Trial 667 finished with value: 4.55288155949001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007212612907819523, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21735547844560973, 'dropout_rate_Layer_2': 0.05924485944436145, 'dropout_rate_Layer_3': 0.07353336305207644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7762347811158817e-05, 'l1_Layer_2': 0.0009431179096257209, 'l1_Layer_3': 0.0010423817319803624, 'n_units_Layer_1': 290, 'n_units_Layer_2': 180, 'n_units_Layer_3': 65}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 19.58% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 17.33 | sMAPE for Test Set is: 19.79% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:45:39,930]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:43,419]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:49,605]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:52,542]\u001b[0m Trial 678 finished with value: 4.7313573939886595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005701243073114191, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009644754031722942, 'dropout_rate_Layer_2': 0.23193814123209344, 'dropout_rate_Layer_3': 0.2848012005144604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013153976992106855, 'l1_Layer_2': 0.001409375250356099, 'l1_Layer_3': 0.028358506431758978, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 19.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 17.13 | sMAPE for Test Set is: 19.74% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:45:55,126]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:59,569]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:45:59,744]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:46:04,969]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:46:07,459]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:46:11,388]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:46:16,858]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:46:30,651]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:46:34,533]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:46:36,540]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:46:39,516]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:46:43,489]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:47:01,046]\u001b[0m Trial 699 finished with value: 5.346657448268755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016970137360599051, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.036090894649661365, 'dropout_rate_Layer_2': 0.19398563071737246, 'dropout_rate_Layer_3': 0.15420035074784824, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0004667836432868216, 'l1_Layer_2': 0.0006224282959108308, 'l1_Layer_3': 0.00013746895616984007, 'n_units_Layer_1': 170, 'n_units_Layer_2': 175, 'n_units_Layer_3': 160}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 22.15% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 56.23 | sMAPE for Test Set is: 50.61% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:47:01,663]\u001b[0m Trial 693 finished with value: 4.657263387439421 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016414271857143202, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03510723799594062, 'dropout_rate_Layer_2': 0.10924483285591946, 'dropout_rate_Layer_3': 0.16144528258871416, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000508069537816895, 'l1_Layer_2': 0.0005981074434500456, 'l1_Layer_3': 0.00014109384998234824, 'n_units_Layer_1': 165, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 20.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 52.45 | sMAPE for Test Set is: 46.51% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:47:29,329]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:47:37,242]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:47:44,935]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:47:46,931]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:47:47,259]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:47:58,104]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:48:13,957]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:48:23,922]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:49:05,928]\u001b[0m Trial 694 finished with value: 4.365345704005815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005983324405955943, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30663020872086316, 'dropout_rate_Layer_2': 0.05601618940603219, 'dropout_rate_Layer_3': 0.07810400729001686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7429333037649068e-05, 'l1_Layer_2': 0.005619627330659028, 'l1_Layer_3': 0.0006619581813532145, 'n_units_Layer_1': 295, 'n_units_Layer_2': 180, 'n_units_Layer_3': 65}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.04 | sMAPE for Test Set is: 20.88% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:49:14,549]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:49:22,775]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:49:53,723]\u001b[0m Trial 712 finished with value: 4.802989405133487 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007205121318718472, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045273315629593774, 'dropout_rate_Layer_2': 0.14693575965285258, 'dropout_rate_Layer_3': 0.11485856768190737, 'dropout_rate_Layer_4': 0.09326697766988877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0001945635337191089, 'l1_Layer_2': 0.0012326970773516744, 'l1_Layer_3': 3.483426647607546e-05, 'l1_Layer_4': 1.5664387365245326e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185, 'n_units_Layer_4': 300}. Best is trial 467 with value: 4.3163796874788085.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 20.16% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 50.59 | sMAPE for Test Set is: 43.56% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:49:54,402]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:50:02,851]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:50:05,279]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:50:06,059]\u001b[0m Trial 709 finished with value: 4.2104837025542885 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005602316255625167, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1394409699122891, 'dropout_rate_Layer_2': 0.019344969851546663, 'dropout_rate_Layer_3': 0.046090080430285826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4050654646470087e-05, 'l1_Layer_2': 0.00043947216058431277, 'l1_Layer_3': 0.0008901261970534745, 'n_units_Layer_1': 200, 'n_units_Layer_2': 175, 'n_units_Layer_3': 55}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 18.89% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 15.80 | sMAPE for Test Set is: 18.14% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:50:12,477]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:50:14,656]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:50:17,447]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:50:21,614]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:50:38,608]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:50:42,358]\u001b[0m Trial 721 finished with value: 5.311292363678623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023218669692701443, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33783210623023846, 'dropout_rate_Layer_2': 0.23192003623599972, 'dropout_rate_Layer_3': 0.17545400398447575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.0633842924170414e-05, 'l1_Layer_2': 0.030451669378062575, 'l1_Layer_3': 0.009333639450496761, 'n_units_Layer_1': 75, 'n_units_Layer_2': 65, 'n_units_Layer_3': 55}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 54.73 | sMAPE for Test Set is: 48.38% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:50:42,743]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:50:47,915]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:50:48,625]\u001b[0m Trial 707 finished with value: 4.4645150051904485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005637826275330222, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24196658634356796, 'dropout_rate_Layer_2': 0.015950563213141037, 'dropout_rate_Layer_3': 0.04394611028125616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007116438419673529, 'l1_Layer_2': 0.0003905219744164601, 'l1_Layer_3': 0.0009915451392326145, 'n_units_Layer_1': 190, 'n_units_Layer_2': 175, 'n_units_Layer_3': 55}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 19.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 15.54 | sMAPE for Test Set is: 18.28% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:50:52,525]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:50:56,507]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:51:04,355]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:51:26,900]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:51:32,523]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:51:36,780]\u001b[0m Trial 723 finished with value: 4.74854171190864 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005125622527298961, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013168482758333155, 'dropout_rate_Layer_2': 0.14585590922816774, 'dropout_rate_Layer_3': 0.08734163417294653, 'dropout_rate_Layer_4': 0.10368590247452078, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00015753130484473413, 'l1_Layer_2': 0.0010389739925586593, 'l1_Layer_3': 9.479800783424054e-05, 'l1_Layer_4': 9.215919922085834e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 105, 'n_units_Layer_3': 170, 'n_units_Layer_4': 230}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 19.83% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 53.43 | sMAPE for Test Set is: 47.54% | rMAE for Test Set is: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:51:44,810]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:51:51,184]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:00,536]\u001b[0m Trial 729 finished with value: 4.432326254811183 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023240736366436656, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35036591915371645, 'dropout_rate_Layer_2': 0.14824668315951564, 'dropout_rate_Layer_3': 0.17170881135758254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.286962345855006e-05, 'l1_Layer_2': 0.0284078538044671, 'l1_Layer_3': 0.008544636118523054, 'n_units_Layer_1': 75, 'n_units_Layer_2': 70, 'n_units_Layer_3': 50}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 19.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.87 | sMAPE for Test Set is: 19.24% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:52:03,972]\u001b[0m Trial 731 finished with value: 4.372285051131647 and parameters: {'n_hidden': 3, 'learning_rate': 0.002402632280841631, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3313431376591139, 'dropout_rate_Layer_2': 0.02922411385224405, 'dropout_rate_Layer_3': 0.17570920217479763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.866760658939413e-05, 'l1_Layer_2': 0.029790941431962543, 'l1_Layer_3': 0.009156704519642456, 'n_units_Layer_1': 75, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 18.69% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.07 | sMAPE for Test Set is: 20.56% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:52:04,557]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:12,152]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:14,334]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:14,953]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:20,708]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:24,983]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:27,222]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:29,506]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:32,199]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:32,888]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:39,037]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:52:39,182]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:53:23,407]\u001b[0m Trial 737 finished with value: 4.486539225476477 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005002755314440089, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020259358007063633, 'dropout_rate_Layer_2': 0.14789603289914777, 'dropout_rate_Layer_3': 0.08125407571434172, 'dropout_rate_Layer_4': 0.09919288868964832, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.372624623066396e-05, 'l1_Layer_2': 0.0048095481341723, 'l1_Layer_3': 0.0004442577534456305, 'l1_Layer_4': 8.162614428817129e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150, 'n_units_Layer_4': 235}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.49 | sMAPE for Test Set is: 43.25% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:54:03,994]\u001b[0m Trial 747 finished with value: 4.357223841052229 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020559474336949045, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31644990465635187, 'dropout_rate_Layer_2': 0.025502300902947004, 'dropout_rate_Layer_3': 0.17022366324349444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.861116507166562e-05, 'l1_Layer_2': 0.03797220097845083, 'l1_Layer_3': 0.009756230888846983, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 19.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.46 | sMAPE for Test Set is: 19.43% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:54:11,075]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:54:16,576]\u001b[0m Trial 752 finished with value: 4.371393802772269 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031555556074360875, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33587787250132667, 'dropout_rate_Layer_2': 0.04497259621577128, 'dropout_rate_Layer_3': 0.16903162288656687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.518656745506138e-05, 'l1_Layer_2': 0.04267463725843378, 'l1_Layer_3': 0.008812554791753396, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 65}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 19.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 18.47 | sMAPE for Test Set is: 20.42% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:54:28,615]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:54:42,425]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:54:50,075]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:54:53,781]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:54:57,753]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:54:58,582]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:55:04,483]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:55:10,976]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:55:46,265]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:55:59,053]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:56:01,697]\u001b[0m Trial 755 finished with value: 4.616762192432692 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005071183105980123, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2574592122931036, 'dropout_rate_Layer_2': 0.01895648873809007, 'dropout_rate_Layer_3': 0.08111929245776014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5694102891415787e-05, 'l1_Layer_2': 0.00033735672215434546, 'l1_Layer_3': 0.000702305478773814, 'n_units_Layer_1': 280, 'n_units_Layer_2': 145, 'n_units_Layer_3': 55}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 21.16% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 15.99 | sMAPE for Test Set is: 18.41% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:56:08,388]\u001b[0m Trial 761 finished with value: 4.3316912615216205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034089259465199724, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3166095287246304, 'dropout_rate_Layer_2': 0.03649193545475408, 'dropout_rate_Layer_3': 0.17379088398748654, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.762599684749897e-05, 'l1_Layer_2': 0.03363012679588254, 'l1_Layer_3': 0.008465316246299431, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 65}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 17.54 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:56:11,805]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:56:16,836]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:56:23,525]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:56:27,870]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:56:34,346]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:56:49,016]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:57:05,511]\u001b[0m Trial 766 finished with value: 4.790304294061971 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005064702158628098, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040156468863986064, 'dropout_rate_Layer_2': 0.13464400898374548, 'dropout_rate_Layer_3': 0.06640184741297372, 'dropout_rate_Layer_4': 0.08880898995195544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.715405196258025e-05, 'l1_Layer_2': 0.012834902434632735, 'l1_Layer_3': 0.00040337076002104676, 'l1_Layer_4': 3.7802753109650666e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120, 'n_units_Layer_4': 250}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 20.10% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.66 | sMAPE for Test Set is: 42.28% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:57:09,203]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:57:15,904]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:57:19,468]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:57:25,553]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:57:27,890]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:57:33,038]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:57:42,746]\u001b[0m Trial 756 finished with value: 4.483851266156264 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005030819515805747, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23866311249591787, 'dropout_rate_Layer_2': 0.02132142846233113, 'dropout_rate_Layer_3': 0.03517560448278887, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2071981673056645e-05, 'l1_Layer_2': 0.0006002379367043246, 'l1_Layer_3': 0.0006357570892826365, 'n_units_Layer_1': 205, 'n_units_Layer_2': 145, 'n_units_Layer_3': 55}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 20.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.28 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:57:49,466]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:57:53,409]\u001b[0m Trial 775 finished with value: 4.3629103253545205 and parameters: {'n_hidden': 3, 'learning_rate': 0.000585497244868419, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23453251293440708, 'dropout_rate_Layer_2': 0.02731161474115902, 'dropout_rate_Layer_3': 0.06755376387675004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6957631933923986e-05, 'l1_Layer_2': 0.0006201826398083104, 'l1_Layer_3': 0.000892378784071302, 'n_units_Layer_1': 295, 'n_units_Layer_2': 185, 'n_units_Layer_3': 50}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 18.54% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.03 | sMAPE for Test Set is: 19.04% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:57:55,784]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:03,854]\u001b[0m Trial 781 finished with value: 5.265964881742897 and parameters: {'n_hidden': 4, 'learning_rate': 0.003146016599261693, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010403698463900823, 'dropout_rate_Layer_2': 0.2867250435773381, 'dropout_rate_Layer_3': 0.2757028357486075, 'dropout_rate_Layer_4': 0.09311962532698771, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007001889838751075, 'l1_Layer_2': 0.024669595889004487, 'l1_Layer_3': 0.021402723357010697, 'l1_Layer_4': 4.8335650759890444e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 180, 'n_units_Layer_3': 110, 'n_units_Layer_4': 145}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 21.59% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 49.37 | sMAPE for Test Set is: 42.28% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 00:58:04,154]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:09,606]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:10,320]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:10,404]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:10,509]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:15,240]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:21,946]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:24,213]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:25,010]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:27,095]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:32,305]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:32,498]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:32,670]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:44,818]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:50,282]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:52,383]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:52,607]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:58:59,923]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:59:04,150]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:59:04,412]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:59:12,271]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:59:21,735]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:59:52,409]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 00:59:58,632]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:00:02,642]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:00:08,058]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:00:17,049]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:00:34,692]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:00:37,403]\u001b[0m Trial 797 finished with value: 4.6812624137514485 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005041945279430679, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03564623372483135, 'dropout_rate_Layer_2': 0.22429537522970133, 'dropout_rate_Layer_3': 0.02562452874584331, 'dropout_rate_Layer_4': 0.0732920022948058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.39888914906472e-05, 'l1_Layer_2': 0.014682115266287057, 'l1_Layer_3': 0.00039808598428747423, 'l1_Layer_4': 4.267171191778089e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 65, 'n_units_Layer_3': 115, 'n_units_Layer_4': 250}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 19.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 49.57 | sMAPE for Test Set is: 42.45% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:00:38,241]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:00:42,524]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:00:43,291]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:00:43,674]\u001b[0m Trial 805 finished with value: 4.694061832941564 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005124315824303328, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.042994479551648215, 'dropout_rate_Layer_2': 0.24039167617916393, 'dropout_rate_Layer_3': 0.02107032312058476, 'dropout_rate_Layer_4': 0.10219012268179782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.511582121584954e-05, 'l1_Layer_2': 0.030314278864277983, 'l1_Layer_3': 0.00040622002949167933, 'l1_Layer_4': 4.022735928009296e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120, 'n_units_Layer_4': 250}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:00:43,756]\u001b[0m Trial 807 finished with value: 4.468434182016132 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008431828538448876, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04024475649345299, 'dropout_rate_Layer_2': 0.27074866099734063, 'dropout_rate_Layer_3': 0.3136574252718054, 'dropout_rate_Layer_4': 0.08150781016407602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011733163967564623, 'l1_Layer_2': 0.04140054389422039, 'l1_Layer_3': 0.010064517946245799, 'l1_Layer_4': 9.782094982595229e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 155, 'n_units_Layer_3': 285, 'n_units_Layer_4': 225}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 19.73% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 49.80 | sMAPE for Test Set is: 42.38% | rMAE for Test Set is: 1.82\n",
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 19.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 32.31 | sMAPE for Test Set is: 27.65% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:00:53,251]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:00:53,820]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:00:58,970]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:02,676]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:03,526]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:08,361]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:08,885]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:11,056]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:15,565]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:18,803]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:22,080]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:22,455]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:30,297]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:38,887]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:44,814]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:45,202]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:01:49,645]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:02:05,897]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:02:12,233]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:02:16,175]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:02:20,759]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:02:24,048]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:02:30,141]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:02:38,199]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:02:50,337]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:02:54,104]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:03:00,163]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:03:02,247]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:03:11,559]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:03:21,970]\u001b[0m Trial 836 finished with value: 4.509507858298283 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008778129415470068, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03519077857352731, 'dropout_rate_Layer_2': 0.2807858233989574, 'dropout_rate_Layer_3': 0.32975182928969765, 'dropout_rate_Layer_4': 0.05836253521584528, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017741670497216126, 'l1_Layer_2': 0.05024492763557219, 'l1_Layer_3': 0.01038931106270758, 'l1_Layer_4': 6.507775235558369e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 285, 'n_units_Layer_4': 245}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.15 | sMAPE for Test Set is: 20.64% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:03:29,279]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:03:29,438]\u001b[0m Trial 830 finished with value: 4.482646180970202 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008705432988848508, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02069114994272654, 'dropout_rate_Layer_2': 0.2578600888572492, 'dropout_rate_Layer_3': 0.01827531558287738, 'dropout_rate_Layer_4': 0.04480193532200553, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.733390690248485e-05, 'l1_Layer_2': 0.02298653691381031, 'l1_Layer_3': 0.001404542093112725, 'l1_Layer_4': 0.00020342159051522446, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 75, 'n_units_Layer_4': 210}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 19.10% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 47.73 | sMAPE for Test Set is: 40.23% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:03:39,130]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:03:49,420]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:03:58,343]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:04:06,343]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:04:15,817]\u001b[0m Trial 852 finished with value: 4.5693000134546224 and parameters: {'n_hidden': 3, 'learning_rate': 0.00500550463946044, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3070923507067023, 'dropout_rate_Layer_2': 0.14737634406350245, 'dropout_rate_Layer_3': 0.1696508048446567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1069518261828896e-05, 'l1_Layer_2': 0.03297102168821592, 'l1_Layer_3': 0.010935276460803913, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 70}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 20.60% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 17.12 | sMAPE for Test Set is: 19.55% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:04:24,212]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:04:29,869]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:04:33,294]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:04:41,796]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:04:47,651]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:04:54,752]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:15,864]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:20,366]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:24,869]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:25,626]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:33,289]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:39,898]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:40,379]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:45,667]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:46,228]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:48,658]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:54,399]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:54,572]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:05:55,150]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:03,227]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:03,644]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:10,469]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:10,973]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:17,152]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:19,541]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:23,855]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:31,343]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:31,892]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:39,295]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:44,583]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:48,868]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:52,316]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:53,617]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:06:58,346]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:07:05,973]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:07:13,505]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:07:18,649]\u001b[0m Trial 883 finished with value: 4.406686609105147 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015901927692735336, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03340663908962556, 'dropout_rate_Layer_2': 0.24153475363736998, 'dropout_rate_Layer_3': 0.30521011518630903, 'dropout_rate_Layer_4': 0.06957229180684746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0015878975075547621, 'l1_Layer_2': 0.032348574545596025, 'l1_Layer_3': 0.0011105580913828524, 'l1_Layer_4': 6.652897512164905e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260, 'n_units_Layer_4': 260}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 19.34% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.30 | sMAPE for Test Set is: 19.36% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:07:19,158]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:07:30,067]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:07:41,368]\u001b[0m Trial 881 finished with value: 4.45899931332029 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009838984566684608, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03601032303353606, 'dropout_rate_Layer_2': 0.2676736112515977, 'dropout_rate_Layer_3': 0.3031928231127306, 'dropout_rate_Layer_4': 0.06842127351764471, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014974212875866293, 'l1_Layer_2': 0.039443003870273746, 'l1_Layer_3': 0.008319234725172577, 'l1_Layer_4': 0.00014623248732776578, 'n_units_Layer_1': 250, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300, 'n_units_Layer_4': 260}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 19.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.44 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:07:43,929]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:07:48,324]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:07:55,005]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:08:00,958]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:08:20,886]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:08:25,304]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:08:30,783]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:08:38,031]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:08:42,275]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:08:49,470]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:09:13,303]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:09:24,436]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:10:08,938]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:10:17,433]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:10:27,631]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:10:36,945]\u001b[0m Trial 894 finished with value: 4.411196609683466 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005043477703686444, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2692260246399154, 'dropout_rate_Layer_2': 0.007634555386771214, 'dropout_rate_Layer_3': 0.07556291332229638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0081348901892216e-05, 'l1_Layer_2': 0.0027903831205223716, 'l1_Layer_3': 0.0006099538794321823, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 19.50% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.66 | sMAPE for Test Set is: 18.06% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:10:48,724]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:10:53,943]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:11:04,808]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:11:14,122]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:11:28,811]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:11:33,832]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:11:37,704]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:11:43,744]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:11:52,593]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:11:58,719]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:12:36,890]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:12:47,706]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:12:49,785]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:12:54,167]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:12:57,112]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:13:01,036]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:13:05,663]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:13:12,031]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:13:17,035]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:13:21,804]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:13:24,252]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:13:29,500]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:13:38,880]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:13:43,942]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:13:53,259]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:13:59,288]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:14:02,562]\u001b[0m Trial 900 finished with value: 4.877689941790553 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005043893676693503, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04169716118055747, 'dropout_rate_Layer_2': 0.215921128970965, 'dropout_rate_Layer_3': 0.036127009510587144, 'dropout_rate_Layer_4': 0.042056407431246765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.659250264894519e-05, 'l1_Layer_2': 0.020090431121504253, 'l1_Layer_3': 0.0017102465767761192, 'l1_Layer_4': 4.270667662137701e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95, 'n_units_Layer_4': 225}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 20.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 50.18 | sMAPE for Test Set is: 43.12% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:14:03,188]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:14:25,053]\u001b[0m Trial 932 finished with value: 4.360722469488018 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010106659024078006, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022268143681249387, 'dropout_rate_Layer_2': 0.26591852237490404, 'dropout_rate_Layer_3': 0.3263973472276189, 'dropout_rate_Layer_4': 0.019642243859731706, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002201825554261298, 'l1_Layer_2': 0.01775824095294802, 'l1_Layer_3': 0.0010744287031603291, 'l1_Layer_4': 2.5163401185104546e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 300, 'n_units_Layer_4': 275}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 19.58% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 16.60 | sMAPE for Test Set is: 18.69% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:14:25,302]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:14:31,833]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:14:35,259]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:14:42,902]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:14:46,072]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:14:50,754]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:14:53,675]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:14:58,220]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:14:58,466]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:06,550]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:09,979]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:11,311]\u001b[0m Trial 940 finished with value: 4.434539017252686 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010253371756627487, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05565355965756297, 'dropout_rate_Layer_2': 0.2529952722017118, 'dropout_rate_Layer_3': 0.28967062457441156, 'dropout_rate_Layer_4': 0.07759349635211837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00226245497744036, 'l1_Layer_2': 0.04035602579533672, 'l1_Layer_3': 0.001725359731619033, 'l1_Layer_4': 7.56810116692672e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300, 'n_units_Layer_4': 255}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 19.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.67 | sMAPE for Test Set is: 19.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:15:11,799]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:18,671]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:20,290]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:21,591]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:27,447]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:32,257]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:32,670]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:37,868]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:40,656]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:44,037]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:44,826]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:48,792]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:49,735]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:15:56,473]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:16:00,393]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:16:03,326]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:16:07,831]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:16:10,464]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:16:14,485]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:16:17,365]\u001b[0m Trial 954 finished with value: 4.348264399465024 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006835299437203455, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25715694697488933, 'dropout_rate_Layer_2': 0.008858662966084754, 'dropout_rate_Layer_3': 0.03606544121289662, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.399564082819252e-05, 'l1_Layer_2': 0.0005463752198770201, 'l1_Layer_3': 0.0007645528142774023, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 18.84% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 16.57 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:16:19,441]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:16:55,159]\u001b[0m Trial 971 finished with value: 4.436207357016612 and parameters: {'n_hidden': 4, 'learning_rate': 0.001176593625142061, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34123065383332407, 'dropout_rate_Layer_2': 0.2764834218464984, 'dropout_rate_Layer_3': 0.3029148527326628, 'dropout_rate_Layer_4': 0.01670052467437392, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005213123170336744, 'l1_Layer_2': 0.030414871746395112, 'l1_Layer_3': 0.0023968004692799614, 'l1_Layer_4': 0.00013106068017992877, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275, 'n_units_Layer_4': 240}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 19.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.23 | sMAPE for Test Set is: 20.79% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:16:59,777]\u001b[0m Trial 965 finished with value: 4.34690301299704 and parameters: {'n_hidden': 3, 'learning_rate': 0.003000585281145931, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3312258055078231, 'dropout_rate_Layer_2': 0.034767120483931865, 'dropout_rate_Layer_3': 0.1539459145787389, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.60834239666356e-05, 'l1_Layer_2': 0.026367288469158257, 'l1_Layer_3': 0.00634892788917751, 'n_units_Layer_1': 85, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.66 | sMAPE for Test Set is: 19.54% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 19.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.28 | sMAPE for Test Set is: 19.62% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:16:59,841]\u001b[0m Trial 973 finished with value: 4.346750512279729 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032267963785278884, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33315284784908056, 'dropout_rate_Layer_2': 0.040303030575969484, 'dropout_rate_Layer_3': 0.1586126227776373, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.631900140072337e-05, 'l1_Layer_2': 0.026648240184340154, 'l1_Layer_3': 0.007350824748189641, 'n_units_Layer_1': 85, 'n_units_Layer_2': 65, 'n_units_Layer_3': 55}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:17:12,332]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:17:13,258]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:17:20,848]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:17:25,142]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:17:25,387]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:17:31,708]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:17:34,603]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:17:39,811]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:17:43,976]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:17:50,739]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:17:57,258]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:02,221]\u001b[0m Trial 975 finished with value: 4.390928466322252 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029873341708628464, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33235125191572085, 'dropout_rate_Layer_2': 0.034198805768827736, 'dropout_rate_Layer_3': 0.1554859604069702, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.482224151832892e-05, 'l1_Layer_2': 0.02979445261567392, 'l1_Layer_3': 0.006582615906291904, 'n_units_Layer_1': 85, 'n_units_Layer_2': 65, 'n_units_Layer_3': 55}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 18.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 18.67 | sMAPE for Test Set is: 20.36% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:18:06,258]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:12,004]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:12,808]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:16,130]\u001b[0m Trial 976 finished with value: 4.348693293084562 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009033164656359842, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25040943094643253, 'dropout_rate_Layer_2': 0.0003339567335398232, 'dropout_rate_Layer_3': 0.02323558208503556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4188006578617929e-05, 'l1_Layer_2': 0.0006335533573063498, 'l1_Layer_3': 0.0007426023821342097, 'n_units_Layer_1': 205, 'n_units_Layer_2': 115, 'n_units_Layer_3': 60}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 19.41% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.84 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:18:18,798]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:19,381]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:22,327]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:30,885]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:31,117]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:39,368]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:42,783]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:43,435]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:49,463]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:50,415]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:18:56,082]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:19:19,635]\u001b[0m Trial 996 finished with value: 4.321149943322082 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027566186239624912, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32133198085645936, 'dropout_rate_Layer_2': 0.007520791857591004, 'dropout_rate_Layer_3': 0.15425118215150746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0995029250852185e-05, 'l1_Layer_2': 0.02728685171670627, 'l1_Layer_3': 0.006998672005820614, 'n_units_Layer_1': 90, 'n_units_Layer_2': 55, 'n_units_Layer_3': 60}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 18.73% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 17.74 | sMAPE for Test Set is: 19.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:19:24,193]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:19:28,087]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:19:32,658]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:20:08,072]\u001b[0m Trial 1003 finished with value: 4.300866279792778 and parameters: {'n_hidden': 3, 'learning_rate': 0.000757253351791966, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25254659086948616, 'dropout_rate_Layer_2': 0.017197741884473594, 'dropout_rate_Layer_3': 0.03764396739451751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5950738035492066e-05, 'l1_Layer_2': 0.0012569618799618126, 'l1_Layer_3': 0.0015459332658897048, 'n_units_Layer_1': 195, 'n_units_Layer_2': 110, 'n_units_Layer_3': 55}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 15.71 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:20:19,997]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:20:36,994]\u001b[0m Trial 1004 finished with value: 5.017554827573239 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006776019671966248, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01125337618312523, 'dropout_rate_Layer_2': 0.2588126820808049, 'dropout_rate_Layer_3': 0.07246007234314833, 'dropout_rate_Layer_4': 0.00045459941933025105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.2806108247062906e-05, 'l1_Layer_2': 0.03785158368875327, 'l1_Layer_3': 0.0005255384115436843, 'l1_Layer_4': 0.0001383694589006391, 'n_units_Layer_1': 225, 'n_units_Layer_2': 60, 'n_units_Layer_3': 125, 'n_units_Layer_4': 265}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 20.90% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 50.47 | sMAPE for Test Set is: 43.20% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:20:48,244]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:20:54,162]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:20:56,965]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:21:00,611]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:21:03,284]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:21:07,466]\u001b[0m Trial 1008 finished with value: 4.309670690844526 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007358497866849474, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.265875274910732, 'dropout_rate_Layer_2': 0.018005729076153085, 'dropout_rate_Layer_3': 0.032939475666648364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3423987874411737e-05, 'l1_Layer_2': 0.0006673063676145816, 'l1_Layer_3': 4.232518707251236e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 100, 'n_units_Layer_3': 75}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 19.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 17.06 | sMAPE for Test Set is: 19.13% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:21:08,129]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:21:16,448]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:21:25,165]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:21:30,028]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:21:33,167]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:21:40,105]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:21:45,392]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:21:56,445]\u001b[0m Trial 1017 finished with value: 4.457695895382787 and parameters: {'n_hidden': 4, 'learning_rate': 0.001358441719182115, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0362007399148458, 'dropout_rate_Layer_2': 0.2415678349945714, 'dropout_rate_Layer_3': 0.27276815578584085, 'dropout_rate_Layer_4': 0.06835216091207817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0037071534000589104, 'l1_Layer_2': 0.033748856384321034, 'l1_Layer_3': 0.0022677833775561367, 'l1_Layer_4': 3.308081689298569e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275, 'n_units_Layer_4': 235}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 19.10% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.92 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:21:56,808]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:22:05,841]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:22:11,894]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:22:22,198]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:22:33,797]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:22:40,967]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:22:53,935]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:22:54,261]\u001b[0m Trial 1025 finished with value: 4.314457961731524 and parameters: {'n_hidden': 3, 'learning_rate': 0.00264644536572701, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3235144056512661, 'dropout_rate_Layer_2': 0.014693453311405801, 'dropout_rate_Layer_3': 0.134642200272429, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3246680529633386e-05, 'l1_Layer_2': 0.022457677121197013, 'l1_Layer_3': 0.0037718282357309596, 'n_units_Layer_1': 90, 'n_units_Layer_2': 65, 'n_units_Layer_3': 55}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 19.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 17.49 | sMAPE for Test Set is: 19.56% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:23:00,681]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:23:04,914]\u001b[0m Trial 1029 finished with value: 4.458371861819715 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012818174842781714, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045119205100413694, 'dropout_rate_Layer_2': 0.2626747515393831, 'dropout_rate_Layer_3': 0.29014083733251744, 'dropout_rate_Layer_4': 0.05161191996832176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0027753102759349624, 'l1_Layer_2': 0.028613531220600775, 'l1_Layer_3': 0.0017800354627480143, 'l1_Layer_4': 2.9012847654020088e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 190, 'n_units_Layer_3': 295, 'n_units_Layer_4': 230}. Best is trial 709 with value: 4.2104837025542885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 19.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.38 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:23:05,265]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:23:12,452]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:23:24,660]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:23:29,924]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:23:32,767]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:23:39,202]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:23:44,488]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:23:56,760]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:01,394]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:07,280]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:13,068]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:17,350]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:21,635]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:26,253]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:29,676]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:35,609]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:40,215]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:47,299]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:51,864]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:24:51,900]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:01,055]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:01,235]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:08,274]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:08,793]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:14,142]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:18,973]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:23,586]\u001b[0m Trial 1034 finished with value: 4.138308957780027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007600329972087515, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2509788584366094, 'dropout_rate_Layer_2': 0.014704448513531913, 'dropout_rate_Layer_3': 0.03873769825073373, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.605992206442565e-05, 'l1_Layer_2': 0.000679853878486036, 'l1_Layer_3': 0.0036822047847675007, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 70}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 18.36% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.76 | sMAPE for Test Set is: 17.98% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:25:25,886]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:36,357]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:39,880]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:43,901]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:48,348]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:50,811]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:51,254]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:25:58,546]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:26:09,590]\u001b[0m Trial 1042 finished with value: 4.167379318735559 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006673589153515539, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24872638904716296, 'dropout_rate_Layer_2': 0.02019765288614924, 'dropout_rate_Layer_3': 0.045847994422794046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.635017579872808e-05, 'l1_Layer_2': 0.0009219641328020639, 'l1_Layer_3': 0.0018173385385595688, 'n_units_Layer_1': 210, 'n_units_Layer_2': 115, 'n_units_Layer_3': 50}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 18.43% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.04 | sMAPE for Test Set is: 18.18% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:26:14,015]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:26:20,327]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:26:24,592]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:26:24,881]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:26:25,424]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:26:40,229]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:26:53,092]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:26:56,497]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:27:00,716]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:27:06,271]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:27:11,309]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:27:39,878]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:27:44,302]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:27:52,239]\u001b[0m Trial 1067 finished with value: 4.168823340967257 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009081427476800044, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2514372743413474, 'dropout_rate_Layer_2': 0.0004216136341795686, 'dropout_rate_Layer_3': 0.03502428152429163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3052624016360575e-05, 'l1_Layer_2': 0.0015469386686169627, 'l1_Layer_3': 0.0018313928184718411, 'n_units_Layer_1': 195, 'n_units_Layer_2': 85, 'n_units_Layer_3': 65}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 18.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.78 | sMAPE for Test Set is: 18.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:27:56,987]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:28:03,925]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:28:25,334]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:28:30,728]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:28:36,290]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:28:41,829]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:28:59,891]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:29:40,239]\u001b[0m Trial 1082 finished with value: 4.179675769936796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006641381176766925, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24350710523009872, 'dropout_rate_Layer_2': 0.03433874708313874, 'dropout_rate_Layer_3': 0.02520521890053009, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6491283397371713e-05, 'l1_Layer_2': 0.0009820346769610164, 'l1_Layer_3': 0.007472171782855201, 'n_units_Layer_1': 225, 'n_units_Layer_2': 115, 'n_units_Layer_3': 110}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 18.36% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.39 | sMAPE for Test Set is: 18.32% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:30:01,754]\u001b[0m Trial 1084 finished with value: 4.186313468919463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005561587602471627, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2615111601816236, 'dropout_rate_Layer_2': 0.00033672697957066577, 'dropout_rate_Layer_3': 0.03524739183631667, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5982277482934352e-05, 'l1_Layer_2': 0.0007595508961746343, 'l1_Layer_3': 0.016489175396762198, 'n_units_Layer_1': 190, 'n_units_Layer_2': 130, 'n_units_Layer_3': 70}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 18.18% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.46 | sMAPE for Test Set is: 18.67% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:30:06,279]\u001b[0m Trial 1091 finished with value: 4.174145438787541 and parameters: {'n_hidden': 3, 'learning_rate': 0.000964993978382095, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26780322873353335, 'dropout_rate_Layer_2': 0.0003055835687742481, 'dropout_rate_Layer_3': 0.012471021706945473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5499274290893145e-05, 'l1_Layer_2': 0.0013770740241394594, 'l1_Layer_3': 0.002338390598485983, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 75}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 18.89% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.07 | sMAPE for Test Set is: 18.26% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:30:06,494]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:30:37,518]\u001b[0m Trial 1093 finished with value: 4.810575444293222 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006089941717492398, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030859388988021708, 'dropout_rate_Layer_2': 0.1054387930728634, 'dropout_rate_Layer_3': 0.06848166505242882, 'dropout_rate_Layer_4': 0.10699465986493645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.912458165720354e-05, 'l1_Layer_2': 0.011324615061774288, 'l1_Layer_3': 0.00039031419200284776, 'l1_Layer_4': 6.517680668569531e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120, 'n_units_Layer_4': 245}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 20.22% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 50.43 | sMAPE for Test Set is: 43.11% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:30:56,363]\u001b[0m Trial 1092 finished with value: 4.216733987523569 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008488235351518274, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2630200083833561, 'dropout_rate_Layer_2': 0.008713304778943656, 'dropout_rate_Layer_3': 0.06065085022398861, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3661682946205537e-05, 'l1_Layer_2': 0.0021869991386287016, 'l1_Layer_3': 0.0017737185596907296, 'n_units_Layer_1': 195, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 16.25 | sMAPE for Test Set is: 18.30% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:30:57,236]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:03,039]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:05,249]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:09,652]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:11,780]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:17,268]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:23,275]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:28,470]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:33,943]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:33,983]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:45,114]\u001b[0m Trial 1095 finished with value: 4.7048709346634885 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005601566846060607, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03038494955395562, 'dropout_rate_Layer_2': 0.23608386865362768, 'dropout_rate_Layer_3': 0.06623009685068589, 'dropout_rate_Layer_4': 0.1046863741898884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.965654341568312e-05, 'l1_Layer_2': 0.01160637576291237, 'l1_Layer_3': 0.00016205038778571246, 'l1_Layer_4': 6.069521822850676e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120, 'n_units_Layer_4': 245}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 50.70 | sMAPE for Test Set is: 43.87% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:31:48,770]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:53,071]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:31:53,713]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:32:01,179]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:32:22,631]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:32:27,740]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:32:33,521]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:32:35,457]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:32:41,747]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:32:55,097]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:33:03,432]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:33:04,027]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:33:13,025]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:33:17,470]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:33:23,429]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:33:29,333]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:33:47,308]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:33:51,924]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:33:56,000]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:33:58,513]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:34:01,452]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:34:07,170]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:34:11,811]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:34:16,345]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:34:21,370]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:34:25,005]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:34:27,554]\u001b[0m Trial 1112 finished with value: 4.203670403270558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008536750344846195, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2514741235699642, 'dropout_rate_Layer_2': 9.21171539669678e-05, 'dropout_rate_Layer_3': 0.019216918370033195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6054437494267602e-05, 'l1_Layer_2': 0.0015575663566279924, 'l1_Layer_3': 0.003128748990460964, 'n_units_Layer_1': 195, 'n_units_Layer_2': 120, 'n_units_Layer_3': 260}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 19.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 16.10 | sMAPE for Test Set is: 18.38% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:34:31,975]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:34:35,705]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:34:44,112]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:07,233]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:07,680]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:14,927]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:24,076]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:27,798]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:28,785]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:34,796]\u001b[0m Trial 1124 finished with value: 4.150831647486104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008069783326508503, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2759616017044819, 'dropout_rate_Layer_2': 0.008304845379431682, 'dropout_rate_Layer_3': 0.03382476415079699, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9061931317446792e-05, 'l1_Layer_2': 0.00138873782206723, 'l1_Layer_3': 0.002758153078861133, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 80}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.61 | sMAPE for Test Set is: 18.72% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:35:38,065]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:40,128]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:40,605]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:48,295]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:51,141]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:55,214]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:35:56,544]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:36:04,119]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:36:04,683]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:36:12,133]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:36:13,753]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:36:21,681]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:36:25,175]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:36:28,938]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:36:34,096]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:36:35,273]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:36:41,205]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:36:42,807]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:37:07,295]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:37:12,095]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:37:18,403]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:37:23,549]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:37:30,337]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:37:35,062]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:37:39,938]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:37:44,230]\u001b[0m Trial 1152 finished with value: 4.201730410669659 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008385043351903648, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2660812652011341, 'dropout_rate_Layer_2': 0.008360323134815816, 'dropout_rate_Layer_3': 0.03039937512448117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7211024026093552e-05, 'l1_Layer_2': 0.0012814855671264655, 'l1_Layer_3': 0.0024899762214942115, 'n_units_Layer_1': 210, 'n_units_Layer_2': 105, 'n_units_Layer_3': 85}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 18.65% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 16.81 | sMAPE for Test Set is: 18.77% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:37:47,423]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:37:52,177]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:37:56,849]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:37:59,437]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:38:06,759]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:38:12,487]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:38:26,878]\u001b[0m Trial 1164 finished with value: 4.486600371717631 and parameters: {'n_hidden': 4, 'learning_rate': 0.000508590113373884, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008426050842355731, 'dropout_rate_Layer_2': 0.11811095079748987, 'dropout_rate_Layer_3': 0.10730917513863994, 'dropout_rate_Layer_4': 0.10409222389672695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.319380074852194e-05, 'l1_Layer_2': 0.0004315317973110011, 'l1_Layer_3': 0.000842933111139836, 'l1_Layer_4': 1.2309138151777738e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 65, 'n_units_Layer_3': 125, 'n_units_Layer_4': 250}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 19.53% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 48.32 | sMAPE for Test Set is: 40.95% | rMAE for Test Set is: 1.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:38:30,124]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:38:33,532]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:38:36,316]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:38:40,441]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:38:50,653]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:38:57,462]\u001b[0m Trial 1175 finished with value: 4.789562809704186 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005098294311706683, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0011251600489653544, 'dropout_rate_Layer_2': 0.13778874065545033, 'dropout_rate_Layer_3': 0.06115726922595088, 'dropout_rate_Layer_4': 0.10181340684563212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.085267053530109e-05, 'l1_Layer_2': 0.011555580265639635, 'l1_Layer_3': 0.0009778502603846836, 'l1_Layer_4': 1.376615816408212e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 65, 'n_units_Layer_3': 125, 'n_units_Layer_4': 245}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 20.00% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.37 | sMAPE for Test Set is: 41.99% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:39:00,611]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:39:00,854]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:39:01,385]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:39:02,930]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:39:12,109]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:39:15,485]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:39:15,973]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:39:22,038]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:39:26,393]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:39:32,221]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:39:50,928]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:40:10,431]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:40:15,548]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:40:20,387]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:09,657]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:13,651]\u001b[0m Trial 1198 finished with value: 4.784239879543292 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006088009236608662, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018552686372344952, 'dropout_rate_Layer_2': 0.1190305154156156, 'dropout_rate_Layer_3': 0.12718431043323, 'dropout_rate_Layer_4': 0.1146569603511746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.032068304186403e-05, 'l1_Layer_2': 0.0007675969477123495, 'l1_Layer_3': 4.977913136000528e-05, 'l1_Layer_4': 0.00025258715756532545, 'n_units_Layer_1': 275, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200, 'n_units_Layer_4': 290}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 20.57% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 51.48 | sMAPE for Test Set is: 44.77% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:41:17,226]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:21,895]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:28,521]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:28,738]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:36,107]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:41,181]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:42,336]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:46,339]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:50,226]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:50,928]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:41:56,264]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:01,397]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:07,467]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:12,694]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:14,227]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:18,632]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:22,022]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:28,374]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:33,897]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:34,407]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:34,568]\u001b[0m Trial 1193 finished with value: 4.821887964591342 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007310018058075972, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19461098747647618, 'dropout_rate_Layer_2': 0.07321149513794675, 'dropout_rate_Layer_3': 0.15969262182634383, 'dropout_rate_Layer_4': 0.1871381624456236, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.853820631603651e-05, 'l1_Layer_2': 0.0008385032672751113, 'l1_Layer_3': 0.0012323888342632109, 'l1_Layer_4': 0.0002348441024701531, 'n_units_Layer_1': 235, 'n_units_Layer_2': 85, 'n_units_Layer_3': 175, 'n_units_Layer_4': 110}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.28 | sMAPE for Test Set is: 42.13% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:42:43,342]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:47,557]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:48,505]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:42:55,632]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:00,588]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:00,758]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:15,600]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:19,728]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:22,683]\u001b[0m Trial 1210 finished with value: 4.297821905351241 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009315662209413946, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01765495501000149, 'dropout_rate_Layer_2': 0.3012032115260872, 'dropout_rate_Layer_3': 0.3005886701696402, 'dropout_rate_Layer_4': 0.10183451802912907, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011746216873135121, 'l1_Layer_2': 0.03461655045838397, 'l1_Layer_3': 0.0004986019202261568, 'l1_Layer_4': 8.59766611828669e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 165, 'n_units_Layer_3': 270, 'n_units_Layer_4': 270}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 17.88 | sMAPE for Test Set is: 19.55% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:43:25,329]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:31,330]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:32,434]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:37,494]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:40,940]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:46,322]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:50,379]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:56,045]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:43:56,421]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:44:05,422]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:44:10,365]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:44:37,821]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:44:48,796]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:44:54,544]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:44:57,745]\u001b[0m Trial 1240 finished with value: 4.71280434068199 and parameters: {'n_hidden': 4, 'learning_rate': 0.000579079366729803, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017727392174486496, 'dropout_rate_Layer_2': 0.11808989121169823, 'dropout_rate_Layer_3': 0.13269251987902209, 'dropout_rate_Layer_4': 0.11732620229762199, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.495578667878071e-05, 'l1_Layer_2': 0.0005729904192512748, 'l1_Layer_3': 0.00014653191510719297, 'l1_Layer_4': 0.00011352170193196747, 'n_units_Layer_1': 275, 'n_units_Layer_2': 80, 'n_units_Layer_3': 190, 'n_units_Layer_4': 290}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 19.96% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 52.17 | sMAPE for Test Set is: 45.34% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:44:59,192]\u001b[0m Trial 1235 finished with value: 4.730971279511766 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005993393858402506, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017093270956628007, 'dropout_rate_Layer_2': 0.11810107015635068, 'dropout_rate_Layer_3': 0.12087240023236871, 'dropout_rate_Layer_4': 0.06580367284607407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.9467876134395367e-05, 'l1_Layer_2': 0.0011942922637271994, 'l1_Layer_3': 6.22846581088579e-05, 'l1_Layer_4': 0.000577200791691032, 'n_units_Layer_1': 300, 'n_units_Layer_2': 110, 'n_units_Layer_3': 220, 'n_units_Layer_4': 290}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 20.05% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 52.79 | sMAPE for Test Set is: 46.37% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:45:04,425]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:04,969]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:05,362]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:14,331]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:17,489]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:20,736]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:21,416]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:27,706]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.31 | sMAPE for Test Set is: 18.49% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:45:31,710]\u001b[0m Trial 1221 finished with value: 4.175936512269957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008390454150545327, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26890966521799914, 'dropout_rate_Layer_2': 0.012855061229097242, 'dropout_rate_Layer_3': 0.030811029078728333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7418756446718955e-05, 'l1_Layer_2': 0.0024272330530254794, 'l1_Layer_3': 0.0056283146569830605, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 75}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:35,354]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:39,943]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:44,353]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:48,366]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:45:54,055]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:46:15,096]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:46:21,698]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:46:26,556]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:46:32,434]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:46:38,766]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:46:46,130]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:47:10,070]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:47:13,954]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:47:32,916]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:47:37,270]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:47:57,720]\u001b[0m Trial 1250 finished with value: 4.179749219735311 and parameters: {'n_hidden': 3, 'learning_rate': 0.000747687852302132, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2733548445501157, 'dropout_rate_Layer_2': 0.008523768897921086, 'dropout_rate_Layer_3': 0.00844050474011835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.993037879040889e-05, 'l1_Layer_2': 0.000715231790773879, 'l1_Layer_3': 0.01843528201917658, 'n_units_Layer_1': 245, 'n_units_Layer_2': 95, 'n_units_Layer_3': 80}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.39 | sMAPE for Test Set is: 18.73% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:48:00,990]\u001b[0m Trial 1266 finished with value: 4.450761663908746 and parameters: {'n_hidden': 4, 'learning_rate': 0.000625375025686753, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027295735483889454, 'dropout_rate_Layer_2': 0.11156534485885154, 'dropout_rate_Layer_3': 0.10909024416715907, 'dropout_rate_Layer_4': 0.06614665672485964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.716549973208411e-05, 'l1_Layer_2': 0.0004064773550085451, 'l1_Layer_3': 0.0018364287963348693, 'l1_Layer_4': 0.0006175464436904965, 'n_units_Layer_1': 300, 'n_units_Layer_2': 110, 'n_units_Layer_3': 185, 'n_units_Layer_4': 295}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 19.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 46.35 | sMAPE for Test Set is: 38.80% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:48:31,702]\u001b[0m Trial 1256 finished with value: 4.146661461082286 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009390037202270441, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28161149584493106, 'dropout_rate_Layer_2': 0.013909321892997683, 'dropout_rate_Layer_3': 0.0196261403579724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8964249843932117e-05, 'l1_Layer_2': 0.0028086615444162222, 'l1_Layer_3': 0.005540756855029303, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 75}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 18.57% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.48 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:48:36,513]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:48:41,168]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:48:47,825]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:48:52,026]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:48:58,602]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:11,971]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:17,028]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:19,464]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:20,299]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:25,511]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:28,799]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:30,237]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:35,240]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:37,504]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:42,245]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:47,370]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:47,967]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:49:55,011]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:50:01,549]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:50:01,779]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:50:10,757]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:50:15,735]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:50:39,483]\u001b[0m Trial 1284 finished with value: 4.61659671035207 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006343895184050548, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050163870979143634, 'dropout_rate_Layer_2': 0.08428579856098892, 'dropout_rate_Layer_3': 0.17374616079178012, 'dropout_rate_Layer_4': 0.04319002916758804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.6108826272863067e-05, 'l1_Layer_2': 0.0004954273762530355, 'l1_Layer_3': 0.0028955976081777527, 'l1_Layer_4': 0.0008256858292018943, 'n_units_Layer_1': 295, 'n_units_Layer_2': 95, 'n_units_Layer_3': 220, 'n_units_Layer_4': 270}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 19.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 47.27 | sMAPE for Test Set is: 39.94% | rMAE for Test Set is: 1.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:50:43,329]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:50:56,050]\u001b[0m Trial 1271 finished with value: 4.171760592102562 and parameters: {'n_hidden': 3, 'learning_rate': 0.000789920893726164, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2565533673071846, 'dropout_rate_Layer_2': 0.014056636898413952, 'dropout_rate_Layer_3': 0.01033026095818582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3890526255337082e-05, 'l1_Layer_2': 0.0029168393450913236, 'l1_Layer_3': 0.00578317018255839, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 80}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.99 | sMAPE for Test Set is: 18.10% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:51:02,871]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:07,518]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:12,168]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:19,354]\u001b[0m Trial 1298 finished with value: 4.385123450893186 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055528327548084455, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20234715105551387, 'dropout_rate_Layer_2': 0.05719046297300773, 'dropout_rate_Layer_3': 0.1698014876933682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046239746001510036, 'l1_Layer_2': 0.02537238432362906, 'l1_Layer_3': 0.009650916301686248, 'n_units_Layer_1': 100, 'n_units_Layer_2': 195, 'n_units_Layer_3': 185}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 18.28 | sMAPE for Test Set is: 19.99% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:51:23,421]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:28,051]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:29,106]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:35,851]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:41,322]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:45,867]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:50,961]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:53,897]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:56,989]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:51:59,460]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:07,339]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:10,776]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:12,992]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:16,871]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:18,010]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:23,971]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:27,297]\u001b[0m Trial 1294 finished with value: 4.232131192173632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008884575245347965, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2809395354151776, 'dropout_rate_Layer_2': 0.0004304788169055343, 'dropout_rate_Layer_3': 0.02367690037906204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6655135607613838e-05, 'l1_Layer_2': 0.0015144992090403069, 'l1_Layer_3': 0.012677030949977814, 'n_units_Layer_1': 215, 'n_units_Layer_2': 100, 'n_units_Layer_3': 80}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 17.56 | sMAPE for Test Set is: 19.21% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:52:29,848]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:29,999]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:37,071]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:41,392]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:45,283]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:50,379]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:52:57,917]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:53:07,379]\u001b[0m Trial 1322 finished with value: 4.45091733896439 and parameters: {'n_hidden': 3, 'learning_rate': 0.00650401420514089, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20116453435723836, 'dropout_rate_Layer_2': 0.050972594926583986, 'dropout_rate_Layer_3': 0.1842600758513368, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4802531045103243e-05, 'l1_Layer_2': 0.03364310219257884, 'l1_Layer_3': 0.0015549218165351905, 'n_units_Layer_1': 100, 'n_units_Layer_2': 180, 'n_units_Layer_3': 185}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 19.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.80 | sMAPE for Test Set is: 21.04% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:53:22,528]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:53:28,143]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:53:34,704]\u001b[0m Trial 1328 finished with value: 4.509829694967969 and parameters: {'n_hidden': 3, 'learning_rate': 0.006289609078173574, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20073197053839925, 'dropout_rate_Layer_2': 0.05613561646078934, 'dropout_rate_Layer_3': 0.1844498522974683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4433626900223955e-05, 'l1_Layer_2': 0.0316647805527679, 'l1_Layer_3': 0.0016926737393500827, 'n_units_Layer_1': 110, 'n_units_Layer_2': 200, 'n_units_Layer_3': 195}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 19.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 18.59 | sMAPE for Test Set is: 20.29% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:53:38,407]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:53:44,128]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:53:48,600]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:53:53,104]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:53:56,694]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:00,637]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:01,072]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.24 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 15.90 | sMAPE for Test Set is: 18.16% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:54:03,215]\u001b[0m Trial 1320 finished with value: 4.243883936624479 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008803003972545332, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2703217069863317, 'dropout_rate_Layer_2': 0.00737874055843106, 'dropout_rate_Layer_3': 0.007893580366169908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7255735453042217e-05, 'l1_Layer_2': 0.0014337401543300684, 'l1_Layer_3': 0.010269057912963002, 'n_units_Layer_1': 215, 'n_units_Layer_2': 100, 'n_units_Layer_3': 170}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:07,471]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:10,371]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:18,069]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:22,422]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:28,209]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:32,448]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:35,819]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:40,460]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:43,118]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:54:52,605]\u001b[0m Trial 1319 finished with value: 4.231483033988849 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008737999078401908, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2650796267519174, 'dropout_rate_Layer_2': 0.007754850348240111, 'dropout_rate_Layer_3': 0.00016174721985520897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3603729483420601e-05, 'l1_Layer_2': 0.0006142761621679791, 'l1_Layer_3': 0.008238456574614778, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 19.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 15.83 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:55:07,575]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:55:16,141]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:55:19,250]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:55:24,089]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:55:25,997]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:55:26,950]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:55:33,439]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:55:34,092]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:55:40,595]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:55:57,787]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:56:42,332]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:56:51,670]\u001b[0m Trial 1359 finished with value: 4.418415091994497 and parameters: {'n_hidden': 4, 'learning_rate': 0.001149243080111026, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027417964743265424, 'dropout_rate_Layer_2': 0.29806505243177805, 'dropout_rate_Layer_3': 0.28572994157599135, 'dropout_rate_Layer_4': 0.30932017437852977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008988548366566676, 'l1_Layer_2': 0.03947451647776998, 'l1_Layer_3': 0.001073509407555176, 'l1_Layer_4': 0.0002902443794354317, 'n_units_Layer_1': 265, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290, 'n_units_Layer_4': 220}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 18.78 | sMAPE for Test Set is: 20.48% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:56:59,421]\u001b[0m Trial 1348 finished with value: 4.182817811276365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010651189462463945, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.277342389694576, 'dropout_rate_Layer_2': 0.009230991309472856, 'dropout_rate_Layer_3': 0.01597437659353971, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4912059808400954e-05, 'l1_Layer_2': 0.0008516500851433842, 'l1_Layer_3': 0.006642423976647169, 'n_units_Layer_1': 215, 'n_units_Layer_2': 100, 'n_units_Layer_3': 165}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 19.41% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.86 | sMAPE for Test Set is: 18.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:57:26,338]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:57:31,050]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:57:32,041]\u001b[0m Trial 1357 finished with value: 4.169270011170827 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008176591097544206, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2562498230917851, 'dropout_rate_Layer_2': 0.00033104640422835716, 'dropout_rate_Layer_3': 0.01525795727472174, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9092545016807787e-05, 'l1_Layer_2': 0.0011434630802065018, 'l1_Layer_3': 0.007067021197821786, 'n_units_Layer_1': 205, 'n_units_Layer_2': 100, 'n_units_Layer_3': 165}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.35 | sMAPE for Test Set is: 18.28% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:57:38,698]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:57:41,177]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:57:45,728]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:57:46,338]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:57:53,301]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:57:55,735]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:57:59,470]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:58:04,103]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:58:09,377]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:58:14,224]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:58:22,153]\u001b[0m Trial 1366 finished with value: 4.436178888777754 and parameters: {'n_hidden': 3, 'learning_rate': 0.005815761281018024, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23318451182895705, 'dropout_rate_Layer_2': 0.05231727013998948, 'dropout_rate_Layer_3': 0.17266713590133037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023619438809741256, 'l1_Layer_2': 0.05199435134462592, 'l1_Layer_3': 0.007510834928782583, 'n_units_Layer_1': 105, 'n_units_Layer_2': 215, 'n_units_Layer_3': 190}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 19.78% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.50 | sMAPE for Test Set is: 19.59% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:58:27,231]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:58:31,930]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:58:32,854]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:58:44,406]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:58:48,847]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:58:59,857]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:59:08,587]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:59:20,778]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:59:26,355]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 01:59:35,384]\u001b[0m Trial 1361 finished with value: 4.160311881972056 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008218951769234003, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28504028533983294, 'dropout_rate_Layer_2': 0.00028344001636322787, 'dropout_rate_Layer_3': 0.023810028641514238, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2836032632682013e-05, 'l1_Layer_2': 0.002141308379856846, 'l1_Layer_3': 0.013971035509978583, 'n_units_Layer_1': 240, 'n_units_Layer_2': 80, 'n_units_Layer_3': 220}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 19.16% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.67 | sMAPE for Test Set is: 18.60% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:59:50,476]\u001b[0m Trial 1379 finished with value: 4.496926383013071 and parameters: {'n_hidden': 4, 'learning_rate': 0.001153668427574431, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027372912247115654, 'dropout_rate_Layer_2': 0.3080785874230156, 'dropout_rate_Layer_3': 0.27039882073224586, 'dropout_rate_Layer_4': 0.2931002422774364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009272075196544374, 'l1_Layer_2': 0.03848520069287655, 'l1_Layer_3': 0.0014715278251625431, 'l1_Layer_4': 0.00013546198187873218, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290, 'n_units_Layer_4': 200}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.13 | sMAPE for Test Set is: 20.43% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 01:59:57,132]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:00:14,230]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:00:21,398]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:00:22,242]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:00:30,266]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:00:30,821]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 19.33% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 18.53 | sMAPE for Test Set is: 19.90% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 02:00:35,067]\u001b[0m Trial 1386 finished with value: 4.31009555745396 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015940675522572289, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03368961536752716, 'dropout_rate_Layer_2': 0.3005094689246999, 'dropout_rate_Layer_3': 0.27349169879536234, 'dropout_rate_Layer_4': 0.000256965373620615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013039127277931957, 'l1_Layer_2': 0.020439345704299658, 'l1_Layer_3': 0.0016956195050442072, 'l1_Layer_4': 0.0002667273571134433, 'n_units_Layer_1': 260, 'n_units_Layer_2': 180, 'n_units_Layer_3': 285, 'n_units_Layer_4': 240}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:00:39,720]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:00:41,240]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:00:46,197]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:00:46,783]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:00:46,916]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:00:56,496]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:00,946]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:05,413]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:10,287]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:17,310]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:17,987]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:24,354]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:28,197]\u001b[0m Trial 1393 finished with value: 4.498834700126862 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015959251696762166, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04406670511260237, 'dropout_rate_Layer_2': 0.32850108741917894, 'dropout_rate_Layer_3': 0.25447112913558556, 'dropout_rate_Layer_4': 0.31203830941123895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012405955811679557, 'l1_Layer_2': 0.062413389930297235, 'l1_Layer_3': 0.0015068907007300266, 'l1_Layer_4': 0.00028380351569120405, 'n_units_Layer_1': 265, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285, 'n_units_Layer_4': 200}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 19.60% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 18.70 | sMAPE for Test Set is: 20.48% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 02:01:33,327]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:40,804]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:45,817]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:50,282]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:53,933]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:56,796]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:01:59,726]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:02:03,443]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:02:04,445]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:02:12,003]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:02:19,279]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:02:23,591]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:02:27,777]\u001b[0m Trial 1397 finished with value: 4.450039887401856 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012702318799345436, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03380731211254483, 'dropout_rate_Layer_2': 0.3173795888640956, 'dropout_rate_Layer_3': 0.2488010391193937, 'dropout_rate_Layer_4': 0.30985584731146065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014996436217270138, 'l1_Layer_2': 0.021017074018523936, 'l1_Layer_3': 0.0015599540097208926, 'l1_Layer_4': 0.0002424559242221749, 'n_units_Layer_1': 275, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290, 'n_units_Layer_4': 230}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 19.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.85 | sMAPE for Test Set is: 19.75% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 02:02:31,258]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:02:36,925]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:02:42,955]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:02:48,041]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:02:53,938]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:03,317]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:08,471]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:13,485]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:16,739]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:24,525]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:28,305]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:33,050]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:33,830]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:45,443]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:50,691]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:53,785]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:58,394]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:03:58,563]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:04:04,934]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:04:08,541]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:04:10,956]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:04:16,225]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:04:19,203]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:04:23,720]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:04:27,460]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:04:28,628]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:04:39,076]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:04:45,520]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:04:51,504]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:05:00,039]\u001b[0m Trial 1425 finished with value: 4.1641899438348355 and parameters: {'n_hidden': 3, 'learning_rate': 0.001110832937297154, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.262961836097738, 'dropout_rate_Layer_2': 0.013968442878244496, 'dropout_rate_Layer_3': 0.00988436593717154, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3656580514447572e-05, 'l1_Layer_2': 0.0011120995942018727, 'l1_Layer_3': 0.008271935895319158, 'n_units_Layer_1': 240, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 19.24% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.97 | sMAPE for Test Set is: 18.25% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 02:05:05,141]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:05:09,991]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:05:16,212]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:05:25,469]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:05:31,320]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:05:50,625]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:05:55,681]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:05:55,847]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:06:11,052]\u001b[0m Trial 1446 finished with value: 4.162212166000735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007274223434476101, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28658647042799357, 'dropout_rate_Layer_2': 0.014472399661842661, 'dropout_rate_Layer_3': 0.02554853824147416, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0200571799606927e-05, 'l1_Layer_2': 0.0017293624387828752, 'l1_Layer_3': 0.0033414558110727906, 'n_units_Layer_1': 220, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 18.59% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 17.11 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 02:06:20,385]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:06:24,700]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:06:27,811]\u001b[0m Trial 1452 finished with value: 4.494433628637602 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011243537064210142, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036035612181247095, 'dropout_rate_Layer_2': 0.3060225421569982, 'dropout_rate_Layer_3': 0.27866827102890834, 'dropout_rate_Layer_4': 0.0005446647777177516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0021780106314355035, 'l1_Layer_2': 0.024769085361754966, 'l1_Layer_3': 0.0017251389335389824, 'l1_Layer_4': 0.00017896341032280308, 'n_units_Layer_1': 275, 'n_units_Layer_2': 190, 'n_units_Layer_3': 280, 'n_units_Layer_4': 195}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 19.84% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 18.16 | sMAPE for Test Set is: 19.98% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 02:06:31,615]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:06:37,234]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:06:41,760]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:06:44,137]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:06:55,827]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:05,883]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:08,297]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:10,177]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:17,626]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:24,948]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:28,289]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:31,251]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:36,749]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:44,574]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:47,596]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:49,910]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:54,933]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:07:56,868]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:08:01,521]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:08:05,886]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:08:13,454]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:08:16,339]\u001b[0m Trial 1466 finished with value: 4.338224036961365 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010165783797971635, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034741521273116485, 'dropout_rate_Layer_2': 0.3119197238379614, 'dropout_rate_Layer_3': 0.2468662708939795, 'dropout_rate_Layer_4': 0.01831621583977278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0015369681714871406, 'l1_Layer_2': 0.02204718736073215, 'l1_Layer_3': 0.0009011675788876041, 'l1_Layer_4': 0.00032678350406592467, 'n_units_Layer_1': 290, 'n_units_Layer_2': 190, 'n_units_Layer_3': 290, 'n_units_Layer_4': 195}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 18.70% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 19.38 | sMAPE for Test Set is: 20.53% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 02:08:19,525]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:08:24,642]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:08:30,203]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:08:52,146]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:08:56,839]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:09:24,103]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:09:39,669]\u001b[0m Trial 1487 finished with value: 5.398391252947538 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008869393363703064, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00805824747496815, 'dropout_rate_Layer_2': 0.10967699928199887, 'dropout_rate_Layer_3': 0.13574224732014256, 'dropout_rate_Layer_4': 0.011941093980989373, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.217511692517437e-05, 'l1_Layer_2': 0.00021482833697715072, 'l1_Layer_3': 0.009675078627654663, 'l1_Layer_4': 0.0037001158102812444, 'n_units_Layer_1': 260, 'n_units_Layer_2': 130, 'n_units_Layer_3': 235, 'n_units_Layer_4': 255}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 22.43% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 51.71 | sMAPE for Test Set is: 45.36% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 02:09:50,622]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:10:05,626]\u001b[0m Trial 1476 finished with value: 4.14276279804462 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008287179223074012, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2643364114635474, 'dropout_rate_Layer_2': 0.006361806675854278, 'dropout_rate_Layer_3': 0.03337665539285659, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8423110273234408e-05, 'l1_Layer_2': 0.0014277796746614692, 'l1_Layer_3': 0.00863849815566427, 'n_units_Layer_1': 245, 'n_units_Layer_2': 95, 'n_units_Layer_3': 120}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 19.19% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.88 | sMAPE for Test Set is: 18.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 02:10:05,857]\u001b[0m Trial 1484 finished with value: 4.169234347964603 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009115381031197923, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2666612738298182, 'dropout_rate_Layer_2': 0.01938915612403714, 'dropout_rate_Layer_3': 0.020031006384922875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.615183381574848e-05, 'l1_Layer_2': 0.0015273790992880183, 'l1_Layer_3': 0.004076287049494488, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 18.84% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 17.07 | sMAPE for Test Set is: 18.91% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 02:10:13,317]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:10:15,070]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:10:19,805]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:10:20,981]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:10:25,896]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:10:28,565]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:10:31,662]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:10:53,848]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 02:11:10,540]\u001b[0m Trial 1493 finished with value: 4.602728800116143 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005719505570257893, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04764145324329533, 'dropout_rate_Layer_2': 0.11834006901403253, 'dropout_rate_Layer_3': 0.168699148166453, 'dropout_rate_Layer_4': 0.08801060598026686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.3449142459065193e-05, 'l1_Layer_2': 0.00033116479039117547, 'l1_Layer_3': 0.0008252903795097902, 'l1_Layer_4': 0.0004545719167039511, 'n_units_Layer_1': 295, 'n_units_Layer_2': 90, 'n_units_Layer_3': 220, 'n_units_Layer_4': 275}. Best is trial 1034 with value: 4.138308957780027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 19.80% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 51.08 | sMAPE for Test Set is: 44.47% | rMAE for Test Set is: 1.87\n",
      "for 2021-01-01, MAE is:4.61 & sMAPE is:9.79% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 9.79% & 0.20\n",
      "for 2021-01-02, MAE is:2.59 & sMAPE is:5.08% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :3.60 & 7.43% & 0.16\n",
      "for 2021-01-03, MAE is:5.41 & sMAPE is:11.52% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 8.80% & 0.17\n",
      "for 2021-01-04, MAE is:3.46 & sMAPE is:6.24% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 8.16% & 0.18\n",
      "for 2021-01-05, MAE is:2.88 & sMAPE is:4.69% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 7.46% & 0.18\n",
      "for 2021-01-06, MAE is:5.01 & sMAPE is:6.67% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 7.33% & 0.20\n",
      "for 2021-01-07, MAE is:13.94 & sMAPE is:17.55% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 8.79% & 0.23\n",
      "for 2021-01-08, MAE is:13.37 & sMAPE is:15.67% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 9.65% & 0.25\n",
      "for 2021-01-09, MAE is:5.96 & sMAPE is:9.37% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 9.62% & 0.28\n",
      "for 2021-01-10, MAE is:4.09 & sMAPE is:7.67% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 9.42% & 0.30\n",
      "for 2021-01-11, MAE is:4.87 & sMAPE is:7.28% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 9.23% & 0.32\n",
      "for 2021-01-12, MAE is:4.63 & sMAPE is:7.33% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 9.07% & 0.41\n",
      "for 2021-01-13, MAE is:9.49 & sMAPE is:13.36% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 9.40% & 0.48\n",
      "for 2021-01-14, MAE is:9.25 & sMAPE is:12.60% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 9.63% & 0.52\n",
      "for 2021-01-15, MAE is:9.49 & sMAPE is:12.99% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 9.85% & 0.53\n",
      "for 2021-01-16, MAE is:4.60 & sMAPE is:7.61% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 9.71% & 0.59\n",
      "for 2021-01-17, MAE is:8.73 & sMAPE is:16.41% & rMAE is:2.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 10.11% & 0.71\n",
      "for 2021-01-18, MAE is:5.49 & sMAPE is:8.13% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 10.00% & 0.77\n",
      "for 2021-01-19, MAE is:5.76 & sMAPE is:9.83% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 9.99% & 0.79\n",
      "for 2021-01-20, MAE is:8.07 & sMAPE is:15.39% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 10.26% & 0.77\n",
      "for 2021-01-21, MAE is:6.71 & sMAPE is:27.16% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 11.06% & 0.74\n",
      "for 2021-01-22, MAE is:5.97 & sMAPE is:13.43% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 11.17% & 0.72\n",
      "for 2021-01-23, MAE is:5.80 & sMAPE is:11.62% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 11.19% & 0.73\n",
      "for 2021-01-24, MAE is:3.18 & sMAPE is:6.35% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 10.99% & 0.71\n",
      "for 2021-01-25, MAE is:5.12 & sMAPE is:8.64% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 10.89% & 0.71\n",
      "for 2021-01-26, MAE is:4.51 & sMAPE is:7.24% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 10.75% & 0.73\n",
      "for 2021-01-27, MAE is:2.95 & sMAPE is:5.35% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 10.55% & 0.71\n",
      "for 2021-01-28, MAE is:2.69 & sMAPE is:4.97% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 10.35% & 0.69\n",
      "for 2021-01-29, MAE is:3.57 & sMAPE is:8.00% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 10.27% & 0.69\n",
      "for 2021-01-30, MAE is:5.95 & sMAPE is:12.73% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 10.36% & 0.72\n",
      "for 2021-01-31, MAE is:7.66 & sMAPE is:17.57% & rMAE is:4.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 10.59% & 0.85\n",
      "for 2021-02-01, MAE is:5.70 & sMAPE is:10.11% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 10.57% & 0.85\n",
      "for 2021-02-02, MAE is:5.70 & sMAPE is:12.37% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 10.63% & 0.84\n",
      "for 2021-02-03, MAE is:5.75 & sMAPE is:18.55% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 10.86% & 0.82\n",
      "for 2021-02-04, MAE is:7.72 & sMAPE is:15.57% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 10.99% & 0.84\n",
      "for 2021-02-05, MAE is:2.88 & sMAPE is:5.50% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 10.84% & 0.84\n",
      "for 2021-02-06, MAE is:6.39 & sMAPE is:15.83% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 10.98% & 0.83\n",
      "for 2021-02-07, MAE is:13.53 & sMAPE is:70.30% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 12.54% & 0.83\n",
      "for 2021-02-08, MAE is:6.73 & sMAPE is:17.80% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 12.67% & 0.83\n",
      "for 2021-02-09, MAE is:10.50 & sMAPE is:16.66% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 12.77% & 0.83\n",
      "for 2021-02-10, MAE is:12.16 & sMAPE is:16.32% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 12.86% & 0.82\n",
      "for 2021-02-11, MAE is:14.58 & sMAPE is:16.74% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 12.95% & 0.81\n",
      "for 2021-02-12, MAE is:4.28 & sMAPE is:6.85% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 12.81% & 0.80\n",
      "for 2021-02-13, MAE is:3.15 & sMAPE is:5.64% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 12.65% & 0.78\n",
      "for 2021-02-14, MAE is:3.37 & sMAPE is:7.00% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 12.52% & 0.77\n",
      "for 2021-02-15, MAE is:4.66 & sMAPE is:9.08% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 12.45% & 0.77\n",
      "for 2021-02-16, MAE is:5.54 & sMAPE is:10.73% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 12.41% & 0.77\n",
      "for 2021-02-17, MAE is:4.17 & sMAPE is:7.98% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 12.32% & 0.75\n",
      "for 2021-02-18, MAE is:4.89 & sMAPE is:10.51% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 12.28% & 0.74\n",
      "for 2021-02-19, MAE is:4.75 & sMAPE is:9.88% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 12.23% & 0.73\n",
      "for 2021-02-20, MAE is:5.64 & sMAPE is:18.18% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 12.35% & 0.72\n",
      "for 2021-02-21, MAE is:12.06 & sMAPE is:40.50% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 12.89% & 0.73\n",
      "for 2021-02-22, MAE is:10.06 & sMAPE is:23.44% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 13.09% & 0.75\n",
      "for 2021-02-23, MAE is:5.53 & sMAPE is:12.13% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 13.07% & 0.74\n",
      "for 2021-02-24, MAE is:8.07 & sMAPE is:25.05% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 13.29% & 0.74\n",
      "for 2021-02-25, MAE is:10.21 & sMAPE is:24.57% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 13.49% & 0.76\n",
      "for 2021-02-26, MAE is:5.50 & sMAPE is:11.29% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 13.45% & 0.77\n",
      "for 2021-02-27, MAE is:6.56 & sMAPE is:15.20% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 13.48% & 0.77\n",
      "for 2021-02-28, MAE is:5.90 & sMAPE is:15.04% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 13.51% & 0.77\n",
      "for 2021-03-01, MAE is:6.43 & sMAPE is:12.81% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 13.50% & 0.78\n",
      "for 2021-03-02, MAE is:7.54 & sMAPE is:13.64% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 13.50% & 0.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-03, MAE is:5.66 & sMAPE is:10.52% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 13.45% & 0.77\n",
      "for 2021-03-04, MAE is:3.13 & sMAPE is:5.73% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 13.33% & 0.77\n",
      "for 2021-03-05, MAE is:4.36 & sMAPE is:8.21% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 13.25% & 0.77\n",
      "for 2021-03-06, MAE is:3.84 & sMAPE is:8.40% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 13.17% & 0.78\n",
      "for 2021-03-07, MAE is:4.14 & sMAPE is:9.00% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 13.11% & 0.78\n",
      "for 2021-03-08, MAE is:8.85 & sMAPE is:13.27% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 13.11% & 0.78\n",
      "for 2021-03-09, MAE is:6.95 & sMAPE is:10.98% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 13.08% & 0.78\n",
      "for 2021-03-10, MAE is:5.96 & sMAPE is:10.63% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 13.05% & 0.79\n",
      "for 2021-03-11, MAE is:5.40 & sMAPE is:14.79% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 13.07% & 0.78\n",
      "for 2021-03-12, MAE is:7.69 & sMAPE is:22.68% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 13.21% & 0.78\n",
      "for 2021-03-13, MAE is:7.44 & sMAPE is:34.63% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 13.50% & 0.77\n",
      "for 2021-03-14, MAE is:10.96 & sMAPE is:46.06% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 13.95% & 0.77\n",
      "for 2021-03-15, MAE is:7.73 & sMAPE is:16.62% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 13.99% & 0.76\n",
      "for 2021-03-16, MAE is:5.71 & sMAPE is:10.05% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 13.93% & 0.77\n",
      "for 2021-03-17, MAE is:7.58 & sMAPE is:13.52% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 13.93% & 0.77\n",
      "for 2021-03-18, MAE is:6.56 & sMAPE is:9.97% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 13.88% & 0.76\n",
      "for 2021-03-19, MAE is:7.68 & sMAPE is:13.70% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 13.88% & 0.76\n",
      "for 2021-03-20, MAE is:5.45 & sMAPE is:10.63% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 13.83% & 0.75\n",
      "for 2021-03-21, MAE is:8.83 & sMAPE is:22.59% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 13.94% & 0.75\n",
      "for 2021-03-22, MAE is:8.80 & sMAPE is:14.90% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 13.96% & 0.75\n",
      "for 2021-03-23, MAE is:7.42 & sMAPE is:12.19% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 13.93% & 0.75\n",
      "for 2021-03-24, MAE is:6.04 & sMAPE is:9.73% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 13.88% & 0.76\n",
      "for 2021-03-25, MAE is:7.09 & sMAPE is:11.71% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 13.86% & 0.76\n",
      "for 2021-03-26, MAE is:6.37 & sMAPE is:12.03% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 13.84% & 0.77\n",
      "for 2021-03-27, MAE is:12.57 & sMAPE is:36.74% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 14.10% & 0.77\n",
      "for 2021-03-28, MAE is:13.18 & sMAPE is:53.59% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 14.56% & 0.77\n",
      "for 2021-03-29, MAE is:12.33 & sMAPE is:29.05% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 14.72% & 0.77\n",
      "for 2021-03-30, MAE is:9.91 & sMAPE is:18.18% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 14.76% & 0.78\n",
      "for 2021-03-31, MAE is:6.49 & sMAPE is:11.35% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 14.72% & 0.78\n",
      "for 2021-04-01, MAE is:4.71 & sMAPE is:8.90% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 14.66% & 0.78\n",
      "for 2021-04-02, MAE is:12.15 & sMAPE is:35.51% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 14.88% & 0.78\n",
      "for 2021-04-03, MAE is:7.46 & sMAPE is:29.60% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 15.04% & 0.78\n",
      "for 2021-04-04, MAE is:8.57 & sMAPE is:44.01% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 15.35% & 0.79\n",
      "for 2021-04-05, MAE is:16.29 & sMAPE is:66.37% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 15.89% & 0.79\n",
      "for 2021-04-06, MAE is:7.22 & sMAPE is:13.57% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 15.86% & 0.79\n",
      "for 2021-04-07, MAE is:12.29 & sMAPE is:15.53% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 15.86% & 0.79\n",
      "for 2021-04-08, MAE is:24.45 & sMAPE is:29.66% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 16.00% & 0.79\n",
      "for 2021-04-09, MAE is:4.59 & sMAPE is:6.43% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 15.90% & 0.79\n",
      "for 2021-04-10, MAE is:4.26 & sMAPE is:6.94% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.81% & 0.78\n",
      "for 2021-04-11, MAE is:5.34 & sMAPE is:10.07% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 15.76% & 0.77\n",
      "for 2021-04-12, MAE is:9.74 & sMAPE is:13.67% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 15.74% & 0.77\n",
      "for 2021-04-13, MAE is:17.39 & sMAPE is:20.67% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 15.79% & 0.77\n",
      "for 2021-04-14, MAE is:9.08 & sMAPE is:10.73% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 15.74% & 0.77\n",
      "for 2021-04-15, MAE is:8.96 & sMAPE is:11.56% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 15.70% & 0.78\n",
      "for 2021-04-16, MAE is:5.78 & sMAPE is:8.26% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 15.63% & 0.79\n",
      "for 2021-04-17, MAE is:4.15 & sMAPE is:6.46% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 15.54% & 0.79\n",
      "for 2021-04-18, MAE is:5.60 & sMAPE is:8.64% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 15.48% & 0.79\n",
      "for 2021-04-19, MAE is:8.50 & sMAPE is:10.26% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 15.43% & 0.79\n",
      "for 2021-04-20, MAE is:6.31 & sMAPE is:7.54% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 15.36% & 0.78\n",
      "for 2021-04-21, MAE is:3.88 & sMAPE is:5.15% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 15.27% & 0.78\n",
      "for 2021-04-22, MAE is:5.09 & sMAPE is:7.76% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 15.20% & 0.78\n",
      "for 2021-04-23, MAE is:7.42 & sMAPE is:11.90% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 15.17% & 0.79\n",
      "for 2021-04-24, MAE is:8.13 & sMAPE is:18.24% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 15.20% & 0.78\n",
      "for 2021-04-25, MAE is:17.32 & sMAPE is:56.58% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 15.56% & 0.78\n",
      "for 2021-04-26, MAE is:10.59 & sMAPE is:18.31% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 15.58% & 0.78\n",
      "for 2021-04-27, MAE is:6.25 & sMAPE is:9.55% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 15.53% & 0.78\n",
      "for 2021-04-28, MAE is:6.63 & sMAPE is:9.72% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 15.48% & 0.78\n",
      "for 2021-04-29, MAE is:3.63 & sMAPE is:5.55% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 15.40% & 0.78\n",
      "for 2021-04-30, MAE is:5.44 & sMAPE is:7.72% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 15.33% & 0.78\n",
      "for 2021-05-01, MAE is:7.62 & sMAPE is:12.70% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 15.31% & 0.78\n",
      "for 2021-05-02, MAE is:12.69 & sMAPE is:36.95% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 15.49% & 0.78\n",
      "for 2021-05-03, MAE is:7.22 & sMAPE is:11.15% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 15.45% & 0.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-04, MAE is:23.94 & sMAPE is:69.69% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 15.89% & 0.78\n",
      "for 2021-05-05, MAE is:9.35 & sMAPE is:15.87% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 15.89% & 0.79\n",
      "for 2021-05-06, MAE is:6.36 & sMAPE is:8.99% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 15.83% & 0.79\n",
      "for 2021-05-07, MAE is:7.14 & sMAPE is:10.16% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 15.79% & 0.79\n",
      "for 2021-05-08, MAE is:19.61 & sMAPE is:48.74% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 16.05% & 0.80\n",
      "for 2021-05-09, MAE is:38.69 & sMAPE is:144.66% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 17.04% & 0.80\n",
      "for 2021-05-10, MAE is:14.92 & sMAPE is:28.10% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 17.13% & 0.80\n",
      "for 2021-05-11, MAE is:6.03 & sMAPE is:8.72% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 17.07% & 0.80\n",
      "for 2021-05-12, MAE is:4.37 & sMAPE is:6.44% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 16.98% & 0.79\n",
      "for 2021-05-13, MAE is:6.42 & sMAPE is:10.45% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 16.94% & 0.79\n",
      "for 2021-05-14, MAE is:5.02 & sMAPE is:7.17% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 16.86% & 0.79\n",
      "for 2021-05-15, MAE is:9.68 & sMAPE is:17.29% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 16.87% & 0.79\n",
      "for 2021-05-16, MAE is:25.16 & sMAPE is:76.45% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 17.30% & 0.79\n",
      "for 2021-05-17, MAE is:17.74 & sMAPE is:28.96% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 17.39% & 0.80\n",
      "for 2021-05-18, MAE is:5.92 & sMAPE is:8.23% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 17.32% & 0.81\n",
      "for 2021-05-19, MAE is:5.44 & sMAPE is:7.15% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 17.25% & 0.80\n",
      "for 2021-05-20, MAE is:9.21 & sMAPE is:13.19% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 17.22% & 0.81\n",
      "for 2021-05-21, MAE is:36.46 & sMAPE is:93.63% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 17.76% & 0.81\n",
      "for 2021-05-22, MAE is:23.62 & sMAPE is:129.41% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 18.55% & 0.81\n",
      "for 2021-05-23, MAE is:23.89 & sMAPE is:90.60% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 19.05% & 0.81\n",
      "for 2021-05-24, MAE is:18.42 & sMAPE is:54.06% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 19.30% & 0.81\n",
      "for 2021-05-25, MAE is:8.74 & sMAPE is:15.20% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 19.27% & 0.81\n",
      "for 2021-05-26, MAE is:5.96 & sMAPE is:8.82% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 19.20% & 0.81\n",
      "for 2021-05-27, MAE is:6.32 & sMAPE is:8.92% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 19.13% & 0.81\n",
      "for 2021-05-28, MAE is:6.34 & sMAPE is:8.83% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 19.06% & 0.80\n",
      "for 2021-05-29, MAE is:9.27 & sMAPE is:20.88% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 19.07% & 0.80\n",
      "for 2021-05-30, MAE is:22.72 & sMAPE is:72.80% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 19.43% & 0.81\n",
      "for 2021-05-31, MAE is:14.27 & sMAPE is:22.96% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 19.45% & 0.81\n",
      "for 2021-06-01, MAE is:8.04 & sMAPE is:11.71% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 19.40% & 0.81\n",
      "for 2021-06-02, MAE is:7.28 & sMAPE is:11.06% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 19.34% & 0.81\n",
      "for 2021-06-03, MAE is:4.62 & sMAPE is:6.82% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 19.26% & 0.81\n",
      "for 2021-06-04, MAE is:4.87 & sMAPE is:6.86% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 19.18% & 0.81\n",
      "for 2021-06-05, MAE is:3.95 & sMAPE is:6.23% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 19.10% & 0.81\n",
      "for 2021-06-06, MAE is:5.73 & sMAPE is:10.33% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 19.04% & 0.80\n",
      "for 2021-06-07, MAE is:7.63 & sMAPE is:10.65% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 18.99% & 0.80\n",
      "for 2021-06-08, MAE is:6.09 & sMAPE is:7.90% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 18.92% & 0.80\n",
      "for 2021-06-09, MAE is:5.97 & sMAPE is:8.10% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 18.85% & 0.80\n",
      "for 2021-06-10, MAE is:5.83 & sMAPE is:7.57% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.36 & 18.78% & 0.80\n",
      "for 2021-06-11, MAE is:6.34 & sMAPE is:8.37% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 18.72% & 0.80\n",
      "for 2021-06-12, MAE is:24.54 & sMAPE is:56.76% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 18.95% & 0.81\n",
      "for 2021-06-13, MAE is:35.29 & sMAPE is:104.51% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 19.47% & 0.81\n",
      "for 2021-06-14, MAE is:11.48 & sMAPE is:16.10% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 19.45% & 0.81\n",
      "for 2021-06-15, MAE is:6.38 & sMAPE is:7.75% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 19.38% & 0.81\n",
      "for 2021-06-16, MAE is:8.70 & sMAPE is:9.76% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 19.33% & 0.81\n",
      "for 2021-06-17, MAE is:9.00 & sMAPE is:10.64% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.62 & 19.27% & 0.81\n",
      "for 2021-06-18, MAE is:7.33 & sMAPE is:9.10% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 19.21% & 0.82\n",
      "for 2021-06-19, MAE is:6.32 & sMAPE is:8.68% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 19.15% & 0.82\n",
      "for 2021-06-20, MAE is:10.30 & sMAPE is:19.96% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.60 & 19.16% & 0.81\n",
      "for 2021-06-21, MAE is:5.16 & sMAPE is:6.80% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 19.09% & 0.81\n",
      "for 2021-06-22, MAE is:5.15 & sMAPE is:6.40% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 19.01% & 0.82\n",
      "for 2021-06-23, MAE is:4.48 & sMAPE is:5.39% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 18.93% & 0.81\n",
      "for 2021-06-24, MAE is:6.10 & sMAPE is:6.83% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.53 & 18.86% & 0.81\n",
      "for 2021-06-25, MAE is:4.62 & sMAPE is:5.63% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 18.79% & 0.81\n",
      "for 2021-06-26, MAE is:5.56 & sMAPE is:7.34% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 18.72% & 0.81\n",
      "for 2021-06-27, MAE is:22.35 & sMAPE is:44.49% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 18.87% & 0.82\n",
      "for 2021-06-28, MAE is:12.15 & sMAPE is:14.94% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 18.85% & 0.82\n",
      "for 2021-06-29, MAE is:4.97 & sMAPE is:5.85% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 18.78% & 0.82\n",
      "for 2021-06-30, MAE is:4.84 & sMAPE is:5.65% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 18.70% & 0.82\n",
      "for 2021-07-01, MAE is:3.29 & sMAPE is:3.73% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 18.62% & 0.82\n",
      "for 2021-07-02, MAE is:7.91 & sMAPE is:8.64% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 18.57% & 0.82\n",
      "for 2021-07-03, MAE is:6.94 & sMAPE is:8.20% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 18.51% & 0.82\n",
      "for 2021-07-04, MAE is:5.69 & sMAPE is:7.26% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 18.45% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-05, MAE is:4.98 & sMAPE is:5.49% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 18.38% & 0.82\n",
      "for 2021-07-06, MAE is:13.44 & sMAPE is:17.25% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 18.37% & 0.82\n",
      "for 2021-07-07, MAE is:11.11 & sMAPE is:11.80% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 18.34% & 0.82\n",
      "for 2021-07-08, MAE is:4.02 & sMAPE is:4.15% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 18.26% & 0.82\n",
      "for 2021-07-09, MAE is:5.44 & sMAPE is:5.90% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 18.20% & 0.82\n",
      "for 2021-07-10, MAE is:5.71 & sMAPE is:6.90% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 18.14% & 0.83\n",
      "for 2021-07-11, MAE is:5.79 & sMAPE is:7.45% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 18.08% & 0.83\n",
      "for 2021-07-12, MAE is:7.14 & sMAPE is:7.73% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 18.03% & 0.84\n",
      "for 2021-07-13, MAE is:6.03 & sMAPE is:6.75% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 17.97% & 0.84\n",
      "for 2021-07-14, MAE is:14.25 & sMAPE is:24.66% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 18.01% & 0.83\n",
      "for 2021-07-15, MAE is:10.67 & sMAPE is:23.61% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 18.03% & 0.83\n",
      "for 2021-07-16, MAE is:5.99 & sMAPE is:7.41% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 17.98% & 0.83\n",
      "for 2021-07-17, MAE is:13.76 & sMAPE is:23.46% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 18.01% & 0.83\n",
      "for 2021-07-18, MAE is:24.02 & sMAPE is:59.05% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 18.21% & 0.83\n",
      "for 2021-07-19, MAE is:13.07 & sMAPE is:15.58% & rMAE is:2.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 18.20% & 0.84\n",
      "for 2021-07-20, MAE is:9.46 & sMAPE is:10.40% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 18.16% & 0.84\n",
      "for 2021-07-21, MAE is:8.07 & sMAPE is:8.97% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 18.12% & 0.84\n",
      "for 2021-07-22, MAE is:6.88 & sMAPE is:7.65% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 18.07% & 0.84\n",
      "for 2021-07-23, MAE is:6.59 & sMAPE is:7.81% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 18.01% & 0.84\n",
      "for 2021-07-24, MAE is:6.15 & sMAPE is:7.95% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 17.97% & 0.84\n",
      "for 2021-07-25, MAE is:14.27 & sMAPE is:22.91% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 17.99% & 0.84\n",
      "for 2021-07-26, MAE is:6.44 & sMAPE is:7.92% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 17.94% & 0.84\n",
      "for 2021-07-27, MAE is:5.59 & sMAPE is:6.35% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 17.89% & 0.84\n",
      "for 2021-07-28, MAE is:18.45 & sMAPE is:28.80% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.60 & 17.94% & 0.84\n",
      "for 2021-07-29, MAE is:26.91 & sMAPE is:57.10% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 18.12% & 0.84\n",
      "for 2021-07-30, MAE is:30.79 & sMAPE is:64.11% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.79 & 18.34% & 0.84\n",
      "for 2021-07-31, MAE is:26.00 & sMAPE is:93.45% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.88 & 18.70% & 0.84\n",
      "for 2021-08-01, MAE is:9.22 & sMAPE is:18.56% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.88 & 18.70% & 0.84\n",
      "for 2021-08-02, MAE is:10.74 & sMAPE is:13.31% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 18.67% & 0.84\n",
      "for 2021-08-03, MAE is:6.99 & sMAPE is:7.95% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.88 & 18.62% & 0.84\n",
      "for 2021-08-04, MAE is:9.38 & sMAPE is:11.15% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.88 & 18.59% & 0.84\n",
      "for 2021-08-05, MAE is:10.71 & sMAPE is:12.84% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 18.56% & 0.84\n",
      "for 2021-08-06, MAE is:51.16 & sMAPE is:130.94% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.08 & 19.08% & 0.84\n",
      "for 2021-08-07, MAE is:14.52 & sMAPE is:46.96% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 19.20% & 0.84\n",
      "for 2021-08-08, MAE is:44.30 & sMAPE is:159.02% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.27 & 19.84% & 0.84\n",
      "for 2021-08-09, MAE is:30.43 & sMAPE is:54.95% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 20.00% & 0.84\n",
      "for 2021-08-10, MAE is:15.66 & sMAPE is:21.36% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 20.00% & 0.85\n",
      "for 2021-08-11, MAE is:14.89 & sMAPE is:15.70% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 19.98% & 0.85\n",
      "for 2021-08-12, MAE is:11.20 & sMAPE is:10.87% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 19.94% & 0.85\n",
      "for 2021-08-13, MAE is:9.70 & sMAPE is:10.39% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 19.90% & 0.84\n",
      "for 2021-08-14, MAE is:12.74 & sMAPE is:19.21% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 19.90% & 0.84\n",
      "for 2021-08-15, MAE is:16.14 & sMAPE is:34.55% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :9.47 & 19.96% & 0.84\n",
      "for 2021-08-16, MAE is:21.60 & sMAPE is:55.36% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 20.12% & 0.84\n",
      "for 2021-08-17, MAE is:11.45 & sMAPE is:19.45% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.53 & 20.11% & 0.84\n",
      "for 2021-08-18, MAE is:7.14 & sMAPE is:9.38% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 20.07% & 0.84\n",
      "for 2021-08-19, MAE is:15.50 & sMAPE is:16.86% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 20.05% & 0.84\n",
      "for 2021-08-20, MAE is:8.38 & sMAPE is:8.60% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 20.00% & 0.84\n",
      "for 2021-08-21, MAE is:8.40 & sMAPE is:9.35% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 19.96% & 0.84\n",
      "for 2021-08-22, MAE is:8.41 & sMAPE is:10.96% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.53 & 19.92% & 0.83\n",
      "for 2021-08-23, MAE is:13.53 & sMAPE is:16.20% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 19.90% & 0.83\n",
      "for 2021-08-24, MAE is:13.20 & sMAPE is:20.89% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 19.91% & 0.83\n",
      "for 2021-08-25, MAE is:11.37 & sMAPE is:13.92% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 19.88% & 0.83\n",
      "for 2021-08-26, MAE is:6.72 & sMAPE is:7.47% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 19.83% & 0.83\n",
      "for 2021-08-27, MAE is:6.76 & sMAPE is:7.30% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 19.78% & 0.83\n",
      "for 2021-08-28, MAE is:12.17 & sMAPE is:17.99% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 19.77% & 0.83\n",
      "for 2021-08-29, MAE is:7.46 & sMAPE is:11.35% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 19.74% & 0.83\n",
      "for 2021-08-30, MAE is:20.95 & sMAPE is:21.28% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 19.74% & 0.84\n",
      "for 2021-08-31, MAE is:10.58 & sMAPE is:9.79% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 19.70% & 0.83\n",
      "for 2021-09-01, MAE is:11.28 & sMAPE is:11.90% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.61 & 19.67% & 0.83\n",
      "for 2021-09-02, MAE is:15.21 & sMAPE is:16.78% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.63 & 19.66% & 0.83\n",
      "for 2021-09-03, MAE is:11.87 & sMAPE is:10.79% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :9.64 & 19.62% & 0.83\n",
      "for 2021-09-04, MAE is:14.49 & sMAPE is:13.81% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.66 & 19.60% & 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-05, MAE is:14.86 & sMAPE is:15.21% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 19.58% & 0.83\n",
      "for 2021-09-06, MAE is:14.38 & sMAPE is:12.02% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.70 & 19.55% & 0.83\n",
      "for 2021-09-07, MAE is:12.16 & sMAPE is:10.34% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 19.51% & 0.83\n",
      "for 2021-09-08, MAE is:12.23 & sMAPE is:10.40% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :9.72 & 19.48% & 0.83\n",
      "for 2021-09-09, MAE is:13.36 & sMAPE is:10.77% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.73 & 19.44% & 0.83\n",
      "for 2021-09-10, MAE is:13.68 & sMAPE is:10.55% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 19.41% & 0.83\n",
      "for 2021-09-11, MAE is:10.71 & sMAPE is:8.59% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 19.36% & 0.83\n",
      "for 2021-09-12, MAE is:13.19 & sMAPE is:12.16% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.77 & 19.34% & 0.83\n",
      "for 2021-09-13, MAE is:15.76 & sMAPE is:11.73% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :9.79 & 19.31% & 0.83\n",
      "for 2021-09-14, MAE is:15.23 & sMAPE is:10.98% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 19.27% & 0.83\n",
      "for 2021-09-15, MAE is:34.94 & sMAPE is:23.23% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.91 & 19.29% & 0.83\n",
      "for 2021-09-16, MAE is:18.53 & sMAPE is:11.43% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 19.26% & 0.83\n",
      "for 2021-09-17, MAE is:11.73 & sMAPE is:7.76% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.95 & 19.22% & 0.82\n",
      "for 2021-09-18, MAE is:10.32 & sMAPE is:7.12% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :9.95 & 19.17% & 0.82\n",
      "for 2021-09-19, MAE is:30.35 & sMAPE is:29.31% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :10.03 & 19.21% & 0.83\n",
      "for 2021-09-20, MAE is:25.58 & sMAPE is:18.03% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 19.20% & 0.83\n",
      "for 2021-09-21, MAE is:13.51 & sMAPE is:9.32% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 19.17% & 0.83\n",
      "for 2021-09-22, MAE is:16.73 & sMAPE is:11.49% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :10.12 & 19.14% & 0.83\n",
      "for 2021-09-23, MAE is:15.39 & sMAPE is:12.37% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 19.11% & 0.83\n",
      "for 2021-09-24, MAE is:13.25 & sMAPE is:9.45% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 19.08% & 0.83\n",
      "for 2021-09-25, MAE is:12.65 & sMAPE is:8.75% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.17 & 19.04% & 0.84\n",
      "for 2021-09-26, MAE is:22.20 & sMAPE is:17.41% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 19.03% & 0.84\n",
      "for 2021-09-27, MAE is:17.95 & sMAPE is:12.37% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 19.01% & 0.84\n",
      "for 2021-09-28, MAE is:23.44 & sMAPE is:14.81% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.29 & 18.99% & 0.84\n",
      "for 2021-09-29, MAE is:18.09 & sMAPE is:12.83% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 18.97% & 0.84\n",
      "for 2021-09-30, MAE is:19.59 & sMAPE is:13.17% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 18.95% & 0.84\n",
      "for 2021-10-01, MAE is:24.98 & sMAPE is:21.92% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 18.96% & 0.84\n",
      "for 2021-10-02, MAE is:45.68 & sMAPE is:41.02% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 19.04% & 0.85\n",
      "for 2021-10-03, MAE is:31.16 & sMAPE is:78.79% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.61 & 19.25% & 0.84\n",
      "for 2021-10-04, MAE is:52.45 & sMAPE is:36.08% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.76 & 19.31% & 0.85\n",
      "for 2021-10-05, MAE is:28.22 & sMAPE is:17.67% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.82 & 19.31% & 0.85\n",
      "for 2021-10-06, MAE is:61.99 & sMAPE is:38.36% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :11.00 & 19.38% & 0.85\n",
      "for 2021-10-07, MAE is:111.50 & sMAPE is:46.09% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :11.36 & 19.47% & 0.85\n",
      "for 2021-10-08, MAE is:51.99 & sMAPE is:23.95% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :11.51 & 19.49% & 0.85\n",
      "for 2021-10-09, MAE is:30.25 & sMAPE is:17.22% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.57 & 19.48% & 0.85\n",
      "for 2021-10-10, MAE is:29.57 & sMAPE is:20.20% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :11.64 & 19.48% & 0.85\n",
      "for 2021-10-11, MAE is:24.95 & sMAPE is:13.40% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.68 & 19.46% & 0.85\n",
      "for 2021-10-12, MAE is:25.99 & sMAPE is:14.35% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.73 & 19.44% & 0.85\n",
      "for 2021-10-13, MAE is:20.74 & sMAPE is:10.57% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :11.77 & 19.41% & 0.85\n",
      "for 2021-10-14, MAE is:19.68 & sMAPE is:9.85% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :11.79 & 19.38% & 0.85\n",
      "for 2021-10-15, MAE is:22.77 & sMAPE is:11.31% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :11.83 & 19.35% & 0.85\n",
      "for 2021-10-16, MAE is:15.20 & sMAPE is:8.21% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :11.84 & 19.31% & 0.85\n",
      "for 2021-10-17, MAE is:22.55 & sMAPE is:13.70% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :11.88 & 19.29% & 0.85\n",
      "for 2021-10-18, MAE is:25.13 & sMAPE is:12.84% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.93 & 19.27% & 0.85\n",
      "for 2021-10-19, MAE is:30.46 & sMAPE is:20.68% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :11.99 & 19.28% & 0.85\n",
      "for 2021-10-20, MAE is:53.45 & sMAPE is:65.15% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :12.13 & 19.43% & 0.85\n",
      "for 2021-10-21, MAE is:79.10 & sMAPE is:82.26% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :12.36 & 19.65% & 0.85\n",
      "for 2021-10-22, MAE is:36.71 & sMAPE is:19.05% & rMAE is:3.59 ||| daily mean of MAE & sMAPE & rMAE till now are :12.44 & 19.64% & 0.86\n",
      "for 2021-10-23, MAE is:20.04 & sMAPE is:10.01% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :12.47 & 19.61% & 0.86\n",
      "for 2021-10-24, MAE is:28.29 & sMAPE is:19.23% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :12.52 & 19.61% & 0.87\n",
      "for 2021-10-25, MAE is:34.25 & sMAPE is:18.29% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :12.59 & 19.61% & 0.87\n",
      "for 2021-10-26, MAE is:25.75 & sMAPE is:12.92% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :12.64 & 19.58% & 0.87\n",
      "for 2021-10-27, MAE is:22.55 & sMAPE is:11.27% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :12.67 & 19.56% & 0.87\n",
      "for 2021-10-28, MAE is:19.75 & sMAPE is:10.46% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.69 & 19.53% & 0.86\n",
      "for 2021-10-29, MAE is:32.62 & sMAPE is:23.10% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :12.76 & 19.54% & 0.86\n",
      "for 2021-10-30, MAE is:36.08 & sMAPE is:29.66% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :12.84 & 19.57% & 0.86\n",
      "for 2021-10-31, MAE is:53.97 & sMAPE is:54.25% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :12.97 & 19.69% & 0.86\n",
      "for 2021-11-01, MAE is:39.79 & sMAPE is:45.70% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :13.06 & 19.77% & 0.86\n",
      "for 2021-11-02, MAE is:66.29 & sMAPE is:37.05% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :13.23 & 19.83% & 0.86\n",
      "for 2021-11-03, MAE is:19.52 & sMAPE is:10.30% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :13.25 & 19.80% & 0.86\n",
      "for 2021-11-04, MAE is:13.34 & sMAPE is:7.72% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :13.25 & 19.76% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-05, MAE is:16.07 & sMAPE is:8.91% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :13.26 & 19.72% & 0.86\n",
      "for 2021-11-06, MAE is:16.55 & sMAPE is:10.03% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :13.27 & 19.69% & 0.86\n",
      "for 2021-11-07, MAE is:25.76 & sMAPE is:20.33% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :13.31 & 19.69% & 0.86\n",
      "for 2021-11-08, MAE is:57.29 & sMAPE is:30.23% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :13.46 & 19.73% & 0.86\n",
      "for 2021-11-09, MAE is:24.01 & sMAPE is:12.27% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :13.49 & 19.70% & 0.86\n",
      "for 2021-11-10, MAE is:46.37 & sMAPE is:21.46% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :13.59 & 19.71% & 0.86\n",
      "for 2021-11-11, MAE is:15.70 & sMAPE is:8.22% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :13.60 & 19.67% & 0.86\n",
      "for 2021-11-12, MAE is:18.94 & sMAPE is:10.73% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :13.62 & 19.64% & 0.86\n",
      "for 2021-11-13, MAE is:16.38 & sMAPE is:9.93% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :13.63 & 19.61% & 0.86\n",
      "for 2021-11-14, MAE is:13.02 & sMAPE is:8.10% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :13.62 & 19.58% & 0.86\n",
      "for 2021-11-15, MAE is:49.63 & sMAPE is:23.13% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :13.74 & 19.59% & 0.86\n",
      "for 2021-11-16, MAE is:38.57 & sMAPE is:16.57% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :13.81 & 19.58% & 0.86\n",
      "for 2021-11-17, MAE is:12.37 & sMAPE is:5.88% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :13.81 & 19.54% & 0.86\n",
      "for 2021-11-18, MAE is:39.86 & sMAPE is:18.50% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :13.89 & 19.53% & 0.86\n",
      "for 2021-11-19, MAE is:27.03 & sMAPE is:11.57% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :13.93 & 19.51% & 0.86\n",
      "for 2021-11-20, MAE is:25.38 & sMAPE is:11.50% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :13.97 & 19.48% & 0.86\n",
      "for 2021-11-21, MAE is:23.31 & sMAPE is:10.83% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :14.00 & 19.46% & 0.86\n",
      "for 2021-11-22, MAE is:28.99 & sMAPE is:11.71% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :14.04 & 19.43% & 0.86\n",
      "for 2021-11-23, MAE is:43.14 & sMAPE is:16.63% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :14.13 & 19.42% & 0.86\n",
      "for 2021-11-24, MAE is:58.90 & sMAPE is:20.25% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :14.27 & 19.43% & 0.86\n",
      "for 2021-11-25, MAE is:46.82 & sMAPE is:15.90% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :14.37 & 19.42% & 0.86\n",
      "for 2021-11-26, MAE is:25.46 & sMAPE is:9.29% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :14.40 & 19.38% & 0.86\n",
      "for 2021-11-27, MAE is:29.12 & sMAPE is:12.23% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :14.44 & 19.36% & 0.86\n",
      "for 2021-11-28, MAE is:19.58 & sMAPE is:9.07% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :14.46 & 19.33% & 0.86\n",
      "for 2021-11-29, MAE is:83.77 & sMAPE is:29.74% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :14.67 & 19.36% & 0.86\n",
      "for 2021-11-30, MAE is:25.05 & sMAPE is:9.69% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :14.70 & 19.33% & 0.87\n",
      "for 2021-12-01, MAE is:43.46 & sMAPE is:16.78% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :14.78 & 19.33% & 0.87\n",
      "for 2021-12-02, MAE is:28.10 & sMAPE is:10.21% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :14.82 & 19.30% & 0.87\n",
      "for 2021-12-03, MAE is:41.95 & sMAPE is:14.65% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :14.90 & 19.29% & 0.87\n",
      "for 2021-12-04, MAE is:28.57 & sMAPE is:11.76% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :14.95 & 19.26% & 0.87\n",
      "for 2021-12-05, MAE is:21.31 & sMAPE is:9.68% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :14.96 & 19.24% & 0.87\n",
      "for 2021-12-06, MAE is:45.51 & sMAPE is:16.03% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :15.05 & 19.23% & 0.88\n",
      "for 2021-12-07, MAE is:29.47 & sMAPE is:11.54% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :15.10 & 19.20% & 0.88\n",
      "for 2021-12-08, MAE is:15.41 & sMAPE is:6.33% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :15.10 & 19.17% & 0.88\n",
      "for 2021-12-09, MAE is:50.43 & sMAPE is:18.04% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :15.20 & 19.16% & 0.88\n",
      "for 2021-12-10, MAE is:25.44 & sMAPE is:10.64% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :15.23 & 19.14% & 0.88\n",
      "for 2021-12-11, MAE is:29.78 & sMAPE is:12.46% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :15.27 & 19.12% & 0.88\n",
      "for 2021-12-12, MAE is:30.42 & sMAPE is:13.22% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :15.32 & 19.10% & 0.88\n",
      "for 2021-12-13, MAE is:40.94 & sMAPE is:14.12% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :15.39 & 19.09% & 0.88\n",
      "for 2021-12-14, MAE is:55.53 & sMAPE is:18.07% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :15.51 & 19.08% & 0.88\n",
      "for 2021-12-15, MAE is:70.13 & sMAPE is:22.11% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :15.66 & 19.09% & 0.88\n",
      "for 2021-12-16, MAE is:62.43 & sMAPE is:18.49% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :15.80 & 19.09% & 0.88\n",
      "for 2021-12-17, MAE is:54.06 & sMAPE is:16.49% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :15.90 & 19.08% & 0.88\n",
      "for 2021-12-18, MAE is:33.35 & sMAPE is:11.27% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :15.95 & 19.06% & 0.88\n",
      "for 2021-12-19, MAE is:46.64 & sMAPE is:14.47% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :16.04 & 19.05% & 0.88\n",
      "for 2021-12-20, MAE is:60.16 & sMAPE is:16.42% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :16.17 & 19.04% & 0.88\n",
      "for 2021-12-21, MAE is:105.14 & sMAPE is:25.30% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :16.42 & 19.06% & 0.88\n",
      "for 2021-12-22, MAE is:85.84 & sMAPE is:20.20% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :16.61 & 19.06% & 0.88\n",
      "for 2021-12-23, MAE is:53.86 & sMAPE is:13.86% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :16.72 & 19.05% & 0.88\n",
      "for 2021-12-24, MAE is:42.17 & sMAPE is:12.01% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :16.79 & 19.03% & 0.88\n",
      "for 2021-12-25, MAE is:65.81 & sMAPE is:27.51% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :16.92 & 19.05% & 0.88\n",
      "for 2021-12-26, MAE is:59.72 & sMAPE is:28.46% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :17.04 & 19.08% & 0.87\n",
      "for 2021-12-27, MAE is:62.77 & sMAPE is:34.51% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :17.17 & 19.12% & 0.87\n",
      "for 2021-12-28, MAE is:110.73 & sMAPE is:78.67% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :17.43 & 19.28% & 0.87\n",
      "for 2021-12-29, MAE is:33.53 & sMAPE is:22.16% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :17.47 & 19.29% & 0.87\n",
      "for 2021-12-30, MAE is:79.42 & sMAPE is:64.09% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :17.64 & 19.42% & 0.87\n",
      "for 2021-12-31, MAE is:46.24 & sMAPE is:38.08% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :17.72 & 19.47% & 0.87\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:09:31,955]\u001b[0m A new study created in RDB with name: FR_2022\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:09:53,234]\u001b[0m Trial 3 finished with value: 62.64499870889014 and parameters: {'n_hidden': 4, 'learning_rate': 0.039793180770939685, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3704299919446159, 'dropout_rate_Layer_2': 0.36381096482272196, 'dropout_rate_Layer_3': 0.18898838099601978, 'dropout_rate_Layer_4': 0.36333532230393084, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.501882933686834e-05, 'l1_Layer_2': 0.0006038360536531608, 'l1_Layer_3': 0.06606593893732275, 'l1_Layer_4': 0.09323392183633976, 'n_units_Layer_1': 260, 'n_units_Layer_2': 95, 'n_units_Layer_3': 145, 'n_units_Layer_4': 105}. Best is trial 3 with value: 62.64499870889014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.64 | sMAPE for Validation Set is: 59.82% | rMAE for Validation Set is: 2.29\n",
      "MAE for Test Set is: 224.76 | sMAPE for Test Set is: 124.98% | rMAE for Test Set is: 3.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:09:58,616]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:10:02,779]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:10:07,572]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:10:10,667]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:10:19,855]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:10:23,570]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:10:28,989]\u001b[0m Trial 1 finished with value: 53.34577242599075 and parameters: {'n_hidden': 3, 'learning_rate': 0.07391274169767509, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12045793170252286, 'dropout_rate_Layer_2': 0.23002030317390998, 'dropout_rate_Layer_3': 0.23785526746270913, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.5684559559032734e-05, 'l1_Layer_2': 0.000885351892755712, 'l1_Layer_3': 0.03041710844445852, 'n_units_Layer_1': 90, 'n_units_Layer_2': 300, 'n_units_Layer_3': 265}. Best is trial 1 with value: 53.34577242599075.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.35 | sMAPE for Validation Set is: 47.07% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 203.67 | sMAPE for Test Set is: 103.64% | rMAE for Test Set is: 2.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:10:31,785]\u001b[0m Trial 0 finished with value: 52.36423902542676 and parameters: {'n_hidden': 4, 'learning_rate': 0.004820254957104918, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18928665114423368, 'dropout_rate_Layer_2': 0.3700290554285001, 'dropout_rate_Layer_3': 0.35751950658069326, 'dropout_rate_Layer_4': 0.3567823914584377, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.000330559228289217, 'l1_Layer_2': 0.0005708476163027374, 'l1_Layer_3': 0.08519521526642344, 'l1_Layer_4': 0.08728451399515162, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 180, 'n_units_Layer_4': 55}. Best is trial 0 with value: 52.36423902542676.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.36 | sMAPE for Validation Set is: 46.23% | rMAE for Validation Set is: 1.92\n",
      "MAE for Test Set is: 203.29 | sMAPE for Test Set is: 103.94% | rMAE for Test Set is: 2.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:10:37,633]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:10:42,187]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:10:50,293]\u001b[0m Trial 12 finished with value: 59.784757057568214 and parameters: {'n_hidden': 4, 'learning_rate': 0.00260780566747953, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2157285450333225, 'dropout_rate_Layer_2': 0.23216961038923523, 'dropout_rate_Layer_3': 0.08996693124404494, 'dropout_rate_Layer_4': 0.19390089232807287, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.057805543755228e-05, 'l1_Layer_2': 0.01615478828316011, 'l1_Layer_3': 9.628315848143444e-05, 'l1_Layer_4': 0.016018274890132, 'n_units_Layer_1': 160, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290, 'n_units_Layer_4': 75}. Best is trial 0 with value: 52.36423902542676.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.78 | sMAPE for Validation Set is: 55.69% | rMAE for Validation Set is: 2.19\n",
      "MAE for Test Set is: 218.76 | sMAPE for Test Set is: 118.57% | rMAE for Test Set is: 3.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:10:52,796]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:10:55,449]\u001b[0m Trial 10 finished with value: 46.92465254774751 and parameters: {'n_hidden': 3, 'learning_rate': 0.002266444298045573, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12274900360121066, 'dropout_rate_Layer_2': 0.033034506377056475, 'dropout_rate_Layer_3': 0.1861854382681185, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009631546464427826, 'l1_Layer_2': 0.07636850004777729, 'l1_Layer_3': 0.00012046497154697157, 'n_units_Layer_1': 150, 'n_units_Layer_2': 110, 'n_units_Layer_3': 175}. Best is trial 10 with value: 46.92465254774751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.92 | sMAPE for Validation Set is: 40.51% | rMAE for Validation Set is: 1.72\n",
      "MAE for Test Set is: 184.43 | sMAPE for Test Set is: 88.46% | rMAE for Test Set is: 2.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:11:00,042]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:02,288]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:04,710]\u001b[0m Trial 2 finished with value: 52.961509992015216 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018496461879035295, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.279886656128137, 'dropout_rate_Layer_2': 0.33443224352979806, 'dropout_rate_Layer_3': 0.03560070737602921, 'dropout_rate_Layer_4': 0.2532708352728707, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003110095056502023, 'l1_Layer_2': 1.622772067284232e-05, 'l1_Layer_3': 0.011577286876474135, 'l1_Layer_4': 1.2098026604169698e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 140, 'n_units_Layer_3': 50, 'n_units_Layer_4': 275}. Best is trial 10 with value: 46.92465254774751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.96 | sMAPE for Validation Set is: 46.11% | rMAE for Validation Set is: 1.94\n",
      "MAE for Test Set is: 207.20 | sMAPE for Test Set is: 107.21% | rMAE for Test Set is: 2.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:11:07,262]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:12,064]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:16,618]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:21,350]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:25,988]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:26,260]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:33,545]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:34,538]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:38,705]\u001b[0m Trial 14 finished with value: 37.81351094250573 and parameters: {'n_hidden': 3, 'learning_rate': 0.000616760679811569, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12834984502570151, 'dropout_rate_Layer_2': 0.16938005223868619, 'dropout_rate_Layer_3': 0.06971963784280662, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.898589012336473e-05, 'l1_Layer_2': 0.01020285623818001, 'l1_Layer_3': 0.0015745371371593238, 'n_units_Layer_1': 65, 'n_units_Layer_2': 155, 'n_units_Layer_3': 205}. Best is trial 14 with value: 37.81351094250573.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.81 | sMAPE for Validation Set is: 32.11% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 165.69 | sMAPE for Test Set is: 74.26% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:11:42,586]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:44,090]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:48,063]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:11:58,035]\u001b[0m Trial 32 finished with value: 59.75383463723699 and parameters: {'n_hidden': 3, 'learning_rate': 0.023008464381248747, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3245899719468975, 'dropout_rate_Layer_2': 0.3817235410747468, 'dropout_rate_Layer_3': 0.38878890887626993, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03824671884229647, 'l1_Layer_2': 6.40509061932335e-05, 'l1_Layer_3': 0.003189232508308927, 'n_units_Layer_1': 50, 'n_units_Layer_2': 95, 'n_units_Layer_3': 265}. Best is trial 14 with value: 37.81351094250573.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.75 | sMAPE for Validation Set is: 55.37% | rMAE for Validation Set is: 2.19\n",
      "MAE for Test Set is: 219.60 | sMAPE for Test Set is: 119.60% | rMAE for Test Set is: 3.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:12:02,046]\u001b[0m Trial 30 finished with value: 17.367747462528374 and parameters: {'n_hidden': 3, 'learning_rate': 0.003554417948116093, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38625717353523326, 'dropout_rate_Layer_2': 0.2613560156301771, 'dropout_rate_Layer_3': 0.30645629895072624, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002604303682988797, 'l1_Layer_2': 0.006018141339783144, 'l1_Layer_3': 0.08476641558523877, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 195}. Best is trial 30 with value: 17.367747462528374.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.37 | sMAPE for Validation Set is: 20.18% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 45.61 | sMAPE for Test Set is: 18.41% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:12:10,584]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:12,673]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:16,968]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:21,107]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:21,555]\u001b[0m Trial 34 finished with value: 17.54865590073321 and parameters: {'n_hidden': 3, 'learning_rate': 0.004377394530891385, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3893209091609109, 'dropout_rate_Layer_2': 0.25664004467985996, 'dropout_rate_Layer_3': 0.3208697471924544, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5002708746530295e-05, 'l1_Layer_2': 0.00754125665534072, 'l1_Layer_3': 0.05915651742493198, 'n_units_Layer_1': 135, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 30 with value: 17.367747462528374.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.55 | sMAPE for Validation Set is: 20.53% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 45.25 | sMAPE for Test Set is: 18.22% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:12:23,470]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:26,540]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:30,352]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:30,690]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:35,385]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:35,821]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:40,492]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:52,702]\u001b[0m Trial 42 finished with value: 55.542890982219404 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024418626167652837, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3794439365173082, 'dropout_rate_Layer_2': 0.21006229300970533, 'dropout_rate_Layer_3': 0.06569669617799333, 'dropout_rate_Layer_4': 0.21661227381524079, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.05184555382853454, 'l1_Layer_2': 0.00028243791230932473, 'l1_Layer_3': 0.0005620463654337612, 'l1_Layer_4': 0.09254224148312398, 'n_units_Layer_1': 155, 'n_units_Layer_2': 285, 'n_units_Layer_3': 110, 'n_units_Layer_4': 245}. Best is trial 30 with value: 17.367747462528374.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.54 | sMAPE for Validation Set is: 49.80% | rMAE for Validation Set is: 2.03\n",
      "MAE for Test Set is: 210.69 | sMAPE for Test Set is: 110.69% | rMAE for Test Set is: 2.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:12:52,996]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:57,194]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:12:58,259]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:03,680]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:03,997]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:07,316]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:12,707]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:17,039]\u001b[0m Trial 20 finished with value: 52.89891185946083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0056886891335152295, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3639727841810251, 'dropout_rate_Layer_2': 0.20342412228570197, 'dropout_rate_Layer_3': 0.21708596711400832, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000963526118828415, 'l1_Layer_2': 0.004416975105684102, 'l1_Layer_3': 2.0657901051246876e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 145}. Best is trial 30 with value: 17.367747462528374.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.90 | sMAPE for Validation Set is: 46.79% | rMAE for Validation Set is: 1.93\n",
      "MAE for Test Set is: 203.01 | sMAPE for Test Set is: 103.66% | rMAE for Test Set is: 2.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:13:20,537]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:21,853]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:23,650]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:26,915]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:32,159]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:34,379]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:36,875]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:38,181]\u001b[0m Trial 51 finished with value: 18.56442787790432 and parameters: {'n_hidden': 3, 'learning_rate': 0.04383932886139928, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07845950028394957, 'dropout_rate_Layer_2': 0.0666888241914542, 'dropout_rate_Layer_3': 0.3728410047544762, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.462472748129251e-05, 'l1_Layer_2': 0.0003262070665227516, 'l1_Layer_3': 2.5870969298954538e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 160, 'n_units_Layer_3': 260}. Best is trial 30 with value: 17.367747462528374.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.56 | sMAPE for Validation Set is: 21.12% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 52.25 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:13:38,285]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:40,144]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:50,050]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:50,276]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:50,486]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:57,117]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:13:59,196]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:03,406]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:05,391]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:07,054]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:07,775]\u001b[0m Trial 62 finished with value: 16.428098241124072 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032215508971933154, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03538108183477684, 'dropout_rate_Layer_2': 0.378369935846677, 'dropout_rate_Layer_3': 0.18771282693388872, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7455564607610863e-05, 'l1_Layer_2': 4.796016546207361e-05, 'l1_Layer_3': 0.07139866016721748, 'n_units_Layer_1': 120, 'n_units_Layer_2': 250, 'n_units_Layer_3': 95}. Best is trial 62 with value: 16.428098241124072.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.43 | sMAPE for Validation Set is: 19.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 45.00 | sMAPE for Test Set is: 17.55% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:14:09,447]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:11,474]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:15,311]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:17,574]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:18,588]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:22,970]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:23,626]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:25,619]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:28,126]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:29,169]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:32,510]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:37,420]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:37,842]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:38,334]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:38,833]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:43,880]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:45,900]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:50,126]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:51,906]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:14:56,968]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:15:09,268]\u001b[0m Trial 94 finished with value: 16.16117539298379 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027589706171960255, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25014882359487595, 'dropout_rate_Layer_2': 0.2242459780116089, 'dropout_rate_Layer_3': 0.20291667463265933, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023703278053404034, 'l1_Layer_2': 1.936704228849217e-05, 'l1_Layer_3': 0.03625438376816088, 'n_units_Layer_1': 155, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 94 with value: 16.16117539298379.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.16 | sMAPE for Validation Set is: 18.69% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 44.19 | sMAPE for Test Set is: 17.50% | rMAE for Test Set is: 0.61\n",
      "MAE for Validation Set is: 17.86 | sMAPE for Validation Set is: 20.59% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 44.95 | sMAPE for Test Set is: 18.28% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:15:09,585]\u001b[0m Trial 92 finished with value: 17.85992249487055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005563388010341798, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0011953053502884448, 'dropout_rate_Layer_2': 0.39715191847479303, 'dropout_rate_Layer_3': 0.018575234601714508, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09630503253350745, 'l1_Layer_2': 1.1061930741081967e-05, 'l1_Layer_3': 0.008937943922343662, 'n_units_Layer_1': 250, 'n_units_Layer_2': 235, 'n_units_Layer_3': 50}. Best is trial 94 with value: 16.16117539298379.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:15:10,232]\u001b[0m Trial 88 finished with value: 17.106316115558702 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038269424734841072, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2511883014212259, 'dropout_rate_Layer_2': 0.00874876877882061, 'dropout_rate_Layer_3': 0.31467543144706633, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003999053161584138, 'l1_Layer_2': 0.00015309604953239056, 'l1_Layer_3': 0.021858336806857063, 'n_units_Layer_1': 140, 'n_units_Layer_2': 145, 'n_units_Layer_3': 180}. Best is trial 94 with value: 16.16117539298379.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.11 | sMAPE for Validation Set is: 20.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 44.32 | sMAPE for Test Set is: 17.62% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:15:18,421]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:15:24,951]\u001b[0m Trial 97 finished with value: 17.38641031283018 and parameters: {'n_hidden': 3, 'learning_rate': 0.002843786285973359, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2528219063613199, 'dropout_rate_Layer_2': 0.09340237443815012, 'dropout_rate_Layer_3': 0.10805647962830686, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019745060428451493, 'l1_Layer_2': 1.9163164370735365e-05, 'l1_Layer_3': 0.02224753270957108, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205}. Best is trial 94 with value: 16.16117539298379.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.39 | sMAPE for Validation Set is: 19.99% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 44.08 | sMAPE for Test Set is: 17.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:15:30,006]\u001b[0m Trial 95 finished with value: 15.903146219608724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028129390172661117, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2507115008166849, 'dropout_rate_Layer_2': 0.22362671134654233, 'dropout_rate_Layer_3': 0.3996320490337944, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002748154303732727, 'l1_Layer_2': 2.0127704142867873e-05, 'l1_Layer_3': 0.021874859138636606, 'n_units_Layer_1': 135, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275}. Best is trial 95 with value: 15.903146219608724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.90 | sMAPE for Validation Set is: 18.66% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 43.93 | sMAPE for Test Set is: 17.25% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:15:33,104]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:15:37,017]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:15:40,452]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:15:44,519]\u001b[0m Trial 90 finished with value: 18.731596991878202 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016104577622515245, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24906297636453584, 'dropout_rate_Layer_2': 0.13833617030047132, 'dropout_rate_Layer_3': 0.1176830951610322, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0034770424039205763, 'l1_Layer_2': 0.09390206644339437, 'l1_Layer_3': 2.6653941679244256e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 95 with value: 15.903146219608724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.73 | sMAPE for Validation Set is: 21.12% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 49.45 | sMAPE for Test Set is: 19.80% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:15:48,421]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:15:51,793]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:15:55,207]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:15:57,902]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:15:59,580]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:16:03,586]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:16:39,906]\u001b[0m Trial 110 finished with value: 19.295658254827643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012154102641579565, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2561403240330563, 'dropout_rate_Layer_2': 0.14916968954479387, 'dropout_rate_Layer_3': 0.13328831936957447, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03568834099810463, 'l1_Layer_2': 0.03288975208835273, 'l1_Layer_3': 3.318650958153971e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 80, 'n_units_Layer_3': 215}. Best is trial 95 with value: 15.903146219608724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.30 | sMAPE for Validation Set is: 22.14% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 48.55 | sMAPE for Test Set is: 19.63% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:16:41,472]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:16:45,770]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:16:48,263]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:16:50,324]\u001b[0m Trial 98 finished with value: 17.725698349160634 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013730378996286213, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.251711530048223, 'dropout_rate_Layer_2': 0.025500689334508025, 'dropout_rate_Layer_3': 0.1240526521562376, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0049405215476475, 'l1_Layer_2': 0.08673221618531975, 'l1_Layer_3': 1.8472126576512908e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 95 with value: 15.903146219608724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.73 | sMAPE for Validation Set is: 20.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 45.78 | sMAPE for Test Set is: 18.23% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:16:53,812]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:16:55,688]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:16:59,808]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:17:00,181]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:17:04,801]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:17:08,845]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:17:16,094]\u001b[0m Trial 118 finished with value: 17.087045195719828 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006359794771321666, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005411597504439911, 'dropout_rate_Layer_2': 0.39359753484642623, 'dropout_rate_Layer_3': 0.016306898729575192, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04083948771662486, 'l1_Layer_2': 1.029280522990798e-05, 'l1_Layer_3': 0.00816956128675753, 'n_units_Layer_1': 260, 'n_units_Layer_2': 240, 'n_units_Layer_3': 50}. Best is trial 95 with value: 15.903146219608724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.09 | sMAPE for Validation Set is: 20.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 43.72 | sMAPE for Test Set is: 17.75% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:17:18,804]\u001b[0m Trial 115 finished with value: 17.42629617867745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006961960865357747, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002351145335210975, 'dropout_rate_Layer_2': 0.38460199240639453, 'dropout_rate_Layer_3': 0.005342760093477351, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05232727064514753, 'l1_Layer_2': 1.5073574981637683e-05, 'l1_Layer_3': 0.007451904387670067, 'n_units_Layer_1': 255, 'n_units_Layer_2': 245, 'n_units_Layer_3': 50}. Best is trial 95 with value: 15.903146219608724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.43 | sMAPE for Validation Set is: 20.31% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 45.90 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:17:22,518]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:17:30,009]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:17:33,451]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:17:38,130]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:18:05,846]\u001b[0m Trial 126 finished with value: 15.709307114218864 and parameters: {'n_hidden': 3, 'learning_rate': 0.002120409773771033, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19119585771036157, 'dropout_rate_Layer_2': 0.3718426942497514, 'dropout_rate_Layer_3': 0.3547661154958067, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002364242167592784, 'l1_Layer_2': 1.6264891165502916e-05, 'l1_Layer_3': 0.0013737082770634878, 'n_units_Layer_1': 135, 'n_units_Layer_2': 125, 'n_units_Layer_3': 205}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.71 | sMAPE for Validation Set is: 18.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 45.17 | sMAPE for Test Set is: 17.75% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:18:14,969]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:18:18,896]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:18:22,802]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:18:27,249]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:18:45,526]\u001b[0m Trial 122 finished with value: 18.22540225800633 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005342124327299528, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2545272137489467, 'dropout_rate_Layer_2': 0.21540459820799976, 'dropout_rate_Layer_3': 0.11465706522629086, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03079518838899418, 'l1_Layer_2': 0.017492029106705335, 'l1_Layer_3': 2.9793871765861313e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 75, 'n_units_Layer_3': 220}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.23 | sMAPE for Validation Set is: 20.97% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 50.81 | sMAPE for Test Set is: 20.05% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:19:06,392]\u001b[0m Trial 109 finished with value: 17.044821751965713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014112672953001195, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10834572275555275, 'dropout_rate_Layer_2': 0.14391004554073183, 'dropout_rate_Layer_3': 0.1307984096765881, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03528656373406855, 'l1_Layer_2': 0.022118758589952926, 'l1_Layer_3': 3.6189382922525206e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 75, 'n_units_Layer_3': 215}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.04 | sMAPE for Validation Set is: 19.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 46.94 | sMAPE for Test Set is: 18.39% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:19:09,666]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:19:13,133]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:19:17,359]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:19:22,958]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:19:27,713]\u001b[0m Trial 137 finished with value: 60.52201748729862 and parameters: {'n_hidden': 3, 'learning_rate': 0.012243306061078554, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3930910990896256, 'dropout_rate_Layer_2': 0.258442153816466, 'dropout_rate_Layer_3': 0.39565853921643807, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09837575756135547, 'l1_Layer_2': 0.0001762060407249572, 'l1_Layer_3': 0.0008056790034284721, 'n_units_Layer_1': 60, 'n_units_Layer_2': 60, 'n_units_Layer_3': 245}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.52 | sMAPE for Validation Set is: 57.71% | rMAE for Validation Set is: 2.21\n",
      "MAE for Test Set is: 216.47 | sMAPE for Test Set is: 116.52% | rMAE for Test Set is: 2.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:19:30,806]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:19:31,026]\u001b[0m Trial 127 finished with value: 15.840518983853373 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007889619437509089, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24569406234085855, 'dropout_rate_Layer_2': 0.10311895446606711, 'dropout_rate_Layer_3': 0.05097231111629248, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014976445491933486, 'l1_Layer_2': 0.0043194094398867, 'l1_Layer_3': 2.673147575488894e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 75, 'n_units_Layer_3': 270}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.84 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.58 | sMAPE for Test Set is: 18.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:19:34,042]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:19:36,540]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:19:38,767]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:19:41,639]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:19:43,777]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:19:50,549]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:19:57,611]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:00,067]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:00,279]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:09,429]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:11,498]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:20,199]\u001b[0m Trial 141 finished with value: 16.242099652503455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013532518106748402, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04572439864841957, 'dropout_rate_Layer_2': 0.33001427729143573, 'dropout_rate_Layer_3': 0.15029652711382904, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009948225364620962, 'l1_Layer_2': 8.203178796616008e-05, 'l1_Layer_3': 0.009699489296014652, 'n_units_Layer_1': 300, 'n_units_Layer_2': 265, 'n_units_Layer_3': 100}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.24 | sMAPE for Validation Set is: 19.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 42.86 | sMAPE for Test Set is: 17.21% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:20:25,385]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:29,146]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:29,498]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.65 | sMAPE for Validation Set is: 19.75% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 46.43 | sMAPE for Test Set is: 18.46% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:20:31,102]\u001b[0m Trial 148 finished with value: 16.649289392581423 and parameters: {'n_hidden': 3, 'learning_rate': 0.003973350448310458, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32359442562848173, 'dropout_rate_Layer_2': 0.3187536726410333, 'dropout_rate_Layer_3': 0.15512740413201087, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006567450622784422, 'l1_Layer_2': 4.6905660381939175e-05, 'l1_Layer_3': 0.0002479525732353969, 'n_units_Layer_1': 205, 'n_units_Layer_2': 165, 'n_units_Layer_3': 220}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:38,161]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:40,887]\u001b[0m Trial 152 finished with value: 58.18727720128313 and parameters: {'n_hidden': 4, 'learning_rate': 0.004666248758382274, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3168374310088413, 'dropout_rate_Layer_2': 0.11675180939698056, 'dropout_rate_Layer_3': 0.3801985478655735, 'dropout_rate_Layer_4': 0.034513860441201194, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006483074006782087, 'l1_Layer_2': 0.000319858839133434, 'l1_Layer_3': 0.002211832658500395, 'l1_Layer_4': 0.001193820717035823, 'n_units_Layer_1': 55, 'n_units_Layer_2': 215, 'n_units_Layer_3': 110, 'n_units_Layer_4': 245}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.19 | sMAPE for Validation Set is: 53.34% | rMAE for Validation Set is: 2.13\n",
      "MAE for Test Set is: 216.53 | sMAPE for Test Set is: 116.44% | rMAE for Test Set is: 2.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:20:43,980]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:47,746]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:47,932]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:48,268]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.44 | sMAPE for Validation Set is: 38.95% | rMAE for Validation Set is: 1.70\n",
      "MAE for Test Set is: 191.24 | sMAPE for Test Set is: 93.24% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:20:54,255]\u001b[0m Trial 156 finished with value: 46.443547152709264 and parameters: {'n_hidden': 3, 'learning_rate': 0.005310720453173905, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3394852001052512, 'dropout_rate_Layer_2': 0.11798785012088309, 'dropout_rate_Layer_3': 0.20831543241389266, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015604415743190748, 'l1_Layer_2': 8.547238950539671e-05, 'l1_Layer_3': 0.00021087915915239544, 'n_units_Layer_1': 295, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:58,428]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:20:58,963]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:03,644]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:06,825]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:07,836]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:09,566]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:12,670]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:16,366]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:16,540]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:17,051]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:25,605]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:26,251]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:26,390]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:33,932]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:37,810]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:39,047]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:21:45,840]\u001b[0m Trial 171 finished with value: 53.42884842819342 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013657254206080587, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2509387320043924, 'dropout_rate_Layer_2': 0.10874707955943447, 'dropout_rate_Layer_3': 0.12399908666032318, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011898327056637697, 'l1_Layer_2': 0.007924014253765141, 'l1_Layer_3': 0.0002115320959319498, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 195}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.43 | sMAPE for Validation Set is: 46.89% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 208.18 | sMAPE for Test Set is: 108.42% | rMAE for Test Set is: 2.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:21:53,585]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:01,165]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.05 | sMAPE for Validation Set is: 47.76% | rMAE for Validation Set is: 1.98\n",
      "MAE for Test Set is: 208.79 | sMAPE for Test Set is: 109.02% | rMAE for Test Set is: 2.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:22:02,727]\u001b[0m Trial 175 finished with value: 54.051828184687224 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014072091164199314, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23397783171206255, 'dropout_rate_Layer_2': 0.11343622974321106, 'dropout_rate_Layer_3': 0.0033169862771704195, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013734215654673815, 'l1_Layer_2': 0.012043969804903975, 'l1_Layer_3': 0.0002471175692433787, 'n_units_Layer_1': 300, 'n_units_Layer_2': 190, 'n_units_Layer_3': 195}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:06,579]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:10,483]\u001b[0m Trial 180 finished with value: 54.43314276256597 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011623084482461662, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2242478205946289, 'dropout_rate_Layer_2': 0.10668657840896478, 'dropout_rate_Layer_3': 0.12977033626578774, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.266379967337514e-05, 'l1_Layer_2': 0.010022667727826423, 'l1_Layer_3': 0.00018788225821728265, 'n_units_Layer_1': 295, 'n_units_Layer_2': 180, 'n_units_Layer_3': 200}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.43 | sMAPE for Validation Set is: 48.21% | rMAE for Validation Set is: 1.99\n",
      "MAE for Test Set is: 210.17 | sMAPE for Test Set is: 110.29% | rMAE for Test Set is: 2.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:22:11,129]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:13,268]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:16,828]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:21,805]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:22,691]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:26,447]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:30,066]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:30,618]\u001b[0m Trial 189 finished with value: 51.59305557590179 and parameters: {'n_hidden': 3, 'learning_rate': 0.004347410720960972, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26651674938295283, 'dropout_rate_Layer_2': 0.14761886037754718, 'dropout_rate_Layer_3': 0.2087415352738765, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1423740077797625e-05, 'l1_Layer_2': 0.0008289104237454135, 'l1_Layer_3': 1.3587989790436773e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 240, 'n_units_Layer_3': 255}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.59 | sMAPE for Validation Set is: 44.91% | rMAE for Validation Set is: 1.89\n",
      "MAE for Test Set is: 203.63 | sMAPE for Test Set is: 104.19% | rMAE for Test Set is: 2.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:22:35,604]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:39,780]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:40,270]\u001b[0m Trial 182 finished with value: 18.031769018199856 and parameters: {'n_hidden': 3, 'learning_rate': 0.002427623380431499, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2704723893820955, 'dropout_rate_Layer_2': 0.12117249501622036, 'dropout_rate_Layer_3': 0.02262056788320116, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005428419707160979, 'l1_Layer_2': 0.04396617889700211, 'l1_Layer_3': 9.734432315137919e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 50, 'n_units_Layer_3': 205}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.03 | sMAPE for Validation Set is: 20.59% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 51.15 | sMAPE for Test Set is: 19.83% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:22:40,351]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:43,917]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:48,103]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:50,738]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:54,195]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:22:55,088]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:00,263]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:02,262]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:06,471]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:08,889]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:12,076]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:13,528]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:18,557]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:24,842]\u001b[0m Trial 205 finished with value: 48.74041885659238 and parameters: {'n_hidden': 3, 'learning_rate': 0.004053977785490472, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.260037673496995, 'dropout_rate_Layer_2': 0.15595301496647976, 'dropout_rate_Layer_3': 0.20094328586016208, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0077294620730251e-05, 'l1_Layer_2': 0.0007428062073287218, 'l1_Layer_3': 1.0055659721095542e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 250, 'n_units_Layer_3': 250}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.74 | sMAPE for Validation Set is: 41.60% | rMAE for Validation Set is: 1.78\n",
      "MAE for Test Set is: 197.24 | sMAPE for Test Set is: 98.54% | rMAE for Test Set is: 2.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:23:32,455]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:33,049]\u001b[0m Trial 209 finished with value: 50.00247120394166 and parameters: {'n_hidden': 3, 'learning_rate': 0.004162632574184893, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25783134037482136, 'dropout_rate_Layer_2': 0.15086860577877906, 'dropout_rate_Layer_3': 0.20652439270586828, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1086069888458336e-05, 'l1_Layer_2': 0.0014361466281481603, 'l1_Layer_3': 1.142501099362135e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.00 | sMAPE for Validation Set is: 43.00% | rMAE for Validation Set is: 1.83\n",
      "MAE for Test Set is: 199.83 | sMAPE for Test Set is: 100.87% | rMAE for Test Set is: 2.75\n",
      "MAE for Validation Set is: 50.40 | sMAPE for Validation Set is: 43.04% | rMAE for Validation Set is: 1.84\n",
      "MAE for Test Set is: 201.52 | sMAPE for Test Set is: 102.17% | rMAE for Test Set is: 2.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:23:35,364]\u001b[0m Trial 210 finished with value: 50.39660207142821 and parameters: {'n_hidden': 3, 'learning_rate': 0.004230245449952138, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2689897257232468, 'dropout_rate_Layer_2': 0.14696495250222646, 'dropout_rate_Layer_3': 0.21860993859720113, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0466207869069435e-05, 'l1_Layer_2': 0.0007606359631547879, 'l1_Layer_3': 1.3873254728465156e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:37,628]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:39,014]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:43,826]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:49,639]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.60 | sMAPE for Validation Set is: 19.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 43.95 | sMAPE for Test Set is: 17.57% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:23:51,156]\u001b[0m Trial 198 finished with value: 16.604306359113483 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022321806114806936, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27325355921706257, 'dropout_rate_Layer_2': 0.07942996805987698, 'dropout_rate_Layer_3': 0.03577174610194733, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010328942536995266, 'l1_Layer_2': 0.04173737557030264, 'l1_Layer_3': 0.00010463563278928911, 'n_units_Layer_1': 160, 'n_units_Layer_2': 60, 'n_units_Layer_3': 200}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:23:57,057]\u001b[0m Trial 214 finished with value: 17.32869954032827 and parameters: {'n_hidden': 3, 'learning_rate': 0.01618201119503253, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04466558270030632, 'dropout_rate_Layer_2': 0.2826368145577074, 'dropout_rate_Layer_3': 0.2843534848839605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004566548628766881, 'l1_Layer_2': 3.504285744083367e-05, 'l1_Layer_3': 0.012914025570888199, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.33 | sMAPE for Validation Set is: 20.28% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.29 | sMAPE for Test Set is: 19.51% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:24:00,919]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:00,968]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:01,307]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:08,969]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:09,180]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:10,160]\u001b[0m Trial 218 finished with value: 17.23081420759027 and parameters: {'n_hidden': 3, 'learning_rate': 0.015573833344363727, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04539588778945254, 'dropout_rate_Layer_2': 0.264837151296771, 'dropout_rate_Layer_3': 0.1921082738589106, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003361471914542046, 'l1_Layer_2': 4.2063700108059776e-05, 'l1_Layer_3': 0.015284497747647336, 'n_units_Layer_1': 185, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.23 | sMAPE for Validation Set is: 20.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 51.08 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:24:14,095]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:16,826]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:20,457]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:23,183]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:25,657]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:26,337]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:27,332]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:33,124]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:33,826]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:41,233]\u001b[0m Trial 230 finished with value: 16.237307924385178 and parameters: {'n_hidden': 3, 'learning_rate': 0.007138633692331488, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16679581387984505, 'dropout_rate_Layer_2': 0.2311724798772044, 'dropout_rate_Layer_3': 0.2480292814689571, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023632371814446968, 'l1_Layer_2': 0.0006324268292903168, 'l1_Layer_3': 1.5620666384576588e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 265, 'n_units_Layer_3': 275}. Best is trial 126 with value: 15.709307114218864.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.24 | sMAPE for Validation Set is: 18.87% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 44.84 | sMAPE for Test Set is: 17.65% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:24:51,900]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:24:57,516]\u001b[0m Trial 236 finished with value: 15.474810648053273 and parameters: {'n_hidden': 3, 'learning_rate': 0.002562226141662096, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19289538161160044, 'dropout_rate_Layer_2': 0.09261143803710274, 'dropout_rate_Layer_3': 0.31520141986621325, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0757629287425162e-05, 'l1_Layer_2': 1.5983723113197226e-05, 'l1_Layer_3': 0.0018815099134166522, 'n_units_Layer_1': 185, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 236 with value: 15.474810648053273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.47 | sMAPE for Validation Set is: 18.06% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 46.83 | sMAPE for Test Set is: 18.23% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:24:57,936]\u001b[0m Trial 235 finished with value: 16.18809897427674 and parameters: {'n_hidden': 3, 'learning_rate': 0.003322994816310092, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20427696440204382, 'dropout_rate_Layer_2': 0.23815939993161586, 'dropout_rate_Layer_3': 0.22856002392313324, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028111566964022903, 'l1_Layer_2': 0.0005400572011659865, 'l1_Layer_3': 1.0688559353644122e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 265, 'n_units_Layer_3': 275}. Best is trial 236 with value: 15.474810648053273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.19 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 46.46 | sMAPE for Test Set is: 17.90% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:25:01,435]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:03,804]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:10,141]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:19,298]\u001b[0m Trial 240 finished with value: 15.176845728223329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022906671064388848, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2671111518483103, 'dropout_rate_Layer_2': 0.08583684664422864, 'dropout_rate_Layer_3': 0.3209969519842046, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0328441947470572e-05, 'l1_Layer_2': 1.5725358507078617e-05, 'l1_Layer_3': 0.0033977240380499724, 'n_units_Layer_1': 200, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.18 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 44.26 | sMAPE for Test Set is: 17.35% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:25:19,674]\u001b[0m Trial 231 finished with value: 17.3862207328807 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006373735658683406, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31138598595682687, 'dropout_rate_Layer_2': 0.053709134856158525, 'dropout_rate_Layer_3': 0.037366303986304944, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.502167423673244e-05, 'l1_Layer_2': 0.06655491969359209, 'l1_Layer_3': 1.0232413075410518e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.39 | sMAPE for Validation Set is: 19.52% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 43.98 | sMAPE for Test Set is: 17.60% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:25:25,854]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:26,214]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:32,206]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:32,352]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:32,649]\u001b[0m Trial 242 finished with value: 15.271934516341105 and parameters: {'n_hidden': 3, 'learning_rate': 0.002123878110127723, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20318093341148313, 'dropout_rate_Layer_2': 0.10126904445291118, 'dropout_rate_Layer_3': 0.32256598536705733, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3539367228337636e-05, 'l1_Layer_2': 2.9658959325093837e-05, 'l1_Layer_3': 0.0026933027196794925, 'n_units_Layer_1': 155, 'n_units_Layer_2': 70, 'n_units_Layer_3': 275}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.27 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 44.45 | sMAPE for Test Set is: 17.51% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:25:41,557]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:45,751]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:47,386]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:51,258]\u001b[0m Trial 247 finished with value: 53.99551770046048 and parameters: {'n_hidden': 3, 'learning_rate': 0.006490756394279269, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1851300829278955, 'dropout_rate_Layer_2': 0.2669296385194431, 'dropout_rate_Layer_3': 0.3377756642713573, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028893558814058244, 'l1_Layer_2': 2.5170349687810675e-05, 'l1_Layer_3': 0.00010083871908367028, 'n_units_Layer_1': 280, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.00 | sMAPE for Validation Set is: 48.85% | rMAE for Validation Set is: 1.98\n",
      "MAE for Test Set is: 199.99 | sMAPE for Test Set is: 100.25% | rMAE for Test Set is: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:25:54,118]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:56,992]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:25:58,687]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.44 | sMAPE for Validation Set is: 19.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 45.00 | sMAPE for Test Set is: 17.62% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:26:03,005]\u001b[0m Trial 239 finished with value: 16.43857815730949 and parameters: {'n_hidden': 3, 'learning_rate': 0.002126600993282775, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24019396749405755, 'dropout_rate_Layer_2': 0.047544087702262636, 'dropout_rate_Layer_3': 0.03614557177017625, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007037893941947163, 'l1_Layer_2': 0.023816582848279675, 'l1_Layer_3': 8.964255621280248e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:26:03,207]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:26:05,044]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:26:06,332]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:26:10,392]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:26:11,413]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:26:16,081]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:26:32,549]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:26:35,150]\u001b[0m Trial 259 finished with value: 17.289807140804978 and parameters: {'n_hidden': 3, 'learning_rate': 0.014498404710988774, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1570031151978337, 'dropout_rate_Layer_2': 0.2264827090886835, 'dropout_rate_Layer_3': 0.24691056317621995, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003124603757531465, 'l1_Layer_2': 0.00044427358673956933, 'l1_Layer_3': 2.679775217679451e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 105, 'n_units_Layer_3': 175}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.29 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 44.00 | sMAPE for Test Set is: 17.46% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:26:38,173]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:26:39,053]\u001b[0m Trial 261 finished with value: 17.740151304106472 and parameters: {'n_hidden': 3, 'learning_rate': 0.017924577314130826, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14803304910543796, 'dropout_rate_Layer_2': 0.221726620198264, 'dropout_rate_Layer_3': 0.2495260108242368, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023475947084624637, 'l1_Layer_2': 9.47831509945572e-05, 'l1_Layer_3': 2.4161716713073806e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.74 | sMAPE for Validation Set is: 20.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.68 | sMAPE for Test Set is: 19.30% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:26:40,380]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:26:41,519]\u001b[0m Trial 263 finished with value: 18.217865993559247 and parameters: {'n_hidden': 3, 'learning_rate': 0.01631589747930614, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1569315091662656, 'dropout_rate_Layer_2': 0.21386245632709955, 'dropout_rate_Layer_3': 0.24103047598970267, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023228425511065648, 'l1_Layer_2': 0.00042649008868077737, 'l1_Layer_3': 4.293478943694818e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.22 | sMAPE for Validation Set is: 20.09% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 47.64 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:26:47,007]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:26:58,808]\u001b[0m Trial 267 finished with value: 15.833657981616824 and parameters: {'n_hidden': 3, 'learning_rate': 0.007861221076780714, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.055728269434789104, 'dropout_rate_Layer_2': 0.32464194459186546, 'dropout_rate_Layer_3': 0.05001587734020266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07693315443930289, 'l1_Layer_2': 7.376976245638739e-05, 'l1_Layer_3': 0.00028844362130907357, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 65}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.83 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 43.04 | sMAPE for Test Set is: 17.19% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:27:08,435]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:12,616]\u001b[0m Trial 266 finished with value: 17.95954744570304 and parameters: {'n_hidden': 3, 'learning_rate': 0.015356811344979708, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1499995899010141, 'dropout_rate_Layer_2': 0.29760577912596536, 'dropout_rate_Layer_3': 0.24410690354225462, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003459104831054021, 'l1_Layer_2': 0.00041434146507521427, 'l1_Layer_3': 2.520091473294823e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 300, 'n_units_Layer_3': 170}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.96 | sMAPE for Validation Set is: 19.61% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.05 | sMAPE for Test Set is: 18.26% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:27:14,525]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:18,195]\u001b[0m Trial 268 finished with value: 16.793659036448105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025079476515126684, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2825091057514199, 'dropout_rate_Layer_2': 0.04920491569088822, 'dropout_rate_Layer_3': 0.05858684683105608, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6885258010889575e-05, 'l1_Layer_2': 0.030469683125662325, 'l1_Layer_3': 0.00014071176631101455, 'n_units_Layer_1': 155, 'n_units_Layer_2': 125, 'n_units_Layer_3': 220}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.79 | sMAPE for Validation Set is: 18.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 47.82 | sMAPE for Test Set is: 18.66% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:27:18,651]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:19,445]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:24,280]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:27,093]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:27,160]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:35,978]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:40,500]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:43,388]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.75 | sMAPE for Validation Set is: 21.91% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 52.47 | sMAPE for Test Set is: 21.16% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:27:45,086]\u001b[0m Trial 277 finished with value: 19.748385265313047 and parameters: {'n_hidden': 3, 'learning_rate': 0.00886131034856606, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.156982770456368, 'dropout_rate_Layer_2': 0.3170400925899514, 'dropout_rate_Layer_3': 0.04859357428874728, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08954368230677232, 'l1_Layer_2': 0.000790370596070931, 'l1_Layer_3': 0.0001821003685648004, 'n_units_Layer_1': 235, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:46,717]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:51,745]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:56,203]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:27:56,822]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:02,701]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:09,172]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:13,241]\u001b[0m Trial 278 finished with value: 17.035478518062465 and parameters: {'n_hidden': 3, 'learning_rate': 0.03652329917683913, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11976049505337238, 'dropout_rate_Layer_2': 0.22906990851197692, 'dropout_rate_Layer_3': 0.27294804900823844, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.063369303305875e-05, 'l1_Layer_2': 0.00011547903655355745, 'l1_Layer_3': 1.9950116573189348e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 215, 'n_units_Layer_3': 135}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.04 | sMAPE for Validation Set is: 19.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 43.51 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:28:15,858]\u001b[0m Trial 285 finished with value: 16.829608268213892 and parameters: {'n_hidden': 3, 'learning_rate': 0.03601841765573823, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12271500440674978, 'dropout_rate_Layer_2': 0.23720895149095553, 'dropout_rate_Layer_3': 0.31061802996863874, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.23193538601799e-05, 'l1_Layer_2': 0.00011874344626120086, 'l1_Layer_3': 1.8615661754721395e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 140}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.83 | sMAPE for Validation Set is: 19.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 44.02 | sMAPE for Test Set is: 17.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:28:19,526]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:19,670]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:27,433]\u001b[0m Trial 287 finished with value: 16.866091569926265 and parameters: {'n_hidden': 3, 'learning_rate': 0.033585444276563216, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12108535516107356, 'dropout_rate_Layer_2': 0.2325237167702568, 'dropout_rate_Layer_3': 0.2751183099818109, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.406666478612628e-05, 'l1_Layer_2': 0.0001096090340911086, 'l1_Layer_3': 1.9078503086674593e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 215, 'n_units_Layer_3': 140}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.87 | sMAPE for Validation Set is: 19.16% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 46.96 | sMAPE for Test Set is: 18.41% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:28:30,900]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:34,864]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:35,487]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:39,372]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:39,609]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:46,131]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:49,495]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:55,679]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:55,927]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:28:58,544]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:29:00,767]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:29:01,472]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:29:27,491]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:29:35,570]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:29:40,842]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:29:44,048]\u001b[0m Trial 304 finished with value: 16.36570037760992 and parameters: {'n_hidden': 3, 'learning_rate': 0.032630121765480094, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006040445351592608, 'dropout_rate_Layer_2': 0.24588934471091392, 'dropout_rate_Layer_3': 0.2763657946204575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022137650044458234, 'l1_Layer_2': 0.0001335354355571789, 'l1_Layer_3': 2.0142524953335353e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.37 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 42.72 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:29:49,514]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.26 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 46.08 | sMAPE for Test Set is: 18.09% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:29:52,104]\u001b[0m Trial 306 finished with value: 16.258552965514042 and parameters: {'n_hidden': 3, 'learning_rate': 0.001560595903465869, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24804406419047914, 'dropout_rate_Layer_2': 0.15218728215678423, 'dropout_rate_Layer_3': 0.045881267192976596, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005094287609852818, 'l1_Layer_2': 0.014674022291122319, 'l1_Layer_3': 0.00018123872721711635, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 225}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:29:54,458]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:29:57,682]\u001b[0m Trial 305 finished with value: 16.532449657086776 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013743782939627882, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24615211979094612, 'dropout_rate_Layer_2': 0.10736189074607154, 'dropout_rate_Layer_3': 0.023175468718739253, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023608714118326687, 'l1_Layer_2': 0.013649259481377702, 'l1_Layer_3': 0.00020080775006395255, 'n_units_Layer_1': 170, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.53 | sMAPE for Validation Set is: 18.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 42.12 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:29:58,537]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:03,677]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:04,023]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:08,070]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:12,078]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:15,553]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:16,684]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:21,961]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:24,872]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:27,898]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:28,044]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:34,855]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:43,222]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:43,447]\u001b[0m Trial 319 finished with value: 15.746501306297617 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030846868903029985, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2762053989896461, 'dropout_rate_Layer_2': 0.022191828088865287, 'dropout_rate_Layer_3': 0.14973856453065384, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.202598228150418e-05, 'l1_Layer_2': 0.0020149149748243168, 'l1_Layer_3': 0.024464334732926477, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 205}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.75 | sMAPE for Validation Set is: 18.18% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.28 | sMAPE for Test Set is: 17.99% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:30:48,964]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:53,053]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:55,417]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:58,580]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:59,125]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:30:59,589]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:07,270]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:07,430]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:07,557]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:14,029]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:14,046]\u001b[0m Trial 330 finished with value: 16.229016147059436 and parameters: {'n_hidden': 3, 'learning_rate': 0.004264517280788918, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2774300366820367, 'dropout_rate_Layer_2': 0.24647718433582755, 'dropout_rate_Layer_3': 0.32701773562993264, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002709055088669525, 'l1_Layer_2': 0.0022182146977105127, 'l1_Layer_3': 0.028654867187739054, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 220}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.23 | sMAPE for Validation Set is: 18.89% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 45.40 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:31:16,191]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:21,499]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:23,973]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:26,106]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:30,962]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:35,080]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:36,543]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:41,859]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:48,027]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:51,560]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:31:51,642]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:09,280]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:09,882]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.22 | sMAPE for Validation Set is: 19.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 44.60 | sMAPE for Test Set is: 18.00% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:32:11,676]\u001b[0m Trial 341 finished with value: 17.223384749973732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012714060328798801, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26139744938153947, 'dropout_rate_Layer_2': 0.1620395071584469, 'dropout_rate_Layer_3': 0.035664578468642696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00292706291284325, 'l1_Layer_2': 0.05158131143743624, 'l1_Layer_3': 0.0003300076279797631, 'n_units_Layer_1': 145, 'n_units_Layer_2': 80, 'n_units_Layer_3': 230}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:14,457]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:18,677]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:22,843]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:23,114]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:23,373]\u001b[0m Trial 348 finished with value: 16.555183106045927 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012400720803774903, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24903465049446682, 'dropout_rate_Layer_2': 0.16150240855892228, 'dropout_rate_Layer_3': 0.2629670794544315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001730171227985733, 'l1_Layer_2': 0.03402127921451717, 'l1_Layer_3': 1.3517390771194328e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 80, 'n_units_Layer_3': 230}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.56 | sMAPE for Validation Set is: 19.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 44.14 | sMAPE for Test Set is: 17.59% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:32:31,292]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:34,979]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:40,643]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:40,794]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:47,369]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:48,852]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:52,627]\u001b[0m Trial 359 finished with value: 16.34867115273822 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014389467794719592, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023271541320094485, 'dropout_rate_Layer_2': 0.37439708758242246, 'dropout_rate_Layer_3': 0.02225650032601951, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02720593716782438, 'l1_Layer_2': 2.3461561993716034e-05, 'l1_Layer_3': 0.0015544978188384313, 'n_units_Layer_1': 280, 'n_units_Layer_2': 250, 'n_units_Layer_3': 60}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.35 | sMAPE for Validation Set is: 19.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 43.92 | sMAPE for Test Set is: 17.66% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:32:54,825]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:32:56,048]\u001b[0m Trial 357 finished with value: 20.19539973695851 and parameters: {'n_hidden': 3, 'learning_rate': 0.008419017873972196, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047676746772379805, 'dropout_rate_Layer_2': 0.3131909542603558, 'dropout_rate_Layer_3': 0.298721401189885, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01648431695528037, 'l1_Layer_2': 0.00034569498788122264, 'l1_Layer_3': 1.0261560039512035e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 195, 'n_units_Layer_3': 100}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.20 | sMAPE for Validation Set is: 21.81% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 54.24 | sMAPE for Test Set is: 21.70% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:32:56,231]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:00,586]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:06,568]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:06,908]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:07,403]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:12,114]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:14,647]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:16,063]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:17,213]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:24,111]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:24,703]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:24,864]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:29,770]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:33,274]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:33,896]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:38,861]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:42,392]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:48,329]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:51,571]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:56,816]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:57,529]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:57,927]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:33:59,916]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:00,778]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:05,947]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:10,196]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:11,589]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:12,999]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:17,197]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:17,956]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:18,183]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:18,709]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:27,876]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:28,173]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:28,266]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:38,145]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:38,320]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:44,194]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:44,847]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:46,889]\u001b[0m Trial 398 finished with value: 17.155973674309763 and parameters: {'n_hidden': 3, 'learning_rate': 0.034668516767634265, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13090628974915425, 'dropout_rate_Layer_2': 0.23281206107770858, 'dropout_rate_Layer_3': 0.22898734510782412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.50630872947884e-05, 'l1_Layer_2': 0.00012886230027928127, 'l1_Layer_3': 3.380146559378757e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 170, 'n_units_Layer_3': 160}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.16 | sMAPE for Validation Set is: 19.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 45.68 | sMAPE for Test Set is: 18.04% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:34:49,530]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:54,450]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:54,608]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:59,247]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:34:59,821]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:00,445]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:07,794]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:10,537]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:14,286]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:16,785]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:19,822]\u001b[0m Trial 411 finished with value: 15.245650180789122 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020518948750784306, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060683188411399275, 'dropout_rate_Layer_2': 0.24588316291061532, 'dropout_rate_Layer_3': 0.06620263507811515, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.835172910993542e-05, 'l1_Layer_2': 2.5980077547426002e-05, 'l1_Layer_3': 0.00020707259057385806, 'n_units_Layer_1': 165, 'n_units_Layer_2': 260, 'n_units_Layer_3': 65}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.25 | sMAPE for Validation Set is: 17.81% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 42.60 | sMAPE for Test Set is: 16.94% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:35:21,864]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:25,166]\u001b[0m Trial 415 finished with value: 18.134447004186818 and parameters: {'n_hidden': 3, 'learning_rate': 0.00210685977153155, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056787384523716816, 'dropout_rate_Layer_2': 0.36662148013544393, 'dropout_rate_Layer_3': 0.07713185582332467, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.061470737876084945, 'l1_Layer_2': 2.5881435986901606e-05, 'l1_Layer_3': 0.0026361392439298065, 'n_units_Layer_1': 160, 'n_units_Layer_2': 260, 'n_units_Layer_3': 70}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.13 | sMAPE for Validation Set is: 20.68% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.84 | sMAPE for Test Set is: 18.99% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:35:27,987]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:30,538]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:33,308]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:33,810]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:36,023]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:40,217]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:43,925]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:44,382]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:45,221]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:48,954]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:52,801]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:57,329]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:57,555]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:35:57,946]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:05,708]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:08,319]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:11,270]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:12,541]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:13,138]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:15,357]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:18,245]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:23,811]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:25,469]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:27,707]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:33,160]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:33,481]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:34,444]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:40,055]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.98 | sMAPE for Validation Set is: 18.36% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 44.63 | sMAPE for Test Set is: 17.53% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:36:40,913]\u001b[0m Trial 439 finished with value: 15.984694613278245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041871475865793316, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24931679817125804, 'dropout_rate_Layer_2': 0.022348475926901798, 'dropout_rate_Layer_3': 0.12527899061580902, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023670435020885328, 'l1_Layer_2': 2.3487593256630894e-05, 'l1_Layer_3': 0.0005642023382124088, 'n_units_Layer_1': 195, 'n_units_Layer_2': 145, 'n_units_Layer_3': 285}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:41,741]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:42,021]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:49,931]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:51,087]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:53,825]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:58,642]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:59,224]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:59,519]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:36:59,535]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:08,720]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:08,865]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:10,027]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:10,193]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:14,431]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:16,030]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:18,444]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:23,233]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:25,581]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:31,101]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:31,915]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:32,726]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:33,229]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:39,472]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:42,262]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:43,335]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:43,927]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:44,382]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:51,417]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:52,924]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:37:56,245]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:00,488]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:03,169]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:06,413]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:06,683]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:06,827]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:15,362]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:15,926]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:19,870]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:19,924]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:20,594]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:25,367]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:28,106]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:29,689]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:30,406]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:32,990]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:40,378]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:40,530]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:41,679]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:49,395]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:49,983]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:55,548]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:38:59,050]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.41 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 44.93 | sMAPE for Test Set is: 17.50% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:39:01,110]\u001b[0m Trial 492 finished with value: 15.407911217907511 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008323079848690646, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11898537360541996, 'dropout_rate_Layer_2': 0.27536865489973517, 'dropout_rate_Layer_3': 0.2828702884161397, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.428528908029589e-05, 'l1_Layer_2': 0.00026677559725945513, 'l1_Layer_3': 1.3678789996264149e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:05,610]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:05,800]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:11,214]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:23,712]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:28,953]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:32,823]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:36,567]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:36,803]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:41,391]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:43,168]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:46,922]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:39:56,924]\u001b[0m Trial 506 finished with value: 15.740498595570719 and parameters: {'n_hidden': 3, 'learning_rate': 0.000705520452716093, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16831164338094762, 'dropout_rate_Layer_2': 0.36391888320642607, 'dropout_rate_Layer_3': 0.08054417045994454, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003785206415610309, 'l1_Layer_2': 0.0002604670606573925, 'l1_Layer_3': 1.2778577360230204e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.74 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.44 | sMAPE for Test Set is: 17.93% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:40:00,549]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:01,203]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:02,013]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:08,901]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:10,476]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:11,689]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:17,432]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:22,433]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:22,692]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:28,694]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:29,447]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:36,482]\u001b[0m Trial 513 finished with value: 16.06245424444671 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009523867339923753, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2635109337162777, 'dropout_rate_Layer_2': 0.07820979246470826, 'dropout_rate_Layer_3': 0.02124976718415788, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4003850791764383e-05, 'l1_Layer_2': 0.032086546182274314, 'l1_Layer_3': 3.3314899915029634e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.06 | sMAPE for Validation Set is: 18.68% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 42.88 | sMAPE for Test Set is: 17.08% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:40:40,573]\u001b[0m Trial 520 finished with value: 15.739988843670993 and parameters: {'n_hidden': 3, 'learning_rate': 0.004475202574558354, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021060538596316063, 'dropout_rate_Layer_2': 0.2530834920074412, 'dropout_rate_Layer_3': 0.11746682421361973, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.098141423637375e-05, 'l1_Layer_2': 6.576951988484881e-05, 'l1_Layer_3': 0.0002736745673661203, 'n_units_Layer_1': 100, 'n_units_Layer_2': 65, 'n_units_Layer_3': 95}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.74 | sMAPE for Validation Set is: 18.32% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 46.51 | sMAPE for Test Set is: 17.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:40:40,984]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:44,257]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:48,134]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:52,419]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:55,955]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:40:56,843]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:01,316]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:01,847]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:11,734]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:15,151]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:15,300]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:21,384]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:21,873]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:30,144]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:34,504]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:38,326]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:38,609]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.11 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 45.13 | sMAPE for Test Set is: 17.77% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:41:43,672]\u001b[0m Trial 530 finished with value: 16.109422425779773 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011001980458081985, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23689352288824594, 'dropout_rate_Layer_2': 0.07105239111907409, 'dropout_rate_Layer_3': 0.014450131761284898, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.514405388157417e-05, 'l1_Layer_2': 0.02986517019370746, 'l1_Layer_3': 2.5573320342508932e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:46,555]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:49,645]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:50,449]\u001b[0m Trial 532 finished with value: 16.333765943782954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011176554370706659, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29279143557726955, 'dropout_rate_Layer_2': 0.06957915262395263, 'dropout_rate_Layer_3': 0.04359099463312838, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.455445414684193e-05, 'l1_Layer_2': 0.038746911524208616, 'l1_Layer_3': 3.239800584636437e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.33 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 45.68 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:41:57,398]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:41:58,776]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:04,664]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:05,287]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:10,714]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:18,591]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:22,215]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:28,228]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:33,537]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:38,064]\u001b[0m Trial 550 finished with value: 15.453143401119297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005828443986635132, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18885774741581884, 'dropout_rate_Layer_2': 0.27908355005494584, 'dropout_rate_Layer_3': 0.1016975129843867, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008187874809458606, 'l1_Layer_2': 0.0005292646560759113, 'l1_Layer_3': 1.3909686717134336e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.45 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 44.30 | sMAPE for Test Set is: 17.35% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:42:38,500]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:43,963]\u001b[0m Trial 545 finished with value: 15.556214235392806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006105356239160846, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09407500384595067, 'dropout_rate_Layer_2': 0.27590321392625927, 'dropout_rate_Layer_3': 0.0861636654205029, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0030553994080938242, 'l1_Layer_2': 6.929284401297793e-05, 'l1_Layer_3': 1.2770388864074658e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.56 | sMAPE for Validation Set is: 17.88% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 44.60 | sMAPE for Test Set is: 17.49% | rMAE for Test Set is: 0.61\n",
      "MAE for Validation Set is: 15.55 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 42.53 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:42:43,978]\u001b[0m Trial 553 finished with value: 15.553598381256478 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005767626544670173, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10049296114722406, 'dropout_rate_Layer_2': 0.3032098702269382, 'dropout_rate_Layer_3': 0.16130085201000705, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.391773813246149e-05, 'l1_Layer_2': 0.0005288059093402133, 'l1_Layer_3': 1.2373991000428572e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 250, 'n_units_Layer_3': 290}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:48,081]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:53,748]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:55,227]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:55,587]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:42:56,634]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:02,518]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:06,663]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:12,222]\u001b[0m Trial 566 finished with value: 15.824798442229657 and parameters: {'n_hidden': 3, 'learning_rate': 0.005954725007120604, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07686715941807408, 'dropout_rate_Layer_2': 0.2615898059282217, 'dropout_rate_Layer_3': 0.08309807878911679, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.510480249678713e-05, 'l1_Layer_2': 0.00010268795811647731, 'l1_Layer_3': 0.00026287974590537207, 'n_units_Layer_1': 245, 'n_units_Layer_2': 100, 'n_units_Layer_3': 80}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.82 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 45.05 | sMAPE for Test Set is: 17.66% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:43:15,954]\u001b[0m Trial 564 finished with value: 15.372108306964684 and parameters: {'n_hidden': 3, 'learning_rate': 0.005381977973509197, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017239561614094262, 'dropout_rate_Layer_2': 0.2577428087223067, 'dropout_rate_Layer_3': 0.15043865666875722, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.2278901683852385e-05, 'l1_Layer_2': 9.741726899825876e-05, 'l1_Layer_3': 0.00022160316905934314, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 80}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:15,985]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.37 | sMAPE for Validation Set is: 17.90% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 42.48 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:43:23,133]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:26,002]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:28,780]\u001b[0m Trial 565 finished with value: 15.371957227575491 and parameters: {'n_hidden': 3, 'learning_rate': 0.005982272771930488, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01618564262919548, 'dropout_rate_Layer_2': 0.25969769072811927, 'dropout_rate_Layer_3': 0.15381347734941075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.80583010583502e-05, 'l1_Layer_2': 0.003016161741073821, 'l1_Layer_3': 0.00027350925962056264, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 80}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.37 | sMAPE for Validation Set is: 17.93% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 41.66 | sMAPE for Test Set is: 16.63% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:43:29,749]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:31,170]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:37,784]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:38,892]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:41,962]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:47,555]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:50,018]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:50,295]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:55,307]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:56,018]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:56,785]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:43:56,847]\u001b[0m Trial 577 finished with value: 15.866224959282901 and parameters: {'n_hidden': 3, 'learning_rate': 0.005557222193779963, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.083707954788078, 'dropout_rate_Layer_2': 0.21605190848188888, 'dropout_rate_Layer_3': 0.10782778040773239, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.028936620006731e-05, 'l1_Layer_2': 0.0019978383479902885, 'l1_Layer_3': 0.0003952301921370535, 'n_units_Layer_1': 65, 'n_units_Layer_2': 50, 'n_units_Layer_3': 85}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.87 | sMAPE for Validation Set is: 18.45% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 41.95 | sMAPE for Test Set is: 16.62% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:44:05,669]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:06,157]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:08,338]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:10,712]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:16,016]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:19,936]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:23,336]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:25,936]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:30,047]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:33,866]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:34,010]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:39,795]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:41,650]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:44,405]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:47,581]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:48,831]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:51,877]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:52,609]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:54,432]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:57,886]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:44:59,636]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:00,278]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:05,776]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:11,069]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:14,448]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:15,720]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:16,457]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.61 | sMAPE for Validation Set is: 18.34% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 41.70 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:45:18,981]\u001b[0m Trial 606 finished with value: 15.605557566426098 and parameters: {'n_hidden': 3, 'learning_rate': 0.008219325187560304, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05247235168682871, 'dropout_rate_Layer_2': 0.24592033265351865, 'dropout_rate_Layer_3': 0.17054657915532162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.325925287736261e-05, 'l1_Layer_2': 0.0002260476846100118, 'l1_Layer_3': 0.00063505703112864, 'n_units_Layer_1': 75, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:24,059]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:24,124]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:30,557]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:31,210]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:31,526]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:36,784]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:40,463]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:44,050]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:44,459]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:47,516]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:51,326]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:56,248]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:45:59,233]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:01,412]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:03,721]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:08,060]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:12,241]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:17,324]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:26,795]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:30,713]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:33,387]\u001b[0m Trial 626 finished with value: 15.685153798306677 and parameters: {'n_hidden': 3, 'learning_rate': 0.000829755574852615, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0349813673883308, 'dropout_rate_Layer_2': 0.32495311989422043, 'dropout_rate_Layer_3': 0.052716822141662144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024774637095546187, 'l1_Layer_2': 0.0010403584220922857, 'l1_Layer_3': 4.4369781091657935e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.69 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 43.96 | sMAPE for Test Set is: 17.36% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:46:38,063]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:38,283]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:43,923]\u001b[0m Trial 633 finished with value: 15.982877741286208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008353932683790281, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1401232426654918, 'dropout_rate_Layer_2': 0.2738394785266718, 'dropout_rate_Layer_3': 0.04793765971787022, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022858666777829163, 'l1_Layer_2': 0.003817451718934896, 'l1_Layer_3': 4.075586770821655e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.98 | sMAPE for Validation Set is: 18.21% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 42.26 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:46:49,520]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:52,905]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:46:55,080]\u001b[0m Trial 630 finished with value: 15.797995624644352 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008473372194618627, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03445521561203322, 'dropout_rate_Layer_2': 0.27131646116156316, 'dropout_rate_Layer_3': 0.020604978459760857, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002485026685804992, 'l1_Layer_2': 0.0010586345570045524, 'l1_Layer_3': 4.0213906642184833e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.80 | sMAPE for Validation Set is: 18.41% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 44.74 | sMAPE for Test Set is: 17.45% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:47:01,778]\u001b[0m Trial 639 finished with value: 15.46557734637731 and parameters: {'n_hidden': 3, 'learning_rate': 0.004172693196319652, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27166828317033115, 'dropout_rate_Layer_2': 5.635574648765328e-05, 'dropout_rate_Layer_3': 0.3023060048471986, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0332324702431873e-05, 'l1_Layer_2': 2.617671926957326e-05, 'l1_Layer_3': 0.0010709102819982314, 'n_units_Layer_1': 200, 'n_units_Layer_2': 285, 'n_units_Layer_3': 195}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.47 | sMAPE for Validation Set is: 17.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 45.18 | sMAPE for Test Set is: 17.43% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:47:05,890]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:47:11,623]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:47:15,250]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:47:19,344]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:47:19,777]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:47:20,902]\u001b[0m Trial 641 finished with value: 15.31435658811413 and parameters: {'n_hidden': 3, 'learning_rate': 0.004071925764134486, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07866975378926586, 'dropout_rate_Layer_2': 0.22096323479973567, 'dropout_rate_Layer_3': 0.1671310314622702, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017655954601901547, 'l1_Layer_2': 0.00011305799915923652, 'l1_Layer_3': 0.0004619063292245269, 'n_units_Layer_1': 95, 'n_units_Layer_2': 65, 'n_units_Layer_3': 50}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.31 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 41.71 | sMAPE for Test Set is: 16.61% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:47:28,995]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:47:29,380]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:47:34,713]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:47:38,446]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:47:38,600]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:47:48,827]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:47:58,896]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:02,611]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:08,135]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:08,336]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:17,085]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:17,220]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.28 | sMAPE for Validation Set is: 18.70% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 46.28 | sMAPE for Test Set is: 18.01% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:48:20,049]\u001b[0m Trial 645 finished with value: 16.2840145687906 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017308501193937127, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2932741459055983, 'dropout_rate_Layer_2': 0.169322632612441, 'dropout_rate_Layer_3': 0.022668108755587682, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.582224817475609e-05, 'l1_Layer_2': 0.00047110072877916615, 'l1_Layer_3': 2.87992344767278e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 75, 'n_units_Layer_3': 170}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:24,602]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:26,070]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:29,239]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:32,946]\u001b[0m Trial 650 finished with value: 16.37197409346561 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019391298840404846, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09525285784302581, 'dropout_rate_Layer_2': 0.12152025282325221, 'dropout_rate_Layer_3': 0.07258734128117689, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014926032606403323, 'l1_Layer_2': 0.03237997219421081, 'l1_Layer_3': 0.00021196847711102263, 'n_units_Layer_1': 160, 'n_units_Layer_2': 215, 'n_units_Layer_3': 245}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.37 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 43.87 | sMAPE for Test Set is: 17.46% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:48:34,879]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:35,483]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:36,911]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:37,015]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:43,688]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:46,784]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:50,827]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:52,904]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:48:56,251]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:01,699]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:06,824]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:10,927]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:11,549]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:12,058]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:20,630]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:22,831]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:27,438]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:27,765]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.52 | sMAPE for Validation Set is: 17.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 43.01 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:49:28,007]\u001b[0m Trial 670 finished with value: 15.52491489575562 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009571651144503944, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11023794658531087, 'dropout_rate_Layer_2': 0.26362947281158533, 'dropout_rate_Layer_3': 0.017700962674138423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002615023449023502, 'l1_Layer_2': 0.0031822527601368176, 'l1_Layer_3': 4.777407551633132e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:37,941]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:41,188]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:41,614]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:45,953]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:47,130]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:50,478]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:51,106]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:56,688]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:49:57,901]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:03,844]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:10,241]\u001b[0m Trial 681 finished with value: 15.459519781360413 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009888601442264015, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11117473908474132, 'dropout_rate_Layer_2': 0.2630203509744702, 'dropout_rate_Layer_3': 0.017962657854590076, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001899746434088855, 'l1_Layer_2': 0.0035247985808412865, 'l1_Layer_3': 2.453819957929631e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.46 | sMAPE for Validation Set is: 17.82% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 42.50 | sMAPE for Test Set is: 16.92% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:50:21,402]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:22,160]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:26,871]\u001b[0m Trial 690 finished with value: 18.91458264380194 and parameters: {'n_hidden': 3, 'learning_rate': 0.022285011928893466, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32379309676277707, 'dropout_rate_Layer_2': 0.2482665558411555, 'dropout_rate_Layer_3': 0.1576464134426074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7173087298347963e-05, 'l1_Layer_2': 0.00022159558334977592, 'l1_Layer_3': 0.0009403445709082362, 'n_units_Layer_1': 70, 'n_units_Layer_2': 65, 'n_units_Layer_3': 50}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.91 | sMAPE for Validation Set is: 20.93% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 51.00 | sMAPE for Test Set is: 19.48% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:50:31,120]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:34,071]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:36,905]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:38,133]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:43,144]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:43,651]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:44,365]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:52,340]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:52,477]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:58,139]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:50:58,811]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:02,633]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:06,386]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:06,875]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:13,202]\u001b[0m Trial 705 finished with value: 15.861831664266532 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034104076816047933, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017897209109280138, 'dropout_rate_Layer_2': 0.3239836446450897, 'dropout_rate_Layer_3': 0.055761539457000436, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4684075525837634e-05, 'l1_Layer_2': 2.107920469056893e-05, 'l1_Layer_3': 0.011272149534950168, 'n_units_Layer_1': 205, 'n_units_Layer_2': 100, 'n_units_Layer_3': 200}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.86 | sMAPE for Validation Set is: 18.39% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 47.05 | sMAPE for Test Set is: 17.96% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:51:13,886]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:22,161]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:22,768]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:23,132]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:29,999]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:31,486]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:35,241]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:42,363]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:42,513]\u001b[0m Trial 717 finished with value: 15.62284433041649 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028184953950715808, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1794970166388341, 'dropout_rate_Layer_2': 0.27113713982028875, 'dropout_rate_Layer_3': 0.18358571026491644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010140711452389104, 'l1_Layer_2': 0.0001125538232719652, 'l1_Layer_3': 0.0001294075454767303, 'n_units_Layer_1': 120, 'n_units_Layer_2': 55, 'n_units_Layer_3': 90}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.62 | sMAPE for Validation Set is: 18.53% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 46.35 | sMAPE for Test Set is: 17.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:51:42,739]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:43,226]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:53,624]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:53,723]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:51:58,924]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:00,413]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:04,390]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:07,817]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:14,952]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:17,977]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:22,998]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:34,656]\u001b[0m Trial 732 finished with value: 16.037647060806304 and parameters: {'n_hidden': 3, 'learning_rate': 0.003511042757821812, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06509754332046708, 'dropout_rate_Layer_2': 0.32916098236700925, 'dropout_rate_Layer_3': 0.062011015301862205, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9778255628872117e-05, 'l1_Layer_2': 1.4206492871298119e-05, 'l1_Layer_3': 0.007887531142056923, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 215}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.04 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 51.08 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:52:37,321]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:39,272]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:41,754]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:47,814]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:50,880]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:53,610]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:52:56,544]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:00,511]\u001b[0m Trial 737 finished with value: 15.751663231800833 and parameters: {'n_hidden': 3, 'learning_rate': 0.007496870092860176, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19130370439381408, 'dropout_rate_Layer_2': 0.21718951523875055, 'dropout_rate_Layer_3': 0.21010563401564125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018502132837768542, 'l1_Layer_2': 0.00031142793464249087, 'l1_Layer_3': 8.180822934524822e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.75 | sMAPE for Validation Set is: 18.27% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 44.78 | sMAPE for Test Set is: 17.42% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:53:04,758]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:07,483]\u001b[0m Trial 724 finished with value: 17.908487841616793 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005858712173593307, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25483256114402747, 'dropout_rate_Layer_2': 0.20991825572214207, 'dropout_rate_Layer_3': 0.12581316244877588, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.019449372701869104, 'l1_Layer_2': 0.01640938459344036, 'l1_Layer_3': 2.986103597125863e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 85, 'n_units_Layer_3': 215}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.91 | sMAPE for Validation Set is: 20.71% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.02 | sMAPE for Test Set is: 19.55% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:53:10,456]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:11,931]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:12,665]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:20,879]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:25,865]\u001b[0m Trial 743 finished with value: 15.63864096583823 and parameters: {'n_hidden': 3, 'learning_rate': 0.004154401836573351, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08509059432348305, 'dropout_rate_Layer_2': 0.3241698968681189, 'dropout_rate_Layer_3': 0.05820484459201178, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.904910231148778e-05, 'l1_Layer_2': 1.4382962491970746e-05, 'l1_Layer_3': 0.009300072672034062, 'n_units_Layer_1': 200, 'n_units_Layer_2': 115, 'n_units_Layer_3': 215}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.64 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 50.21 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:53:27,057]\u001b[0m Trial 748 finished with value: 15.877958792334828 and parameters: {'n_hidden': 3, 'learning_rate': 0.004630189948206398, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03329129584411165, 'dropout_rate_Layer_2': 0.2943607551885722, 'dropout_rate_Layer_3': 0.18054071489553447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.8864684860456464e-05, 'l1_Layer_2': 0.0001324010947360234, 'l1_Layer_3': 0.0003357433955881431, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 90}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.88 | sMAPE for Validation Set is: 18.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 42.11 | sMAPE for Test Set is: 16.90% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:53:34,044]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:36,209]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:38,459]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:42,738]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:44,959]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:46,360]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:50,913]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:50,986]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:53:51,955]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:00,730]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:00,849]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:04,039]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:07,621]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:10,418]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:14,366]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:17,282]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:19,724]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:19,883]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:25,537]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:26,355]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:32,972]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:37,015]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:38,915]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:40,645]\u001b[0m Trial 769 finished with value: 15.437683832987284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023735874128317787, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1401168280384449, 'dropout_rate_Layer_2': 0.27504460288260096, 'dropout_rate_Layer_3': 0.11163377408675251, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.36906396396533e-05, 'l1_Layer_2': 3.975063541151495e-05, 'l1_Layer_3': 0.0006050629816791684, 'n_units_Layer_1': 65, 'n_units_Layer_2': 90, 'n_units_Layer_3': 110}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.44 | sMAPE for Validation Set is: 17.72% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 41.11 | sMAPE for Test Set is: 16.48% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:54:44,049]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:45,485]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:46,996]\u001b[0m Trial 764 finished with value: 15.67290383099622 and parameters: {'n_hidden': 3, 'learning_rate': 0.003168879165176266, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06976421037041773, 'dropout_rate_Layer_2': 0.3128153867439967, 'dropout_rate_Layer_3': 0.06476885860309552, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003332511973387302, 'l1_Layer_2': 1.2451045784405465e-05, 'l1_Layer_3': 0.009958078788582809, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 200}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.67 | sMAPE for Validation Set is: 18.25% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 47.16 | sMAPE for Test Set is: 18.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:54:53,950]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:54:56,258]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:00,493]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:03,480]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:06,412]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:10,682]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:14,772]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:15,650]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.42 | sMAPE for Validation Set is: 18.04% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 41.72 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:55:18,918]\u001b[0m Trial 780 finished with value: 15.420508619114008 and parameters: {'n_hidden': 3, 'learning_rate': 0.002123966189473264, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21969449066744617, 'dropout_rate_Layer_2': 0.2235269038574236, 'dropout_rate_Layer_3': 0.20057798274472505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016797385459548173, 'l1_Layer_2': 3.693664879145116e-05, 'l1_Layer_3': 0.0008345379426088758, 'n_units_Layer_1': 75, 'n_units_Layer_2': 150, 'n_units_Layer_3': 75}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:19,768]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:21,037]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:29,263]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:32,130]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:32,462]\u001b[0m Trial 782 finished with value: 15.2146854744144 and parameters: {'n_hidden': 3, 'learning_rate': 0.002218659786480206, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17448913362993432, 'dropout_rate_Layer_2': 0.20205149219200888, 'dropout_rate_Layer_3': 0.20227235397318016, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026245040981429205, 'l1_Layer_2': 3.535349354928261e-05, 'l1_Layer_3': 0.0008273686507585582, 'n_units_Layer_1': 80, 'n_units_Layer_2': 145, 'n_units_Layer_3': 75}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.21 | sMAPE for Validation Set is: 17.74% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 42.07 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:55:35,191]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:36,906]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:38,648]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:47,262]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:48,595]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:54,417]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:55:56,809]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:01,203]\u001b[0m Trial 795 finished with value: 15.48543632462038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021482393960665096, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2095766982387643, 'dropout_rate_Layer_2': 0.11744035636599413, 'dropout_rate_Layer_3': 0.24391579745043698, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002478901272055574, 'l1_Layer_2': 3.5969826655989017e-05, 'l1_Layer_3': 0.0018937149414748927, 'n_units_Layer_1': 60, 'n_units_Layer_2': 145, 'n_units_Layer_3': 155}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.49 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 41.58 | sMAPE for Test Set is: 16.52% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:56:05,200]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:11,339]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:13,713]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:20,244]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:20,911]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:21,065]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:22,652]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:30,888]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:37,323]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:41,850]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:49,469]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:50,096]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:56:50,450]\u001b[0m Trial 807 finished with value: 15.76985540917022 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010822808432940788, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1639001568812745, 'dropout_rate_Layer_2': 0.22052541547427337, 'dropout_rate_Layer_3': 0.1375963539046965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015270641754136128, 'l1_Layer_2': 1.0277459546698761e-05, 'l1_Layer_3': 0.0008332725744448173, 'n_units_Layer_1': 80, 'n_units_Layer_2': 125, 'n_units_Layer_3': 185}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.77 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 41.49 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:57:00,384]\u001b[0m Trial 808 finished with value: 15.572526300868063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006453552249875012, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12453974018702318, 'dropout_rate_Layer_2': 0.27358036426523347, 'dropout_rate_Layer_3': 0.13043353610142622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.24771472783679e-05, 'l1_Layer_2': 0.0035670635727951504, 'l1_Layer_3': 1.605130964845037e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.57 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 42.59 | sMAPE for Test Set is: 16.97% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:57:00,641]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:00,810]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:01,125]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:13,155]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:17,264]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:20,910]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:24,655]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:24,880]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:25,118]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:32,215]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:33,829]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:38,940]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:39,685]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:43,126]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:43,819]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:44,752]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:52,348]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:57:56,174]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:00,181]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:00,755]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:07,683]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:11,681]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:11,938]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:18,458]\u001b[0m Trial 830 finished with value: 15.602921258493064 and parameters: {'n_hidden': 3, 'learning_rate': 0.00221720087385164, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20748036652167715, 'dropout_rate_Layer_2': 0.11097526866684189, 'dropout_rate_Layer_3': 0.24160749241983293, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002071741897756963, 'l1_Layer_2': 3.0615071456092526e-05, 'l1_Layer_3': 0.0018896197912421804, 'n_units_Layer_1': 60, 'n_units_Layer_2': 155, 'n_units_Layer_3': 145}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.60 | sMAPE for Validation Set is: 18.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 41.16 | sMAPE for Test Set is: 16.32% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:58:21,744]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:21,894]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:29,099]\u001b[0m Trial 827 finished with value: 16.525325369293242 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011379929103901378, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26372888354679824, 'dropout_rate_Layer_2': 0.17673617688575788, 'dropout_rate_Layer_3': 0.07142546157361503, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019356808531549696, 'l1_Layer_2': 0.02992020087415465, 'l1_Layer_3': 0.00010861425469090389, 'n_units_Layer_1': 220, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:29,241]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.53 | sMAPE for Validation Set is: 19.37% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 42.54 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 05:58:35,941]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:36,364]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:43,287]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:43,378]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:44,239]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:45,066]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:52,629]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:52,788]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:55,927]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:58:56,820]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:05,048]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:05,254]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:09,174]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:10,178]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:15,564]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:15,603]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:16,432]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:18,603]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:25,731]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:26,386]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:30,372]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:33,913]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:37,152]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:38,219]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:44,364]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:44,994]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:45,281]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 05:59:58,642]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:02,277]\u001b[0m Trial 860 finished with value: 15.780498037271657 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007141220593692495, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09176990734599733, 'dropout_rate_Layer_2': 0.2493497080239821, 'dropout_rate_Layer_3': 0.13850360750974372, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029838954435971628, 'l1_Layer_2': 0.00024852270549500735, 'l1_Layer_3': 1.9590934912965188e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.78 | sMAPE for Validation Set is: 18.36% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 45.61 | sMAPE for Test Set is: 17.64% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:00:03,776]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:04,803]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:10,708]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:11,248]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:11,440]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:19,814]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:23,611]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:27,502]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:27,664]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:27,934]\u001b[0m Trial 869 finished with value: 15.712969295965229 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005061518057171107, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09528024767405754, 'dropout_rate_Layer_2': 0.24801338520942595, 'dropout_rate_Layer_3': 0.14193038812189565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011343081430039963, 'l1_Layer_2': 0.00953686501390682, 'l1_Layer_3': 1.8328149484737425e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.71 | sMAPE for Validation Set is: 18.20% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 43.79 | sMAPE for Test Set is: 17.19% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:00:34,974]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:36,097]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:36,304]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:39,653]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:40,478]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:45,784]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:45,995]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:50,694]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:54,252]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:57,258]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:57,866]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:58,525]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:00:58,804]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:09,153]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:11,554]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:15,207]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:15,455]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:15,905]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:20,625]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:25,017]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:26,737]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:33,195]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:47,338]\u001b[0m Trial 903 finished with value: 15.902674255153544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034397672146992144, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.054783528253490546, 'dropout_rate_Layer_2': 0.34218874304274083, 'dropout_rate_Layer_3': 0.32185272705259516, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016862309966384447, 'l1_Layer_2': 1.3616850229771563e-05, 'l1_Layer_3': 0.007983024264816216, 'n_units_Layer_1': 140, 'n_units_Layer_2': 85, 'n_units_Layer_3': 190}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.90 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 45.49 | sMAPE for Test Set is: 17.55% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:01:50,734]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:50,875]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:01:56,983]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:04,153]\u001b[0m Trial 901 finished with value: 16.264112367390254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006580380546991428, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05635484280995963, 'dropout_rate_Layer_2': 0.2474592382818657, 'dropout_rate_Layer_3': 0.09851675524056916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018448408936184858, 'l1_Layer_2': 0.018688891620750755, 'l1_Layer_3': 2.9385328904933292e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 270}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.26 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 44.10 | sMAPE for Test Set is: 17.35% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:02:12,933]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:13,414]\u001b[0m Trial 907 finished with value: 16.473147486690255 and parameters: {'n_hidden': 4, 'learning_rate': 0.004238884460416853, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04201475757616178, 'dropout_rate_Layer_2': 0.34147568961394426, 'dropout_rate_Layer_3': 0.30374223559783364, 'dropout_rate_Layer_4': 0.2546414313293194, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00016742552218682516, 'l1_Layer_2': 1.426869828866313e-05, 'l1_Layer_3': 0.008004669283822631, 'l1_Layer_4': 7.506005746953808e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 85, 'n_units_Layer_3': 180, 'n_units_Layer_4': 205}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.47 | sMAPE for Validation Set is: 19.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 47.40 | sMAPE for Test Set is: 18.17% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:02:21,037]\u001b[0m Trial 906 finished with value: 17.0897273561808 and parameters: {'n_hidden': 3, 'learning_rate': 0.003211277917030276, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20044193519136033, 'dropout_rate_Layer_2': 0.1974400295570172, 'dropout_rate_Layer_3': 0.24261345895787687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007712948295901678, 'l1_Layer_2': 1.3217964610057406e-05, 'l1_Layer_3': 0.004361578136371428, 'n_units_Layer_1': 55, 'n_units_Layer_2': 110, 'n_units_Layer_3': 180}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.09 | sMAPE for Validation Set is: 19.36% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 45.41 | sMAPE for Test Set is: 17.83% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:02:21,237]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:28,718]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:29,050]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:34,733]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:35,646]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:40,566]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:43,448]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:45,031]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:50,225]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:53,135]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:53,565]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:02:53,629]\u001b[0m Trial 909 finished with value: 16.42656065770368 and parameters: {'n_hidden': 3, 'learning_rate': 0.003441556173497816, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28944708818228937, 'dropout_rate_Layer_2': 0.20105595870646714, 'dropout_rate_Layer_3': 0.237486254009072, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007898907601642845, 'l1_Layer_2': 1.2989742532801217e-05, 'l1_Layer_3': 0.0037096740132473256, 'n_units_Layer_1': 55, 'n_units_Layer_2': 115, 'n_units_Layer_3': 185}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.43 | sMAPE for Validation Set is: 19.27% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 47.38 | sMAPE for Test Set is: 18.20% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:02:57,157]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:02,184]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:02,407]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:02,907]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:05,288]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:12,243]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:12,378]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:13,192]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:13,637]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:22,883]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:23,253]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:29,437]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:29,687]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:35,332]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:39,286]\u001b[0m Trial 933 finished with value: 16.404963190240345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007564497376104039, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11985923691402364, 'dropout_rate_Layer_2': 0.23859116075125864, 'dropout_rate_Layer_3': 0.14022730712500028, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3928797149672175e-05, 'l1_Layer_2': 0.0005022113197518304, 'l1_Layer_3': 2.3402361942897244e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 260, 'n_units_Layer_3': 260}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.40 | sMAPE for Validation Set is: 18.89% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 44.77 | sMAPE for Test Set is: 17.63% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:03:41,733]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:46,347]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:46,569]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:47,606]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:52,057]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:56,001]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:56,422]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:03:56,890]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:00,259]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:06,318]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:09,376]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:13,254]\u001b[0m Trial 944 finished with value: 15.623116945403472 and parameters: {'n_hidden': 3, 'learning_rate': 0.00541766898541513, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01677004645202264, 'dropout_rate_Layer_2': 0.07154316287173111, 'dropout_rate_Layer_3': 0.05488484456308163, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019641487233645246, 'l1_Layer_2': 2.4440917217862558e-05, 'l1_Layer_3': 0.0004899109054289487, 'n_units_Layer_1': 115, 'n_units_Layer_2': 115, 'n_units_Layer_3': 190}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.62 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 49.73 | sMAPE for Test Set is: 18.89% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:04:13,561]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:19,380]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:23,001]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:24,279]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:24,359]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.68 | sMAPE for Validation Set is: 18.22% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 42.32 | sMAPE for Test Set is: 16.76% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:04:30,039]\u001b[0m Trial 948 finished with value: 15.681858987666153 and parameters: {'n_hidden': 3, 'learning_rate': 0.003912772585460883, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21271952244573547, 'dropout_rate_Layer_2': 0.17400928017397674, 'dropout_rate_Layer_3': 0.21973016008173893, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001516905967236668, 'l1_Layer_2': 5.279926930661866e-05, 'l1_Layer_3': 0.0003963801702730915, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 70}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:32,449]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:32,758]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:32,844]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:42,777]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:45,294]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:48,360]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:49,077]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:55,399]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:55,544]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:04:55,999]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:04,860]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:05,080]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:11,183]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:13,743]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:14,472]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:19,120]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:20,300]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:22,439]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:22,701]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:23,003]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:25,309]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:32,641]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:38,423]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:40,027]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:45,093]\u001b[0m Trial 976 finished with value: 15.592333917275932 and parameters: {'n_hidden': 3, 'learning_rate': 0.004048435609485789, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24279746971341287, 'dropout_rate_Layer_2': 0.09315977673612327, 'dropout_rate_Layer_3': 0.325967281735162, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001105947120502454, 'l1_Layer_2': 3.175355074852806e-05, 'l1_Layer_3': 0.0008206189603942937, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.59 | sMAPE for Validation Set is: 17.99% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 46.69 | sMAPE for Test Set is: 18.08% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:05:45,321]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:45,519]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:55,268]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:56,295]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:05:56,520]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:02,373]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:04,952]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:08,876]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:09,130]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:15,608]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:19,943]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:23,099]\u001b[0m Trial 981 finished with value: 15.230059669812519 and parameters: {'n_hidden': 3, 'learning_rate': 0.001185961664700388, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16384403769753045, 'dropout_rate_Layer_2': 0.2385239450820514, 'dropout_rate_Layer_3': 0.060221766416886174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017837009212368872, 'l1_Layer_2': 5.868023162209088e-05, 'l1_Layer_3': 2.6227416065169136e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.23 | sMAPE for Validation Set is: 17.70% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 42.48 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:06:26,406]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:30,002]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:31,665]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:35,556]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:39,485]\u001b[0m Trial 990 finished with value: 15.562877904165612 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008859513947967525, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17324331174158486, 'dropout_rate_Layer_2': 0.21182638711077376, 'dropout_rate_Layer_3': 0.12638539868703325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012913367874298697, 'l1_Layer_2': 2.744033618861941e-05, 'l1_Layer_3': 0.0012490114454386313, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 60}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.56 | sMAPE for Validation Set is: 18.08% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 41.18 | sMAPE for Test Set is: 16.54% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:06:40,041]\u001b[0m Trial 992 finished with value: 15.903774043727855 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016581204260256073, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24517462657672587, 'dropout_rate_Layer_2': 0.26130302818576545, 'dropout_rate_Layer_3': 0.10582278138727534, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.769135977266313e-05, 'l1_Layer_2': 2.7821734280472627e-05, 'l1_Layer_3': 0.002270963375354925, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.90 | sMAPE for Validation Set is: 18.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 43.09 | sMAPE for Test Set is: 17.08% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:06:40,811]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:48,271]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:53,506]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:06:56,971]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:01,811]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:06,032]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:10,489]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:11,534]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:14,919]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:20,610]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:23,064]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:28,226]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:32,700]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:33,868]\u001b[0m Trial 1003 finished with value: 15.521813389007384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009659039228782849, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12899365818157288, 'dropout_rate_Layer_2': 0.22733280557160343, 'dropout_rate_Layer_3': 0.07661112308178061, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013429217467796329, 'l1_Layer_2': 5.3300533162639785e-05, 'l1_Layer_3': 2.7069067693384807e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.52 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 41.47 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:07:38,377]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:39,107]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:40,266]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.41 | sMAPE for Validation Set is: 18.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 42.41 | sMAPE for Test Set is: 16.67% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:07:41,746]\u001b[0m Trial 1006 finished with value: 15.408128623873607 and parameters: {'n_hidden': 3, 'learning_rate': 0.007051849880779581, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16631039276501472, 'dropout_rate_Layer_2': 0.3081890997803761, 'dropout_rate_Layer_3': 0.1607314371578782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005806670374700355, 'l1_Layer_2': 1.9566150903179355e-05, 'l1_Layer_3': 0.0008067577293958744, 'n_units_Layer_1': 85, 'n_units_Layer_2': 75, 'n_units_Layer_3': 80}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:49,952]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:52,409]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:07:59,319]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:05,505]\u001b[0m Trial 1019 finished with value: 61.21945403418727 and parameters: {'n_hidden': 3, 'learning_rate': 0.006622953282053617, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19227638723510013, 'dropout_rate_Layer_2': 0.30579054111232384, 'dropout_rate_Layer_3': 0.166571305238865, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005038881618644094, 'l1_Layer_2': 6.453457965050678e-05, 'l1_Layer_3': 0.00034090986880374463, 'n_units_Layer_1': 95, 'n_units_Layer_2': 195, 'n_units_Layer_3': 85}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.22 | sMAPE for Validation Set is: 57.90% | rMAE for Validation Set is: 2.24\n",
      "MAE for Test Set is: 222.06 | sMAPE for Test Set is: 122.15% | rMAE for Test Set is: 3.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:08:08,907]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:09,135]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:14,220]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:20,019]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:20,243]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:20,940]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:21,002]\u001b[0m Trial 1018 finished with value: 15.269895851785245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015627706578817244, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07623956399814347, 'dropout_rate_Layer_2': 0.20693711783046956, 'dropout_rate_Layer_3': 0.09005043227289138, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009302039812948535, 'l1_Layer_2': 2.6850240067567952e-05, 'l1_Layer_3': 1.2328484990087649e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 230, 'n_units_Layer_3': 270}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.27 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 43.07 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:08:30,730]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:31,785]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:34,032]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:39,743]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:39,964]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:41,356]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:46,550]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:50,532]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:53,037]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:08:53,531]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:01,860]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:04,362]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:05,130]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:05,898]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:06,640]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:13,180]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:20,623]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:23,935]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:24,247]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:24,420]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:25,011]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:36,702]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:37,821]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:37,984]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:43,396]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:45,638]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:49,290]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:53,183]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:58,059]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:58,467]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:58,682]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:09:59,609]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:09,601]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:15,351]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:15,866]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:16,033]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:16,217]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:27,205]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:28,048]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:28,411]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:31,759]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:35,919]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:39,358]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:41,080]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:46,592]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:47,004]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:47,312]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:48,505]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:57,141]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:10:57,490]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:01,265]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:06,023]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:10,501]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:14,684]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:15,243]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:20,029]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:23,908]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:28,482]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:29,812]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:34,073]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:37,260]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:38,343]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:42,299]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:45,132]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:46,060]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:47,588]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:54,265]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:11:58,428]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:00,739]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:06,928]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:09,336]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:10,367]\u001b[0m Trial 1094 finished with value: 16.517625885933253 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011187002003564368, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18341350374089968, 'dropout_rate_Layer_2': 0.21163987849723764, 'dropout_rate_Layer_3': 0.10281190770882773, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00034651083996583323, 'l1_Layer_2': 4.454800130965372e-05, 'l1_Layer_3': 5.0418161806656673e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 270, 'n_units_Layer_3': 265}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.52 | sMAPE for Validation Set is: 19.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 46.44 | sMAPE for Test Set is: 18.12% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:12:15,099]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:16,043]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:20,355]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:24,920]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:25,109]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:36,565]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:36,986]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.25 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 42.32 | sMAPE for Test Set is: 16.83% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:12:42,357]\u001b[0m Trial 1101 finished with value: 15.247442240697266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009346846181951454, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1810639532801117, 'dropout_rate_Layer_2': 0.19342753578715022, 'dropout_rate_Layer_3': 0.13044115355468994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006180468300531806, 'l1_Layer_2': 2.6563077031209973e-05, 'l1_Layer_3': 0.003212436167619391, 'n_units_Layer_1': 80, 'n_units_Layer_2': 100, 'n_units_Layer_3': 60}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:43,024]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:45,620]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:52,848]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:12:58,317]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:02,102]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:02,936]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:09,045]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:12,473]\u001b[0m Trial 1108 finished with value: 15.638167840568714 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022023316956057562, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2490084564243692, 'dropout_rate_Layer_2': 0.25892463478327327, 'dropout_rate_Layer_3': 0.37547343640269154, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.468195359507644e-05, 'l1_Layer_2': 1.5803979317739022e-05, 'l1_Layer_3': 0.001010195996055597, 'n_units_Layer_1': 295, 'n_units_Layer_2': 105, 'n_units_Layer_3': 190}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.64 | sMAPE for Validation Set is: 18.12% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 45.92 | sMAPE for Test Set is: 17.70% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:13:13,208]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:19,491]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:23,827]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:26,654]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:29,969]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:35,387]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:37,694]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:40,069]\u001b[0m Trial 1117 finished with value: 15.58360702068002 and parameters: {'n_hidden': 3, 'learning_rate': 0.002511376237541318, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2397215805045447, 'dropout_rate_Layer_2': 0.24466833869476046, 'dropout_rate_Layer_3': 0.3441753976760097, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.193762010807523e-05, 'l1_Layer_2': 1.163292189712391e-05, 'l1_Layer_3': 0.0009929736467991438, 'n_units_Layer_1': 55, 'n_units_Layer_2': 110, 'n_units_Layer_3': 180}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.58 | sMAPE for Validation Set is: 18.33% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 42.19 | sMAPE for Test Set is: 16.67% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:13:42,389]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:42,507]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:50,138]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:52,588]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:54,270]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:55,021]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:13:57,993]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:03,404]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:05,763]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:08,836]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:09,837]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:20,236]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:20,377]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:22,607]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:28,838]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:30,771]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:34,527]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:40,948]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:44,097]\u001b[0m Trial 1133 finished with value: 15.374491476018115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026742530041442623, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25314441267549004, 'dropout_rate_Layer_2': 0.2746339847208948, 'dropout_rate_Layer_3': 0.3900754229478506, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.823849115181934e-05, 'l1_Layer_2': 1.4624432506174696e-05, 'l1_Layer_3': 0.0011980462220807669, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 185}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.37 | sMAPE for Validation Set is: 17.99% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 42.94 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:14:46,628]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:47,561]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:48,785]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:14:56,385]\u001b[0m Trial 1140 finished with value: 16.086512357282906 and parameters: {'n_hidden': 3, 'learning_rate': 0.003243046345422208, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2250266377630359, 'dropout_rate_Layer_2': 0.2805051051392118, 'dropout_rate_Layer_3': 0.3326602504126212, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.846703177460313e-05, 'l1_Layer_2': 1.4383232786596268e-05, 'l1_Layer_3': 0.0015684920905842685, 'n_units_Layer_1': 250, 'n_units_Layer_2': 110, 'n_units_Layer_3': 190}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.09 | sMAPE for Validation Set is: 18.43% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 47.45 | sMAPE for Test Set is: 18.27% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:14:57,163]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:01,936]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:06,158]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:08,005]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:08,585]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:17,920]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:22,068]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:22,213]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.23 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 42.05 | sMAPE for Test Set is: 16.74% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:15:28,859]\u001b[0m Trial 1146 finished with value: 15.226670908199788 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011924017101587433, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22030286119562895, 'dropout_rate_Layer_2': 0.26423551450535154, 'dropout_rate_Layer_3': 0.17690247815842033, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012446317312185976, 'l1_Layer_2': 6.007629961767211e-05, 'l1_Layer_3': 0.000592605305557473, 'n_units_Layer_1': 75, 'n_units_Layer_2': 70, 'n_units_Layer_3': 65}. Best is trial 240 with value: 15.176845728223329.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:29,658]\u001b[0m Trial 1150 finished with value: 15.077415814661668 and parameters: {'n_hidden': 3, 'learning_rate': 0.002444075057316842, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20691430640332817, 'dropout_rate_Layer_2': 0.08463077107206102, 'dropout_rate_Layer_3': 0.14983421534007615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00035584213411470246, 'l1_Layer_2': 6.129179590819933e-05, 'l1_Layer_3': 0.0010086095590756332, 'n_units_Layer_1': 75, 'n_units_Layer_2': 115, 'n_units_Layer_3': 65}. Best is trial 1150 with value: 15.077415814661668.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.08 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 42.44 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:15:30,988]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:31,033]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:37,678]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:40,457]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:44,608]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:49,167]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:51,229]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:15:56,730]\u001b[0m Trial 1157 finished with value: 15.740878035946707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012852863836808762, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22536054025747512, 'dropout_rate_Layer_2': 0.2568956944242468, 'dropout_rate_Layer_3': 0.17443739018645898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003402769105212601, 'l1_Layer_2': 0.00017745283751276867, 'l1_Layer_3': 0.0010106413765363672, 'n_units_Layer_1': 75, 'n_units_Layer_2': 115, 'n_units_Layer_3': 65}. Best is trial 1150 with value: 15.077415814661668.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.74 | sMAPE for Validation Set is: 18.45% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 41.59 | sMAPE for Test Set is: 16.69% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:15:56,852]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:03,714]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:10,146]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:14,541]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:18,833]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:20,981]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:23,776]\u001b[0m Trial 1159 finished with value: 16.176520512845485 and parameters: {'n_hidden': 3, 'learning_rate': 0.002331754322736425, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2735863417200643, 'dropout_rate_Layer_2': 0.11416674573113916, 'dropout_rate_Layer_3': 0.28267436129691614, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003742790501508115, 'l1_Layer_2': 0.009167035195387883, 'l1_Layer_3': 3.5259624052198035e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 65, 'n_units_Layer_3': 215}. Best is trial 1150 with value: 15.077415814661668.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.18 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 44.48 | sMAPE for Test Set is: 17.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:16:26,891]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:32,074]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:34,941]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:37,843]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:40,468]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:40,979]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.34 | sMAPE for Validation Set is: 17.96% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 40.21 | sMAPE for Test Set is: 16.22% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:16:48,370]\u001b[0m Trial 1168 finished with value: 15.340675474673896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007639415680905841, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24085494705060354, 'dropout_rate_Layer_2': 0.23104321083469356, 'dropout_rate_Layer_3': 0.14872858317981397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001190098387738797, 'l1_Layer_2': 8.008865120087023e-05, 'l1_Layer_3': 0.00010498557022249407, 'n_units_Layer_1': 130, 'n_units_Layer_2': 70, 'n_units_Layer_3': 65}. Best is trial 1150 with value: 15.077415814661668.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:49,178]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:49,887]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:57,264]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:16:58,982]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:00,327]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:07,415]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:08,227]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:11,071]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:12,583]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:21,509]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:25,665]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:29,881]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:34,368]\u001b[0m Trial 1186 finished with value: 15.852050463256445 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026129416967837723, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22856302085056515, 'dropout_rate_Layer_2': 0.01649080766583149, 'dropout_rate_Layer_3': 0.3181067989202553, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6212347617938153e-05, 'l1_Layer_2': 1.9932157115701554e-05, 'l1_Layer_3': 0.0011669023720259019, 'n_units_Layer_1': 255, 'n_units_Layer_2': 105, 'n_units_Layer_3': 175}. Best is trial 1150 with value: 15.077415814661668.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:34,466]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.85 | sMAPE for Validation Set is: 18.25% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 44.87 | sMAPE for Test Set is: 17.47% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:17:34,651]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:44,546]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:45,369]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:45,754]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:53,360]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:17:59,936]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:07,027]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:11,580]\u001b[0m Trial 1193 finished with value: 15.386514801650518 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005650637113389056, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2328048534793384, 'dropout_rate_Layer_2': 0.2660465979786836, 'dropout_rate_Layer_3': 0.09619634773168048, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002425882974312439, 'l1_Layer_2': 0.0005664361687985845, 'l1_Layer_3': 1.3961436967342871e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 1150 with value: 15.077415814661668.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.39 | sMAPE for Validation Set is: 17.73% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 43.73 | sMAPE for Test Set is: 17.18% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:18:13,118]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:18,800]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:20,453]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:23,307]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:23,934]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:30,457]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:35,288]\u001b[0m Trial 1196 finished with value: 14.835225732912567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017909530316339924, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22875136986459207, 'dropout_rate_Layer_2': 0.02363780654445679, 'dropout_rate_Layer_3': 0.33888505775360656, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.192587946685372e-05, 'l1_Layer_2': 0.0018891812933823297, 'l1_Layer_3': 0.001130559227258817, 'n_units_Layer_1': 250, 'n_units_Layer_2': 100, 'n_units_Layer_3': 170}. Best is trial 1196 with value: 14.835225732912567.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.84 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 43.60 | sMAPE for Test Set is: 17.07% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:18:41,780]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:44,569]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:45,960]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:49,278]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:59,275]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:18:59,903]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:05,753]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:06,791]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:12,735]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:15,503]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:17,462]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:18,363]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:19,651]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:31,312]\u001b[0m Trial 1218 finished with value: 15.234141567827825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0062293123848567705, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2035279051701116, 'dropout_rate_Layer_2': 0.003667995236130289, 'dropout_rate_Layer_3': 0.16119717642688164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005935207167008622, 'l1_Layer_2': 4.891619922356388e-05, 'l1_Layer_3': 0.0002345588813583411, 'n_units_Layer_1': 85, 'n_units_Layer_2': 60, 'n_units_Layer_3': 85}. Best is trial 1196 with value: 14.835225732912567.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.23 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 39.71 | sMAPE for Test Set is: 16.03% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:19:35,248]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:43,945]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:44,355]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:50,538]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:19:51,499]\u001b[0m Trial 1219 finished with value: 15.249095608211318 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016481209743656714, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22144111782814982, 'dropout_rate_Layer_2': 0.04163022564659195, 'dropout_rate_Layer_3': 0.052893755446946494, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.073136301627351e-05, 'l1_Layer_2': 0.003121485181585451, 'l1_Layer_3': 0.0018744944070936782, 'n_units_Layer_1': 260, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 1196 with value: 14.835225732912567.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.25 | sMAPE for Validation Set is: 17.59% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 46.32 | sMAPE for Test Set is: 18.01% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:19:57,194]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:01,264]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.03 | sMAPE for Validation Set is: 19.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 43.94 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:20:03,225]\u001b[0m Trial 1221 finished with value: 17.032223515608237 and parameters: {'n_hidden': 3, 'learning_rate': 0.001408955317827327, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25520798748475065, 'dropout_rate_Layer_2': 0.15931523608401876, 'dropout_rate_Layer_3': 0.2772430994711605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004024956055745426, 'l1_Layer_2': 0.0839248833461856, 'l1_Layer_3': 0.00016512965114961998, 'n_units_Layer_1': 140, 'n_units_Layer_2': 70, 'n_units_Layer_3': 195}. Best is trial 1196 with value: 14.835225732912567.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:08,490]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:13,086]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:13,406]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:15,202]\u001b[0m Trial 1224 finished with value: 15.256849699135822 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015692822345002271, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20346049167065336, 'dropout_rate_Layer_2': 0.07791339316712598, 'dropout_rate_Layer_3': 0.16004963713499212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006564072211201112, 'l1_Layer_2': 5.883776592319931e-05, 'l1_Layer_3': 0.00022237749494617723, 'n_units_Layer_1': 90, 'n_units_Layer_2': 60, 'n_units_Layer_3': 85}. Best is trial 1196 with value: 14.835225732912567.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.26 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 43.95 | sMAPE for Test Set is: 17.26% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:20:20,748]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:23,725]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:28,985]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:33,766]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:37,975]\u001b[0m Trial 1226 finished with value: 16.644148572934185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029752358037080334, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26770934507733934, 'dropout_rate_Layer_2': 0.14353866631350756, 'dropout_rate_Layer_3': 0.10093959454263667, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00041710726068144936, 'l1_Layer_2': 0.019722499326589742, 'l1_Layer_3': 2.149914840866344e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 115, 'n_units_Layer_3': 170}. Best is trial 1196 with value: 14.835225732912567.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.64 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 46.45 | sMAPE for Test Set is: 18.23% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:20:39,047]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:43,062]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:47,098]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:20:50,873]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:00,117]\u001b[0m Trial 1237 finished with value: 15.103800718140556 and parameters: {'n_hidden': 3, 'learning_rate': 0.00188962559536184, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22154488071711267, 'dropout_rate_Layer_2': 0.022764822271134744, 'dropout_rate_Layer_3': 0.042799099355540694, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.7605486331350926e-05, 'l1_Layer_2': 0.00216539567914796, 'l1_Layer_3': 0.002197914030209163, 'n_units_Layer_1': 245, 'n_units_Layer_2': 105, 'n_units_Layer_3': 285}. Best is trial 1196 with value: 14.835225732912567.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.10 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 42.57 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:21:04,717]\u001b[0m Trial 1243 finished with value: 15.63530637696691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023668324801338725, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030159639358277666, 'dropout_rate_Layer_2': 0.02890795726874158, 'dropout_rate_Layer_3': 0.3895553973018224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.320208722231417e-05, 'l1_Layer_2': 1.0158951215567933e-05, 'l1_Layer_3': 0.0018199889311488447, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170}. Best is trial 1196 with value: 14.835225732912567.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.64 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 43.55 | sMAPE for Test Set is: 17.11% | rMAE for Test Set is: 0.60\n",
      "MAE for Validation Set is: 14.83 | sMAPE for Validation Set is: 17.25% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 44.25 | sMAPE for Test Set is: 17.21% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:21:04,732]\u001b[0m Trial 1234 finished with value: 14.834860434829634 and parameters: {'n_hidden': 3, 'learning_rate': 0.00181853704633765, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2040988258108678, 'dropout_rate_Layer_2': 0.05653866724701425, 'dropout_rate_Layer_3': 0.06682431334524169, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.675431778066205e-05, 'l1_Layer_2': 0.002295770540311547, 'l1_Layer_3': 0.0014389876194046618, 'n_units_Layer_1': 245, 'n_units_Layer_2': 110, 'n_units_Layer_3': 275}. Best is trial 1234 with value: 14.834860434829634.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:07,124]\u001b[0m Trial 1240 finished with value: 15.280153384839133 and parameters: {'n_hidden': 3, 'learning_rate': 0.00145542109337477, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20587961341145017, 'dropout_rate_Layer_2': 0.006045084846966031, 'dropout_rate_Layer_3': 0.09648257957035922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00040608309770276597, 'l1_Layer_2': 7.078778491789588e-05, 'l1_Layer_3': 0.0002221907239839677, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 95}. Best is trial 1234 with value: 14.834860434829634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.28 | sMAPE for Validation Set is: 17.72% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 43.48 | sMAPE for Test Set is: 17.18% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:21:12,352]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:17,063]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:21,088]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:24,789]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:25,207]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:32,104]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:36,565]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:36,682]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:44,102]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:44,641]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:44,751]\u001b[0m Trial 1244 finished with value: 15.295361591473196 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012066986122208612, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20391814463942892, 'dropout_rate_Layer_2': 0.005404647404639251, 'dropout_rate_Layer_3': 0.1475462722811238, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00038275173884284327, 'l1_Layer_2': 7.369999722307574e-05, 'l1_Layer_3': 0.00022820213028373055, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 85}. Best is trial 1234 with value: 14.834860434829634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.30 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 44.07 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:21:52,554]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:53,300]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:21:58,671]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:01,131]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:05,057]\u001b[0m Trial 1249 finished with value: 15.058331913313166 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018855305854085756, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2100236870093974, 'dropout_rate_Layer_2': 0.04200187246775242, 'dropout_rate_Layer_3': 0.04477258300444037, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.3827281359793724e-05, 'l1_Layer_2': 0.0035217084672810864, 'l1_Layer_3': 0.00199817136341444, 'n_units_Layer_1': 245, 'n_units_Layer_2': 110, 'n_units_Layer_3': 290}. Best is trial 1234 with value: 14.834860434829634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.06 | sMAPE for Validation Set is: 17.59% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 43.16 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:22:06,121]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:08,012]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:14,387]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:15,066]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:16,299]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:16,450]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:23,352]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:27,033]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:34,462]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:37,080]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:37,530]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:37,911]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:45,449]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:47,414]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:54,802]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:22:55,523]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:00,026]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:09,969]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:14,200]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:14,354]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:17,987]\u001b[0m Trial 1275 finished with value: 15.058157658106346 and parameters: {'n_hidden': 3, 'learning_rate': 0.001528391082858456, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20493728801819946, 'dropout_rate_Layer_2': 0.003648005386478396, 'dropout_rate_Layer_3': 0.09404746851698759, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006097317579252049, 'l1_Layer_2': 6.608120938468679e-05, 'l1_Layer_3': 0.0002141759245196116, 'n_units_Layer_1': 200, 'n_units_Layer_2': 65, 'n_units_Layer_3': 95}. Best is trial 1234 with value: 14.834860434829634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.06 | sMAPE for Validation Set is: 17.57% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 43.84 | sMAPE for Test Set is: 17.33% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:23:22,505]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:24,483]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:30,282]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:34,055]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:37,951]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:40,699]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:42,540]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:46,675]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:49,410]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:23:53,791]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:01,784]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:02,966]\u001b[0m Trial 1279 finished with value: 15.63054980966632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005016511332440652, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20679950568213548, 'dropout_rate_Layer_2': 0.03939397821326534, 'dropout_rate_Layer_3': 0.1430393013906465, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006611742851050405, 'l1_Layer_2': 0.00011328048872968217, 'l1_Layer_3': 0.00011704792140576417, 'n_units_Layer_1': 200, 'n_units_Layer_2': 60, 'n_units_Layer_3': 95}. Best is trial 1234 with value: 14.834860434829634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.63 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 41.96 | sMAPE for Test Set is: 16.70% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:24:03,212]\u001b[0m Trial 1285 finished with value: 15.504983625691699 and parameters: {'n_hidden': 3, 'learning_rate': 0.001550527342213319, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2047828484342227, 'dropout_rate_Layer_2': 0.00022010545277641787, 'dropout_rate_Layer_3': 0.09502450705287675, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006531455895517939, 'l1_Layer_2': 0.00011339961498916661, 'l1_Layer_3': 0.00022616387868908168, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 90}. Best is trial 1234 with value: 14.834860434829634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.50 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 42.95 | sMAPE for Test Set is: 17.05% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:24:10,441]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:14,809]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:14,943]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:15,061]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:24,450]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:24,855]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:25,133]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:28,662]\u001b[0m Trial 1293 finished with value: 15.263341490587486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007200069217149208, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21279964970254348, 'dropout_rate_Layer_2': 0.26306586977081414, 'dropout_rate_Layer_3': 0.23807858600134107, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002504871355141589, 'l1_Layer_2': 0.0005140528973583954, 'l1_Layer_3': 1.186321403333751e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 275, 'n_units_Layer_3': 270}. Best is trial 1234 with value: 14.834860434829634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.26 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 44.10 | sMAPE for Test Set is: 17.24% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:24:34,569]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:36,974]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:37,621]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:44,646]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:50,406]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:54,947]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:24:58,441]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:25:00,141]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:25:07,346]\u001b[0m Trial 1306 finished with value: 15.676201895903832 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012690136087279594, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1943759949913557, 'dropout_rate_Layer_2': 0.00010110859701623932, 'dropout_rate_Layer_3': 0.07952729775203378, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003787595043594015, 'l1_Layer_2': 7.550011850310562e-05, 'l1_Layer_3': 0.0002019886492156651, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 85}. Best is trial 1234 with value: 14.834860434829634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.68 | sMAPE for Validation Set is: 18.20% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 44.59 | sMAPE for Test Set is: 17.53% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:25:11,325]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:25:12,893]\u001b[0m Trial 1302 finished with value: 15.461867444120083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012228977866446194, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19908013697440036, 'dropout_rate_Layer_2': 0.005437727726177177, 'dropout_rate_Layer_3': 0.07526268626410622, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004046876050492414, 'l1_Layer_2': 7.758967110459202e-05, 'l1_Layer_3': 0.0002966306843860181, 'n_units_Layer_1': 225, 'n_units_Layer_2': 65, 'n_units_Layer_3': 85}. Best is trial 1234 with value: 14.834860434829634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.46 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 43.98 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:25:18,511]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:25:22,656]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:25:30,005]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:25:33,899]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:25:38,209]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:25:42,362]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:25:43,503]\u001b[0m Trial 1312 finished with value: 15.475124707457296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009899734538312967, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22013970561677224, 'dropout_rate_Layer_2': 0.2541351707143575, 'dropout_rate_Layer_3': 0.24205799222624916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012082577354719374, 'l1_Layer_2': 0.006343323229944791, 'l1_Layer_3': 1.8583165629896718e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295}. Best is trial 1234 with value: 14.834860434829634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.48 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 43.29 | sMAPE for Test Set is: 17.25% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:25:47,786]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:25:52,988]\u001b[0m Trial 1315 finished with value: 14.77893062732295 and parameters: {'n_hidden': 3, 'learning_rate': 0.002336335125889461, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22253222168666054, 'dropout_rate_Layer_2': 0.03891690818634842, 'dropout_rate_Layer_3': 0.029774090799854838, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.178159922622534e-05, 'l1_Layer_2': 1.653001971169624e-05, 'l1_Layer_3': 0.0008749078254500327, 'n_units_Layer_1': 270, 'n_units_Layer_2': 110, 'n_units_Layer_3': 175}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.78 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 45.55 | sMAPE for Test Set is: 17.93% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:25:55,792]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:25:59,360]\u001b[0m Trial 1313 finished with value: 15.15696473072361 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009833146339067863, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16555523305898454, 'dropout_rate_Layer_2': 0.25331864966268813, 'dropout_rate_Layer_3': 0.12785542910585979, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016186505866042886, 'l1_Layer_2': 0.0006926463157951221, 'l1_Layer_3': 1.80474482511192e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.16 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 42.84 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:26:04,455]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:06,672]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:10,854]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:11,000]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:17,259]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:18,760]\u001b[0m Trial 1324 finished with value: 15.669155189826725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010031459219096415, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22250725593601103, 'dropout_rate_Layer_2': 0.25162620738428887, 'dropout_rate_Layer_3': 0.12808590772858305, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001581105489690433, 'l1_Layer_2': 0.000285870439937519, 'l1_Layer_3': 1.8953593484321495e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 280, 'n_units_Layer_3': 265}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.67 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 46.23 | sMAPE for Test Set is: 17.90% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:26:19,256]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:23,643]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:30,841]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:34,819]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:35,217]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:41,821]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.43 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 43.64 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:26:43,817]\u001b[0m Trial 1328 finished with value: 15.425601863044157 and parameters: {'n_hidden': 3, 'learning_rate': 0.001466502652395648, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18411140114740251, 'dropout_rate_Layer_2': 0.017662061029239253, 'dropout_rate_Layer_3': 0.09232282708496922, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010687383864757915, 'l1_Layer_2': 6.258645092197123e-05, 'l1_Layer_3': 7.318785851660277e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 95}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:49,452]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:54,367]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:26:58,334]\u001b[0m Trial 1333 finished with value: 15.084250201832651 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010208435693093182, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22158979087534578, 'dropout_rate_Layer_2': 0.25571016795043733, 'dropout_rate_Layer_3': 0.12362436884976345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011374345176196625, 'l1_Layer_2': 0.000619219551806069, 'l1_Layer_3': 1.4449440505836789e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 280, 'n_units_Layer_3': 265}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.08 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 43.96 | sMAPE for Test Set is: 17.26% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:27:04,511]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:27:08,472]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:27:12,477]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:27:18,734]\u001b[0m Trial 1343 finished with value: 14.930656508546967 and parameters: {'n_hidden': 3, 'learning_rate': 0.00203380290007891, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21902200134934446, 'dropout_rate_Layer_2': 0.024249876074189824, 'dropout_rate_Layer_3': 0.3892801341031642, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.785204865010852e-05, 'l1_Layer_2': 1.3068243678535108e-05, 'l1_Layer_3': 0.0006010683034632028, 'n_units_Layer_1': 270, 'n_units_Layer_2': 100, 'n_units_Layer_3': 180}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.93 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 40.65 | sMAPE for Test Set is: 16.16% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:27:19,767]\u001b[0m Trial 1342 finished with value: 15.607535339050008 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013966653694410542, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2178631443643714, 'dropout_rate_Layer_2': 0.2574849862824327, 'dropout_rate_Layer_3': 0.2559546465574602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014669264044841451, 'l1_Layer_2': 0.0005951457465962543, 'l1_Layer_3': 1.375422246693972e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.61 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 47.39 | sMAPE for Test Set is: 18.35% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:27:26,067]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:27:26,696]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:27:37,400]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:27:44,720]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:27:46,524]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:27:51,387]\u001b[0m Trial 1350 finished with value: 15.579519585200087 and parameters: {'n_hidden': 3, 'learning_rate': 0.001855181589419214, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2251747865949017, 'dropout_rate_Layer_2': 0.02618131391863633, 'dropout_rate_Layer_3': 0.3717218759583768, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.708790366430674e-05, 'l1_Layer_2': 1.1640156162978496e-05, 'l1_Layer_3': 0.0011889750322262701, 'n_units_Layer_1': 270, 'n_units_Layer_2': 90, 'n_units_Layer_3': 185}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.58 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 48.04 | sMAPE for Test Set is: 18.31% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:27:51,651]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:27:58,969]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:27:59,320]\u001b[0m Trial 1346 finished with value: 15.195061575638297 and parameters: {'n_hidden': 3, 'learning_rate': 0.000765229652944358, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22979705288203048, 'dropout_rate_Layer_2': 0.05182666317624726, 'dropout_rate_Layer_3': 0.05877190896056831, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003073567472255928, 'l1_Layer_2': 4.559310736659014e-05, 'l1_Layer_3': 0.00042874466909963106, 'n_units_Layer_1': 180, 'n_units_Layer_2': 65, 'n_units_Layer_3': 50}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:27:59,350]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.20 | sMAPE for Validation Set is: 17.74% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 41.88 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:27:59,450]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:10,776]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:10,850]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:11,012]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:12,298]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:23,588]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:24,439]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:29,067]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:30,728]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:32,850]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:33,671]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:36,469]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:43,683]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:45,088]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:45,781]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:48,432]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:53,179]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:28:59,176]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:29:02,848]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:29:05,427]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:29:15,997]\u001b[0m Trial 1377 finished with value: 15.705465859505495 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010984622717570033, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24498625820676434, 'dropout_rate_Layer_2': 0.25132040974290054, 'dropout_rate_Layer_3': 0.25108646495898407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001303980256206562, 'l1_Layer_2': 0.000431730213081477, 'l1_Layer_3': 1.2328646941339932e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.71 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 45.69 | sMAPE for Test Set is: 17.80% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:29:19,187]\u001b[0m Trial 1375 finished with value: 15.690229472918661 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014565433651333895, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22061865490560598, 'dropout_rate_Layer_2': 0.24084719479526281, 'dropout_rate_Layer_3': 0.25858980241003693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012621893365267765, 'l1_Layer_2': 0.0005914616684674095, 'l1_Layer_3': 1.2905552102607365e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.69 | sMAPE for Validation Set is: 17.88% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 43.75 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:29:22,148]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:29:26,315]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:29:37,107]\u001b[0m Trial 1380 finished with value: 15.709072405710346 and parameters: {'n_hidden': 3, 'learning_rate': 0.002136417381364933, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20922109147812545, 'dropout_rate_Layer_2': 0.05709905889779845, 'dropout_rate_Layer_3': 0.3814767615600958, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.838697662669864e-05, 'l1_Layer_2': 1.0235664046283853e-05, 'l1_Layer_3': 0.002340931133893169, 'n_units_Layer_1': 285, 'n_units_Layer_2': 105, 'n_units_Layer_3': 195}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.71 | sMAPE for Validation Set is: 18.21% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 49.58 | sMAPE for Test Set is: 18.75% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:29:37,275]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:29:43,938]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:29:47,835]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:29:51,715]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:30:00,009]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:30:16,024]\u001b[0m Trial 1388 finished with value: 15.40677077700972 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012167953952611735, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21962865577692348, 'dropout_rate_Layer_2': 0.24202653694252915, 'dropout_rate_Layer_3': 0.2632462458449992, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015708820127874177, 'l1_Layer_2': 0.0006412751815014047, 'l1_Layer_3': 1.3841942576718115e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.41 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 45.67 | sMAPE for Test Set is: 17.83% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:30:19,577]\u001b[0m Trial 1384 finished with value: 16.74933470522669 and parameters: {'n_hidden': 3, 'learning_rate': 0.002353716519067709, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23611773411203354, 'dropout_rate_Layer_2': 0.16430282130710916, 'dropout_rate_Layer_3': 0.033021480345393664, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2901469727849518e-05, 'l1_Layer_2': 0.07823917364059362, 'l1_Layer_3': 0.0002496467701161872, 'n_units_Layer_1': 165, 'n_units_Layer_2': 170, 'n_units_Layer_3': 205}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.75 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 43.69 | sMAPE for Test Set is: 17.44% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:30:20,037]\u001b[0m Trial 1373 finished with value: 16.767519185840527 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009620844225703806, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23243611135175335, 'dropout_rate_Layer_2': 0.11703337968720251, 'dropout_rate_Layer_3': 0.27175563705556005, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010985306304473433, 'l1_Layer_2': 0.02758981983215228, 'l1_Layer_3': 5.140347928997902e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 225}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.77 | sMAPE for Validation Set is: 19.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 44.36 | sMAPE for Test Set is: 17.48% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:30:21,999]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:30:29,725]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:30:37,848]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:30:41,527]\u001b[0m Trial 1392 finished with value: 15.406204314391706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019130462917071513, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2569052360246454, 'dropout_rate_Layer_2': 0.01138526356021649, 'dropout_rate_Layer_3': 0.0624295274778271, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000302412445747732, 'l1_Layer_2': 3.0472328166920825e-05, 'l1_Layer_3': 0.00041442198291109225, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 60}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.41 | sMAPE for Validation Set is: 17.90% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 43.22 | sMAPE for Test Set is: 17.16% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:30:41,731]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:30:47,845]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:30:49,057]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:30:49,528]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:30:58,595]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:30:58,631]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:00,752]\u001b[0m Trial 1378 finished with value: 16.30829655086084 and parameters: {'n_hidden': 3, 'learning_rate': 0.00201198222630415, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2347646591919323, 'dropout_rate_Layer_2': 0.16651424956455396, 'dropout_rate_Layer_3': 0.2773969385495848, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042849065504484656, 'l1_Layer_2': 0.014113687383269409, 'l1_Layer_3': 4.838425250691436e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 235}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.31 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 46.94 | sMAPE for Test Set is: 18.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:31:09,776]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:17,445]\u001b[0m Trial 1397 finished with value: 15.473362176555943 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024127729534258705, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22242768722096815, 'dropout_rate_Layer_2': 0.0599325315502787, 'dropout_rate_Layer_3': 0.36089450346796886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.8006251641660377e-05, 'l1_Layer_2': 0.004148547824865475, 'l1_Layer_3': 0.0010364581716810644, 'n_units_Layer_1': 275, 'n_units_Layer_2': 95, 'n_units_Layer_3': 195}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.47 | sMAPE for Validation Set is: 18.21% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 46.22 | sMAPE for Test Set is: 17.73% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:31:20,809]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:22,064]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:27,916]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:32,104]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:32,589]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:33,380]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:40,344]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:42,432]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:44,165]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:47,903]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:55,475]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:31:56,927]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:00,752]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:05,574]\u001b[0m Trial 1405 finished with value: 15.35828450176303 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012474139926029494, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20911016165547586, 'dropout_rate_Layer_2': 0.2625151356803492, 'dropout_rate_Layer_3': 0.2661863548110343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001556447226198846, 'l1_Layer_2': 0.0004862486084111999, 'l1_Layer_3': 2.3520452385863892e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.36 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 43.54 | sMAPE for Test Set is: 17.15% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:32:05,992]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:05,992]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:14,793]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:16,215]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:16,779]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:17,646]\u001b[0m Trial 1412 finished with value: 15.360965118066337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025231588193672157, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23419960258474795, 'dropout_rate_Layer_2': 0.086138275475116, 'dropout_rate_Layer_3': 0.36193135273095933, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000927882821434686, 'l1_Layer_2': 0.0046539920813841625, 'l1_Layer_3': 0.0006168478866979104, 'n_units_Layer_1': 280, 'n_units_Layer_2': 115, 'n_units_Layer_3': 185}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.36 | sMAPE for Validation Set is: 17.98% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 43.44 | sMAPE for Test Set is: 17.14% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:32:23,966]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:29,807]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:30,844]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:37,032]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:41,301]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:43,768]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:47,336]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:51,573]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:52,134]\u001b[0m Trial 1422 finished with value: 15.591035955893483 and parameters: {'n_hidden': 3, 'learning_rate': 0.001286066264524618, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20952681906747345, 'dropout_rate_Layer_2': 0.26292533509447763, 'dropout_rate_Layer_3': 0.2670628321187022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015844528871605186, 'l1_Layer_2': 0.00048294886259311274, 'l1_Layer_3': 2.1837850956867536e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.59 | sMAPE for Validation Set is: 18.09% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 45.54 | sMAPE for Test Set is: 17.76% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:32:59,590]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:32:59,744]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:01,112]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:08,458]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:09,101]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:13,098]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:15,523]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:18,494]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:21,375]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:27,885]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:28,717]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:28,924]\u001b[0m Trial 1430 finished with value: 15.479566333298356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012323721618690212, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21500025989203125, 'dropout_rate_Layer_2': 0.26323554972048974, 'dropout_rate_Layer_3': 0.29698425665496325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001548428580567128, 'l1_Layer_2': 0.0006186475337714691, 'l1_Layer_3': 2.2320318888017642e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.48 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 44.47 | sMAPE for Test Set is: 17.34% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:33:35,755]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:40,408]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:40,878]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:42,576]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:44,032]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:52,860]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:53,074]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:33:58,086]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:02,912]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:03,584]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:05,780]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:12,448]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:13,494]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:17,996]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.53 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 42.75 | sMAPE for Test Set is: 17.12% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:34:20,389]\u001b[0m Trial 1450 finished with value: 15.532585259274176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008783792869016059, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23451148325641227, 'dropout_rate_Layer_2': 0.052733819872481665, 'dropout_rate_Layer_3': 0.11156885555849487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00034975505994333246, 'l1_Layer_2': 5.6245622618620744e-05, 'l1_Layer_3': 0.0005234692275515109, 'n_units_Layer_1': 155, 'n_units_Layer_2': 60, 'n_units_Layer_3': 65}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:26,748]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:31,272]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:40,088]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:45,932]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:46,539]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.39 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 43.26 | sMAPE for Test Set is: 17.14% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:34:51,504]\u001b[0m Trial 1456 finished with value: 15.391076541954803 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008703610211647635, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2310167306318328, 'dropout_rate_Layer_2': 0.04193758676128259, 'dropout_rate_Layer_3': 0.12991047157891694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00030055849268032436, 'l1_Layer_2': 6.852957272559742e-05, 'l1_Layer_3': 0.00019485607616119094, 'n_units_Layer_1': 155, 'n_units_Layer_2': 60, 'n_units_Layer_3': 65}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:34:59,887]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:05,071]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:10,036]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:10,325]\u001b[0m Trial 1465 finished with value: 15.337233627219883 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021387007932294703, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19668669631837224, 'dropout_rate_Layer_2': 0.035949459961169626, 'dropout_rate_Layer_3': 0.009283420989811553, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.482483694822108e-05, 'l1_Layer_2': 0.0016167086574804623, 'l1_Layer_3': 0.0011670820285832983, 'n_units_Layer_1': 285, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.34 | sMAPE for Validation Set is: 17.82% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 43.91 | sMAPE for Test Set is: 17.16% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:35:17,089]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:20,862]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:25,213]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:25,642]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:31,430]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:32,506]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:33,238]\u001b[0m Trial 1458 finished with value: 16.016139709270195 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023732814461715004, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24591375822201914, 'dropout_rate_Layer_2': 0.05686499949401781, 'dropout_rate_Layer_3': 0.28928497024196886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00031970971883752656, 'l1_Layer_2': 0.03590253973748764, 'l1_Layer_3': 4.811353450710204e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 100, 'n_units_Layer_3': 235}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.02 | sMAPE for Validation Set is: 18.45% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 42.75 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:35:38,773]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:45,121]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:45,235]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:45,802]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:55,170]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:55,327]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:55,513]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:35:58,986]\u001b[0m Trial 1474 finished with value: 15.386408513373723 and parameters: {'n_hidden': 3, 'learning_rate': 0.001669332346879911, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20449380328253197, 'dropout_rate_Layer_2': 0.27655782237913895, 'dropout_rate_Layer_3': 0.2665418142997279, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013582584284843144, 'l1_Layer_2': 0.00042942968055275813, 'l1_Layer_3': 1.68091383004706e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.39 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 46.37 | sMAPE for Test Set is: 17.98% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:36:08,356]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:09,366]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:17,491]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:21,827]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:26,056]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:26,215]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:33,692]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:36,720]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:37,362]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:37,966]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:45,785]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:47,143]\u001b[0m Trial 1487 finished with value: 15.137317640754764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016948103757456457, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23413947391686007, 'dropout_rate_Layer_2': 0.2815007218732724, 'dropout_rate_Layer_3': 0.27008761254792624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002024903441993927, 'l1_Layer_2': 0.0004388001454050137, 'l1_Layer_3': 1.7350509170323317e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 1315 with value: 14.77893062732295.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.14 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 46.04 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 06:36:47,510]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:54,523]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:56,428]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:36:58,869]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:37:05,852]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 06:37:06,737]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-01-01, MAE is:36.09 & sMAPE is:39.02% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :36.09 & 39.02% & 0.28\n",
      "for 2022-01-02, MAE is:50.61 & sMAPE is:66.79% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :43.35 & 52.91% & 0.32\n",
      "for 2022-01-03, MAE is:35.57 & sMAPE is:70.63% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :40.75 & 58.81% & 0.39\n",
      "for 2022-01-04, MAE is:51.67 & sMAPE is:39.58% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :43.48 & 54.00% & 0.52\n",
      "for 2022-01-05, MAE is:49.66 & sMAPE is:28.56% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :44.72 & 48.92% & 0.69\n",
      "for 2022-01-06, MAE is:33.04 & sMAPE is:16.33% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :42.77 & 43.49% & 0.62\n",
      "for 2022-01-07, MAE is:10.42 & sMAPE is:4.75% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :38.15 & 37.95% & 0.55\n",
      "for 2022-01-08, MAE is:21.41 & sMAPE is:12.16% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :36.06 & 34.73% & 0.51\n",
      "for 2022-01-09, MAE is:44.34 & sMAPE is:32.08% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :36.98 & 34.43% & 0.50\n",
      "for 2022-01-10, MAE is:74.52 & sMAPE is:32.55% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :40.73 & 34.24% & 0.49\n",
      "for 2022-01-11, MAE is:20.44 & sMAPE is:7.98% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :38.89 & 31.86% & 0.47\n",
      "for 2022-01-12, MAE is:15.23 & sMAPE is:6.32% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :36.92 & 29.73% & 0.45\n",
      "for 2022-01-13, MAE is:17.30 & sMAPE is:7.68% & rMAE is:2.94 ||| daily mean of MAE & sMAPE & rMAE till now are :35.41 & 28.03% & 0.65\n",
      "for 2022-01-14, MAE is:19.24 & sMAPE is:8.87% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :34.25 & 26.66% & 0.67\n",
      "for 2022-01-15, MAE is:26.06 & sMAPE is:12.70% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :33.71 & 25.73% & 0.67\n",
      "for 2022-01-16, MAE is:13.73 & sMAPE is:6.48% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :32.46 & 24.53% & 0.64\n",
      "for 2022-01-17, MAE is:31.51 & sMAPE is:13.37% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :32.40 & 23.87% & 0.67\n",
      "for 2022-01-18, MAE is:27.79 & sMAPE is:10.75% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :32.14 & 23.14% & 0.78\n",
      "for 2022-01-19, MAE is:17.49 & sMAPE is:7.25% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :31.37 & 22.31% & 0.82\n",
      "for 2022-01-20, MAE is:19.78 & sMAPE is:8.42% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :30.79 & 21.61% & 0.84\n",
      "for 2022-01-21, MAE is:23.98 & sMAPE is:11.12% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :30.47 & 21.11% & 0.87\n",
      "for 2022-01-22, MAE is:12.35 & sMAPE is:6.24% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :29.65 & 20.44% & 0.86\n",
      "for 2022-01-23, MAE is:15.74 & sMAPE is:8.09% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :29.04 & 19.90% & 0.87\n",
      "for 2022-01-24, MAE is:31.81 & sMAPE is:13.65% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :29.16 & 19.64% & 0.89\n",
      "for 2022-01-25, MAE is:49.17 & sMAPE is:16.74% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :29.96 & 19.52% & 0.89\n",
      "for 2022-01-26, MAE is:25.31 & sMAPE is:9.53% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :29.78 & 19.14% & 0.88\n",
      "for 2022-01-27, MAE is:27.72 & sMAPE is:10.81% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :29.70 & 18.83% & 0.88\n",
      "for 2022-01-28, MAE is:26.18 & sMAPE is:10.88% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :29.58 & 18.55% & 0.87\n",
      "for 2022-01-29, MAE is:22.73 & sMAPE is:11.60% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :29.34 & 18.31% & 0.88\n",
      "for 2022-01-30, MAE is:28.03 & sMAPE is:13.70% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :29.30 & 18.15% & 0.89\n",
      "for 2022-01-31, MAE is:33.46 & sMAPE is:15.27% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :29.43 & 18.06% & 0.89\n",
      "for 2022-02-01, MAE is:36.30 & sMAPE is:15.45% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :29.65 & 17.98% & 0.87\n",
      "for 2022-02-02, MAE is:22.06 & sMAPE is:10.36% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :29.42 & 17.75% & 0.85\n",
      "for 2022-02-03, MAE is:18.07 & sMAPE is:8.21% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :29.08 & 17.47% & 0.84\n",
      "for 2022-02-04, MAE is:29.62 & sMAPE is:13.93% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :29.10 & 17.37% & 0.83\n",
      "for 2022-02-05, MAE is:18.53 & sMAPE is:10.13% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :28.80 & 17.17% & 0.83\n",
      "for 2022-02-06, MAE is:39.16 & sMAPE is:30.72% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :29.08 & 17.53% & 0.82\n",
      "for 2022-02-07, MAE is:43.99 & sMAPE is:24.45% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :29.48 & 17.71% & 0.86\n",
      "for 2022-02-08, MAE is:25.56 & sMAPE is:11.84% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :29.38 & 17.56% & 0.89\n",
      "for 2022-02-09, MAE is:19.84 & sMAPE is:10.07% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :29.14 & 17.38% & 0.90\n",
      "for 2022-02-10, MAE is:15.06 & sMAPE is:7.42% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :28.79 & 17.13% & 0.93\n",
      "for 2022-02-11, MAE is:10.32 & sMAPE is:5.09% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :28.35 & 16.85% & 0.93\n",
      "for 2022-02-12, MAE is:10.51 & sMAPE is:5.54% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :27.94 & 16.58% & 0.92\n",
      "for 2022-02-13, MAE is:29.49 & sMAPE is:20.17% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :27.97 & 16.67% & 0.92\n",
      "for 2022-02-14, MAE is:36.81 & sMAPE is:21.25% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :28.17 & 16.77% & 0.94\n",
      "for 2022-02-15, MAE is:25.65 & sMAPE is:13.47% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :28.12 & 16.70% & 0.95\n",
      "for 2022-02-16, MAE is:25.92 & sMAPE is:15.94% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :28.07 & 16.68% & 0.94\n",
      "for 2022-02-17, MAE is:28.58 & sMAPE is:31.38% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :28.08 & 16.99% & 0.93\n",
      "for 2022-02-18, MAE is:18.53 & sMAPE is:11.99% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :27.88 & 16.88% & 0.92\n",
      "for 2022-02-19, MAE is:37.82 & sMAPE is:30.91% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :28.08 & 17.16% & 0.91\n",
      "for 2022-02-20, MAE is:16.28 & sMAPE is:17.11% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :27.85 & 17.16% & 0.90\n",
      "for 2022-02-21, MAE is:40.97 & sMAPE is:29.58% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :28.10 & 17.40% & 0.91\n",
      "for 2022-02-22, MAE is:21.53 & sMAPE is:13.13% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :27.98 & 17.32% & 0.91\n",
      "for 2022-02-23, MAE is:27.49 & sMAPE is:15.86% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :27.97 & 17.29% & 0.91\n",
      "for 2022-02-24, MAE is:17.31 & sMAPE is:9.77% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :27.78 & 17.16% & 0.90\n",
      "for 2022-02-25, MAE is:67.96 & sMAPE is:30.91% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :28.49 & 17.40% & 0.89\n",
      "for 2022-02-26, MAE is:30.30 & sMAPE is:12.91% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :28.53 & 17.32% & 0.88\n",
      "for 2022-02-27, MAE is:24.26 & sMAPE is:12.46% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :28.45 & 17.24% & 0.87\n",
      "for 2022-02-28, MAE is:51.36 & sMAPE is:22.18% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :28.84 & 17.32% & 0.87\n",
      "for 2022-03-01, MAE is:54.50 & sMAPE is:22.05% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :29.27 & 17.40% & 0.86\n",
      "for 2022-03-02, MAE is:39.71 & sMAPE is:15.20% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :29.44 & 17.37% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-03, MAE is:79.63 & sMAPE is:26.10% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :30.25 & 17.51% & 0.85\n",
      "for 2022-03-04, MAE is:31.82 & sMAPE is:9.04% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :30.27 & 17.37% & 0.84\n",
      "for 2022-03-05, MAE is:32.05 & sMAPE is:9.40% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :30.30 & 17.25% & 0.83\n",
      "for 2022-03-06, MAE is:40.72 & sMAPE is:11.43% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :30.46 & 17.16% & 0.82\n",
      "for 2022-03-07, MAE is:42.65 & sMAPE is:10.51% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :30.65 & 17.06% & 0.81\n",
      "for 2022-03-08, MAE is:152.10 & sMAPE is:31.62% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :32.46 & 17.28% & 0.81\n",
      "for 2022-03-09, MAE is:75.70 & sMAPE is:15.90% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :33.10 & 17.26% & 0.80\n",
      "for 2022-03-10, MAE is:85.96 & sMAPE is:21.30% & rMAE is:3.57 ||| daily mean of MAE & sMAPE & rMAE till now are :33.86 & 17.31% & 0.84\n",
      "for 2022-03-11, MAE is:88.80 & sMAPE is:28.61% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :34.65 & 17.48% & 0.85\n",
      "for 2022-03-12, MAE is:61.37 & sMAPE is:20.56% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :35.02 & 17.52% & 0.84\n",
      "for 2022-03-13, MAE is:45.98 & sMAPE is:17.84% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :35.18 & 17.52% & 0.84\n",
      "for 2022-03-14, MAE is:61.73 & sMAPE is:19.29% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :35.54 & 17.55% & 0.83\n",
      "for 2022-03-15, MAE is:116.41 & sMAPE is:31.99% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :36.63 & 17.74% & 0.83\n",
      "for 2022-03-16, MAE is:91.48 & sMAPE is:27.81% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :37.36 & 17.88% & 0.82\n",
      "for 2022-03-17, MAE is:58.44 & sMAPE is:20.03% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :37.64 & 17.91% & 0.82\n",
      "for 2022-03-18, MAE is:39.96 & sMAPE is:15.74% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :37.67 & 17.88% & 0.82\n",
      "for 2022-03-19, MAE is:25.29 & sMAPE is:13.68% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :37.51 & 17.82% & 0.81\n",
      "for 2022-03-20, MAE is:21.52 & sMAPE is:9.29% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :37.31 & 17.72% & 0.81\n",
      "for 2022-03-21, MAE is:28.69 & sMAPE is:11.07% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :37.20 & 17.63% & 0.81\n",
      "for 2022-03-22, MAE is:33.37 & sMAPE is:13.46% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :37.15 & 17.58% & 0.81\n",
      "for 2022-03-23, MAE is:35.75 & sMAPE is:14.39% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :37.14 & 17.54% & 0.81\n",
      "for 2022-03-24, MAE is:30.53 & sMAPE is:12.09% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :37.06 & 17.48% & 0.81\n",
      "for 2022-03-25, MAE is:54.61 & sMAPE is:22.18% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :37.27 & 17.53% & 0.82\n",
      "for 2022-03-26, MAE is:25.32 & sMAPE is:11.18% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :37.13 & 17.46% & 0.82\n",
      "for 2022-03-27, MAE is:36.12 & sMAPE is:19.37% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :37.11 & 17.48% & 0.83\n",
      "for 2022-03-28, MAE is:22.82 & sMAPE is:8.58% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :36.95 & 17.38% & 0.83\n",
      "for 2022-03-29, MAE is:21.87 & sMAPE is:8.72% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :36.78 & 17.28% & 0.83\n",
      "for 2022-03-30, MAE is:53.85 & sMAPE is:18.95% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :36.97 & 17.30% & 0.83\n",
      "for 2022-03-31, MAE is:21.79 & sMAPE is:7.23% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :36.80 & 17.19% & 0.82\n",
      "for 2022-04-01, MAE is:31.71 & sMAPE is:9.93% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :36.75 & 17.11% & 0.82\n",
      "for 2022-04-02, MAE is:18.19 & sMAPE is:6.31% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :36.54 & 16.99% & 0.82\n",
      "for 2022-04-03, MAE is:37.78 & sMAPE is:12.01% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :36.56 & 16.94% & 0.81\n",
      "for 2022-04-04, MAE is:239.19 & sMAPE is:22.05% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :38.71 & 16.99% & 0.81\n",
      "for 2022-04-05, MAE is:131.24 & sMAPE is:35.36% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :39.69 & 17.18% & 0.83\n",
      "for 2022-04-06, MAE is:57.69 & sMAPE is:19.36% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :39.87 & 17.21% & 0.84\n",
      "for 2022-04-07, MAE is:57.70 & sMAPE is:23.89% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :40.06 & 17.27% & 0.84\n",
      "for 2022-04-08, MAE is:26.24 & sMAPE is:10.36% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :39.92 & 17.20% & 0.83\n",
      "for 2022-04-09, MAE is:30.50 & sMAPE is:11.98% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :39.82 & 17.15% & 0.83\n",
      "for 2022-04-10, MAE is:61.01 & sMAPE is:30.04% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :40.03 & 17.28% & 0.83\n",
      "for 2022-04-11, MAE is:128.85 & sMAPE is:44.14% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :40.91 & 17.55% & 0.83\n",
      "for 2022-04-12, MAE is:15.37 & sMAPE is:6.27% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :40.66 & 17.44% & 0.82\n",
      "for 2022-04-13, MAE is:27.27 & sMAPE is:10.78% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :40.53 & 17.37% & 0.82\n",
      "for 2022-04-14, MAE is:16.26 & sMAPE is:7.01% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :40.30 & 17.27% & 0.81\n",
      "for 2022-04-15, MAE is:36.38 & sMAPE is:16.73% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :40.26 & 17.27% & 0.81\n",
      "for 2022-04-16, MAE is:47.22 & sMAPE is:32.42% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :40.33 & 17.41% & 0.81\n",
      "for 2022-04-17, MAE is:43.37 & sMAPE is:51.00% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :40.36 & 17.72% & 0.81\n",
      "for 2022-04-18, MAE is:48.80 & sMAPE is:38.81% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :40.43 & 17.92% & 0.80\n",
      "for 2022-04-19, MAE is:38.17 & sMAPE is:19.19% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :40.41 & 17.93% & 0.81\n",
      "for 2022-04-20, MAE is:18.27 & sMAPE is:8.67% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :40.21 & 17.85% & 0.81\n",
      "for 2022-04-21, MAE is:22.21 & sMAPE is:10.39% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :40.05 & 17.78% & 0.81\n",
      "for 2022-04-22, MAE is:30.36 & sMAPE is:16.79% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :39.96 & 17.77% & 0.81\n",
      "for 2022-04-23, MAE is:28.83 & sMAPE is:17.76% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :39.86 & 17.77% & 0.81\n",
      "for 2022-04-24, MAE is:20.43 & sMAPE is:13.16% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :39.69 & 17.73% & 0.81\n",
      "for 2022-04-25, MAE is:73.44 & sMAPE is:39.26% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :39.99 & 17.92% & 0.81\n",
      "for 2022-04-26, MAE is:22.91 & sMAPE is:10.04% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :39.84 & 17.85% & 0.81\n",
      "for 2022-04-27, MAE is:16.32 & sMAPE is:7.09% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :39.64 & 17.76% & 0.81\n",
      "for 2022-04-28, MAE is:41.88 & sMAPE is:20.08% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :39.66 & 17.78% & 0.82\n",
      "for 2022-04-29, MAE is:25.58 & sMAPE is:12.04% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :39.54 & 17.73% & 0.82\n",
      "for 2022-04-30, MAE is:16.74 & sMAPE is:8.99% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :39.35 & 17.66% & 0.81\n",
      "for 2022-05-01, MAE is:22.33 & sMAPE is:12.84% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :39.21 & 17.62% & 0.81\n",
      "for 2022-05-02, MAE is:19.10 & sMAPE is:8.96% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :39.04 & 17.54% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-03, MAE is:16.91 & sMAPE is:7.85% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :38.86 & 17.47% & 0.82\n",
      "for 2022-05-04, MAE is:21.23 & sMAPE is:9.66% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :38.72 & 17.40% & 0.82\n",
      "for 2022-05-05, MAE is:16.82 & sMAPE is:7.56% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :38.55 & 17.32% & 0.83\n",
      "for 2022-05-06, MAE is:18.07 & sMAPE is:8.09% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :38.38 & 17.25% & 0.84\n",
      "for 2022-05-07, MAE is:19.81 & sMAPE is:10.74% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :38.24 & 17.20% & 0.85\n",
      "for 2022-05-08, MAE is:21.91 & sMAPE is:13.64% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :38.11 & 17.17% & 0.85\n",
      "for 2022-05-09, MAE is:32.66 & sMAPE is:16.49% & rMAE is:5.03 ||| daily mean of MAE & sMAPE & rMAE till now are :38.07 & 17.17% & 0.88\n",
      "for 2022-05-10, MAE is:13.42 & sMAPE is:6.15% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :37.88 & 17.08% & 0.88\n",
      "for 2022-05-11, MAE is:21.42 & sMAPE is:10.81% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :37.75 & 17.03% & 0.88\n",
      "for 2022-05-12, MAE is:20.69 & sMAPE is:11.54% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :37.62 & 16.99% & 0.88\n",
      "for 2022-05-13, MAE is:18.70 & sMAPE is:9.87% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :37.48 & 16.94% & 0.88\n",
      "for 2022-05-14, MAE is:22.55 & sMAPE is:12.55% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :37.37 & 16.91% & 0.88\n",
      "for 2022-05-15, MAE is:45.46 & sMAPE is:36.77% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :37.43 & 17.05% & 0.88\n",
      "for 2022-05-16, MAE is:40.77 & sMAPE is:20.46% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :37.45 & 17.08% & 0.89\n",
      "for 2022-05-17, MAE is:18.04 & sMAPE is:8.09% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :37.31 & 17.01% & 0.89\n",
      "for 2022-05-18, MAE is:20.73 & sMAPE is:9.75% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :37.19 & 16.96% & 0.89\n",
      "for 2022-05-19, MAE is:25.75 & sMAPE is:12.63% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :37.11 & 16.93% & 0.90\n",
      "for 2022-05-20, MAE is:20.24 & sMAPE is:9.29% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :36.99 & 16.87% & 0.90\n",
      "for 2022-05-21, MAE is:13.73 & sMAPE is:7.73% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :36.83 & 16.81% & 0.90\n",
      "for 2022-05-22, MAE is:26.93 & sMAPE is:16.82% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :36.76 & 16.81% & 0.90\n",
      "for 2022-05-23, MAE is:19.02 & sMAPE is:10.55% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :36.63 & 16.77% & 0.90\n",
      "for 2022-05-24, MAE is:14.20 & sMAPE is:7.24% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :36.48 & 16.70% & 0.90\n",
      "for 2022-05-25, MAE is:17.22 & sMAPE is:9.48% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :36.34 & 16.65% & 0.90\n",
      "for 2022-05-26, MAE is:16.26 & sMAPE is:10.05% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :36.21 & 16.60% & 0.89\n",
      "for 2022-05-27, MAE is:18.97 & sMAPE is:11.02% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :36.09 & 16.57% & 0.89\n",
      "for 2022-05-28, MAE is:14.08 & sMAPE is:9.74% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :35.94 & 16.52% & 0.89\n",
      "for 2022-05-29, MAE is:30.56 & sMAPE is:22.09% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :35.90 & 16.56% & 0.89\n",
      "for 2022-05-30, MAE is:42.76 & sMAPE is:21.43% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :35.95 & 16.59% & 0.90\n",
      "for 2022-05-31, MAE is:24.98 & sMAPE is:12.68% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :35.88 & 16.56% & 0.90\n",
      "for 2022-06-01, MAE is:22.19 & sMAPE is:10.84% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :35.79 & 16.53% & 0.90\n",
      "for 2022-06-02, MAE is:19.39 & sMAPE is:10.57% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :35.68 & 16.49% & 0.89\n",
      "for 2022-06-03, MAE is:31.95 & sMAPE is:17.43% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :35.66 & 16.49% & 0.89\n",
      "for 2022-06-04, MAE is:23.80 & sMAPE is:15.57% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :35.58 & 16.49% & 0.90\n",
      "for 2022-06-05, MAE is:21.00 & sMAPE is:14.78% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :35.49 & 16.48% & 0.90\n",
      "for 2022-06-06, MAE is:29.83 & sMAPE is:21.26% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :35.45 & 16.51% & 0.90\n",
      "for 2022-06-07, MAE is:17.11 & sMAPE is:9.53% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :35.33 & 16.46% & 0.89\n",
      "for 2022-06-08, MAE is:14.85 & sMAPE is:7.85% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :35.20 & 16.41% & 0.89\n",
      "for 2022-06-09, MAE is:12.94 & sMAPE is:7.29% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :35.07 & 16.35% & 0.89\n",
      "for 2022-06-10, MAE is:18.39 & sMAPE is:10.03% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :34.96 & 16.31% & 0.90\n",
      "for 2022-06-11, MAE is:25.89 & sMAPE is:15.80% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :34.91 & 16.31% & 0.90\n",
      "for 2022-06-12, MAE is:30.93 & sMAPE is:23.45% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :34.88 & 16.35% & 0.91\n",
      "for 2022-06-13, MAE is:57.63 & sMAPE is:33.05% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :35.02 & 16.46% & 0.91\n",
      "for 2022-06-14, MAE is:19.98 & sMAPE is:9.81% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :34.93 & 16.41% & 0.91\n",
      "for 2022-06-15, MAE is:34.92 & sMAPE is:15.72% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :34.93 & 16.41% & 0.91\n",
      "for 2022-06-16, MAE is:58.74 & sMAPE is:23.91% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :35.07 & 16.46% & 0.91\n",
      "for 2022-06-17, MAE is:57.45 & sMAPE is:20.67% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :35.20 & 16.48% & 0.90\n",
      "for 2022-06-18, MAE is:23.10 & sMAPE is:8.52% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :35.13 & 16.43% & 0.90\n",
      "for 2022-06-19, MAE is:52.21 & sMAPE is:31.63% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :35.23 & 16.52% & 0.90\n",
      "for 2022-06-20, MAE is:93.84 & sMAPE is:36.26% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :35.58 & 16.64% & 0.90\n",
      "for 2022-06-21, MAE is:93.18 & sMAPE is:28.44% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :35.91 & 16.71% & 0.90\n",
      "for 2022-06-22, MAE is:70.72 & sMAPE is:19.39% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :36.11 & 16.72% & 0.90\n",
      "for 2022-06-23, MAE is:36.17 & sMAPE is:10.65% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :36.11 & 16.69% & 0.90\n",
      "for 2022-06-24, MAE is:37.32 & sMAPE is:11.45% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :36.12 & 16.66% & 0.90\n",
      "for 2022-06-25, MAE is:25.89 & sMAPE is:10.94% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :36.06 & 16.63% & 0.90\n",
      "for 2022-06-26, MAE is:32.97 & sMAPE is:14.25% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :36.04 & 16.61% & 0.90\n",
      "for 2022-06-27, MAE is:56.39 & sMAPE is:18.82% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :36.16 & 16.62% & 0.90\n",
      "for 2022-06-28, MAE is:61.30 & sMAPE is:18.17% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :36.30 & 16.63% & 0.91\n",
      "for 2022-06-29, MAE is:32.72 & sMAPE is:9.11% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :36.28 & 16.59% & 0.90\n",
      "for 2022-06-30, MAE is:54.73 & sMAPE is:16.31% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :36.38 & 16.59% & 0.91\n",
      "for 2022-07-01, MAE is:33.84 & sMAPE is:10.45% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :36.37 & 16.56% & 0.91\n",
      "for 2022-07-02, MAE is:28.41 & sMAPE is:10.52% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :36.32 & 16.52% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-03, MAE is:43.88 & sMAPE is:21.67% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :36.36 & 16.55% & 0.92\n",
      "for 2022-07-04, MAE is:82.56 & sMAPE is:25.15% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :36.61 & 16.60% & 0.92\n",
      "for 2022-07-05, MAE is:28.41 & sMAPE is:7.84% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :36.57 & 16.55% & 0.92\n",
      "for 2022-07-06, MAE is:62.26 & sMAPE is:17.44% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :36.71 & 16.55% & 0.92\n",
      "for 2022-07-07, MAE is:33.82 & sMAPE is:9.24% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :36.69 & 16.52% & 0.92\n",
      "for 2022-07-08, MAE is:63.05 & sMAPE is:17.10% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :36.83 & 16.52% & 0.92\n",
      "for 2022-07-09, MAE is:42.12 & sMAPE is:12.79% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :36.86 & 16.50% & 0.92\n",
      "for 2022-07-10, MAE is:63.92 & sMAPE is:28.89% & rMAE is:2.85 ||| daily mean of MAE & sMAPE & rMAE till now are :37.00 & 16.56% & 0.93\n",
      "for 2022-07-11, MAE is:49.29 & sMAPE is:14.01% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :37.06 & 16.55% & 0.94\n",
      "for 2022-07-12, MAE is:60.77 & sMAPE is:15.05% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :37.19 & 16.54% & 0.94\n",
      "for 2022-07-13, MAE is:44.99 & sMAPE is:10.53% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :37.23 & 16.51% & 0.94\n",
      "for 2022-07-14, MAE is:26.21 & sMAPE is:6.88% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :37.17 & 16.46% & 0.94\n",
      "for 2022-07-15, MAE is:63.66 & sMAPE is:17.89% & rMAE is:2.76 ||| daily mean of MAE & sMAPE & rMAE till now are :37.31 & 16.47% & 0.95\n",
      "for 2022-07-16, MAE is:36.34 & sMAPE is:11.03% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :37.30 & 16.44% & 0.95\n",
      "for 2022-07-17, MAE is:87.01 & sMAPE is:36.69% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :37.55 & 16.54% & 0.95\n",
      "for 2022-07-18, MAE is:119.84 & sMAPE is:26.09% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :37.97 & 16.59% & 0.95\n",
      "for 2022-07-19, MAE is:83.20 & sMAPE is:16.73% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :38.19 & 16.59% & 0.95\n",
      "for 2022-07-20, MAE is:127.42 & sMAPE is:22.61% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :38.64 & 16.62% & 0.95\n",
      "for 2022-07-21, MAE is:92.38 & sMAPE is:17.50% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :38.90 & 16.63% & 0.95\n",
      "for 2022-07-22, MAE is:101.95 & sMAPE is:20.22% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :39.21 & 16.65% & 0.95\n",
      "for 2022-07-23, MAE is:84.59 & sMAPE is:21.92% & rMAE is:2.51 ||| daily mean of MAE & sMAPE & rMAE till now are :39.44 & 16.67% & 0.96\n",
      "for 2022-07-24, MAE is:34.39 & sMAPE is:10.41% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :39.41 & 16.64% & 0.96\n",
      "for 2022-07-25, MAE is:49.91 & sMAPE is:12.59% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :39.46 & 16.62% & 0.95\n",
      "for 2022-07-26, MAE is:139.03 & sMAPE is:29.24% & rMAE is:3.15 ||| daily mean of MAE & sMAPE & rMAE till now are :39.94 & 16.68% & 0.96\n",
      "for 2022-07-27, MAE is:43.62 & sMAPE is:8.98% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :39.96 & 16.64% & 0.96\n",
      "for 2022-07-28, MAE is:41.74 & sMAPE is:8.20% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :39.97 & 16.60% & 0.96\n",
      "for 2022-07-29, MAE is:60.58 & sMAPE is:11.25% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :40.07 & 16.58% & 0.96\n",
      "for 2022-07-30, MAE is:33.46 & sMAPE is:8.57% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :40.04 & 16.54% & 0.96\n",
      "for 2022-07-31, MAE is:52.70 & sMAPE is:16.71% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :40.10 & 16.54% & 0.96\n",
      "for 2022-08-01, MAE is:96.86 & sMAPE is:23.62% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :40.36 & 16.58% & 0.96\n",
      "for 2022-08-02, MAE is:47.26 & sMAPE is:10.33% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :40.39 & 16.55% & 0.96\n",
      "for 2022-08-03, MAE is:43.78 & sMAPE is:8.92% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :40.41 & 16.51% & 0.96\n",
      "for 2022-08-04, MAE is:47.97 & sMAPE is:9.87% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :40.44 & 16.48% & 0.96\n",
      "for 2022-08-05, MAE is:70.09 & sMAPE is:16.04% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :40.58 & 16.48% & 0.96\n",
      "for 2022-08-06, MAE is:53.30 & sMAPE is:19.86% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :40.64 & 16.49% & 0.96\n",
      "for 2022-08-07, MAE is:69.15 & sMAPE is:36.16% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :40.77 & 16.58% & 0.96\n",
      "for 2022-08-08, MAE is:41.51 & sMAPE is:12.30% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :40.77 & 16.56% & 0.96\n",
      "for 2022-08-09, MAE is:49.61 & sMAPE is:14.57% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :40.81 & 16.55% & 0.95\n",
      "for 2022-08-10, MAE is:39.54 & sMAPE is:12.02% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :40.81 & 16.53% & 0.95\n",
      "for 2022-08-11, MAE is:55.59 & sMAPE is:15.74% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :40.87 & 16.53% & 0.95\n",
      "for 2022-08-12, MAE is:73.93 & sMAPE is:18.46% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :41.02 & 16.54% & 0.95\n",
      "for 2022-08-13, MAE is:28.35 & sMAPE is:7.51% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :40.97 & 16.50% & 0.95\n",
      "for 2022-08-14, MAE is:31.46 & sMAPE is:9.19% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :40.92 & 16.47% & 0.94\n",
      "for 2022-08-15, MAE is:102.77 & sMAPE is:27.71% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :41.20 & 16.52% & 0.95\n",
      "for 2022-08-16, MAE is:61.87 & sMAPE is:12.87% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :41.29 & 16.50% & 0.95\n",
      "for 2022-08-17, MAE is:79.42 & sMAPE is:15.07% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :41.45 & 16.49% & 0.94\n",
      "for 2022-08-18, MAE is:31.01 & sMAPE is:5.79% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :41.41 & 16.45% & 0.94\n",
      "for 2022-08-19, MAE is:46.90 & sMAPE is:9.24% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :41.43 & 16.42% & 0.94\n",
      "for 2022-08-20, MAE is:35.15 & sMAPE is:8.14% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :41.40 & 16.38% & 0.94\n",
      "for 2022-08-21, MAE is:77.83 & sMAPE is:19.95% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :41.56 & 16.40% & 0.94\n",
      "for 2022-08-22, MAE is:89.44 & sMAPE is:17.33% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :41.76 & 16.40% & 0.94\n",
      "for 2022-08-23, MAE is:53.49 & sMAPE is:9.21% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :41.81 & 16.37% & 0.94\n",
      "for 2022-08-24, MAE is:58.08 & sMAPE is:9.40% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :41.88 & 16.34% & 0.93\n",
      "for 2022-08-25, MAE is:63.09 & sMAPE is:9.78% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :41.97 & 16.31% & 0.93\n",
      "for 2022-08-26, MAE is:82.21 & sMAPE is:12.41% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :42.14 & 16.30% & 0.93\n",
      "for 2022-08-27, MAE is:56.07 & sMAPE is:8.82% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :42.20 & 16.26% & 0.93\n",
      "for 2022-08-28, MAE is:86.55 & sMAPE is:16.83% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :42.39 & 16.27% & 0.93\n",
      "for 2022-08-29, MAE is:189.96 & sMAPE is:30.10% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :43.00 & 16.32% & 0.93\n",
      "for 2022-08-30, MAE is:64.85 & sMAPE is:9.13% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :43.09 & 16.29% & 0.93\n",
      "for 2022-08-31, MAE is:95.21 & sMAPE is:13.59% & rMAE is:3.15 ||| daily mean of MAE & sMAPE & rMAE till now are :43.30 & 16.28% & 0.94\n",
      "for 2022-09-01, MAE is:53.83 & sMAPE is:8.61% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :43.35 & 16.25% & 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-02, MAE is:102.05 & sMAPE is:18.24% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :43.59 & 16.26% & 0.94\n",
      "for 2022-09-03, MAE is:71.78 & sMAPE is:17.01% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :43.70 & 16.26% & 0.94\n",
      "for 2022-09-04, MAE is:84.02 & sMAPE is:26.37% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :43.86 & 16.30% & 0.94\n",
      "for 2022-09-05, MAE is:55.51 & sMAPE is:15.48% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :43.91 & 16.30% & 0.93\n",
      "for 2022-09-06, MAE is:42.34 & sMAPE is:8.77% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :43.90 & 16.27% & 0.93\n",
      "for 2022-09-07, MAE is:61.43 & sMAPE is:12.97% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :43.97 & 16.26% & 0.93\n",
      "for 2022-09-08, MAE is:43.54 & sMAPE is:10.38% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :43.97 & 16.23% & 0.93\n",
      "for 2022-09-09, MAE is:64.35 & sMAPE is:19.02% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :44.05 & 16.24% & 0.92\n",
      "for 2022-09-10, MAE is:62.42 & sMAPE is:17.57% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :44.13 & 16.25% & 0.93\n",
      "for 2022-09-11, MAE is:39.51 & sMAPE is:11.02% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :44.11 & 16.23% & 0.92\n",
      "for 2022-09-12, MAE is:48.48 & sMAPE is:12.22% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :44.12 & 16.21% & 0.92\n",
      "for 2022-09-13, MAE is:67.93 & sMAPE is:16.08% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :44.22 & 16.21% & 0.92\n",
      "for 2022-09-14, MAE is:58.35 & sMAPE is:13.17% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :44.27 & 16.20% & 0.92\n",
      "for 2022-09-15, MAE is:42.61 & sMAPE is:10.36% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :44.27 & 16.18% & 0.92\n",
      "for 2022-09-16, MAE is:56.96 & sMAPE is:14.50% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :44.32 & 16.17% & 0.92\n",
      "for 2022-09-17, MAE is:82.96 & sMAPE is:32.41% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :44.46 & 16.23% & 0.92\n",
      "for 2022-09-18, MAE is:42.22 & sMAPE is:25.36% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :44.46 & 16.27% & 0.92\n",
      "for 2022-09-19, MAE is:58.13 & sMAPE is:19.65% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :44.51 & 16.28% & 0.92\n",
      "for 2022-09-20, MAE is:67.38 & sMAPE is:18.62% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :44.59 & 16.29% & 0.92\n",
      "for 2022-09-21, MAE is:55.57 & sMAPE is:14.68% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :44.64 & 16.29% & 0.92\n",
      "for 2022-09-22, MAE is:48.68 & sMAPE is:12.03% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :44.65 & 16.27% & 0.92\n",
      "for 2022-09-23, MAE is:36.30 & sMAPE is:9.14% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :44.62 & 16.24% & 0.92\n",
      "for 2022-09-24, MAE is:31.52 & sMAPE is:9.35% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :44.57 & 16.22% & 0.91\n",
      "for 2022-09-25, MAE is:41.69 & sMAPE is:15.47% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :44.56 & 16.21% & 0.91\n",
      "for 2022-09-26, MAE is:62.50 & sMAPE is:24.12% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :44.63 & 16.24% & 0.91\n",
      "for 2022-09-27, MAE is:81.82 & sMAPE is:23.78% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :44.76 & 16.27% & 0.91\n",
      "for 2022-09-28, MAE is:86.95 & sMAPE is:23.60% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :44.92 & 16.30% & 0.92\n",
      "for 2022-09-29, MAE is:91.25 & sMAPE is:20.33% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :45.09 & 16.31% & 0.92\n",
      "for 2022-09-30, MAE is:108.07 & sMAPE is:30.06% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :45.32 & 16.36% & 0.92\n",
      "for 2022-10-01, MAE is:37.81 & sMAPE is:29.75% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :45.29 & 16.41% & 0.92\n",
      "for 2022-10-02, MAE is:63.80 & sMAPE is:32.69% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :45.36 & 16.47% & 0.92\n",
      "for 2022-10-03, MAE is:46.19 & sMAPE is:16.41% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :45.36 & 16.47% & 0.92\n",
      "for 2022-10-04, MAE is:67.00 & sMAPE is:21.95% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :45.44 & 16.49% & 0.92\n",
      "for 2022-10-05, MAE is:70.48 & sMAPE is:28.20% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :45.53 & 16.53% & 0.92\n",
      "for 2022-10-06, MAE is:50.77 & sMAPE is:19.50% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :45.55 & 16.54% & 0.92\n",
      "for 2022-10-07, MAE is:53.68 & sMAPE is:20.30% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :45.58 & 16.56% & 0.92\n",
      "for 2022-10-08, MAE is:37.41 & sMAPE is:17.93% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :45.55 & 16.56% & 0.91\n",
      "for 2022-10-09, MAE is:48.48 & sMAPE is:29.03% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :45.56 & 16.61% & 0.91\n",
      "for 2022-10-10, MAE is:26.07 & sMAPE is:12.95% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :45.49 & 16.59% & 0.91\n",
      "for 2022-10-11, MAE is:66.22 & sMAPE is:24.96% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :45.57 & 16.62% & 0.91\n",
      "for 2022-10-12, MAE is:51.30 & sMAPE is:16.70% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :45.59 & 16.62% & 0.91\n",
      "for 2022-10-13, MAE is:30.59 & sMAPE is:12.06% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :45.53 & 16.61% & 0.91\n",
      "for 2022-10-14, MAE is:44.64 & sMAPE is:18.28% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :45.53 & 16.61% & 0.92\n",
      "for 2022-10-15, MAE is:31.59 & sMAPE is:18.51% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :45.48 & 16.62% & 0.91\n",
      "for 2022-10-16, MAE is:32.69 & sMAPE is:25.05% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :45.44 & 16.65% & 0.91\n",
      "for 2022-10-17, MAE is:18.73 & sMAPE is:11.15% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :45.35 & 16.63% & 0.91\n",
      "for 2022-10-18, MAE is:33.68 & sMAPE is:17.43% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :45.31 & 16.63% & 0.91\n",
      "for 2022-10-19, MAE is:30.97 & sMAPE is:19.15% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :45.26 & 16.64% & 0.91\n",
      "for 2022-10-20, MAE is:26.79 & sMAPE is:19.28% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :45.19 & 16.65% & 0.91\n",
      "for 2022-10-21, MAE is:22.02 & sMAPE is:15.67% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :45.11 & 16.65% & 0.90\n",
      "for 2022-10-22, MAE is:12.26 & sMAPE is:9.42% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :45.00 & 16.62% & 0.90\n",
      "for 2022-10-23, MAE is:29.74 & sMAPE is:28.56% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :44.95 & 16.66% & 0.90\n",
      "for 2022-10-24, MAE is:31.53 & sMAPE is:32.83% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :44.91 & 16.72% & 0.90\n",
      "for 2022-10-25, MAE is:22.05 & sMAPE is:19.84% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :44.83 & 16.73% & 0.90\n",
      "for 2022-10-26, MAE is:19.29 & sMAPE is:16.46% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :44.74 & 16.73% & 0.90\n",
      "for 2022-10-27, MAE is:17.30 & sMAPE is:14.96% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :44.65 & 16.72% & 0.89\n",
      "for 2022-10-28, MAE is:22.50 & sMAPE is:18.36% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :44.58 & 16.73% & 0.89\n",
      "for 2022-10-29, MAE is:10.74 & sMAPE is:10.56% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :44.47 & 16.71% & 0.89\n",
      "for 2022-10-30, MAE is:18.63 & sMAPE is:17.12% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :44.38 & 16.71% & 0.89\n",
      "for 2022-10-31, MAE is:20.46 & sMAPE is:14.78% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :44.30 & 16.70% & 0.89\n",
      "for 2022-11-01, MAE is:14.59 & sMAPE is:17.37% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :44.21 & 16.70% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-02, MAE is:26.60 & sMAPE is:26.95% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :44.15 & 16.74% & 0.89\n",
      "for 2022-11-03, MAE is:12.53 & sMAPE is:10.09% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :44.04 & 16.71% & 0.89\n",
      "for 2022-11-04, MAE is:71.27 & sMAPE is:47.68% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :44.13 & 16.82% & 0.89\n",
      "for 2022-11-05, MAE is:40.20 & sMAPE is:24.84% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :44.12 & 16.84% & 0.89\n",
      "for 2022-11-06, MAE is:14.82 & sMAPE is:13.30% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :44.03 & 16.83% & 0.89\n",
      "for 2022-11-07, MAE is:33.02 & sMAPE is:27.33% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :43.99 & 16.86% & 0.89\n",
      "for 2022-11-08, MAE is:16.13 & sMAPE is:14.21% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :43.90 & 16.86% & 0.89\n",
      "for 2022-11-09, MAE is:18.00 & sMAPE is:12.89% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :43.82 & 16.84% & 0.89\n",
      "for 2022-11-10, MAE is:21.29 & sMAPE is:13.51% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :43.75 & 16.83% & 0.89\n",
      "for 2022-11-11, MAE is:17.22 & sMAPE is:12.13% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :43.66 & 16.82% & 0.89\n",
      "for 2022-11-12, MAE is:31.19 & sMAPE is:22.07% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :43.62 & 16.83% & 0.89\n",
      "for 2022-11-13, MAE is:15.91 & sMAPE is:10.45% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :43.54 & 16.81% & 0.89\n",
      "for 2022-11-14, MAE is:41.09 & sMAPE is:21.92% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :43.53 & 16.83% & 0.89\n",
      "for 2022-11-15, MAE is:22.35 & sMAPE is:12.46% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :43.46 & 16.82% & 0.89\n",
      "for 2022-11-16, MAE is:37.56 & sMAPE is:22.92% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :43.44 & 16.83% & 0.89\n",
      "for 2022-11-17, MAE is:35.96 & sMAPE is:24.83% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :43.42 & 16.86% & 0.89\n",
      "for 2022-11-18, MAE is:47.33 & sMAPE is:21.14% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :43.43 & 16.87% & 0.89\n",
      "for 2022-11-19, MAE is:15.99 & sMAPE is:7.49% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :43.35 & 16.84% & 0.89\n",
      "for 2022-11-20, MAE is:20.42 & sMAPE is:10.09% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :43.28 & 16.82% & 0.88\n",
      "for 2022-11-21, MAE is:37.47 & sMAPE is:16.32% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :43.26 & 16.82% & 0.88\n",
      "for 2022-11-22, MAE is:25.91 & sMAPE is:15.59% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :43.21 & 16.82% & 0.88\n",
      "for 2022-11-23, MAE is:45.33 & sMAPE is:22.76% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :43.21 & 16.84% & 0.88\n",
      "for 2022-11-24, MAE is:51.61 & sMAPE is:22.99% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :43.24 & 16.85% & 0.88\n",
      "for 2022-11-25, MAE is:33.96 & sMAPE is:13.53% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :43.21 & 16.84% & 0.89\n",
      "for 2022-11-26, MAE is:29.41 & sMAPE is:12.43% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :43.17 & 16.83% & 0.89\n",
      "for 2022-11-27, MAE is:26.11 & sMAPE is:15.52% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :43.12 & 16.83% & 0.88\n",
      "for 2022-11-28, MAE is:98.22 & sMAPE is:35.72% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :43.28 & 16.88% & 0.89\n",
      "for 2022-11-29, MAE is:65.63 & sMAPE is:17.63% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :43.35 & 16.89% & 0.88\n",
      "for 2022-11-30, MAE is:71.62 & sMAPE is:18.08% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :43.43 & 16.89% & 0.88\n",
      "for 2022-12-01, MAE is:37.47 & sMAPE is:9.74% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :43.42 & 16.87% & 0.88\n",
      "for 2022-12-02, MAE is:30.19 & sMAPE is:8.26% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :43.38 & 16.84% & 0.88\n",
      "for 2022-12-03, MAE is:26.20 & sMAPE is:7.92% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :43.33 & 16.82% & 0.88\n",
      "for 2022-12-04, MAE is:18.02 & sMAPE is:5.68% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :43.25 & 16.78% & 0.88\n",
      "for 2022-12-05, MAE is:38.46 & sMAPE is:11.28% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :43.24 & 16.77% & 0.87\n",
      "for 2022-12-06, MAE is:90.73 & sMAPE is:23.37% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :43.38 & 16.79% & 0.88\n",
      "for 2022-12-07, MAE is:49.70 & sMAPE is:11.94% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :43.39 & 16.77% & 0.88\n",
      "for 2022-12-08, MAE is:28.07 & sMAPE is:6.81% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :43.35 & 16.74% & 0.88\n",
      "for 2022-12-09, MAE is:70.95 & sMAPE is:16.39% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :43.43 & 16.74% & 0.88\n",
      "for 2022-12-10, MAE is:21.06 & sMAPE is:5.44% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :43.37 & 16.71% & 0.88\n",
      "for 2022-12-11, MAE is:23.96 & sMAPE is:6.88% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :43.31 & 16.68% & 0.88\n",
      "for 2022-12-12, MAE is:105.63 & sMAPE is:23.41% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :43.49 & 16.70% & 0.88\n",
      "for 2022-12-13, MAE is:70.75 & sMAPE is:15.19% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :43.57 & 16.70% & 0.88\n",
      "for 2022-12-14, MAE is:54.33 & sMAPE is:11.74% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :43.60 & 16.68% & 0.88\n",
      "for 2022-12-15, MAE is:34.14 & sMAPE is:8.69% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :43.57 & 16.66% & 0.88\n",
      "for 2022-12-16, MAE is:56.12 & sMAPE is:13.52% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :43.61 & 16.65% & 0.88\n",
      "for 2022-12-17, MAE is:71.40 & sMAPE is:21.94% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :43.69 & 16.67% & 0.88\n",
      "for 2022-12-18, MAE is:33.92 & sMAPE is:14.97% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :43.66 & 16.66% & 0.88\n",
      "for 2022-12-19, MAE is:23.22 & sMAPE is:14.67% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :43.60 & 16.65% & 0.88\n",
      "for 2022-12-20, MAE is:27.10 & sMAPE is:16.08% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :43.55 & 16.65% & 0.88\n",
      "for 2022-12-21, MAE is:36.57 & sMAPE is:20.42% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :43.53 & 16.66% & 0.88\n",
      "for 2022-12-22, MAE is:58.16 & sMAPE is:38.91% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :43.58 & 16.73% & 0.87\n",
      "for 2022-12-23, MAE is:40.99 & sMAPE is:30.74% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :43.57 & 16.77% & 0.87\n",
      "for 2022-12-24, MAE is:28.77 & sMAPE is:27.97% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :43.53 & 16.80% & 0.87\n",
      "for 2022-12-25, MAE is:22.96 & sMAPE is:24.50% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :43.47 & 16.82% & 0.87\n",
      "for 2022-12-26, MAE is:41.08 & sMAPE is:59.43% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :43.46 & 16.94% & 0.87\n",
      "for 2022-12-27, MAE is:13.68 & sMAPE is:12.15% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :43.38 & 16.92% & 0.86\n",
      "for 2022-12-28, MAE is:50.45 & sMAPE is:80.91% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :43.40 & 17.10% & 0.86\n",
      "for 2022-12-29, MAE is:41.50 & sMAPE is:110.47% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :43.40 & 17.36% & 0.86\n",
      "for 2022-12-30, MAE is:44.85 & sMAPE is:118.66% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :43.40 & 17.64% & 0.86\n",
      "for 2022-12-31, MAE is:17.47 & sMAPE is:160.37% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :43.33 & 18.03% & 0.86\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:20:09,103]\u001b[0m A new study created in RDB with name: FR_2023\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 111.82 | sMAPE for Validation Set is: 42.16% | rMAE for Validation Set is: 1.54\n",
      "MAE for Test Set is: 30.45 | sMAPE for Test Set is: 30.05% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:20:43,153]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 71.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:20:43,194]\u001b[0m Trial 2 finished with value: 111.82204298426984 and parameters: {'n_hidden': 3, 'learning_rate': 0.09391593388832317, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022260606717898448, 'dropout_rate_Layer_2': 0.11203306522762345, 'dropout_rate_Layer_3': 0.10035179317375774, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0027564882808079182, 'l1_Layer_2': 0.00581843409532031, 'l1_Layer_3': 0.010525100825617315, 'n_units_Layer_1': 300, 'n_units_Layer_2': 65, 'n_units_Layer_3': 205}. Best is trial 2 with value: 111.82204298426984.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:20:48,481]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:20:50,334]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:20:54,620]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:20:55,147]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:20:59,203]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:20:59,764]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:04,503]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:07,552]\u001b[0m Trial 1 finished with value: 91.72250143110641 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029136125407272133, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09310726340666653, 'dropout_rate_Layer_2': 0.10881409564613027, 'dropout_rate_Layer_3': 0.21853718936828745, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.81923947081281e-05, 'l1_Layer_2': 0.0009678360759140635, 'l1_Layer_3': 0.005002227092227988, 'n_units_Layer_1': 235, 'n_units_Layer_2': 175, 'n_units_Layer_3': 155}. Best is trial 1 with value: 91.72250143110641.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 91.72 | sMAPE for Validation Set is: 32.83% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 23.24 | sMAPE for Test Set is: 26.72% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:21:09,042]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:13,237]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:23,689]\u001b[0m Trial 3 finished with value: 64.50254640163656 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007506992746797114, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18987688819790394, 'dropout_rate_Layer_2': 0.3506925688488191, 'dropout_rate_Layer_3': 0.19141190216152065, 'dropout_rate_Layer_4': 0.3412648187748739, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.705506033490135e-05, 'l1_Layer_2': 0.0022357706221360707, 'l1_Layer_3': 0.0034041461463573588, 'l1_Layer_4': 1.4567826419769409e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 110, 'n_units_Layer_3': 265, 'n_units_Layer_4': 180}. Best is trial 3 with value: 64.50254640163656.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 64.50 | sMAPE for Validation Set is: 23.16% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 25.00 | sMAPE for Test Set is: 26.19% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:21:27,950]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:28,375]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:39,393]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:41,406]\u001b[0m Trial 15 finished with value: 231.5859123894178 and parameters: {'n_hidden': 4, 'learning_rate': 0.0045082162151368335, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15525634576637712, 'dropout_rate_Layer_2': 0.19199334172383514, 'dropout_rate_Layer_3': 0.06907566389158522, 'dropout_rate_Layer_4': 0.17952445363974132, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.000817081218032495, 'l1_Layer_2': 5.744698808604951e-05, 'l1_Layer_3': 1.205164428681308e-05, 'l1_Layer_4': 0.06035677169196276, 'n_units_Layer_1': 170, 'n_units_Layer_2': 295, 'n_units_Layer_3': 245, 'n_units_Layer_4': 55}. Best is trial 3 with value: 64.50254640163656.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 231.59 | sMAPE for Validation Set is: 132.52% | rMAE for Validation Set is: 3.18\n",
      "MAE for Test Set is: 68.01 | sMAPE for Test Set is: 82.63% | rMAE for Test Set is: 2.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:21:46,093]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:47,447]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:50,966]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:54,268]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:55,599]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:21:59,136]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:01,787]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:06,358]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:10,497]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:10,904]\u001b[0m Trial 12 finished with value: 79.02087551806892 and parameters: {'n_hidden': 4, 'learning_rate': 0.001059690641140837, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36806544140912156, 'dropout_rate_Layer_2': 0.23477676742345788, 'dropout_rate_Layer_3': 0.3297034423539866, 'dropout_rate_Layer_4': 0.2308557166543652, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005769152073976428, 'l1_Layer_2': 1.273438477193e-05, 'l1_Layer_3': 1.1631363360800246e-05, 'l1_Layer_4': 0.011030380247398849, 'n_units_Layer_1': 80, 'n_units_Layer_2': 180, 'n_units_Layer_3': 70, 'n_units_Layer_4': 135}. Best is trial 3 with value: 64.50254640163656.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 79.02 | sMAPE for Validation Set is: 28.45% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 36.63 | sMAPE for Test Set is: 32.48% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:22:17,530]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:19,566]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:23,451]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:26,370]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:26,485]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:31,853]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:34,779]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:36,603]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:41,123]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:42,820]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:22:47,183]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:00,821]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:05,037]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:08,454]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:10,364]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:16,342]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:20,102]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:20,895]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:22,251]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:25,175]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:32,717]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:35,399]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:37,311]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:42,019]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:42,484]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:47,340]\u001b[0m Trial 25 finished with value: 49.91036630935952 and parameters: {'n_hidden': 3, 'learning_rate': 0.010030395707578141, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3500845139237653, 'dropout_rate_Layer_2': 0.23172591218768954, 'dropout_rate_Layer_3': 0.3821298672306236, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023826837256589768, 'l1_Layer_2': 8.83274935616243e-05, 'l1_Layer_3': 0.009017314493625694, 'n_units_Layer_1': 220, 'n_units_Layer_2': 110, 'n_units_Layer_3': 100}. Best is trial 25 with value: 49.91036630935952.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.91 | sMAPE for Validation Set is: 21.69% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 26.83 | sMAPE for Test Set is: 32.44% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:23:49,904]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:53,882]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:55,167]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:23:56,262]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:00,589]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:03,515]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:04,208]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:06,351]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:10,765]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:11,126]\u001b[0m Trial 53 finished with value: 57.82255141686238 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012264991130419055, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1442575068167823, 'dropout_rate_Layer_2': 0.30568863340420904, 'dropout_rate_Layer_3': 0.14678192476827917, 'dropout_rate_Layer_4': 0.3037786556870573, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.9492892617398546e-05, 'l1_Layer_2': 0.00025734542928968065, 'l1_Layer_3': 0.0003879984078349909, 'l1_Layer_4': 8.469969099327537e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 225, 'n_units_Layer_3': 80, 'n_units_Layer_4': 270}. Best is trial 25 with value: 49.91036630935952.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.82 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 21.83 | sMAPE for Test Set is: 26.68% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:24:18,237]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:32,292]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:38,941]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:43,275]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:44,047]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:47,513]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:48,869]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:50,887]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:24:59,154]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:25:00,753]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:25:01,353]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:25:03,445]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:25:08,310]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:25:17,514]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:25:25,131]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:25:28,572]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:25:35,387]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:25:37,223]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:25:52,220]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:01,944]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:05,242]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:13,956]\u001b[0m Trial 81 finished with value: 42.35056680687313 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036327204175261242, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1274562073385982, 'dropout_rate_Layer_2': 0.20711479013815354, 'dropout_rate_Layer_3': 0.1498452787749335, 'dropout_rate_Layer_4': 0.3306679431902966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.453967658983676e-05, 'l1_Layer_2': 0.002033881074761864, 'l1_Layer_3': 0.03565113254481634, 'l1_Layer_4': 0.0011241554179252835, 'n_units_Layer_1': 110, 'n_units_Layer_2': 210, 'n_units_Layer_3': 100, 'n_units_Layer_4': 280}. Best is trial 81 with value: 42.35056680687313.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:14,069]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.35 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 19.83 | sMAPE for Test Set is: 25.00% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:26:17,202]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:24,068]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:24,292]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:24,324]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:25,471]\u001b[0m Trial 83 finished with value: 44.51214804826392 and parameters: {'n_hidden': 4, 'learning_rate': 0.003166343769569517, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13125650272968498, 'dropout_rate_Layer_2': 0.2583085424485841, 'dropout_rate_Layer_3': 0.14623467305089707, 'dropout_rate_Layer_4': 0.33958775552526066, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00016952602342209464, 'l1_Layer_2': 0.002033029268056276, 'l1_Layer_3': 0.036519781390675285, 'l1_Layer_4': 0.0012650227207604413, 'n_units_Layer_1': 115, 'n_units_Layer_2': 300, 'n_units_Layer_3': 100, 'n_units_Layer_4': 280}. Best is trial 81 with value: 42.35056680687313.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.51 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 22.42 | sMAPE for Test Set is: 28.28% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:26:36,532]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:36,825]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:42,463]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:42,774]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:51,876]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:26:58,356]\u001b[0m Trial 94 finished with value: 74.5286731754557 and parameters: {'n_hidden': 4, 'learning_rate': 0.001710545432097241, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32034896103488697, 'dropout_rate_Layer_2': 0.12798539170676437, 'dropout_rate_Layer_3': 0.2850829441450514, 'dropout_rate_Layer_4': 0.030692827438806025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07700142738714502, 'l1_Layer_2': 7.480574033071761e-05, 'l1_Layer_3': 0.00019328278603687992, 'l1_Layer_4': 0.05511096778389037, 'n_units_Layer_1': 275, 'n_units_Layer_2': 145, 'n_units_Layer_3': 170, 'n_units_Layer_4': 180}. Best is trial 81 with value: 42.35056680687313.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.53 | sMAPE for Validation Set is: 26.38% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 33.48 | sMAPE for Test Set is: 31.09% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:27:00,327]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:06,756]\u001b[0m Trial 95 finished with value: 37.383199268191 and parameters: {'n_hidden': 3, 'learning_rate': 0.007649232417229372, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15006711145567378, 'dropout_rate_Layer_2': 0.32316105823277386, 'dropout_rate_Layer_3': 0.08530594844819961, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042723021489486754, 'l1_Layer_2': 0.001159932531779135, 'l1_Layer_3': 0.02736504190093945, 'n_units_Layer_1': 125, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155}. Best is trial 95 with value: 37.383199268191.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.38 | sMAPE for Validation Set is: 15.33% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.21 | sMAPE for Test Set is: 21.05% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:27:12,865]\u001b[0m Trial 98 finished with value: 39.12609050426181 and parameters: {'n_hidden': 3, 'learning_rate': 0.002689576119710956, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1543425465133253, 'dropout_rate_Layer_2': 0.16778076407489104, 'dropout_rate_Layer_3': 0.08068531177072417, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000961077538089574, 'l1_Layer_2': 0.003802904777966311, 'l1_Layer_3': 0.02262438099751734, 'n_units_Layer_1': 220, 'n_units_Layer_2': 165, 'n_units_Layer_3': 155}. Best is trial 95 with value: 37.383199268191.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.13 | sMAPE for Validation Set is: 15.91% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 16.54 | sMAPE for Test Set is: 21.46% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:27:15,507]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:19,915]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:22,887]\u001b[0m Trial 101 finished with value: 64.70017913824131 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021647156258803525, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22254024260856026, 'dropout_rate_Layer_2': 0.12890079554726222, 'dropout_rate_Layer_3': 0.2520851946341691, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05062871773576376, 'l1_Layer_2': 0.00011196839124044953, 'l1_Layer_3': 0.00037880689620041556, 'n_units_Layer_1': 255, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210}. Best is trial 95 with value: 37.383199268191.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 64.70 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 22.97 | sMAPE for Test Set is: 24.73% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:27:23,331]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:33,632]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:33,642]\u001b[0m Trial 102 finished with value: 58.47054595545018 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022878626980370772, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22810978906024587, 'dropout_rate_Layer_2': 0.11560481476726783, 'dropout_rate_Layer_3': 0.24962144243714982, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0740308972071158, 'l1_Layer_2': 9.83926890930877e-05, 'l1_Layer_3': 0.00028447191162192075, 'n_units_Layer_1': 255, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210}. Best is trial 95 with value: 37.383199268191.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.47 | sMAPE for Validation Set is: 21.16% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 17.84 | sMAPE for Test Set is: 22.29% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:27:39,682]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:40,016]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:44,213]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:45,542]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:46,170]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:48,792]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:53,345]\u001b[0m Trial 106 finished with value: 37.13483087047074 and parameters: {'n_hidden': 3, 'learning_rate': 0.00998871974741017, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15644804217628305, 'dropout_rate_Layer_2': 0.27892854399581435, 'dropout_rate_Layer_3': 0.03977857385273716, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001013579681242268, 'l1_Layer_2': 0.0014497396612946224, 'l1_Layer_3': 0.054896730496896744, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 170}. Best is trial 106 with value: 37.13483087047074.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.13 | sMAPE for Validation Set is: 15.33% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 17.30 | sMAPE for Test Set is: 21.82% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:27:55,691]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:59,578]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:27:59,798]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:03,342]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:06,934]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:07,067]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:07,442]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:14,510]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:17,208]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:17,437]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:18,035]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:25,339]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:25,499]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:25,939]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:34,504]\u001b[0m Trial 114 finished with value: 36.89328984646824 and parameters: {'n_hidden': 3, 'learning_rate': 0.002674829995087887, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10899329786302084, 'dropout_rate_Layer_2': 0.32319329595641116, 'dropout_rate_Layer_3': 0.0765608621372667, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015370619360515995, 'l1_Layer_2': 0.0016063565523416795, 'l1_Layer_3': 0.0031675730523323493, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 115}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:34,634]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.89 | sMAPE for Validation Set is: 15.31% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.10 | sMAPE for Test Set is: 21.17% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:28:37,102]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:40,403]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:40,886]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:47,503]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:51,261]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:51,366]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:56,554]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:57,243]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:28:57,288]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:02,238]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:04,468]\u001b[0m Trial 131 finished with value: 63.24332744548662 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012382389572063157, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21800127683938572, 'dropout_rate_Layer_2': 0.14987157670305545, 'dropout_rate_Layer_3': 0.23810390174116133, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03513333967056082, 'l1_Layer_2': 0.00020318506377107426, 'l1_Layer_3': 0.0004668624593342522, 'n_units_Layer_1': 265, 'n_units_Layer_2': 85, 'n_units_Layer_3': 225}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 63.24 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 20.11 | sMAPE for Test Set is: 23.74% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:29:06,789]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:12,853]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:13,449]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:18,846]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:20,970]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:28,902]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:33,130]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:37,069]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:37,745]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:39,900]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:45,132]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:49,618]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:29:58,338]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:06,556]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:09,854]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:10,727]\u001b[0m Trial 156 finished with value: 43.426368848784676 and parameters: {'n_hidden': 3, 'learning_rate': 0.01353612487832268, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1707674338472761, 'dropout_rate_Layer_2': 0.2070535967027912, 'dropout_rate_Layer_3': 0.36306563753447424, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03371122676718592, 'l1_Layer_2': 0.00021099427312587873, 'l1_Layer_3': 0.00040685048534805477, 'n_units_Layer_1': 225, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.43 | sMAPE for Validation Set is: 17.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.85 | sMAPE for Test Set is: 24.85% | rMAE for Test Set is: 0.70\n",
      "MAE for Validation Set is: 55.90 | sMAPE for Validation Set is: 20.33% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 19.15 | sMAPE for Test Set is: 22.62% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:30:10,889]\u001b[0m Trial 147 finished with value: 55.89934190980106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010798423352943046, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18538627700714522, 'dropout_rate_Layer_2': 0.16634567084785942, 'dropout_rate_Layer_3': 0.33321350698238894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.036943670511482694, 'l1_Layer_2': 3.2488701944478466e-05, 'l1_Layer_3': 7.09808998290684e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:11,679]\u001b[0m Trial 155 finished with value: 39.92722028021928 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006425954031088959, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34531443475573287, 'dropout_rate_Layer_2': 0.21430443725985893, 'dropout_rate_Layer_3': 0.36453801474971137, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.28750846882398e-05, 'l1_Layer_2': 0.0002608026107258864, 'l1_Layer_3': 0.001120355996403477, 'n_units_Layer_1': 225, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.93 | sMAPE for Validation Set is: 16.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 17.93 | sMAPE for Test Set is: 22.17% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:30:18,569]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:21,025]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:21,264]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:21,459]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:25,814]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:29,831]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:39,830]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:44,208]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:48,541]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:53,558]\u001b[0m Trial 164 finished with value: 40.44642113606579 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006072195159365952, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10125574751484792, 'dropout_rate_Layer_2': 0.29492458492586476, 'dropout_rate_Layer_3': 0.3253142526141433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.424616521409339e-05, 'l1_Layer_2': 0.00031403380223517783, 'l1_Layer_3': 0.0034676502742104188, 'n_units_Layer_1': 200, 'n_units_Layer_2': 100, 'n_units_Layer_3': 265}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:30:53,592]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.45 | sMAPE for Validation Set is: 16.43% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 19.33 | sMAPE for Test Set is: 23.04% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:30:58,064]\u001b[0m Trial 166 finished with value: 52.82965328356852 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005096443588488219, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17577929214121132, 'dropout_rate_Layer_2': 0.25995818038938423, 'dropout_rate_Layer_3': 0.32651877397629026, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.715392220888601e-05, 'l1_Layer_2': 0.000257560999050091, 'l1_Layer_3': 2.9745158916679316e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 105, 'n_units_Layer_3': 270}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.83 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 22.60 | sMAPE for Test Set is: 25.13% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:31:00,265]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:03,072]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:04,944]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:05,343]\u001b[0m Trial 165 finished with value: 38.96963459730593 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005183230428577626, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17204995720061902, 'dropout_rate_Layer_2': 0.2591809857256885, 'dropout_rate_Layer_3': 0.3311422591758533, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9680650181834043e-05, 'l1_Layer_2': 0.0002514451311327568, 'l1_Layer_3': 3.1009093404266175e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 140, 'n_units_Layer_3': 265}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.97 | sMAPE for Validation Set is: 15.87% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.28 | sMAPE for Test Set is: 21.52% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:31:06,004]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:15,901]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:17,657]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:18,166]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:21,714]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:25,911]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:26,414]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:31,756]\u001b[0m Trial 175 finished with value: 88.36775652896092 and parameters: {'n_hidden': 3, 'learning_rate': 0.02106445144806589, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.100307046651884, 'dropout_rate_Layer_2': 0.3136995121181872, 'dropout_rate_Layer_3': 0.31279511090337075, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.9131897871732103e-05, 'l1_Layer_2': 0.00042387873524353146, 'l1_Layer_3': 0.003474912299033825, 'n_units_Layer_1': 195, 'n_units_Layer_2': 145, 'n_units_Layer_3': 280}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 88.37 | sMAPE for Validation Set is: 31.83% | rMAE for Validation Set is: 1.21\n",
      "MAE for Test Set is: 40.84 | sMAPE for Test Set is: 35.77% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:31:32,084]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:36,205]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:39,403]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:40,993]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:41,532]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:46,766]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:47,099]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:52,815]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:31:53,575]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:19,312]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:22,647]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:25,065]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:26,984]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:29,567]\u001b[0m Trial 180 finished with value: 37.73511165849767 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007543199096587041, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1041111998555737, 'dropout_rate_Layer_2': 0.3101304769361311, 'dropout_rate_Layer_3': 0.3445277968778239, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1823399421675785e-05, 'l1_Layer_2': 0.0008465081593875402, 'l1_Layer_3': 0.002982307757862563, 'n_units_Layer_1': 200, 'n_units_Layer_2': 210, 'n_units_Layer_3': 260}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.74 | sMAPE for Validation Set is: 15.51% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.94 | sMAPE for Test Set is: 20.80% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:32:32,614]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:35,230]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:35,670]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:39,826]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:42,402]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:45,441]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:46,950]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:51,059]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:54,694]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:32:58,150]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:33:04,638]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:33:13,218]\u001b[0m Trial 198 finished with value: 37.63464890641873 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007460246367803306, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11559841597255506, 'dropout_rate_Layer_2': 0.22085260563346984, 'dropout_rate_Layer_3': 0.3538820006926411, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007883347047011947, 'l1_Layer_2': 0.0009117571807773366, 'l1_Layer_3': 1.1585070397943087e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 100, 'n_units_Layer_3': 265}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.63 | sMAPE for Validation Set is: 15.48% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.42 | sMAPE for Test Set is: 21.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:33:16,487]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:33:18,903]\u001b[0m Trial 199 finished with value: 39.56781487022698 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007099052752827613, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11682076610226275, 'dropout_rate_Layer_2': 0.3026686235996295, 'dropout_rate_Layer_3': 0.39853222937789895, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.610749449684831e-05, 'l1_Layer_2': 0.00100401959943324, 'l1_Layer_3': 0.0021153127953121276, 'n_units_Layer_1': 195, 'n_units_Layer_2': 225, 'n_units_Layer_3': 260}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.57 | sMAPE for Validation Set is: 16.29% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 16.88 | sMAPE for Test Set is: 22.01% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:33:21,321]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:33:23,934]\u001b[0m Trial 210 finished with value: 37.713953200649726 and parameters: {'n_hidden': 3, 'learning_rate': 0.01084861336698841, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07698955141856856, 'dropout_rate_Layer_2': 0.1177643856418056, 'dropout_rate_Layer_3': 0.012656085045882465, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009263864692826653, 'l1_Layer_2': 0.0012637284292576897, 'l1_Layer_3': 0.00014296037714679735, 'n_units_Layer_1': 50, 'n_units_Layer_2': 165, 'n_units_Layer_3': 95}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.71 | sMAPE for Validation Set is: 15.56% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.70 | sMAPE for Test Set is: 21.99% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:33:24,365]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:33:38,192]\u001b[0m Trial 216 finished with value: 79.16993027396707 and parameters: {'n_hidden': 3, 'learning_rate': 0.02677274814559992, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38444348390230926, 'dropout_rate_Layer_2': 0.2289602667491555, 'dropout_rate_Layer_3': 0.0900536602830054, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.338547191332863e-05, 'l1_Layer_2': 3.167562627408761e-05, 'l1_Layer_3': 2.8111855024344477e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 50, 'n_units_Layer_3': 255}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 79.17 | sMAPE for Validation Set is: 29.00% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 45.47 | sMAPE for Test Set is: 39.77% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:33:42,840]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:33:45,868]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:33:49,520]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:33:56,469]\u001b[0m Trial 209 finished with value: 37.667439671237595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006983323757577314, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11601849814741029, 'dropout_rate_Layer_2': 0.2994210171949419, 'dropout_rate_Layer_3': 0.35345799825988905, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010061808121278203, 'l1_Layer_2': 0.00017191926410474115, 'l1_Layer_3': 0.002426990444698997, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.67 | sMAPE for Validation Set is: 15.41% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.86 | sMAPE for Test Set is: 21.52% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:34:04,905]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:13,403]\u001b[0m Trial 213 finished with value: 37.60045801608479 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007225437921116276, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11664712794607254, 'dropout_rate_Layer_2': 0.32915508386716147, 'dropout_rate_Layer_3': 0.39678355204362264, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.72108133720063e-05, 'l1_Layer_2': 0.0009889423370732862, 'l1_Layer_3': 1.0909528738447251e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 240, 'n_units_Layer_3': 245}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.60 | sMAPE for Validation Set is: 15.42% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.36 | sMAPE for Test Set is: 21.22% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:34:18,601]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:21,613]\u001b[0m Trial 222 finished with value: 36.9499184568945 and parameters: {'n_hidden': 3, 'learning_rate': 0.008609191908709247, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07594682215883727, 'dropout_rate_Layer_2': 0.08480555906459596, 'dropout_rate_Layer_3': 0.03021264853190151, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001810484109683646, 'l1_Layer_2': 0.0008446769219174552, 'l1_Layer_3': 0.00011790892896929453, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 95}. Best is trial 114 with value: 36.89328984646824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.95 | sMAPE for Validation Set is: 15.10% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.00 | sMAPE for Test Set is: 20.12% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:34:24,393]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:25,528]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:27,331]\u001b[0m Trial 215 finished with value: 36.3286485193051 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007382114348780003, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11722915432732851, 'dropout_rate_Layer_2': 0.3328883945914963, 'dropout_rate_Layer_3': 0.39741209866910193, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.075371089272311e-05, 'l1_Layer_2': 0.0007991729946445369, 'l1_Layer_3': 1.4726548203770928e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 240, 'n_units_Layer_3': 280}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.33 | sMAPE for Validation Set is: 14.98% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.22 | sMAPE for Test Set is: 20.48% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:34:30,508]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:33,628]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:35,027]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:37,040]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:37,826]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:41,806]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:45,309]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:47,757]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:34:52,825]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:00,314]\u001b[0m Trial 220 finished with value: 36.60912386864035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007017026697785072, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04489198108825081, 'dropout_rate_Layer_2': 0.3290792404478967, 'dropout_rate_Layer_3': 0.39346152241580906, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5851603975550315e-05, 'l1_Layer_2': 0.0009033313257796644, 'l1_Layer_3': 1.3245964953779324e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 235, 'n_units_Layer_3': 280}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:00,387]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.61 | sMAPE for Validation Set is: 15.02% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.28 | sMAPE for Test Set is: 20.39% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:35:07,834]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:10,448]\u001b[0m Trial 237 finished with value: 37.460897739390866 and parameters: {'n_hidden': 3, 'learning_rate': 0.009173731555642823, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08951720028341453, 'dropout_rate_Layer_2': 0.2485659140845969, 'dropout_rate_Layer_3': 0.01182067353070727, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014696805368429782, 'l1_Layer_2': 0.0006545764656281012, 'l1_Layer_3': 0.00018797220272962463, 'n_units_Layer_1': 50, 'n_units_Layer_2': 175, 'n_units_Layer_3': 65}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.46 | sMAPE for Validation Set is: 15.26% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.85 | sMAPE for Test Set is: 20.80% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:35:14,171]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:19,237]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:19,551]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:24,225]\u001b[0m Trial 239 finished with value: 36.81948536828465 and parameters: {'n_hidden': 3, 'learning_rate': 0.009020567578002094, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07298218933855452, 'dropout_rate_Layer_2': 0.07414429400131928, 'dropout_rate_Layer_3': 0.009936751712422576, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009000773947521482, 'l1_Layer_2': 0.0006437965564547242, 'l1_Layer_3': 0.00010875709431563381, 'n_units_Layer_1': 50, 'n_units_Layer_2': 175, 'n_units_Layer_3': 85}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.82 | sMAPE for Validation Set is: 15.07% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.46 | sMAPE for Test Set is: 20.64% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:35:28,312]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:31,931]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:32,092]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:33,132]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:37,545]\u001b[0m Trial 243 finished with value: 38.31421457146799 and parameters: {'n_hidden': 3, 'learning_rate': 0.010026540233449958, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09526482934317826, 'dropout_rate_Layer_2': 0.26400330774980735, 'dropout_rate_Layer_3': 0.013605346089171709, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.180247669029782e-05, 'l1_Layer_2': 0.0010720655851923127, 'l1_Layer_3': 5.90254900127463e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 180, 'n_units_Layer_3': 55}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.31 | sMAPE for Validation Set is: 15.77% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 16.07 | sMAPE for Test Set is: 21.10% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:35:39,949]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:40,414]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:44,233]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:50,378]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:35:54,274]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:01,276]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:03,970]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:10,455]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:13,534]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:19,431]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:22,373]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:30,660]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:31,499]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:31,891]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:33,906]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 63.00 | sMAPE for Validation Set is: 23.39% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 27.11 | sMAPE for Test Set is: 28.14% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:36:36,545]\u001b[0m Trial 259 finished with value: 62.99996707834566 and parameters: {'n_hidden': 3, 'learning_rate': 0.022577434661051846, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3597875481459851, 'dropout_rate_Layer_2': 0.25195290554615807, 'dropout_rate_Layer_3': 0.08754542897102341, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004068554102732394, 'l1_Layer_2': 4.4060636365575335e-05, 'l1_Layer_3': 2.602515913414987e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 270}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:37,702]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:37,969]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:43,852]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:47,291]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:49,277]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:52,751]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:36:59,638]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:37:20,259]\u001b[0m Trial 269 finished with value: 38.08467272213273 and parameters: {'n_hidden': 3, 'learning_rate': 0.00071376447246539, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12606764459857947, 'dropout_rate_Layer_2': 0.36502887680037094, 'dropout_rate_Layer_3': 0.34869673079049446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7994483785268526e-05, 'l1_Layer_2': 0.0006345750942354525, 'l1_Layer_3': 4.501900001616403e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.08 | sMAPE for Validation Set is: 15.71% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.44 | sMAPE for Test Set is: 21.63% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:37:25,122]\u001b[0m Trial 271 finished with value: 38.02873761577535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006416530469110023, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12004267984099046, 'dropout_rate_Layer_2': 0.358281740446963, 'dropout_rate_Layer_3': 0.34653194642236396, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.396100298742544e-05, 'l1_Layer_2': 0.0004433554045372428, 'l1_Layer_3': 2.36704431741156e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.03 | sMAPE for Validation Set is: 15.60% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.06 | sMAPE for Test Set is: 21.36% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:37:25,802]\u001b[0m Trial 267 finished with value: 37.36919821782263 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006781656441383867, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1102542214425115, 'dropout_rate_Layer_2': 0.3599494092670664, 'dropout_rate_Layer_3': 0.34664161461244763, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7073906372644503e-05, 'l1_Layer_2': 0.0007905008621706247, 'l1_Layer_3': 4.076524538056758e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 195, 'n_units_Layer_3': 280}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.37 | sMAPE for Validation Set is: 15.34% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.20 | sMAPE for Test Set is: 21.24% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:37:30,439]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:37:30,623]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:37:35,629]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:37:35,690]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:37:42,026]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:37:48,339]\u001b[0m Trial 273 finished with value: 38.043969098962215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006415678749792211, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12300726350389277, 'dropout_rate_Layer_2': 0.3593937694315335, 'dropout_rate_Layer_3': 0.3522180527489525, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.1535413736367446e-05, 'l1_Layer_2': 0.0007697118936726104, 'l1_Layer_3': 2.1867723622080858e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 195, 'n_units_Layer_3': 280}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.04 | sMAPE for Validation Set is: 15.67% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.09 | sMAPE for Test Set is: 21.44% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:38:03,205]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:06,441]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:16,794]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:19,804]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:22,942]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:25,866]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:30,359]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:32,611]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:33,307]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:37,831]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:38,187]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:38,521]\u001b[0m Trial 281 finished with value: 38.67858926524219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027995177046681798, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07537271223546993, 'dropout_rate_Layer_2': 0.3965108883810668, 'dropout_rate_Layer_3': 0.3761964377918875, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001898329279540356, 'l1_Layer_2': 0.000143796823101518, 'l1_Layer_3': 4.2695874125465476e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 190, 'n_units_Layer_3': 290}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:38,588]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.68 | sMAPE for Validation Set is: 15.76% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 15.89 | sMAPE for Test Set is: 20.80% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:38:45,279]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:46,758]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:47,900]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:50,193]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:54,340]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:38:58,210]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:06,417]\u001b[0m Trial 296 finished with value: 67.33613417920232 and parameters: {'n_hidden': 3, 'learning_rate': 0.04165806621701674, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35523233292076556, 'dropout_rate_Layer_2': 0.23650242170634808, 'dropout_rate_Layer_3': 0.0794727470030202, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.193424872491506e-05, 'l1_Layer_2': 2.052049678252333e-05, 'l1_Layer_3': 1.3642582103597186e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 50, 'n_units_Layer_3': 295}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.34 | sMAPE for Validation Set is: 25.11% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 36.88 | sMAPE for Test Set is: 36.05% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:39:07,045]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:13,110]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:23,918]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:26,720]\u001b[0m Trial 300 finished with value: 61.62183839261642 and parameters: {'n_hidden': 3, 'learning_rate': 0.04129040293833358, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.328483920027958, 'dropout_rate_Layer_2': 0.2414866850037878, 'dropout_rate_Layer_3': 0.07916107921589385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011146722471783324, 'l1_Layer_2': 1.3656719905538282e-05, 'l1_Layer_3': 0.008197890417942973, 'n_units_Layer_1': 160, 'n_units_Layer_2': 55, 'n_units_Layer_3': 275}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.62 | sMAPE for Validation Set is: 23.76% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 37.56 | sMAPE for Test Set is: 49.81% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:39:29,719]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:30,157]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:30,818]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:37,336]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:40,836]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:42,682]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:47,037]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:49,155]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:52,206]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:54,028]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:58,473]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:39:58,631]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:04,400]\u001b[0m Trial 303 finished with value: 37.4880475401279 and parameters: {'n_hidden': 3, 'learning_rate': 0.000805673065405141, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09755419913863554, 'dropout_rate_Layer_2': 0.3038464288488228, 'dropout_rate_Layer_3': 0.27213657726745494, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.6871159608718874e-05, 'l1_Layer_2': 0.00040398983139875285, 'l1_Layer_3': 1.5905108783651826e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 235, 'n_units_Layer_3': 255}. Best is trial 215 with value: 36.3286485193051.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.49 | sMAPE for Validation Set is: 15.35% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.61 | sMAPE for Test Set is: 20.81% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:40:06,718]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:10,581]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:13,875]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:14,102]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:20,024]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:22,291]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:26,610]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:30,062]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:35,472]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:36,262]\u001b[0m Trial 307 finished with value: 35.87763600021102 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008246732475610604, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1323378147629344, 'dropout_rate_Layer_2': 0.29851779787141747, 'dropout_rate_Layer_3': 0.00418875418876527, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4097630894316e-05, 'l1_Layer_2': 0.0011938949211714308, 'l1_Layer_3': 2.5305336131525882e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 225, 'n_units_Layer_3': 240}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.88 | sMAPE for Validation Set is: 14.77% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.63 | sMAPE for Test Set is: 19.81% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:40:36,722]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:41,303]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:44,773]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:44,870]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:45,542]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:51,565]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:53,617]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:56,634]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:40:59,646]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:02,326]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:02,958]\u001b[0m Trial 324 finished with value: 37.11772093321802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005958142609284891, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03561088037094373, 'dropout_rate_Layer_2': 0.2955692494296772, 'dropout_rate_Layer_3': 0.2797561273819626, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.88608221432059e-05, 'l1_Layer_2': 7.40878310895296e-05, 'l1_Layer_3': 2.415669610030747e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 225, 'n_units_Layer_3': 195}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.12 | sMAPE for Validation Set is: 15.15% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.04 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:41:04,607]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:12,082]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:16,875]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:18,761]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:19,223]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:25,565]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:28,139]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:28,597]\u001b[0m Trial 341 finished with value: 38.98988688477812 and parameters: {'n_hidden': 3, 'learning_rate': 0.008543367390799738, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1534882191064633, 'dropout_rate_Layer_2': 0.25524956942539745, 'dropout_rate_Layer_3': 0.018255101052131732, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.709031499136802e-05, 'l1_Layer_2': 0.00017905683969420604, 'l1_Layer_3': 9.997275520403849e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 55}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.99 | sMAPE for Validation Set is: 15.91% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 15.51 | sMAPE for Test Set is: 20.68% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:41:31,990]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:35,840]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:39,425]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:39,820]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:46,624]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:51,346]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:51,686]\u001b[0m Trial 347 finished with value: 37.535381279844145 and parameters: {'n_hidden': 3, 'learning_rate': 0.008168961932160509, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1963814855284867, 'dropout_rate_Layer_2': 0.10608529643884933, 'dropout_rate_Layer_3': 0.001659565606050569, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.612644195282722e-05, 'l1_Layer_2': 0.000824891429726198, 'l1_Layer_3': 0.00015145791651295767, 'n_units_Layer_1': 200, 'n_units_Layer_2': 180, 'n_units_Layer_3': 145}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:41:51,766]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.54 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.28 | sMAPE for Test Set is: 20.52% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:41:59,116]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:02,108]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:05,099]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:08,060]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:09,939]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:10,165]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:15,621]\u001b[0m Trial 346 finished with value: 36.76986718019737 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008747499045517011, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13654532647728262, 'dropout_rate_Layer_2': 0.2485329645701514, 'dropout_rate_Layer_3': 0.1084487480550232, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.928654366118095e-05, 'l1_Layer_2': 0.0017151200955043669, 'l1_Layer_3': 5.7538222403615595e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.77 | sMAPE for Validation Set is: 15.06% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.53 | sMAPE for Test Set is: 20.71% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:42:18,033]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:22,060]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:24,290]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:24,871]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:29,712]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:30,206]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:35,776]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:39,159]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:42:51,369]\u001b[0m Trial 365 finished with value: 61.95482146884698 and parameters: {'n_hidden': 3, 'learning_rate': 0.025327618723002855, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3902024091681341, 'dropout_rate_Layer_2': 0.2904847715118774, 'dropout_rate_Layer_3': 0.13008588515187341, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000139066020172087, 'l1_Layer_2': 2.6763927054887447e-05, 'l1_Layer_3': 1.5494543923707162e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 120, 'n_units_Layer_3': 245}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.95 | sMAPE for Validation Set is: 24.09% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 36.64 | sMAPE for Test Set is: 32.30% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:42:57,468]\u001b[0m Trial 360 finished with value: 37.220235003908016 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008727206582095158, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02003820498179182, 'dropout_rate_Layer_2': 0.2529750855222426, 'dropout_rate_Layer_3': 0.1082010634000639, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4343109342936263e-05, 'l1_Layer_2': 0.001800323155420285, 'l1_Layer_3': 6.223403612439039e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 230, 'n_units_Layer_3': 145}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.22 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.30 | sMAPE for Test Set is: 20.34% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:42:58,663]\u001b[0m Trial 368 finished with value: 37.045838327945056 and parameters: {'n_hidden': 3, 'learning_rate': 0.006247733457300894, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.063783381150368, 'dropout_rate_Layer_2': 0.2882594310929822, 'dropout_rate_Layer_3': 0.10508311903233661, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6826583791767953e-05, 'l1_Layer_2': 0.004194409060054823, 'l1_Layer_3': 3.301279125595153e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 170}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.05 | sMAPE for Validation Set is: 15.36% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.28 | sMAPE for Test Set is: 21.23% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:43:00,357]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:02,608]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:02,667]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:04,748]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:08,832]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:13,044]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:13,760]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:17,669]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:20,028]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:20,244]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:25,718]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:25,976]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:30,801]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:34,872]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:35,252]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:42,336]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:47,194]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:52,129]\u001b[0m Trial 388 finished with value: 37.967997249158394 and parameters: {'n_hidden': 3, 'learning_rate': 0.008258754697832361, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14196987606380745, 'dropout_rate_Layer_2': 0.13715624307474023, 'dropout_rate_Layer_3': 0.03287378389102459, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1878597832359788e-05, 'l1_Layer_2': 0.0008013242978970539, 'l1_Layer_3': 0.00020409733769066992, 'n_units_Layer_1': 190, 'n_units_Layer_2': 165, 'n_units_Layer_3': 170}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.97 | sMAPE for Validation Set is: 15.54% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.04 | sMAPE for Test Set is: 21.53% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:43:53,045]\u001b[0m Trial 382 finished with value: 36.74255790933328 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055324236253712555, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023909299375902106, 'dropout_rate_Layer_2': 0.2516184464334376, 'dropout_rate_Layer_3': 0.10621189848407601, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5817508985174444e-05, 'l1_Layer_2': 0.003817357122068036, 'l1_Layer_3': 9.169387793691023e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 265, 'n_units_Layer_3': 170}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.74 | sMAPE for Validation Set is: 15.08% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.70 | sMAPE for Test Set is: 20.05% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:43:57,791]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:58,302]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:43:58,848]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:03,193]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:03,732]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:06,440]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:08,223]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:10,112]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:11,212]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:18,782]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:19,058]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:19,902]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:22,952]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:24,390]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:24,954]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:30,021]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:30,640]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:31,229]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:31,560]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:36,228]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:41,276]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:45,915]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:48,821]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:50,755]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:53,803]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:54,029]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:44:56,021]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:01,603]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:05,559]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:09,642]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:13,839]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:20,712]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:22,982]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:25,343]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.53 | sMAPE for Validation Set is: 25.46% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 35.64 | sMAPE for Test Set is: 32.12% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:45:26,984]\u001b[0m Trial 422 finished with value: 69.52742926766308 and parameters: {'n_hidden': 3, 'learning_rate': 0.027546908938180233, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3393028097678685, 'dropout_rate_Layer_2': 0.25920314802736316, 'dropout_rate_Layer_3': 0.12966485831288513, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012572902239750325, 'l1_Layer_2': 3.275949711533938e-05, 'l1_Layer_3': 1.4743913774181836e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 260}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:30,765]\u001b[0m Trial 420 finished with value: 64.61681129856926 and parameters: {'n_hidden': 3, 'learning_rate': 0.030291979605057848, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3423754934669331, 'dropout_rate_Layer_2': 0.2542309524377384, 'dropout_rate_Layer_3': 0.1297164624929374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001299512849464762, 'l1_Layer_2': 3.325567539961795e-05, 'l1_Layer_3': 1.624093408797216e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 110, 'n_units_Layer_3': 255}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 64.62 | sMAPE for Validation Set is: 23.76% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 28.12 | sMAPE for Test Set is: 29.01% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:45:32,701]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:37,464]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:37,644]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:44,709]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:50,077]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:50,699]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:54,705]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:57,021]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:45:57,440]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:00,634]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:02,293]\u001b[0m Trial 427 finished with value: 63.569802569064336 and parameters: {'n_hidden': 3, 'learning_rate': 0.039895905998907945, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30347573838275377, 'dropout_rate_Layer_2': 0.2611329100777889, 'dropout_rate_Layer_3': 0.08640126346382629, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011822537108089256, 'l1_Layer_2': 2.956100602609097e-05, 'l1_Layer_3': 1.3694745307724565e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 95}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 63.57 | sMAPE for Validation Set is: 23.59% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 33.45 | sMAPE for Test Set is: 34.30% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:46:05,819]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:09,209]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:10,304]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:11,449]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:12,856]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:18,127]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:19,798]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:25,252]\u001b[0m Trial 446 finished with value: 77.64888864153146 and parameters: {'n_hidden': 3, 'learning_rate': 0.03546874538022452, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3257811902860199, 'dropout_rate_Layer_2': 0.2622500872563197, 'dropout_rate_Layer_3': 0.07359205009868662, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018014314669474913, 'l1_Layer_2': 1.0064784989437162e-05, 'l1_Layer_3': 0.0002871055675309529, 'n_units_Layer_1': 185, 'n_units_Layer_2': 130, 'n_units_Layer_3': 95}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.65 | sMAPE for Validation Set is: 28.03% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 27.17 | sMAPE for Test Set is: 29.18% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:46:33,017]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:36,969]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:40,121]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:43,409]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:47,512]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:50,947]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:46:54,713]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:01,671]\u001b[0m Trial 445 finished with value: 38.22333675788989 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006556200228451425, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04672986175875635, 'dropout_rate_Layer_2': 0.3028203319624793, 'dropout_rate_Layer_3': 0.04057105486470393, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.659352441848464e-05, 'l1_Layer_2': 0.0014150661043532276, 'l1_Layer_3': 5.373921086861358e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 230, 'n_units_Layer_3': 125}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.22 | sMAPE for Validation Set is: 15.79% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 15.43 | sMAPE for Test Set is: 20.60% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:47:02,491]\u001b[0m Trial 447 finished with value: 37.122562691790215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006546928617919573, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048354619774678906, 'dropout_rate_Layer_2': 0.3049470299873492, 'dropout_rate_Layer_3': 0.05724444508736984, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.665051844050469e-05, 'l1_Layer_2': 0.0014507624206100578, 'l1_Layer_3': 5.0626229464166336e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 230, 'n_units_Layer_3': 170}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.12 | sMAPE for Validation Set is: 15.14% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.26 | sMAPE for Test Set is: 20.23% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:47:06,743]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:09,981]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:13,181]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:17,404]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:20,673]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:23,439]\u001b[0m Trial 442 finished with value: 36.28560851335525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006317883965406627, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09444939562430928, 'dropout_rate_Layer_2': 0.3065381389701434, 'dropout_rate_Layer_3': 0.0469099294235655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.52569234794797e-05, 'l1_Layer_2': 0.0028139896102882555, 'l1_Layer_3': 5.009173448990589e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 230, 'n_units_Layer_3': 170}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.29 | sMAPE for Validation Set is: 14.93% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.92 | sMAPE for Test Set is: 20.07% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:47:25,260]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:26,201]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:28,124]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:33,496]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:33,771]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:38,525]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:40,332]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:42,508]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:43,658]\u001b[0m Trial 455 finished with value: 37.48322796660872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008389316488695008, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047760286630120816, 'dropout_rate_Layer_2': 0.30532313295532565, 'dropout_rate_Layer_3': 0.05519275521646478, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5801673815016836e-05, 'l1_Layer_2': 0.0014594579159534968, 'l1_Layer_3': 5.299958461720473e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 230, 'n_units_Layer_3': 150}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.48 | sMAPE for Validation Set is: 15.28% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.26 | sMAPE for Test Set is: 20.20% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:47:44,458]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:50,430]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:50,962]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:53,134]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:55,328]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:55,503]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:47:57,213]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:04,689]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:04,976]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:08,598]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:12,387]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:12,979]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:13,350]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:17,183]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:18,871]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:22,845]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:23,307]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:27,786]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:27,923]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:28,170]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:34,588]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:39,897]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:46,209]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:48,614]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:48:49,390]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:02,141]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:05,959]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:08,831]\u001b[0m Trial 492 finished with value: 39.80978087284933 and parameters: {'n_hidden': 3, 'learning_rate': 0.003081302583110389, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15446305366400956, 'dropout_rate_Layer_2': 0.12310642004280119, 'dropout_rate_Layer_3': 0.02499653336821181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001644009437876339, 'l1_Layer_2': 0.0009227290938618721, 'l1_Layer_3': 0.00020245135670665863, 'n_units_Layer_1': 185, 'n_units_Layer_2': 180, 'n_units_Layer_3': 125}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.81 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 15.92 | sMAPE for Test Set is: 20.81% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:49:10,291]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:14,992]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:19,107]\u001b[0m Trial 494 finished with value: 36.945766557297446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006594962913875508, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0917099323194952, 'dropout_rate_Layer_2': 0.3342610872179495, 'dropout_rate_Layer_3': 0.1218818208609916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.716260778081747e-05, 'l1_Layer_2': 0.0008895026161294505, 'l1_Layer_3': 4.6499469866891593e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 205, 'n_units_Layer_3': 185}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.95 | sMAPE for Validation Set is: 15.13% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.60 | sMAPE for Test Set is: 19.69% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:49:23,329]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:25,263]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:29,941]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:33,170]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:33,325]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.71 | sMAPE for Validation Set is: 27.37% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 27.62 | sMAPE for Test Set is: 29.63% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:49:37,357]\u001b[0m Trial 501 finished with value: 75.70542523417838 and parameters: {'n_hidden': 3, 'learning_rate': 0.05006243727608309, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34204653190549517, 'dropout_rate_Layer_2': 0.24281156161442202, 'dropout_rate_Layer_3': 0.1197708487920028, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.694039562846796e-05, 'l1_Layer_2': 2.8800227537966135e-05, 'l1_Layer_3': 2.106901703005575e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 100, 'n_units_Layer_3': 265}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:42,735]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:43,195]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:43,830]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:50,659]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:51,524]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:57,021]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:49:57,530]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:01,940]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:02,336]\u001b[0m Trial 496 finished with value: 36.99470190360948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006600147871760852, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.041105123508743055, 'dropout_rate_Layer_2': 0.31828942803072013, 'dropout_rate_Layer_3': 0.058661279027401696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.300257715544237e-05, 'l1_Layer_2': 0.0036454332947708904, 'l1_Layer_3': 2.0010745171229334e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 220, 'n_units_Layer_3': 180}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.99 | sMAPE for Validation Set is: 15.21% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.02 | sMAPE for Test Set is: 20.71% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:50:07,119]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:10,011]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:13,697]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:25,700]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:33,904]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:40,073]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:43,148]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:50,682]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:54,726]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:57,794]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:50:59,946]\u001b[0m Trial 520 finished with value: 37.36546023720913 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005463561901259415, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0783817264259275, 'dropout_rate_Layer_2': 0.296305982835831, 'dropout_rate_Layer_3': 0.03020283640470659, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2679470640327247e-05, 'l1_Layer_2': 0.005897326040452907, 'l1_Layer_3': 2.424012628786216e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 220, 'n_units_Layer_3': 190}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.37 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.09 | sMAPE for Test Set is: 20.24% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:51:02,675]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:03,573]\u001b[0m Trial 517 finished with value: 37.773056254666606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005028241680019844, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.042077698817667604, 'dropout_rate_Layer_2': 0.29469726273135816, 'dropout_rate_Layer_3': 0.01215755209814584, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8920627223092775e-05, 'l1_Layer_2': 0.009270153369769767, 'l1_Layer_3': 2.373994777071909e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 220, 'n_units_Layer_3': 185}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.77 | sMAPE for Validation Set is: 15.35% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.79 | sMAPE for Test Set is: 20.63% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:51:07,853]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:08,708]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:12,471]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:17,649]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:21,098]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:23,764]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:24,713]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:30,348]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:33,464]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:34,214]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:40,568]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:40,968]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:47,302]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:50,158]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:50,395]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:53,598]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:54,617]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:51:56,365]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:01,462]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:02,287]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:06,221]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:08,664]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:09,927]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:10,344]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:15,692]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:16,781]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:19,094]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:22,314]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:22,826]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:23,214]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:29,777]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:32,625]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:33,465]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:37,087]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:37,254]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:37,796]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:44,205]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:45,175]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:46,716]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:47,916]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:49,645]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:52:56,565]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:00,002]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:04,341]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:06,241]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:09,694]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:10,179]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:13,530]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:15,241]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:19,117]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:22,650]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:27,813]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:27,893]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:33,595]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:33,693]\u001b[0m Trial 580 finished with value: 37.483803992759796 and parameters: {'n_hidden': 3, 'learning_rate': 0.007182295392718018, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09148514815090666, 'dropout_rate_Layer_2': 0.24743483032340133, 'dropout_rate_Layer_3': 0.0062444005497746926, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027036259787787157, 'l1_Layer_2': 0.000891403934240556, 'l1_Layer_3': 0.00015851274653340901, 'n_units_Layer_1': 115, 'n_units_Layer_2': 160, 'n_units_Layer_3': 155}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.48 | sMAPE for Validation Set is: 15.55% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.91 | sMAPE for Test Set is: 20.60% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:53:35,513]\u001b[0m Trial 571 finished with value: 37.23927142531401 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007639605176419933, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015615499379706306, 'dropout_rate_Layer_2': 0.30909023748862297, 'dropout_rate_Layer_3': 0.09582279299628835, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.493310675302706e-05, 'l1_Layer_2': 0.0015252634339796018, 'l1_Layer_3': 3.518305507067143e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.24 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.45 | sMAPE for Test Set is: 20.61% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:53:38,775]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:40,175]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:40,829]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:43,170]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:43,706]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:50,582]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:52,922]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:55,083]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:55,194]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:53:57,986]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:01,606]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:06,855]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:11,891]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:12,132]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:18,710]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:18,880]\u001b[0m Trial 595 finished with value: 37.77579336275601 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027443049321043333, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07761239650241608, 'dropout_rate_Layer_2': 0.09878961335713297, 'dropout_rate_Layer_3': 0.031060968773881724, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.070323490131993e-05, 'l1_Layer_2': 0.0007434561186325263, 'l1_Layer_3': 0.0001499020673154172, 'n_units_Layer_1': 260, 'n_units_Layer_2': 165, 'n_units_Layer_3': 90}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:18,963]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.78 | sMAPE for Validation Set is: 15.59% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.81 | sMAPE for Test Set is: 20.51% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:54:27,121]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:27,401]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:27,520]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:33,944]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:37,780]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:39,875]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:44,239]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:47,509]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:51,254]\u001b[0m Trial 597 finished with value: 36.16445816974303 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011348110032446807, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06289593318852366, 'dropout_rate_Layer_2': 0.31998017188984723, 'dropout_rate_Layer_3': 0.10926402315557944, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.439224267214004e-05, 'l1_Layer_2': 0.0020220223173172958, 'l1_Layer_3': 4.5587975812631005e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 255, 'n_units_Layer_3': 155}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.16 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.23 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:54:51,855]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:54:58,336]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:01,029]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:03,621]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:05,760]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:08,868]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:09,421]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:09,527]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:15,746]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:19,352]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:19,800]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:24,540]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:24,817]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:29,940]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:32,938]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:35,025]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:37,947]\u001b[0m Trial 621 finished with value: 37.42421720336936 and parameters: {'n_hidden': 3, 'learning_rate': 0.00256586947159888, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08255039876226232, 'dropout_rate_Layer_2': 0.09842295706881611, 'dropout_rate_Layer_3': 0.03527356059428998, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010662039233514185, 'l1_Layer_2': 0.0012100089604651222, 'l1_Layer_3': 0.00011230594572473155, 'n_units_Layer_1': 250, 'n_units_Layer_2': 105, 'n_units_Layer_3': 85}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.42 | sMAPE for Validation Set is: 15.38% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.82 | sMAPE for Test Set is: 20.45% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:55:41,064]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:46,690]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:50,304]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:53,872]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:55:58,232]\u001b[0m Trial 626 finished with value: 37.936387667562705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007166290873887698, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10657214933318374, 'dropout_rate_Layer_2': 0.30991928902565463, 'dropout_rate_Layer_3': 0.06204819683050093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.123589469124018e-05, 'l1_Layer_2': 1.4155796136615584e-05, 'l1_Layer_3': 1.6797553578212477e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.94 | sMAPE for Validation Set is: 15.59% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.16 | sMAPE for Test Set is: 20.20% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:56:00,705]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:05,391]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:06,227]\u001b[0m Trial 629 finished with value: 36.75339543775473 and parameters: {'n_hidden': 3, 'learning_rate': 0.002479172386486647, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07279922853450141, 'dropout_rate_Layer_2': 0.09083918974710212, 'dropout_rate_Layer_3': 0.09515483368229699, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000812178857088645, 'l1_Layer_2': 0.0006820595825212619, 'l1_Layer_3': 0.00021454016440376606, 'n_units_Layer_1': 210, 'n_units_Layer_2': 110, 'n_units_Layer_3': 125}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.75 | sMAPE for Validation Set is: 15.16% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.97 | sMAPE for Test Set is: 21.39% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:56:06,968]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:08,847]\u001b[0m Trial 630 finished with value: 39.311497341882806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025271956110131653, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07003658088979657, 'dropout_rate_Layer_2': 0.09207696627425732, 'dropout_rate_Layer_3': 0.054817941483954, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008725203275583699, 'l1_Layer_2': 0.001656203516746554, 'l1_Layer_3': 8.506616617799561e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 110, 'n_units_Layer_3': 85}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.31 | sMAPE for Validation Set is: 16.02% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 17.15 | sMAPE for Test Set is: 21.40% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:56:15,281]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:15,923]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:16,684]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:22,164]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:24,184]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:24,560]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:27,310]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:31,220]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:32,008]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:32,048]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:36,701]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:42,220]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:45,934]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:49,433]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:53,017]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:56:53,538]\u001b[0m Trial 648 finished with value: 70.19143306314834 and parameters: {'n_hidden': 3, 'learning_rate': 0.04376991978549396, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30607942614929895, 'dropout_rate_Layer_2': 0.27039191579125216, 'dropout_rate_Layer_3': 0.10305256272315147, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.612264717460179e-05, 'l1_Layer_2': 4.963670807525306e-05, 'l1_Layer_3': 2.2017524855974908e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 75, 'n_units_Layer_3': 145}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.19 | sMAPE for Validation Set is: 25.65% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 25.48 | sMAPE for Test Set is: 29.60% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:56:54,499]\u001b[0m Trial 651 finished with value: 75.91904388756281 and parameters: {'n_hidden': 3, 'learning_rate': 0.04024074088693219, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31405477020485073, 'dropout_rate_Layer_2': 0.06392565005550119, 'dropout_rate_Layer_3': 0.0851106037984326, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.869061089440892e-05, 'l1_Layer_2': 6.774220929383463e-05, 'l1_Layer_3': 2.2596384247837472e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.92 | sMAPE for Validation Set is: 28.07% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 45.63 | sMAPE for Test Set is: 57.02% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:56:59,067]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:04,342]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:05,116]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:10,590]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:12,672]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:17,919]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:18,112]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:25,142]\u001b[0m Trial 653 finished with value: 36.72393685941589 and parameters: {'n_hidden': 3, 'learning_rate': 0.000910519883520189, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08389369000367258, 'dropout_rate_Layer_2': 0.2024320257178651, 'dropout_rate_Layer_3': 0.07469191063675547, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0356238324969967e-05, 'l1_Layer_2': 0.0012433563520725303, 'l1_Layer_3': 2.929028294402615e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.72 | sMAPE for Validation Set is: 15.06% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.44 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:57:37,163]\u001b[0m Trial 659 finished with value: 36.79569120827333 and parameters: {'n_hidden': 3, 'learning_rate': 0.000918872162446203, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06323942142320697, 'dropout_rate_Layer_2': 0.28250016778321957, 'dropout_rate_Layer_3': 0.07502269978082438, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.479720411124556e-05, 'l1_Layer_2': 0.0011038426695471216, 'l1_Layer_3': 1.2884390710077965e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 245, 'n_units_Layer_3': 130}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.80 | sMAPE for Validation Set is: 15.13% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.21 | sMAPE for Test Set is: 20.29% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:57:41,128]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:41,959]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:46,506]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:49,819]\u001b[0m Trial 663 finished with value: 37.215452799662756 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009204810404505008, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06488403070889097, 'dropout_rate_Layer_2': 0.2573931977372745, 'dropout_rate_Layer_3': 0.14541650087577374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4216188843904388e-05, 'l1_Layer_2': 0.0011845330481992527, 'l1_Layer_3': 1.2888218939908237e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.22 | sMAPE for Validation Set is: 15.26% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.14 | sMAPE for Test Set is: 20.25% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:57:50,205]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:50,738]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:57:51,344]\u001b[0m Trial 664 finished with value: 37.08496200481273 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006846332149637728, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06170640415986985, 'dropout_rate_Layer_2': 0.2261975522156255, 'dropout_rate_Layer_3': 0.05142758983175809, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3945428284927077e-05, 'l1_Layer_2': 0.0012586466765573902, 'l1_Layer_3': 1.2631564321508683e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.08 | sMAPE for Validation Set is: 15.22% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.66 | sMAPE for Test Set is: 20.44% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:58:01,139]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:03,014]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:06,068]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:09,265]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:09,807]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:10,699]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:13,044]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:16,025]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:17,951]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:23,747]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:23,873]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:24,100]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:27,181]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:31,200]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:32,591]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:32,788]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:36,457]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:39,146]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:41,817]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:41,861]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:45,709]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:48,494]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:48,601]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:51,602]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:54,677]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:55,175]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:58:57,702]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:03,892]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:04,836]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:06,982]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:13,925]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:17,087]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:17,624]\u001b[0m Trial 695 finished with value: 65.77405791272885 and parameters: {'n_hidden': 3, 'learning_rate': 0.04396822931778947, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31338734114394445, 'dropout_rate_Layer_2': 0.2879153086131345, 'dropout_rate_Layer_3': 0.07871330584220376, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010358386487843345, 'l1_Layer_2': 0.00034107045721964616, 'l1_Layer_3': 2.139381653027344e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 265}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.77 | sMAPE for Validation Set is: 24.58% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 28.38 | sMAPE for Test Set is: 33.47% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:59:22,804]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:23,322]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:24,223]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:28,937]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:33,196]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:37,284]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:37,866]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:43,303]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:43,692]\u001b[0m Trial 703 finished with value: 36.20726730651696 and parameters: {'n_hidden': 3, 'learning_rate': 0.002288542472206017, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06939609157088103, 'dropout_rate_Layer_2': 0.27809396436234923, 'dropout_rate_Layer_3': 0.17951234013594605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011005408451521682, 'l1_Layer_2': 0.0019053274479124572, 'l1_Layer_3': 0.000160258350921272, 'n_units_Layer_1': 245, 'n_units_Layer_2': 245, 'n_units_Layer_3': 155}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.21 | sMAPE for Validation Set is: 14.89% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.79 | sMAPE for Test Set is: 20.63% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 07:59:44,439]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:54,991]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:58,619]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 07:59:58,863]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:03,719]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:06,758]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.21 | sMAPE for Validation Set is: 15.57% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 15.46 | sMAPE for Test Set is: 20.53% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:00:08,431]\u001b[0m Trial 709 finished with value: 38.207093687292804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005792780542214365, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.058612781137778514, 'dropout_rate_Layer_2': 0.20624399708676172, 'dropout_rate_Layer_3': 0.0472380483561116, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.255776121459886e-05, 'l1_Layer_2': 0.0003264162121767037, 'l1_Layer_3': 1.000111707908795e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 255, 'n_units_Layer_3': 90}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:11,628]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:11,698]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:13,767]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:14,006]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:20,653]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:23,555]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:24,309]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:27,029]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:27,456]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:29,106]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:31,560]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:36,565]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:38,483]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:39,451]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:40,894]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:44,944]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:47,298]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:47,659]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:52,649]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:57,862]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:00:58,072]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:03,427]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:06,352]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:07,728]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:10,003]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:11,897]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:16,357]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:20,170]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:22,528]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:22,681]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:27,535]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:28,401]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:28,545]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:37,544]\u001b[0m Trial 750 finished with value: 73.67851472350306 and parameters: {'n_hidden': 3, 'learning_rate': 0.05804522039701707, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34251394694441384, 'dropout_rate_Layer_2': 0.25368177412149395, 'dropout_rate_Layer_3': 0.11919243428446089, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012224441752564278, 'l1_Layer_2': 2.7869227782791412e-05, 'l1_Layer_3': 1.7323438375106042e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 85, 'n_units_Layer_3': 255}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.68 | sMAPE for Validation Set is: 27.15% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 41.53 | sMAPE for Test Set is: 49.39% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:01:38,484]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:42,925]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:45,018]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:48,927]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:55,351]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:01:58,659]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:01,142]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:02,204]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:05,096]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:09,570]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:10,367]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:12,847]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:15,241]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:20,622]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:22,668]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:25,444]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:28,256]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:28,824]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:34,842]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:45,416]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:51,858]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:02:59,338]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.85 | sMAPE for Validation Set is: 25.29% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 32.10 | sMAPE for Test Set is: 31.57% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:03:02,294]\u001b[0m Trial 775 finished with value: 65.8459996544893 and parameters: {'n_hidden': 3, 'learning_rate': 0.05959093334123431, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24696914623276817, 'dropout_rate_Layer_2': 0.25271830201692236, 'dropout_rate_Layer_3': 0.07162304226646099, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.828801202047348e-05, 'l1_Layer_2': 2.696015296001094e-05, 'l1_Layer_3': 1.442243240697054e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 100, 'n_units_Layer_3': 265}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:05,718]\u001b[0m Trial 773 finished with value: 70.29820432701146 and parameters: {'n_hidden': 3, 'learning_rate': 0.0550581521195728, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3039579763760736, 'dropout_rate_Layer_2': 0.25396456857541255, 'dropout_rate_Layer_3': 0.13928541086396662, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.750012557381683e-05, 'l1_Layer_2': 1.2172661224487807e-05, 'l1_Layer_3': 1.3820373536233252e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 100, 'n_units_Layer_3': 265}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.30 | sMAPE for Validation Set is: 26.20% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 37.91 | sMAPE for Test Set is: 33.98% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:03:11,035]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:11,733]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:14,513]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:15,707]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:16,537]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:19,721]\u001b[0m Trial 765 finished with value: 35.98934355522556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006325935628143838, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0489492069123816, 'dropout_rate_Layer_2': 0.3000348932074294, 'dropout_rate_Layer_3': 0.08824815782686993, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.492034995438969e-05, 'l1_Layer_2': 0.001341077785192749, 'l1_Layer_3': 3.43794902784469e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.99 | sMAPE for Validation Set is: 14.82% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.91 | sMAPE for Test Set is: 20.01% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:03:22,065]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:29,357]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:29,549]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:34,589]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:39,892]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:41,589]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:44,029]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:47,272]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:52,833]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:54,801]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:03:58,396]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:03,806]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:07,605]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:13,124]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:17,089]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:21,765]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:22,387]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:29,677]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:35,842]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:36,172]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:41,350]\u001b[0m Trial 791 finished with value: 37.16487792242838 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006163983512294949, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12899256271598375, 'dropout_rate_Layer_2': 0.30292778863609804, 'dropout_rate_Layer_3': 0.06752358080887808, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0042207394757657e-05, 'l1_Layer_2': 0.0021303094652793605, 'l1_Layer_3': 3.354627953788222e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 240, 'n_units_Layer_3': 180}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.16 | sMAPE for Validation Set is: 15.25% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.57 | sMAPE for Test Set is: 20.62% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:04:47,246]\u001b[0m Trial 794 finished with value: 37.74709514866106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007626292827770085, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03733575144910462, 'dropout_rate_Layer_2': 0.3042232588340842, 'dropout_rate_Layer_3': 0.07608199154744548, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.49364276963658e-05, 'l1_Layer_2': 0.002169799039224689, 'l1_Layer_3': 2.7707449541507014e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 225, 'n_units_Layer_3': 175}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.75 | sMAPE for Validation Set is: 15.51% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.58 | sMAPE for Test Set is: 20.62% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:04:49,729]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:56,444]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:04:58,953]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:01,153]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:07,839]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:13,253]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:16,810]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:16,989]\u001b[0m Trial 806 finished with value: 37.62747647631102 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008745210544796856, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030271524700767966, 'dropout_rate_Layer_2': 0.2292160208899626, 'dropout_rate_Layer_3': 0.11062093105093161, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.768809684510036e-05, 'l1_Layer_2': 0.0016026629512838652, 'l1_Layer_3': 2.189630913655818e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 220, 'n_units_Layer_3': 190}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.63 | sMAPE for Validation Set is: 15.42% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 17.01 | sMAPE for Test Set is: 21.42% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:05:22,862]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:23,548]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:25,692]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:29,075]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:32,620]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:45,708]\u001b[0m Trial 819 finished with value: 64.5032993237 and parameters: {'n_hidden': 3, 'learning_rate': 0.03760661517402018, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32380301746397866, 'dropout_rate_Layer_2': 0.3069220182157213, 'dropout_rate_Layer_3': 0.1905850297361979, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014949044866135281, 'l1_Layer_2': 5.3314019049609714e-05, 'l1_Layer_3': 2.4444824791501158e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 275}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 64.50 | sMAPE for Validation Set is: 23.87% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 34.07 | sMAPE for Test Set is: 38.43% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:05:46,095]\u001b[0m Trial 812 finished with value: 37.427818701369354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005458270998488145, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14319212624319433, 'dropout_rate_Layer_2': 0.285642255459675, 'dropout_rate_Layer_3': 0.033235985274207014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.916805143460146e-05, 'l1_Layer_2': 0.0017223272546469585, 'l1_Layer_3': 2.1962485890639244e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.43 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.57 | sMAPE for Test Set is: 20.51% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:05:46,444]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:48,411]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:56,251]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:05:59,719]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:04,321]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:04,555]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:05,438]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:05,708]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:10,821]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:13,193]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:14,459]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:14,882]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:19,874]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:26,152]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:26,457]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:31,525]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:34,841]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:38,041]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:42,071]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:45,389]\u001b[0m Trial 833 finished with value: 72.25547619835625 and parameters: {'n_hidden': 3, 'learning_rate': 0.03271114497303489, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1804351291876279, 'dropout_rate_Layer_2': 0.16135013533735415, 'dropout_rate_Layer_3': 0.21690818410000776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018971651141334308, 'l1_Layer_2': 7.251051446039584e-05, 'l1_Layer_3': 2.5445629471991412e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275}. Best is trial 307 with value: 35.87763600021102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.26 | sMAPE for Validation Set is: 26.14% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 30.39 | sMAPE for Test Set is: 31.14% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:06:52,348]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:54,987]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:06:58,370]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:01,181]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:04,647]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:06,529]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:08,042]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:08,090]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:10,081]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:12,207]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:19,600]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:19,855]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:25,024]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:30,935]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:34,990]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:35,674]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:41,163]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:43,157]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:07:50,077]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:00,605]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.67 | sMAPE for Validation Set is: 14.78% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 19.86% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:08:02,198]\u001b[0m Trial 850 finished with value: 35.67097545047712 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023946388501283685, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04177001858040479, 'dropout_rate_Layer_2': 0.22021658125901158, 'dropout_rate_Layer_3': 0.01930560350358373, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009070857886700551, 'l1_Layer_2': 0.0028525441527308903, 'l1_Layer_3': 0.00010035592083221638, 'n_units_Layer_1': 65, 'n_units_Layer_2': 190, 'n_units_Layer_3': 50}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:05,763]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:07,387]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:11,017]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:11,568]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:17,117]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:19,217]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:23,525]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:26,636]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:26,810]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:31,648]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:32,721]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:35,637]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:40,838]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:41,274]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:45,413]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:45,564]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:45,787]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:53,018]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:56,529]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:08:59,401]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:05,773]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:11,245]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:17,240]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:17,522]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:22,345]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:24,699]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:25,834]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:29,653]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:33,035]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:38,400]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:39,178]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:41,279]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:42,422]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:46,641]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:48,993]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:54,127]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:55,173]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:09:57,322]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:01,931]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:07,585]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:11,131]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:11,806]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:15,687]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:19,413]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:19,735]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:20,293]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:27,259]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:30,096]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:30,717]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:33,094]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:37,385]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:43,619]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:46,719]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:50,336]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:51,190]\u001b[0m Trial 914 finished with value: 75.60771270538898 and parameters: {'n_hidden': 3, 'learning_rate': 0.024985109368595982, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31596028013013927, 'dropout_rate_Layer_2': 0.21722557654928953, 'dropout_rate_Layer_3': 0.08167111828539309, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007268076050061017, 'l1_Layer_2': 0.00012907319797566245, 'l1_Layer_3': 3.274076909574716e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 50, 'n_units_Layer_3': 265}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.61 | sMAPE for Validation Set is: 28.20% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 24.09 | sMAPE for Test Set is: 28.77% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:10:51,543]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:10:56,555]\u001b[0m Trial 878 finished with value: 36.884948452216065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005330029884525444, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1350148892041434, 'dropout_rate_Layer_2': 0.17401720300475026, 'dropout_rate_Layer_3': 0.06278036493534199, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8325454721596857e-05, 'l1_Layer_2': 0.000550536968166523, 'l1_Layer_3': 2.5628249275955674e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 245, 'n_units_Layer_3': 175}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.88 | sMAPE for Validation Set is: 15.10% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.34 | sMAPE for Test Set is: 20.25% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:10:57,997]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:00,874]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:01,216]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:04,795]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:05,255]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:12,118]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:12,797]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:16,961]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:17,692]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:21,440]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:22,636]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:24,783]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:28,739]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:29,939]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:34,044]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:36,301]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:40,116]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:40,704]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:46,054]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:46,437]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:55,377]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:11:59,834]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:12:05,796]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:12:16,672]\u001b[0m Trial 942 finished with value: 37.49910254040855 and parameters: {'n_hidden': 3, 'learning_rate': 0.00937080533433135, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1377484156908532, 'dropout_rate_Layer_2': 0.05297890805548908, 'dropout_rate_Layer_3': 0.016553090071809, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3691176125299e-05, 'l1_Layer_2': 0.0018330152377066399, 'l1_Layer_3': 0.00010310466024206955, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 130}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.50 | sMAPE for Validation Set is: 15.39% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.86 | sMAPE for Test Set is: 21.14% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:12:20,484]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:12:25,859]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:12:32,646]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:12:37,351]\u001b[0m Trial 924 finished with value: 36.771208227963314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007307677242667344, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17661601895495566, 'dropout_rate_Layer_2': 0.15053593971020796, 'dropout_rate_Layer_3': 0.18842215325182154, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.1917799907267225e-05, 'l1_Layer_2': 0.0005283942087172691, 'l1_Layer_3': 1.4508655309824675e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.77 | sMAPE for Validation Set is: 15.16% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.32 | sMAPE for Test Set is: 20.21% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:12:42,838]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:13:39,642]\u001b[0m Trial 941 finished with value: 35.70657733076333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005688465155189275, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1343825541628118, 'dropout_rate_Layer_2': 0.18271413359337918, 'dropout_rate_Layer_3': 0.18243255156153876, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7262346983140955e-05, 'l1_Layer_2': 0.0010881837608748654, 'l1_Layer_3': 3.4999590665931545e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 240, 'n_units_Layer_3': 165}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.71 | sMAPE for Validation Set is: 14.74% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.81 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:13:52,178]\u001b[0m Trial 948 finished with value: 36.00350063830115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006109623223468691, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14059176316906236, 'dropout_rate_Layer_2': 0.1732098663875635, 'dropout_rate_Layer_3': 0.054218714192244236, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7707600718113407e-05, 'l1_Layer_2': 0.0008776066141890926, 'l1_Layer_3': 2.4650126016708552e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 240, 'n_units_Layer_3': 185}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.00 | sMAPE for Validation Set is: 14.81% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.42 | sMAPE for Test Set is: 20.36% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:13:55,210]\u001b[0m Trial 944 finished with value: 36.297228456173976 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006368140003257977, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13894535853497506, 'dropout_rate_Layer_2': 0.17558290686061742, 'dropout_rate_Layer_3': 0.057187229833925386, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7672273869867214e-05, 'l1_Layer_2': 0.0015130087992122436, 'l1_Layer_3': 3.586659859740561e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 240, 'n_units_Layer_3': 170}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.30 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.26 | sMAPE for Test Set is: 20.50% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:14:03,058]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:14:08,194]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:14:15,886]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:14:26,406]\u001b[0m Trial 950 finished with value: 36.951751393821205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007382795146518147, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1769528729471981, 'dropout_rate_Layer_2': 0.1549708008060366, 'dropout_rate_Layer_3': 0.19127317258315962, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.3547071141922175e-05, 'l1_Layer_2': 0.000494315586358282, 'l1_Layer_3': 1.9836504114141366e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 255, 'n_units_Layer_3': 155}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.95 | sMAPE for Validation Set is: 15.14% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.85 | sMAPE for Test Set is: 21.08% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:14:26,601]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:14:34,024]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:14:39,195]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:14:42,121]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:14:51,805]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:14:52,264]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:00,348]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:03,874]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:08,540]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:08,923]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:14,531]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:15,033]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:20,383]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:23,837]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:27,324]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:30,865]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:35,410]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:15:40,669]\u001b[0m Trial 962 finished with value: 38.023907051133875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027127728523026213, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10400764528962934, 'dropout_rate_Layer_2': 0.05365568014663854, 'dropout_rate_Layer_3': 0.01808429511900876, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6383096279560407e-05, 'l1_Layer_2': 0.0015800816058935863, 'l1_Layer_3': 9.00742386120765e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 115}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.02 | sMAPE for Validation Set is: 15.48% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.61 | sMAPE for Test Set is: 20.50% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:15:41,008]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:16:07,843]\u001b[0m Trial 951 finished with value: 36.712528411511826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007217629372848602, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13759942354399915, 'dropout_rate_Layer_2': 0.17610522684726193, 'dropout_rate_Layer_3': 0.2100453283446763, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5194839053176573e-05, 'l1_Layer_2': 0.0005042924153683785, 'l1_Layer_3': 2.0341333415163358e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 255, 'n_units_Layer_3': 165}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.71 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.35 | sMAPE for Test Set is: 20.71% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:16:09,764]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:16:09,837]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:16:23,813]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:16:28,824]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:17:00,199]\u001b[0m Trial 978 finished with value: 38.25068697208355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026973425905821627, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12151815463666094, 'dropout_rate_Layer_2': 0.041556492361646685, 'dropout_rate_Layer_3': 0.025173817850665463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2638742362943589e-05, 'l1_Layer_2': 0.0017064558656826663, 'l1_Layer_3': 9.565826581845903e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.25 | sMAPE for Validation Set is: 15.43% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 15.99 | sMAPE for Test Set is: 20.47% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:17:03,861]\u001b[0m Trial 981 finished with value: 37.80296668064217 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026398642470904033, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10300582565895086, 'dropout_rate_Layer_2': 0.051534983831779485, 'dropout_rate_Layer_3': 0.0257763141315561, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4538529262353352e-05, 'l1_Layer_2': 6.109306528665493e-05, 'l1_Layer_3': 8.725882902166464e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 65, 'n_units_Layer_3': 115}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.80 | sMAPE for Validation Set is: 15.66% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.93 | sMAPE for Test Set is: 20.77% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:17:11,121]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:17:16,377]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:17:18,151]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:17:24,313]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:17:27,695]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:17:30,772]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:17:33,420]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:17:40,937]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:18:20,770]\u001b[0m Trial 989 finished with value: 36.973741513719325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025471622263876868, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1187059824117119, 'dropout_rate_Layer_2': 0.036446483423508674, 'dropout_rate_Layer_3': 0.03220311508708472, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1906236641960792e-05, 'l1_Layer_2': 3.768969995802219e-05, 'l1_Layer_3': 5.1538103013246764e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.97 | sMAPE for Validation Set is: 15.01% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.20 | sMAPE for Test Set is: 20.34% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:18:28,175]\u001b[0m Trial 969 finished with value: 36.54150322620429 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007305697028519114, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1472957099202254, 'dropout_rate_Layer_2': 0.16688558328918424, 'dropout_rate_Layer_3': 0.2071641281402219, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7267369928565192e-05, 'l1_Layer_2': 0.0005587572824048427, 'l1_Layer_3': 2.799029679361065e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.54 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.23 | sMAPE for Test Set is: 20.81% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:18:35,594]\u001b[0m Trial 982 finished with value: 36.64417700243673 and parameters: {'n_hidden': 3, 'learning_rate': 0.000737788441126691, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17699586661612535, 'dropout_rate_Layer_2': 0.17549765375622797, 'dropout_rate_Layer_3': 0.2047275977154956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.705476530918456e-05, 'l1_Layer_2': 0.0008266946398192529, 'l1_Layer_3': 1.666997934315273e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 260, 'n_units_Layer_3': 155}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.64 | sMAPE for Validation Set is: 15.04% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.41 | sMAPE for Test Set is: 20.55% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:18:38,528]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:18:43,286]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:18:46,583]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:19:02,503]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.07 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.75 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:19:04,593]\u001b[0m Trial 992 finished with value: 38.06756296190359 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022906231591813754, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11631455833487425, 'dropout_rate_Layer_2': 0.035172714772401796, 'dropout_rate_Layer_3': 0.03583657322016766, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0981722570656233e-05, 'l1_Layer_2': 4.1603158438260505e-05, 'l1_Layer_3': 6.498094773619174e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 70, 'n_units_Layer_3': 125}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:19:14,553]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:19:17,600]\u001b[0m Trial 991 finished with value: 36.94151885347049 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007358053627134159, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19524829225711632, 'dropout_rate_Layer_2': 0.17892415999202452, 'dropout_rate_Layer_3': 0.17295366207420143, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7907489649421517e-05, 'l1_Layer_2': 0.00036799945008048643, 'l1_Layer_3': 1.5599486457678732e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 155}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.94 | sMAPE for Validation Set is: 15.17% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.22 | sMAPE for Test Set is: 20.29% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:19:22,362]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:19:43,000]\u001b[0m Trial 996 finished with value: 36.61105141818191 and parameters: {'n_hidden': 3, 'learning_rate': 0.002479099820037211, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10337402473221691, 'dropout_rate_Layer_2': 0.02885330205825387, 'dropout_rate_Layer_3': 0.024308078353475912, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1384529337640426e-05, 'l1_Layer_2': 5.361922757625547e-05, 'l1_Layer_3': 4.5845010234985174e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 70, 'n_units_Layer_3': 130}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.61 | sMAPE for Validation Set is: 15.02% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.92 | sMAPE for Test Set is: 21.43% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:19:51,155]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:19:58,709]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:01,253]\u001b[0m Trial 1000 finished with value: 37.07814515713235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022544253535253965, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11045636759099974, 'dropout_rate_Layer_2': 0.030283039472414293, 'dropout_rate_Layer_3': 0.03900244093236014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0067192773195138e-05, 'l1_Layer_2': 3.609095360854341e-05, 'l1_Layer_3': 4.897167479935399e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 130}. Best is trial 850 with value: 35.67097545047712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.08 | sMAPE for Validation Set is: 15.38% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.91 | sMAPE for Test Set is: 20.96% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:20:07,234]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:08,797]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:14,153]\u001b[0m Trial 1002 finished with value: 35.6644780026823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018084601586392287, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1036468744020028, 'dropout_rate_Layer_2': 0.031012667378835356, 'dropout_rate_Layer_3': 0.04690210256153051, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3859351403769148e-05, 'l1_Layer_2': 5.886279195202749e-05, 'l1_Layer_3': 4.5607670818679405e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.66 | sMAPE for Validation Set is: 14.76% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 16.04 | sMAPE for Test Set is: 20.76% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:20:16,179]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:18,918]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:22,674]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:26,318]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:28,149]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:28,965]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:33,595]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:37,204]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:38,286]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:20:44,237]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:21:02,407]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:21:13,922]\u001b[0m Trial 1011 finished with value: 36.67813609102807 and parameters: {'n_hidden': 3, 'learning_rate': 0.001715395967583288, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10490942669623987, 'dropout_rate_Layer_2': 0.022136089703780396, 'dropout_rate_Layer_3': 0.042338992257144645, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0072882151048655e-05, 'l1_Layer_2': 4.565917392173006e-05, 'l1_Layer_3': 2.2485721605078567e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.68 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.85 | sMAPE for Test Set is: 20.75% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:21:18,367]\u001b[0m Trial 1013 finished with value: 36.962155027227475 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019964537225181933, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11600893597280479, 'dropout_rate_Layer_2': 0.01633875195564881, 'dropout_rate_Layer_3': 0.03568973311652796, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3748027485116115e-05, 'l1_Layer_2': 3.0832429282075144e-05, 'l1_Layer_3': 3.208044718667817e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.96 | sMAPE for Validation Set is: 15.28% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.36 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:21:20,705]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:21:29,409]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:21:35,910]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:21:41,000]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:21:48,159]\u001b[0m Trial 1020 finished with value: 36.05667609711155 and parameters: {'n_hidden': 3, 'learning_rate': 0.002021996039797367, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11759659729899599, 'dropout_rate_Layer_2': 0.011730721189543353, 'dropout_rate_Layer_3': 0.04975614582070534, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0049058035138706e-05, 'l1_Layer_2': 3.526581170565407e-05, 'l1_Layer_3': 3.3633926493747554e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.06 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.64 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:22:22,438]\u001b[0m Trial 1027 finished with value: 37.50851808175694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013664159950371882, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10579567414796372, 'dropout_rate_Layer_2': 0.017775689569263557, 'dropout_rate_Layer_3': 0.04821724954755317, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0144566401039285e-05, 'l1_Layer_2': 2.642890075572754e-05, 'l1_Layer_3': 2.5679788904872112e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.51 | sMAPE for Validation Set is: 15.36% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.16 | sMAPE for Test Set is: 21.25% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:22:26,000]\u001b[0m Trial 1025 finished with value: 35.919071902775904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016231028278878587, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10752766307543406, 'dropout_rate_Layer_2': 0.009427733849306416, 'dropout_rate_Layer_3': 0.04843468168538184, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3538250564711266e-05, 'l1_Layer_2': 3.6869322544780695e-05, 'l1_Layer_3': 2.4277484180490523e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.92 | sMAPE for Validation Set is: 14.80% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.26 | sMAPE for Test Set is: 20.31% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:22:32,156]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:22:43,358]\u001b[0m Trial 1029 finished with value: 73.27071062002324 and parameters: {'n_hidden': 3, 'learning_rate': 0.0393757533986911, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33912845988715234, 'dropout_rate_Layer_2': 0.2571521893709909, 'dropout_rate_Layer_3': 0.07937547184122083, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.316303162459337e-05, 'l1_Layer_2': 3.415720123467564e-05, 'l1_Layer_3': 1.833563083151132e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 130, 'n_units_Layer_3': 85}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.27 | sMAPE for Validation Set is: 26.91% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 31.69 | sMAPE for Test Set is: 30.70% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:22:47,081]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:22:49,809]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:22:50,516]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:22:59,570]\u001b[0m Trial 1026 finished with value: 37.125655590922364 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008932872583521324, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14067536879634965, 'dropout_rate_Layer_2': 0.17103408518318733, 'dropout_rate_Layer_3': 0.2151456287893999, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1238461451664368e-05, 'l1_Layer_2': 0.00034215843054376905, 'l1_Layer_3': 1.0016649716238465e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 250, 'n_units_Layer_3': 160}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.13 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.02 | sMAPE for Test Set is: 20.18% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:23:07,924]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:23:08,298]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:23:15,055]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:23:18,449]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:23:30,890]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:23:37,938]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:23:47,239]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:23:56,109]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:24:01,173]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:24:13,972]\u001b[0m Trial 1037 finished with value: 36.254759756544225 and parameters: {'n_hidden': 3, 'learning_rate': 0.001760449128336606, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1038309430274515, 'dropout_rate_Layer_2': 0.009154195983298988, 'dropout_rate_Layer_3': 0.05461125105174555, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0060381328122231e-05, 'l1_Layer_2': 2.0787467611414026e-05, 'l1_Layer_3': 2.473561265928839e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.25 | sMAPE for Validation Set is: 14.98% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.72 | sMAPE for Test Set is: 19.86% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:24:22,904]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:24:32,727]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:24:39,178]\u001b[0m Trial 1033 finished with value: 37.29159265166249 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008046675803822832, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19964727904200802, 'dropout_rate_Layer_2': 0.18034939974307096, 'dropout_rate_Layer_3': 0.21739266144064065, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0437315096648068e-05, 'l1_Layer_2': 0.000363734821935038, 'l1_Layer_3': 1.0128932168672217e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 250, 'n_units_Layer_3': 150}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.29 | sMAPE for Validation Set is: 15.40% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.51 | sMAPE for Test Set is: 21.00% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:24:48,558]\u001b[0m Trial 1044 finished with value: 38.87017444360189 and parameters: {'n_hidden': 3, 'learning_rate': 0.001428483398755336, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10484089109254933, 'dropout_rate_Layer_2': 0.022402757632144405, 'dropout_rate_Layer_3': 0.04786124885544347, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0298678172008172e-05, 'l1_Layer_2': 3.623021532671973e-05, 'l1_Layer_3': 1.8180341761047524e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 60, 'n_units_Layer_3': 140}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.87 | sMAPE for Validation Set is: 16.22% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 16.10 | sMAPE for Test Set is: 21.91% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:24:50,933]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:24:53,208]\u001b[0m Trial 1048 finished with value: 81.88563960775316 and parameters: {'n_hidden': 3, 'learning_rate': 0.04482820193202674, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32943864214002605, 'dropout_rate_Layer_2': 0.23806191044612182, 'dropout_rate_Layer_3': 0.24916949998354737, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.113579914670576e-05, 'l1_Layer_2': 0.0007596845075770472, 'l1_Layer_3': 3.685956915907115e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 125, 'n_units_Layer_3': 85}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 81.89 | sMAPE for Validation Set is: 30.20% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 57.46 | sMAPE for Test Set is: 91.43% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:25:14,282]\u001b[0m Trial 1043 finished with value: 37.442296417048084 and parameters: {'n_hidden': 3, 'learning_rate': 0.001039665544155523, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16735111081682208, 'dropout_rate_Layer_2': 0.18068602751636084, 'dropout_rate_Layer_3': 0.23431500613783712, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0858595890812187e-05, 'l1_Layer_2': 0.0006016426202260044, 'l1_Layer_3': 3.120037061697063e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.44 | sMAPE for Validation Set is: 15.38% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.97 | sMAPE for Test Set is: 21.04% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:25:17,607]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:25:33,347]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:25:33,918]\u001b[0m Trial 1051 finished with value: 36.48931936109976 and parameters: {'n_hidden': 3, 'learning_rate': 0.001682255047216022, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09818659440563397, 'dropout_rate_Layer_2': 0.0012652475906200483, 'dropout_rate_Layer_3': 0.048606768733915263, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.003631316261899e-05, 'l1_Layer_2': 1.7664910544768913e-05, 'l1_Layer_3': 3.1562697850956885e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 135}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.49 | sMAPE for Validation Set is: 15.25% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.34 | sMAPE for Test Set is: 20.56% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:25:41,477]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:26:15,210]\u001b[0m Trial 1052 finished with value: 35.863362053452924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014769097936256595, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0952796561272084, 'dropout_rate_Layer_2': 0.013156521727508006, 'dropout_rate_Layer_3': 0.05691235681941912, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2423336244527243e-05, 'l1_Layer_2': 1.4967176547791566e-05, 'l1_Layer_3': 3.1773557192592726e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 50, 'n_units_Layer_3': 135}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.86 | sMAPE for Validation Set is: 14.85% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.04 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:26:17,645]\u001b[0m Trial 1054 finished with value: 36.68523783193398 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015970937264173203, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11204186612718352, 'dropout_rate_Layer_2': 0.0051245224602195355, 'dropout_rate_Layer_3': 0.056082609739996334, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.196770494211907e-05, 'l1_Layer_2': 1.5312935661655832e-05, 'l1_Layer_3': 3.2179859433393164e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 140}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.69 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 16.20 | sMAPE for Test Set is: 21.39% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:26:20,474]\u001b[0m Trial 1053 finished with value: 36.377571356962505 and parameters: {'n_hidden': 3, 'learning_rate': 0.001602751806968347, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11285094559592897, 'dropout_rate_Layer_2': 0.012836980710509108, 'dropout_rate_Layer_3': 0.049976116759324514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2500229685775425e-05, 'l1_Layer_2': 3.5551423221426965e-05, 'l1_Layer_3': 2.86984086125327e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.38 | sMAPE for Validation Set is: 15.10% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.41 | sMAPE for Test Set is: 20.47% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:26:22,611]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:26:31,024]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:26:36,292]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:26:52,971]\u001b[0m Trial 1056 finished with value: 38.511937233820085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005399123275550939, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22949979318346986, 'dropout_rate_Layer_2': 0.19794269887503657, 'dropout_rate_Layer_3': 0.1790955214080944, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4015448819023702e-05, 'l1_Layer_2': 0.000762859389785778, 'l1_Layer_3': 2.2435038495817622e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.51 | sMAPE for Validation Set is: 15.71% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 15.67 | sMAPE for Test Set is: 20.55% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:27:04,050]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:27:08,551]\u001b[0m Trial 1058 finished with value: 37.12987466008303 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015764881708873319, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10839271998316886, 'dropout_rate_Layer_2': 0.011501818628022561, 'dropout_rate_Layer_3': 0.053373177879445476, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2462895505262988e-05, 'l1_Layer_2': 1.237773798455274e-05, 'l1_Layer_3': 2.5405653326790906e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 135}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.13 | sMAPE for Validation Set is: 15.24% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.63 | sMAPE for Test Set is: 20.72% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:27:16,238]\u001b[0m Trial 1062 finished with value: 37.769593026535915 and parameters: {'n_hidden': 3, 'learning_rate': 0.001623223348530275, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09848887145853574, 'dropout_rate_Layer_2': 0.008890287090138681, 'dropout_rate_Layer_3': 0.051978388147828805, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.431732562014448e-05, 'l1_Layer_2': 1.852955127390698e-05, 'l1_Layer_3': 3.165584771422336e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.77 | sMAPE for Validation Set is: 15.56% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.09 | sMAPE for Test Set is: 21.49% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:27:21,168]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:27:21,449]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:27:22,560]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:27:32,468]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:27:35,534]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:27:51,320]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:27:59,087]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:28:30,198]\u001b[0m Trial 1071 finished with value: 36.326645068829286 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013180992852229478, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10842353096164582, 'dropout_rate_Layer_2': 0.013096710906278829, 'dropout_rate_Layer_3': 0.06652348533542261, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.280247554778578e-05, 'l1_Layer_2': 1.0171686976452732e-05, 'l1_Layer_3': 2.5943679687564985e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 140}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.33 | sMAPE for Validation Set is: 14.98% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.65 | sMAPE for Test Set is: 20.39% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:28:40,112]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:28:46,268]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:28:56,504]\u001b[0m Trial 1063 finished with value: 36.95283467531649 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006723559060732422, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12551999323659147, 'dropout_rate_Layer_2': 0.1290869361843036, 'dropout_rate_Layer_3': 0.203486933366696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8138171905854804e-05, 'l1_Layer_2': 0.000991638479477056, 'l1_Layer_3': 1.729601359124855e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 1002 with value: 35.6644780026823.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.95 | sMAPE for Validation Set is: 15.30% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.53 | sMAPE for Test Set is: 21.85% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:29:02,137]\u001b[0m Trial 1073 finished with value: 35.6460842201652 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017008359621191436, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10950761471584415, 'dropout_rate_Layer_2': 0.01679472385334005, 'dropout_rate_Layer_3': 0.06498142884687297, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2981013279057636e-05, 'l1_Layer_2': 1.012978947556059e-05, 'l1_Layer_3': 1.5201425785806312e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 140}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.65 | sMAPE for Validation Set is: 14.75% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.26 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:29:11,695]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:29:16,507]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:29:22,654]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:29:34,292]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:29:36,480]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:29:43,686]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:29:45,921]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:29:53,928]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:30:15,794]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:30:27,936]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:30:50,754]\u001b[0m Trial 1077 finished with value: 37.45560360231463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007931501976815458, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1425017808124863, 'dropout_rate_Layer_2': 0.14741372051944196, 'dropout_rate_Layer_3': 0.18563919501013426, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5558960367911218e-05, 'l1_Layer_2': 0.0005086435404334436, 'l1_Layer_3': 1.3662830047386195e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 235, 'n_units_Layer_3': 155}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.46 | sMAPE for Validation Set is: 15.39% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.35 | sMAPE for Test Set is: 20.18% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:30:53,589]\u001b[0m Trial 1088 finished with value: 73.37591976566243 and parameters: {'n_hidden': 3, 'learning_rate': 0.04589381506420297, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3452857917844978, 'dropout_rate_Layer_2': 0.16371827631152275, 'dropout_rate_Layer_3': 0.2702741269410517, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.6122728699441e-05, 'l1_Layer_2': 0.0011884465182425206, 'l1_Layer_3': 2.191216766452059e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 65, 'n_units_Layer_3': 95}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.38 | sMAPE for Validation Set is: 27.06% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 33.46 | sMAPE for Test Set is: 31.40% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:31:11,462]\u001b[0m Trial 1087 finished with value: 36.84286854916667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018091914223358832, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10189347084406299, 'dropout_rate_Layer_2': 0.00981079419546153, 'dropout_rate_Layer_3': 0.05727778328063113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5246499030145809e-05, 'l1_Layer_2': 1.0138165397100579e-05, 'l1_Layer_3': 2.288262401187168e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.84 | sMAPE for Validation Set is: 15.44% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.98 | sMAPE for Test Set is: 20.23% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:31:23,608]\u001b[0m Trial 1081 finished with value: 36.11759911864829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012876349756927345, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12224445030139339, 'dropout_rate_Layer_2': 0.0004228616272916267, 'dropout_rate_Layer_3': 0.054736427379136074, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0105310793409906e-05, 'l1_Layer_2': 1.5145968375825548e-05, 'l1_Layer_3': 2.1235567813438662e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.12 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 17.37 | sMAPE for Test Set is: 22.02% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:31:33,694]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:31:38,683]\u001b[0m Trial 1090 finished with value: 37.23431493063879 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018137221353020526, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1024021829867626, 'dropout_rate_Layer_2': 0.009633964116653656, 'dropout_rate_Layer_3': 0.06093797017200662, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.55080942002656e-05, 'l1_Layer_2': 3.518824450151813e-05, 'l1_Layer_3': 2.286497669769167e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.23 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.55 | sMAPE for Test Set is: 20.37% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:31:48,989]\u001b[0m Trial 1089 finished with value: 36.677225315557514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018084192483212994, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10340343656344125, 'dropout_rate_Layer_2': 0.00975457095882952, 'dropout_rate_Layer_3': 0.05988294713426237, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4903683110461573e-05, 'l1_Layer_2': 2.2128376436292618e-05, 'l1_Layer_3': 2.457723561827529e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.68 | sMAPE for Validation Set is: 15.17% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.03 | sMAPE for Test Set is: 20.25% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:31:52,174]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:31:58,289]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:32:01,781]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:32:07,495]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:32:16,390]\u001b[0m Trial 1091 finished with value: 36.46466056913859 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018005532213646747, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11359894368420476, 'dropout_rate_Layer_2': 0.009857557086242348, 'dropout_rate_Layer_3': 0.0596430367347295, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4870792221042392e-05, 'l1_Layer_2': 1.2613964336031736e-05, 'l1_Layer_3': 2.2214760320230333e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.46 | sMAPE for Validation Set is: 15.18% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.58 | sMAPE for Test Set is: 20.98% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:32:17,284]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:32:23,000]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:32:27,590]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:32:54,953]\u001b[0m Trial 1097 finished with value: 36.27494500649042 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014503649925468702, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1043794190516222, 'dropout_rate_Layer_2': 0.002113412121510465, 'dropout_rate_Layer_3': 0.06599148810951018, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2581274839913396e-05, 'l1_Layer_2': 1.290546397422378e-05, 'l1_Layer_3': 1.6230009094761594e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 60, 'n_units_Layer_3': 135}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.27 | sMAPE for Validation Set is: 15.01% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.01 | sMAPE for Test Set is: 19.93% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:33:09,421]\u001b[0m Trial 1103 finished with value: 36.97561615293918 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018751913954014171, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12253968153046121, 'dropout_rate_Layer_2': 0.0006462505763122229, 'dropout_rate_Layer_3': 0.0716513880089139, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4475972109550427e-05, 'l1_Layer_2': 1.3469128175785814e-05, 'l1_Layer_3': 2.028738372419366e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.98 | sMAPE for Validation Set is: 15.30% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.98 | sMAPE for Test Set is: 20.95% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:33:12,352]\u001b[0m Trial 1102 finished with value: 35.86665875281979 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016829617508339178, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12232226458297808, 'dropout_rate_Layer_2': 0.0014020286892848035, 'dropout_rate_Layer_3': 0.07278503741527219, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4670407710424692e-05, 'l1_Layer_2': 1.0180985569875561e-05, 'l1_Layer_3': 1.6951487434844235e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.87 | sMAPE for Validation Set is: 15.00% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.47 | sMAPE for Test Set is: 20.63% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:33:16,578]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:33:21,286]\u001b[0m Trial 1101 finished with value: 35.880540764877914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018091631458998563, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10043738091385432, 'dropout_rate_Layer_2': 0.0008394275094052474, 'dropout_rate_Layer_3': 0.07100038868405747, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7420179869330204e-05, 'l1_Layer_2': 2.6335914240340786e-05, 'l1_Layer_3': 1.6021219308025395e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.88 | sMAPE for Validation Set is: 14.72% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.71 | sMAPE for Test Set is: 19.87% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:33:26,405]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:33:29,438]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:33:33,464]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:33:34,349]\u001b[0m Trial 1104 finished with value: 60.59835498464397 and parameters: {'n_hidden': 3, 'learning_rate': 0.04670117663431061, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3464658235041663, 'dropout_rate_Layer_2': 0.2535746542340377, 'dropout_rate_Layer_3': 0.243878454878233, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.921329073199064e-05, 'l1_Layer_2': 0.0012510570137533234, 'l1_Layer_3': 1.86618548576879e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 100}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.60 | sMAPE for Validation Set is: 22.94% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 38.05 | sMAPE for Test Set is: 34.87% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:33:41,483]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:33:42,001]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:33:48,058]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:33:48,137]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:33:49,333]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:33:57,280]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:33:59,808]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:34:03,496]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:34:05,743]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:34:10,479]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:34:15,743]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:34:24,157]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:34:32,544]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:34:55,134]\u001b[0m Trial 1120 finished with value: 36.25814884302003 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018720409567508495, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10481735652032743, 'dropout_rate_Layer_2': 0.0203476232178812, 'dropout_rate_Layer_3': 0.05820459173027151, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1974039881669935e-05, 'l1_Layer_2': 1.80347677530813e-05, 'l1_Layer_3': 2.200927756778822e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 1073 with value: 35.6460842201652.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.26 | sMAPE for Validation Set is: 15.02% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.07 | sMAPE for Test Set is: 19.92% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:34:55,869]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:34:58,950]\u001b[0m Trial 1115 finished with value: 35.52422351637699 and parameters: {'n_hidden': 3, 'learning_rate': 0.001494009670912756, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1056642255703592, 'dropout_rate_Layer_2': 0.02021403389629737, 'dropout_rate_Layer_3': 0.060785181685534574, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.224451662520729e-05, 'l1_Layer_2': 1.7949651705106036e-05, 'l1_Layer_3': 2.2387717365808243e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 60, 'n_units_Layer_3': 145}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.52 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.45 | sMAPE for Test Set is: 20.91% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:35:05,345]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:35:08,830]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:35:16,629]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:35:25,079]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:35:30,521]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:35:53,630]\u001b[0m Trial 1128 finished with value: 36.11565464486844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015278776647169026, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12403198931402193, 'dropout_rate_Layer_2': 0.021835114086944767, 'dropout_rate_Layer_3': 0.055494172490128835, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1910766499393327e-05, 'l1_Layer_2': 1.9128712109447632e-05, 'l1_Layer_3': 2.2909669015535835e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 145}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.12 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 16.00 | sMAPE for Test Set is: 21.22% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:35:57,289]\u001b[0m Trial 1119 finished with value: 37.29438223380173 and parameters: {'n_hidden': 3, 'learning_rate': 0.000623765760017138, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17243722004761639, 'dropout_rate_Layer_2': 0.18808117441897634, 'dropout_rate_Layer_3': 0.15283647083778007, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.199539490581049e-05, 'l1_Layer_2': 0.0014666467183997581, 'l1_Layer_3': 3.453304082791406e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.29 | sMAPE for Validation Set is: 15.38% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.90 | sMAPE for Test Set is: 21.01% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:35:58,600]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:36:03,417]\u001b[0m Trial 1130 finished with value: 36.63442165091051 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018454174492293402, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1223560560933957, 'dropout_rate_Layer_2': 0.025996826899951114, 'dropout_rate_Layer_3': 0.05743047088441901, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2062859595712684e-05, 'l1_Layer_2': 1.7937555672003363e-05, 'l1_Layer_3': 2.319854097412298e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 145}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.63 | sMAPE for Validation Set is: 15.12% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.54 | sMAPE for Test Set is: 20.67% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:36:06,671]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:36:11,479]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:36:18,102]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:36:22,086]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:36:26,645]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:36:31,786]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.88 | sMAPE for Validation Set is: 14.79% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.92 | sMAPE for Test Set is: 20.05% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:36:34,088]\u001b[0m Trial 1133 finished with value: 35.88011704655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014647270648020139, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11562806737393157, 'dropout_rate_Layer_2': 0.008581047799204237, 'dropout_rate_Layer_3': 0.058811094643845374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1543254423613489e-05, 'l1_Layer_2': 1.4636500488725103e-05, 'l1_Layer_3': 1.7535908690806673e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 55, 'n_units_Layer_3': 145}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:36:34,231]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.63 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 16.43 | sMAPE for Test Set is: 21.83% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:36:38,614]\u001b[0m Trial 1135 finished with value: 36.63112471625403 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015206260387052137, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12437725136075699, 'dropout_rate_Layer_2': 0.027618614275394734, 'dropout_rate_Layer_3': 0.05009203737848091, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0031264210477052e-05, 'l1_Layer_2': 1.856506554299147e-05, 'l1_Layer_3': 1.582919133925584e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 65, 'n_units_Layer_3': 145}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:36:45,200]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:36:49,706]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:36:50,541]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:36:53,263]\u001b[0m Trial 1144 finished with value: 81.4446069794305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0627512906341928, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20796410281202982, 'dropout_rate_Layer_2': 0.3713438182504163, 'dropout_rate_Layer_3': 0.0733265247876597, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012429906108884042, 'l1_Layer_2': 0.0019072506398306085, 'l1_Layer_3': 2.2038505472939528e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 195}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 81.44 | sMAPE for Validation Set is: 29.83% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 44.46 | sMAPE for Test Set is: 66.84% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:36:57,023]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:04,997]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:11,314]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:15,817]\u001b[0m Trial 1143 finished with value: 36.90070916686866 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019229030045863039, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12344943528967775, 'dropout_rate_Layer_2': 0.0077568171968793505, 'dropout_rate_Layer_3': 0.04793012732194002, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.379839970462398e-05, 'l1_Layer_2': 1.4334303674049725e-05, 'l1_Layer_3': 2.6860917120752765e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 60, 'n_units_Layer_3': 140}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.90 | sMAPE for Validation Set is: 15.15% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.64 | sMAPE for Test Set is: 20.55% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:37:16,413]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:17,047]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:23,832]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:24,700]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:30,701]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:33,853]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:34,319]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:37,020]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:41,314]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:48,637]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:53,128]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:37:58,789]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:38:04,667]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:38:06,583]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:38:12,027]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:38:18,361]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:38:23,321]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:38:23,511]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:38:32,410]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:38:34,003]\u001b[0m Trial 1161 finished with value: 36.35559046204974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018059262700938878, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10755107532152554, 'dropout_rate_Layer_2': 0.03337503774485921, 'dropout_rate_Layer_3': 0.06776735744710483, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8027660038819382e-05, 'l1_Layer_2': 4.948897990116704e-05, 'l1_Layer_3': 2.3405290801065967e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.36 | sMAPE for Validation Set is: 14.93% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.17 | sMAPE for Test Set is: 20.24% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:38:41,550]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:38:42,095]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:38:59,793]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:39:03,930]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:39:13,886]\u001b[0m Trial 1164 finished with value: 37.48061824956198 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009270112017336884, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11865759620109347, 'dropout_rate_Layer_2': 0.1550504697930748, 'dropout_rate_Layer_3': 0.22113198345501844, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.24553618914192e-05, 'l1_Layer_2': 0.001026980335536068, 'l1_Layer_3': 6.580592612630576e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.48 | sMAPE for Validation Set is: 15.46% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.84 | sMAPE for Test Set is: 21.68% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:39:18,151]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:39:24,069]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:39:40,489]\u001b[0m Trial 1173 finished with value: 36.72741429024957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016691537797871529, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11349943595862791, 'dropout_rate_Layer_2': 0.0005708360354469253, 'dropout_rate_Layer_3': 0.054993840509337706, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.576493877670815e-05, 'l1_Layer_2': 2.2007320541901298e-05, 'l1_Layer_3': 1.95082808481363e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 125}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.73 | sMAPE for Validation Set is: 15.12% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.95 | sMAPE for Test Set is: 20.08% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:39:58,788]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:40:07,042]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:40:14,503]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:40:27,106]\u001b[0m Trial 1178 finished with value: 37.23484455266034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006867649394152332, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12299300012182766, 'dropout_rate_Layer_2': 0.1070087816881584, 'dropout_rate_Layer_3': 0.20363519018078863, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3165260916583078e-05, 'l1_Layer_2': 0.000919448560324669, 'l1_Layer_3': 1.6854469594368113e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.23 | sMAPE for Validation Set is: 15.24% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.25 | sMAPE for Test Set is: 20.13% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:40:34,814]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:40:39,151]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:40:46,022]\u001b[0m Trial 1182 finished with value: 36.24915830223254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019675984672320817, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12338090367438148, 'dropout_rate_Layer_2': 0.03005802777346784, 'dropout_rate_Layer_3': 0.08107266577004046, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3225833458096624e-05, 'l1_Layer_2': 1.6291320138563053e-05, 'l1_Layer_3': 2.9979801231126096e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 140}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.25 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.32 | sMAPE for Test Set is: 20.78% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:40:50,729]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:40:54,175]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:40:55,454]\u001b[0m Trial 1181 finished with value: 36.58213542112647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006788643090950348, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12862389399518803, 'dropout_rate_Layer_2': 0.07107249931585986, 'dropout_rate_Layer_3': 0.2093608014117059, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8180088280540615e-05, 'l1_Layer_2': 0.0009303197111712452, 'l1_Layer_3': 1.6975350673375598e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.58 | sMAPE for Validation Set is: 15.21% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.62 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:40:58,366]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:03,146]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:10,759]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:11,559]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:17,344]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:20,715]\u001b[0m Trial 1185 finished with value: 36.163907856119856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019146987603084645, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12424844204078836, 'dropout_rate_Layer_2': 0.031979182827858284, 'dropout_rate_Layer_3': 0.07940800611091857, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3885005381128094e-05, 'l1_Layer_2': 1.533700497634858e-05, 'l1_Layer_3': 1.4693977677272704e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 240}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.16 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.69 | sMAPE for Test Set is: 20.84% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:41:24,438]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:27,972]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:32,274]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:33,641]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:37,629]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:42,023]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:44,472]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:45,972]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:50,149]\u001b[0m Trial 1194 finished with value: 37.64506612664939 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020591411783906126, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1289667042110885, 'dropout_rate_Layer_2': 0.03326117239181593, 'dropout_rate_Layer_3': 0.08151335710557567, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2318376256147854e-05, 'l1_Layer_2': 1.547926559294428e-05, 'l1_Layer_3': 3.228945619315676e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 55, 'n_units_Layer_3': 150}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.65 | sMAPE for Validation Set is: 15.45% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.96 | sMAPE for Test Set is: 21.08% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:41:54,186]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:54,617]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:41:56,284]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:42:02,404]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:42:06,348]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:42:17,002]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:42:38,715]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:42:43,008]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:43:03,358]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:43:10,678]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:43:33,759]\u001b[0m Trial 1209 finished with value: 36.64561665001528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006192853936906756, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15777721751341375, 'dropout_rate_Layer_2': 0.19051558911555663, 'dropout_rate_Layer_3': 0.29219237805985243, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.838837862883961e-05, 'l1_Layer_2': 0.0006807157972165328, 'l1_Layer_3': 2.1879881383528528e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.65 | sMAPE for Validation Set is: 15.13% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.63 | sMAPE for Test Set is: 20.96% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:43:41,721]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:43:49,564]\u001b[0m Trial 1212 finished with value: 36.746429372495335 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013304659192635386, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02907696408161222, 'dropout_rate_Layer_2': 0.01953067267850189, 'dropout_rate_Layer_3': 0.06586492516870567, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5993361530673997e-05, 'l1_Layer_2': 1.3809417437897545e-05, 'l1_Layer_3': 2.0242937472828228e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 60, 'n_units_Layer_3': 250}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.75 | sMAPE for Validation Set is: 15.05% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.00 | sMAPE for Test Set is: 19.97% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:43:55,206]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.51 | sMAPE for Validation Set is: 15.02% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.44 | sMAPE for Test Set is: 20.89% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:43:57,671]\u001b[0m Trial 1206 finished with value: 36.510830773800556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006278738701132812, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15567706814407592, 'dropout_rate_Layer_2': 0.0822584884950954, 'dropout_rate_Layer_3': 0.10792987510305797, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8134809802852287e-05, 'l1_Layer_2': 0.0007102710814964691, 'l1_Layer_3': 2.7213146927833725e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 155, 'n_units_Layer_3': 160}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:44:05,686]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:44:06,772]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:44:13,645]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:44:18,480]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:44:20,869]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:44:26,659]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:44:33,680]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:44:38,192]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:44:41,864]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:44:49,171]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:44:57,767]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:45:01,584]\u001b[0m Trial 1219 finished with value: 36.77601774645251 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006503887257338904, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15744259836488286, 'dropout_rate_Layer_2': 0.19949772990791353, 'dropout_rate_Layer_3': 0.29197140770151275, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4391323855188452e-05, 'l1_Layer_2': 0.0006075682044062023, 'l1_Layer_3': 2.0888820916792582e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.78 | sMAPE for Validation Set is: 15.20% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.01 | sMAPE for Test Set is: 20.91% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:45:05,694]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:45:09,235]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:45:13,846]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:45:20,540]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:45:22,805]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:45:25,147]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:45:26,720]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:45:31,800]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:45:46,642]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:45:57,036]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:45:57,793]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:46:02,991]\u001b[0m Trial 1241 finished with value: 70.00553604392366 and parameters: {'n_hidden': 3, 'learning_rate': 0.0542333692984055, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3271099603804558, 'dropout_rate_Layer_2': 0.26446150185161466, 'dropout_rate_Layer_3': 0.08623355966725231, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.178104923034027e-05, 'l1_Layer_2': 0.0014501125167832212, 'l1_Layer_3': 1.3421704878200309e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 115, 'n_units_Layer_3': 275}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.01 | sMAPE for Validation Set is: 25.77% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 32.22 | sMAPE for Test Set is: 30.93% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:46:06,040]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:46:22,984]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:46:33,716]\u001b[0m Trial 1246 finished with value: 61.158692231466866 and parameters: {'n_hidden': 3, 'learning_rate': 0.06493854963380301, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3116453909633461, 'dropout_rate_Layer_2': 0.2684186336186796, 'dropout_rate_Layer_3': 0.10180606461865245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012370128447120567, 'l1_Layer_2': 0.0012916174558725137, 'l1_Layer_3': 1.0839014004265637e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.16 | sMAPE for Validation Set is: 23.98% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 31.34 | sMAPE for Test Set is: 41.17% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:46:34,803]\u001b[0m Trial 1244 finished with value: 37.35188782455535 and parameters: {'n_hidden': 3, 'learning_rate': 0.001645947766517337, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002193348029293961, 'dropout_rate_Layer_2': 0.00022167392356694891, 'dropout_rate_Layer_3': 0.07539726994570323, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0992317736173714e-05, 'l1_Layer_2': 7.80339340450275e-05, 'l1_Layer_3': 4.0815473823503275e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.35 | sMAPE for Validation Set is: 15.32% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.00 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:46:41,191]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:46:42,317]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:46:43,001]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:46:55,764]\u001b[0m Trial 1237 finished with value: 36.88148310933033 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005297444210856315, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16231128647052634, 'dropout_rate_Layer_2': 0.21162714940687347, 'dropout_rate_Layer_3': 0.3305151600639312, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.768272909475894e-05, 'l1_Layer_2': 0.0005876997156116535, 'l1_Layer_3': 2.2031647080606138e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 135, 'n_units_Layer_3': 150}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.88 | sMAPE for Validation Set is: 15.28% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.96 | sMAPE for Test Set is: 21.10% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:46:56,207]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:47:05,718]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:47:09,996]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:47:16,243]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:47:16,459]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:47:22,475]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:47:28,569]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:47:42,040]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:47:45,961]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:47:56,009]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:47:58,989]\u001b[0m Trial 1255 finished with value: 35.787428794795126 and parameters: {'n_hidden': 3, 'learning_rate': 0.001443947394761748, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10590210943936143, 'dropout_rate_Layer_2': 0.012340568337007854, 'dropout_rate_Layer_3': 0.06350520256338103, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.001199206080358e-05, 'l1_Layer_2': 2.4107382733728663e-05, 'l1_Layer_3': 1.8262965311081515e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 145}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.79 | sMAPE for Validation Set is: 14.80% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.13 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:47:59,417]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:48:06,873]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:48:08,908]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:48:19,086]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:48:55,646]\u001b[0m Trial 1265 finished with value: 36.21753464686804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011669749675898146, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09416712062100972, 'dropout_rate_Layer_2': 0.0072955349487833785, 'dropout_rate_Layer_3': 0.0735915422846124, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2456063196190328e-05, 'l1_Layer_2': 5.0322752119451365e-05, 'l1_Layer_3': 2.624151850822613e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.22 | sMAPE for Validation Set is: 15.08% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.88 | sMAPE for Test Set is: 19.94% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:49:01,906]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:49:11,810]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:49:23,092]\u001b[0m Trial 1267 finished with value: 36.73651692748292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005009673860684202, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13526746434595935, 'dropout_rate_Layer_2': 0.17622086404449078, 'dropout_rate_Layer_3': 0.3393692838934816, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.995996891734596e-05, 'l1_Layer_2': 0.0006771331153156, 'l1_Layer_3': 1.9743214397580392e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.74 | sMAPE for Validation Set is: 15.17% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 16.41 | sMAPE for Test Set is: 21.59% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:49:27,372]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:49:33,519]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:49:43,372]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:49:47,143]\u001b[0m Trial 1260 finished with value: 37.06531291716481 and parameters: {'n_hidden': 3, 'learning_rate': 0.000574567585057694, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16984322098355667, 'dropout_rate_Layer_2': 0.177872575792948, 'dropout_rate_Layer_3': 0.3365904847283867, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.927765949806358e-05, 'l1_Layer_2': 0.000829648708468902, 'l1_Layer_3': 0.0005862472586136328, 'n_units_Layer_1': 195, 'n_units_Layer_2': 125, 'n_units_Layer_3': 160}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.07 | sMAPE for Validation Set is: 15.20% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.44 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:49:50,100]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:49:51,356]\u001b[0m Trial 1269 finished with value: 37.703032636319385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005885063763058892, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13498130130942915, 'dropout_rate_Layer_2': 0.025436760492178342, 'dropout_rate_Layer_3': 0.39355061508993344, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1170340880572415e-05, 'l1_Layer_2': 0.0003961812313907362, 'l1_Layer_3': 2.0241995665423232e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.70 | sMAPE for Validation Set is: 15.51% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.96 | sMAPE for Test Set is: 21.10% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:49:53,938]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:01,897]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:04,973]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:11,631]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:14,922]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:18,198]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:18,812]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:24,236]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:28,987]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:32,246]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:34,989]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:38,826]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:43,792]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:49,659]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:50:59,318]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:51:02,351]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:51:14,330]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:51:40,266]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:51:44,645]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:51:50,824]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:51:56,179]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:51:56,634]\u001b[0m Trial 1291 finished with value: 37.02223311664367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007221757192645198, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1467876599756256, 'dropout_rate_Layer_2': 0.17392802006155506, 'dropout_rate_Layer_3': 0.08800996535961053, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6260769479612867e-05, 'l1_Layer_2': 0.000485950449499684, 'l1_Layer_3': 1.1577831014070479e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.02 | sMAPE for Validation Set is: 15.34% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.35 | sMAPE for Test Set is: 20.54% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:51:57,800]\u001b[0m Trial 1295 finished with value: 36.33926571823809 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019122545769211803, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0989506089436615, 'dropout_rate_Layer_2': 0.01835938386650989, 'dropout_rate_Layer_3': 0.0822678935687031, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3592723672608212e-05, 'l1_Layer_2': 3.130209325415279e-05, 'l1_Layer_3': 2.3173221840017113e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 50, 'n_units_Layer_3': 230}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.34 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.53 | sMAPE for Test Set is: 20.62% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:52:03,433]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:52:03,873]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:52:22,599]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:52:25,430]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:52:26,334]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:52:30,002]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:52:33,120]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:52:36,052]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:52:40,728]\u001b[0m Trial 1303 finished with value: 37.29202022445935 and parameters: {'n_hidden': 3, 'learning_rate': 0.002036598374920699, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11727140678020016, 'dropout_rate_Layer_2': 0.02193642881390456, 'dropout_rate_Layer_3': 0.0969766361023956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9547030078046232e-05, 'l1_Layer_2': 3.401078973277379e-05, 'l1_Layer_3': 2.398463282448768e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 60, 'n_units_Layer_3': 225}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.29 | sMAPE for Validation Set is: 15.33% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.38 | sMAPE for Test Set is: 20.33% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:52:42,622]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:52:47,214]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:52:56,803]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:53:05,436]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:53:10,158]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:53:15,352]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:53:22,640]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:53:24,374]\u001b[0m Trial 1312 finished with value: 60.66994256633176 and parameters: {'n_hidden': 3, 'learning_rate': 0.04678579546730478, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3453981140311442, 'dropout_rate_Layer_2': 0.25083750545369227, 'dropout_rate_Layer_3': 0.09200800305313703, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019217767171560434, 'l1_Layer_2': 2.622705620189049e-05, 'l1_Layer_3': 0.0004550089888098252, 'n_units_Layer_1': 150, 'n_units_Layer_2': 85, 'n_units_Layer_3': 275}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.67 | sMAPE for Validation Set is: 23.45% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 24.79 | sMAPE for Test Set is: 27.75% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:53:29,254]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:53:45,271]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:53:50,219]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:53:52,144]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:53:57,187]\u001b[0m Trial 1311 finished with value: 37.3875752256991 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006345339666004518, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1296893681211895, 'dropout_rate_Layer_2': 0.17084259118715164, 'dropout_rate_Layer_3': 0.06377881442745806, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.476530206616333e-05, 'l1_Layer_2': 0.0006107030407439211, 'l1_Layer_3': 1.4609937911929977e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.39 | sMAPE for Validation Set is: 15.38% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.71 | sMAPE for Test Set is: 20.60% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:54:02,518]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:54:11,569]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:54:17,922]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:54:36,533]\u001b[0m Trial 1322 finished with value: 66.18445502575993 and parameters: {'n_hidden': 3, 'learning_rate': 0.04360413701201318, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3543207118813551, 'dropout_rate_Layer_2': 0.2512997011505974, 'dropout_rate_Layer_3': 0.20565928853730922, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022724547466340702, 'l1_Layer_2': 2.423974814927508e-05, 'l1_Layer_3': 0.00044186005559772567, 'n_units_Layer_1': 95, 'n_units_Layer_2': 90, 'n_units_Layer_3': 275}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 66.18 | sMAPE for Validation Set is: 24.06% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 20.55 | sMAPE for Test Set is: 24.32% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:54:47,329]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:54:50,773]\u001b[0m Trial 1327 finished with value: 51.422978334284814 and parameters: {'n_hidden': 3, 'learning_rate': 0.051762121069740395, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3247410389011482, 'dropout_rate_Layer_2': 0.25267819227061966, 'dropout_rate_Layer_3': 0.11789466588664142, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002759797182413241, 'l1_Layer_2': 3.649431540383313e-05, 'l1_Layer_3': 1.5453720341173886e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.42 | sMAPE for Validation Set is: 20.32% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 27.80 | sMAPE for Test Set is: 28.19% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:55:13,448]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:55:23,401]\u001b[0m Trial 1320 finished with value: 36.61016721425553 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006497955609700817, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1307673970589172, 'dropout_rate_Layer_2': 0.17989162619747595, 'dropout_rate_Layer_3': 0.33987109800096105, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8424118256395855e-05, 'l1_Layer_2': 0.0009690203381885486, 'l1_Layer_3': 2.118743341879729e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 145, 'n_units_Layer_3': 165}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.61 | sMAPE for Validation Set is: 15.05% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.56 | sMAPE for Test Set is: 20.94% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:55:28,665]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:55:34,492]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:55:37,456]\u001b[0m Trial 1324 finished with value: 36.808328479765954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009274158194745831, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15658858767028086, 'dropout_rate_Layer_2': 0.1810383951577628, 'dropout_rate_Layer_3': 0.2465041639959748, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3924301380111918e-05, 'l1_Layer_2': 0.000992779886227698, 'l1_Layer_3': 2.0561119543140725e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.81 | sMAPE for Validation Set is: 15.24% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.15 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:55:38,357]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:55:45,411]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:55:48,104]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:55:55,418]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:55:56,215]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:55:56,577]\u001b[0m Trial 1330 finished with value: 35.86398154089127 and parameters: {'n_hidden': 3, 'learning_rate': 0.001737391722330575, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03399478862040717, 'dropout_rate_Layer_2': 0.017213783841129246, 'dropout_rate_Layer_3': 0.05550683430696925, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6260166227664554e-05, 'l1_Layer_2': 4.703507302943542e-05, 'l1_Layer_3': 2.084555932164403e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.86 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.11 | sMAPE for Test Set is: 20.63% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:56:04,218]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:08,259]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:09,015]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:11,469]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:16,299]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:16,576]\u001b[0m Trial 1338 finished with value: 64.28804134059662 and parameters: {'n_hidden': 3, 'learning_rate': 0.05695819955322402, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35127188470448134, 'dropout_rate_Layer_2': 0.24989555059167617, 'dropout_rate_Layer_3': 0.1977642355900713, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002034957305278407, 'l1_Layer_2': 3.691978364901191e-05, 'l1_Layer_3': 1.4188277407937618e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 64.29 | sMAPE for Validation Set is: 24.91% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 24.61 | sMAPE for Test Set is: 28.83% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:56:18,701]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:25,598]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:26,478]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:27,114]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:35,798]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:36,031]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:46,225]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:46,513]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:55,015]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:56:57,962]\u001b[0m Trial 1349 finished with value: 59.7029478658289 and parameters: {'n_hidden': 3, 'learning_rate': 0.06465071652791658, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3646063286507769, 'dropout_rate_Layer_2': 0.2595160741502749, 'dropout_rate_Layer_3': 0.1986418186775654, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023757654961240092, 'l1_Layer_2': 3.8208296597384156e-05, 'l1_Layer_3': 1.2592370390254882e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.70 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 32.29 | sMAPE for Test Set is: 32.07% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:57:01,415]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:04,766]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:05,345]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:12,524]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:23,003]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:23,342]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:28,248]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:32,347]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:32,765]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:40,154]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:46,227]\u001b[0m Trial 1357 finished with value: 37.270078452037474 and parameters: {'n_hidden': 3, 'learning_rate': 0.001616108605235509, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.047753762017302026, 'dropout_rate_Layer_2': 0.0009200420420714976, 'dropout_rate_Layer_3': 0.05559762277708647, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3946913706326559e-05, 'l1_Layer_2': 1.0127565281835274e-05, 'l1_Layer_3': 1.2276174061338497e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.27 | sMAPE for Validation Set is: 15.55% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.74 | sMAPE for Test Set is: 21.09% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:57:52,100]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:56,973]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:57:59,131]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:02,522]\u001b[0m Trial 1366 finished with value: 61.64654885660559 and parameters: {'n_hidden': 3, 'learning_rate': 0.05837707224898646, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35545139343002924, 'dropout_rate_Layer_2': 0.27195686500468585, 'dropout_rate_Layer_3': 0.1883601468133136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002197679411474927, 'l1_Layer_2': 3.974015958841654e-05, 'l1_Layer_3': 1.3521169133416685e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.65 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 22.59 | sMAPE for Test Set is: 26.15% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:58:05,320]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:08,225]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:10,497]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:13,402]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:17,914]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:18,746]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:20,899]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:29,251]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:32,033]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:33,078]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:33,551]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:39,926]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:44,356]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:48,865]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:58:55,012]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:59:00,720]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:59:09,318]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:59:09,655]\u001b[0m Trial 1384 finished with value: 59.45407404110197 and parameters: {'n_hidden': 3, 'learning_rate': 0.06600969709366794, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35231092480116144, 'dropout_rate_Layer_2': 0.15855893784664185, 'dropout_rate_Layer_3': 0.21288942040858602, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002081154454899546, 'l1_Layer_2': 3.464126876919579e-05, 'l1_Layer_3': 1.4030952379161033e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.45 | sMAPE for Validation Set is: 22.83% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 32.91 | sMAPE for Test Set is: 44.02% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 08:59:21,373]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:59:27,676]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:59:33,604]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:59:37,163]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 08:59:40,730]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:01,493]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:02,873]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:06,072]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:09,753]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:11,890]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:16,959]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:21,612]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:32,958]\u001b[0m Trial 1376 finished with value: 36.386266492428724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012081842988104939, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12111706118299301, 'dropout_rate_Layer_2': 0.00913855305913144, 'dropout_rate_Layer_3': 0.07664020102762513, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2635995766164097e-05, 'l1_Layer_2': 3.313338853852025e-05, 'l1_Layer_3': 2.683634304908277e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.39 | sMAPE for Validation Set is: 14.99% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.15 | sMAPE for Test Set is: 20.40% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:00:36,472]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:41,035]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:45,768]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:46,710]\u001b[0m Trial 1399 finished with value: 57.04253629264442 and parameters: {'n_hidden': 3, 'learning_rate': 0.06581574118503866, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35245382202884884, 'dropout_rate_Layer_2': 0.2866101145976483, 'dropout_rate_Layer_3': 0.20995856741324295, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002161589877150912, 'l1_Layer_2': 4.689303318013191e-05, 'l1_Layer_3': 1.4758467768673396e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 90, 'n_units_Layer_3': 285}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.04 | sMAPE for Validation Set is: 22.35% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 28.91 | sMAPE for Test Set is: 31.22% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:00:51,937]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:56,552]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:00:59,224]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:01:05,877]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:01:06,636]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:01:12,074]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:01:12,872]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:01:20,515]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:01:22,556]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:01:31,746]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:01:32,151]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:01:40,071]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:01:46,417]\u001b[0m Trial 1406 finished with value: 57.437012345129325 and parameters: {'n_hidden': 3, 'learning_rate': 0.011256055382602787, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36654707939669184, 'dropout_rate_Layer_2': 0.28072450491595446, 'dropout_rate_Layer_3': 0.21282701552349048, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002384799307409144, 'l1_Layer_2': 4.714685120700755e-05, 'l1_Layer_3': 1.1822971747584743e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.44 | sMAPE for Validation Set is: 21.38% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 23.59 | sMAPE for Test Set is: 27.84% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:01:51,224]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:01:57,310]\u001b[0m Trial 1410 finished with value: 59.964776947120924 and parameters: {'n_hidden': 3, 'learning_rate': 0.06846979329124915, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.367345189798664, 'dropout_rate_Layer_2': 0.30748772762340204, 'dropout_rate_Layer_3': 0.21671899686516705, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018234566940725867, 'l1_Layer_2': 4.8345879883583113e-05, 'l1_Layer_3': 1.3399681474311621e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 90, 'n_units_Layer_3': 300}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.96 | sMAPE for Validation Set is: 22.84% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 22.37 | sMAPE for Test Set is: 26.85% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:02:01,897]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:02:02,742]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:02:11,475]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:02:17,405]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:02:37,260]\u001b[0m Trial 1418 finished with value: 35.95350136419471 and parameters: {'n_hidden': 3, 'learning_rate': 0.002109133884143304, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0844460592686854, 'dropout_rate_Layer_2': 0.013521108459506216, 'dropout_rate_Layer_3': 0.07144898769050313, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.145842673556016e-05, 'l1_Layer_2': 2.4768843541323388e-05, 'l1_Layer_3': 3.949829695057906e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 50, 'n_units_Layer_3': 135}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.95 | sMAPE for Validation Set is: 14.81% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.94 | sMAPE for Test Set is: 20.52% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:02:40,620]\u001b[0m Trial 1420 finished with value: 61.13694190400051 and parameters: {'n_hidden': 3, 'learning_rate': 0.006524165640600086, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36845444767887475, 'dropout_rate_Layer_2': 0.290304260636072, 'dropout_rate_Layer_3': 0.20716516773834123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024366020066226933, 'l1_Layer_2': 3.964393826199067e-05, 'l1_Layer_3': 1.0403910030427247e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.14 | sMAPE for Validation Set is: 23.48% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 28.52 | sMAPE for Test Set is: 33.01% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:02:46,450]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:01,543]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:03,730]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:08,295]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:11,038]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:19,173]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:24,587]\u001b[0m Trial 1423 finished with value: 36.0156280000383 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013502577529489414, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1126041948139941, 'dropout_rate_Layer_2': 0.03525264704034332, 'dropout_rate_Layer_3': 0.09101343168685638, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3720497501935106e-05, 'l1_Layer_2': 1.0206433930809794e-05, 'l1_Layer_3': 2.360975437213815e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.02 | sMAPE for Validation Set is: 14.92% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.02 | sMAPE for Test Set is: 20.34% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:03:29,770]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:29,829]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:32,093]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:37,906]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:40,240]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:45,159]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:48,984]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:03:57,220]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:04:00,716]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:04:06,709]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:04:07,477]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:04:16,252]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:04:25,196]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:04:49,634]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:05,687]\u001b[0m Trial 1445 finished with value: 50.56464525349757 and parameters: {'n_hidden': 3, 'learning_rate': 0.007410461859196092, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37708523855338283, 'dropout_rate_Layer_2': 0.3218516027744608, 'dropout_rate_Layer_3': 0.19893293223837025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004232684767386396, 'l1_Layer_2': 3.2210368155844594e-05, 'l1_Layer_3': 1.0042478199007596e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 85, 'n_units_Layer_3': 295}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.56 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 25.39 | sMAPE for Test Set is: 27.55% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:05:09,211]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:17,821]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:23,921]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:24,114]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:24,532]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:24,697]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:35,740]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:38,259]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:38,939]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:43,994]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:46,424]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:46,873]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:53,176]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:56,212]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:05:59,004]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:06:03,159]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:06:03,996]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:06:05,053]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:06:44,418]\u001b[0m Trial 1466 finished with value: 36.967014514236695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018071175703150888, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08254363296343821, 'dropout_rate_Layer_2': 0.008283264213360961, 'dropout_rate_Layer_3': 0.08795620406362809, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.596763147202782e-05, 'l1_Layer_2': 1.295123212812743e-05, 'l1_Layer_3': 1.6602202613269513e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 50, 'n_units_Layer_3': 145}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.97 | sMAPE for Validation Set is: 15.22% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.12 | sMAPE for Test Set is: 20.91% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:06:48,342]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:06:51,533]\u001b[0m Trial 1468 finished with value: 60.118063342842085 and parameters: {'n_hidden': 3, 'learning_rate': 0.010035186173572895, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.370172446095764, 'dropout_rate_Layer_2': 0.32060140026514067, 'dropout_rate_Layer_3': 0.18835977221361336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004011424209214996, 'l1_Layer_2': 3.8716907225151143e-05, 'l1_Layer_3': 1.0416937558104201e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 290}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.12 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 37.09 | sMAPE for Test Set is: 33.59% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:06:55,627]\u001b[0m Trial 1465 finished with value: 35.92716515823006 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017651130810534882, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11829425239809704, 'dropout_rate_Layer_2': 0.011989908913019886, 'dropout_rate_Layer_3': 0.06349782134918894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0076059330588422e-05, 'l1_Layer_2': 1.4224192382028842e-05, 'l1_Layer_3': 1.6185716653344255e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 65, 'n_units_Layer_3': 150}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.93 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.01 | sMAPE for Test Set is: 19.97% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:07:05,973]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:07:17,094]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:07:19,179]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:07:36,861]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:07:42,447]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:07:46,583]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:07:52,474]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:07:55,848]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:07:56,382]\u001b[0m Trial 1474 finished with value: 62.32092217223383 and parameters: {'n_hidden': 3, 'learning_rate': 0.009747166937662644, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37017160384297954, 'dropout_rate_Layer_2': 0.3059414143586027, 'dropout_rate_Layer_3': 0.1860373621937008, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005055473009320435, 'l1_Layer_2': 5.248237938953389e-05, 'l1_Layer_3': 1.0082125676782774e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.32 | sMAPE for Validation Set is: 22.70% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 31.16 | sMAPE for Test Set is: 31.92% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:07:56,713]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:08:06,943]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:08:10,324]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:08:15,803]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:08:16,109]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:08:34,001]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:08:37,430]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:08:44,585]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:08:50,631]\u001b[0m Trial 1481 finished with value: 54.514060075367404 and parameters: {'n_hidden': 3, 'learning_rate': 0.011138633477768164, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3729533590215689, 'dropout_rate_Layer_2': 0.3220288783225368, 'dropout_rate_Layer_3': 0.18561262246476784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005171264408028656, 'l1_Layer_2': 5.9540062906324114e-05, 'l1_Layer_3': 1.0017965629895918e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.51 | sMAPE for Validation Set is: 20.92% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 29.94 | sMAPE for Test Set is: 32.23% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:08:51,492]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:08:58,976]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:09:02,759]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:09:03,273]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:09:04,670]\u001b[0m Trial 1483 finished with value: 61.023542420033856 and parameters: {'n_hidden': 3, 'learning_rate': 0.01114792720031235, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37952790533282027, 'dropout_rate_Layer_2': 0.3087776022751945, 'dropout_rate_Layer_3': 0.18424270505876733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004183837751124689, 'l1_Layer_2': 5.155023091509004e-05, 'l1_Layer_3': 1.008666844403568e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.02 | sMAPE for Validation Set is: 22.83% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 24.76 | sMAPE for Test Set is: 27.16% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 09:09:11,646]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:09:11,979]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:09:13,599]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:09:21,218]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:09:21,265]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:09:21,608]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:09:23,615]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 09:09:45,078]\u001b[0m Trial 1499 finished with value: 37.07388083969858 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005922621970832872, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1463525284494691, 'dropout_rate_Layer_2': 0.20794518776952525, 'dropout_rate_Layer_3': 0.35639809856083626, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.429855177048751e-05, 'l1_Layer_2': 0.0005005520910733145, 'l1_Layer_3': 1.1293009654588798e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 270, 'n_units_Layer_3': 250}. Best is trial 1115 with value: 35.52422351637699.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.07 | sMAPE for Validation Set is: 15.24% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.86 | sMAPE for Test Set is: 20.88% | rMAE for Test Set is: 0.56\n",
      "for 2023-01-01, MAE is:19.67 & sMAPE is:154.46% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :19.67 & 154.46% & 0.21\n",
      "for 2023-01-02, MAE is:80.08 & sMAPE is:94.13% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :49.87 & 124.30% & 0.85\n",
      "for 2023-01-03, MAE is:20.63 & sMAPE is:15.55% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :40.12 & 88.05% & 0.86\n",
      "for 2023-01-04, MAE is:20.01 & sMAPE is:28.66% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :35.10 & 73.20% & 0.75\n",
      "for 2023-01-05, MAE is:46.36 & sMAPE is:41.85% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :37.35 & 66.93% & 0.70\n",
      "for 2023-01-06, MAE is:10.91 & sMAPE is:9.19% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :32.94 & 57.31% & 0.60\n",
      "for 2023-01-07, MAE is:14.62 & sMAPE is:17.41% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :30.33 & 51.61% & 0.54\n",
      "for 2023-01-08, MAE is:39.30 & sMAPE is:78.75% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :31.45 & 55.00% & 0.56\n",
      "for 2023-01-09, MAE is:26.80 & sMAPE is:25.22% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :30.93 & 51.69% & 0.76\n",
      "for 2023-01-10, MAE is:19.98 & sMAPE is:16.75% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :29.84 & 48.20% & 0.79\n",
      "for 2023-01-11, MAE is:32.17 & sMAPE is:57.24% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :30.05 & 49.02% & 0.85\n",
      "for 2023-01-12, MAE is:25.52 & sMAPE is:44.00% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :29.67 & 48.60% & 0.83\n",
      "for 2023-01-13, MAE is:24.32 & sMAPE is:42.44% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :29.26 & 48.13% & 0.81\n",
      "for 2023-01-14, MAE is:17.14 & sMAPE is:27.64% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :28.39 & 46.66% & 0.79\n",
      "for 2023-01-15, MAE is:20.12 & sMAPE is:66.54% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :27.84 & 47.99% & 0.78\n",
      "for 2023-01-16, MAE is:50.02 & sMAPE is:41.61% & rMAE is:3.59 ||| daily mean of MAE & sMAPE & rMAE till now are :29.23 & 47.59% & 0.95\n",
      "for 2023-01-17, MAE is:43.40 & sMAPE is:27.41% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :30.06 & 46.40% & 0.95\n",
      "for 2023-01-18, MAE is:8.86 & sMAPE is:5.58% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :28.88 & 44.13% & 0.90\n",
      "for 2023-01-19, MAE is:40.04 & sMAPE is:23.93% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :29.47 & 43.07% & 0.87\n",
      "for 2023-01-20, MAE is:15.42 & sMAPE is:8.20% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :28.77 & 41.33% & 0.84\n",
      "for 2023-01-21, MAE is:7.77 & sMAPE is:4.99% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :27.77 & 39.60% & 0.80\n",
      "for 2023-01-22, MAE is:28.14 & sMAPE is:18.20% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :27.79 & 38.62% & 0.77\n",
      "for 2023-01-23, MAE is:20.56 & sMAPE is:9.96% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :27.47 & 37.38% & 0.75\n",
      "for 2023-01-24, MAE is:21.71 & sMAPE is:10.63% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :27.23 & 36.26% & 0.76\n",
      "for 2023-01-25, MAE is:9.18 & sMAPE is:4.87% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :26.51 & 35.01% & 0.74\n",
      "for 2023-01-26, MAE is:12.63 & sMAPE is:7.20% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :25.98 & 33.94% & 0.75\n",
      "for 2023-01-27, MAE is:10.98 & sMAPE is:6.53% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :25.42 & 32.92% & 0.74\n",
      "for 2023-01-28, MAE is:10.90 & sMAPE is:7.33% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :24.90 & 32.01% & 0.75\n",
      "for 2023-01-29, MAE is:9.33 & sMAPE is:6.51% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :24.36 & 31.13% & 0.74\n",
      "for 2023-01-30, MAE is:14.81 & sMAPE is:9.49% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :24.05 & 30.41% & 0.73\n",
      "for 2023-01-31, MAE is:14.96 & sMAPE is:9.04% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :23.75 & 29.72% & 0.72\n",
      "for 2023-02-01, MAE is:12.51 & sMAPE is:8.49% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :23.40 & 29.06% & 0.70\n",
      "for 2023-02-02, MAE is:12.52 & sMAPE is:7.74% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :23.07 & 28.41% & 0.71\n",
      "for 2023-02-03, MAE is:8.81 & sMAPE is:6.47% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :22.65 & 27.76% & 0.69\n",
      "for 2023-02-04, MAE is:33.18 & sMAPE is:24.28% & rMAE is:3.63 ||| daily mean of MAE & sMAPE & rMAE till now are :22.95 & 27.66% & 0.78\n",
      "for 2023-02-05, MAE is:10.72 & sMAPE is:8.05% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :22.61 & 27.12% & 0.78\n",
      "for 2023-02-06, MAE is:16.92 & sMAPE is:9.47% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :22.46 & 26.64% & 0.78\n",
      "for 2023-02-07, MAE is:18.47 & sMAPE is:10.34% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :22.35 & 26.21% & 0.79\n",
      "for 2023-02-08, MAE is:16.88 & sMAPE is:9.99% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :22.21 & 25.80% & 0.80\n",
      "for 2023-02-09, MAE is:33.53 & sMAPE is:20.15% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :22.50 & 25.66% & 0.81\n",
      "for 2023-02-10, MAE is:16.14 & sMAPE is:9.88% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :22.34 & 25.27% & 0.81\n",
      "for 2023-02-11, MAE is:14.03 & sMAPE is:9.78% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :22.14 & 24.90% & 0.83\n",
      "for 2023-02-12, MAE is:13.18 & sMAPE is:9.83% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :21.94 & 24.55% & 0.84\n",
      "for 2023-02-13, MAE is:16.07 & sMAPE is:9.52% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :21.80 & 24.21% & 0.85\n",
      "for 2023-02-14, MAE is:19.60 & sMAPE is:12.26% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :21.75 & 23.95% & 0.86\n",
      "for 2023-02-15, MAE is:13.19 & sMAPE is:9.11% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :21.57 & 23.62% & 0.86\n",
      "for 2023-02-16, MAE is:17.35 & sMAPE is:12.46% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :21.48 & 23.39% & 0.85\n",
      "for 2023-02-17, MAE is:14.39 & sMAPE is:11.55% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :21.33 & 23.14% & 0.84\n",
      "for 2023-02-18, MAE is:13.23 & sMAPE is:11.92% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :21.16 & 22.91% & 0.83\n",
      "for 2023-02-19, MAE is:24.08 & sMAPE is:21.82% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :21.22 & 22.89% & 0.84\n",
      "for 2023-02-20, MAE is:14.03 & sMAPE is:10.00% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :21.08 & 22.63% & 0.83\n",
      "for 2023-02-21, MAE is:21.30 & sMAPE is:15.35% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :21.09 & 22.49% & 0.86\n",
      "for 2023-02-22, MAE is:11.56 & sMAPE is:7.88% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :20.91 & 22.22% & 0.87\n",
      "for 2023-02-23, MAE is:9.48 & sMAPE is:6.47% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :20.69 & 21.93% & 0.88\n",
      "for 2023-02-24, MAE is:17.33 & sMAPE is:12.34% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :20.63 & 21.75% & 0.88\n",
      "for 2023-02-25, MAE is:17.78 & sMAPE is:13.34% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :20.58 & 21.60% & 0.87\n",
      "for 2023-02-26, MAE is:18.12 & sMAPE is:16.72% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :20.54 & 21.52% & 0.88\n",
      "for 2023-02-27, MAE is:15.81 & sMAPE is:10.24% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :20.46 & 21.32% & 0.88\n",
      "for 2023-02-28, MAE is:12.15 & sMAPE is:7.74% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :20.32 & 21.09% & 0.88\n",
      "for 2023-03-01, MAE is:14.10 & sMAPE is:9.35% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :20.21 & 20.90% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-02, MAE is:33.42 & sMAPE is:21.91% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :20.43 & 20.91% & 0.91\n",
      "for 2023-03-03, MAE is:14.91 & sMAPE is:9.20% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :20.34 & 20.72% & 0.91\n",
      "for 2023-03-04, MAE is:8.14 & sMAPE is:5.80% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :20.15 & 20.49% & 0.91\n",
      "for 2023-03-05, MAE is:19.38 & sMAPE is:14.07% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :20.13 & 20.39% & 0.91\n",
      "for 2023-03-06, MAE is:15.84 & sMAPE is:9.50% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :20.07 & 20.22% & 0.92\n",
      "for 2023-03-07, MAE is:16.14 & sMAPE is:10.33% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :20.01 & 20.07% & 0.93\n",
      "for 2023-03-08, MAE is:10.49 & sMAPE is:7.64% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :19.87 & 19.88% & 0.92\n",
      "for 2023-03-09, MAE is:9.05 & sMAPE is:7.20% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :19.71 & 19.70% & 0.91\n",
      "for 2023-03-10, MAE is:7.44 & sMAPE is:6.24% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :19.53 & 19.50% & 0.90\n",
      "for 2023-03-11, MAE is:18.34 & sMAPE is:15.89% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :19.51 & 19.45% & 0.90\n",
      "for 2023-03-12, MAE is:11.35 & sMAPE is:11.69% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :19.40 & 19.34% & 0.89\n",
      "for 2023-03-13, MAE is:67.53 & sMAPE is:97.94% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :20.07 & 20.43% & 0.89\n",
      "for 2023-03-14, MAE is:44.91 & sMAPE is:73.93% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :20.41 & 21.17% & 0.88\n",
      "for 2023-03-15, MAE is:49.52 & sMAPE is:40.69% & rMAE is:4.70 ||| daily mean of MAE & sMAPE & rMAE till now are :20.80 & 21.43% & 0.93\n",
      "for 2023-03-16, MAE is:19.67 & sMAPE is:17.52% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :20.79 & 21.38% & 0.93\n",
      "for 2023-03-17, MAE is:21.84 & sMAPE is:22.48% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :20.80 & 21.39% & 0.94\n",
      "for 2023-03-18, MAE is:24.51 & sMAPE is:23.63% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :20.85 & 21.42% & 0.94\n",
      "for 2023-03-19, MAE is:18.17 & sMAPE is:17.75% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :20.81 & 21.37% & 0.95\n",
      "for 2023-03-20, MAE is:10.85 & sMAPE is:8.67% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :20.69 & 21.21% & 0.94\n",
      "for 2023-03-21, MAE is:15.07 & sMAPE is:13.61% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :20.62 & 21.12% & 0.93\n",
      "for 2023-03-22, MAE is:16.09 & sMAPE is:18.12% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :20.56 & 21.08% & 0.92\n",
      "for 2023-03-23, MAE is:20.45 & sMAPE is:25.13% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :20.56 & 21.13% & 0.92\n",
      "for 2023-03-24, MAE is:24.00 & sMAPE is:44.89% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :20.60 & 21.42% & 0.91\n",
      "for 2023-03-25, MAE is:28.90 & sMAPE is:108.67% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :20.70 & 22.46% & 0.91\n",
      "for 2023-03-26, MAE is:36.53 & sMAPE is:68.27% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :20.89 & 22.99% & 0.91\n",
      "for 2023-03-27, MAE is:17.54 & sMAPE is:14.54% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :20.85 & 22.90% & 0.91\n",
      "for 2023-03-28, MAE is:12.68 & sMAPE is:10.24% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :20.75 & 22.75% & 0.91\n",
      "for 2023-03-29, MAE is:13.99 & sMAPE is:12.25% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :20.68 & 22.63% & 0.91\n",
      "for 2023-03-30, MAE is:17.36 & sMAPE is:26.87% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :20.64 & 22.68% & 0.90\n",
      "for 2023-03-31, MAE is:19.07 & sMAPE is:30.47% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :20.62 & 22.77% & 0.90\n",
      "for 2023-04-01, MAE is:12.28 & sMAPE is:21.06% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :20.53 & 22.75% & 0.90\n",
      "for 2023-04-02, MAE is:22.88 & sMAPE is:33.45% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :20.56 & 22.86% & 0.91\n",
      "for 2023-04-03, MAE is:20.15 & sMAPE is:17.01% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :20.55 & 22.80% & 0.91\n",
      "for 2023-04-04, MAE is:16.33 & sMAPE is:11.61% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :20.51 & 22.68% & 0.91\n",
      "for 2023-04-05, MAE is:22.79 & sMAPE is:16.18% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :20.53 & 22.61% & 0.91\n",
      "for 2023-04-06, MAE is:9.28 & sMAPE is:7.01% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :20.41 & 22.45% & 0.90\n",
      "for 2023-04-07, MAE is:9.26 & sMAPE is:7.81% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :20.30 & 22.30% & 0.90\n",
      "for 2023-04-08, MAE is:13.23 & sMAPE is:12.77% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :20.23 & 22.20% & 0.89\n",
      "for 2023-04-09, MAE is:16.66 & sMAPE is:17.61% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :20.19 & 22.16% & 0.88\n",
      "for 2023-04-10, MAE is:40.87 & sMAPE is:71.99% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :20.40 & 22.65% & 0.88\n",
      "for 2023-04-11, MAE is:44.65 & sMAPE is:69.06% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :20.64 & 23.11% & 0.88\n",
      "for 2023-04-12, MAE is:10.69 & sMAPE is:10.44% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :20.54 & 22.99% & 0.88\n",
      "for 2023-04-13, MAE is:25.02 & sMAPE is:21.68% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :20.58 & 22.98% & 0.88\n",
      "for 2023-04-14, MAE is:13.48 & sMAPE is:10.29% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :20.52 & 22.85% & 0.89\n",
      "for 2023-04-15, MAE is:9.69 & sMAPE is:9.20% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :20.41 & 22.72% & 0.89\n",
      "for 2023-04-16, MAE is:13.19 & sMAPE is:13.11% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :20.34 & 22.63% & 0.89\n",
      "for 2023-04-17, MAE is:16.45 & sMAPE is:12.75% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :20.31 & 22.54% & 0.88\n",
      "for 2023-04-18, MAE is:10.45 & sMAPE is:9.37% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :20.22 & 22.42% & 0.87\n",
      "for 2023-04-19, MAE is:15.42 & sMAPE is:14.93% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :20.17 & 22.35% & 0.88\n",
      "for 2023-04-20, MAE is:13.17 & sMAPE is:11.30% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :20.11 & 22.25% & 0.88\n",
      "for 2023-04-21, MAE is:15.70 & sMAPE is:13.68% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :20.07 & 22.17% & 0.88\n",
      "for 2023-04-22, MAE is:16.33 & sMAPE is:21.73% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :20.04 & 22.17% & 0.88\n",
      "for 2023-04-23, MAE is:18.70 & sMAPE is:31.89% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :20.02 & 22.26% & 0.88\n",
      "for 2023-04-24, MAE is:8.83 & sMAPE is:8.67% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :19.93 & 22.14% & 0.88\n",
      "for 2023-04-25, MAE is:8.93 & sMAPE is:7.89% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :19.83 & 22.01% & 0.88\n",
      "for 2023-04-26, MAE is:15.16 & sMAPE is:13.11% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :19.79 & 21.94% & 0.89\n",
      "for 2023-04-27, MAE is:13.94 & sMAPE is:13.26% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :19.74 & 21.86% & 0.90\n",
      "for 2023-04-28, MAE is:13.00 & sMAPE is:12.98% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :19.68 & 21.79% & 0.89\n",
      "for 2023-04-29, MAE is:14.97 & sMAPE is:15.81% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :19.64 & 21.74% & 0.90\n",
      "for 2023-04-30, MAE is:15.12 & sMAPE is:34.86% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :19.61 & 21.85% & 0.90\n",
      "for 2023-05-01, MAE is:18.53 & sMAPE is:28.85% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :19.60 & 21.90% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-02, MAE is:25.68 & sMAPE is:26.70% & rMAE is:3.85 ||| daily mean of MAE & sMAPE & rMAE till now are :19.65 & 21.94% & 0.92\n",
      "for 2023-05-03, MAE is:13.77 & sMAPE is:16.21% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :19.60 & 21.90% & 0.92\n",
      "for 2023-05-04, MAE is:10.99 & sMAPE is:12.57% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :19.53 & 21.82% & 0.91\n",
      "for 2023-05-05, MAE is:12.36 & sMAPE is:13.00% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :19.47 & 21.75% & 0.92\n",
      "for 2023-05-06, MAE is:10.31 & sMAPE is:12.58% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :19.40 & 21.68% & 0.92\n",
      "for 2023-05-07, MAE is:10.18 & sMAPE is:16.53% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :19.33 & 21.64% & 0.92\n",
      "for 2023-05-08, MAE is:18.60 & sMAPE is:22.32% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :19.32 & 21.64% & 0.92\n",
      "for 2023-05-09, MAE is:9.29 & sMAPE is:8.96% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :19.24 & 21.54% & 0.92\n",
      "for 2023-05-10, MAE is:16.58 & sMAPE is:17.28% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :19.22 & 21.51% & 0.92\n",
      "for 2023-05-11, MAE is:22.05 & sMAPE is:21.11% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :19.24 & 21.51% & 0.92\n",
      "for 2023-05-12, MAE is:10.47 & sMAPE is:10.40% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :19.18 & 21.42% & 0.92\n",
      "for 2023-05-13, MAE is:17.25 & sMAPE is:30.78% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :19.16 & 21.49% & 0.92\n",
      "for 2023-05-14, MAE is:21.20 & sMAPE is:59.30% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :19.18 & 21.78% & 0.92\n",
      "for 2023-05-15, MAE is:11.14 & sMAPE is:12.98% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :19.12 & 21.71% & 0.92\n",
      "for 2023-05-16, MAE is:14.92 & sMAPE is:21.75% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :19.09 & 21.71% & 0.92\n",
      "for 2023-05-17, MAE is:18.88 & sMAPE is:26.90% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :19.09 & 21.75% & 0.92\n",
      "for 2023-05-18, MAE is:19.85 & sMAPE is:27.25% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :19.09 & 21.79% & 0.91\n",
      "for 2023-05-19, MAE is:8.75 & sMAPE is:11.41% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :19.02 & 21.71% & 0.91\n",
      "for 2023-05-20, MAE is:25.17 & sMAPE is:66.51% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :19.06 & 22.03% & 0.91\n",
      "for 2023-05-21, MAE is:24.02 & sMAPE is:94.98% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :19.10 & 22.55% & 0.91\n",
      "for 2023-05-22, MAE is:13.75 & sMAPE is:16.84% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :19.06 & 22.51% & 0.91\n",
      "for 2023-05-23, MAE is:13.13 & sMAPE is:19.84% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :19.02 & 22.49% & 0.91\n",
      "for 2023-05-24, MAE is:9.42 & sMAPE is:11.85% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :18.95 & 22.42% & 0.91\n",
      "for 2023-05-25, MAE is:17.67 & sMAPE is:29.06% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :18.94 & 22.46% & 0.91\n",
      "for 2023-05-26, MAE is:17.72 & sMAPE is:37.45% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :18.93 & 22.57% & 0.92\n",
      "for 2023-05-27, MAE is:22.73 & sMAPE is:63.95% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :18.96 & 22.85% & 0.92\n",
      "for 2023-05-28, MAE is:26.12 & sMAPE is:85.19% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :19.01 & 23.27% & 0.92\n",
      "for 2023-05-29, MAE is:42.27 & sMAPE is:103.45% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :19.16 & 23.81% & 0.92\n",
      "for 2023-05-30, MAE is:16.34 & sMAPE is:23.40% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :19.15 & 23.81% & 0.93\n",
      "for 2023-05-31, MAE is:19.86 & sMAPE is:41.16% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :19.15 & 23.92% & 0.93\n",
      "for 2023-06-01, MAE is:19.52 & sMAPE is:33.36% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :19.15 & 23.98% & 0.94\n",
      "for 2023-06-02, MAE is:12.09 & sMAPE is:17.51% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :19.11 & 23.94% & 0.94\n",
      "for 2023-06-03, MAE is:19.40 & sMAPE is:61.39% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :19.11 & 24.18% & 0.95\n",
      "for 2023-06-04, MAE is:20.73 & sMAPE is:73.08% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :19.12 & 24.50% & 0.95\n",
      "for 2023-06-05, MAE is:9.01 & sMAPE is:11.04% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :19.05 & 24.41% & 0.95\n",
      "for 2023-06-06, MAE is:7.89 & sMAPE is:9.54% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :18.98 & 24.32% & 0.95\n",
      "for 2023-06-07, MAE is:21.64 & sMAPE is:27.92% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :19.00 & 24.34% & 0.95\n",
      "for 2023-06-08, MAE is:10.36 & sMAPE is:13.23% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :18.95 & 24.27% & 0.94\n",
      "for 2023-06-09, MAE is:10.58 & sMAPE is:12.64% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :18.89 & 24.20% & 0.94\n",
      "for 2023-06-10, MAE is:20.64 & sMAPE is:43.16% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :18.90 & 24.32% & 0.95\n",
      "for 2023-06-11, MAE is:20.49 & sMAPE is:70.83% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :18.91 & 24.60% & 0.96\n",
      "for 2023-06-12, MAE is:13.22 & sMAPE is:13.79% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :18.88 & 24.54% & 0.95\n",
      "for 2023-06-13, MAE is:13.08 & sMAPE is:14.71% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :18.84 & 24.48% & 0.96\n",
      "for 2023-06-14, MAE is:18.41 & sMAPE is:19.26% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :18.84 & 24.45% & 0.96\n",
      "for 2023-06-15, MAE is:23.27 & sMAPE is:22.42% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :18.87 & 24.43% & 0.96\n",
      "for 2023-06-16, MAE is:21.36 & sMAPE is:17.69% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :18.88 & 24.39% & 0.95\n",
      "for 2023-06-17, MAE is:16.16 & sMAPE is:18.52% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :18.87 & 24.36% & 0.95\n",
      "for 2023-06-18, MAE is:15.71 & sMAPE is:21.36% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :18.85 & 24.34% & 0.95\n",
      "for 2023-06-19, MAE is:15.77 & sMAPE is:13.70% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :18.83 & 24.28% & 0.95\n",
      "for 2023-06-20, MAE is:11.29 & sMAPE is:9.30% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :18.79 & 24.19% & 0.95\n",
      "for 2023-06-21, MAE is:19.57 & sMAPE is:16.14% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :18.79 & 24.14% & 0.95\n",
      "for 2023-06-22, MAE is:11.72 & sMAPE is:9.50% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :18.75 & 24.06% & 0.94\n",
      "for 2023-06-23, MAE is:13.13 & sMAPE is:12.33% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :18.72 & 23.99% & 0.94\n",
      "for 2023-06-24, MAE is:21.69 & sMAPE is:41.45% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :18.73 & 24.09% & 0.94\n",
      "for 2023-06-25, MAE is:25.25 & sMAPE is:63.49% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :18.77 & 24.31% & 0.94\n",
      "for 2023-06-26, MAE is:21.57 & sMAPE is:22.59% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :18.79 & 24.30% & 0.94\n",
      "for 2023-06-27, MAE is:14.42 & sMAPE is:14.15% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :18.76 & 24.25% & 0.94\n",
      "for 2023-06-28, MAE is:8.29 & sMAPE is:7.64% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :18.70 & 24.16% & 0.94\n",
      "for 2023-06-29, MAE is:9.96 & sMAPE is:9.46% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :18.65 & 24.07% & 0.94\n",
      "for 2023-06-30, MAE is:10.41 & sMAPE is:10.23% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :18.61 & 24.00% & 0.94\n",
      "CPU times: total: 2d 3h 45min 48s\n",
      "Wall time: 1d 18min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
