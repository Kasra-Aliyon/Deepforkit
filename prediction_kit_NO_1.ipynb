{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 'NO_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:52:51,661]\u001b[0m A new study created in RDB with name: NO_1_2018\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:53:06,467]\u001b[0m Trial 0 finished with value: 1.6771284359393837 and parameters: {'n_hidden': 4, 'learning_rate': 0.005338659054776288, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21081323650666073, 'dropout_rate_Layer_2': 0.14522718641514773, 'dropout_rate_Layer_3': 0.03858861625273527, 'dropout_rate_Layer_4': 0.08853416772145915, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00956223873709739, 'l1_Layer_2': 0.0024944615775773712, 'l1_Layer_3': 1.2017877810703648e-05, 'l1_Layer_4': 1.5045791422355723e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 100, 'n_units_Layer_3': 100, 'n_units_Layer_4': 155}. Best is trial 0 with value: 1.6771284359393837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 5.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.54 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:53:32,487]\u001b[0m Trial 1 finished with value: 1.9632162596793148 and parameters: {'n_hidden': 3, 'learning_rate': 0.01087391037934887, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22756369418103542, 'dropout_rate_Layer_2': 0.21576157744369917, 'dropout_rate_Layer_3': 0.3435256504337793, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.8955824014228976e-05, 'l1_Layer_2': 0.005153511315969885, 'l1_Layer_3': 0.033906597143925465, 'n_units_Layer_1': 140, 'n_units_Layer_2': 290, 'n_units_Layer_3': 195}. Best is trial 0 with value: 1.6771284359393837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 6.79% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.61 | sMAPE for Test Set is: 26.29% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:53:40,360]\u001b[0m Trial 2 finished with value: 3.861697219408201 and parameters: {'n_hidden': 3, 'learning_rate': 0.07400985904865695, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09666774146545697, 'dropout_rate_Layer_2': 0.32150586974658174, 'dropout_rate_Layer_3': 0.27371030482170555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001670923165786491, 'l1_Layer_2': 1.9270558416118403e-05, 'l1_Layer_3': 8.815324119702735e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 285, 'n_units_Layer_3': 260}. Best is trial 0 with value: 1.6771284359393837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 1.41\n",
      "MAE for Test Set is: 18.39 | sMAPE for Test Set is: 50.62% | rMAE for Test Set is: 3.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:53:48,403]\u001b[0m Trial 4 finished with value: 1.8336514289152683 and parameters: {'n_hidden': 3, 'learning_rate': 0.015306169151887717, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24916391655650233, 'dropout_rate_Layer_2': 0.24862714723820398, 'dropout_rate_Layer_3': 0.19276747320603327, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08506691700361033, 'l1_Layer_2': 0.09523818027987487, 'l1_Layer_3': 0.02845037006854835, 'n_units_Layer_1': 230, 'n_units_Layer_2': 115, 'n_units_Layer_3': 130}. Best is trial 0 with value: 1.6771284359393837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.83 | sMAPE for Validation Set is: 6.23% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 13.19 | sMAPE for Test Set is: 33.46% | rMAE for Test Set is: 2.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:53:51,171]\u001b[0m Trial 3 finished with value: 1.7722625257005458 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018828161160056377, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09647791278459006, 'dropout_rate_Layer_2': 0.0276078971789278, 'dropout_rate_Layer_3': 0.02282015148231964, 'dropout_rate_Layer_4': 0.08675918604875905, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0047271279171189635, 'l1_Layer_2': 0.0009430042414864362, 'l1_Layer_3': 0.001481490799045238, 'l1_Layer_4': 0.005777748565508883, 'n_units_Layer_1': 265, 'n_units_Layer_2': 170, 'n_units_Layer_3': 165, 'n_units_Layer_4': 205}. Best is trial 0 with value: 1.6771284359393837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.77 | sMAPE for Validation Set is: 6.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.64 | sMAPE for Test Set is: 20.87% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:53:52,232]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:53:54,881]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:53:57,989]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:53:59,435]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:54:01,612]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:54:03,734]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:54:04,943]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:54:08,369]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:54:15,704]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:54:27,360]\u001b[0m Trial 14 finished with value: 1.9054000858044047 and parameters: {'n_hidden': 3, 'learning_rate': 0.0654379106529848, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06821119337583896, 'dropout_rate_Layer_2': 0.2709792183627057, 'dropout_rate_Layer_3': 0.3517370510453152, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6926217416769257e-05, 'l1_Layer_2': 0.040843037308487457, 'l1_Layer_3': 0.024610493967524218, 'n_units_Layer_1': 200, 'n_units_Layer_2': 250, 'n_units_Layer_3': 85}. Best is trial 0 with value: 1.6771284359393837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 6.58% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 16.19% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:54:29,334]\u001b[0m Trial 15 finished with value: 3.2589933518901653 and parameters: {'n_hidden': 3, 'learning_rate': 0.06758491122002153, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31170274684607135, 'dropout_rate_Layer_2': 0.19215230412863613, 'dropout_rate_Layer_3': 0.3622433353491446, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001704011963365766, 'l1_Layer_2': 0.0009853031761117206, 'l1_Layer_3': 0.002365734255284799, 'n_units_Layer_1': 295, 'n_units_Layer_2': 290, 'n_units_Layer_3': 80}. Best is trial 0 with value: 1.6771284359393837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.26 | sMAPE for Validation Set is: 11.44% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 14.49 | sMAPE for Test Set is: 37.67% | rMAE for Test Set is: 2.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:54:34,800]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:54:39,522]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:54:42,048]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:54:45,326]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:18,969]\u001b[0m Trial 17 finished with value: 2.373751383449334 and parameters: {'n_hidden': 3, 'learning_rate': 0.011749857046726968, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3256329833647245, 'dropout_rate_Layer_2': 0.1974284232556444, 'dropout_rate_Layer_3': 0.21949578249141943, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015644429763109673, 'l1_Layer_2': 3.9685133142136805e-05, 'l1_Layer_3': 7.19753507947527e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 0 with value: 1.6771284359393837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.37 | sMAPE for Validation Set is: 8.14% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 26.12% | rMAE for Test Set is: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:55:21,400]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:23,898]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:26,356]\u001b[0m Trial 21 finished with value: 1.7555567970844173 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032507380118548235, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14756021487267199, 'dropout_rate_Layer_2': 0.3691147867767521, 'dropout_rate_Layer_3': 0.29014814214076595, 'dropout_rate_Layer_4': 0.1745059243310661, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05561656764240587, 'l1_Layer_2': 0.00015574062451031474, 'l1_Layer_3': 0.00014496378335862391, 'l1_Layer_4': 0.0036690356973511765, 'n_units_Layer_1': 110, 'n_units_Layer_2': 280, 'n_units_Layer_3': 90, 'n_units_Layer_4': 265}. Best is trial 0 with value: 1.6771284359393837.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.76 | sMAPE for Validation Set is: 6.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 25.80% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:55:29,703]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:32,322]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:35,087]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:39,613]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:42,271]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:42,631]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:45,594]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:47,320]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:49,613]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:51,108]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:56,240]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:55:59,262]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:02,567]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:05,861]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:12,852]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:14,719]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:29,458]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:35,962]\u001b[0m Trial 34 finished with value: 1.4676476120815594 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005035023676930881, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07259592117538656, 'dropout_rate_Layer_2': 0.10080998961926398, 'dropout_rate_Layer_3': 0.15975547261162376, 'dropout_rate_Layer_4': 0.03419623441976092, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004218841401437003, 'l1_Layer_2': 0.0002743406194203803, 'l1_Layer_3': 0.007119282142223374, 'l1_Layer_4': 0.0001234183917412735, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 185, 'n_units_Layer_4': 255}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 4.99% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 7.55 | sMAPE for Test Set is: 18.14% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:56:38,619]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:41,126]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:46,944]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:49,800]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:55,175]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:56:58,777]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:57:01,498]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:57:31,032]\u001b[0m Trial 50 finished with value: 1.8229222268276812 and parameters: {'n_hidden': 4, 'learning_rate': 0.004172633484820226, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1478331324919819, 'dropout_rate_Layer_2': 0.3838861522306685, 'dropout_rate_Layer_3': 0.3331133618167096, 'dropout_rate_Layer_4': 0.20558729899558076, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004654982592384831, 'l1_Layer_2': 0.004341531443961321, 'l1_Layer_3': 0.06370423839788221, 'l1_Layer_4': 0.0006991684024950789, 'n_units_Layer_1': 210, 'n_units_Layer_2': 245, 'n_units_Layer_3': 110, 'n_units_Layer_4': 55}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.82 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.04 | sMAPE for Test Set is: 19.34% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:57:35,359]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:57:40,322]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:57:42,996]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:57:52,160]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:02,588]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:05,091]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:09,303]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:12,267]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:14,421]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:19,287]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:24,527]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:29,581]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:34,557]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:37,340]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:42,305]\u001b[0m Trial 60 finished with value: 1.6666831184809876 and parameters: {'n_hidden': 4, 'learning_rate': 0.0041901658358885, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14978562724835043, 'dropout_rate_Layer_2': 0.39280684532681853, 'dropout_rate_Layer_3': 0.21466182642738818, 'dropout_rate_Layer_4': 0.2075921309343575, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007877597596349902, 'l1_Layer_2': 0.005349344607702831, 'l1_Layer_3': 0.0001903786539879883, 'l1_Layer_4': 0.0007150323186460737, 'n_units_Layer_1': 300, 'n_units_Layer_2': 295, 'n_units_Layer_3': 125, 'n_units_Layer_4': 70}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.67 | sMAPE for Validation Set is: 5.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.42 | sMAPE for Test Set is: 25.48% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:58:47,042]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:54,168]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:58:59,313]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:08,636]\u001b[0m Trial 65 finished with value: 2.4095268530375016 and parameters: {'n_hidden': 4, 'learning_rate': 0.05433798701550333, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06904566844230246, 'dropout_rate_Layer_2': 0.30725393883776986, 'dropout_rate_Layer_3': 0.18365118580375986, 'dropout_rate_Layer_4': 0.10947265833301478, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0052282233577979655, 'l1_Layer_2': 0.007451233747521348, 'l1_Layer_3': 0.0004882905396317617, 'l1_Layer_4': 0.0047741951798102025, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200, 'n_units_Layer_4': 265}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.41 | sMAPE for Validation Set is: 8.32% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 13.44 | sMAPE for Test Set is: 34.42% | rMAE for Test Set is: 2.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 10:59:12,008]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:14,611]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:17,007]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:17,164]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:22,561]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:29,511]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:34,372]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:37,610]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:37,786]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:44,635]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:49,829]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:52,745]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:55,239]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 10:59:59,526]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:01,834]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:04,613]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:07,076]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:10,029]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:11,939]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:14,282]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:19,194]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:24,494]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:28,889]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:29,204]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:36,341]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:41,476]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:41,563]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:00:48,426]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:11,168]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:19,271]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:01:40,681]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 5.58% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 15.60% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:02:00,155]\u001b[0m Trial 96 finished with value: 1.6327650722045466 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015151032628890867, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10718022725799982, 'dropout_rate_Layer_2': 0.11318858094125053, 'dropout_rate_Layer_3': 0.2697603773903526, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.030410076251243357, 'l1_Layer_2': 0.0008010105821806307, 'l1_Layer_3': 0.0001257495238461811, 'n_units_Layer_1': 190, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:02:03,719]\u001b[0m Trial 101 finished with value: 1.728117592570058 and parameters: {'n_hidden': 4, 'learning_rate': 0.002666229310444907, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10228355522587192, 'dropout_rate_Layer_2': 0.35459257604975114, 'dropout_rate_Layer_3': 0.35806507778886765, 'dropout_rate_Layer_4': 0.21457984621705084, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0024328724836577497, 'l1_Layer_2': 0.0007448229920025835, 'l1_Layer_3': 0.032770691708901206, 'l1_Layer_4': 0.00024151500725807078, 'n_units_Layer_1': 280, 'n_units_Layer_2': 270, 'n_units_Layer_3': 90, 'n_units_Layer_4': 80}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.73 | sMAPE for Validation Set is: 5.94% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.12 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:02:11,183]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:02:15,191]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:02:20,838]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:02:40,557]\u001b[0m Trial 103 finished with value: 1.727895442813468 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022594680706133764, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020230519636860733, 'dropout_rate_Layer_2': 0.35226530854052673, 'dropout_rate_Layer_3': 0.36164712838307433, 'dropout_rate_Layer_4': 0.2592952223842558, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007419233362048743, 'l1_Layer_2': 0.0004292355692414773, 'l1_Layer_3': 0.014344226886190956, 'l1_Layer_4': 2.2086479246961192e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50, 'n_units_Layer_4': 265}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.73 | sMAPE for Validation Set is: 5.91% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.75 | sMAPE for Test Set is: 23.67% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:02:45,793]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:02:47,441]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:02:52,713]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:02:57,072]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:02,475]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:09,474]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:14,672]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:29,339]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:49,601]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:53,934]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:03:54,109]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:01,855]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:07,245]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:12,303]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:19,304]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:29,322]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:34,963]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:38,987]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:43,925]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:44,276]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:04:49,478]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:05:01,461]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:05:48,550]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:06:30,248]\u001b[0m Trial 126 finished with value: 1.6149481139458313 and parameters: {'n_hidden': 3, 'learning_rate': 0.002132333612259374, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26452095997632463, 'dropout_rate_Layer_2': 0.014144435839341885, 'dropout_rate_Layer_3': 0.19184484218230693, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0014659082764072293, 'l1_Layer_2': 0.0013445066900835809, 'l1_Layer_3': 0.027590650295141343, 'n_units_Layer_1': 140, 'n_units_Layer_2': 215, 'n_units_Layer_3': 195}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.61 | sMAPE for Validation Set is: 5.51% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.67 | sMAPE for Test Set is: 23.46% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:06:35,409]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:06:42,017]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:06:55,096]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:07:04,348]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:07:19,093]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:07:26,599]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:07:41,818]\u001b[0m Trial 130 finished with value: 1.6180704854364947 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013788070339114844, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10997906802776079, 'dropout_rate_Layer_2': 0.04343188199933248, 'dropout_rate_Layer_3': 0.07444173814392717, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026661599728932197, 'l1_Layer_2': 0.0013606959657870516, 'l1_Layer_3': 0.0005202756814358658, 'n_units_Layer_1': 80, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 5.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.14 | sMAPE for Test Set is: 7.90% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:08:19,095]\u001b[0m Trial 138 finished with value: 1.6629721228548047 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018605111218843525, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30398403819498465, 'dropout_rate_Layer_2': 0.2533979388629062, 'dropout_rate_Layer_3': 0.18770775640027065, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.615314036634717e-05, 'l1_Layer_2': 0.0034252179685596777, 'l1_Layer_3': 0.0021640167418259942, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.66 | sMAPE for Validation Set is: 5.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.60 | sMAPE for Test Set is: 26.01% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:08:28,105]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:08:28,308]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:08:35,673]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:08:42,898]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:08:50,093]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:08:55,677]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:10,222]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:15,542]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:09:20,339]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:14,558]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:26,246]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:10:51,894]\u001b[0m Trial 145 finished with value: 1.653192702787104 and parameters: {'n_hidden': 3, 'learning_rate': 0.001371932619922499, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27758539134547244, 'dropout_rate_Layer_2': 0.021645321015192395, 'dropout_rate_Layer_3': 0.221388537122596, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0026928563137285895, 'l1_Layer_2': 0.0010826580592152954, 'l1_Layer_3': 0.013518872953930226, 'n_units_Layer_1': 80, 'n_units_Layer_2': 180, 'n_units_Layer_3': 195}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 5.67% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 15.59% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:11:11,645]\u001b[0m Trial 150 finished with value: 1.5745502069764516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034334402708048463, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1576418147484564, 'dropout_rate_Layer_2': 0.20639052367537314, 'dropout_rate_Layer_3': 0.3088786790875253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.4475395086517455e-05, 'l1_Layer_2': 0.020746349639828573, 'l1_Layer_3': 0.021764503925956934, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 205}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.39% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.48 | sMAPE for Test Set is: 17.80% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:11:23,395]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:31,201]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:39,526]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:44,505]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:52,698]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:11:57,467]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:05,553]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:23,411]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:30,742]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:37,304]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:45,026]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:49,943]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:12:57,443]\u001b[0m Trial 151 finished with value: 1.618729529407437 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012473686688924928, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23380239527559843, 'dropout_rate_Layer_2': 0.0011681485845081649, 'dropout_rate_Layer_3': 0.07411562300075905, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0017002350031524694, 'l1_Layer_2': 0.00504041243790779, 'l1_Layer_3': 0.04308648230559308, 'n_units_Layer_1': 80, 'n_units_Layer_2': 240, 'n_units_Layer_3': 205}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 5.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 15.65% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:13:04,392]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:06,718]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:17,166]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:19,050]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:39,045]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:43,460]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:13:48,770]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:14:00,658]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:14:08,545]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:14:08,774]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:14:18,790]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:14:51,798]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:14:59,098]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:09,126]\u001b[0m Trial 175 finished with value: 1.556717752140549 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016261855202610947, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1769741589450806, 'dropout_rate_Layer_2': 0.17087983201129742, 'dropout_rate_Layer_3': 0.24549369579461572, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014299400251990916, 'l1_Layer_2': 0.0030468351597532557, 'l1_Layer_3': 0.028203614246792113, 'n_units_Layer_1': 115, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:15:24,086]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:26,364]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:33,371]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:36,112]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:42,864]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:15:47,993]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:00,399]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:18,009]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:25,246]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:31,942]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:37,839]\u001b[0m Trial 184 finished with value: 1.4684305863495866 and parameters: {'n_hidden': 3, 'learning_rate': 0.004196205477635853, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18471042296257437, 'dropout_rate_Layer_2': 0.16780497732778293, 'dropout_rate_Layer_3': 0.2059551946524167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00034703535901281843, 'l1_Layer_2': 0.013590202872957823, 'l1_Layer_3': 0.0012874495873642497, 'n_units_Layer_1': 85, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:37,877]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.95 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:16:48,402]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:48,483]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:16:57,102]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:17:07,042]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:17:12,120]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:08,289]\u001b[0m Trial 196 finished with value: 1.5676583566434779 and parameters: {'n_hidden': 4, 'learning_rate': 0.006411120375322129, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0625516569237446, 'dropout_rate_Layer_2': 0.3817136698275303, 'dropout_rate_Layer_3': 0.26144574477126803, 'dropout_rate_Layer_4': 0.0867460177735263, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0043907280074838816, 'l1_Layer_2': 0.005340836752069522, 'l1_Layer_3': 0.0001026258460431167, 'l1_Layer_4': 0.00019668233814433626, 'n_units_Layer_1': 205, 'n_units_Layer_2': 195, 'n_units_Layer_3': 150, 'n_units_Layer_4': 190}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.61 | sMAPE for Test Set is: 23.40% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:18:13,131]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:20,235]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:23,004]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:27,495]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:30,419]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:18:35,511]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:19:17,087]\u001b[0m Trial 203 finished with value: 1.5332235855585592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024573606950641573, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13625711116425895, 'dropout_rate_Layer_2': 0.15214906433097344, 'dropout_rate_Layer_3': 0.2277764907305239, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0012270879755654986, 'l1_Layer_2': 0.032733078033513587, 'l1_Layer_3': 0.0005550986643683681, 'n_units_Layer_1': 80, 'n_units_Layer_2': 185, 'n_units_Layer_3': 300}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.09 | sMAPE for Test Set is: 19.30% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:19:20,341]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:19:26,821]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:19:34,344]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:19:39,661]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:19:39,967]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:19:47,079]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:19:51,563]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:19:59,179]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:19:59,486]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:20:07,013]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:20:59,465]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:04,159]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:11,915]\u001b[0m Trial 214 finished with value: 1.5423367016719485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020462352073125478, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08120855093147897, 'dropout_rate_Layer_2': 0.036956926520463625, 'dropout_rate_Layer_3': 0.1607975738215658, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02858028236218603, 'l1_Layer_2': 0.0021375093633304513, 'l1_Layer_3': 2.01081736491652e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 150, 'n_units_Layer_3': 205}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 14.02% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:21:16,612]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:41,543]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:48,868]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:21:55,390]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:13,490]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:18,588]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:19,053]\u001b[0m Trial 221 finished with value: 1.5670179716657213 and parameters: {'n_hidden': 3, 'learning_rate': 0.004607914952149121, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13584484650456624, 'dropout_rate_Layer_2': 0.14673457377582405, 'dropout_rate_Layer_3': 0.23118893153622855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0033427426111416873, 'l1_Layer_2': 0.022055444890565334, 'l1_Layer_3': 0.00019498425830892765, 'n_units_Layer_1': 80, 'n_units_Layer_2': 195, 'n_units_Layer_3': 270}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.36% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.99 | sMAPE for Test Set is: 19.04% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:22:28,205]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:37,492]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:42,437]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:22:47,531]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:02,973]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:07,632]\u001b[0m Trial 224 finished with value: 1.6471490826242683 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009812384208619936, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09493290672001019, 'dropout_rate_Layer_2': 0.2048618678613104, 'dropout_rate_Layer_3': 0.1697108859955424, 'dropout_rate_Layer_4': 0.0832098877647066, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.028297153443220147, 'l1_Layer_2': 0.003097603836140709, 'l1_Layer_3': 1.256288364905837e-05, 'l1_Layer_4': 2.0180828733447647e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 170, 'n_units_Layer_3': 215, 'n_units_Layer_4': 185}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 5.62% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 16.36% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:23:29,697]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:36,773]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:46,441]\u001b[0m Trial 230 finished with value: 1.9710280399304747 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035818424422324677, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38762691434382324, 'dropout_rate_Layer_2': 0.004175685145935526, 'dropout_rate_Layer_3': 0.1359018363862824, 'dropout_rate_Layer_4': 0.17633164693598524, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0021016827543058054, 'l1_Layer_2': 4.384889251558122e-05, 'l1_Layer_3': 7.715455141747384e-05, 'l1_Layer_4': 0.002722530053766905, 'n_units_Layer_1': 165, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255, 'n_units_Layer_4': 195}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 6.83% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 14.12% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:23:51,620]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:23:57,148]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:04,120]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:18,228]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:37,955]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:41,248]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:24:42,127]\u001b[0m Trial 232 finished with value: 1.6314802730549645 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008579838665846987, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20360767655392176, 'dropout_rate_Layer_2': 0.24374805145625703, 'dropout_rate_Layer_3': 0.15054502131203543, 'dropout_rate_Layer_4': 0.06549366169318524, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02173018585311094, 'l1_Layer_2': 0.0036754493005787753, 'l1_Layer_3': 2.2150054930453777e-05, 'l1_Layer_4': 0.0001161592255097566, 'n_units_Layer_1': 55, 'n_units_Layer_2': 195, 'n_units_Layer_3': 220, 'n_units_Layer_4': 175}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 5.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:24:48,729]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:15,641]\u001b[0m Trial 240 finished with value: 2.951616365097088 and parameters: {'n_hidden': 3, 'learning_rate': 0.0418361348233064, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04767090371176155, 'dropout_rate_Layer_2': 0.19636289469932466, 'dropout_rate_Layer_3': 0.31153594062483825, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.027156021692315586, 'l1_Layer_2': 0.002055954780191799, 'l1_Layer_3': 0.00134071524258538, 'n_units_Layer_1': 110, 'n_units_Layer_2': 250, 'n_units_Layer_3': 110}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.95 | sMAPE for Validation Set is: 10.41% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 14.73 | sMAPE for Test Set is: 38.61% | rMAE for Test Set is: 2.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:25:37,846]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:44,587]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:49,265]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:54,851]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:25:58,028]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:07,364]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:12,302]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:18,175]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:25,280]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:25,398]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:35,121]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:37,944]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:43,109]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:48,254]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:55,174]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:26:55,290]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:05,082]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:10,125]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:15,431]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:22,380]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:28,025]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:30,247]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:35,267]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:37,538]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:47,812]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:27:56,947]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:10,103]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:23,381]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:31,081]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:33,557]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:38,248]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:38,743]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:47,069]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:49,099]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:28:56,280]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:29:11,313]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:29:21,587]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:29:29,103]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:29:33,809]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:29:43,596]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:29:50,583]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:30:02,551]\u001b[0m Trial 275 finished with value: 1.6156002529240183 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008305799519981707, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1106504314120872, 'dropout_rate_Layer_2': 0.0369667666032912, 'dropout_rate_Layer_3': 0.17793017670532765, 'dropout_rate_Layer_4': 0.01692377331472107, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02279799046116137, 'l1_Layer_2': 0.004763761556677134, 'l1_Layer_3': 9.178925444603061e-05, 'l1_Layer_4': 1.4724088538459364e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 225, 'n_units_Layer_4': 120}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 5.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.54 | sMAPE for Test Set is: 17.89% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:30:10,083]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:30:20,517]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:30:25,081]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:30:35,134]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:30:42,361]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:30:47,580]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:30:59,804]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:31:37,055]\u001b[0m Trial 283 finished with value: 1.659962063475028 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009066496387480304, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09390823220302257, 'dropout_rate_Layer_2': 0.11211502273937891, 'dropout_rate_Layer_3': 0.24346127278977586, 'dropout_rate_Layer_4': 0.07456683424640517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02037392589298539, 'l1_Layer_2': 0.0012381789796209479, 'l1_Layer_3': 2.5052309970226665e-05, 'l1_Layer_4': 0.00020581219770161087, 'n_units_Layer_1': 60, 'n_units_Layer_2': 155, 'n_units_Layer_3': 240, 'n_units_Layer_4': 230}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.66 | sMAPE for Validation Set is: 5.70% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 14.72% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:31:41,487]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:31:49,430]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:31:59,502]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:32:06,036]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:32:13,435]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:32:19,242]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:32:28,963]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:32:38,881]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:32:51,189]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:00,445]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:06,201]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:14,461]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:19,137]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:26,261]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:33:36,551]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:34:03,431]\u001b[0m Trial 295 finished with value: 1.5049050953357135 and parameters: {'n_hidden': 3, 'learning_rate': 0.001448462252003028, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13271509195675185, 'dropout_rate_Layer_2': 0.09037698620442672, 'dropout_rate_Layer_3': 0.2504669808893525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0007844157455500211, 'l1_Layer_2': 0.0009117490365373408, 'l1_Layer_3': 1.176154297751064e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 185, 'n_units_Layer_3': 240}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 15.31% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:35:10,711]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:35:15,568]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:35:20,643]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:35:45,591]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:35:47,454]\u001b[0m Trial 308 finished with value: 1.4742336415267745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016324567520188723, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1794214745632149, 'dropout_rate_Layer_2': 0.06423150970323248, 'dropout_rate_Layer_3': 0.25385146323961394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006611298857989673, 'l1_Layer_2': 0.0009830035868658787, 'l1_Layer_3': 1.0306273780315248e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.12 | sMAPE for Test Set is: 16.85% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:35:59,749]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:36:00,331]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:36:08,171]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:36:12,277]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:36:19,906]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:36:27,459]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:36:35,619]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:36:40,002]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:37:12,159]\u001b[0m Trial 318 finished with value: 1.749869135283003 and parameters: {'n_hidden': 4, 'learning_rate': 0.004802992333029255, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38310491450203, 'dropout_rate_Layer_2': 0.006599263601142352, 'dropout_rate_Layer_3': 0.05805162306409237, 'dropout_rate_Layer_4': 0.10044282628557234, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000396832368324493, 'l1_Layer_2': 5.8108054234496465e-05, 'l1_Layer_3': 3.415157695691008e-05, 'l1_Layer_4': 0.0019682778804924685, 'n_units_Layer_1': 195, 'n_units_Layer_2': 135, 'n_units_Layer_3': 250, 'n_units_Layer_4': 215}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.75 | sMAPE for Validation Set is: 5.91% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 3.74 | sMAPE for Test Set is: 9.21% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:37:59,872]\u001b[0m Trial 321 finished with value: 1.5234752216463427 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017498621463137565, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25100160588405634, 'dropout_rate_Layer_2': 0.07411496588876793, 'dropout_rate_Layer_3': 0.1576192038600914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004942890809387828, 'l1_Layer_2': 0.0014222529359526523, 'l1_Layer_3': 1.0054013941970109e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 195, 'n_units_Layer_3': 250}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.60 | sMAPE for Test Set is: 18.05% | rMAE for Test Set is: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:38:04,700]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:38:16,665]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:38:58,819]\u001b[0m Trial 325 finished with value: 1.5946429677870908 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018491506548029345, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10904606301280348, 'dropout_rate_Layer_2': 0.06642782764036705, 'dropout_rate_Layer_3': 0.0031454714905346237, 'dropout_rate_Layer_4': 0.0847848201035716, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00031046261979514106, 'l1_Layer_2': 1.3112225757581353e-05, 'l1_Layer_3': 3.157451981067685e-05, 'l1_Layer_4': 5.2679852129660394e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 135, 'n_units_Layer_3': 230, 'n_units_Layer_4': 225}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 5.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.84 | sMAPE for Test Set is: 11.78% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:39:05,914]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:39:18,425]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:39:21,017]\u001b[0m Trial 322 finished with value: 1.5191591883327262 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016936199772201953, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.250560741217861, 'dropout_rate_Layer_2': 0.08738436917733605, 'dropout_rate_Layer_3': 0.08206808459089923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00048472155223122816, 'l1_Layer_2': 0.002075391184163261, 'l1_Layer_3': 1.8293605270191602e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 105, 'n_units_Layer_3': 250}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 15.36% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:39:48,092]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:39:52,275]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:39:55,160]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:39:59,528]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:40:42,404]\u001b[0m Trial 333 finished with value: 1.5944457953868632 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009703389941156768, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10300621483374423, 'dropout_rate_Layer_2': 0.06575628284125655, 'dropout_rate_Layer_3': 0.014768321709191274, 'dropout_rate_Layer_4': 0.013946351787102629, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0023897868212604e-05, 'l1_Layer_2': 1.3398436522676671e-05, 'l1_Layer_3': 1.1287201940561507e-05, 'l1_Layer_4': 5.521486125054763e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230, 'n_units_Layer_4': 245}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 5.40% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 21.45% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:41:42,547]\u001b[0m Trial 332 finished with value: 1.4964323699318942 and parameters: {'n_hidden': 3, 'learning_rate': 0.001711248860499107, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25018423562092756, 'dropout_rate_Layer_2': 0.07884869194115601, 'dropout_rate_Layer_3': 0.0812964801923671, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003652370219443883, 'l1_Layer_2': 0.0014251321282584266, 'l1_Layer_3': 1.0281382775302713e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 105, 'n_units_Layer_3': 260}. Best is trial 34 with value: 1.4676476120815594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.33 | sMAPE for Test Set is: 17.43% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:41:59,881]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:16,579]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:22,035]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:29,238]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:34,277]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:43,401]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:53,331]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:42:58,046]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:43:02,828]\u001b[0m Trial 334 finished with value: 1.448086753810584 and parameters: {'n_hidden': 3, 'learning_rate': 0.001730410144081521, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2513461632315169, 'dropout_rate_Layer_2': 0.08237255675125629, 'dropout_rate_Layer_3': 0.1600499964620328, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004425520486439054, 'l1_Layer_2': 0.0013544946944515947, 'l1_Layer_3': 1.0220242759106988e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 105, 'n_units_Layer_3': 260}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 7.99 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:43:18,132]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:43:24,689]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:43:32,364]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:43:53,006]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:02,069]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:09,655]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:24,478]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:29,373]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:34,368]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:44:56,554]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:45:05,768]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:45:20,696]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:45:35,283]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:46:51,973]\u001b[0m Trial 357 finished with value: 1.4875724646321444 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018294389640129464, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22689093463525534, 'dropout_rate_Layer_2': 0.07660722974560596, 'dropout_rate_Layer_3': 0.10368093138534899, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005979266708135146, 'l1_Layer_2': 0.0010964336023883867, 'l1_Layer_3': 0.0012192644485990892, 'n_units_Layer_1': 95, 'n_units_Layer_2': 115, 'n_units_Layer_3': 260}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 15.97% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:47:04,165]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:47:26,175]\u001b[0m Trial 359 finished with value: 1.7107524455637015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021542071052937694, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12479727665162003, 'dropout_rate_Layer_2': 0.37304676001724263, 'dropout_rate_Layer_3': 0.2266096972418861, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00041702963332428643, 'l1_Layer_2': 0.0007390589054866435, 'l1_Layer_3': 0.005305860711609485, 'n_units_Layer_1': 295, 'n_units_Layer_2': 50, 'n_units_Layer_3': 290}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.71 | sMAPE for Validation Set is: 5.85% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.13 | sMAPE for Test Set is: 16.93% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:47:33,387]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:48:05,506]\u001b[0m Trial 358 finished with value: 1.495841148321411 and parameters: {'n_hidden': 3, 'learning_rate': 0.001862629128407321, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2223592756243357, 'dropout_rate_Layer_2': 0.06691719272029169, 'dropout_rate_Layer_3': 0.09146812859586041, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002887632573623538, 'l1_Layer_2': 0.0008008613803809259, 'l1_Layer_3': 0.0010092301034122057, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 260}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 15.43% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:49:24,196]\u001b[0m Trial 361 finished with value: 1.5214878455753433 and parameters: {'n_hidden': 3, 'learning_rate': 0.002619346161333959, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2189503653087207, 'dropout_rate_Layer_2': 0.07750046313020115, 'dropout_rate_Layer_3': 0.09463971729650547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005680923996565594, 'l1_Layer_2': 0.001071750190019869, 'l1_Layer_3': 0.0023071562498352483, 'n_units_Layer_1': 105, 'n_units_Layer_2': 110, 'n_units_Layer_3': 255}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.91 | sMAPE for Test Set is: 16.35% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:49:31,237]\u001b[0m Trial 362 finished with value: 1.5144788921256749 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015496851766509047, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22339495196831224, 'dropout_rate_Layer_2': 0.0766210454559738, 'dropout_rate_Layer_3': 0.09121190674686551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00027356967493837443, 'l1_Layer_2': 0.001119384072715194, 'l1_Layer_3': 0.0022416630471791222, 'n_units_Layer_1': 105, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.74 | sMAPE for Test Set is: 15.95% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:49:36,204]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:50:18,514]\u001b[0m Trial 363 finished with value: 1.5230703272189061 and parameters: {'n_hidden': 3, 'learning_rate': 0.001933963580726191, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23651728868260924, 'dropout_rate_Layer_2': 0.07757115466217769, 'dropout_rate_Layer_3': 0.09289339357190077, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00025910442229891943, 'l1_Layer_2': 0.0008573679730074057, 'l1_Layer_3': 0.0012093200997882803, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 260}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.36 | sMAPE for Test Set is: 17.49% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:51:03,408]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:51:15,058]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:51:29,895]\u001b[0m Trial 365 finished with value: 1.5206576526719984 and parameters: {'n_hidden': 3, 'learning_rate': 0.002680006158937563, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22483466266199956, 'dropout_rate_Layer_2': 0.07698431336643402, 'dropout_rate_Layer_3': 0.10911500250217854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002581976389111525, 'l1_Layer_2': 0.0008545690825693103, 'l1_Layer_3': 0.0014832443062875373, 'n_units_Layer_1': 105, 'n_units_Layer_2': 120, 'n_units_Layer_3': 260}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.16% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 16.67% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:51:37,589]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:07,254]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:52:29,124]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:53:00,698]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:53:23,257]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:53:33,305]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:53:41,194]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:53:41,548]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:53:52,754]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:00,773]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:24,720]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:32,749]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:44,800]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:54:47,639]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:55:09,859]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:55:46,579]\u001b[0m Trial 384 finished with value: 1.5566115290270612 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020643407120694473, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11385385232098251, 'dropout_rate_Layer_2': 0.06802184156883258, 'dropout_rate_Layer_3': 0.0007600488751431924, 'dropout_rate_Layer_4': 0.07983579813967956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00023677874857913606, 'l1_Layer_2': 1.471764504483415e-05, 'l1_Layer_3': 3.134633429005097e-05, 'l1_Layer_4': 5.298900069371602e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 120, 'n_units_Layer_3': 230, 'n_units_Layer_4': 235}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.15 | sMAPE for Test Set is: 10.12% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:55:51,746]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:56:23,390]\u001b[0m Trial 382 finished with value: 1.5369004748964221 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015236864641553249, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24274011385548294, 'dropout_rate_Layer_2': 0.07007151381924771, 'dropout_rate_Layer_3': 0.11280583811110285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006358869648234641, 'l1_Layer_2': 0.001053870113963763, 'l1_Layer_3': 0.0010128127730138297, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 16.35% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:56:33,414]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:56:43,495]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:56:53,191]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:57:17,974]\u001b[0m Trial 386 finished with value: 1.5345916687576464 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015729180189990237, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2402526462856927, 'dropout_rate_Layer_2': 0.07164888772171565, 'dropout_rate_Layer_3': 0.10793386705556812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000609862099896202, 'l1_Layer_2': 0.0010239823185250532, 'l1_Layer_3': 0.0009174395856521305, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 260}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 16.55% | rMAE for Test Set is: 1.33\n",
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.17 | sMAPE for Test Set is: 14.58% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:58:51,828]\u001b[0m Trial 390 finished with value: 1.556379987931562 and parameters: {'n_hidden': 3, 'learning_rate': 0.001668925823123633, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23908908498703726, 'dropout_rate_Layer_2': 0.07027421149486596, 'dropout_rate_Layer_3': 0.09805053572564995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0008304175492371893, 'l1_Layer_2': 0.0016520401259433179, 'l1_Layer_3': 0.0009930775153562568, 'n_units_Layer_1': 90, 'n_units_Layer_2': 115, 'n_units_Layer_3': 255}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:58:57,066]\u001b[0m Trial 391 finished with value: 1.5148281466450326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017482657152705873, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24071500063811896, 'dropout_rate_Layer_2': 0.0687340008633802, 'dropout_rate_Layer_3': 0.09979198097726183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006576578019015113, 'l1_Layer_2': 0.001001809116501632, 'l1_Layer_3': 0.0014201908075998336, 'n_units_Layer_1': 125, 'n_units_Layer_2': 115, 'n_units_Layer_3': 255}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.36 | sMAPE for Test Set is: 15.00% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 11:59:07,034]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 11:59:59,643]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:11,818]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:11,983]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:24,921]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:32,344]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:44,793]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:00:52,688]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:01:04,719]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:01:20,149]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:02:48,286]\u001b[0m Trial 402 finished with value: 1.5098553232995713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015270109011339388, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24225931298957892, 'dropout_rate_Layer_2': 0.0662717774606139, 'dropout_rate_Layer_3': 0.06778874385772311, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004736084531980715, 'l1_Layer_2': 0.0012211089547583835, 'l1_Layer_3': 0.0008803924780614452, 'n_units_Layer_1': 125, 'n_units_Layer_2': 130, 'n_units_Layer_3': 245}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 15.44% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:04:24,668]\u001b[0m Trial 404 finished with value: 1.5192081197546845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015885887471388275, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24269030310291434, 'dropout_rate_Layer_2': 0.06852768816574181, 'dropout_rate_Layer_3': 0.06908912629604944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0008816998821869322, 'l1_Layer_2': 0.001220975962564412, 'l1_Layer_3': 0.0006374556204635428, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 270}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 16.09% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:04:44,151]\u001b[0m Trial 403 finished with value: 1.4501462942173138 and parameters: {'n_hidden': 3, 'learning_rate': 0.001555221372805102, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2172706541713239, 'dropout_rate_Layer_2': 0.06395820032624533, 'dropout_rate_Layer_3': 0.07089103098564772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00032706364037340165, 'l1_Layer_2': 0.0012077431624671511, 'l1_Layer_3': 0.0013603142639241925, 'n_units_Layer_1': 115, 'n_units_Layer_2': 110, 'n_units_Layer_3': 270}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 14.10% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:06:11,936]\u001b[0m Trial 406 finished with value: 1.4818125847065247 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016308083617255437, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.215598726325892, 'dropout_rate_Layer_2': 0.06456778039365592, 'dropout_rate_Layer_3': 0.06591258961967472, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003007033100833698, 'l1_Layer_2': 0.0011941992562435554, 'l1_Layer_3': 0.0006391238193414966, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:06:16,825]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:06:38,608]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:08,915]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:27,967]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:38,274]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:07:48,456]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:09:12,009]\u001b[0m Trial 409 finished with value: 1.4718699176529044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015631377958580926, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21734225320731465, 'dropout_rate_Layer_2': 0.06508325551368384, 'dropout_rate_Layer_3': 0.06807843067490575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003225704250343437, 'l1_Layer_2': 0.0012036037618954423, 'l1_Layer_3': 0.0008726408198557877, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 14.41% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:09:44,094]\u001b[0m Trial 413 finished with value: 1.5470650859030044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019609934934767055, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21282053661642913, 'dropout_rate_Layer_2': 0.07100046158967498, 'dropout_rate_Layer_3': 0.11108003984988812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0007051527405209082, 'l1_Layer_2': 0.0012223066201775456, 'l1_Layer_3': 0.001125842171845598, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 270}. Best is trial 334 with value: 1.448086753810584.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 14.95% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:09:49,499]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:09:58,975]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:10:51,546]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:10,489]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:11:15,971]\u001b[0m Trial 414 finished with value: 1.4414668374088222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014572250836038926, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21406459103226533, 'dropout_rate_Layer_2': 0.07040000822730504, 'dropout_rate_Layer_3': 0.10790918189366587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003452427725064403, 'l1_Layer_2': 0.0011099797983454393, 'l1_Layer_3': 0.000925205360195128, 'n_units_Layer_1': 110, 'n_units_Layer_2': 105, 'n_units_Layer_3': 285}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 14.27% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:12:27,350]\u001b[0m Trial 419 finished with value: 1.7313591604836602 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014717765988056396, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15319371367861997, 'dropout_rate_Layer_2': 0.3560323373124964, 'dropout_rate_Layer_3': 0.3120883837287081, 'dropout_rate_Layer_4': 0.25976813421729644, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0025064761482418416, 'l1_Layer_2': 4.360427819022376e-05, 'l1_Layer_3': 2.0924576366520345e-05, 'l1_Layer_4': 0.0007916390141155942, 'n_units_Layer_1': 60, 'n_units_Layer_2': 120, 'n_units_Layer_3': 280, 'n_units_Layer_4': 265}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.73 | sMAPE for Validation Set is: 5.92% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.40 | sMAPE for Test Set is: 25.47% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:13:11,997]\u001b[0m Trial 420 finished with value: 1.4531625861695356 and parameters: {'n_hidden': 3, 'learning_rate': 0.001477776876632615, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22246789542512335, 'dropout_rate_Layer_2': 0.07674299496147646, 'dropout_rate_Layer_3': 0.11690039369789129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003113068827109157, 'l1_Layer_2': 0.000718743734347687, 'l1_Layer_3': 0.0012242277788317704, 'n_units_Layer_1': 105, 'n_units_Layer_2': 110, 'n_units_Layer_3': 280}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 4.94% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 15.60% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:13:36,600]\u001b[0m Trial 421 finished with value: 1.6761404948971566 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009920950185464768, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011244595655032552, 'dropout_rate_Layer_2': 0.35535311804683617, 'dropout_rate_Layer_3': 0.2929551650521567, 'dropout_rate_Layer_4': 0.2624430422489413, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0024459985608086135, 'l1_Layer_2': 1.001138886011369e-05, 'l1_Layer_3': 1.0741439207155895e-05, 'l1_Layer_4': 0.0007770674867631557, 'n_units_Layer_1': 50, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290, 'n_units_Layer_4': 75}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 5.75% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.61 | sMAPE for Test Set is: 26.04% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:15:03,709]\u001b[0m Trial 422 finished with value: 1.4922331945145817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014555732479134126, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.221424824795107, 'dropout_rate_Layer_2': 0.08717122038660757, 'dropout_rate_Layer_3': 0.12114415977702346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00030767120005387226, 'l1_Layer_2': 0.0007359119959647836, 'l1_Layer_3': 0.0014112328824248653, 'n_units_Layer_1': 120, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 14.52% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:15:36,587]\u001b[0m Trial 423 finished with value: 1.4877085124980134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014657621111550613, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22544680910876758, 'dropout_rate_Layer_2': 0.08529560764053204, 'dropout_rate_Layer_3': 0.12197437872436678, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00031031569052020495, 'l1_Layer_2': 0.0007897530113733686, 'l1_Layer_3': 0.001389087343712105, 'n_units_Layer_1': 120, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 14.68% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:15:40,332]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:46,958]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:15:50,169]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:16:02,460]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:17:11,336]\u001b[0m Trial 428 finished with value: 1.4916084847547932 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013724360626225262, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20503412496216267, 'dropout_rate_Layer_2': 0.09881755595900682, 'dropout_rate_Layer_3': 0.07211962405005724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00021245619306068403, 'l1_Layer_2': 0.0007261321627921461, 'l1_Layer_3': 0.002731118972322939, 'n_units_Layer_1': 130, 'n_units_Layer_2': 110, 'n_units_Layer_3': 280}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 16.24% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:17:40,193]\u001b[0m Trial 429 finished with value: 1.5076515332813367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014007919370995995, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20572828969457563, 'dropout_rate_Layer_2': 0.10148877221421716, 'dropout_rate_Layer_3': 0.12410706922917486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00021801440682779323, 'l1_Layer_2': 0.0008622537831492853, 'l1_Layer_3': 0.0028277385040679677, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 295}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 15.47% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:18:00,558]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:18:10,359]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:20:01,710]\u001b[0m Trial 430 finished with value: 1.446480597162158 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013500993576578565, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20473900180666443, 'dropout_rate_Layer_2': 0.0883521034023388, 'dropout_rate_Layer_3': 0.06737975686288043, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00020427181407516756, 'l1_Layer_2': 0.0007531886641082197, 'l1_Layer_3': 0.002828706002398309, 'n_units_Layer_1': 130, 'n_units_Layer_2': 110, 'n_units_Layer_3': 280}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 14.19% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:20:02,366]\u001b[0m Trial 433 finished with value: 1.6546357237782108 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006667157874688645, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006855619422552877, 'dropout_rate_Layer_2': 0.18443714581895607, 'dropout_rate_Layer_3': 0.3340612598622067, 'dropout_rate_Layer_4': 0.31026715873432414, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0024219406843161814, 'l1_Layer_2': 8.597335348635596e-05, 'l1_Layer_3': 1.728720135307659e-05, 'l1_Layer_4': 0.0006104338587344158, 'n_units_Layer_1': 55, 'n_units_Layer_2': 135, 'n_units_Layer_3': 295, 'n_units_Layer_4': 265}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 5.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 20.94% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:20:14,864]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:21:10,834]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:21:18,531]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:21:38,684]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:21:50,473]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:22:47,219]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:23:34,773]\u001b[0m Trial 437 finished with value: 1.5170887953031886 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007653768134735203, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12641207001293905, 'dropout_rate_Layer_2': 0.03339429756034365, 'dropout_rate_Layer_3': 0.2408111277489366, 'dropout_rate_Layer_4': 0.12758590192088148, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008034470782154329, 'l1_Layer_2': 0.00036157525501138554, 'l1_Layer_3': 4.304739675823494e-05, 'l1_Layer_4': 7.530648793753609e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270, 'n_units_Layer_4': 210}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.52 | sMAPE for Test Set is: 8.63% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:23:56,498]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:24:06,614]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:24:31,497]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:24:47,136]\u001b[0m Trial 441 finished with value: 1.5700741148616568 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006286001152503355, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0013911351077184018, 'dropout_rate_Layer_2': 0.18409161603657814, 'dropout_rate_Layer_3': 0.29874526148956104, 'dropout_rate_Layer_4': 0.3105766959133225, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003255210415453519, 'l1_Layer_2': 0.0001278309322746698, 'l1_Layer_3': 1.2186378080690255e-05, 'l1_Layer_4': 0.00020365080835923186, 'n_units_Layer_1': 50, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.34% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.55 | sMAPE for Test Set is: 17.96% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:24:52,129]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:23,178]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:44,752]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:45,105]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:25:51,852]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:38,837]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:43,801]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:48,595]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:26:58,264]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:27:10,947]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:27:20,073]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:00,065]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:09,953]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:28:19,825]\u001b[0m Trial 453 finished with value: 1.5163612184222626 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015807229995304646, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18882309132189035, 'dropout_rate_Layer_2': 0.07831803740958972, 'dropout_rate_Layer_3': 0.07585639043970048, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00015870251654541128, 'l1_Layer_2': 0.0005954591727310438, 'l1_Layer_3': 0.003878974984488917, 'n_units_Layer_1': 120, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 15.32% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:29:08,546]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:29:25,077]\u001b[0m Trial 459 finished with value: 1.6814840234902093 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009277592815028226, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03699207430912176, 'dropout_rate_Layer_2': 0.1880522511686365, 'dropout_rate_Layer_3': 0.35664234964293534, 'dropout_rate_Layer_4': 0.25887523457908634, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0021483042072133066, 'l1_Layer_2': 8.311544978841371e-05, 'l1_Layer_3': 1.6885839363694308e-05, 'l1_Layer_4': 6.796687977676285e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 180, 'n_units_Layer_3': 295, 'n_units_Layer_4': 75}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 5.77% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 23.19% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:29:32,772]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:29:45,485]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:29:59,807]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:30:49,565]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:30:56,509]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:31:04,038]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:31:07,230]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:31:26,057]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:31:33,806]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:31:55,739]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:03,581]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:06,542]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:27,886]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:38,022]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:45,027]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:32:55,156]\u001b[0m Trial 473 finished with value: 1.555246850418645 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008587295214092163, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10396015008143926, 'dropout_rate_Layer_2': 0.06076793043273583, 'dropout_rate_Layer_3': 0.2926300116980707, 'dropout_rate_Layer_4': 0.07394526952745013, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0065689745321209775, 'l1_Layer_2': 0.00012975187791674172, 'l1_Layer_3': 5.0511760865279586e-05, 'l1_Layer_4': 6.84563077975526e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 120, 'n_units_Layer_3': 235, 'n_units_Layer_4': 245}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 10.23% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:33:07,735]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:33:17,645]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:33:29,973]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:33:34,709]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:33:37,723]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:33:54,982]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:34:31,206]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:34:41,551]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:34:48,525]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:34:48,841]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:35:01,204]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:35:22,852]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:35:28,138]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:35:46,010]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:35:53,202]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:22,430]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:29,549]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:36,925]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:47,233]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:52,248]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:36:52,510]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:04,865]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:14,737]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:24,625]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:27,316]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:33,985]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:34,279]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:46,435]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:37:56,654]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:16,164]\u001b[0m Trial 504 finished with value: 1.5339601638552416 and parameters: {'n_hidden': 4, 'learning_rate': 0.004978854441008522, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024750622758615476, 'dropout_rate_Layer_2': 0.10066068327956572, 'dropout_rate_Layer_3': 0.20924056411968384, 'dropout_rate_Layer_4': 0.14324656829995158, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.022406096087813316, 'l1_Layer_2': 0.001078904364457998, 'l1_Layer_3': 0.0749937528860697, 'l1_Layer_4': 1.469504545471922e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155, 'n_units_Layer_4': 255}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.20 | sMAPE for Test Set is: 7.96% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:38:16,605]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:25,784]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:26,274]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:38,583]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:38,711]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:44,420]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:45,961]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:38:51,532]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:39:11,555]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:39:16,365]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:39:23,594]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:39:31,052]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:39:43,266]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:39:49,737]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:40:02,299]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:40:46,712]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:40:52,066]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:01,144]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:10,942]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:20,831]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:41:57,221]\u001b[0m Trial 523 finished with value: 1.470727898528456 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017698926138306208, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2306027014332513, 'dropout_rate_Layer_2': 0.08155669058986995, 'dropout_rate_Layer_3': 0.07501975090955294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00019501333619046307, 'l1_Layer_2': 0.0007989556883428727, 'l1_Layer_3': 0.0009660507430870254, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 16.45% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:42:02,233]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:15,071]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:17,548]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:22,056]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:24,877]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:29,831]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:30,431]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:44,560]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:42:54,540]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:44:05,140]\u001b[0m Trial 538 finished with value: 1.6919765772011468 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013002755463388171, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 5.0793837470676506e-05, 'dropout_rate_Layer_2': 0.23963709669913996, 'dropout_rate_Layer_3': 0.26686159262267595, 'dropout_rate_Layer_4': 0.2597260806820409, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0023768526417291083, 'l1_Layer_2': 0.0028819792970479264, 'l1_Layer_3': 0.032191390648828734, 'l1_Layer_4': 1.821600875518112e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 145, 'n_units_Layer_3': 180, 'n_units_Layer_4': 295}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.69 | sMAPE for Validation Set is: 5.81% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 20.84% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:44:34,478]\u001b[0m Trial 536 finished with value: 1.6014991446979883 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005241964066046322, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01094488318519604, 'dropout_rate_Layer_2': 0.13715461766920536, 'dropout_rate_Layer_3': 0.20416040722699674, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01862076152336794, 'l1_Layer_2': 0.0008561674613467541, 'l1_Layer_3': 0.022235962955738375, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 220}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 5.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.11 | sMAPE for Test Set is: 7.83% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:45:23,689]\u001b[0m Trial 539 finished with value: 1.6671255561093377 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017040435269134277, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004756401174321516, 'dropout_rate_Layer_2': 0.24387624225811022, 'dropout_rate_Layer_3': 0.2191517995418946, 'dropout_rate_Layer_4': 0.26184219770981854, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009087487570036128, 'l1_Layer_2': 0.0026766813194717236, 'l1_Layer_3': 0.027903196986611385, 'l1_Layer_4': 2.0253688929598683e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 150, 'n_units_Layer_3': 185, 'n_units_Layer_4': 295}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.67 | sMAPE for Validation Set is: 5.69% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.13 | sMAPE for Test Set is: 24.73% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:45:29,160]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:45:29,300]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:45:43,656]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:23,748]\u001b[0m Trial 544 finished with value: 1.6243840950782957 and parameters: {'n_hidden': 4, 'learning_rate': 0.005004003184518637, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01970494955718611, 'dropout_rate_Layer_2': 0.1726164376053935, 'dropout_rate_Layer_3': 0.13950810485715479, 'dropout_rate_Layer_4': 0.14043394887337746, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.049014409986281204, 'l1_Layer_2': 0.00014463664097546966, 'l1_Layer_3': 0.08365012941387226, 'l1_Layer_4': 1.966228955442653e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 100, 'n_units_Layer_3': 125, 'n_units_Layer_4': 255}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 5.58% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.66 | sMAPE for Test Set is: 18.30% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:46:25,581]\u001b[0m Trial 543 finished with value: 1.621626867954957 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013192441455712402, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006106881861336747, 'dropout_rate_Layer_2': 0.24988498138855297, 'dropout_rate_Layer_3': 0.2704700775241171, 'dropout_rate_Layer_4': 0.2629564195369424, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0086127722055707, 'l1_Layer_2': 0.003433455945653139, 'l1_Layer_3': 0.038468413018786694, 'l1_Layer_4': 1.772280751844377e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 150, 'n_units_Layer_3': 185, 'n_units_Layer_4': 295}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 5.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.67 | sMAPE for Test Set is: 23.45% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:46:32,455]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:35,424]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:45,092]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:46:49,807]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:47:02,397]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:47:12,800]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:47:20,318]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:47:27,518]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:47:49,307]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:17,974]\u001b[0m Trial 554 finished with value: 1.5301204692229653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013035951752999042, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19169932476425566, 'dropout_rate_Layer_2': 0.08365342303244498, 'dropout_rate_Layer_3': 0.07378207181059045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003491813106967528, 'l1_Layer_2': 0.0010465961955110794, 'l1_Layer_3': 0.006074051518711681, 'n_units_Layer_1': 125, 'n_units_Layer_2': 95, 'n_units_Layer_3': 280}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.22% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 15.73% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:49:27,152]\u001b[0m Trial 555 finished with value: 1.527798782158608 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014833925981329367, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26255099658110664, 'dropout_rate_Layer_2': 0.11109291043472441, 'dropout_rate_Layer_3': 0.0726910637752627, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003643221933708406, 'l1_Layer_2': 0.0010474924532585235, 'l1_Layer_3': 0.0016242900575098994, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.22% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 16.44% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:49:34,883]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:42,173]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:47,070]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:49:56,828]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:50:12,138]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:50:33,492]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:50:45,804]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:50:54,908]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:51:26,582]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:51:36,252]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:51:38,552]\u001b[0m Trial 556 finished with value: 1.52228145301009 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014644796737222734, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2617685975947495, 'dropout_rate_Layer_2': 0.10458499097118529, 'dropout_rate_Layer_3': 0.09807568335870218, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00043339681461209594, 'l1_Layer_2': 0.0007807118342263449, 'l1_Layer_3': 0.0012183840054067587, 'n_units_Layer_1': 120, 'n_units_Layer_2': 105, 'n_units_Layer_3': 240}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.40 | sMAPE for Test Set is: 15.12% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:51:46,568]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:51:49,108]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:52:00,812]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:52:08,490]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:52:20,516]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:52:25,358]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:52:57,692]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:22,093]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:22,568]\u001b[0m Trial 575 finished with value: 1.5605411576336763 and parameters: {'n_hidden': 3, 'learning_rate': 0.002142943965839936, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19250937367225107, 'dropout_rate_Layer_2': 0.34576685097910814, 'dropout_rate_Layer_3': 0.38128981042716503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0013930333022368268, 'l1_Layer_2': 0.009471195980168661, 'l1_Layer_3': 0.0016589695384647185, 'n_units_Layer_1': 120, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 5.34% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.37 | sMAPE for Test Set is: 25.37% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:53:29,413]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:32,401]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:37,021]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:39,718]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:44,570]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:51,742]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:53:57,607]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:07,042]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:14,322]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:19,030]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:27,336]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:54:39,289]\u001b[0m Trial 581 finished with value: 1.5270774545882666 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020805253997128116, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19247646241884475, 'dropout_rate_Layer_2': 0.34201974233790344, 'dropout_rate_Layer_3': 0.1530496157892886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004339208191195948, 'l1_Layer_2': 0.034827944998683406, 'l1_Layer_3': 0.002232879293208335, 'n_units_Layer_1': 65, 'n_units_Layer_2': 290, 'n_units_Layer_3': 280}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.53 | sMAPE for Test Set is: 23.06% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:54:54,389]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:55:36,268]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:55:43,563]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:55:51,168]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:00,910]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:05,847]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:06,345]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:13,623]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:18,709]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:25,465]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:52,164]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:56:59,831]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:09,659]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:14,862]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:16,719]\u001b[0m Trial 597 finished with value: 1.5328433643373032 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015600869201314862, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20303064361519513, 'dropout_rate_Layer_2': 0.08387144765173403, 'dropout_rate_Layer_3': 0.0876532439709258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00021388774437429116, 'l1_Layer_2': 0.000750536909876543, 'l1_Layer_3': 0.0013353593232296181, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.09 | sMAPE for Test Set is: 16.81% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 12:57:24,396]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:26,196]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:33,811]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:36,038]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:41,323]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:43,907]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:45,938]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:48,407]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:57:50,778]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:00,180]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:10,423]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:17,790]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:24,805]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:32,330]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:37,621]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:47,400]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:58:59,596]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:08,966]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:18,598]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:25,853]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 12:59:46,491]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:06,469]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:12,813]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:23,538]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:30,055]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:52,370]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:00:58,384]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:03,356]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:03,369]\u001b[0m Trial 612 finished with value: 1.4480479008214655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012161922237190303, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23037076453099226, 'dropout_rate_Layer_2': 0.07684831386667859, 'dropout_rate_Layer_3': 0.05590984757558098, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004176234727542583, 'l1_Layer_2': 0.0010504110808641622, 'l1_Layer_3': 0.0020271728478611895, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 4.91% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 13.53% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:01:11,030]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:20,918]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:21,429]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:28,083]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:28,596]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:01:52,768]\u001b[0m Trial 638 finished with value: 1.5486213755474407 and parameters: {'n_hidden': 3, 'learning_rate': 0.004109444271541891, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17834831038745091, 'dropout_rate_Layer_2': 0.3754808191315364, 'dropout_rate_Layer_3': 0.17345864609108366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.006957708887510286, 'l1_Layer_2': 0.005525724181046097, 'l1_Layer_3': 0.0003837806682559363, 'n_units_Layer_1': 80, 'n_units_Layer_2': 180, 'n_units_Layer_3': 270}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.33 | sMAPE for Test Set is: 19.91% | rMAE for Test Set is: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:02:22,396]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:02:29,612]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:02:30,403]\u001b[0m Trial 639 finished with value: 1.6062065036070414 and parameters: {'n_hidden': 4, 'learning_rate': 0.01566239733859176, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14891001906477982, 'dropout_rate_Layer_2': 0.05810718560040205, 'dropout_rate_Layer_3': 0.3099548839730518, 'dropout_rate_Layer_4': 0.04810274777579013, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007978210543816013, 'l1_Layer_2': 0.0011616216062583014, 'l1_Layer_3': 1.703761643921527e-05, 'l1_Layer_4': 3.708527945274782e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 175, 'n_units_Layer_4': 225}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.61 | sMAPE for Validation Set is: 5.46% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.56 | sMAPE for Test Set is: 8.80% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:02:37,419]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:02:37,991]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:02:45,201]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:04:18,528]\u001b[0m Trial 645 finished with value: 1.51548881194223 and parameters: {'n_hidden': 3, 'learning_rate': 0.001770864926266017, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24845697871800076, 'dropout_rate_Layer_2': 0.08636230278680036, 'dropout_rate_Layer_3': 0.06586291888160378, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003698256188261182, 'l1_Layer_2': 0.0010087351695069202, 'l1_Layer_3': 0.004639370239577968, 'n_units_Layer_1': 95, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:04:27,384]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:04:42,316]\u001b[0m Trial 643 finished with value: 1.5384268758727628 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013987951736969663, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23852171378565967, 'dropout_rate_Layer_2': 0.1051105107180883, 'dropout_rate_Layer_3': 0.04037494793659853, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00036589469164234693, 'l1_Layer_2': 0.0019422790262649547, 'l1_Layer_3': 0.005034812519010298, 'n_units_Layer_1': 80, 'n_units_Layer_2': 115, 'n_units_Layer_3': 275}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.29 | sMAPE for Test Set is: 14.86% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:04:52,662]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:46,756]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:05:55,077]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:00,885]\u001b[0m Trial 647 finished with value: 1.5342573326082423 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018393640518909672, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2628551858250433, 'dropout_rate_Layer_2': 0.0871122587350802, 'dropout_rate_Layer_3': 0.06053520761286682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004454298255221217, 'l1_Layer_2': 0.0018566605578467798, 'l1_Layer_3': 0.005034793360733732, 'n_units_Layer_1': 75, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 15.29% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:06:07,599]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:12,471]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:21,433]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:28,386]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:06:38,784]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:09,016]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:13,644]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:20,829]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:20,974]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:28,866]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:28,963]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:07:39,009]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:02,807]\u001b[0m Trial 662 finished with value: 1.5142665508117534 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012831456174494731, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20931604697838052, 'dropout_rate_Layer_2': 0.0717190085269242, 'dropout_rate_Layer_3': 0.07538852560598196, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00029593113408571344, 'l1_Layer_2': 0.001261613191814373, 'l1_Layer_3': 0.006936684722475912, 'n_units_Layer_1': 150, 'n_units_Layer_2': 110, 'n_units_Layer_3': 285}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.16% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 15.87% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:09:07,752]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:19,959]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:25,568]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:42,649]\u001b[0m Trial 664 finished with value: 1.4995399847865325 and parameters: {'n_hidden': 3, 'learning_rate': 0.001982211050693411, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20485225035907018, 'dropout_rate_Layer_2': 0.0472407679109645, 'dropout_rate_Layer_3': 0.07581367349494303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00029257503052430725, 'l1_Layer_2': 0.0012536253324741272, 'l1_Layer_3': 0.000859926559750569, 'n_units_Layer_1': 95, 'n_units_Layer_2': 110, 'n_units_Layer_3': 285}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 14.46% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:09:47,234]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:09:59,114]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:10:14,382]\u001b[0m Trial 671 finished with value: 1.625997568251256 and parameters: {'n_hidden': 3, 'learning_rate': 0.005957203315105307, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14561467120942004, 'dropout_rate_Layer_2': 0.3616402994386051, 'dropout_rate_Layer_3': 0.17252714025508858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.013198611484433001, 'l1_Layer_2': 0.006375064148854755, 'l1_Layer_3': 0.000541811364837528, 'n_units_Layer_1': 80, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255}. Best is trial 414 with value: 1.4414668374088222.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 5.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.67 | sMAPE for Test Set is: 20.79% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:10:18,584]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:10:33,425]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:10:55,430]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:10,737]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:16,100]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:19,063]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:30,019]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:40,011]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:45,177]\u001b[0m Trial 669 finished with value: 1.4336095965774367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020076162933722577, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19416427266539646, 'dropout_rate_Layer_2': 0.043081468704997836, 'dropout_rate_Layer_3': 0.0631651744283478, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002633123452442807, 'l1_Layer_2': 0.001323686797022264, 'l1_Layer_3': 0.0011044671591915987, 'n_units_Layer_1': 90, 'n_units_Layer_2': 110, 'n_units_Layer_3': 285}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.88% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 15.53% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:11:53,208]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:11:59,765]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:13,411]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:18,820]\u001b[0m Trial 682 finished with value: 1.5815691076221856 and parameters: {'n_hidden': 3, 'learning_rate': 0.005748532820076445, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14276655344565276, 'dropout_rate_Layer_2': 0.3882746367648891, 'dropout_rate_Layer_3': 0.22595026855951114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.021408012160896817, 'l1_Layer_2': 0.009219101634778537, 'l1_Layer_3': 0.00015090582036633165, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 285}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 5.42% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.02 | sMAPE for Test Set is: 19.12% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:12:19,351]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:27,017]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:12:53,728]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:03,147]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:21,384]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:27,064]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:34,489]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:43,878]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:13:58,742]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:14:03,978]\u001b[0m Trial 686 finished with value: 1.5084908616209827 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022429145460040544, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20142759441214908, 'dropout_rate_Layer_2': 0.03907981430827871, 'dropout_rate_Layer_3': 0.05996842299703642, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00038317544677692836, 'l1_Layer_2': 0.001427760745670249, 'l1_Layer_3': 0.0009759784097959614, 'n_units_Layer_1': 90, 'n_units_Layer_2': 105, 'n_units_Layer_3': 290}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 15.53% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:14:38,171]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:14:59,854]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:06,923]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:14,666]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:19,406]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:29,743]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:32,394]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:39,644]\u001b[0m Trial 694 finished with value: 1.6753864610794533 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008920849630442599, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06627623740268271, 'dropout_rate_Layer_2': 0.15271363387865078, 'dropout_rate_Layer_3': 0.33149097419936363, 'dropout_rate_Layer_4': 0.032330442789157504, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003906596951356546, 'l1_Layer_2': 0.02285978515453161, 'l1_Layer_3': 0.002960086714418242, 'l1_Layer_4': 0.0007819335259633997, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 245, 'n_units_Layer_4': 225}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 5.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 14.82% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:15:51,920]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:15:56,968]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:03,465]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:13,827]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:21,124]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:31,319]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:38,487]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:39,115]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:43,905]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:46,369]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:16:50,496]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:17:07,890]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:17:32,350]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:17:42,730]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:17:45,481]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:17:52,894]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:18:17,044]\u001b[0m Trial 719 finished with value: 1.5357205958073363 and parameters: {'n_hidden': 3, 'learning_rate': 0.004665952671722373, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1305891766987739, 'dropout_rate_Layer_2': 0.32698386767881626, 'dropout_rate_Layer_3': 0.21228701494194258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02268475688741461, 'l1_Layer_2': 0.012390394637911905, 'l1_Layer_3': 0.00023321185587666212, 'n_units_Layer_1': 105, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.77 | sMAPE for Test Set is: 18.50% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:18:22,070]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:18:34,236]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:18:38,990]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:18:46,496]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:18:55,817]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:19:05,907]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:19:12,845]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:19:20,646]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:19:26,184]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:19:30,919]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:19:35,510]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:19:40,995]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:19:47,529]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:19:52,796]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:19:55,165]\u001b[0m Trial 717 finished with value: 1.492019577053006 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013683269556302043, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20640010713279963, 'dropout_rate_Layer_2': 0.046625681852394324, 'dropout_rate_Layer_3': 0.0726737593339363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00019551508219153895, 'l1_Layer_2': 0.0012804708822646452, 'l1_Layer_3': 0.001185931681804839, 'n_units_Layer_1': 105, 'n_units_Layer_2': 205, 'n_units_Layer_3': 290}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 14.09% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:20:02,403]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:20:05,589]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:20:12,280]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:20:22,346]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:26,458]\u001b[0m Trial 734 finished with value: 1.518401659001185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013772522542242667, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18698780313983399, 'dropout_rate_Layer_2': 0.060121135835965206, 'dropout_rate_Layer_3': 0.1331440698012915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004093720805154122, 'l1_Layer_2': 0.0015012216732732291, 'l1_Layer_3': 0.0021092316161837286, 'n_units_Layer_1': 105, 'n_units_Layer_2': 110, 'n_units_Layer_3': 295}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 15.23% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:21:31,308]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:21:49,145]\u001b[0m Trial 739 finished with value: 1.5347976280990256 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014267580273038824, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20698565378823217, 'dropout_rate_Layer_2': 0.10705034216680709, 'dropout_rate_Layer_3': 0.06627437816698124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003009934895276504, 'l1_Layer_2': 0.0011533021279221836, 'l1_Layer_3': 0.0009109559923459633, 'n_units_Layer_1': 90, 'n_units_Layer_2': 215, 'n_units_Layer_3': 300}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 14.44% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:21:58,519]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:03,569]\u001b[0m Trial 741 finished with value: 1.5965081923234397 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008893543447221981, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09668797862063215, 'dropout_rate_Layer_2': 0.09447083010304372, 'dropout_rate_Layer_3': 0.07349896003836003, 'dropout_rate_Layer_4': 0.01656803330421765, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.6615999788964016e-05, 'l1_Layer_2': 1.0607992801539008e-05, 'l1_Layer_3': 1.5776929241357116e-05, 'l1_Layer_4': 5.464574188051664e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 80, 'n_units_Layer_3': 180, 'n_units_Layer_4': 245}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 5.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.22 | sMAPE for Test Set is: 19.70% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:22:08,942]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:13,876]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:25,250]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:28,676]\u001b[0m Trial 743 finished with value: 1.548604516095067 and parameters: {'n_hidden': 3, 'learning_rate': 0.004785293299457459, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17730960702994428, 'dropout_rate_Layer_2': 0.30487989500347573, 'dropout_rate_Layer_3': 0.24782567906338843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0061424665236172, 'l1_Layer_2': 0.01205870677714752, 'l1_Layer_3': 0.0007313803305797977, 'n_units_Layer_1': 105, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 15.65% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:22:37,840]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:43,275]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:47,623]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:22:54,694]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:00,468]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:12,465]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:21,933]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:22,284]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:44,252]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:44,660]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:53,719]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:23:56,970]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:24:16,024]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:24:21,532]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:24:26,812]\u001b[0m Trial 760 finished with value: 1.5745918434292243 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025258832454059725, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20545359838381425, 'dropout_rate_Layer_2': 0.3221031363413665, 'dropout_rate_Layer_3': 0.24920494838615212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002864991862821495, 'l1_Layer_2': 0.0333255319170887, 'l1_Layer_3': 0.0007012998970346685, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 300}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.36% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 15.78% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:24:30,828]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:24:50,604]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:24:52,998]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:00,764]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:05,539]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:22,364]\u001b[0m Trial 766 finished with value: 1.5823343546918869 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030907450782445014, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1707774872355461, 'dropout_rate_Layer_2': 0.31045907484834584, 'dropout_rate_Layer_3': 0.21358651025885292, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0018751918507999398, 'l1_Layer_2': 0.020882314223692744, 'l1_Layer_3': 0.0004197245428639033, 'n_units_Layer_1': 125, 'n_units_Layer_2': 155, 'n_units_Layer_3': 290}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 5.42% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 16.00% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:25:32,317]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:37,155]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:44,704]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:48,997]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:49,738]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:25:58,759]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:26:01,503]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:26:09,078]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:26:16,799]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:26:43,567]\u001b[0m Trial 776 finished with value: 1.5337504112609492 and parameters: {'n_hidden': 3, 'learning_rate': 0.00200945409417563, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18419872709379942, 'dropout_rate_Layer_2': 0.15910430071778203, 'dropout_rate_Layer_3': 0.23274680132588452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0008480968587216147, 'l1_Layer_2': 0.01767404385643437, 'l1_Layer_3': 0.00023025247902741392, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.41 | sMAPE for Test Set is: 17.60% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:26:45,973]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:26:48,554]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:26:55,267]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:26:58,495]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:27:05,052]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:27:08,301]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:27:12,283]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:27:20,245]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:27:32,678]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:27:44,556]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:27:44,844]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:27:56,997]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:28:04,468]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:28:14,059]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:28:46,036]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:28:55,933]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:29:35,520]\u001b[0m Trial 795 finished with value: 1.544175361974279 and parameters: {'n_hidden': 4, 'learning_rate': 0.003376649308157492, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35744118526616614, 'dropout_rate_Layer_2': 0.021968614944530583, 'dropout_rate_Layer_3': 0.2816787637559621, 'dropout_rate_Layer_4': 0.11340732760353056, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008114390583180557, 'l1_Layer_2': 0.013919508704521213, 'l1_Layer_3': 3.988061339987312e-05, 'l1_Layer_4': 5.123009775167042e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 195, 'n_units_Layer_3': 215, 'n_units_Layer_4': 250}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.33 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:29:42,056]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:29:52,381]\u001b[0m Trial 789 finished with value: 1.4834468428471457 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016636900191997874, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21631522396675165, 'dropout_rate_Layer_2': 0.054577675080877464, 'dropout_rate_Layer_3': 0.07992582435931514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004026673982988883, 'l1_Layer_2': 0.00093675921168264, 'l1_Layer_3': 0.0005895997975667934, 'n_units_Layer_1': 85, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 14.04% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:29:56,933]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:30:04,287]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:30:24,572]\u001b[0m Trial 797 finished with value: 1.6191936379526801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018362941943446927, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0005225822924291026, 'dropout_rate_Layer_2': 0.36837655314540413, 'dropout_rate_Layer_3': 0.327989240454395, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024690934174735253, 'l1_Layer_2': 0.0037970796119721818, 'l1_Layer_3': 1.3545729531450998e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 5.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.96 | sMAPE for Test Set is: 24.25% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:30:33,616]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:30:45,935]\u001b[0m Trial 800 finished with value: 1.6701985424901296 and parameters: {'n_hidden': 4, 'learning_rate': 0.004092512346457837, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33462509730358586, 'dropout_rate_Layer_2': 0.018269704389883897, 'dropout_rate_Layer_3': 0.28292922587997443, 'dropout_rate_Layer_4': 0.11363244638214731, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00879549341277176, 'l1_Layer_2': 0.016198200158772817, 'l1_Layer_3': 3.976246298590602e-05, 'l1_Layer_4': 1.1872632456316723e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 195, 'n_units_Layer_3': 195, 'n_units_Layer_4': 255}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.67 | sMAPE for Validation Set is: 5.73% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.69 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:30:56,482]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:31:05,958]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:31:26,170]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:31:38,019]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:31:38,117]\u001b[0m Trial 805 finished with value: 1.619109747849363 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033148063921867392, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3693045312288377, 'dropout_rate_Layer_2': 0.001424485562517154, 'dropout_rate_Layer_3': 0.3209738944567967, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.03157250786020962, 'l1_Layer_2': 0.07409480954900295, 'l1_Layer_3': 7.193164092851783e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 5.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.14 | sMAPE for Test Set is: 16.92% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:31:44,709]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:31:46,783]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:31:52,105]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:31:54,586]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:32:14,048]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:32:21,212]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:32:26,845]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:33:12,866]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:33:20,089]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:33:47,619]\u001b[0m Trial 815 finished with value: 1.554495175084588 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018416140894443995, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014762540857430125, 'dropout_rate_Layer_2': 0.35438042468996883, 'dropout_rate_Layer_3': 0.31640738381926076, 'dropout_rate_Layer_4': 0.15035194256378798, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01185744407726489, 'l1_Layer_2': 0.005068627119453176, 'l1_Layer_3': 0.00010979363053840646, 'l1_Layer_4': 0.0005707913177098552, 'n_units_Layer_1': 105, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260, 'n_units_Layer_4': 250}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 20.92% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:33:57,053]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:02,123]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:09,544]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:14,924]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:15,019]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:22,744]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:32,530]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:35,171]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:43,866]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:47,038]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:49,101]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:34:51,567]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:01,571]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:09,068]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:11,351]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:16,658]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:18,906]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:23,587]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:25,920]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:38,559]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:45,652]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:35:53,463]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:36:00,767]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:36:03,035]\u001b[0m Trial 836 finished with value: 1.5719804057773044 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028712085509222892, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1550713733662749, 'dropout_rate_Layer_2': 0.07085596703784433, 'dropout_rate_Layer_3': 0.30296075033152703, 'dropout_rate_Layer_4': 0.04767241310903342, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0062991614580037445, 'l1_Layer_2': 0.013803001476464741, 'l1_Layer_3': 4.149101530949339e-05, 'l1_Layer_4': 3.678688233740432e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 215, 'n_units_Layer_3': 215, 'n_units_Layer_4': 235}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.36% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 17.60% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:36:12,093]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:36:19,321]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:36:26,805]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:36:32,494]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:36:39,567]\u001b[0m Trial 841 finished with value: 1.7155805891274962 and parameters: {'n_hidden': 4, 'learning_rate': 0.005362904166182438, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06483039810404544, 'dropout_rate_Layer_2': 0.07115310808772835, 'dropout_rate_Layer_3': 0.018293135928907526, 'dropout_rate_Layer_4': 0.09486236031831054, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008873063686054757, 'l1_Layer_2': 0.034027385598372845, 'l1_Layer_3': 4.5508193054351644e-05, 'l1_Layer_4': 3.491899370991265e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215, 'n_units_Layer_4': 230}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.72 | sMAPE for Validation Set is: 5.89% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.57 | sMAPE for Test Set is: 23.41% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:36:46,273]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:36:51,419]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:36:58,739]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:37:05,843]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:37:16,116]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:37:28,321]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:37:45,542]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:38:02,390]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:38:09,824]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:38:29,615]\u001b[0m Trial 854 finished with value: 1.5973550164188974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018552886848135987, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035012426206531305, 'dropout_rate_Layer_2': 0.3888607743791533, 'dropout_rate_Layer_3': 0.349579802904537, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0016343862854552723, 'l1_Layer_2': 0.005387538669520848, 'l1_Layer_3': 6.536429257113383e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 5.46% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.13 | sMAPE for Test Set is: 22.05% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:38:44,759]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:38:50,092]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:39:01,994]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:39:04,174]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:39:09,244]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:39:11,943]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:39:19,337]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:39:26,416]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:39:36,423]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:39:43,235]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:40:07,705]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:40:27,647]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:40:34,422]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:40:37,597]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:40:37,786]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:10,067]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:10,597]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:15,750]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:19,982]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:25,259]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:32,049]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:35,144]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:39,551]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:42,212]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:47,092]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:41:49,697]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:42:11,846]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:12,358]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:18,124]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:20,577]\u001b[0m Trial 882 finished with value: 1.530917671006485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014258776672994213, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21365409054160017, 'dropout_rate_Layer_2': 0.10215183088811858, 'dropout_rate_Layer_3': 0.07074999396023424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00037631132353281983, 'l1_Layer_2': 0.0008711618937114515, 'l1_Layer_3': 0.0018891558028895133, 'n_units_Layer_1': 135, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 14.33% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:43:27,491]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:30,304]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:34,848]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:34,955]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:43,504]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:48,792]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:53,393]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:43:56,017]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:00,761]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:03,539]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:08,343]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:08,454]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:21,645]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:26,749]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:31,995]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:32,166]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:40,391]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:47,193]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:44:54,620]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:45:01,673]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:45:06,745]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:45:29,472]\u001b[0m Trial 908 finished with value: 1.7239117772530352 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027781475312380816, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1420217477181137, 'dropout_rate_Layer_2': 0.043755032937912, 'dropout_rate_Layer_3': 0.28184098599219687, 'dropout_rate_Layer_4': 0.04789638108046661, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002572290361969456, 'l1_Layer_2': 0.005744757444258112, 'l1_Layer_3': 6.431475772104522e-05, 'l1_Layer_4': 2.9129383007991532e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 240, 'n_units_Layer_3': 200, 'n_units_Layer_4': 225}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.72 | sMAPE for Validation Set is: 5.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.63 | sMAPE for Test Set is: 20.88% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:46:20,425]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:46:25,873]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:46:40,007]\u001b[0m Trial 903 finished with value: 1.4470328587082733 and parameters: {'n_hidden': 3, 'learning_rate': 0.001176163038989337, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23652238121871785, 'dropout_rate_Layer_2': 0.12245881434509548, 'dropout_rate_Layer_3': 0.12445524075209162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00032375281534049484, 'l1_Layer_2': 0.0011584525006030598, 'l1_Layer_3': 0.0009264721052305263, 'n_units_Layer_1': 90, 'n_units_Layer_2': 100, 'n_units_Layer_3': 280}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 6.27 | sMAPE for Test Set is: 14.81% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:46:47,235]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:46:54,270]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:00,175]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:06,976]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:11,962]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:17,218]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:22,411]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:24,911]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:33,851]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:46,403]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:56,628]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:47:58,914]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:04,009]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:08,203]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:18,779]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:28,430]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:28,550]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:34,321]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:34,428]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:44,494]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:48:51,859]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:49:02,150]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:49:17,316]\u001b[0m Trial 932 finished with value: 1.6310763187159816 and parameters: {'n_hidden': 4, 'learning_rate': 0.003049366980667347, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19185166353992716, 'dropout_rate_Layer_2': 0.05460964835411411, 'dropout_rate_Layer_3': 0.17382682520511056, 'dropout_rate_Layer_4': 0.07573243223671015, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00170360870705783, 'l1_Layer_2': 0.01832838749618516, 'l1_Layer_3': 3.0291297155289458e-05, 'l1_Layer_4': 9.956211912024038e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 190, 'n_units_Layer_3': 170, 'n_units_Layer_4': 205}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 5.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.27 | sMAPE for Test Set is: 22.45% | rMAE for Test Set is: 1.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:49:22,341]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:49:29,133]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:49:36,458]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:49:41,398]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:49:48,717]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:49:59,015]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:50:08,874]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:50:09,361]\u001b[0m Trial 939 finished with value: 1.5491769836113216 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023709627025194453, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2109445825083453, 'dropout_rate_Layer_2': 0.3218309425929045, 'dropout_rate_Layer_3': 0.25131286854879575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0031487721655748748, 'l1_Layer_2': 0.035355866966353344, 'l1_Layer_3': 0.00024553478401306096, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 300}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 16.08% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:50:17,683]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:50:22,554]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:50:32,237]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:50:46,914]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:51:06,611]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:51:16,590]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:51:28,164]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:51:29,730]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:51:37,944]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:51:45,723]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:51:50,804]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:52:05,329]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:52:12,599]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:25,666]\u001b[0m Trial 950 finished with value: 1.4657919083227657 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013862450860852218, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21548375139754472, 'dropout_rate_Layer_2': 0.06731092767608986, 'dropout_rate_Layer_3': 0.034304523820770996, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00028591879558635257, 'l1_Layer_2': 0.0007578219269192026, 'l1_Layer_3': 0.001422662917638074, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 295}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 14.35% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:53:32,672]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:39,861]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:47,216]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:53:52,612]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:02,778]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:09,601]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:09,973]\u001b[0m Trial 956 finished with value: 1.4448401878044368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015030362532891688, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 6.587113914949261e-05, 'dropout_rate_Layer_2': 0.18601076045296738, 'dropout_rate_Layer_3': 0.09233742195149369, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00026976743219723955, 'l1_Layer_2': 0.0011600991966920532, 'l1_Layer_3': 0.0008171460629793013, 'n_units_Layer_1': 95, 'n_units_Layer_2': 125, 'n_units_Layer_3': 280}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 4.90% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 6.38 | sMAPE for Test Set is: 15.07% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:54:18,006]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:25,403]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:31,981]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:33,893]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:39,629]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:42,594]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:47,637]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:54:57,344]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:01,332]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:09,043]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:16,897]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:24,482]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:36,203]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:46,067]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:55:51,828]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:03,633]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:03,772]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:15,949]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:21,283]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:28,410]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:36,645]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:56:43,355]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:05,777]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:21,254]\u001b[0m Trial 986 finished with value: 1.5935836957508844 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024266428943541794, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1300614150189084, 'dropout_rate_Layer_2': 0.1279353035419127, 'dropout_rate_Layer_3': 0.3192772384431277, 'dropout_rate_Layer_4': 0.10774999941125346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013515581757096547, 'l1_Layer_2': 0.00629568388465482, 'l1_Layer_3': 0.00021798827857080787, 'l1_Layer_4': 1.6706553524060716e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290, 'n_units_Layer_4': 250}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 5.47% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.26 | sMAPE for Test Set is: 8.19% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:57:30,774]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:34,150]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:40,605]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:42,680]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:47,935]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:57:57,513]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:58:08,289]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:58:25,670]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:58:32,189]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:58:42,785]\u001b[0m Trial 991 finished with value: 1.8479368518584263 and parameters: {'n_hidden': 4, 'learning_rate': 0.00740785027520831, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3357278595354823, 'dropout_rate_Layer_2': 0.15366296220874254, 'dropout_rate_Layer_3': 0.3016849750689568, 'dropout_rate_Layer_4': 0.16162379827845352, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004302473639479722, 'l1_Layer_2': 0.0021688879597017174, 'l1_Layer_3': 0.0005418060648126521, 'l1_Layer_4': 6.832455166432625e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 160, 'n_units_Layer_3': 185, 'n_units_Layer_4': 275}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 6.37% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.00 | sMAPE for Test Set is: 19.22% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 13:58:49,132]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:58:49,595]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:58:58,137]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:59:07,162]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:59:09,495]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:59:16,641]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:59:23,886]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:59:29,145]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:59:34,678]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 13:59:46,349]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:00:09,300]\u001b[0m Trial 1002 finished with value: 1.6019392388626184 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015801277233497366, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12958384205748252, 'dropout_rate_Layer_2': 0.12879084852453543, 'dropout_rate_Layer_3': 0.3280517673340749, 'dropout_rate_Layer_4': 0.10793689242277796, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01584644452470496, 'l1_Layer_2': 0.031058274534146134, 'l1_Layer_3': 0.0002174589129710768, 'l1_Layer_4': 1.4551475472398897e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 270, 'n_units_Layer_4': 245}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 5.47% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.87 | sMAPE for Test Set is: 9.51% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:00:21,172]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:00:36,869]\u001b[0m Trial 1008 finished with value: 1.620740662580096 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022589738141881384, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13343028012693692, 'dropout_rate_Layer_2': 0.12379561093859098, 'dropout_rate_Layer_3': 0.3219618258061461, 'dropout_rate_Layer_4': 0.10976146677330165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014537809384889926, 'l1_Layer_2': 0.006429695025331781, 'l1_Layer_3': 0.00025470411423502033, 'l1_Layer_4': 1.4875231248508168e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275, 'n_units_Layer_4': 250}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 5.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.32 | sMAPE for Test Set is: 8.20% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:00:58,907]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:03,096]\u001b[0m Trial 1010 finished with value: 1.5449915013766156 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023849364533022614, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08613854933440013, 'dropout_rate_Layer_2': 0.08380719237916501, 'dropout_rate_Layer_3': 0.2872282742692125, 'dropout_rate_Layer_4': 0.0924903403379933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.008851914962015877, 'l1_Layer_2': 0.010854254380547325, 'l1_Layer_3': 5.6376740375856296e-05, 'l1_Layer_4': 2.2081029832972885e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 190, 'n_units_Layer_3': 295, 'n_units_Layer_4': 255}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.06 | sMAPE for Test Set is: 7.71% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:01:06,299]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:13,572]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:23,397]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:28,017]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:28,441]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:33,474]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:38,210]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:40,717]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:01:52,716]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:02:02,802]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:02:13,066]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:02:24,900]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:02:30,062]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:03:02,592]\u001b[0m Trial 1026 finished with value: 1.56680552608696 and parameters: {'n_hidden': 3, 'learning_rate': 0.002497710211617917, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21001230852205133, 'dropout_rate_Layer_2': 0.3026195586564515, 'dropout_rate_Layer_3': 0.24900123488395576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0021860644467616283, 'l1_Layer_2': 0.034708005650767225, 'l1_Layer_3': 0.0006168503436668736, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 300}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.00 | sMAPE for Test Set is: 16.62% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:03:09,515]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:03:56,332]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:04:04,137]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:04:11,805]\u001b[0m Trial 1020 finished with value: 1.4964715310137582 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015424795125617103, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18783647773482268, 'dropout_rate_Layer_2': 0.0831810997333575, 'dropout_rate_Layer_3': 0.09147027141223166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000407385921392852, 'l1_Layer_2': 0.0016472966806172042, 'l1_Layer_3': 0.0008033595826735978, 'n_units_Layer_1': 85, 'n_units_Layer_2': 115, 'n_units_Layer_3': 275}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 14.04% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:04:33,822]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:04:40,843]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:04:46,397]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:05:01,144]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:05:10,417]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:05:43,180]\u001b[0m Trial 1030 finished with value: 1.5723450896282654 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005075183205906844, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11103129263137528, 'dropout_rate_Layer_2': 0.10179313569508189, 'dropout_rate_Layer_3': 0.28897671359616467, 'dropout_rate_Layer_4': 0.05523469294293851, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.037547690736236046, 'l1_Layer_2': 0.0033917957407753442, 'l1_Layer_3': 9.16768211907937e-05, 'l1_Layer_4': 2.1677039875662166e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290, 'n_units_Layer_4': 240}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.99 | sMAPE for Test Set is: 7.57% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:05:50,232]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:00,214]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:00,445]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:13,712]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:13,854]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:24,146]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:31,543]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:36,656]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:41,681]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:46,917]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:51,298]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:57,018]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:06:59,748]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:07:06,488]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:07:19,150]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:07:41,640]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:07:48,387]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:07:55,951]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:08:03,239]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:08:10,628]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 5.30% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.64 | sMAPE for Test Set is: 15.72% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:08:37,651]\u001b[0m Trial 1057 finished with value: 1.5550222095475295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034147869035854967, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1906326922654593, 'dropout_rate_Layer_2': 0.19622308090561696, 'dropout_rate_Layer_3': 0.33278385411844735, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0025610872281031077, 'l1_Layer_2': 0.038850904103324486, 'l1_Layer_3': 0.0005591077799581618, 'n_units_Layer_1': 120, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:09:00,109]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:09:07,514]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:09:13,312]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:09:24,913]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:09:50,371]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:09:55,455]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:10:27,911]\u001b[0m Trial 1064 finished with value: 1.5506125144230365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032107358323230496, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1916663911573765, 'dropout_rate_Layer_2': 0.1810486916456568, 'dropout_rate_Layer_3': 0.22247592632289828, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0025498895006467195, 'l1_Layer_2': 0.05824437096547531, 'l1_Layer_3': 0.0006387159328404452, 'n_units_Layer_1': 90, 'n_units_Layer_2': 160, 'n_units_Layer_3': 280}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.30% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 16.15% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:10:34,908]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:10:42,044]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:10:49,165]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:10:56,775]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:01,621]\u001b[0m Trial 1054 finished with value: 1.467071974610483 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015907230348178915, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20312948834851058, 'dropout_rate_Layer_2': 0.09145399782657469, 'dropout_rate_Layer_3': 0.050753812621831616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004202856868612406, 'l1_Layer_2': 0.0021359559074143864, 'l1_Layer_3': 0.001134121701907323, 'n_units_Layer_1': 125, 'n_units_Layer_2': 110, 'n_units_Layer_3': 265}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 14.50% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:11:07,126]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:10,507]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:20,839]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:28,226]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:40,021]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:49,875]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:55,377]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:57,368]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:11:59,701]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:12:04,685]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:12:12,403]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:12:14,778]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:12:22,238]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:12:43,839]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:13:20,721]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:13:26,194]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:13:48,034]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:13:55,377]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:14:05,950]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:14:10,278]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:14:15,466]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:14:27,592]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:14:35,021]\u001b[0m Trial 1084 finished with value: 1.5417419031168047 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017439140174710852, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.221081821528635, 'dropout_rate_Layer_2': 0.07275478567762372, 'dropout_rate_Layer_3': 0.057736969449529565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00040175304874097455, 'l1_Layer_2': 0.001989273146224918, 'l1_Layer_3': 0.0007307783240727815, 'n_units_Layer_1': 120, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 15.72% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:14:37,861]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:14:45,065]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:14:52,421]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:14:57,480]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:00,000]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:05,313]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:14,087]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:16,979]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:19,318]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:24,664]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:27,111]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:29,405]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:37,184]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:42,151]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:44,441]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:54,677]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:15:54,874]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:12,668]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:20,317]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:20,715]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:28,300]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:33,548]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:16:46,472]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:17:00,945]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:00,010]\u001b[0m Trial 1115 finished with value: 1.543553000180193 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006038508334153526, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09726782578660442, 'dropout_rate_Layer_2': 0.08141217419992429, 'dropout_rate_Layer_3': 0.27973266443041706, 'dropout_rate_Layer_4': 0.07253579518915483, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03648095181056396, 'l1_Layer_2': 0.009511670267670056, 'l1_Layer_3': 8.49267612060895e-05, 'l1_Layer_4': 2.0796874679527916e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285, 'n_units_Layer_4': 235}. Best is trial 669 with value: 1.4336095965774367.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.26 | sMAPE for Test Set is: 8.16% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:18:02,969]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:10,440]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:19,948]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:25,560]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:35,347]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:47,577]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:18:57,280]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:04,327]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:07,596]\u001b[0m Trial 1117 finished with value: 1.426645945703517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015120341916257521, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19031981472047574, 'dropout_rate_Layer_2': 0.07869325481754233, 'dropout_rate_Layer_3': 0.06362059538617132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001546383095600523, 'l1_Layer_2': 0.0008050906205033619, 'l1_Layer_3': 0.0015589670740672427, 'n_units_Layer_1': 230, 'n_units_Layer_2': 115, 'n_units_Layer_3': 275}. Best is trial 1117 with value: 1.426645945703517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.84% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 14.69% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:19:14,632]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:15,147]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:20,504]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:25,083]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:27,691]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:32,750]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:42,631]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:47,169]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:54,439]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:19:59,514]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:20:04,834]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:20:09,672]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:20:14,962]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:20:21,591]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:20:27,000]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:20:32,144]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:20:41,419]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:20:50,842]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:21:11,588]\u001b[0m Trial 1145 finished with value: 1.556334336394482 and parameters: {'n_hidden': 3, 'learning_rate': 0.004568071281478465, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1639358315229096, 'dropout_rate_Layer_2': 0.16461015171998258, 'dropout_rate_Layer_3': 0.30603879978819976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0022881259213030137, 'l1_Layer_2': 0.01700837893960243, 'l1_Layer_3': 0.0001776496305442136, 'n_units_Layer_1': 115, 'n_units_Layer_2': 175, 'n_units_Layer_3': 215}. Best is trial 1117 with value: 1.426645945703517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 15.74% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:21:46,270]\u001b[0m Trial 1137 finished with value: 1.4136677715809431 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006051805477727625, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08937633157878783, 'dropout_rate_Layer_2': 0.06089498598719109, 'dropout_rate_Layer_3': 0.26052480090202296, 'dropout_rate_Layer_4': 0.08436625765585526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.023989121874906556, 'l1_Layer_2': 0.00021453096205986558, 'l1_Layer_3': 5.3583140825390586e-05, 'l1_Layer_4': 7.908373539687519e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260, 'n_units_Layer_4': 260}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.81% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.03 | sMAPE for Test Set is: 7.56% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:22:01,053]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:22:07,614]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:22:21,022]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:22:48,959]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:22:56,039]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:23:25,722]\u001b[0m Trial 1152 finished with value: 1.511299392888444 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041403493024575145, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1221399007581224, 'dropout_rate_Layer_2': 0.15683521286354377, 'dropout_rate_Layer_3': 0.33327829433415324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0020632425296837195, 'l1_Layer_2': 0.00967575929931442, 'l1_Layer_3': 0.00017806609227271337, 'n_units_Layer_1': 110, 'n_units_Layer_2': 185, 'n_units_Layer_3': 270}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 14.85% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:23:32,533]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:23:38,030]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:23:40,053]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:23:45,628]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:23:50,086]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:23:59,970]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:24:06,889]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:24:17,371]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:24:22,710]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:14,008]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:18,804]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:28,868]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:31,212]\u001b[0m Trial 1162 finished with value: 1.5191858802560987 and parameters: {'n_hidden': 4, 'learning_rate': 0.000669751814134649, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21337441002295365, 'dropout_rate_Layer_2': 0.061527065431036164, 'dropout_rate_Layer_3': 0.23253034807366058, 'dropout_rate_Layer_4': 0.11894251295063989, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02559667645920388, 'l1_Layer_2': 8.610988640350548e-05, 'l1_Layer_3': 7.302236421743367e-05, 'l1_Layer_4': 0.0003466010578432644, 'n_units_Layer_1': 160, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265, 'n_units_Layer_4': 205}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.16% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.04 | sMAPE for Test Set is: 7.65% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:26:36,226]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:41,159]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:46,142]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:53,134]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:26:58,507]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:27:05,687]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:27:10,398]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:27:49,300]\u001b[0m Trial 1173 finished with value: 1.4487872410797316 and parameters: {'n_hidden': 3, 'learning_rate': 0.003236482130581197, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20033168014592534, 'dropout_rate_Layer_2': 0.17352107330213912, 'dropout_rate_Layer_3': 0.3284160689949495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0014933174395244076, 'l1_Layer_2': 0.008098038166001504, 'l1_Layer_3': 7.903674546212654e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 14.49% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:28:07,015]\u001b[0m Trial 1167 finished with value: 1.5766916586256112 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005928137253618102, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0881682128585883, 'dropout_rate_Layer_2': 0.06197157725709974, 'dropout_rate_Layer_3': 0.2320090654558484, 'dropout_rate_Layer_4': 0.12795617453451488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.03884433921211598, 'l1_Layer_2': 9.194529236085496e-05, 'l1_Layer_3': 8.466418240920664e-05, 'l1_Layer_4': 5.74173142965653e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280, 'n_units_Layer_4': 260}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.96 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:28:13,951]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:28:32,658]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:28:46,993]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:28:52,519]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:28:59,411]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:29:11,453]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:29:16,885]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:29:40,160]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:29:46,705]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:29:52,414]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:13,775]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:19,442]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:23,542]\u001b[0m Trial 1177 finished with value: 1.4435515647049943 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010727924193847, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17976554805258793, 'dropout_rate_Layer_2': 0.08170064505545158, 'dropout_rate_Layer_3': 0.09089755341299319, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00018499018883622587, 'l1_Layer_2': 0.0013780405401039389, 'l1_Layer_3': 0.0010967023913856127, 'n_units_Layer_1': 125, 'n_units_Layer_2': 100, 'n_units_Layer_3': 295}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 4.90% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 14.45% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:30:36,678]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:41,572]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:30:55,674]\u001b[0m Trial 1187 finished with value: 1.5398008347534375 and parameters: {'n_hidden': 3, 'learning_rate': 0.003906025947312554, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12434624708611326, 'dropout_rate_Layer_2': 0.17818355288260576, 'dropout_rate_Layer_3': 0.3302609291969247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0015176216764408675, 'l1_Layer_2': 0.0069993587125737255, 'l1_Layer_3': 5.783018503561542e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 140, 'n_units_Layer_3': 255}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 15.42% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:31:00,424]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:07,860]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:07,995]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:16,470]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:18,673]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:29,009]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:33,492]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:40,788]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:45,449]\u001b[0m Trial 1195 finished with value: 1.533306765804965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036862532124290388, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12371276951022825, 'dropout_rate_Layer_2': 0.174717566800453, 'dropout_rate_Layer_3': 0.32240295844953315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0009242460616152569, 'l1_Layer_2': 0.006636133984643195, 'l1_Layer_3': 2.4159086584190694e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 140, 'n_units_Layer_3': 250}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.77 | sMAPE for Test Set is: 15.96% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:31:51,065]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:57,773]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:31:58,324]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:08,134]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:10,445]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:15,121]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:15,497]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:25,046]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:30,777]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:37,555]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:47,269]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:32:55,160]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:33:00,450]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:33:12,600]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:33:25,239]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:33:32,205]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:33:35,019]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:33:51,388]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:33:58,868]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:34:04,715]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:34:14,014]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:34:21,056]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:34:28,452]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:34:38,979]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:34:44,161]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:34:58,648]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:35:13,557]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:35:20,561]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:35:24,227]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:35:30,319]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:35:37,375]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:35:44,596]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:35:57,857]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:08,941]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:15,020]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:22,409]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:33,231]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:37,968]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:42,767]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:36:50,888]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:00,069]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:01,142]\u001b[0m Trial 1213 finished with value: 1.5992997234049675 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011274571592322078, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36627896247413133, 'dropout_rate_Layer_2': 0.047844993309596406, 'dropout_rate_Layer_3': 0.24711766249607478, 'dropout_rate_Layer_4': 0.1151845626062034, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.000507638563363404, 'l1_Layer_2': 0.0003176287563035493, 'l1_Layer_3': 0.09956906822342536, 'l1_Layer_4': 0.000529447683458622, 'n_units_Layer_1': 185, 'n_units_Layer_2': 130, 'n_units_Layer_3': 270, 'n_units_Layer_4': 285}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 5.47% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.80 | sMAPE for Test Set is: 9.42% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:37:08,446]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:14,297]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:16,111]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:23,770]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:23,897]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:31,555]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:38,932]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:39,531]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:47,576]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:50,386]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:37:55,036]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:38:02,310]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:38:24,890]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:38:29,749]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:38:54,205]\u001b[0m Trial 1256 finished with value: 1.625082898956881 and parameters: {'n_hidden': 3, 'learning_rate': 0.006248155259649132, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11368024185245634, 'dropout_rate_Layer_2': 0.16051154789249827, 'dropout_rate_Layer_3': 0.3210009813798133, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006855990707798317, 'l1_Layer_2': 0.013330870792230451, 'l1_Layer_3': 0.00011078609310977997, 'n_units_Layer_1': 110, 'n_units_Layer_2': 150, 'n_units_Layer_3': 225}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 5.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 15.04% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:39:01,892]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:09,335]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:19,390]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:24,837]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:25,028]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:32,872]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:33,821]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:41,185]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:47,907]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:39:55,593]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:18,437]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:25,159]\u001b[0m Trial 1267 finished with value: 1.5658515451118713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033275138169250726, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12314986606136853, 'dropout_rate_Layer_2': 0.20380386864036812, 'dropout_rate_Layer_3': 0.3347429700569795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003240166325803177, 'l1_Layer_2': 0.0021251202553552568, 'l1_Layer_3': 6.252252243904155e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 160, 'n_units_Layer_3': 285}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.34% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.37 | sMAPE for Test Set is: 14.99% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:40:30,773]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:32,572]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:39,862]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:40,430]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:47,826]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:40:57,506]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:41:02,832]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:41:14,810]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:41:22,481]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:41:28,398]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:41:38,016]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:41:50,041]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:41:57,148]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:02,458]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:07,941]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:15,407]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:42:53,130]\u001b[0m Trial 1273 finished with value: 1.6028740905161454 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006160353984190263, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03321593412576573, 'dropout_rate_Layer_2': 0.08484381294170304, 'dropout_rate_Layer_3': 0.2565781118469397, 'dropout_rate_Layer_4': 0.0818434450500865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02042459581982636, 'l1_Layer_2': 0.00020286997191958837, 'l1_Layer_3': 6.82376479909229e-05, 'l1_Layer_4': 1.896914734576165e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 160, 'n_units_Layer_3': 155, 'n_units_Layer_4': 210}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 5.48% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.00 | sMAPE for Test Set is: 9.86% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:43:00,174]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:43:15,734]\u001b[0m Trial 1285 finished with value: 1.613447575715667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015841049168091534, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04549132813749805, 'dropout_rate_Layer_2': 0.3531514873420672, 'dropout_rate_Layer_3': 0.2918751003916579, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005233883003406528, 'l1_Layer_2': 3.240973004194705e-05, 'l1_Layer_3': 0.0002123375767443498, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 290}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.61 | sMAPE for Validation Set is: 5.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.46 | sMAPE for Test Set is: 17.70% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:43:50,305]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:43:59,895]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:44:09,254]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:44:29,378]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:44:36,902]\u001b[0m Trial 1288 finished with value: 1.5748079331094325 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007396751640028442, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09197050855135463, 'dropout_rate_Layer_2': 0.385172880369084, 'dropout_rate_Layer_3': 0.2312204892953858, 'dropout_rate_Layer_4': 0.07275775928013192, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02398037274003818, 'l1_Layer_2': 0.003611961701539943, 'l1_Layer_3': 5.226587702574949e-05, 'l1_Layer_4': 0.004698727360609894, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 280, 'n_units_Layer_4': 220}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.39% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.13 | sMAPE for Test Set is: 7.87% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:44:37,248]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:44:42,897]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:44:52,856]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:45:02,663]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:45:14,421]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:45:20,110]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:45:36,793]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:45:44,172]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:45:44,371]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:45:52,966]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:02,284]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:07,573]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:12,141]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:14,699]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:22,008]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:22,703]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:29,121]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:36,936]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:46,799]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:46:54,049]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:47:00,945]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:47:06,259]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:47:06,449]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:47:14,938]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:47:17,586]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:47:25,066]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:47:30,035]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:48:02,576]\u001b[0m Trial 1320 finished with value: 1.539603340674601 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026484224717063794, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16725569951010708, 'dropout_rate_Layer_2': 0.13504853851155432, 'dropout_rate_Layer_3': 0.3313585507005508, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002610803422717816, 'l1_Layer_2': 0.013487646360559912, 'l1_Layer_3': 0.0002994393443731934, 'n_units_Layer_1': 120, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 14.47% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:48:12,437]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:48:24,844]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:48:33,923]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:48:39,650]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:48:39,896]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:48:49,772]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:49:04,712]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:49:10,345]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:49:16,991]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:49:22,020]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:49:34,605]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:49:41,611]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:09,212]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:50:19,275]\u001b[0m Trial 1325 finished with value: 1.511510571536627 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005594223006476005, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08339911935006605, 'dropout_rate_Layer_2': 0.14329597142263029, 'dropout_rate_Layer_3': 0.2843456366929945, 'dropout_rate_Layer_4': 0.10021749497177398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04974339620494575, 'l1_Layer_2': 3.9132530925894446e-05, 'l1_Layer_3': 2.452832738657973e-05, 'l1_Layer_4': 8.106690656394644e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 165, 'n_units_Layer_4': 195}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 2.96 | sMAPE for Test Set is: 7.47% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:50:29,272]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:01,496]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:05,163]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:12,490]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:17,998]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:20,466]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:27,716]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:32,718]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:37,556]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:42,902]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:45,195]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:52,105]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:52,892]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:51:59,875]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:52:00,437]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:52:11,201]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:52:20,230]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:52:38,015]\u001b[0m Trial 1350 finished with value: 1.5405063015211449 and parameters: {'n_hidden': 3, 'learning_rate': 0.002754986280458539, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14537450826800435, 'dropout_rate_Layer_2': 0.1347271787308832, 'dropout_rate_Layer_3': 0.31165005260676315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0028068574365130985, 'l1_Layer_2': 0.01743683529963018, 'l1_Layer_3': 0.00029529713436850745, 'n_units_Layer_1': 120, 'n_units_Layer_2': 50, 'n_units_Layer_3': 290}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 14.58% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:52:44,950]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:52:58,041]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:53:04,716]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:53:09,838]\u001b[0m Trial 1352 finished with value: 1.4748427826066255 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007243920953072916, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09655261749341702, 'dropout_rate_Layer_2': 0.10659340292633701, 'dropout_rate_Layer_3': 0.28246222973978724, 'dropout_rate_Layer_4': 0.08598988663548157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.053788761501173135, 'l1_Layer_2': 3.792155471507047e-05, 'l1_Layer_3': 1.8958917148556713e-05, 'l1_Layer_4': 7.782627915785923e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 190, 'n_units_Layer_3': 165, 'n_units_Layer_4': 195}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.30 | sMAPE for Test Set is: 8.24% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:53:14,863]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:53:35,061]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:54:26,766]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:54:31,723]\u001b[0m Trial 1357 finished with value: 1.5389389831038605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017626750644220692, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27312367168796614, 'dropout_rate_Layer_2': 0.04971756643589312, 'dropout_rate_Layer_3': 0.05164384871505282, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00018416835760952935, 'l1_Layer_2': 0.0023524260962188076, 'l1_Layer_3': 0.001018403890803678, 'n_units_Layer_1': 130, 'n_units_Layer_2': 100, 'n_units_Layer_3': 255}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 16.17% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:54:35,812]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:54:39,096]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:54:43,643]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:54:48,477]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:54:55,796]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:01,515]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:13,193]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:13,763]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:21,671]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:22,285]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:30,634]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:37,850]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:39,877]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:44,759]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:55:54,602]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:04,492]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:09,930]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:10,054]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:19,110]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:25,829]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:35,584]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:40,613]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:41,288]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:50,305]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:52,598]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:57,515]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:56:59,941]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:04,565]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:07,333]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:10,147]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:14,690]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:17,067]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:24,658]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:57:33,802]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:58:24,551]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:58:46,742]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:58:54,275]\u001b[0m Trial 1393 finished with value: 1.4732727315483591 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018206507443020534, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22460344513292088, 'dropout_rate_Layer_2': 0.10503891990801277, 'dropout_rate_Layer_3': 0.09281398114476665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000426493733724662, 'l1_Layer_2': 0.0008281682450370702, 'l1_Layer_3': 0.0016917158668079638, 'n_units_Layer_1': 135, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 15.90% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 14:59:15,865]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:20,804]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:26,012]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:30,375]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:37,510]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:40,604]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:44,851]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:49,864]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:52,718]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 14:59:57,794]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:02,711]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:05,219]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:12,356]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:17,493]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:24,686]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:31,390]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:36,874]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:43,954]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:00:48,802]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:04,095]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:10,628]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:28,659]\u001b[0m Trial 1409 finished with value: 1.4253739044253386 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005551506013721024, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10534557398633411, 'dropout_rate_Layer_2': 0.10604026599478814, 'dropout_rate_Layer_3': 0.25111904669154633, 'dropout_rate_Layer_4': 0.09185897583530862, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04437531369236595, 'l1_Layer_2': 6.867895548632935e-05, 'l1_Layer_3': 1.9010898790483417e-05, 'l1_Layer_4': 5.0243538924773785e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 190, 'n_units_Layer_3': 160, 'n_units_Layer_4': 190}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.87% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.01 | sMAPE for Test Set is: 7.56% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:01:48,012]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:01:55,269]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:02:02,656]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:02:47,205]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:03:22,051]\u001b[0m Trial 1423 finished with value: 1.4181645833091805 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005592855274589398, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07631492446134394, 'dropout_rate_Layer_2': 0.10849008763182545, 'dropout_rate_Layer_3': 0.24769580255124019, 'dropout_rate_Layer_4': 0.1167470560418194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05433366821242616, 'l1_Layer_2': 6.537171691373131e-05, 'l1_Layer_3': 1.929050297275962e-05, 'l1_Layer_4': 0.00010532159042237557, 'n_units_Layer_1': 165, 'n_units_Layer_2': 185, 'n_units_Layer_3': 150, 'n_units_Layer_4': 190}. Best is trial 1137 with value: 1.4136677715809431.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 4.83% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.05 | sMAPE for Test Set is: 7.65% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:03:31,922]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:03:36,627]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:03:54,194]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:03:59,632]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:04:18,308]\u001b[0m Trial 1424 finished with value: 1.3998653407514203 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005575844756400432, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07445832923825053, 'dropout_rate_Layer_2': 0.14107386512427988, 'dropout_rate_Layer_3': 0.24468692187671132, 'dropout_rate_Layer_4': 0.11633769484607828, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.054771753112738755, 'l1_Layer_2': 7.126488442309837e-05, 'l1_Layer_3': 1.8926969743778827e-05, 'l1_Layer_4': 0.00010625809275681996, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 175, 'n_units_Layer_4': 190}. Best is trial 1424 with value: 1.3998653407514203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 4.76% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 2.93 | sMAPE for Test Set is: 7.38% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:04:24,235]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:04:30,921]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:04:38,182]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:04:45,990]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:04:55,853]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:04:59,157]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:04,053]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:08,362]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:11,439]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:23,098]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:33,308]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:35,976]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:40,856]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:45,020]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:52,573]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:05:52,886]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:06,711]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:11,563]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:18,424]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:23,688]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:36,462]\u001b[0m Trial 1447 finished with value: 1.613610585903544 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006531617443923189, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07386449989729313, 'dropout_rate_Layer_2': 0.12002328416831792, 'dropout_rate_Layer_3': 0.22609351078242576, 'dropout_rate_Layer_4': 0.14765794860960602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05267221330941415, 'l1_Layer_2': 2.3106074590324787e-05, 'l1_Layer_3': 1.3147142225656048e-05, 'l1_Layer_4': 0.00012837971940839651, 'n_units_Layer_1': 165, 'n_units_Layer_2': 195, 'n_units_Layer_3': 165, 'n_units_Layer_4': 180}. Best is trial 1424 with value: 1.3998653407514203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.61 | sMAPE for Validation Set is: 5.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 11.17% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:06:40,640]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:43,853]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:06:58,735]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:07:08,158]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:07:13,202]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:07:18,341]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:07:25,224]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:07:30,902]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:07:37,545]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:07:47,649]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:07:59,477]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:05,251]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:14,702]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:19,835]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:27,403]\u001b[0m Trial 1452 finished with value: 1.4726771223522874 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005045452429208986, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09221841252927256, 'dropout_rate_Layer_2': 0.10893285309136207, 'dropout_rate_Layer_3': 0.26715414893413886, 'dropout_rate_Layer_4': 0.09932912786823966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07496394273261017, 'l1_Layer_2': 4.900556979914e-05, 'l1_Layer_3': 1.067604952349927e-05, 'l1_Layer_4': 0.0001615969777138595, 'n_units_Layer_1': 175, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180, 'n_units_Layer_4': 190}. Best is trial 1424 with value: 1.3998653407514203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.06 | sMAPE for Test Set is: 7.72% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:08:31,940]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:34,775]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:39,724]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:45,006]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:51,657]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:08:57,238]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:04,703]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:11,390]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:21,229]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:29,311]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:46,083]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:09:55,628]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:10:03,789]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:10:11,117]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:10:18,342]\u001b[0m Trial 1468 finished with value: 1.4974900625626688 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005034354603804952, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0264873636865084, 'dropout_rate_Layer_2': 0.14061766594782557, 'dropout_rate_Layer_3': 0.2104513545842162, 'dropout_rate_Layer_4': 0.10191157122772945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0683614185588398, 'l1_Layer_2': 4.902629023780267e-05, 'l1_Layer_3': 1.0225860517703131e-05, 'l1_Layer_4': 0.0001561774391252543, 'n_units_Layer_1': 175, 'n_units_Layer_2': 165, 'n_units_Layer_3': 175, 'n_units_Layer_4': 190}. Best is trial 1424 with value: 1.3998653407514203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 2.98 | sMAPE for Test Set is: 7.55% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:10:23,503]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:10:25,890]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:10:59,930]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:10,305]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:15,312]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:30,376]\u001b[0m Trial 1482 finished with value: 1.4794669267984737 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005073573825281767, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02363776378636571, 'dropout_rate_Layer_2': 0.14361942521548599, 'dropout_rate_Layer_3': 0.21694354426770246, 'dropout_rate_Layer_4': 0.2707320647873354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04500533272128065, 'l1_Layer_2': 4.090202142243542e-05, 'l1_Layer_3': 1.0087434070628456e-05, 'l1_Layer_4': 0.00015767062736608324, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180, 'n_units_Layer_4': 165}. Best is trial 1424 with value: 1.3998653407514203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.86 | sMAPE for Test Set is: 7.25% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:11:37,206]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:44,320]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:49,627]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:54,409]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:11:59,516]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:12:04,217]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:12:08,934]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:12:18,778]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:12:28,626]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:12:35,479]\u001b[0m Trial 1493 finished with value: 1.5086990131346205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041185057985775875, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1626955115983299, 'dropout_rate_Layer_2': 0.11027638479859052, 'dropout_rate_Layer_3': 0.0713716456871677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.005984457604574287, 'l1_Layer_2': 0.006339509993291645, 'l1_Layer_3': 9.799714221389911e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 215, 'n_units_Layer_3': 220}. Best is trial 1424 with value: 1.3998653407514203.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 14.52% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 15:12:35,934]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:12:44,722]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:12:47,032]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 15:12:49,850]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-01-01, MAE is:0.60 & sMAPE is:2.30% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :0.60 & 2.30% & 1.80\n",
      "for 2018-01-02, MAE is:5.17 & sMAPE is:16.53% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.88 & 9.42% & 1.35\n",
      "for 2018-01-03, MAE is:1.84 & sMAPE is:5.99% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 8.27% & 1.13\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000235AE6739D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:3.45 & sMAPE is:10.61% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.76 & 8.86% & 1.43\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000235ACCD8E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:1.95 & sMAPE is:6.26% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.60 & 8.34% & 1.30\n",
      "for 2018-01-06, MAE is:1.33 & sMAPE is:4.17% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 7.64% & 1.13\n",
      "for 2018-01-07, MAE is:1.43 & sMAPE is:4.85% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 7.24% & 1.08\n",
      "for 2018-01-08, MAE is:3.44 & sMAPE is:10.19% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 7.61% & 1.02\n",
      "for 2018-01-09, MAE is:0.66 & sMAPE is:2.19% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 7.01% & 0.93\n",
      "for 2018-01-10, MAE is:9.64 & sMAPE is:25.04% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.95 & 8.81% & 0.92\n",
      "for 2018-01-11, MAE is:10.15 & sMAPE is:23.84% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.60 & 10.18% & 0.92\n",
      "for 2018-01-12, MAE is:3.96 & sMAPE is:10.77% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 10.23% & 0.92\n",
      "for 2018-01-13, MAE is:1.33 & sMAPE is:4.22% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 9.77% & 0.98\n",
      "for 2018-01-14, MAE is:1.08 & sMAPE is:3.59% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.29 & 9.33% & 0.98\n",
      "for 2018-01-15, MAE is:1.65 & sMAPE is:5.38% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.18 & 9.06% & 0.94\n",
      "for 2018-01-16, MAE is:2.61 & sMAPE is:7.87% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 8.99% & 0.97\n",
      "for 2018-01-17, MAE is:3.12 & sMAPE is:8.86% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 8.98% & 0.95\n",
      "for 2018-01-18, MAE is:4.22 & sMAPE is:11.67% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 9.13% & 0.92\n",
      "for 2018-01-19, MAE is:6.60 & sMAPE is:16.56% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 9.52% & 0.96\n",
      "for 2018-01-20, MAE is:3.33 & sMAPE is:9.44% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 9.52% & 0.98\n",
      "for 2018-01-21, MAE is:2.57 & sMAPE is:7.11% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 9.40% & 0.97\n",
      "for 2018-01-22, MAE is:7.33 & sMAPE is:18.81% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 9.83% & 0.96\n",
      "for 2018-01-23, MAE is:4.23 & sMAPE is:11.75% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 9.91% & 0.96\n",
      "for 2018-01-24, MAE is:1.19 & sMAPE is:4.09% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.45 & 9.67% & 0.93\n",
      "for 2018-01-25, MAE is:1.73 & sMAPE is:5.87% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 9.52% & 0.91\n",
      "for 2018-01-26, MAE is:2.23 & sMAPE is:7.05% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 9.42% & 0.88\n",
      "for 2018-01-27, MAE is:1.28 & sMAPE is:4.19% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.26 & 9.23% & 0.87\n",
      "for 2018-01-28, MAE is:1.28 & sMAPE is:4.37% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 9.06% & 0.84\n",
      "for 2018-01-29, MAE is:0.87 & sMAPE is:2.93% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :3.11 & 8.85% & 0.82\n",
      "for 2018-01-30, MAE is:2.05 & sMAPE is:6.05% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 8.75% & 0.81\n",
      "for 2018-01-31, MAE is:1.61 & sMAPE is:5.20% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 8.64% & 0.83\n",
      "for 2018-02-01, MAE is:2.23 & sMAPE is:7.49% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 8.60% & 0.86\n",
      "for 2018-02-02, MAE is:4.64 & sMAPE is:13.30% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 8.74% & 0.88\n",
      "for 2018-02-03, MAE is:1.75 & sMAPE is:5.04% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 8.64% & 0.87\n",
      "for 2018-02-04, MAE is:1.96 & sMAPE is:5.67% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 8.55% & 0.85\n",
      "for 2018-02-05, MAE is:10.94 & sMAPE is:25.09% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 9.01% & 0.85\n",
      "for 2018-02-06, MAE is:8.63 & sMAPE is:17.92% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 9.25% & 0.84\n",
      "for 2018-02-07, MAE is:6.80 & sMAPE is:14.24% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 9.38% & 0.83\n",
      "for 2018-02-08, MAE is:5.77 & sMAPE is:13.03% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 9.48% & 0.82\n",
      "for 2018-02-09, MAE is:0.77 & sMAPE is:2.43% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 9.30% & 0.81\n",
      "for 2018-02-10, MAE is:1.09 & sMAPE is:3.43% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 9.16% & 0.80\n",
      "for 2018-02-11, MAE is:1.46 & sMAPE is:4.73% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 9.05% & 0.79\n",
      "for 2018-02-12, MAE is:0.93 & sMAPE is:2.92% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.91% & 0.77\n",
      "for 2018-02-13, MAE is:3.88 & sMAPE is:9.82% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.29 & 8.93% & 0.77\n",
      "for 2018-02-14, MAE is:3.54 & sMAPE is:9.47% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.94% & 0.76\n",
      "for 2018-02-15, MAE is:1.00 & sMAPE is:3.03% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 8.81% & 0.74\n",
      "for 2018-02-16, MAE is:3.45 & sMAPE is:9.52% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 8.83% & 0.75\n",
      "for 2018-02-17, MAE is:3.98 & sMAPE is:10.61% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.27 & 8.86% & 0.75\n",
      "for 2018-02-18, MAE is:2.18 & sMAPE is:5.79% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.24 & 8.80% & 0.74\n",
      "for 2018-02-19, MAE is:4.91 & sMAPE is:11.18% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.85% & 0.73\n",
      "for 2018-02-20, MAE is:6.91 & sMAPE is:15.78% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.99% & 0.74\n",
      "for 2018-02-21, MAE is:2.10 & sMAPE is:4.50% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.90% & 0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-22, MAE is:4.96 & sMAPE is:10.96% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.94% & 0.72\n",
      "for 2018-02-23, MAE is:2.98 & sMAPE is:6.61% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.89% & 0.72\n",
      "for 2018-02-24, MAE is:1.61 & sMAPE is:4.28% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.81% & 0.72\n",
      "for 2018-02-25, MAE is:1.44 & sMAPE is:3.70% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.72% & 0.71\n",
      "for 2018-02-26, MAE is:6.14 & sMAPE is:12.32% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.78% & 0.72\n",
      "for 2018-02-27, MAE is:3.14 & sMAPE is:7.39% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.76% & 0.71\n",
      "for 2018-02-28, MAE is:2.00 & sMAPE is:4.61% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.69% & 0.72\n",
      "for 2018-03-01, MAE is:52.56 & sMAPE is:56.23% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 9.48% & 0.72\n",
      "for 2018-03-02, MAE is:7.04 & sMAPE is:14.79% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 9.57% & 0.73\n",
      "for 2018-03-03, MAE is:2.23 & sMAPE is:5.17% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 9.50% & 0.73\n",
      "for 2018-03-04, MAE is:1.78 & sMAPE is:4.41% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 9.42% & 0.73\n",
      "for 2018-03-05, MAE is:11.98 & sMAPE is:23.05% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 9.63% & 0.74\n",
      "for 2018-03-06, MAE is:4.00 & sMAPE is:7.81% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 9.60% & 0.74\n",
      "for 2018-03-07, MAE is:6.13 & sMAPE is:12.76% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 9.65% & 0.74\n",
      "for 2018-03-08, MAE is:4.71 & sMAPE is:11.05% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 9.67% & 0.73\n",
      "for 2018-03-09, MAE is:3.30 & sMAPE is:8.22% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 9.65% & 0.73\n",
      "for 2018-03-10, MAE is:2.08 & sMAPE is:5.45% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 9.59% & 0.73\n",
      "for 2018-03-11, MAE is:1.20 & sMAPE is:3.39% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 9.50% & 0.72\n",
      "for 2018-03-12, MAE is:5.74 & sMAPE is:13.83% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 9.56% & 0.72\n",
      "for 2018-03-13, MAE is:3.12 & sMAPE is:7.26% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 9.53% & 0.72\n",
      "for 2018-03-14, MAE is:7.14 & sMAPE is:14.72% & rMAE is:4.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 9.60% & 0.77\n",
      "for 2018-03-15, MAE is:5.56 & sMAPE is:11.18% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 9.62% & 0.78\n",
      "for 2018-03-16, MAE is:2.05 & sMAPE is:4.89% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 9.56% & 0.77\n",
      "for 2018-03-17, MAE is:1.65 & sMAPE is:4.26% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 9.49% & 0.78\n",
      "for 2018-03-18, MAE is:1.21 & sMAPE is:3.23% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 9.41% & 0.79\n",
      "for 2018-03-19, MAE is:4.19 & sMAPE is:9.63% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 9.41% & 0.80\n",
      "for 2018-03-20, MAE is:4.42 & sMAPE is:9.83% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 9.42% & 0.82\n",
      "for 2018-03-21, MAE is:1.96 & sMAPE is:4.59% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 9.35% & 0.81\n",
      "for 2018-03-22, MAE is:1.52 & sMAPE is:3.75% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 9.29% & 0.80\n",
      "for 2018-03-23, MAE is:5.01 & sMAPE is:9.99% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 9.29% & 0.80\n",
      "for 2018-03-24, MAE is:1.03 & sMAPE is:2.54% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 9.21% & 0.80\n",
      "for 2018-03-25, MAE is:1.14 & sMAPE is:2.88% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 9.14% & 0.80\n",
      "for 2018-03-26, MAE is:6.64 & sMAPE is:13.81% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 9.19% & 0.80\n",
      "for 2018-03-27, MAE is:3.30 & sMAPE is:6.62% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 9.16% & 0.80\n",
      "for 2018-03-28, MAE is:5.05 & sMAPE is:10.78% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 9.18% & 0.81\n",
      "for 2018-03-29, MAE is:0.92 & sMAPE is:2.25% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 9.10% & 0.81\n",
      "for 2018-03-30, MAE is:0.73 & sMAPE is:1.81% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 9.02% & 0.80\n",
      "for 2018-03-31, MAE is:1.29 & sMAPE is:3.20% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 8.96% & 0.80\n",
      "for 2018-04-01, MAE is:1.10 & sMAPE is:2.85% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.89% & 0.80\n",
      "for 2018-04-02, MAE is:0.75 & sMAPE is:1.89% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 8.81% & 0.80\n",
      "for 2018-04-03, MAE is:2.80 & sMAPE is:6.42% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 8.79% & 0.80\n",
      "for 2018-04-04, MAE is:1.65 & sMAPE is:3.72% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 8.73% & 0.79\n",
      "for 2018-04-05, MAE is:2.73 & sMAPE is:6.28% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 8.71% & 0.80\n",
      "for 2018-04-06, MAE is:1.55 & sMAPE is:3.76% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 8.66% & 0.80\n",
      "for 2018-04-07, MAE is:0.76 & sMAPE is:1.96% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 8.59% & 0.80\n",
      "for 2018-04-08, MAE is:0.99 & sMAPE is:2.55% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 8.52% & 0.81\n",
      "for 2018-04-09, MAE is:3.35 & sMAPE is:7.47% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 8.51% & 0.81\n",
      "for 2018-04-10, MAE is:0.79 & sMAPE is:1.92% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 8.45% & 0.81\n",
      "for 2018-04-11, MAE is:1.66 & sMAPE is:4.07% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 8.40% & 0.81\n",
      "for 2018-04-12, MAE is:1.36 & sMAPE is:3.42% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 8.36% & 0.81\n",
      "for 2018-04-13, MAE is:1.01 & sMAPE is:2.55% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 8.30% & 0.81\n",
      "for 2018-04-14, MAE is:1.87 & sMAPE is:4.86% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 8.27% & 0.82\n",
      "for 2018-04-15, MAE is:1.26 & sMAPE is:3.20% & rMAE is:3.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.61 & 8.22% & 0.84\n",
      "for 2018-04-16, MAE is:4.05 & sMAPE is:9.08% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.62 & 8.23% & 0.86\n",
      "for 2018-04-17, MAE is:1.47 & sMAPE is:3.47% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :3.60 & 8.18% & 0.86\n",
      "for 2018-04-18, MAE is:2.08 & sMAPE is:4.75% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 8.15% & 0.87\n",
      "for 2018-04-19, MAE is:2.47 & sMAPE is:6.17% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.57 & 8.13% & 0.87\n",
      "for 2018-04-20, MAE is:2.13 & sMAPE is:5.87% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 8.11% & 0.87\n",
      "for 2018-04-21, MAE is:4.15 & sMAPE is:12.72% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.57 & 8.15% & 0.86\n",
      "for 2018-04-22, MAE is:1.16 & sMAPE is:3.37% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 8.11% & 0.86\n",
      "for 2018-04-23, MAE is:2.25 & sMAPE is:7.10% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 8.10% & 0.85\n",
      "for 2018-04-24, MAE is:1.51 & sMAPE is:4.61% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 8.07% & 0.85\n",
      "for 2018-04-25, MAE is:1.41 & sMAPE is:3.85% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 8.03% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-26, MAE is:1.36 & sMAPE is:3.73% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 8.00% & 0.84\n",
      "for 2018-04-27, MAE is:1.24 & sMAPE is:3.35% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 7.96% & 0.84\n",
      "for 2018-04-28, MAE is:0.72 & sMAPE is:2.00% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 7.91% & 0.84\n",
      "for 2018-04-29, MAE is:0.50 & sMAPE is:1.42% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 7.85% & 0.83\n",
      "for 2018-04-30, MAE is:3.07 & sMAPE is:9.90% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 7.87% & 0.83\n",
      "for 2018-05-01, MAE is:1.82 & sMAPE is:6.20% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 7.86% & 0.83\n",
      "for 2018-05-02, MAE is:5.82 & sMAPE is:16.90% & rMAE is:5.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 7.93% & 0.87\n",
      "for 2018-05-03, MAE is:1.00 & sMAPE is:2.84% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 7.89% & 0.88\n",
      "for 2018-05-04, MAE is:1.14 & sMAPE is:3.12% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 7.85% & 0.88\n",
      "for 2018-05-05, MAE is:2.68 & sMAPE is:8.39% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 7.85% & 0.88\n",
      "for 2018-05-06, MAE is:6.93 & sMAPE is:27.91% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 8.01% & 0.88\n",
      "for 2018-05-07, MAE is:6.17 & sMAPE is:22.04% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 8.12% & 0.89\n",
      "for 2018-05-08, MAE is:5.22 & sMAPE is:19.66% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 8.21% & 0.89\n",
      "for 2018-05-09, MAE is:5.79 & sMAPE is:27.56% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.45 & 8.36% & 0.88\n",
      "for 2018-05-10, MAE is:7.65 & sMAPE is:58.16% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.49 & 8.75% & 0.88\n",
      "for 2018-05-11, MAE is:13.32 & sMAPE is:68.14% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 9.20% & 0.88\n",
      "for 2018-05-12, MAE is:3.51 & sMAPE is:12.11% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 9.22% & 0.89\n",
      "for 2018-05-13, MAE is:7.19 & sMAPE is:35.41% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 9.42% & 0.89\n",
      "for 2018-05-14, MAE is:12.11 & sMAPE is:42.83% & rMAE is:4.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 9.67% & 0.92\n",
      "for 2018-05-15, MAE is:1.85 & sMAPE is:5.42% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 9.64% & 0.92\n",
      "for 2018-05-16, MAE is:3.34 & sMAPE is:10.12% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 9.64% & 0.91\n",
      "for 2018-05-17, MAE is:8.01 & sMAPE is:35.33% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 9.83% & 0.91\n",
      "for 2018-05-18, MAE is:8.27 & sMAPE is:34.26% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 10.00% & 0.92\n",
      "for 2018-05-19, MAE is:3.10 & sMAPE is:9.28% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 10.00% & 0.92\n",
      "for 2018-05-20, MAE is:6.92 & sMAPE is:25.74% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 10.11% & 0.92\n",
      "for 2018-05-21, MAE is:10.71 & sMAPE is:40.35% & rMAE is:3.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 10.33% & 0.93\n",
      "for 2018-05-22, MAE is:6.77 & sMAPE is:19.12% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 10.39% & 0.94\n",
      "for 2018-05-23, MAE is:2.78 & sMAPE is:7.17% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 10.37% & 0.94\n",
      "for 2018-05-24, MAE is:2.46 & sMAPE is:6.49% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 10.34% & 0.93\n",
      "for 2018-05-25, MAE is:2.68 & sMAPE is:6.97% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 10.32% & 0.93\n",
      "for 2018-05-26, MAE is:1.81 & sMAPE is:4.65% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 10.28% & 0.93\n",
      "for 2018-05-27, MAE is:1.70 & sMAPE is:4.54% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :3.74 & 10.24% & 0.92\n",
      "for 2018-05-28, MAE is:2.88 & sMAPE is:7.61% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 10.22% & 0.92\n",
      "for 2018-05-29, MAE is:2.22 & sMAPE is:5.41% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 10.19% & 0.92\n",
      "for 2018-05-30, MAE is:1.88 & sMAPE is:4.70% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 10.15% & 0.92\n",
      "for 2018-05-31, MAE is:1.34 & sMAPE is:3.17% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 10.11% & 0.91\n",
      "for 2018-06-01, MAE is:1.36 & sMAPE is:3.21% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 10.06% & 0.91\n",
      "for 2018-06-02, MAE is:0.94 & sMAPE is:2.28% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 10.01% & 0.91\n",
      "for 2018-06-03, MAE is:1.48 & sMAPE is:3.49% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 9.97% & 0.90\n",
      "for 2018-06-04, MAE is:3.73 & sMAPE is:9.17% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 9.96% & 0.90\n",
      "for 2018-06-05, MAE is:2.28 & sMAPE is:5.11% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 9.93% & 0.90\n",
      "for 2018-06-06, MAE is:1.91 & sMAPE is:4.15% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 9.89% & 0.90\n",
      "for 2018-06-07, MAE is:2.76 & sMAPE is:5.96% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.62 & 9.87% & 0.90\n",
      "for 2018-06-08, MAE is:2.02 & sMAPE is:4.25% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.61 & 9.83% & 0.89\n",
      "for 2018-06-09, MAE is:0.74 & sMAPE is:1.65% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.60 & 9.78% & 0.89\n",
      "for 2018-06-10, MAE is:1.24 & sMAPE is:2.69% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 9.74% & 0.89\n",
      "for 2018-06-11, MAE is:1.38 & sMAPE is:3.01% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.57 & 9.70% & 0.88\n",
      "for 2018-06-12, MAE is:1.62 & sMAPE is:3.67% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 9.66% & 0.89\n",
      "for 2018-06-13, MAE is:0.75 & sMAPE is:1.65% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 9.61% & 0.89\n",
      "for 2018-06-14, MAE is:0.98 & sMAPE is:2.14% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 9.57% & 0.89\n",
      "for 2018-06-15, MAE is:1.96 & sMAPE is:4.55% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 9.54% & 0.88\n",
      "for 2018-06-16, MAE is:0.91 & sMAPE is:2.09% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 9.49% & 0.88\n",
      "for 2018-06-17, MAE is:1.03 & sMAPE is:2.39% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 9.45% & 0.88\n",
      "for 2018-06-18, MAE is:1.60 & sMAPE is:3.74% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.47 & 9.41% & 0.88\n",
      "for 2018-06-19, MAE is:0.90 & sMAPE is:2.22% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 9.37% & 0.87\n",
      "for 2018-06-20, MAE is:1.38 & sMAPE is:3.22% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 9.34% & 0.87\n",
      "for 2018-06-21, MAE is:1.68 & sMAPE is:3.98% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 9.31% & 0.87\n",
      "for 2018-06-22, MAE is:1.43 & sMAPE is:3.52% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 9.27% & 0.86\n",
      "for 2018-06-23, MAE is:1.41 & sMAPE is:3.52% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 9.24% & 0.86\n",
      "for 2018-06-24, MAE is:2.29 & sMAPE is:5.45% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 9.22% & 0.87\n",
      "for 2018-06-25, MAE is:1.74 & sMAPE is:3.89% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 9.19% & 0.87\n",
      "for 2018-06-26, MAE is:1.97 & sMAPE is:4.32% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 9.16% & 0.87\n",
      "for 2018-06-27, MAE is:2.48 & sMAPE is:5.36% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 9.14% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-28, MAE is:1.94 & sMAPE is:4.19% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 9.11% & 0.86\n",
      "for 2018-06-29, MAE is:2.68 & sMAPE is:5.84% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 9.09% & 0.86\n",
      "for 2018-06-30, MAE is:1.35 & sMAPE is:2.92% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 9.06% & 0.86\n",
      "for 2018-07-01, MAE is:1.23 & sMAPE is:2.70% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 9.02% & 0.85\n",
      "for 2018-07-02, MAE is:3.63 & sMAPE is:7.30% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 9.01% & 0.85\n",
      "for 2018-07-03, MAE is:2.89 & sMAPE is:5.61% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 9.00% & 0.85\n",
      "for 2018-07-04, MAE is:3.26 & sMAPE is:6.05% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.98% & 0.85\n",
      "for 2018-07-05, MAE is:4.04 & sMAPE is:7.23% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.97% & 0.85\n",
      "for 2018-07-06, MAE is:2.40 & sMAPE is:4.75% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.95% & 0.85\n",
      "for 2018-07-07, MAE is:0.76 & sMAPE is:1.63% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.91% & 0.84\n",
      "for 2018-07-08, MAE is:1.92 & sMAPE is:3.97% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.88% & 0.84\n",
      "for 2018-07-09, MAE is:1.86 & sMAPE is:3.63% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.85% & 0.84\n",
      "for 2018-07-10, MAE is:3.68 & sMAPE is:6.92% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.84% & 0.85\n",
      "for 2018-07-11, MAE is:2.14 & sMAPE is:3.99% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.82% & 0.85\n",
      "for 2018-07-12, MAE is:2.41 & sMAPE is:4.46% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.80% & 0.85\n",
      "for 2018-07-13, MAE is:1.33 & sMAPE is:2.48% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.76% & 0.85\n",
      "for 2018-07-14, MAE is:0.83 & sMAPE is:1.59% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.73% & 0.85\n",
      "for 2018-07-15, MAE is:1.32 & sMAPE is:2.54% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.27 & 8.70% & 0.85\n",
      "for 2018-07-16, MAE is:2.46 & sMAPE is:4.56% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.27 & 8.67% & 0.85\n",
      "for 2018-07-17, MAE is:1.84 & sMAPE is:3.46% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.26 & 8.65% & 0.85\n",
      "for 2018-07-18, MAE is:1.37 & sMAPE is:2.68% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 8.62% & 0.85\n",
      "for 2018-07-19, MAE is:2.18 & sMAPE is:4.20% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 8.60% & 0.85\n",
      "for 2018-07-20, MAE is:2.97 & sMAPE is:5.53% & rMAE is:2.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 8.58% & 0.86\n",
      "for 2018-07-21, MAE is:0.79 & sMAPE is:1.49% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 8.55% & 0.86\n",
      "for 2018-07-22, MAE is:1.16 & sMAPE is:2.19% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.22 & 8.51% & 0.86\n",
      "for 2018-07-23, MAE is:2.64 & sMAPE is:4.85% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.22 & 8.50% & 0.87\n",
      "for 2018-07-24, MAE is:2.46 & sMAPE is:4.35% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.22 & 8.48% & 0.87\n",
      "for 2018-07-25, MAE is:1.18 & sMAPE is:2.12% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 8.45% & 0.87\n",
      "for 2018-07-26, MAE is:1.67 & sMAPE is:3.10% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 8.42% & 0.87\n",
      "for 2018-07-27, MAE is:1.14 & sMAPE is:2.19% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 8.39% & 0.87\n",
      "for 2018-07-28, MAE is:1.22 & sMAPE is:2.48% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.18 & 8.36% & 0.87\n",
      "for 2018-07-29, MAE is:1.79 & sMAPE is:3.62% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 8.34% & 0.87\n",
      "for 2018-07-30, MAE is:1.78 & sMAPE is:3.41% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 8.32% & 0.87\n",
      "for 2018-07-31, MAE is:1.07 & sMAPE is:1.95% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.16 & 8.29% & 0.86\n",
      "for 2018-08-01, MAE is:4.03 & sMAPE is:7.14% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.16 & 8.28% & 0.87\n",
      "for 2018-08-02, MAE is:4.74 & sMAPE is:8.13% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 8.28% & 0.87\n",
      "for 2018-08-03, MAE is:3.98 & sMAPE is:6.63% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 8.27% & 0.87\n",
      "for 2018-08-04, MAE is:1.67 & sMAPE is:3.17% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 8.25% & 0.87\n",
      "for 2018-08-05, MAE is:1.60 & sMAPE is:3.22% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.16 & 8.23% & 0.87\n",
      "for 2018-08-06, MAE is:4.48 & sMAPE is:8.14% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.16 & 8.22% & 0.88\n",
      "for 2018-08-07, MAE is:1.41 & sMAPE is:2.61% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.16 & 8.20% & 0.88\n",
      "for 2018-08-08, MAE is:2.56 & sMAPE is:4.98% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.15 & 8.18% & 0.87\n",
      "for 2018-08-09, MAE is:1.89 & sMAPE is:3.71% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.15 & 8.16% & 0.87\n",
      "for 2018-08-10, MAE is:2.08 & sMAPE is:4.58% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 8.15% & 0.87\n",
      "for 2018-08-11, MAE is:1.54 & sMAPE is:3.34% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 8.13% & 0.87\n",
      "for 2018-08-12, MAE is:2.98 & sMAPE is:6.48% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 8.12% & 0.87\n",
      "for 2018-08-13, MAE is:0.86 & sMAPE is:1.79% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 8.09% & 0.86\n",
      "for 2018-08-14, MAE is:0.89 & sMAPE is:1.82% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 8.06% & 0.86\n",
      "for 2018-08-15, MAE is:0.64 & sMAPE is:1.28% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 8.03% & 0.86\n",
      "for 2018-08-16, MAE is:0.82 & sMAPE is:1.64% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.01% & 0.86\n",
      "for 2018-08-17, MAE is:1.42 & sMAPE is:2.84% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 7.98% & 0.85\n",
      "for 2018-08-18, MAE is:1.69 & sMAPE is:3.58% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 7.96% & 0.85\n",
      "for 2018-08-19, MAE is:1.83 & sMAPE is:3.97% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 7.95% & 0.85\n",
      "for 2018-08-20, MAE is:2.24 & sMAPE is:4.54% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 7.93% & 0.86\n",
      "for 2018-08-21, MAE is:1.61 & sMAPE is:3.23% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 7.91% & 0.86\n",
      "for 2018-08-22, MAE is:2.03 & sMAPE is:4.00% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 7.89% & 0.87\n",
      "for 2018-08-23, MAE is:1.69 & sMAPE is:3.44% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 7.88% & 0.87\n",
      "for 2018-08-24, MAE is:1.31 & sMAPE is:2.65% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 7.85% & 0.87\n",
      "for 2018-08-25, MAE is:2.21 & sMAPE is:4.50% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 7.84% & 0.87\n",
      "for 2018-08-26, MAE is:0.93 & sMAPE is:1.86% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 7.81% & 0.87\n",
      "for 2018-08-27, MAE is:1.66 & sMAPE is:3.24% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 7.80% & 0.87\n",
      "for 2018-08-28, MAE is:4.43 & sMAPE is:8.35% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 7.80% & 0.87\n",
      "for 2018-08-29, MAE is:2.89 & sMAPE is:5.30% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 7.79% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-30, MAE is:4.33 & sMAPE is:7.49% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 7.79% & 0.87\n",
      "for 2018-08-31, MAE is:1.47 & sMAPE is:2.61% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 7.76% & 0.86\n",
      "for 2018-09-01, MAE is:1.75 & sMAPE is:3.17% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 7.75% & 0.86\n",
      "for 2018-09-02, MAE is:1.97 & sMAPE is:3.53% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 7.73% & 0.86\n",
      "for 2018-09-03, MAE is:2.35 & sMAPE is:4.05% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 7.71% & 0.86\n",
      "for 2018-09-04, MAE is:1.49 & sMAPE is:2.59% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 7.69% & 0.86\n",
      "for 2018-09-05, MAE is:1.70 & sMAPE is:2.94% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.01 & 7.67% & 0.86\n",
      "for 2018-09-06, MAE is:1.16 & sMAPE is:2.01% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 7.65% & 0.85\n",
      "for 2018-09-07, MAE is:1.36 & sMAPE is:2.43% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 7.63% & 0.86\n",
      "for 2018-09-08, MAE is:1.10 & sMAPE is:2.01% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.61% & 0.85\n",
      "for 2018-09-09, MAE is:1.23 & sMAPE is:2.27% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.59% & 0.85\n",
      "for 2018-09-10, MAE is:1.48 & sMAPE is:2.72% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.57% & 0.85\n",
      "for 2018-09-11, MAE is:2.74 & sMAPE is:5.18% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.56% & 0.85\n",
      "for 2018-09-12, MAE is:1.34 & sMAPE is:2.62% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.54% & 0.85\n",
      "for 2018-09-13, MAE is:1.68 & sMAPE is:3.20% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.52% & 0.84\n",
      "for 2018-09-14, MAE is:1.59 & sMAPE is:3.04% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.50% & 0.84\n",
      "for 2018-09-15, MAE is:2.59 & sMAPE is:5.21% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.50% & 0.84\n",
      "for 2018-09-16, MAE is:3.94 & sMAPE is:8.64% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.50% & 0.84\n",
      "for 2018-09-17, MAE is:2.50 & sMAPE is:5.16% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.49% & 0.84\n",
      "for 2018-09-18, MAE is:4.26 & sMAPE is:9.07% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.50% & 0.84\n",
      "for 2018-09-19, MAE is:1.70 & sMAPE is:3.97% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.48% & 0.84\n",
      "for 2018-09-20, MAE is:3.58 & sMAPE is:8.95% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.49% & 0.83\n",
      "for 2018-09-21, MAE is:7.45 & sMAPE is:22.96% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.55% & 0.83\n",
      "for 2018-09-22, MAE is:7.16 & sMAPE is:47.84% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.70% & 0.83\n",
      "for 2018-09-23, MAE is:9.91 & sMAPE is:33.67% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 7.80% & 0.83\n",
      "for 2018-09-24, MAE is:6.99 & sMAPE is:27.38% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 7.87% & 0.83\n",
      "for 2018-09-25, MAE is:1.67 & sMAPE is:4.46% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 7.86% & 0.83\n",
      "for 2018-09-26, MAE is:7.95 & sMAPE is:31.58% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 7.95% & 0.82\n",
      "for 2018-09-27, MAE is:7.84 & sMAPE is:25.27% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.01% & 0.83\n",
      "for 2018-09-28, MAE is:5.89 & sMAPE is:15.68% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 8.04% & 0.83\n",
      "for 2018-09-29, MAE is:4.80 & sMAPE is:13.45% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 8.06% & 0.83\n",
      "for 2018-09-30, MAE is:6.21 & sMAPE is:18.71% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.10% & 0.83\n",
      "for 2018-10-01, MAE is:4.71 & sMAPE is:11.10% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 8.11% & 0.82\n",
      "for 2018-10-02, MAE is:3.04 & sMAPE is:6.87% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 8.10% & 0.82\n",
      "for 2018-10-03, MAE is:2.04 & sMAPE is:4.59% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 8.09% & 0.82\n",
      "for 2018-10-04, MAE is:3.46 & sMAPE is:7.57% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 8.09% & 0.82\n",
      "for 2018-10-05, MAE is:1.62 & sMAPE is:3.55% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.07% & 0.82\n",
      "for 2018-10-06, MAE is:2.00 & sMAPE is:4.39% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.06% & 0.81\n",
      "for 2018-10-07, MAE is:1.13 & sMAPE is:2.51% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 8.04% & 0.81\n",
      "for 2018-10-08, MAE is:0.89 & sMAPE is:1.93% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.02% & 0.81\n",
      "for 2018-10-09, MAE is:2.04 & sMAPE is:4.70% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.01% & 0.81\n",
      "for 2018-10-10, MAE is:1.18 & sMAPE is:2.78% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 7.99% & 0.81\n",
      "for 2018-10-11, MAE is:2.19 & sMAPE is:5.79% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 7.98% & 0.81\n",
      "for 2018-10-12, MAE is:1.28 & sMAPE is:3.02% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 7.96% & 0.81\n",
      "for 2018-10-13, MAE is:5.95 & sMAPE is:18.04% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 8.00% & 0.81\n",
      "for 2018-10-14, MAE is:12.52 & sMAPE is:70.23% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 8.21% & 0.80\n",
      "for 2018-10-15, MAE is:19.22 & sMAPE is:77.23% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.15 & 8.45% & 0.81\n",
      "for 2018-10-16, MAE is:4.62 & sMAPE is:11.99% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.16 & 8.47% & 0.81\n",
      "for 2018-10-17, MAE is:0.98 & sMAPE is:2.49% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.15 & 8.45% & 0.81\n",
      "for 2018-10-18, MAE is:0.84 & sMAPE is:2.08% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 8.42% & 0.81\n",
      "for 2018-10-19, MAE is:0.99 & sMAPE is:2.52% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 8.40% & 0.81\n",
      "for 2018-10-20, MAE is:1.40 & sMAPE is:3.55% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 8.39% & 0.80\n",
      "for 2018-10-21, MAE is:1.86 & sMAPE is:4.74% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 8.38% & 0.80\n",
      "for 2018-10-22, MAE is:5.02 & sMAPE is:15.17% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 8.40% & 0.80\n",
      "for 2018-10-23, MAE is:4.39 & sMAPE is:15.97% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 8.42% & 0.80\n",
      "for 2018-10-24, MAE is:7.30 & sMAPE is:18.59% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.15 & 8.46% & 0.81\n",
      "for 2018-10-25, MAE is:2.66 & sMAPE is:6.12% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.15 & 8.45% & 0.81\n",
      "for 2018-10-26, MAE is:2.43 & sMAPE is:5.37% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.15 & 8.44% & 0.80\n",
      "for 2018-10-27, MAE is:0.85 & sMAPE is:1.96% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 8.42% & 0.80\n",
      "for 2018-10-28, MAE is:0.90 & sMAPE is:2.05% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 8.40% & 0.80\n",
      "for 2018-10-29, MAE is:1.84 & sMAPE is:4.16% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 8.38% & 0.80\n",
      "for 2018-10-30, MAE is:1.24 & sMAPE is:2.93% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 8.36% & 0.80\n",
      "for 2018-10-31, MAE is:1.87 & sMAPE is:4.42% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 8.35% & 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-11-01, MAE is:2.23 & sMAPE is:5.17% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.11 & 8.34% & 0.80\n",
      "for 2018-11-02, MAE is:1.09 & sMAPE is:2.49% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.11 & 8.32% & 0.80\n",
      "for 2018-11-03, MAE is:1.14 & sMAPE is:2.70% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 8.30% & 0.80\n",
      "for 2018-11-04, MAE is:2.01 & sMAPE is:4.79% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 8.29% & 0.80\n",
      "for 2018-11-05, MAE is:2.18 & sMAPE is:4.95% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.28% & 0.81\n",
      "for 2018-11-06, MAE is:2.90 & sMAPE is:6.26% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.28% & 0.81\n",
      "for 2018-11-07, MAE is:1.15 & sMAPE is:2.54% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.26% & 0.80\n",
      "for 2018-11-08, MAE is:1.38 & sMAPE is:3.04% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 8.24% & 0.80\n",
      "for 2018-11-09, MAE is:1.50 & sMAPE is:3.38% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 8.22% & 0.80\n",
      "for 2018-11-10, MAE is:1.42 & sMAPE is:3.26% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.21% & 0.81\n",
      "for 2018-11-11, MAE is:1.59 & sMAPE is:3.94% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.20% & 0.81\n",
      "for 2018-11-12, MAE is:4.41 & sMAPE is:10.07% & rMAE is:3.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.20% & 0.81\n",
      "for 2018-11-13, MAE is:3.22 & sMAPE is:6.87% & rMAE is:3.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.20% & 0.82\n",
      "for 2018-11-14, MAE is:3.02 & sMAPE is:6.31% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.19% & 0.82\n",
      "for 2018-11-15, MAE is:1.17 & sMAPE is:2.48% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 8.17% & 0.82\n",
      "for 2018-11-16, MAE is:1.39 & sMAPE is:3.01% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 8.16% & 0.83\n",
      "for 2018-11-17, MAE is:1.49 & sMAPE is:3.26% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 8.14% & 0.82\n",
      "for 2018-11-18, MAE is:1.50 & sMAPE is:3.16% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 8.13% & 0.82\n",
      "for 2018-11-19, MAE is:2.74 & sMAPE is:5.75% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 8.12% & 0.82\n",
      "for 2018-11-20, MAE is:1.91 & sMAPE is:3.98% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 8.11% & 0.83\n",
      "for 2018-11-21, MAE is:2.95 & sMAPE is:5.77% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 8.10% & 0.83\n",
      "for 2018-11-22, MAE is:1.70 & sMAPE is:3.27% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 8.08% & 0.83\n",
      "for 2018-11-23, MAE is:2.53 & sMAPE is:4.76% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 8.07% & 0.82\n",
      "for 2018-11-24, MAE is:1.30 & sMAPE is:2.66% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 8.06% & 0.82\n",
      "for 2018-11-25, MAE is:1.53 & sMAPE is:3.18% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 8.04% & 0.82\n",
      "for 2018-11-26, MAE is:15.16 & sMAPE is:22.10% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.09% & 0.82\n",
      "for 2018-11-27, MAE is:10.05 & sMAPE is:14.40% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.10% & 0.82\n",
      "for 2018-11-28, MAE is:3.49 & sMAPE is:6.64% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.10% & 0.82\n",
      "for 2018-11-29, MAE is:1.29 & sMAPE is:2.75% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 8.08% & 0.82\n",
      "for 2018-11-30, MAE is:1.87 & sMAPE is:4.05% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 8.07% & 0.82\n",
      "for 2018-12-01, MAE is:2.28 & sMAPE is:5.05% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 8.06% & 0.82\n",
      "for 2018-12-02, MAE is:0.95 & sMAPE is:2.12% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.05% & 0.82\n",
      "for 2018-12-03, MAE is:2.85 & sMAPE is:6.08% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.04% & 0.82\n",
      "for 2018-12-04, MAE is:1.40 & sMAPE is:2.98% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 8.02% & 0.81\n",
      "for 2018-12-05, MAE is:2.72 & sMAPE is:5.42% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 8.02% & 0.81\n",
      "for 2018-12-06, MAE is:3.77 & sMAPE is:7.26% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.01% & 0.81\n",
      "for 2018-12-07, MAE is:1.92 & sMAPE is:3.94% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 8.00% & 0.81\n",
      "for 2018-12-08, MAE is:1.23 & sMAPE is:2.78% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 7.99% & 0.81\n",
      "for 2018-12-09, MAE is:0.97 & sMAPE is:2.14% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 7.97% & 0.82\n",
      "for 2018-12-10, MAE is:1.95 & sMAPE is:4.11% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 7.96% & 0.82\n",
      "for 2018-12-11, MAE is:3.70 & sMAPE is:7.42% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 7.96% & 0.82\n",
      "for 2018-12-12, MAE is:10.63 & sMAPE is:17.78% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 7.99% & 0.82\n",
      "for 2018-12-13, MAE is:6.08 & sMAPE is:10.05% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 7.99% & 0.82\n",
      "for 2018-12-14, MAE is:6.26 & sMAPE is:10.39% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.00% & 0.82\n",
      "for 2018-12-15, MAE is:2.54 & sMAPE is:4.81% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 7.99% & 0.82\n",
      "for 2018-12-16, MAE is:2.97 & sMAPE is:6.05% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 7.98% & 0.82\n",
      "for 2018-12-17, MAE is:14.19 & sMAPE is:22.20% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 8.02% & 0.82\n",
      "for 2018-12-18, MAE is:7.01 & sMAPE is:11.70% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 8.03% & 0.82\n",
      "for 2018-12-19, MAE is:1.77 & sMAPE is:3.39% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 8.02% & 0.82\n",
      "for 2018-12-20, MAE is:2.06 & sMAPE is:3.87% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 8.01% & 0.82\n",
      "for 2018-12-21, MAE is:1.81 & sMAPE is:3.47% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 8.00% & 0.82\n",
      "for 2018-12-22, MAE is:2.50 & sMAPE is:4.93% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 7.99% & 0.82\n",
      "for 2018-12-23, MAE is:2.42 & sMAPE is:4.54% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 7.98% & 0.82\n",
      "for 2018-12-24, MAE is:3.39 & sMAPE is:6.27% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 7.97% & 0.81\n",
      "for 2018-12-25, MAE is:2.72 & sMAPE is:5.38% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 7.97% & 0.81\n",
      "for 2018-12-26, MAE is:1.80 & sMAPE is:3.63% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.11 & 7.95% & 0.81\n",
      "for 2018-12-27, MAE is:1.46 & sMAPE is:2.86% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.11 & 7.94% & 0.81\n",
      "for 2018-12-28, MAE is:1.92 & sMAPE is:3.60% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 7.93% & 0.81\n",
      "for 2018-12-29, MAE is:2.56 & sMAPE is:4.89% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 7.92% & 0.82\n",
      "for 2018-12-30, MAE is:2.63 & sMAPE is:5.21% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 7.91% & 0.82\n",
      "for 2018-12-31, MAE is:3.51 & sMAPE is:6.66% & rMAE is:2.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 7.91% & 0.82\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 19:54:54,734]\u001b[0m A new study created in RDB with name: NO_1_2019\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:55:45,275]\u001b[0m Trial 1 finished with value: 6.943530022045753 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006508848614135357, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2591310917255529, 'dropout_rate_Layer_2': 0.130029676411447, 'dropout_rate_Layer_3': 0.3876601482446278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0035635318472151617, 'l1_Layer_2': 0.0005507754842618196, 'l1_Layer_3': 0.0030625382802294474, 'n_units_Layer_1': 135, 'n_units_Layer_2': 115, 'n_units_Layer_3': 60}. Best is trial 1 with value: 6.943530022045753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.94 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 1.32\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 11.61% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 19:55:59,999]\u001b[0m Trial 0 finished with value: 8.665889041721266 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023154310403038867, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3753375869418516, 'dropout_rate_Layer_2': 0.2372834731391512, 'dropout_rate_Layer_3': 0.28436829220619014, 'dropout_rate_Layer_4': 0.03281614167856502, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009791879372639981, 'l1_Layer_2': 0.061213124937136126, 'l1_Layer_3': 0.00010457257829314675, 'l1_Layer_4': 0.01511867454736512, 'n_units_Layer_1': 220, 'n_units_Layer_2': 295, 'n_units_Layer_3': 245, 'n_units_Layer_4': 130}. Best is trial 1 with value: 6.943530022045753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.67 | sMAPE for Validation Set is: 20.78% | rMAE for Validation Set is: 1.65\n",
      "MAE for Test Set is: 4.82 | sMAPE for Test Set is: 12.12% | rMAE for Test Set is: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 19:56:29,675]\u001b[0m Trial 2 finished with value: 6.437011340707818 and parameters: {'n_hidden': 4, 'learning_rate': 0.001405423531600474, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003458215924741426, 'dropout_rate_Layer_2': 0.31589900636669593, 'dropout_rate_Layer_3': 0.20939614812160978, 'dropout_rate_Layer_4': 0.3886868681406064, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.7183502996106435e-05, 'l1_Layer_2': 0.00010824849634961078, 'l1_Layer_3': 0.011153047677655644, 'l1_Layer_4': 0.0004889392075996228, 'n_units_Layer_1': 250, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235, 'n_units_Layer_4': 245}. Best is trial 2 with value: 6.437011340707818.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 3.48 | sMAPE for Test Set is: 8.72% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 19:56:39,386]\u001b[0m Trial 3 finished with value: 6.945641835512839 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018916660666139578, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15479535034754682, 'dropout_rate_Layer_2': 0.35071166966384193, 'dropout_rate_Layer_3': 0.1170069460231018, 'dropout_rate_Layer_4': 0.3553299442917096, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.7766128957057906e-05, 'l1_Layer_2': 0.011939481373730706, 'l1_Layer_3': 0.0018304210780467852, 'l1_Layer_4': 0.03850621333263746, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 265, 'n_units_Layer_4': 145}. Best is trial 2 with value: 6.437011340707818.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.95 | sMAPE for Validation Set is: 16.74% | rMAE for Validation Set is: 1.32\n",
      "MAE for Test Set is: 4.08 | sMAPE for Test Set is: 10.42% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 19:56:43,877]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:56:55,914]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:57:01,667]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:57:01,924]\u001b[0m Trial 4 finished with value: 17.148092711198263 and parameters: {'n_hidden': 3, 'learning_rate': 0.001926450708066447, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04662476123121078, 'dropout_rate_Layer_2': 0.15021227582345797, 'dropout_rate_Layer_3': 0.1317588215877423, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.010132079630249476, 'l1_Layer_2': 0.005885328566001222, 'l1_Layer_3': 0.05424807033152545, 'n_units_Layer_1': 295, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140}. Best is trial 2 with value: 6.437011340707818.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.15 | sMAPE for Validation Set is: 46.25% | rMAE for Validation Set is: 3.27\n",
      "MAE for Test Set is: 12.02 | sMAPE for Test Set is: 34.37% | rMAE for Test Set is: 3.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 19:57:06,794]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:57:31,090]\u001b[0m Trial 10 finished with value: 5.3330982621066845 and parameters: {'n_hidden': 3, 'learning_rate': 0.06333378415689274, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21760956603280965, 'dropout_rate_Layer_2': 0.21158862508635648, 'dropout_rate_Layer_3': 0.32639544267685605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0030256503247275838, 'l1_Layer_2': 0.0003075541111006014, 'l1_Layer_3': 0.000655132519622874, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290}. Best is trial 10 with value: 5.3330982621066845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 12.92% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 3.62 | sMAPE for Test Set is: 9.17% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 19:57:35,477]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:57:38,829]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:57:43,576]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:57:50,187]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:57:56,072]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:58:03,189]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:58:20,152]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:58:25,301]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:58:32,384]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:58:35,392]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:58:40,082]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:58:44,968]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:58:52,045]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:59:09,474]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 19:59:35,077]\u001b[0m Trial 9 finished with value: 6.423332143003049 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015073605127253974, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3734064004095903, 'dropout_rate_Layer_2': 0.2338061343005825, 'dropout_rate_Layer_3': 0.2896633410988404, 'dropout_rate_Layer_4': 0.2206652965724567, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.002517915420691045, 'l1_Layer_2': 0.04314621036188439, 'l1_Layer_3': 0.001112037082317803, 'l1_Layer_4': 7.925309839151107e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260, 'n_units_Layer_4': 240}. Best is trial 10 with value: 5.3330982621066845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 15.38% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 3.53 | sMAPE for Test Set is: 8.79% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 19:59:57,149]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:00:06,877]\u001b[0m Trial 25 finished with value: 5.932419123907107 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009690128912483674, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25330084223566707, 'dropout_rate_Layer_2': 0.1680609183875173, 'dropout_rate_Layer_3': 0.36073481908040894, 'dropout_rate_Layer_4': 0.18224630493599842, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.021656388995390456, 'l1_Layer_2': 6.202064088103522e-05, 'l1_Layer_3': 0.005762478722019309, 'l1_Layer_4': 0.003720610185140389, 'n_units_Layer_1': 65, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260, 'n_units_Layer_4': 125}. Best is trial 10 with value: 5.3330982621066845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 14.02% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 3.25 | sMAPE for Test Set is: 8.07% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:00:12,241]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:00:16,819]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:00:19,304]\u001b[0m Trial 27 finished with value: 7.286977094618304 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027140724588889734, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3443914662427317, 'dropout_rate_Layer_2': 0.27378182793426004, 'dropout_rate_Layer_3': 0.13466028573730074, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006560590469523977, 'l1_Layer_2': 8.83607138025845e-05, 'l1_Layer_3': 0.0005024853546289378, 'n_units_Layer_1': 230, 'n_units_Layer_2': 95, 'n_units_Layer_3': 220}. Best is trial 10 with value: 5.3330982621066845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 1.39\n",
      "MAE for Test Set is: 3.77 | sMAPE for Test Set is: 9.28% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:00:21,657]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:00:24,187]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:00:28,484]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:00:35,945]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:00:41,602]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:00:44,231]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:00:55,590]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:01:03,117]\u001b[0m Trial 35 finished with value: 7.978122301936371 and parameters: {'n_hidden': 3, 'learning_rate': 0.004484088640835219, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3417489061310573, 'dropout_rate_Layer_2': 0.26422071606210856, 'dropout_rate_Layer_3': 0.08105632596251713, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005321530288726997, 'l1_Layer_2': 0.0003701505359119378, 'l1_Layer_3': 0.0007095508660828984, 'n_units_Layer_1': 145, 'n_units_Layer_2': 95, 'n_units_Layer_3': 210}. Best is trial 10 with value: 5.3330982621066845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.98 | sMAPE for Validation Set is: 18.94% | rMAE for Validation Set is: 1.52\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 10.58% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:01:07,488]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:01:12,353]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:01:17,625]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:01:20,387]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:01:32,004]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:01:34,276]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:01:37,258]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:01:42,156]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:01:42,402]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:01:47,793]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:01:47,950]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:02:02,634]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:02:02,684]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:02:08,769]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:02:13,180]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:02:30,138]\u001b[0m Trial 53 finished with value: 5.743602375469173 and parameters: {'n_hidden': 3, 'learning_rate': 0.014343144428585653, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24710255992466593, 'dropout_rate_Layer_2': 0.27183177256759755, 'dropout_rate_Layer_3': 0.20891048985893174, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011684852579290863, 'l1_Layer_2': 2.2671591040463787e-05, 'l1_Layer_3': 0.0011334362828401185, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 235}. Best is trial 10 with value: 5.3330982621066845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 13.67% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 4.13 | sMAPE for Test Set is: 10.36% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:02:35,233]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:02:42,946]\u001b[0m Trial 54 finished with value: 4.669414827268661 and parameters: {'n_hidden': 3, 'learning_rate': 0.013154118173570283, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23874155613430043, 'dropout_rate_Layer_2': 0.28700833640389845, 'dropout_rate_Layer_3': 0.2082574185908957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012520931830808676, 'l1_Layer_2': 0.0033878720679406593, 'l1_Layer_3': 0.0009801192913791753, 'n_units_Layer_1': 80, 'n_units_Layer_2': 130, 'n_units_Layer_3': 235}. Best is trial 54 with value: 4.669414827268661.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 11.10% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 3.36 | sMAPE for Test Set is: 8.49% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:02:47,555]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:02:50,268]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:02:52,199]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:03:09,498]\u001b[0m Trial 59 finished with value: 5.272768485932377 and parameters: {'n_hidden': 3, 'learning_rate': 0.022067952028859243, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09957447787222326, 'dropout_rate_Layer_2': 0.07949740865178045, 'dropout_rate_Layer_3': 0.2462864627299818, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022538788380027124, 'l1_Layer_2': 0.0003199088423276798, 'l1_Layer_3': 0.0008656944187804906, 'n_units_Layer_1': 250, 'n_units_Layer_2': 200, 'n_units_Layer_3': 225}. Best is trial 54 with value: 4.669414827268661.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 16.78% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:03:14,161]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:03:34,173]\u001b[0m Trial 62 finished with value: 5.762022931189512 and parameters: {'n_hidden': 3, 'learning_rate': 0.013011635283290045, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23819609094309213, 'dropout_rate_Layer_2': 0.09074801166570824, 'dropout_rate_Layer_3': 0.30475656652460237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.019198797458242368, 'l1_Layer_2': 0.01608377721269948, 'l1_Layer_3': 0.0019074884761927464, 'n_units_Layer_1': 65, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 54 with value: 4.669414827268661.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 13.59% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 3.11 | sMAPE for Test Set is: 7.77% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:03:58,439]\u001b[0m Trial 63 finished with value: 6.728882742354325 and parameters: {'n_hidden': 3, 'learning_rate': 0.013458053629149466, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22948291642732765, 'dropout_rate_Layer_2': 0.09205392998413842, 'dropout_rate_Layer_3': 0.2970291381046253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015954611552590224, 'l1_Layer_2': 0.027018981182554788, 'l1_Layer_3': 0.002191489852379647, 'n_units_Layer_1': 65, 'n_units_Layer_2': 155, 'n_units_Layer_3': 285}. Best is trial 54 with value: 4.669414827268661.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.73 | sMAPE for Validation Set is: 15.85% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 3.69 | sMAPE for Test Set is: 9.17% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:04:02,993]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:04:10,532]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:04:27,689]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:04:32,758]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:04:50,555]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:05:03,129]\u001b[0m Trial 69 finished with value: 5.03093255546506 and parameters: {'n_hidden': 3, 'learning_rate': 0.018958166773426842, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10734614514754784, 'dropout_rate_Layer_2': 0.10869007522402042, 'dropout_rate_Layer_3': 0.1358378172502272, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001737740577186678, 'l1_Layer_2': 0.0003636002067786675, 'l1_Layer_3': 0.0015186876612978749, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210}. Best is trial 54 with value: 4.669414827268661.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 11.96% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 3.55 | sMAPE for Test Set is: 8.88% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:05:05,688]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:05:08,069]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:05:14,902]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:05:27,796]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:05:33,015]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:05:34,913]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:05:47,304]\u001b[0m Trial 75 finished with value: 4.834132401405989 and parameters: {'n_hidden': 3, 'learning_rate': 0.014821909883353121, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10008424912088053, 'dropout_rate_Layer_2': 0.11046572927581072, 'dropout_rate_Layer_3': 0.09894849517067787, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002268533632832207, 'l1_Layer_2': 0.000464383051297258, 'l1_Layer_3': 0.0011493457597472295, 'n_units_Layer_1': 235, 'n_units_Layer_2': 215, 'n_units_Layer_3': 200}. Best is trial 54 with value: 4.669414827268661.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 9.90% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:05:52,752]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:05:55,424]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:05:59,527]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:04,419]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:09,107]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:14,771]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:19,335]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:19,525]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:25,257]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:25,395]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:30,400]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:32,399]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:34,425]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:44,211]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:47,403]\u001b[0m Trial 89 finished with value: 4.023567580368709 and parameters: {'n_hidden': 3, 'learning_rate': 0.045563575075224454, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06910517949695769, 'dropout_rate_Layer_2': 0.13447121451434052, 'dropout_rate_Layer_3': 0.07477048773454206, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.699487180178134e-05, 'l1_Layer_2': 0.0006643562462484153, 'l1_Layer_3': 7.902617137577219e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 245, 'n_units_Layer_3': 160}. Best is trial 89 with value: 4.023567580368709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 9.78% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 3.29 | sMAPE for Test Set is: 8.23% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:06:51,507]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:54,143]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:57,237]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:06:59,321]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:07:03,372]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:07:06,223]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:07:08,937]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:07:11,566]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:07:15,649]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:07:52,760]\u001b[0m Trial 101 finished with value: 5.487588753074242 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027990827109054617, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3948625531026895, 'dropout_rate_Layer_2': 0.1534922616607607, 'dropout_rate_Layer_3': 0.19937932285260854, 'dropout_rate_Layer_4': 0.2146577889907848, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0002891225948374464, 'l1_Layer_2': 8.751181879863082e-05, 'l1_Layer_3': 2.928683502717758e-05, 'l1_Layer_4': 0.014876675255887862, 'n_units_Layer_1': 110, 'n_units_Layer_2': 165, 'n_units_Layer_3': 175, 'n_units_Layer_4': 290}. Best is trial 89 with value: 4.023567580368709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 13.34% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 11.73% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:07:55,591]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:07:59,789]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:08:09,520]\u001b[0m Trial 100 finished with value: 3.8273318256079825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007902142764421111, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05659091311545553, 'dropout_rate_Layer_2': 0.24992569452635938, 'dropout_rate_Layer_3': 0.37095409757133185, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00641379610582883, 'l1_Layer_2': 4.6334506594056805e-05, 'l1_Layer_3': 0.0005757171803991724, 'n_units_Layer_1': 270, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170}. Best is trial 100 with value: 3.8273318256079825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 9.28% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 2.49 | sMAPE for Test Set is: 6.37% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:08:12,778]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:08:20,173]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:08:24,637]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:08:31,826]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:08:34,565]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:08:56,538]\u001b[0m Trial 110 finished with value: 4.168871191058524 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008046951778362266, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.060464641973046046, 'dropout_rate_Layer_2': 0.2850937355914396, 'dropout_rate_Layer_3': 0.3903173559930557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012403972647069965, 'l1_Layer_2': 5.261962920062169e-05, 'l1_Layer_3': 0.0009527581065991162, 'n_units_Layer_1': 175, 'n_units_Layer_2': 265, 'n_units_Layer_3': 300}. Best is trial 100 with value: 3.8273318256079825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 9.99% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 2.44 | sMAPE for Test Set is: 6.19% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:09:18,916]\u001b[0m Trial 111 finished with value: 3.6187240062568002 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019062934619947624, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.050701376486139565, 'dropout_rate_Layer_2': 0.2895011025049708, 'dropout_rate_Layer_3': 0.3886214423638602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04506237753030715, 'l1_Layer_2': 6.756166009700599e-05, 'l1_Layer_3': 0.0009458956107373028, 'n_units_Layer_1': 210, 'n_units_Layer_2': 275, 'n_units_Layer_3': 155}. Best is trial 111 with value: 3.6187240062568002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 8.83% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 2.61 | sMAPE for Test Set is: 6.72% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:09:27,908]\u001b[0m Trial 109 finished with value: 4.5430336022066236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007198788676755827, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0009264982716317843, 'dropout_rate_Layer_2': 0.287531301156274, 'dropout_rate_Layer_3': 0.38082382838694867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014190360666834658, 'l1_Layer_2': 3.754735850314699e-05, 'l1_Layer_3': 0.000958717870147343, 'n_units_Layer_1': 175, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300}. Best is trial 111 with value: 3.6187240062568002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 10.80% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 2.56 | sMAPE for Test Set is: 6.45% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:09:59,577]\u001b[0m Trial 113 finished with value: 3.972067099860705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018207946944705914, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04241564833548038, 'dropout_rate_Layer_2': 0.2908587728314573, 'dropout_rate_Layer_3': 0.3779484478746122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.043878950348956836, 'l1_Layer_2': 4.170752242385423e-05, 'l1_Layer_3': 0.0009304203808981177, 'n_units_Layer_1': 210, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 111 with value: 3.6187240062568002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 9.54% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 2.50 | sMAPE for Test Set is: 6.38% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:10:07,149]\u001b[0m Trial 112 finished with value: 3.506918949246185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007661835007262953, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04692090825308924, 'dropout_rate_Layer_2': 0.2871296400600906, 'dropout_rate_Layer_3': 0.38391549325589797, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.044440257582473656, 'l1_Layer_2': 4.4506128363519565e-05, 'l1_Layer_3': 0.0009371137313702788, 'n_units_Layer_1': 210, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155}. Best is trial 112 with value: 3.506918949246185.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.51 | sMAPE for Validation Set is: 8.61% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 2.72 | sMAPE for Test Set is: 7.02% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:10:11,954]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:10:17,333]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:10:39,145]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:10:48,631]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:10:58,733]\u001b[0m Trial 114 finished with value: 3.4985452154450805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007640863648546869, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0001309713437807336, 'dropout_rate_Layer_2': 0.28451012553906413, 'dropout_rate_Layer_3': 0.38414674032728324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.044604410764407056, 'l1_Layer_2': 4.360273837106544e-05, 'l1_Layer_3': 0.0008190008190091735, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140}. Best is trial 114 with value: 3.4985452154450805.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 8.57% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 2.51 | sMAPE for Test Set is: 6.46% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:11:25,822]\u001b[0m Trial 119 finished with value: 3.6016476276422567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007900132288925463, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00430447296151501, 'dropout_rate_Layer_2': 0.29352889247686, 'dropout_rate_Layer_3': 0.3869676993246634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07562397179396668, 'l1_Layer_2': 3.74291505900084e-05, 'l1_Layer_3': 0.0008300600057481117, 'n_units_Layer_1': 210, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180}. Best is trial 114 with value: 3.4985452154450805.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 8.76% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 2.27 | sMAPE for Test Set is: 5.84% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:11:33,754]\u001b[0m Trial 120 finished with value: 3.6733863945469074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006207069886296803, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.001432649667981007, 'dropout_rate_Layer_2': 0.29674527140145873, 'dropout_rate_Layer_3': 0.3876098831382693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04539647428837549, 'l1_Layer_2': 3.5529651593728956e-05, 'l1_Layer_3': 0.0008784133873280633, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 160}. Best is trial 114 with value: 3.4985452154450805.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 8.92% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 2.29 | sMAPE for Test Set is: 5.88% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:11:40,545]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:12:34,325]\u001b[0m Trial 121 finished with value: 3.296495099467272 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007593014897030223, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006794339419625706, 'dropout_rate_Layer_2': 0.30275285312739925, 'dropout_rate_Layer_3': 0.38926918021161555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07257618815575816, 'l1_Layer_2': 3.772815068418861e-05, 'l1_Layer_3': 0.0004131956934882832, 'n_units_Layer_1': 210, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160}. Best is trial 121 with value: 3.296495099467272.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.30 | sMAPE for Validation Set is: 8.18% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.49 | sMAPE for Test Set is: 6.46% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:12:44,196]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:12:56,398]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:12:59,433]\u001b[0m Trial 125 finished with value: 4.33164398053061 and parameters: {'n_hidden': 3, 'learning_rate': 0.004754621519473916, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08525320985553998, 'dropout_rate_Layer_2': 0.1294702715228589, 'dropout_rate_Layer_3': 0.1569999044989454, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2346921232817558e-05, 'l1_Layer_2': 0.0010412318182238083, 'l1_Layer_3': 6.97439318190735e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160}. Best is trial 121 with value: 3.296495099467272.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 10.45% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 3.35 | sMAPE for Test Set is: 8.54% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:13:06,675]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:13:50,925]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:14:00,609]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:14:02,778]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:14:05,299]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:14:07,518]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:14:10,593]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:14:15,445]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:14:24,558]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:14:36,844]\u001b[0m Trial 133 finished with value: 3.750777472908048 and parameters: {'n_hidden': 3, 'learning_rate': 0.0944741499340895, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11653429795571793, 'dropout_rate_Layer_2': 0.02882720201848693, 'dropout_rate_Layer_3': 0.29979783741977895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019884941533913577, 'l1_Layer_2': 0.000606667246641792, 'l1_Layer_3': 0.0002709804280846297, 'n_units_Layer_1': 250, 'n_units_Layer_2': 120, 'n_units_Layer_3': 300}. Best is trial 121 with value: 3.296495099467272.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 9.26% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 2.76 | sMAPE for Test Set is: 7.20% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:14:57,289]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:14:59,952]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:15:12,170]\u001b[0m Trial 136 finished with value: 3.5799589560418155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014865164049418398, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01764808647414124, 'dropout_rate_Layer_2': 0.29860445189104545, 'dropout_rate_Layer_3': 0.359656682665666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03285445413023566, 'l1_Layer_2': 5.36461548031467e-05, 'l1_Layer_3': 0.0004798934482956815, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160}. Best is trial 121 with value: 3.296495099467272.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 8.75% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 2.63 | sMAPE for Test Set is: 6.78% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:15:27,052]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:15:51,071]\u001b[0m Trial 141 finished with value: 3.7059506186515487 and parameters: {'n_hidden': 3, 'learning_rate': 0.09582004257494511, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12653036068700244, 'dropout_rate_Layer_2': 0.03654782979644805, 'dropout_rate_Layer_3': 0.2991276553594948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019064050757972518, 'l1_Layer_2': 0.0007760105753985521, 'l1_Layer_3': 0.00024814684957123897, 'n_units_Layer_1': 245, 'n_units_Layer_2': 110, 'n_units_Layer_3': 300}. Best is trial 121 with value: 3.296495099467272.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 9.11% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 2.57 | sMAPE for Test Set is: 6.69% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:16:12,885]\u001b[0m Trial 140 finished with value: 3.3806783728981373 and parameters: {'n_hidden': 3, 'learning_rate': 0.001399868936185019, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03382210633449516, 'dropout_rate_Layer_2': 0.2994431839781651, 'dropout_rate_Layer_3': 0.377209950468719, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04110128646818608, 'l1_Layer_2': 1.9647344163977357e-05, 'l1_Layer_3': 8.910862844246681e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 290, 'n_units_Layer_3': 130}. Best is trial 121 with value: 3.296495099467272.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.38 | sMAPE for Validation Set is: 8.38% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.64 | sMAPE for Test Set is: 6.79% | rMAE for Test Set is: 0.79\n",
      "MAE for Validation Set is: 3.21 | sMAPE for Validation Set is: 8.02% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.54 | sMAPE for Test Set is: 6.58% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:17:08,618]\u001b[0m Trial 142 finished with value: 3.206935439198599 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013846260666369645, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010845460324108047, 'dropout_rate_Layer_2': 0.29461917485533473, 'dropout_rate_Layer_3': 0.3759456533792403, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04424299410772978, 'l1_Layer_2': 1.8847304632286828e-05, 'l1_Layer_3': 9.445396660047028e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 175}. Best is trial 142 with value: 3.206935439198599.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:17:21,102]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:17:31,136]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:18:01,447]\u001b[0m Trial 146 finished with value: 3.5056751707989853 and parameters: {'n_hidden': 3, 'learning_rate': 0.03151398776387411, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10968383743910051, 'dropout_rate_Layer_2': 0.01679432241923234, 'dropout_rate_Layer_3': 0.29080027902540834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001020277646402238, 'l1_Layer_2': 0.0006793823047503406, 'l1_Layer_3': 0.00012931417870195113, 'n_units_Layer_1': 215, 'n_units_Layer_2': 125, 'n_units_Layer_3': 300}. Best is trial 142 with value: 3.206935439198599.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.51 | sMAPE for Validation Set is: 8.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 2.82 | sMAPE for Test Set is: 7.41% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:18:10,971]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:18:22,893]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:18:38,190]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:18:40,848]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:19:04,737]\u001b[0m Trial 151 finished with value: 4.445374088287354 and parameters: {'n_hidden': 3, 'learning_rate': 0.01453238865817204, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10217915614373789, 'dropout_rate_Layer_2': 0.10552877763400051, 'dropout_rate_Layer_3': 0.0007660560997188454, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.07463156490838e-05, 'l1_Layer_2': 0.00012574986753130383, 'l1_Layer_3': 0.0067687602056849165, 'n_units_Layer_1': 250, 'n_units_Layer_2': 215, 'n_units_Layer_3': 190}. Best is trial 142 with value: 3.206935439198599.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 10.72% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 3.75 | sMAPE for Test Set is: 9.51% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:19:27,287]\u001b[0m Trial 145 finished with value: 3.2726355465208794 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013466663639058831, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013751372565112248, 'dropout_rate_Layer_2': 0.3678285406034536, 'dropout_rate_Layer_3': 0.3601284824683628, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03707771441270357, 'l1_Layer_2': 1.5311255972652372e-05, 'l1_Layer_3': 2.5934716418450432e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 142 with value: 3.206935439198599.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.27 | sMAPE for Validation Set is: 8.13% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.50 | sMAPE for Test Set is: 6.46% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:19:58,769]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:20:08,926]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:21:10,699]\u001b[0m Trial 155 finished with value: 3.1908104923450744 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012848526831374556, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006687985743868613, 'dropout_rate_Layer_2': 0.34690403287049276, 'dropout_rate_Layer_3': 0.3920920667639113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06782169652002457, 'l1_Layer_2': 5.7216355540209486e-05, 'l1_Layer_3': 0.00010534943822237359, 'n_units_Layer_1': 225, 'n_units_Layer_2': 285, 'n_units_Layer_3': 135}. Best is trial 155 with value: 3.1908104923450744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.19 | sMAPE for Validation Set is: 8.00% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.62 | sMAPE for Test Set is: 6.77% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:21:13,395]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:21:17,441]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:21:39,394]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:22:07,081]\u001b[0m Trial 152 finished with value: 3.82628396354796 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014033169240152499, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2537574559458171, 'dropout_rate_Layer_2': 0.25240241268205765, 'dropout_rate_Layer_3': 0.01709113050840458, 'dropout_rate_Layer_4': 0.225463225892566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017812300645329263, 'l1_Layer_2': 0.015835836866830877, 'l1_Layer_3': 0.013993422073952884, 'l1_Layer_4': 0.007075754928260986, 'n_units_Layer_1': 125, 'n_units_Layer_2': 90, 'n_units_Layer_3': 155, 'n_units_Layer_4': 230}. Best is trial 155 with value: 3.1908104923450744.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 9.33% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 2.67 | sMAPE for Test Set is: 6.84% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:22:12,158]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:22:16,903]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:22:22,072]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:22:22,278]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:23:14,099]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:23:21,150]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:23:25,593]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.26 | sMAPE for Validation Set is: 8.13% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.61 | sMAPE for Test Set is: 6.74% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:24:52,526]\u001b[0m Trial 167 finished with value: 3.258205714980539 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014049454388181091, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007457638566429412, 'dropout_rate_Layer_2': 0.26517643718178874, 'dropout_rate_Layer_3': 0.3993474459835928, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08242967776420322, 'l1_Layer_2': 8.057835839340091e-05, 'l1_Layer_3': 0.0002022591866421052, 'n_units_Layer_1': 245, 'n_units_Layer_2': 270, 'n_units_Layer_3': 110}. Best is trial 155 with value: 3.1908104923450744.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:24:56,811]\u001b[0m Trial 164 finished with value: 2.961376707265275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011449424917053886, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3945756250419448, 'dropout_rate_Layer_2': 0.16146676246676755, 'dropout_rate_Layer_3': 0.33936761520984293, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012143595549102195, 'l1_Layer_2': 0.00036058888078929324, 'l1_Layer_3': 0.05448361673243939, 'n_units_Layer_1': 110, 'n_units_Layer_2': 250, 'n_units_Layer_3': 110}. Best is trial 164 with value: 2.961376707265275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.96 | sMAPE for Validation Set is: 7.52% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.09 | sMAPE for Test Set is: 5.51% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:25:11,662]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:26:16,267]\u001b[0m Trial 170 finished with value: 3.024260180329477 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009271504317176655, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31543032477933597, 'dropout_rate_Layer_2': 0.10266434466710883, 'dropout_rate_Layer_3': 0.396972150059018, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00034787037601111977, 'l1_Layer_2': 7.167270380947788e-05, 'l1_Layer_3': 0.031523210789130104, 'n_units_Layer_1': 50, 'n_units_Layer_2': 200, 'n_units_Layer_3': 110}. Best is trial 164 with value: 2.961376707265275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.02 | sMAPE for Validation Set is: 7.67% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.01 | sMAPE for Test Set is: 5.31% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:26:48,075]\u001b[0m Trial 169 finished with value: 3.2710710287360505 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013510414244187385, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007618370407915298, 'dropout_rate_Layer_2': 0.30709886779934703, 'dropout_rate_Layer_3': 0.35399931980775406, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0984343957880276, 'l1_Layer_2': 1.0386109140035415e-05, 'l1_Layer_3': 0.00020802811547976173, 'n_units_Layer_1': 260, 'n_units_Layer_2': 250, 'n_units_Layer_3': 110}. Best is trial 164 with value: 2.961376707265275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.27 | sMAPE for Validation Set is: 8.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.58 | sMAPE for Test Set is: 6.67% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:27:05,792]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:27:12,479]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:27:33,071]\u001b[0m Trial 174 finished with value: 3.0903895658976097 and parameters: {'n_hidden': 3, 'learning_rate': 0.005749836467269637, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1386510291878043, 'dropout_rate_Layer_2': 0.16768766714679476, 'dropout_rate_Layer_3': 0.00626291035571859, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8284903161932706e-05, 'l1_Layer_2': 2.1567333622980217e-05, 'l1_Layer_3': 0.03873173518191092, 'n_units_Layer_1': 235, 'n_units_Layer_2': 265, 'n_units_Layer_3': 230}. Best is trial 164 with value: 2.961376707265275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.09 | sMAPE for Validation Set is: 7.84% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.27 | sMAPE for Test Set is: 6.14% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:27:47,203]\u001b[0m Trial 172 finished with value: 3.383300673095873 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015590735764011757, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030695185372643062, 'dropout_rate_Layer_2': 0.278023173799682, 'dropout_rate_Layer_3': 0.3994210308311952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07582623489675412, 'l1_Layer_2': 1.3859274045747315e-05, 'l1_Layer_3': 0.00010524276166856033, 'n_units_Layer_1': 240, 'n_units_Layer_2': 270, 'n_units_Layer_3': 110}. Best is trial 164 with value: 2.961376707265275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.38 | sMAPE for Validation Set is: 8.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.69 | sMAPE for Test Set is: 6.94% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:27:52,564]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:28:35,520]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:28:42,906]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:28:55,527]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:29:00,649]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:29:20,266]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:29:25,217]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:29:44,430]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:29:47,494]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:29:51,586]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:29:57,537]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:30:04,531]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:30:09,265]\u001b[0m Trial 177 finished with value: 2.957272523333019 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008089663509191345, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3172210796864233, 'dropout_rate_Layer_2': 0.07942030806883482, 'dropout_rate_Layer_3': 0.3924493038943667, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00036808768635978353, 'l1_Layer_2': 6.89971515019624e-05, 'l1_Layer_3': 0.030760835525312207, 'n_units_Layer_1': 55, 'n_units_Layer_2': 195, 'n_units_Layer_3': 105}. Best is trial 177 with value: 2.957272523333019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.96 | sMAPE for Validation Set is: 7.49% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.02 | sMAPE for Test Set is: 5.32% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:30:11,503]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:30:16,397]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:30:22,040]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:31:05,693]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:31:10,802]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:31:15,599]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:31:20,320]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:31:23,296]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:31:26,167]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:31:30,151]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:31:37,629]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:31:40,518]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:31:55,301]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:32:02,327]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:32:12,139]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:32:15,184]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:32:17,299]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:32:20,021]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:32:24,110]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:32:29,486]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:32:34,476]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:32:37,445]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:32:43,935]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:33:04,294]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:33:08,631]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:33:23,445]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:33:28,346]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:33:31,352]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:33:36,174]\u001b[0m Trial 214 finished with value: 5.73466601757142 and parameters: {'n_hidden': 3, 'learning_rate': 0.03202504671845489, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12413199789345475, 'dropout_rate_Layer_2': 0.06856847801299236, 'dropout_rate_Layer_3': 0.2827994326435542, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.027645060382400357, 'l1_Layer_2': 2.9422285190878065e-05, 'l1_Layer_3': 0.007611249452909154, 'n_units_Layer_1': 300, 'n_units_Layer_2': 135, 'n_units_Layer_3': 265}. Best is trial 177 with value: 2.957272523333019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 3.61 | sMAPE for Test Set is: 9.34% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:33:40,940]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:33:50,610]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:33:57,891]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:34:03,511]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:34:29,939]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:34:35,113]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:34:39,748]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.03 | sMAPE for Validation Set is: 7.70% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.08 | sMAPE for Test Set is: 5.51% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:34:54,472]\u001b[0m Trial 222 finished with value: 3.0283455653341567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010242901928881564, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39559459035903555, 'dropout_rate_Layer_2': 0.013962993785314945, 'dropout_rate_Layer_3': 0.36718561956352047, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007674964959574177, 'l1_Layer_2': 6.294710650259749e-05, 'l1_Layer_3': 0.005333237618387062, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 95}. Best is trial 177 with value: 2.957272523333019.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:34:59,583]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:35:02,169]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:35:06,887]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:35:09,662]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:35:12,540]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:35:17,001]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:35:22,378]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:35:26,366]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:35:31,462]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:35:36,209]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:35:39,409]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:35:44,336]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:36:13,630]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:36:36,151]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:36:43,049]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:36:48,500]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:37:05,954]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:37:10,149]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:37:17,596]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:37:37,671]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:37:45,346]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:37:52,410]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:37:57,219]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:38:06,789]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:38:11,997]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:38:16,283]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:38:24,062]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:38:30,680]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:38:36,466]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:38:43,249]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:38:47,877]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:38:52,984]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:38:56,181]\u001b[0m Trial 244 finished with value: 3.090536627289969 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010131944762416941, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33277639182567453, 'dropout_rate_Layer_2': 0.11564292971217918, 'dropout_rate_Layer_3': 0.31519523431648794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.394360784565768e-05, 'l1_Layer_2': 3.058032794160805e-05, 'l1_Layer_3': 0.09191100977390146, 'n_units_Layer_1': 95, 'n_units_Layer_2': 255, 'n_units_Layer_3': 75}. Best is trial 177 with value: 2.957272523333019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.09 | sMAPE for Validation Set is: 7.86% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.13 | sMAPE for Test Set is: 5.57% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:39:08,781]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:13,194]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:13,754]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:19,862]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:25,471]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:29,821]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:32,934]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:34,740]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:39,528]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:44,745]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:47,229]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:52,161]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:54,166]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:56,779]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:39:59,254]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:40:04,732]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:40:09,289]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:40:09,796]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:40:14,380]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:40:16,589]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:40:19,093]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:40:26,066]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:40:29,447]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:40:33,378]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:40:33,700]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:40:40,530]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:41:21,169]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:41:28,371]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:41:47,667]\u001b[0m Trial 286 finished with value: 4.186060386219061 and parameters: {'n_hidden': 3, 'learning_rate': 0.006181828368123286, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08129302010986197, 'dropout_rate_Layer_2': 0.0027429277440346057, 'dropout_rate_Layer_3': 0.24849661502633463, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014798106946866945, 'l1_Layer_2': 0.0017290274996208446, 'l1_Layer_3': 0.0028433631851925586, 'n_units_Layer_1': 260, 'n_units_Layer_2': 235, 'n_units_Layer_3': 160}. Best is trial 177 with value: 2.957272523333019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 10.11% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 2.75 | sMAPE for Test Set is: 6.87% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:42:02,148]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:42:15,135]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:42:19,141]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:42:24,110]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:42:27,377]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:42:34,116]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:43:01,153]\u001b[0m Trial 294 finished with value: 2.8804778729515146 and parameters: {'n_hidden': 3, 'learning_rate': 0.0073383531792105584, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02151692451175241, 'dropout_rate_Layer_2': 0.09854376314903188, 'dropout_rate_Layer_3': 0.18170850645715447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.479792705444506e-05, 'l1_Layer_2': 0.0014010080537074912, 'l1_Layer_3': 0.005492740165081299, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 190}. Best is trial 294 with value: 2.8804778729515146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.88 | sMAPE for Validation Set is: 7.25% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:43:04,273]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:43:20,732]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:43:35,753]\u001b[0m Trial 288 finished with value: 2.9538007728125577 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008040857694424755, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39910114699777277, 'dropout_rate_Layer_2': 0.004687973852878216, 'dropout_rate_Layer_3': 0.3725421428559764, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008085777997636202, 'l1_Layer_2': 7.857147240796567e-05, 'l1_Layer_3': 0.004610432498121279, 'n_units_Layer_1': 100, 'n_units_Layer_2': 265, 'n_units_Layer_3': 95}. Best is trial 294 with value: 2.8804778729515146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.95 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.98 | sMAPE for Test Set is: 5.26% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:43:38,541]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:43:45,223]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:43:48,458]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:44:07,762]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:44:12,238]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:44:17,763]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:44:42,396]\u001b[0m Trial 304 finished with value: 2.7835335729108848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0053308449767540565, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04640834683475001, 'dropout_rate_Layer_2': 0.13106651890238083, 'dropout_rate_Layer_3': 0.1820547239850816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011056774993174741, 'l1_Layer_2': 0.0007927200106337211, 'l1_Layer_3': 0.0023084144289394148, 'n_units_Layer_1': 225, 'n_units_Layer_2': 190, 'n_units_Layer_3': 175}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.08% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 4.86% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:44:49,211]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:44:49,778]\u001b[0m Trial 297 finished with value: 2.9967703739269265 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007976001236042041, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3988393002875328, 'dropout_rate_Layer_2': 0.04462668110891706, 'dropout_rate_Layer_3': 0.36391700702608454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009664253539766057, 'l1_Layer_2': 7.128496132359385e-05, 'l1_Layer_3': 0.0064535592818535225, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 95}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 7.62% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.32% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:45:19,154]\u001b[0m Trial 306 finished with value: 2.8508249597709274 and parameters: {'n_hidden': 3, 'learning_rate': 0.005861346632564807, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02630050628480285, 'dropout_rate_Layer_2': 0.1329069970217818, 'dropout_rate_Layer_3': 0.20411413433149733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.282481331290645e-05, 'l1_Layer_2': 0.002103747718292976, 'l1_Layer_3': 0.00618974494214774, 'n_units_Layer_1': 180, 'n_units_Layer_2': 190, 'n_units_Layer_3': 175}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.85 | sMAPE for Validation Set is: 7.24% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 4.87% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:45:26,805]\u001b[0m Trial 307 finished with value: 3.3598485650163794 and parameters: {'n_hidden': 3, 'learning_rate': 0.05021513990417637, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16649651698641105, 'dropout_rate_Layer_2': 0.04357448227967115, 'dropout_rate_Layer_3': 0.3429929390191756, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00039380543790754627, 'l1_Layer_2': 0.0001494916258092094, 'l1_Layer_3': 9.241559775429889e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.36 | sMAPE for Validation Set is: 8.34% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.09 | sMAPE for Test Set is: 5.50% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:45:36,809]\u001b[0m Trial 308 finished with value: 2.9663667333681047 and parameters: {'n_hidden': 3, 'learning_rate': 0.005771102319946906, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031353177431696064, 'dropout_rate_Layer_2': 0.13222606205300877, 'dropout_rate_Layer_3': 0.17882657064437407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.309308225755988e-05, 'l1_Layer_2': 0.006589724511774099, 'l1_Layer_3': 0.007054431410784512, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.97 | sMAPE for Validation Set is: 7.52% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.18% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:45:41,267]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:45:43,840]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:45:48,506]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:03,633]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:11,223]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:15,343]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:27,725]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:32,449]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:37,731]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:40,812]\u001b[0m Trial 316 finished with value: 3.0940256573945226 and parameters: {'n_hidden': 3, 'learning_rate': 0.007734546713003045, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005775702589534845, 'dropout_rate_Layer_2': 0.17568728491050684, 'dropout_rate_Layer_3': 0.2061960705936074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.8600357747340285e-05, 'l1_Layer_2': 0.0268067977501702, 'l1_Layer_3': 0.0041648808383686845, 'n_units_Layer_1': 155, 'n_units_Layer_2': 145, 'n_units_Layer_3': 175}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.09 | sMAPE for Validation Set is: 7.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.18% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:46:43,227]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:45,117]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:47,881]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:50,290]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:52,369]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:54,847]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:46:55,293]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:47:04,314]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:47:19,274]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:47:20,889]\u001b[0m Trial 327 finished with value: 3.077003737197464 and parameters: {'n_hidden': 3, 'learning_rate': 0.004513738530322546, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.054401197094974235, 'dropout_rate_Layer_2': 0.14817984071531676, 'dropout_rate_Layer_3': 0.2076873002526414, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.481388824849114e-05, 'l1_Layer_2': 0.017225361887453376, 'l1_Layer_3': 0.010066955301125844, 'n_units_Layer_1': 195, 'n_units_Layer_2': 145, 'n_units_Layer_3': 165}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.08 | sMAPE for Validation Set is: 7.78% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.04 | sMAPE for Test Set is: 5.36% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:47:26,625]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:47:36,471]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:47:39,575]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:47:43,717]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:47:54,088]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:48:00,964]\u001b[0m Trial 330 finished with value: 2.9812160716776077 and parameters: {'n_hidden': 3, 'learning_rate': 0.05942314140168319, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11364939074491551, 'dropout_rate_Layer_2': 0.11786451229414802, 'dropout_rate_Layer_3': 0.2693323701393827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.483005382672261e-05, 'l1_Layer_2': 5.2298029215401216e-05, 'l1_Layer_3': 3.683105841005915e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 250}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.98 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.17% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:48:10,854]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:48:15,733]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:48:16,244]\u001b[0m Trial 335 finished with value: 3.26585020257996 and parameters: {'n_hidden': 3, 'learning_rate': 0.007982396539922838, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0006221634689956984, 'dropout_rate_Layer_2': 0.18488457415627915, 'dropout_rate_Layer_3': 0.21341067326336272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5228162093063785e-05, 'l1_Layer_2': 0.06255290888305985, 'l1_Layer_3': 0.009450361458664897, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 150}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.27 | sMAPE for Validation Set is: 8.22% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.02 | sMAPE for Test Set is: 5.31% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:48:25,328]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:48:30,395]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:48:37,485]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:48:47,189]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:06,886]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:11,686]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:16,698]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:24,000]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:24,247]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:29,326]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:33,541]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:33,819]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:38,858]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:39,129]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:44,148]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:51,288]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:49:56,254]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:50:01,524]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:50:11,227]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:50:25,150]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:50:30,530]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:50:34,865]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:50:57,631]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:51:00,338]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:51:05,380]\u001b[0m Trial 358 finished with value: 3.0356147797458437 and parameters: {'n_hidden': 3, 'learning_rate': 0.01981986310478701, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2544870632633916, 'dropout_rate_Layer_2': 0.12430282027213073, 'dropout_rate_Layer_3': 0.26625944287925113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.337217320765939e-05, 'l1_Layer_2': 6.0180638432405754e-05, 'l1_Layer_3': 4.919560857833207e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.04 | sMAPE for Validation Set is: 7.59% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.18% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:51:10,134]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:51:15,026]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:51:20,154]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:51:22,440]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:51:26,611]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:51:29,842]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:51:31,530]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:51:36,944]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:51:39,531]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:51:56,587]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:52:01,485]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:52:08,406]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:52:13,691]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:52:37,803]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:52:41,124]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:52:43,689]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:52:48,681]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:52:51,102]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:52:53,697]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:52:58,235]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:53:52,525]\u001b[0m Trial 384 finished with value: 3.320089757899776 and parameters: {'n_hidden': 3, 'learning_rate': 0.009951078511747636, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3176363749339389, 'dropout_rate_Layer_2': 0.1279345935314352, 'dropout_rate_Layer_3': 0.26027635782691466, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.6596036351108326e-05, 'l1_Layer_2': 1.2893422250803335e-05, 'l1_Layer_3': 3.7249909831919374e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.32 | sMAPE for Validation Set is: 8.29% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.16 | sMAPE for Test Set is: 5.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:54:04,405]\u001b[0m Trial 373 finished with value: 3.34718445576325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005709207204243433, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024086879691209956, 'dropout_rate_Layer_2': 0.27946087195658353, 'dropout_rate_Layer_3': 0.37642147299582335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05017701607916712, 'l1_Layer_2': 3.087761455692288e-05, 'l1_Layer_3': 0.00022482431457607134, 'n_units_Layer_1': 120, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.35 | sMAPE for Validation Set is: 8.31% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.38 | sMAPE for Test Set is: 6.16% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:54:09,374]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:54:09,560]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:54:14,523]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:54:14,873]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:54:21,317]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:54:26,935]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:54:40,997]\u001b[0m Trial 389 finished with value: 5.97242893404579 and parameters: {'n_hidden': 3, 'learning_rate': 0.021348664039329897, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26022922765692336, 'dropout_rate_Layer_2': 0.1307507827849337, 'dropout_rate_Layer_3': 0.2614847350236881, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.869683190579872e-05, 'l1_Layer_2': 2.4198736602372282e-05, 'l1_Layer_3': 4.7993419782732825e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 80, 'n_units_Layer_3': 195}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 13.37% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:54:56,129]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:55:01,522]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:55:03,157]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:55:08,736]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:55:20,586]\u001b[0m Trial 395 finished with value: 6.144021385919227 and parameters: {'n_hidden': 3, 'learning_rate': 0.008492357001471953, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36803903723672826, 'dropout_rate_Layer_2': 0.1907746767722523, 'dropout_rate_Layer_3': 0.3169583357835374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.056018035355519e-05, 'l1_Layer_2': 5.964156274543661e-05, 'l1_Layer_3': 1.5772487102897504e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 95, 'n_units_Layer_3': 250}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 14.70% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 13.98% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:55:25,096]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:55:35,561]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:55:40,554]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:55:50,173]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:55:52,345]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:56:06,525]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:56:14,460]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:56:14,854]\u001b[0m Trial 403 finished with value: 6.288471134836669 and parameters: {'n_hidden': 3, 'learning_rate': 0.04303547408755726, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31008161643803234, 'dropout_rate_Layer_2': 0.06403655411421244, 'dropout_rate_Layer_3': 0.26523223478876473, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.243298430748784e-05, 'l1_Layer_2': 7.18611337273822e-05, 'l1_Layer_3': 0.0001461696342950173, 'n_units_Layer_1': 275, 'n_units_Layer_2': 90, 'n_units_Layer_3': 230}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 15.08% | rMAE for Validation Set is: 1.20\n",
      "MAE for Test Set is: 4.16 | sMAPE for Test Set is: 10.51% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:56:26,451]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:56:29,561]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:56:34,425]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:56:38,677]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:56:39,153]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:56:46,196]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:56:46,330]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:57:08,820]\u001b[0m Trial 412 finished with value: 2.9650967267283286 and parameters: {'n_hidden': 3, 'learning_rate': 0.002229541955450553, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3361094039523984, 'dropout_rate_Layer_2': 0.1516698408531158, 'dropout_rate_Layer_3': 0.2229541895876316, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.065709485997004e-05, 'l1_Layer_2': 1.046306733356003e-05, 'l1_Layer_3': 7.10479869352071e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 195, 'n_units_Layer_3': 125}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.97 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.08% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:57:13,321]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:57:13,616]\u001b[0m Trial 413 finished with value: 5.721122250849974 and parameters: {'n_hidden': 3, 'learning_rate': 0.02115285001826767, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24395171357233775, 'dropout_rate_Layer_2': 0.2708786614164711, 'dropout_rate_Layer_3': 0.36649571569406286, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.005087362887476e-05, 'l1_Layer_2': 1.6031793403358565e-05, 'l1_Layer_3': 2.2112061374345748e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 220}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 13.53% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 6.96 | sMAPE for Test Set is: 16.76% | rMAE for Test Set is: 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 20:57:18,739]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:57:21,127]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:57:23,504]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:57:23,641]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:57:31,405]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:57:43,164]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:57:48,803]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:57:52,992]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:57:55,659]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:00,883]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:05,905]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:10,289]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:13,514]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:15,790]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:18,154]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:24,880]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:27,461]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:32,528]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:34,703]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:37,924]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:40,531]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:45,592]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:58:59,408]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:59:09,230]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:59:11,660]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:59:14,053]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:59:21,838]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:59:28,476]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:59:33,339]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:59:38,969]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:59:43,492]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:59:48,702]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 20:59:56,061]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:00:05,175]\u001b[0m Trial 448 finished with value: 9.401301838583564 and parameters: {'n_hidden': 4, 'learning_rate': 0.07318883533721943, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23210370085640597, 'dropout_rate_Layer_2': 0.13702800656927996, 'dropout_rate_Layer_3': 0.22624942926977681, 'dropout_rate_Layer_4': 0.34311909352644254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.3027017214703768e-05, 'l1_Layer_2': 4.760948247060322e-05, 'l1_Layer_3': 5.08533135322683e-05, 'l1_Layer_4': 1.5066078882953173e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 295, 'n_units_Layer_3': 125, 'n_units_Layer_4': 60}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.40 | sMAPE for Validation Set is: 22.73% | rMAE for Validation Set is: 1.79\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 13.52% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:00:08,436]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:02:31,137]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:02:35,149]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:02:43,119]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:02:47,879]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:03:07,973]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:03:26,958]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:03:37,393]\u001b[0m Trial 449 finished with value: 3.0134131924133727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006686609199272147, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3499142882322192, 'dropout_rate_Layer_2': 0.06448960700126602, 'dropout_rate_Layer_3': 0.32953126936192845, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019270522113342325, 'l1_Layer_2': 4.071421996076804e-05, 'l1_Layer_3': 0.006708358795881364, 'n_units_Layer_1': 115, 'n_units_Layer_2': 280, 'n_units_Layer_3': 120}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.01 | sMAPE for Validation Set is: 7.64% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.12% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:03:39,491]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:03:41,821]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:03:42,533]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:03:49,001]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:03:54,323]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:04:18,988]\u001b[0m Trial 463 finished with value: 2.8985839571633156 and parameters: {'n_hidden': 3, 'learning_rate': 0.006582353449001979, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08000589794951601, 'dropout_rate_Layer_2': 0.19124800243114295, 'dropout_rate_Layer_3': 0.040479100083389924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5477994055513367e-05, 'l1_Layer_2': 0.0031499184330559386, 'l1_Layer_3': 4.885961896532309e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 265, 'n_units_Layer_3': 170}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.90 | sMAPE for Validation Set is: 7.39% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.28% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:04:21,315]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:04:25,850]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:04:29,126]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:04:31,880]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:04:36,600]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:04:43,174]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:04:47,765]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:04:47,901]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:04:53,229]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:04:58,066]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:05:22,630]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:05:24,527]\u001b[0m Trial 474 finished with value: 3.423117187178557 and parameters: {'n_hidden': 3, 'learning_rate': 0.01507712682283795, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17992413098424836, 'dropout_rate_Layer_2': 0.20929874948580127, 'dropout_rate_Layer_3': 0.17783405838216448, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.560869455219137e-05, 'l1_Layer_2': 0.00040226950769337526, 'l1_Layer_3': 2.2109076459956857e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 60, 'n_units_Layer_3': 65}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 8.65% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 2.55 | sMAPE for Test Set is: 6.70% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:05:31,290]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:05:36,758]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:05:39,238]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:05:44,632]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:01,124]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:10,963]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:16,818]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:19,200]\u001b[0m Trial 480 finished with value: 2.971520943046727 and parameters: {'n_hidden': 3, 'learning_rate': 0.010901211145349895, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06779030461929329, 'dropout_rate_Layer_2': 0.13354302595215897, 'dropout_rate_Layer_3': 0.0762739242068265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4893558777105394e-05, 'l1_Layer_2': 0.0016281114339636025, 'l1_Layer_3': 0.006314007593984861, 'n_units_Layer_1': 235, 'n_units_Layer_2': 160, 'n_units_Layer_3': 165}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.97 | sMAPE for Validation Set is: 7.49% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.03 | sMAPE for Test Set is: 5.35% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:06:19,418]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:26,356]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:36,408]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:41,203]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:44,224]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:48,850]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:51,368]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:53,729]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:55,716]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:06:58,713]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:07:01,195]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:07:05,671]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:07:06,107]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:07:10,974]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:07:15,629]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:07:18,128]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:07:20,702]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:07:23,085]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:07:42,740]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:07,466]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:09,756]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:11,847]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:15,002]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:17,488]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:19,650]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:21,770]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:24,261]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:26,469]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:36,451]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:38,855]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:41,649]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:46,777]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:08:50,777]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:09:12,900]\u001b[0m Trial 517 finished with value: 3.7622655772186087 and parameters: {'n_hidden': 3, 'learning_rate': 0.026377112479024127, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17399898646713569, 'dropout_rate_Layer_2': 0.253722927670381, 'dropout_rate_Layer_3': 0.11156400597019435, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.573786991043878e-05, 'l1_Layer_2': 0.0004418472703061807, 'l1_Layer_3': 3.637896171579732e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 50, 'n_units_Layer_3': 100}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 9.54% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 3.05 | sMAPE for Test Set is: 7.99% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:09:19,776]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:09:23,270]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:09:29,756]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:09:37,027]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:09:47,835]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:09:50,348]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:09:56,626]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:10:14,447]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:10:17,471]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:10:22,644]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:10:29,181]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:10:32,597]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:10:37,208]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:10:42,426]\u001b[0m Trial 525 finished with value: 2.88688535098035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009230534279277654, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03746841950766236, 'dropout_rate_Layer_2': 0.010681327964404071, 'dropout_rate_Layer_3': 0.37283313005838437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004458904780705694, 'l1_Layer_2': 3.286926838504022e-05, 'l1_Layer_3': 0.005485853904765738, 'n_units_Layer_1': 80, 'n_units_Layer_2': 215, 'n_units_Layer_3': 135}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.89 | sMAPE for Validation Set is: 7.36% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.20% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:10:46,628]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:11:02,374]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:11:14,177]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:12:16,165]\u001b[0m Trial 531 finished with value: 2.9640192714616576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009401874011595048, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3546295183492591, 'dropout_rate_Layer_2': 0.019223882855991664, 'dropout_rate_Layer_3': 0.3394945485339904, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013103114842146122, 'l1_Layer_2': 0.0013454864669547786, 'l1_Layer_3': 0.009672945456210521, 'n_units_Layer_1': 90, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.96 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.05% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:12:18,830]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:12:33,058]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:12:38,946]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:12:43,714]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:12:47,794]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:12:52,685]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:13:28,179]\u001b[0m Trial 535 finished with value: 2.951547878574393 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015288108263518218, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06504178789356946, 'dropout_rate_Layer_2': 0.01647017022255113, 'dropout_rate_Layer_3': 0.2756005402683268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011902287109832822, 'l1_Layer_2': 3.6861430632315504e-05, 'l1_Layer_3': 0.010567027669463554, 'n_units_Layer_1': 85, 'n_units_Layer_2': 205, 'n_units_Layer_3': 115}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.95 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.87 | sMAPE for Test Set is: 4.96% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:13:38,132]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:13:42,981]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:13:45,135]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:13:49,469]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:13:56,670]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:13:59,459]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:02,515]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:09,265]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:12,230]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:17,291]\u001b[0m Trial 548 finished with value: 5.253004682761109 and parameters: {'n_hidden': 3, 'learning_rate': 0.024076480482335388, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25772850835774497, 'dropout_rate_Layer_2': 0.1671220300077243, 'dropout_rate_Layer_3': 0.05912742494202122, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.1229102716371575e-05, 'l1_Layer_2': 0.00023995536711073626, 'l1_Layer_3': 0.0003943034738833162, 'n_units_Layer_1': 245, 'n_units_Layer_2': 125, 'n_units_Layer_3': 150}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 11.16% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:14:19,279]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:21,630]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:26,071]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:26,391]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:31,212]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:38,485]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:42,685]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:45,743]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:54,759]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:14:57,980]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:15:02,070]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:15:05,576]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:15:11,979]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:15:31,941]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:15:36,658]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:15:42,224]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:15:46,355]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:15:49,642]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:15:53,924]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:15:58,394]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:16:01,792]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:16:09,174]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:16:25,849]\u001b[0m Trial 575 finished with value: 5.294341688404758 and parameters: {'n_hidden': 3, 'learning_rate': 0.06777017116417278, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14262338021776988, 'dropout_rate_Layer_2': 0.14327023593695917, 'dropout_rate_Layer_3': 0.13193254890020872, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001891543440190646, 'l1_Layer_2': 9.853516653569134e-05, 'l1_Layer_3': 2.9084437131935817e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 105, 'n_units_Layer_3': 210}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 3.84 | sMAPE for Test Set is: 9.60% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:16:30,450]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:16:35,124]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:16:40,156]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:17:21,897]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:17:24,915]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:17:49,783]\u001b[0m Trial 579 finished with value: 5.3736830018308135 and parameters: {'n_hidden': 3, 'learning_rate': 0.03759211407550001, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29709991586705065, 'dropout_rate_Layer_2': 0.05730748309494581, 'dropout_rate_Layer_3': 0.2832574390809821, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5255616591375824e-05, 'l1_Layer_2': 0.007492358859598941, 'l1_Layer_3': 7.879695484092736e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 90, 'n_units_Layer_3': 55}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 12.81% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 10.16% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:17:54,516]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:17:58,768]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:04,350]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:11,292]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:14,183]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:19,082]\u001b[0m Trial 582 finished with value: 4.146890969294187 and parameters: {'n_hidden': 3, 'learning_rate': 0.00485762084775896, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04935521492785498, 'dropout_rate_Layer_2': 0.3129943205028623, 'dropout_rate_Layer_3': 0.3749384988549244, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012353898789381118, 'l1_Layer_2': 5.659325229192817e-05, 'l1_Layer_3': 0.00019379685902792747, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 240}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 10.20% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 2.84 | sMAPE for Test Set is: 7.39% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:18:19,340]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:31,480]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:35,909]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:39,324]\u001b[0m Trial 588 finished with value: 6.287787482882789 and parameters: {'n_hidden': 4, 'learning_rate': 0.018169724789778432, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10224759706619621, 'dropout_rate_Layer_2': 0.103692791155462, 'dropout_rate_Layer_3': 0.27104996154512073, 'dropout_rate_Layer_4': 0.2680357935242959, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.7777285522133246e-05, 'l1_Layer_2': 0.00013241682873579958, 'l1_Layer_3': 0.0001022439615099721, 'l1_Layer_4': 7.93186624827649e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285, 'n_units_Layer_4': 235}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 1.20\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 15.09% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:18:41,550]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:44,169]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:46,658]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:48,330]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:50,809]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:55,556]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:58,449]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:18:58,675]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:19:05,058]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:19:05,260]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:19:11,083]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:19:33,662]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:19:38,709]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:19:42,938]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:19:47,232]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:19:50,577]\u001b[0m Trial 603 finished with value: 4.0858267936227035 and parameters: {'n_hidden': 3, 'learning_rate': 0.031009237049361392, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13033141453581693, 'dropout_rate_Layer_2': 0.08300115543926576, 'dropout_rate_Layer_3': 0.29957822575651755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009063485974090311, 'l1_Layer_2': 0.0003947842431602839, 'l1_Layer_3': 0.00014080594860597123, 'n_units_Layer_1': 210, 'n_units_Layer_2': 125, 'n_units_Layer_3': 265}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 9.95% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 2.64 | sMAPE for Test Set is: 6.82% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:19:52,639]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:19:57,251]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:20:04,922]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:20:09,694]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:20:15,435]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:20:17,881]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:20:20,017]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:20:27,029]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:20:33,929]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:20:41,646]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:21:01,295]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:21:45,839]\u001b[0m Trial 618 finished with value: 2.9602598002947023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011498866618885435, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13409122024396297, 'dropout_rate_Layer_2': 0.0009580220314612392, 'dropout_rate_Layer_3': 0.3523639548647058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004402081834433668, 'l1_Layer_2': 2.8005215800116885e-05, 'l1_Layer_3': 0.0024691494801024317, 'n_units_Layer_1': 90, 'n_units_Layer_2': 270, 'n_units_Layer_3': 100}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.96 | sMAPE for Validation Set is: 7.49% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.93 | sMAPE for Test Set is: 5.14% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:21:50,813]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:22:03,052]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:22:07,575]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:22:11,089]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:22:14,968]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:22:22,849]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:22:30,181]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:22:37,269]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:22:40,555]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:22:44,863]\u001b[0m Trial 619 finished with value: 2.9403515975302157 and parameters: {'n_hidden': 3, 'learning_rate': 0.001177357710828867, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1371979128777435, 'dropout_rate_Layer_2': 0.2767055274443905, 'dropout_rate_Layer_3': 0.3201761392311631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00044440160020498486, 'l1_Layer_2': 2.6921340356386546e-05, 'l1_Layer_3': 0.009390355315924167, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 90}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.94 | sMAPE for Validation Set is: 7.45% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.13% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:22:47,782]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:22:54,188]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:22:58,864]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:02,189]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:06,215]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:06,602]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:11,695]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:12,057]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:16,622]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:18,480]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:23,527]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:25,651]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:28,633]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:32,812]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:33,017]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:40,147]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:40,350]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:49,808]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:23:54,718]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:24:15,209]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:24:17,910]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:24:24,470]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:24:32,463]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:24:42,265]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:24:46,710]\u001b[0m Trial 646 finished with value: 2.9750653249147443 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017440507473419208, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13010490350722062, 'dropout_rate_Layer_2': 0.306664742775444, 'dropout_rate_Layer_3': 0.3721582000200011, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046864720913102255, 'l1_Layer_2': 0.0011486689241379374, 'l1_Layer_3': 0.003921858849076661, 'n_units_Layer_1': 100, 'n_units_Layer_2': 270, 'n_units_Layer_3': 80}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.98 | sMAPE for Validation Set is: 7.54% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.03 | sMAPE for Test Set is: 5.39% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:24:49,801]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:24:54,731]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:24:57,433]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:01,517]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:01,617]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:09,154]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:14,120]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:18,894]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:26,318]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:26,896]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:31,743]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:33,815]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:37,002]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:37,048]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:43,579]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:45,882]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:50,916]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:25:53,466]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:26:00,800]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:26:10,132]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:26:27,552]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:26:42,036]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:26:46,513]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:26:52,186]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:26:57,076]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:26:57,210]\u001b[0m Trial 674 finished with value: 2.8936504585738505 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017267286869603906, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16413069979158532, 'dropout_rate_Layer_2': 0.32207548426793253, 'dropout_rate_Layer_3': 0.34078482694888107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027064730796996095, 'l1_Layer_2': 0.0012666072915390712, 'l1_Layer_3': 0.0029569481473831986, 'n_units_Layer_1': 90, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.89 | sMAPE for Validation Set is: 7.37% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.22% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:27:03,457]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:27:03,664]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:27:10,764]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:27:13,232]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:27:15,962]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:27:18,066]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:27:20,643]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:27:23,786]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:27:35,829]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:27:38,413]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:27:52,853]\u001b[0m Trial 687 finished with value: 3.2642860724362133 and parameters: {'n_hidden': 3, 'learning_rate': 0.014404449040671554, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21812328505809583, 'dropout_rate_Layer_2': 0.02269638658034283, 'dropout_rate_Layer_3': 0.23722904104501336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009945515440430842, 'l1_Layer_2': 3.0504027307170212e-05, 'l1_Layer_3': 5.962566370934614e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 115, 'n_units_Layer_3': 275}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.26 | sMAPE for Validation Set is: 8.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.33 | sMAPE for Test Set is: 6.13% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:27:57,800]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 10.85% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 3.26 | sMAPE for Test Set is: 8.47% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:28:04,397]\u001b[0m Trial 691 finished with value: 4.427092680398313 and parameters: {'n_hidden': 3, 'learning_rate': 0.07457578261011417, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22146637967950863, 'dropout_rate_Layer_2': 0.02197477994610051, 'dropout_rate_Layer_3': 0.23863615635838356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007731013047098547, 'l1_Layer_2': 3.264688920319671e-05, 'l1_Layer_3': 0.005399069163988079, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:28:04,804]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:28:11,538]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:28:11,730]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:28:18,850]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:28:21,542]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:28:26,046]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:28:33,537]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:28:38,581]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:28:51,053]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:28:54,102]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:28:58,617]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:04,412]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:11,268]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:11,548]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:16,892]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:20,926]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:24,040]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:26,624]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:31,241]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:31,599]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:38,916]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:44,141]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:46,112]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:53,578]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:29:58,318]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:30:02,771]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:30:07,851]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:30:12,996]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:30:40,769]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:30:45,560]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:30:49,670]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:30:55,623]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:12,792]\u001b[0m Trial 722 finished with value: 2.808523266950356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023436347080802345, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18186921585131155, 'dropout_rate_Layer_2': 0.24818321228240356, 'dropout_rate_Layer_3': 0.3155414466763343, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00035313661424179516, 'l1_Layer_2': 0.00032725312263625847, 'l1_Layer_3': 0.0021029367877261292, 'n_units_Layer_1': 80, 'n_units_Layer_2': 195, 'n_units_Layer_3': 125}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.13% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.80 | sMAPE for Test Set is: 4.75% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:31:15,308]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:22,605]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:26,915]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:32,056]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:35,139]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:39,332]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:47,320]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:49,557]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:52,766]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:55,056]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:57,361]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:31:59,743]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:32:30,567]\u001b[0m Trial 738 finished with value: 3.202567640878191 and parameters: {'n_hidden': 3, 'learning_rate': 0.00626246497235483, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03809053151639228, 'dropout_rate_Layer_2': 0.3601336326478828, 'dropout_rate_Layer_3': 0.3933529296147479, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007834548897208969, 'l1_Layer_2': 0.03502550769722704, 'l1_Layer_3': 0.0003416357507041416, 'n_units_Layer_1': 65, 'n_units_Layer_2': 285, 'n_units_Layer_3': 220}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.20 | sMAPE for Validation Set is: 8.03% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.22 | sMAPE for Test Set is: 5.81% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:32:50,933]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:32:55,787]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:32:57,471]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:00,298]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:02,668]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:07,200]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:12,247]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:12,419]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:17,595]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:21,831]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:25,058]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:29,349]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:34,119]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:34,679]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:41,175]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:43,951]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:46,451]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:48,800]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:53,517]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:55,965]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:33:58,795]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:02,989]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:03,129]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:08,684]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:10,476]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:12,985]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:18,002]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:20,386]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:25,015]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:28,202]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:35,453]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:40,087]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:47,429]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:52,804]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:57,210]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:34:59,760]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:35:04,236]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:35:38,867]\u001b[0m Trial 777 finished with value: 3.572224061511303 and parameters: {'n_hidden': 3, 'learning_rate': 0.01282359083188007, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17088698591676332, 'dropout_rate_Layer_2': 0.015030457482839307, 'dropout_rate_Layer_3': 0.27439805071825557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016868666428205522, 'l1_Layer_2': 4.4881023028759576e-05, 'l1_Layer_3': 8.524851316033175e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 130, 'n_units_Layer_3': 295}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 8.72% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 2.50 | sMAPE for Test Set is: 6.48% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:35:44,238]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:35:48,511]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:35:56,294]\u001b[0m Trial 776 finished with value: 3.4572337206604318 and parameters: {'n_hidden': 3, 'learning_rate': 0.027359684510469745, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16674710514834767, 'dropout_rate_Layer_2': 0.018394521993391786, 'dropout_rate_Layer_3': 0.2723316746286293, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009171414042796325, 'l1_Layer_2': 4.38170943804341e-05, 'l1_Layer_3': 9.304439424697393e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 125, 'n_units_Layer_3': 300}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.46 | sMAPE for Validation Set is: 8.51% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 2.25 | sMAPE for Test Set is: 5.87% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:36:00,878]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:36:18,073]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:36:39,761]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:36:52,200]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:37:32,068]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:37:41,891]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:37:54,022]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:38:18,790]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:38:23,480]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:38:30,744]\u001b[0m Trial 788 finished with value: 3.3190264928007926 and parameters: {'n_hidden': 3, 'learning_rate': 0.016685121011929354, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24098203575473046, 'dropout_rate_Layer_2': 0.11389712393235779, 'dropout_rate_Layer_3': 0.24027243179572383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009032251828029907, 'l1_Layer_2': 2.8809728315145133e-05, 'l1_Layer_3': 3.877876475272205e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 115, 'n_units_Layer_3': 280}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.32 | sMAPE for Validation Set is: 8.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.45 | sMAPE for Test Set is: 6.46% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:38:41,000]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:38:45,878]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:38:51,128]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:39:03,394]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:39:17,848]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:39:24,375]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:39:29,278]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:39:32,557]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:39:37,275]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:39:49,050]\u001b[0m Trial 795 finished with value: 3.239868986251411 and parameters: {'n_hidden': 3, 'learning_rate': 0.016965602077134063, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2429780258958395, 'dropout_rate_Layer_2': 0.10567759842176792, 'dropout_rate_Layer_3': 0.22457283564962754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00048407057231597615, 'l1_Layer_2': 6.094459326544481e-05, 'l1_Layer_3': 3.7765298672719425e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.24 | sMAPE for Validation Set is: 7.99% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.15 | sMAPE for Test Set is: 5.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:39:52,100]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:40:16,474]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:40:21,611]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:40:21,703]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:40:26,895]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:40:29,503]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:40:34,500]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:40:39,609]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:40:42,174]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:40:46,499]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:40:52,182]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:41:24,026]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:41:28,523]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:41:33,196]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:41:36,418]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:41:41,295]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:41:45,732]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:41:50,205]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:41:53,421]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:41:57,954]\u001b[0m Trial 812 finished with value: 2.9704236421105583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006478648038890237, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0193454545947062, 'dropout_rate_Layer_2': 0.2866414710046204, 'dropout_rate_Layer_3': 0.265348688246742, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017570932342190523, 'l1_Layer_2': 1.8334921990996988e-05, 'l1_Layer_3': 0.000142477801431786, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 135}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.97 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 5.47% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:42:00,855]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:42:19,506]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:42:20,278]\u001b[0m Trial 820 finished with value: 3.2715001468463094 and parameters: {'n_hidden': 3, 'learning_rate': 0.007564250601520164, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0373218880651453, 'dropout_rate_Layer_2': 0.1671297346708976, 'dropout_rate_Layer_3': 0.15627003616478036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.776047153581243e-05, 'l1_Layer_2': 0.035020683687337975, 'l1_Layer_3': 0.007946880720300526, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 185}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.27 | sMAPE for Validation Set is: 8.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.06 | sMAPE for Test Set is: 5.40% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:42:24,977]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:42:32,082]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:42:34,609]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:42:38,791]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:42:42,014]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:42:46,595]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:42:58,693]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:43:06,098]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:43:11,800]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:43:16,685]\u001b[0m Trial 828 finished with value: 3.449951174840803 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013592177993545125, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2896279921645965, 'dropout_rate_Layer_2': 0.11595836262849182, 'dropout_rate_Layer_3': 0.39460298456923343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000581672194281822, 'l1_Layer_2': 6.060402926504627e-05, 'l1_Layer_3': 6.23327694507672e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 304 with value: 2.7835335729108848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 8.61% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 2.28 | sMAPE for Test Set is: 6.04% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:43:21,523]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:43:23,666]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:43:29,023]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:43:38,827]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:43:46,626]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:43:53,404]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:43:58,154]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:44:03,395]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:44:07,723]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:44:13,257]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:44:18,086]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:44:23,046]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:44:32,262]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:44:38,267]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:44:44,574]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:44:52,404]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:45:04,676]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:45:49,326]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:45:53,704]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:46:45,342]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:46:50,386]\u001b[0m Trial 835 finished with value: 2.729089683838175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007821316094707758, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00034721147743970414, 'dropout_rate_Layer_2': 0.2989080189928074, 'dropout_rate_Layer_3': 0.2703330119826145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.046629313158623696, 'l1_Layer_2': 2.0936671295021375e-05, 'l1_Layer_3': 0.00022472438187946608, 'n_units_Layer_1': 175, 'n_units_Layer_2': 300, 'n_units_Layer_3': 150}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.73 | sMAPE for Validation Set is: 6.90% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.74 | sMAPE for Test Set is: 4.63% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:46:50,617]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:46:55,717]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:47:02,884]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:47:14,534]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:47:21,853]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:47:41,646]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:48:40,501]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:48:46,172]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:48:47,936]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:00,082]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:08,168]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:17,399]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:24,256]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:29,027]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:31,810]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:34,583]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:36,824]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:39,439]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:41,815]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:44,920]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:49,429]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:54,391]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:49:59,563]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:50:11,124]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:50:11,176]\u001b[0m Trial 876 finished with value: 2.8681151710542223 and parameters: {'n_hidden': 3, 'learning_rate': 0.005970408165214788, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08668932939522563, 'dropout_rate_Layer_2': 0.08806756820957998, 'dropout_rate_Layer_3': 0.3469459183989504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.96463712198184e-05, 'l1_Layer_2': 0.026107734818411898, 'l1_Layer_3': 5.985838811185769e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 215, 'n_units_Layer_3': 205}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.87 | sMAPE for Validation Set is: 7.31% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.06% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:50:16,799]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:50:21,898]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:50:53,917]\u001b[0m Trial 882 finished with value: 2.8425689172922346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0049944003479005915, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08035417283306495, 'dropout_rate_Layer_2': 0.08463653075669406, 'dropout_rate_Layer_3': 0.3483134377983058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.0117840074544394e-05, 'l1_Layer_2': 0.025553329805668563, 'l1_Layer_3': 5.03948473722403e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 205, 'n_units_Layer_3': 205}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.84 | sMAPE for Validation Set is: 7.22% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.77 | sMAPE for Test Set is: 4.70% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:50:57,102]\u001b[0m Trial 881 finished with value: 3.155789986153998 and parameters: {'n_hidden': 3, 'learning_rate': 0.004395811340641258, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01985255352651588, 'dropout_rate_Layer_2': 0.3025808448112798, 'dropout_rate_Layer_3': 0.2861569696812163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04812910066533154, 'l1_Layer_2': 4.034862447331039e-05, 'l1_Layer_3': 0.0008143117019315391, 'n_units_Layer_1': 230, 'n_units_Layer_2': 285, 'n_units_Layer_3': 150}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.16 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.15 | sMAPE for Test Set is: 5.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:51:01,649]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:51:45,044]\u001b[0m Trial 885 finished with value: 3.360283471769904 and parameters: {'n_hidden': 3, 'learning_rate': 0.007717757970494122, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01957508090293317, 'dropout_rate_Layer_2': 0.30475950518915684, 'dropout_rate_Layer_3': 0.26750615501700886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04933961794209885, 'l1_Layer_2': 3.907684995876454e-05, 'l1_Layer_3': 0.0008703431428223207, 'n_units_Layer_1': 230, 'n_units_Layer_2': 285, 'n_units_Layer_3': 150}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.36 | sMAPE for Validation Set is: 8.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.30 | sMAPE for Test Set is: 6.02% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:52:02,428]\u001b[0m Trial 883 finished with value: 3.056426871955061 and parameters: {'n_hidden': 3, 'learning_rate': 0.001731507589775311, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09343284203645275, 'dropout_rate_Layer_2': 0.3052722011376724, 'dropout_rate_Layer_3': 0.20815699608113394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05214107625278831, 'l1_Layer_2': 3.878351860103181e-05, 'l1_Layer_3': 0.0008197026861636255, 'n_units_Layer_1': 260, 'n_units_Layer_2': 285, 'n_units_Layer_3': 150}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.06 | sMAPE for Validation Set is: 7.72% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.16% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:52:07,113]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:52:29,664]\u001b[0m Trial 886 finished with value: 3.768681544698151 and parameters: {'n_hidden': 3, 'learning_rate': 0.01438502734674331, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22065459046450275, 'dropout_rate_Layer_2': 0.18463813537509893, 'dropout_rate_Layer_3': 0.1693866711814756, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008024572421095052, 'l1_Layer_2': 0.0001294042931470987, 'l1_Layer_3': 2.329506015098275e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 70, 'n_units_Layer_3': 245}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 9.28% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 2.17 | sMAPE for Test Set is: 5.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:52:36,681]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:52:39,549]\u001b[0m Trial 888 finished with value: 2.990259904985765 and parameters: {'n_hidden': 3, 'learning_rate': 0.004790180715683431, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020004502709705784, 'dropout_rate_Layer_2': 0.3115523370482315, 'dropout_rate_Layer_3': 0.2631914207639775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.052995059845210676, 'l1_Layer_2': 3.5606810270118936e-05, 'l1_Layer_3': 0.0005057989535117223, 'n_units_Layer_1': 230, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.99 | sMAPE for Validation Set is: 7.59% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.11% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:52:46,258]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:52:46,712]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:52:53,618]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:52:53,738]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:53:01,220]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:53:04,078]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:53:10,911]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:53:15,775]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:53:22,790]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:53:27,563]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:53:36,071]\u001b[0m Trial 895 finished with value: 3.6715070241256798 and parameters: {'n_hidden': 3, 'learning_rate': 0.02139933166080895, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2502041207617225, 'dropout_rate_Layer_2': 0.15519385026153829, 'dropout_rate_Layer_3': 0.31174014887317447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002614991945805916, 'l1_Layer_2': 0.04364305538389516, 'l1_Layer_3': 6.811759678064717e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 80, 'n_units_Layer_3': 260}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 9.00% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 2.48 | sMAPE for Test Set is: 6.42% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:53:38,242]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:53:52,540]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:54:01,941]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:54:06,936]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:54:27,367]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:54:31,342]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:54:51,440]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:54:54,147]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:54:56,155]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:54:58,454]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:55:00,979]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:55:05,323]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:55:18,436]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:55:27,971]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:55:47,542]\u001b[0m Trial 915 finished with value: 3.1593277053371267 and parameters: {'n_hidden': 3, 'learning_rate': 0.007068555617735283, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08083640389362173, 'dropout_rate_Layer_2': 0.3253735305046692, 'dropout_rate_Layer_3': 0.27732543480703686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.060464612877436735, 'l1_Layer_2': 2.686315102124366e-05, 'l1_Layer_3': 0.0008576302123217068, 'n_units_Layer_1': 220, 'n_units_Layer_2': 285, 'n_units_Layer_3': 135}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.16 | sMAPE for Validation Set is: 7.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.16 | sMAPE for Test Set is: 5.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:55:52,704]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:55:55,514]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:55:59,576]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:56:02,986]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:56:07,240]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:56:12,036]\u001b[0m Trial 916 finished with value: 3.0560894508912355 and parameters: {'n_hidden': 3, 'learning_rate': 0.04650341545284843, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18665308104218875, 'dropout_rate_Layer_2': 0.06217299141544065, 'dropout_rate_Layer_3': 0.25680840509354924, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5275819557004e-05, 'l1_Layer_2': 3.610317125563018e-05, 'l1_Layer_3': 2.8522897123320522e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 110, 'n_units_Layer_3': 275}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:56:12,094]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.06 | sMAPE for Validation Set is: 7.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.27% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:56:17,917]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:56:22,735]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:56:25,356]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:56:30,126]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:56:36,164]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:56:52,903]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:57:10,305]\u001b[0m Trial 929 finished with value: 3.1271715918599554 and parameters: {'n_hidden': 3, 'learning_rate': 0.007055716356661864, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02465954069666388, 'dropout_rate_Layer_2': 0.3420069152949204, 'dropout_rate_Layer_3': 0.2640360642098321, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07399513860674597, 'l1_Layer_2': 2.4249126983564937e-05, 'l1_Layer_3': 0.00018503861701722917, 'n_units_Layer_1': 250, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.13 | sMAPE for Validation Set is: 7.83% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.02 | sMAPE for Test Set is: 5.26% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:57:15,186]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:57:19,694]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:57:24,446]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:57:29,574]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:57:34,173]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:57:42,523]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:57:47,071]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:57:47,332]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:57:52,661]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:57:55,085]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:58:12,338]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:58:17,223]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:58:21,472]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:58:24,614]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:58:28,743]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:58:41,746]\u001b[0m Trial 942 finished with value: 3.2363732956508016 and parameters: {'n_hidden': 3, 'learning_rate': 0.004209250763408243, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009913114742135524, 'dropout_rate_Layer_2': 0.33335415939356144, 'dropout_rate_Layer_3': 0.2671957569561715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09981403952840032, 'l1_Layer_2': 3.1203510117034144e-05, 'l1_Layer_3': 0.0002145486343758894, 'n_units_Layer_1': 240, 'n_units_Layer_2': 285, 'n_units_Layer_3': 130}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.24 | sMAPE for Validation Set is: 8.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.11 | sMAPE for Test Set is: 5.54% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:58:46,256]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:58:50,675]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:58:56,217]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:59:00,703]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:59:05,401]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:59:08,882]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:59:13,046]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:59:20,311]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:59:25,637]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 21:59:33,411]\u001b[0m Trial 946 finished with value: 3.2750686224612444 and parameters: {'n_hidden': 3, 'learning_rate': 0.005016935643056516, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007512272117666254, 'dropout_rate_Layer_2': 0.3298936777420902, 'dropout_rate_Layer_3': 0.28844169294923516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07817714188650547, 'l1_Layer_2': 1.2438616058324045e-05, 'l1_Layer_3': 0.00022434541698839152, 'n_units_Layer_1': 230, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.28 | sMAPE for Validation Set is: 8.13% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.13 | sMAPE for Test Set is: 5.53% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 21:59:37,687]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:00:03,299]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:00:23,038]\u001b[0m Trial 956 finished with value: 2.7700251420516544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017052130557888626, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07971732419303963, 'dropout_rate_Layer_2': 0.1422286763688849, 'dropout_rate_Layer_3': 0.1438259142525551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.849590206660776e-05, 'l1_Layer_2': 0.0014931686718010003, 'l1_Layer_3': 0.0027804002836685857, 'n_units_Layer_1': 150, 'n_units_Layer_2': 125, 'n_units_Layer_3': 165}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.77 | sMAPE for Validation Set is: 6.99% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.77 | sMAPE for Test Set is: 4.72% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:00:32,679]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:00:35,391]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:00:37,884]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:00:40,663]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.76 | sMAPE for Validation Set is: 7.03% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.80 | sMAPE for Test Set is: 4.83% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:01:14,590]\u001b[0m Trial 962 finished with value: 2.758670679346365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018099080992245503, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09356007358439976, 'dropout_rate_Layer_2': 0.13474545666273355, 'dropout_rate_Layer_3': 0.1404420287588869, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.133457576363643e-05, 'l1_Layer_2': 0.00149890123535199, 'l1_Layer_3': 0.002602531182172719, 'n_units_Layer_1': 155, 'n_units_Layer_2': 120, 'n_units_Layer_3': 175}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:01:27,302]\u001b[0m Trial 964 finished with value: 3.422962010044403 and parameters: {'n_hidden': 3, 'learning_rate': 0.005695041089613284, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006313164008918092, 'dropout_rate_Layer_2': 0.3396671065092521, 'dropout_rate_Layer_3': 0.26171096346388895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06096293763530229, 'l1_Layer_2': 1.1522325100095682e-05, 'l1_Layer_3': 0.00022917988021885547, 'n_units_Layer_1': 250, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 8.58% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 2.50 | sMAPE for Test Set is: 6.51% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:01:32,267]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:01:58,982]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:02:03,671]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:02:09,492]\u001b[0m Trial 965 finished with value: 2.8121005680308 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016643844649768505, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09351633977347557, 'dropout_rate_Layer_2': 0.1285167964156232, 'dropout_rate_Layer_3': 0.12756033401980504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.994208510410764e-05, 'l1_Layer_2': 0.001421201341047912, 'l1_Layer_3': 0.002877008640142534, 'n_units_Layer_1': 150, 'n_units_Layer_2': 140, 'n_units_Layer_3': 175}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.09% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.77 | sMAPE for Test Set is: 4.72% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:02:28,384]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:02:31,803]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:02:36,270]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:02:38,766]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:02:43,540]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:02:55,315]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:03:00,734]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:03:22,595]\u001b[0m Trial 973 finished with value: 3.1233244845143466 and parameters: {'n_hidden': 3, 'learning_rate': 0.005006235758321823, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007001171179648092, 'dropout_rate_Layer_2': 0.3398052090443379, 'dropout_rate_Layer_3': 0.2545885130381785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06262477630061844, 'l1_Layer_2': 1.5149395316545522e-05, 'l1_Layer_3': 0.00021977516959240307, 'n_units_Layer_1': 255, 'n_units_Layer_2': 285, 'n_units_Layer_3': 140}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.12 | sMAPE for Validation Set is: 7.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 5.23% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:03:27,415]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:03:30,301]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:03:33,042]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:03:35,213]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:03:45,184]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:03:49,950]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:04:01,931]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:04:14,256]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:04:19,351]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:04:26,598]\u001b[0m Trial 982 finished with value: 2.998432354225571 and parameters: {'n_hidden': 3, 'learning_rate': 0.004871881932641397, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022825280351205034, 'dropout_rate_Layer_2': 0.33127572388378, 'dropout_rate_Layer_3': 0.2711780467439065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05341231349009219, 'l1_Layer_2': 1.011687702765669e-05, 'l1_Layer_3': 0.0003304299335659035, 'n_units_Layer_1': 255, 'n_units_Layer_2': 285, 'n_units_Layer_3': 135}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 7.55% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.02 | sMAPE for Test Set is: 5.31% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:04:31,678]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:04:48,516]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:04:55,611]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:05:03,310]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:05:15,671]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:05:25,423]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:05:35,796]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:05:47,958]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:05:53,268]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:05:57,937]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:06:37,237]\u001b[0m Trial 993 finished with value: 3.766399283595591 and parameters: {'n_hidden': 3, 'learning_rate': 0.0062484360981282265, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12368444231611747, 'dropout_rate_Layer_2': 0.3519698370816883, 'dropout_rate_Layer_3': 0.28196082963813696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05294042222061653, 'l1_Layer_2': 1.0197483583126011e-05, 'l1_Layer_3': 0.00018265304106623398, 'n_units_Layer_1': 255, 'n_units_Layer_2': 285, 'n_units_Layer_3': 140}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 9.10% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 2.46 | sMAPE for Test Set is: 6.26% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:06:49,313]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:06:59,157]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:07:02,197]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:07:07,005]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:07:31,476]\u001b[0m Trial 999 finished with value: 4.401966388594062 and parameters: {'n_hidden': 3, 'learning_rate': 0.05917115258612215, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32515792765668716, 'dropout_rate_Layer_2': 0.10544440114438179, 'dropout_rate_Layer_3': 0.26211703797389285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003680727168418335, 'l1_Layer_2': 1.9854331738989177e-05, 'l1_Layer_3': 4.613345687645904e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 110, 'n_units_Layer_3': 250}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 2.90 | sMAPE for Test Set is: 7.64% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:07:36,339]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:07:44,221]\u001b[0m Trial 1003 finished with value: 3.2956823764477803 and parameters: {'n_hidden': 3, 'learning_rate': 0.003997721784910104, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027262505950687632, 'dropout_rate_Layer_2': 0.3304961483127276, 'dropout_rate_Layer_3': 0.2768058191023794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0409957883480202, 'l1_Layer_2': 1.2571973522079549e-05, 'l1_Layer_3': 6.262693928076788e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 275, 'n_units_Layer_3': 125}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.30 | sMAPE for Validation Set is: 8.15% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.21 | sMAPE for Test Set is: 5.76% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:07:55,770]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:08:00,636]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:08:06,168]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:08:25,449]\u001b[0m Trial 1006 finished with value: 3.6370789986704533 and parameters: {'n_hidden': 3, 'learning_rate': 0.027565553372312885, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.259762819356617, 'dropout_rate_Layer_2': 0.058839058570329325, 'dropout_rate_Layer_3': 0.3335688685562208, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001549533395442018, 'l1_Layer_2': 6.93251896155806e-05, 'l1_Layer_3': 5.835317829782217e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 205, 'n_units_Layer_3': 275}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 8.97% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 2.75 | sMAPE for Test Set is: 7.30% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:08:27,474]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:08:30,425]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:08:32,504]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:08:40,132]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:08:52,502]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:08:57,193]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:09:02,648]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:09:09,736]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:09:16,633]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:09:21,622]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:09:34,080]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:09:40,893]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:09:44,308]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:09:51,014]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:09:55,746]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:10:15,789]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:10:28,854]\u001b[0m Trial 1025 finished with value: 4.285094724811434 and parameters: {'n_hidden': 3, 'learning_rate': 0.008858125447071812, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23546960442332937, 'dropout_rate_Layer_2': 0.0820985210787955, 'dropout_rate_Layer_3': 0.22164887889780252, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0406561426658445e-05, 'l1_Layer_2': 4.1876565805163894e-05, 'l1_Layer_3': 0.00017167598883527678, 'n_units_Layer_1': 285, 'n_units_Layer_2': 95, 'n_units_Layer_3': 285}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 10.55% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 2.93 | sMAPE for Test Set is: 7.80% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:10:46,037]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:10:50,752]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:10:55,913]\u001b[0m Trial 1027 finished with value: 3.2514519541401214 and parameters: {'n_hidden': 3, 'learning_rate': 0.011440438976221575, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18132850465602024, 'dropout_rate_Layer_2': 0.1378000010948062, 'dropout_rate_Layer_3': 0.1478606443743391, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.189433786169649e-05, 'l1_Layer_2': 0.000155965794714138, 'l1_Layer_3': 2.097230164987614e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 65, 'n_units_Layer_3': 160}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.25 | sMAPE for Validation Set is: 8.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.01 | sMAPE for Test Set is: 5.32% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:10:58,007]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:01,056]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:03,354]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:06,016]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:13,042]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:15,857]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:17,632]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:20,428]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:23,039]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:25,579]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:30,627]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:35,423]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:11:40,512]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:12:12,536]\u001b[0m Trial 1039 finished with value: 3.1901915098790568 and parameters: {'n_hidden': 3, 'learning_rate': 0.004453992069634938, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007174005450309891, 'dropout_rate_Layer_2': 0.33505442090333876, 'dropout_rate_Layer_3': 0.25602299554606384, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.085687969907547, 'l1_Layer_2': 1.572231465128505e-05, 'l1_Layer_3': 0.00024072027888903178, 'n_units_Layer_1': 255, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.19 | sMAPE for Validation Set is: 8.01% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.21% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:12:19,293]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:12:24,215]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:12:28,492]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:12:33,645]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:12:38,959]\u001b[0m Trial 1043 finished with value: 3.1615042971410343 and parameters: {'n_hidden': 3, 'learning_rate': 0.004983325830145601, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00833221818564654, 'dropout_rate_Layer_2': 0.33743406908841933, 'dropout_rate_Layer_3': 0.2694427925182693, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08546532933849758, 'l1_Layer_2': 1.453668340380782e-05, 'l1_Layer_3': 0.00027993306655890667, 'n_units_Layer_1': 255, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.16 | sMAPE for Validation Set is: 7.85% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.06 | sMAPE for Test Set is: 5.38% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:13:25,747]\u001b[0m Trial 1048 finished with value: 3.1600381406414666 and parameters: {'n_hidden': 3, 'learning_rate': 0.0050559971048866345, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008832765499665066, 'dropout_rate_Layer_2': 0.32905342389791215, 'dropout_rate_Layer_3': 0.26661237730942483, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08774304400383282, 'l1_Layer_2': 1.776929300127042e-05, 'l1_Layer_3': 0.0003692327991662585, 'n_units_Layer_1': 260, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.16 | sMAPE for Validation Set is: 7.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.11% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:13:30,904]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:13:39,787]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:14:00,243]\u001b[0m Trial 1049 finished with value: 3.173752842659835 and parameters: {'n_hidden': 3, 'learning_rate': 0.004201138551297328, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03221012797184866, 'dropout_rate_Layer_2': 0.3260347878908257, 'dropout_rate_Layer_3': 0.26993997309515466, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08277684206671294, 'l1_Layer_2': 0.09986669272815196, 'l1_Layer_3': 0.0003009254956739303, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 130}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.17 | sMAPE for Validation Set is: 7.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 5.37% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:14:12,485]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:14:16,996]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:14:32,965]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:15:01,724]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:15:28,897]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:15:33,653]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:15:36,440]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:15:36,476]\u001b[0m Trial 1055 finished with value: 3.1012145210866375 and parameters: {'n_hidden': 3, 'learning_rate': 0.004198737470851817, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009438849639882391, 'dropout_rate_Layer_2': 0.32754690542009923, 'dropout_rate_Layer_3': 0.27069252519462894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08705043735054725, 'l1_Layer_2': 0.08461805486727506, 'l1_Layer_3': 0.0002695631236393578, 'n_units_Layer_1': 270, 'n_units_Layer_2': 260, 'n_units_Layer_3': 125}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.10 | sMAPE for Validation Set is: 7.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.23% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:15:43,840]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:15:51,415]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:16:00,862]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:16:12,996]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:16:15,609]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:16:18,322]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:16:20,578]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:16:33,001]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:16:45,392]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:16:50,149]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:16:53,059]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:16:57,991]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:17:27,703]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 7.56% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.98 | sMAPE for Test Set is: 5.17% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:17:38,210]\u001b[0m Trial 1071 finished with value: 3.003370306114467 and parameters: {'n_hidden': 3, 'learning_rate': 0.012684684176262723, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1870682258275443, 'dropout_rate_Layer_2': 0.1333343922823251, 'dropout_rate_Layer_3': 0.19818812454219525, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.114409132665157e-05, 'l1_Layer_2': 0.00016251874841179213, 'l1_Layer_3': 2.0638324044412554e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 165}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:18:07,757]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:18:15,138]\u001b[0m Trial 1074 finished with value: 3.943368344644373 and parameters: {'n_hidden': 3, 'learning_rate': 0.01247740728424575, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18846847145866838, 'dropout_rate_Layer_2': 0.101143494646891, 'dropout_rate_Layer_3': 0.12515483014572387, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09250709370566024, 'l1_Layer_2': 0.0002164614870725216, 'l1_Layer_3': 1.9079776535483747e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 150}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 9.71% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 2.85 | sMAPE for Test Set is: 7.29% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:18:27,333]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:18:39,521]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:19:05,646]\u001b[0m Trial 1076 finished with value: 2.981891936137023 and parameters: {'n_hidden': 3, 'learning_rate': 0.011974498487905015, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1885121532766807, 'dropout_rate_Layer_2': 0.13922946163050345, 'dropout_rate_Layer_3': 0.20114053152777994, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.322385543075071e-05, 'l1_Layer_2': 8.704950542598884e-05, 'l1_Layer_3': 1.868561551316104e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 75, 'n_units_Layer_3': 160}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.98 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.16% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:19:08,000]\u001b[0m Trial 1079 finished with value: 3.1914430210266254 and parameters: {'n_hidden': 3, 'learning_rate': 0.010540237685061713, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2202699790964887, 'dropout_rate_Layer_2': 0.14043841960440243, 'dropout_rate_Layer_3': 0.15299716715249695, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.8644460336164455e-05, 'l1_Layer_2': 9.376538024446612e-05, 'l1_Layer_3': 3.6082099552999685e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 85, 'n_units_Layer_3': 160}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.19 | sMAPE for Validation Set is: 8.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.17 | sMAPE for Test Set is: 5.73% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:19:10,965]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:19:13,215]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:19:55,132]\u001b[0m Trial 1082 finished with value: 3.081743803610349 and parameters: {'n_hidden': 3, 'learning_rate': 0.006522488200168265, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20178955054491987, 'dropout_rate_Layer_2': 0.14220436524878627, 'dropout_rate_Layer_3': 0.14279974679605761, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.363553826736213e-05, 'l1_Layer_2': 0.00010645589176045714, 'l1_Layer_3': 1.1742400390722585e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.08 | sMAPE for Validation Set is: 7.75% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 5.29% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:20:04,165]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:20:11,585]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:20:16,408]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:20:19,533]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:20:23,979]\u001b[0m Trial 1083 finished with value: 3.1571335855143032 and parameters: {'n_hidden': 3, 'learning_rate': 0.004740770124616632, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009241876332226017, 'dropout_rate_Layer_2': 0.32523880901280844, 'dropout_rate_Layer_3': 0.0019324469751104134, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09971932860543496, 'l1_Layer_2': 0.09542982762932474, 'l1_Layer_3': 0.0004174142806352584, 'n_units_Layer_1': 250, 'n_units_Layer_2': 265, 'n_units_Layer_3': 145}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.16 | sMAPE for Validation Set is: 7.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 1.98 | sMAPE for Test Set is: 5.17% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:20:24,501]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:21:17,609]\u001b[0m Trial 1090 finished with value: 3.042412031855663 and parameters: {'n_hidden': 3, 'learning_rate': 0.00630967008074936, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1362191706088338, 'dropout_rate_Layer_2': 0.13791755179985704, 'dropout_rate_Layer_3': 0.1517671532035604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5378887096738736e-05, 'l1_Layer_2': 0.00010656450092734373, 'l1_Layer_3': 1.2304773459932565e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.04 | sMAPE for Validation Set is: 7.66% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.87 | sMAPE for Test Set is: 4.97% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:22:06,722]\u001b[0m Trial 1091 finished with value: 2.9177854255946207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033717999290093863, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14397636879869408, 'dropout_rate_Layer_2': 0.16035970262031105, 'dropout_rate_Layer_3': 0.1461421608354585, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.890080830010653e-05, 'l1_Layer_2': 0.00010678447386044992, 'l1_Layer_3': 1.1650987443350328e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.92 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 4.93% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:22:11,736]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:22:17,164]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:22:47,174]\u001b[0m Trial 1089 finished with value: 2.9485701660514985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009406693967724881, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14389560837522894, 'dropout_rate_Layer_2': 0.1528673134986106, 'dropout_rate_Layer_3': 0.3388777351010446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017497534684750527, 'l1_Layer_2': 3.80230028502795e-05, 'l1_Layer_3': 0.006645747886882056, 'n_units_Layer_1': 75, 'n_units_Layer_2': 250, 'n_units_Layer_3': 115}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.95 | sMAPE for Validation Set is: 7.49% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.26% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:22:59,314]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:23:01,353]\u001b[0m Trial 1094 finished with value: 3.0340700546545247 and parameters: {'n_hidden': 3, 'learning_rate': 0.002703803412201789, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13035422206289865, 'dropout_rate_Layer_2': 0.16268839255775672, 'dropout_rate_Layer_3': 0.14785967831807084, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.697214123967863e-05, 'l1_Layer_2': 0.000299147815505806, 'l1_Layer_3': 1.2032846184000378e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.03 | sMAPE for Validation Set is: 7.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 4.90% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:23:06,473]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:23:13,704]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:23:15,958]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:23:18,936]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:23:28,430]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:24:09,911]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:24:15,186]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:24:34,366]\u001b[0m Trial 1102 finished with value: 2.7843741188102604 and parameters: {'n_hidden': 3, 'learning_rate': 0.001856751919960542, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24721472357793028, 'dropout_rate_Layer_2': 0.14607370907313172, 'dropout_rate_Layer_3': 0.148822811042485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.893337172464476e-05, 'l1_Layer_2': 0.0009300338747711282, 'l1_Layer_3': 0.003276540460215746, 'n_units_Layer_1': 225, 'n_units_Layer_2': 150, 'n_units_Layer_3': 140}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.07% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.77 | sMAPE for Test Set is: 4.70% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:24:44,030]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:24:46,757]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:24:49,481]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:25:08,543]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:25:35,907]\u001b[0m Trial 1107 finished with value: 2.870293076473464 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020388671357097032, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08661312500925614, 'dropout_rate_Layer_2': 0.1458549096833655, 'dropout_rate_Layer_3': 0.14810591470757312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.260883273796691e-05, 'l1_Layer_2': 0.001014996956389452, 'l1_Layer_3': 0.0033029355175944143, 'n_units_Layer_1': 225, 'n_units_Layer_2': 145, 'n_units_Layer_3': 230}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.87 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.96% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:25:40,820]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:25:57,275]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:26:17,355]\u001b[0m Trial 1111 finished with value: 2.795226170648187 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018186823768266342, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2544482801441951, 'dropout_rate_Layer_2': 0.14087708534079366, 'dropout_rate_Layer_3': 0.15624107554945244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5927808647613136e-05, 'l1_Layer_2': 0.0012617581296414724, 'l1_Layer_3': 0.0035380192273613198, 'n_units_Layer_1': 225, 'n_units_Layer_2': 150, 'n_units_Layer_3': 170}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.80 | sMAPE for Validation Set is: 7.10% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.83 | sMAPE for Test Set is: 4.92% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:26:37,005]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:26:41,661]\u001b[0m Trial 1112 finished with value: 2.7755961286466664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017014831305871897, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08178631044192891, 'dropout_rate_Layer_2': 0.16118892100935817, 'dropout_rate_Layer_3': 0.1497520043747729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.115839036940659e-05, 'l1_Layer_2': 0.001280246411579864, 'l1_Layer_3': 0.0032115963979026537, 'n_units_Layer_1': 225, 'n_units_Layer_2': 150, 'n_units_Layer_3': 170}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 7.05% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 5.05% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:26:46,437]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:27:06,722]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:27:16,008]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:28:00,381]\u001b[0m Trial 1118 finished with value: 3.112651009506353 and parameters: {'n_hidden': 3, 'learning_rate': 0.002253853092145641, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14354429979852087, 'dropout_rate_Layer_2': 0.15386041882131202, 'dropout_rate_Layer_3': 0.15819621934577122, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5061947771025282e-05, 'l1_Layer_2': 0.00010471197502579592, 'l1_Layer_3': 1.3898321989676925e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.11 | sMAPE for Validation Set is: 7.84% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.22% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:28:12,800]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:28:17,990]\u001b[0m Trial 1117 finished with value: 3.1688204805100653 and parameters: {'n_hidden': 3, 'learning_rate': 0.005261407917589656, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011276987930271232, 'dropout_rate_Layer_2': 0.3430188001531014, 'dropout_rate_Layer_3': 0.18525702911229122, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08232195482751152, 'l1_Layer_2': 0.06798472640972883, 'l1_Layer_3': 0.0003231689239165213, 'n_units_Layer_1': 255, 'n_units_Layer_2': 275, 'n_units_Layer_3': 145}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:28:18,099]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.17 | sMAPE for Validation Set is: 7.92% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.07 | sMAPE for Test Set is: 5.37% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:28:25,630]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:28:25,768]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:28:41,750]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:28:58,360]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:29:08,503]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:29:11,176]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:29:13,644]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:29:16,439]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:29:23,303]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:29:43,210]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:30:05,805]\u001b[0m Trial 1129 finished with value: 2.929053298090645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021779355876358343, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12286481755440228, 'dropout_rate_Layer_2': 0.19427292787251066, 'dropout_rate_Layer_3': 0.11127748840467125, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3869606404504138e-05, 'l1_Layer_2': 0.00011264885317363831, 'l1_Layer_3': 1.3151488481921955e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.93 | sMAPE for Validation Set is: 7.41% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.87 | sMAPE for Test Set is: 4.98% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:30:10,570]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:30:34,745]\u001b[0m Trial 1132 finished with value: 2.9853879660245872 and parameters: {'n_hidden': 3, 'learning_rate': 0.002192278184564419, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14356613386166117, 'dropout_rate_Layer_2': 0.1594384659249916, 'dropout_rate_Layer_3': 0.10903693078275302, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5055091072767574e-05, 'l1_Layer_2': 0.00012270485284905446, 'l1_Layer_3': 1.3834756102173562e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.99 | sMAPE for Validation Set is: 7.56% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.13% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:30:57,040]\u001b[0m Trial 1134 finished with value: 3.03173226313884 and parameters: {'n_hidden': 3, 'learning_rate': 0.0040152763868221185, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03460270838234192, 'dropout_rate_Layer_2': 0.3695724149583925, 'dropout_rate_Layer_3': 0.2825668171217527, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08444834412044155, 'l1_Layer_2': 0.09957216318602581, 'l1_Layer_3': 0.00022408046532652317, 'n_units_Layer_1': 260, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.03 | sMAPE for Validation Set is: 7.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.98 | sMAPE for Test Set is: 5.19% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:31:09,250]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:31:38,482]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:31:50,788]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:32:00,707]\u001b[0m Trial 1135 finished with value: 3.061436688895554 and parameters: {'n_hidden': 3, 'learning_rate': 0.003956692391388935, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03297651471334613, 'dropout_rate_Layer_2': 0.33205740303519177, 'dropout_rate_Layer_3': 0.015052565529466239, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08714116760335706, 'l1_Layer_2': 0.09493048789744758, 'l1_Layer_3': 0.000213461718327951, 'n_units_Layer_1': 260, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.06 | sMAPE for Validation Set is: 7.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.15% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:32:07,996]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:32:45,636]\u001b[0m Trial 1139 finished with value: 3.012663964852274 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018002815414199468, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08963008521332387, 'dropout_rate_Layer_2': 0.19291285922993157, 'dropout_rate_Layer_3': 0.08283982473691905, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9858350049154338e-05, 'l1_Layer_2': 0.0001680130301301801, 'l1_Layer_3': 1.589870415401641e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.01 | sMAPE for Validation Set is: 7.57% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 5.02% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:32:52,685]\u001b[0m Trial 1141 finished with value: 3.0769402693103807 and parameters: {'n_hidden': 3, 'learning_rate': 0.003295279227801388, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12055581380687383, 'dropout_rate_Layer_2': 0.19284551631937777, 'dropout_rate_Layer_3': 0.09575009727759398, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.136541273776061e-05, 'l1_Layer_2': 0.0001635926049123303, 'l1_Layer_3': 1.5126875893366985e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.08 | sMAPE for Validation Set is: 7.73% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.08 | sMAPE for Test Set is: 5.45% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:33:00,647]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:33:00,767]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:33:32,029]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:33:32,171]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:33:40,391]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:33:40,803]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:33:50,830]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:33:54,130]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:33:58,503]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:34:16,203]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:34:18,704]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:34:23,239]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:34:25,941]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:34:33,140]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:34:37,689]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:34:40,643]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:34:48,374]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:34:53,278]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:35:05,234]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:35:10,164]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:35:22,462]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:35:42,497]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:35:49,405]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:35:55,175]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:36:00,160]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:36:06,418]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:36:06,526]\u001b[0m Trial 1159 finished with value: 3.20432919232317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033734010755490855, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025630113451100743, 'dropout_rate_Layer_2': 0.3359560553077328, 'dropout_rate_Layer_3': 0.24890885795436568, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07167287243722163, 'l1_Layer_2': 0.09827692841429272, 'l1_Layer_3': 0.0002246960606979294, 'n_units_Layer_1': 255, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.20 | sMAPE for Validation Set is: 7.96% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.07 | sMAPE for Test Set is: 5.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:36:20,650]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:36:35,328]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:36:40,330]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:36:47,323]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:36:51,631]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:36:51,734]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:37:23,355]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:38:00,895]\u001b[0m Trial 1175 finished with value: 3.2380286144189108 and parameters: {'n_hidden': 3, 'learning_rate': 0.004076823974351917, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025926819254194003, 'dropout_rate_Layer_2': 0.32165870987740874, 'dropout_rate_Layer_3': 0.2605410571016965, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09995277596546696, 'l1_Layer_2': 0.0779244286398909, 'l1_Layer_3': 0.00025399429244013337, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.24 | sMAPE for Validation Set is: 8.12% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.14 | sMAPE for Test Set is: 5.57% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:38:05,335]\u001b[0m Trial 1177 finished with value: 3.0989775004200433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022809202633171286, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06499091618864872, 'dropout_rate_Layer_2': 0.19251644078914784, 'dropout_rate_Layer_3': 0.11246910600594356, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7216512106967115e-05, 'l1_Layer_2': 7.970349682938032e-05, 'l1_Layer_3': 1.2428677040044576e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 70, 'n_units_Layer_3': 185}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.10 | sMAPE for Validation Set is: 7.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.16% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:38:08,279]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:38:15,353]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:38:23,052]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:38:27,483]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:38:32,742]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:38:42,501]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:38:54,528]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:38:59,876]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:39:07,506]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:39:19,629]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:39:19,837]\u001b[0m Trial 1182 finished with value: 2.8221211506534565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024997394863144366, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22509977687001717, 'dropout_rate_Layer_2': 0.13822311486567376, 'dropout_rate_Layer_3': 0.1623399134358286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.631282373198124e-05, 'l1_Layer_2': 0.0011624999316390172, 'l1_Layer_3': 0.0031478831012407274, 'n_units_Layer_1': 230, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.17% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.85 | sMAPE for Test Set is: 4.89% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:39:26,180]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:39:47,831]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:39:59,914]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:40:22,154]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:40:27,648]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:40:51,211]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:40:56,614]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:41:08,747]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:41:14,079]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:41:21,107]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:41:31,014]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:41:35,434]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:41:45,753]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:41:50,666]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:41:55,371]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:42:00,209]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:42:26,541]\u001b[0m Trial 1202 finished with value: 3.0950717759265576 and parameters: {'n_hidden': 3, 'learning_rate': 0.003773698196430093, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.032460903432949856, 'dropout_rate_Layer_2': 0.3320455139543798, 'dropout_rate_Layer_3': 0.18881773404191343, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.054683318624262046, 'l1_Layer_2': 0.08079525343972754, 'l1_Layer_3': 0.0003910705511307507, 'n_units_Layer_1': 265, 'n_units_Layer_2': 290, 'n_units_Layer_3': 125}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.10 | sMAPE for Validation Set is: 7.75% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 5.20% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:42:33,908]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:42:41,852]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:42:48,367]\u001b[0m Trial 1206 finished with value: 2.7892441114766644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017432797800184649, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22494113632687152, 'dropout_rate_Layer_2': 0.14029249173699648, 'dropout_rate_Layer_3': 0.14677171757753318, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0150598314587655e-05, 'l1_Layer_2': 0.0016637661714738817, 'l1_Layer_3': 0.006295651264248859, 'n_units_Layer_1': 230, 'n_units_Layer_2': 120, 'n_units_Layer_3': 170}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.79 | sMAPE for Validation Set is: 7.10% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.83 | sMAPE for Test Set is: 4.90% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:42:54,110]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:43:20,653]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:43:27,731]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:43:35,169]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:43:49,724]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:00,246]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:04,696]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:11,785]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:14,446]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:19,681]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:24,690]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:31,800]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:36,825]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:41,861]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:46,606]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:47,045]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:52,088]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:56,618]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:44:59,562]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:45:06,384]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:45:06,984]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:45:11,413]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:45:16,466]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:45:21,526]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:45:31,135]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:45:34,250]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:45:38,242]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:45:46,066]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:45:53,907]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:45:58,326]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:46:08,887]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:46:13,102]\u001b[0m Trial 1237 finished with value: 3.170856471958551 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019378135245904716, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09461298170867569, 'dropout_rate_Layer_2': 0.16342797296014883, 'dropout_rate_Layer_3': 0.09110606273950655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2528485812459195e-05, 'l1_Layer_2': 0.00011178756291613922, 'l1_Layer_3': 1.867653118901986e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.17 | sMAPE for Validation Set is: 8.00% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.13 | sMAPE for Test Set is: 5.57% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:46:13,477]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:46:20,521]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:47:05,849]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:47:10,573]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:47:12,339]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:47:17,217]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:47:23,032]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:47:27,860]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:47:32,484]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:47:44,951]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:47:54,256]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:47:59,907]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:48:04,893]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:48:14,436]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:48:21,821]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:48:44,382]\u001b[0m Trial 1247 finished with value: 3.118081471951092 and parameters: {'n_hidden': 3, 'learning_rate': 0.003400411673281206, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027166173413702196, 'dropout_rate_Layer_2': 0.30947332116314324, 'dropout_rate_Layer_3': 0.010405675254834794, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05003802432903264, 'l1_Layer_2': 0.09895165397433038, 'l1_Layer_3': 0.0002645237845559693, 'n_units_Layer_1': 255, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.12 | sMAPE for Validation Set is: 7.80% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.13% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:48:50,707]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:49:00,728]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:49:17,746]\u001b[0m Trial 1257 finished with value: 3.1471837419904154 and parameters: {'n_hidden': 3, 'learning_rate': 0.004643193433963801, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02605468368606133, 'dropout_rate_Layer_2': 0.3476044585991428, 'dropout_rate_Layer_3': 0.0074886647242448446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08412356578605337, 'l1_Layer_2': 0.09971008282835495, 'l1_Layer_3': 0.00022283049933478742, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.15 | sMAPE for Validation Set is: 7.89% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 5.34% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:50:01,698]\u001b[0m Trial 1260 finished with value: 2.86749570456741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009881953348358872, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10451885155633293, 'dropout_rate_Layer_2': 0.024177393821603714, 'dropout_rate_Layer_3': 0.3849178460427617, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046157229130797356, 'l1_Layer_2': 0.0009801783949898628, 'l1_Layer_3': 2.1008075317515062e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.87 | sMAPE for Validation Set is: 7.32% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 5.30% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:50:13,748]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:50:19,527]\u001b[0m Trial 1261 finished with value: 3.313053832746751 and parameters: {'n_hidden': 3, 'learning_rate': 0.007236097089677752, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04742002795847107, 'dropout_rate_Layer_2': 0.3547709513857108, 'dropout_rate_Layer_3': 0.00907728407421145, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04590382789171855, 'l1_Layer_2': 0.08346148593327832, 'l1_Layer_3': 0.000422522136592738, 'n_units_Layer_1': 265, 'n_units_Layer_2': 275, 'n_units_Layer_3': 145}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.31 | sMAPE for Validation Set is: 8.18% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.25 | sMAPE for Test Set is: 5.84% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:50:48,538]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:50:53,013]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:51:02,923]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:51:07,540]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:51:10,937]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:51:18,004]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:51:24,918]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:51:52,410]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:51:57,378]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:52:02,071]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:52:14,661]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:52:27,582]\u001b[0m Trial 1263 finished with value: 2.9949676400545147 and parameters: {'n_hidden': 3, 'learning_rate': 0.001062806215761311, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08539272000231174, 'dropout_rate_Layer_2': 0.023241913256149688, 'dropout_rate_Layer_3': 0.3687645916056132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003784238875421726, 'l1_Layer_2': 0.0005705224458943684, 'l1_Layer_3': 0.0049792533260307765, 'n_units_Layer_1': 190, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.99 | sMAPE for Validation Set is: 7.58% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.24% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:52:33,730]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:52:39,001]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:52:44,076]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:52:46,632]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:52:49,413]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:52:55,990]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:53:15,750]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:53:25,324]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:53:30,088]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:53:37,216]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:53:42,432]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:54:01,821]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:54:06,928]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:54:11,840]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:54:21,964]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:54:27,092]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:54:31,633]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:54:37,238]\u001b[0m Trial 1287 finished with value: 3.0974909704268754 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013865576645794493, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07120204664423793, 'dropout_rate_Layer_2': 0.20341036684837963, 'dropout_rate_Layer_3': 0.16719367401312768, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1306241788490873e-05, 'l1_Layer_2': 8.51331879181022e-05, 'l1_Layer_3': 1.2739106720984778e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.10 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.85 | sMAPE for Test Set is: 4.92% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:54:49,434]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:55:08,362]\u001b[0m Trial 1293 finished with value: 3.0949693224993937 and parameters: {'n_hidden': 3, 'learning_rate': 0.003677416767779248, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1325701863295844, 'dropout_rate_Layer_2': 0.21890246490494553, 'dropout_rate_Layer_3': 0.13412948228041383, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9441978442106927e-05, 'l1_Layer_2': 0.00016893715597967945, 'l1_Layer_3': 1.4444827848381285e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.09 | sMAPE for Validation Set is: 7.80% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.18% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:55:13,768]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:55:16,675]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:55:26,216]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:56:29,924]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:57:18,666]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:57:30,371]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:57:48,012]\u001b[0m Trial 1299 finished with value: 2.9136473741700084 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008968446582656181, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0752820030997948, 'dropout_rate_Layer_2': 0.025093794365125578, 'dropout_rate_Layer_3': 0.3788637655015833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001537513729475707, 'l1_Layer_2': 0.0006817589542375156, 'l1_Layer_3': 1.000512082045446e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 140, 'n_units_Layer_3': 140}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.91 | sMAPE for Validation Set is: 7.36% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.08% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:57:52,252]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:57:57,859]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:58:05,155]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:58:10,406]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:58:19,619]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:58:24,861]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:58:32,210]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:58:32,605]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:58:37,604]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:58:44,777]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:58:49,770]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:58:55,122]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:59:01,513]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:59:01,678]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:59:24,160]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:59:28,910]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:59:38,352]\u001b[0m Trial 1316 finished with value: 3.0023147564982122 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026211001607971277, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10652099049046607, 'dropout_rate_Layer_2': 0.1582949167680772, 'dropout_rate_Layer_3': 0.06902697374251412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5614606327888974e-05, 'l1_Layer_2': 6.780514645227512e-05, 'l1_Layer_3': 2.066224182925848e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 7.57% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.98% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 22:59:43,591]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:59:48,474]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 22:59:55,438]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:00:00,123]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:00:05,139]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:00:08,421]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:00:17,304]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:00:18,407]\u001b[0m Trial 1319 finished with value: 2.8971017552043694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025820267953152254, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10482510370682735, 'dropout_rate_Layer_2': 0.13252872838099722, 'dropout_rate_Layer_3': 0.11991987704371199, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.456110455400633e-05, 'l1_Layer_2': 7.177662392424942e-05, 'l1_Layer_3': 1.8689883651957426e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.90 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.85 | sMAPE for Test Set is: 4.92% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:00:25,467]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:00:25,602]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:00:33,697]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:00:34,022]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:00:41,703]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:00:41,884]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:00:56,984]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:01:09,550]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:01:16,580]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:01:33,925]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:01:39,059]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:01:39,470]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:01:51,432]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:01:58,986]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:02:06,224]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:02:08,830]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:02:15,642]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:02:18,887]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:02:55,680]\u001b[0m Trial 1345 finished with value: 2.8567869736051645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019667739613252423, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05770290319118862, 'dropout_rate_Layer_2': 0.13488158793626326, 'dropout_rate_Layer_3': 0.14996220039775632, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0632028256636636e-05, 'l1_Layer_2': 0.024889992859082263, 'l1_Layer_3': 4.7939437577585355e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 150, 'n_units_Layer_3': 155}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.86 | sMAPE for Validation Set is: 7.30% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.81 | sMAPE for Test Set is: 4.82% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:03:00,592]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:04:40,318]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:04:46,925]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:04:57,401]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:05:04,045]\u001b[0m Trial 1348 finished with value: 2.9269232221511046 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007272081008057547, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3995740568661376, 'dropout_rate_Layer_2': 0.025344564937349413, 'dropout_rate_Layer_3': 0.3583755048287428, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017618559672913793, 'l1_Layer_2': 0.001364211230093385, 'l1_Layer_3': 1.0110344766724321e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 115, 'n_units_Layer_3': 145}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.93 | sMAPE for Validation Set is: 7.44% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 5.04% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:05:18,892]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:05:33,901]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:05:38,563]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:05:40,831]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:05:45,844]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:05:50,993]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:05:56,296]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:06:07,809]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:06:14,146]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:06:53,736]\u001b[0m Trial 1361 finished with value: 3.0867822578987827 and parameters: {'n_hidden': 3, 'learning_rate': 0.0053967717052373155, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020077323995203254, 'dropout_rate_Layer_2': 0.32265467550004745, 'dropout_rate_Layer_3': 0.2021089645975973, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04749068663632293, 'l1_Layer_2': 0.06854039334187947, 'l1_Layer_3': 0.0002274346838274697, 'n_units_Layer_1': 265, 'n_units_Layer_2': 270, 'n_units_Layer_3': 135}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.09 | sMAPE for Validation Set is: 7.75% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 5.22% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:07:01,178]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:07:31,093]\u001b[0m Trial 1359 finished with value: 2.887208958142741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009264545897026999, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11801506592281491, 'dropout_rate_Layer_2': 0.014665164093931107, 'dropout_rate_Layer_3': 0.3897734304460476, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012764413375631058, 'l1_Layer_2': 0.0015072579418106908, 'l1_Layer_3': 1.6295782075589845e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 130, 'n_units_Layer_3': 150}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.89 | sMAPE for Validation Set is: 7.35% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.11% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:07:36,045]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:07:43,010]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:07:58,414]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:08:02,948]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:08:10,534]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:08:15,885]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:08:20,938]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:08:27,523]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:09:19,834]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:10:06,320]\u001b[0m Trial 1373 finished with value: 3.1122873453055013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026797974231516507, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07548293175097896, 'dropout_rate_Layer_2': 0.11880243928264024, 'dropout_rate_Layer_3': 0.06625335929887241, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6588268649060572e-05, 'l1_Layer_2': 0.00024049244434735305, 'l1_Layer_3': 1.703102538761716e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.11 | sMAPE for Validation Set is: 7.88% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.18% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:10:16,326]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:10:41,222]\u001b[0m Trial 1374 finished with value: 3.011092691368231 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030090737429700584, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.061190259115257835, 'dropout_rate_Layer_2': 0.1323043464238961, 'dropout_rate_Layer_3': 0.04211298380470607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2857135277510187e-05, 'l1_Layer_2': 0.00019700771071141766, 'l1_Layer_3': 1.893607488635571e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 75, 'n_units_Layer_3': 200}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.01 | sMAPE for Validation Set is: 7.64% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.83 | sMAPE for Test Set is: 4.89% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:10:45,793]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:10:51,554]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:05,567]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:09,024]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:35,451]\u001b[0m Trial 1377 finished with value: 2.9751383632255 and parameters: {'n_hidden': 3, 'learning_rate': 0.003018596411308717, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04437388706270244, 'dropout_rate_Layer_2': 0.1292614670005157, 'dropout_rate_Layer_3': 0.044293018963801105, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3680070503446297e-05, 'l1_Layer_2': 0.00018746253196797114, 'l1_Layer_3': 1.9423088151146688e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 50, 'n_units_Layer_3': 200}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.98 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 5.05% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:11:38,274]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:48,082]\u001b[0m Trial 1380 finished with value: 3.0618519516008966 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034049021265025563, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034939797179510124, 'dropout_rate_Layer_2': 0.12811478177664798, 'dropout_rate_Layer_3': 0.023927534516002127, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3664810411871423e-05, 'l1_Layer_2': 0.00020297596522094398, 'l1_Layer_3': 1.99547700544738e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 75, 'n_units_Layer_3': 200}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.06 | sMAPE for Validation Set is: 7.68% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.09% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:11:52,583]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:11:58,158]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:04,671]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:21,176]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:26,705]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:33,521]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:47,879]\u001b[0m Trial 1385 finished with value: 2.977086002031962 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029476357608683988, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05361785943595481, 'dropout_rate_Layer_2': 0.1516106474077264, 'dropout_rate_Layer_3': 0.04751342976944031, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1622339835779937e-05, 'l1_Layer_2': 0.0001597652019897846, 'l1_Layer_3': 1.5582735608839742e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.98 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.17% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:12:53,015]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:12:55,546]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:13:01,002]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:13:07,987]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:13:13,292]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:13:39,687]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:13:57,114]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:03,805]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:13,600]\u001b[0m Trial 1393 finished with value: 3.1852558443399785 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034041585825090506, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08927999184967522, 'dropout_rate_Layer_2': 0.3558891871277358, 'dropout_rate_Layer_3': 0.21754348280196661, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.047538270690363274, 'l1_Layer_2': 0.0442732031786806, 'l1_Layer_3': 0.0002592739081554586, 'n_units_Layer_1': 255, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.19 | sMAPE for Validation Set is: 8.01% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.01 | sMAPE for Test Set is: 5.31% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:14:16,802]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:24,105]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:28,912]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:33,766]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:38,850]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:46,488]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:51,594]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:14:55,555]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:15:03,703]\u001b[0m Trial 1401 finished with value: 3.092556800780127 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029533827747011826, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05871244052678842, 'dropout_rate_Layer_2': 0.14484533742880668, 'dropout_rate_Layer_3': 0.03283129116580654, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1634237971915627e-05, 'l1_Layer_2': 0.0001848752461049683, 'l1_Layer_3': 2.4125377784887544e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 65, 'n_units_Layer_3': 190}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.09 | sMAPE for Validation Set is: 7.76% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.08% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:15:08,071]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:15:18,782]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:15:43,223]\u001b[0m Trial 1410 finished with value: 3.1207530144029048 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018850866015809333, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.047658495791334646, 'dropout_rate_Layer_2': 0.13196547838606826, 'dropout_rate_Layer_3': 0.014220931840912415, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5365437946009243e-05, 'l1_Layer_2': 8.391385932688152e-05, 'l1_Layer_3': 3.2904859279328005e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.12 | sMAPE for Validation Set is: 7.92% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.17 | sMAPE for Test Set is: 5.69% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:16:08,570]\u001b[0m Trial 1409 finished with value: 3.0996629557352047 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029171870542460837, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10143042198802812, 'dropout_rate_Layer_2': 0.36348804286037856, 'dropout_rate_Layer_3': 0.20440659121472593, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03854865669242066, 'l1_Layer_2': 0.03137792865557604, 'l1_Layer_3': 0.0003734269265247889, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 120}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.10 | sMAPE for Validation Set is: 7.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 5.35% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:16:18,452]\u001b[0m Trial 1411 finished with value: 3.050040672327109 and parameters: {'n_hidden': 3, 'learning_rate': 0.002490669319509833, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01151716840864972, 'dropout_rate_Layer_2': 0.1702628015659693, 'dropout_rate_Layer_3': 0.0403324271243646, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.905557255704729e-05, 'l1_Layer_2': 0.00012175309298678087, 'l1_Layer_3': 1.7596962739986055e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 210}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.05 | sMAPE for Validation Set is: 7.68% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.98 | sMAPE for Test Set is: 5.23% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:16:22,893]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:27,455]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:32,518]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:43,029]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:45,673]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:16:55,948]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:02,574]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:07,694]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:12,784]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:17,632]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:22,125]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:25,297]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:32,213]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:40,154]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:44,948]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:49,814]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:17:59,738]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:05,418]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:25,298]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:29,560]\u001b[0m Trial 1426 finished with value: 2.814710202749881 and parameters: {'n_hidden': 3, 'learning_rate': 0.001410171019525252, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019523907015394817, 'dropout_rate_Layer_2': 0.19928791085630945, 'dropout_rate_Layer_3': 0.03136632810318663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.545621523920046e-05, 'l1_Layer_2': 0.0015907147993041225, 'l1_Layer_3': 0.0028146327049684847, 'n_units_Layer_1': 145, 'n_units_Layer_2': 170, 'n_units_Layer_3': 180}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.10% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 5.00% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:18:32,601]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:39,388]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:39,900]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:51,341]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:18:59,051]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:19:06,750]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:19:11,860]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:19:38,568]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:19:52,802]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:19:57,230]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:10,023]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:14,880]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:25,917]\u001b[0m Trial 1435 finished with value: 2.8294855491187096 and parameters: {'n_hidden': 3, 'learning_rate': 0.001835298223793771, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08900011078488032, 'dropout_rate_Layer_2': 0.02711382808688243, 'dropout_rate_Layer_3': 0.36593796807828016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000413713026900676, 'l1_Layer_2': 0.0009223828549322423, 'l1_Layer_3': 1.3781411830412944e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 265, 'n_units_Layer_3': 160}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.83 | sMAPE for Validation Set is: 7.25% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.16% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:20:30,315]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:37,283]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:42,351]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:49,700]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:20:58,764]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:03,704]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:04,304]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:11,984]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:12,680]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:19,997]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:20,717]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:28,740]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:38,952]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:43,774]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:48,698]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:54,101]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:21:59,132]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:05,736]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:18,439]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:22,814]\u001b[0m Trial 1457 finished with value: 2.768082598343464 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012198965574725302, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026618119328489877, 'dropout_rate_Layer_2': 0.18212465170813988, 'dropout_rate_Layer_3': 0.21276559764165842, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.921038781624455e-05, 'l1_Layer_2': 0.002085123929515227, 'l1_Layer_3': 0.0020952060222329846, 'n_units_Layer_1': 230, 'n_units_Layer_2': 155, 'n_units_Layer_3': 185}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.77 | sMAPE for Validation Set is: 7.01% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.83 | sMAPE for Test Set is: 4.88% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:22:27,661]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:40,828]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:47,724]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:22:55,271]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:00,049]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:04,924]\u001b[0m Trial 1467 finished with value: 3.04518471173512 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041141163162893785, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09845365493592939, 'dropout_rate_Layer_2': 0.1885052331116931, 'dropout_rate_Layer_3': 0.06744790005030897, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0117350945116282e-05, 'l1_Layer_2': 0.00023818178738363953, 'l1_Layer_3': 1.5176469028218785e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 835 with value: 2.729089683838175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.05 | sMAPE for Validation Set is: 7.73% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 5.00% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-31 23:23:11,871]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:12,014]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:19,321]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:22,078]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:24,437]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:27,036]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:31,602]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:35,815]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:36,463]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:42,466]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:47,047]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:47,189]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:23:54,957]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:00,103]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:04,226]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:24,741]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:31,126]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:34,554]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:24:53,929]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:04,134]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:08,599]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:18,670]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:23,718]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:26,289]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:31,122]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:33,623]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:40,338]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:45,171]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-31 23:25:48,425]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-01-01, MAE is:2.05 & sMAPE is:4.30% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 4.30% & 1.33\n",
      "for 2019-01-02, MAE is:1.97 & sMAPE is:3.83% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.01 & 4.07% & 1.32\n",
      "for 2019-01-03, MAE is:4.73 & sMAPE is:8.09% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.91 & 5.41% & 1.17\n",
      "for 2019-01-04, MAE is:3.03 & sMAPE is:5.69% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 5.48% & 1.20\n",
      "for 2019-01-05, MAE is:2.15 & sMAPE is:4.28% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.78 & 5.24% & 1.21\n",
      "for 2019-01-06, MAE is:1.14 & sMAPE is:2.23% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 4.74% & 1.14\n",
      "for 2019-01-07, MAE is:1.75 & sMAPE is:3.36% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.54% & 1.07\n",
      "for 2019-01-08, MAE is:1.09 & sMAPE is:2.22% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 4.25% & 1.02\n",
      "for 2019-01-09, MAE is:1.78 & sMAPE is:3.57% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 4.18% & 1.15\n",
      "for 2019-01-10, MAE is:7.74 & sMAPE is:12.56% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.74 & 5.01% & 1.14\n",
      "for 2019-01-11, MAE is:2.98 & sMAPE is:5.80% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.76 & 5.09% & 1.25\n",
      "for 2019-01-12, MAE is:1.59 & sMAPE is:3.26% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.67 & 4.93% & 1.24\n",
      "for 2019-01-13, MAE is:1.86 & sMAPE is:3.80% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :2.60 & 4.85% & 1.21\n",
      "for 2019-01-14, MAE is:1.85 & sMAPE is:3.59% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 4.76% & 1.18\n",
      "for 2019-01-15, MAE is:1.13 & sMAPE is:2.16% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 4.58% & 1.13\n",
      "for 2019-01-16, MAE is:1.71 & sMAPE is:3.27% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 4.50% & 1.10\n",
      "for 2019-01-17, MAE is:1.53 & sMAPE is:2.85% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 4.40% & 1.05\n",
      "for 2019-01-18, MAE is:8.58 & sMAPE is:14.21% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.70 & 4.95% & 1.03\n",
      "for 2019-01-19, MAE is:2.31 & sMAPE is:4.23% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.68 & 4.91% & 1.00\n",
      "for 2019-01-20, MAE is:3.27 & sMAPE is:5.82% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.71 & 4.96% & 0.98\n",
      "for 2019-01-21, MAE is:11.29 & sMAPE is:16.44% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 5.50% & 0.96\n",
      "for 2019-01-22, MAE is:5.94 & sMAPE is:9.16% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 5.67% & 0.94\n",
      "for 2019-01-23, MAE is:12.95 & sMAPE is:19.22% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 6.26% & 0.94\n",
      "for 2019-01-24, MAE is:19.76 & sMAPE is:25.52% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 7.06% & 0.93\n",
      "for 2019-01-25, MAE is:6.88 & sMAPE is:10.04% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 7.18% & 0.94\n",
      "for 2019-01-26, MAE is:1.75 & sMAPE is:3.18% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 7.03% & 0.94\n",
      "for 2019-01-27, MAE is:2.15 & sMAPE is:4.05% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 6.92% & 0.93\n",
      "for 2019-01-28, MAE is:2.35 & sMAPE is:4.12% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 6.82% & 0.91\n",
      "for 2019-01-29, MAE is:6.57 & sMAPE is:10.58% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 6.95% & 0.94\n",
      "for 2019-01-30, MAE is:3.76 & sMAPE is:6.42% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 6.93% & 0.93\n",
      "for 2019-01-31, MAE is:3.18 & sMAPE is:5.42% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 6.88% & 0.90\n",
      "for 2019-02-01, MAE is:1.72 & sMAPE is:3.10% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 6.76% & 0.88\n",
      "for 2019-02-02, MAE is:2.11 & sMAPE is:3.99% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 6.68% & 0.87\n",
      "for 2019-02-03, MAE is:1.55 & sMAPE is:3.07% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 6.57% & 0.87\n",
      "for 2019-02-04, MAE is:2.28 & sMAPE is:4.17% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 6.50% & 0.87\n",
      "for 2019-02-05, MAE is:1.03 & sMAPE is:1.97% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 6.38% & 0.85\n",
      "for 2019-02-06, MAE is:2.53 & sMAPE is:4.62% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 6.33% & 0.84\n",
      "for 2019-02-07, MAE is:2.08 & sMAPE is:4.06% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 6.27% & 0.83\n",
      "for 2019-02-08, MAE is:1.78 & sMAPE is:3.61% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.74 & 6.20% & 0.82\n",
      "for 2019-02-09, MAE is:1.68 & sMAPE is:3.57% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 6.14% & 0.81\n",
      "for 2019-02-10, MAE is:1.73 & sMAPE is:3.69% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 6.08% & 0.80\n",
      "for 2019-02-11, MAE is:1.43 & sMAPE is:3.02% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 6.00% & 0.79\n",
      "for 2019-02-12, MAE is:1.04 & sMAPE is:2.15% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 5.91% & 0.78\n",
      "for 2019-02-13, MAE is:1.41 & sMAPE is:3.03% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 5.85% & 0.77\n",
      "for 2019-02-14, MAE is:1.48 & sMAPE is:3.23% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 5.79% & 0.76\n",
      "for 2019-02-15, MAE is:1.38 & sMAPE is:3.11% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 5.73% & 0.74\n",
      "for 2019-02-16, MAE is:2.29 & sMAPE is:5.21% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 5.72% & 0.74\n",
      "for 2019-02-17, MAE is:1.38 & sMAPE is:3.18% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 5.67% & 0.73\n",
      "for 2019-02-18, MAE is:1.00 & sMAPE is:2.26% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 5.60% & 0.72\n",
      "for 2019-02-19, MAE is:1.31 & sMAPE is:3.00% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.24 & 5.55% & 0.71\n",
      "for 2019-02-20, MAE is:1.14 & sMAPE is:2.60% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 5.49% & 0.71\n",
      "for 2019-02-21, MAE is:1.08 & sMAPE is:2.47% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.16 & 5.43% & 0.71\n",
      "for 2019-02-22, MAE is:1.30 & sMAPE is:2.99% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 5.38% & 0.74\n",
      "for 2019-02-23, MAE is:2.10 & sMAPE is:4.97% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 5.38% & 0.75\n",
      "for 2019-02-24, MAE is:1.34 & sMAPE is:3.27% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 5.34% & 0.76\n",
      "for 2019-02-25, MAE is:1.71 & sMAPE is:4.00% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 5.31% & 0.76\n",
      "for 2019-02-26, MAE is:1.07 & sMAPE is:2.52% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.01 & 5.27% & 0.77\n",
      "for 2019-02-27, MAE is:1.87 & sMAPE is:4.42% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 5.25% & 0.77\n",
      "for 2019-02-28, MAE is:1.26 & sMAPE is:3.02% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 5.21% & 0.77\n",
      "for 2019-03-01, MAE is:2.78 & sMAPE is:6.37% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 5.23% & 0.79\n",
      "for 2019-03-02, MAE is:1.84 & sMAPE is:4.25% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 5.22% & 0.79\n",
      "for 2019-03-03, MAE is:1.48 & sMAPE is:3.55% & rMAE is:3.08 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 5.19% & 0.83\n",
      "for 2019-03-04, MAE is:0.96 & sMAPE is:2.31% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.89 & 5.14% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-05, MAE is:1.75 & sMAPE is:3.98% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.87 & 5.13% & 0.84\n",
      "for 2019-03-06, MAE is:1.87 & sMAPE is:4.27% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.86 & 5.11% & 0.83\n",
      "for 2019-03-07, MAE is:1.90 & sMAPE is:4.38% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.84 & 5.10% & 0.83\n",
      "for 2019-03-08, MAE is:1.49 & sMAPE is:3.45% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 5.08% & 0.83\n",
      "for 2019-03-09, MAE is:1.31 & sMAPE is:3.13% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.80 & 5.05% & 0.84\n",
      "for 2019-03-10, MAE is:1.95 & sMAPE is:4.51% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 5.04% & 0.84\n",
      "for 2019-03-11, MAE is:1.94 & sMAPE is:4.34% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.77 & 5.03% & 0.84\n",
      "for 2019-03-12, MAE is:1.96 & sMAPE is:4.30% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.76 & 5.02% & 0.84\n",
      "for 2019-03-13, MAE is:1.18 & sMAPE is:2.73% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.74 & 4.99% & 0.83\n",
      "for 2019-03-14, MAE is:1.24 & sMAPE is:2.87% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.72 & 4.96% & 0.83\n",
      "for 2019-03-15, MAE is:1.21 & sMAPE is:2.90% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.70 & 4.93% & 0.84\n",
      "for 2019-03-16, MAE is:1.35 & sMAPE is:3.33% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.68 & 4.91% & 0.84\n",
      "for 2019-03-17, MAE is:0.99 & sMAPE is:2.47% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.66 & 4.88% & 0.83\n",
      "for 2019-03-18, MAE is:1.26 & sMAPE is:3.04% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.64 & 4.85% & 0.82\n",
      "for 2019-03-19, MAE is:3.63 & sMAPE is:7.78% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.65 & 4.89% & 0.83\n",
      "for 2019-03-20, MAE is:2.67 & sMAPE is:6.10% & rMAE is:3.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.65 & 4.91% & 0.86\n",
      "for 2019-03-21, MAE is:2.24 & sMAPE is:5.38% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.65 & 4.91% & 0.86\n",
      "for 2019-03-22, MAE is:2.37 & sMAPE is:5.67% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.65 & 4.92% & 0.86\n",
      "for 2019-03-23, MAE is:1.66 & sMAPE is:4.27% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.63 & 4.91% & 0.86\n",
      "for 2019-03-24, MAE is:1.52 & sMAPE is:3.98% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :2.62 & 4.90% & 0.86\n",
      "for 2019-03-25, MAE is:1.36 & sMAPE is:3.50% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.61 & 4.89% & 0.86\n",
      "for 2019-03-26, MAE is:1.41 & sMAPE is:3.44% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.59 & 4.87% & 0.85\n",
      "for 2019-03-27, MAE is:1.54 & sMAPE is:3.79% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :2.58 & 4.86% & 0.85\n",
      "for 2019-03-28, MAE is:0.83 & sMAPE is:2.08% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 4.82% & 0.85\n",
      "for 2019-03-29, MAE is:2.50 & sMAPE is:6.10% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 4.84% & 0.86\n",
      "for 2019-03-30, MAE is:1.47 & sMAPE is:3.82% & rMAE is:3.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 4.83% & 0.90\n",
      "for 2019-03-31, MAE is:1.39 & sMAPE is:3.63% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 4.81% & 0.91\n",
      "for 2019-04-01, MAE is:2.13 & sMAPE is:5.24% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 4.82% & 0.92\n",
      "for 2019-04-02, MAE is:1.33 & sMAPE is:3.38% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 4.80% & 0.92\n",
      "for 2019-04-03, MAE is:2.07 & sMAPE is:5.01% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 4.81% & 0.92\n",
      "for 2019-04-04, MAE is:2.37 & sMAPE is:5.93% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 4.82% & 0.93\n",
      "for 2019-04-05, MAE is:1.16 & sMAPE is:2.95% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 4.80% & 0.93\n",
      "for 2019-04-06, MAE is:1.53 & sMAPE is:3.94% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 4.79% & 0.93\n",
      "for 2019-04-07, MAE is:1.81 & sMAPE is:4.63% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 4.79% & 0.93\n",
      "for 2019-04-08, MAE is:1.12 & sMAPE is:2.71% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 4.77% & 0.93\n",
      "for 2019-04-09, MAE is:2.59 & sMAPE is:6.15% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 4.78% & 0.93\n",
      "for 2019-04-10, MAE is:3.13 & sMAPE is:7.15% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 4.80% & 0.93\n",
      "for 2019-04-11, MAE is:5.74 & sMAPE is:12.85% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 4.88% & 0.93\n",
      "for 2019-04-12, MAE is:2.40 & sMAPE is:5.07% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 4.89% & 0.92\n",
      "for 2019-04-13, MAE is:1.44 & sMAPE is:3.38% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 4.87% & 0.92\n",
      "for 2019-04-14, MAE is:1.44 & sMAPE is:3.45% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 4.86% & 0.91\n",
      "for 2019-04-15, MAE is:1.81 & sMAPE is:4.04% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 4.85% & 0.91\n",
      "for 2019-04-16, MAE is:2.06 & sMAPE is:4.71% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 4.85% & 0.91\n",
      "for 2019-04-17, MAE is:1.41 & sMAPE is:3.28% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 4.83% & 0.91\n",
      "for 2019-04-18, MAE is:1.79 & sMAPE is:4.22% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 4.83% & 0.91\n",
      "for 2019-04-19, MAE is:1.21 & sMAPE is:2.89% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 4.81% & 0.90\n",
      "for 2019-04-20, MAE is:1.19 & sMAPE is:2.84% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 4.79% & 0.90\n",
      "for 2019-04-21, MAE is:1.52 & sMAPE is:3.72% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 4.78% & 0.90\n",
      "for 2019-04-22, MAE is:1.32 & sMAPE is:3.22% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 4.77% & 0.89\n",
      "for 2019-04-23, MAE is:1.39 & sMAPE is:3.46% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 4.76% & 0.89\n",
      "for 2019-04-24, MAE is:1.99 & sMAPE is:5.02% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.76% & 0.88\n",
      "for 2019-04-25, MAE is:2.18 & sMAPE is:5.48% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.77% & 0.88\n",
      "for 2019-04-26, MAE is:2.09 & sMAPE is:5.20% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.77% & 0.88\n",
      "for 2019-04-27, MAE is:5.78 & sMAPE is:16.38% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 4.87% & 0.88\n",
      "for 2019-04-28, MAE is:3.32 & sMAPE is:9.56% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 4.91% & 0.88\n",
      "for 2019-04-29, MAE is:1.36 & sMAPE is:3.42% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 4.90% & 0.88\n",
      "for 2019-04-30, MAE is:1.97 & sMAPE is:5.02% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 4.90% & 0.88\n",
      "for 2019-05-01, MAE is:2.24 & sMAPE is:6.29% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 4.91% & 0.87\n",
      "for 2019-05-02, MAE is:2.09 & sMAPE is:5.81% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 4.92% & 0.87\n",
      "for 2019-05-03, MAE is:1.52 & sMAPE is:3.85% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 4.91% & 0.87\n",
      "for 2019-05-04, MAE is:1.60 & sMAPE is:3.93% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.90% & 0.87\n",
      "for 2019-05-05, MAE is:0.95 & sMAPE is:2.35% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 4.88% & 0.86\n",
      "for 2019-05-06, MAE is:1.48 & sMAPE is:3.51% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 4.87% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-07, MAE is:1.07 & sMAPE is:2.52% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 4.85% & 0.85\n",
      "for 2019-05-08, MAE is:2.38 & sMAPE is:5.50% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 4.85% & 0.85\n",
      "for 2019-05-09, MAE is:1.82 & sMAPE is:4.31% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 4.85% & 0.85\n",
      "for 2019-05-10, MAE is:1.27 & sMAPE is:2.93% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 4.84% & 0.84\n",
      "for 2019-05-11, MAE is:1.64 & sMAPE is:3.91% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 4.83% & 0.84\n",
      "for 2019-05-12, MAE is:1.45 & sMAPE is:3.52% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 4.82% & 0.85\n",
      "for 2019-05-13, MAE is:1.70 & sMAPE is:3.95% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 4.81% & 0.85\n",
      "for 2019-05-14, MAE is:1.63 & sMAPE is:3.71% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 4.80% & 0.86\n",
      "for 2019-05-15, MAE is:1.23 & sMAPE is:2.90% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 4.79% & 0.86\n",
      "for 2019-05-16, MAE is:2.22 & sMAPE is:5.54% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 4.79% & 0.86\n",
      "for 2019-05-17, MAE is:1.45 & sMAPE is:3.68% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 4.79% & 0.86\n",
      "for 2019-05-18, MAE is:2.90 & sMAPE is:7.56% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 4.81% & 0.86\n",
      "for 2019-05-19, MAE is:3.06 & sMAPE is:8.01% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 4.83% & 0.86\n",
      "for 2019-05-20, MAE is:2.90 & sMAPE is:7.13% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 4.85% & 0.86\n",
      "for 2019-05-21, MAE is:2.12 & sMAPE is:5.55% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 4.85% & 0.86\n",
      "for 2019-05-22, MAE is:2.74 & sMAPE is:7.38% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 4.87% & 0.86\n",
      "for 2019-05-23, MAE is:2.20 & sMAPE is:5.87% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 4.88% & 0.86\n",
      "for 2019-05-24, MAE is:2.56 & sMAPE is:6.57% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 4.89% & 0.86\n",
      "for 2019-05-25, MAE is:1.81 & sMAPE is:5.00% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 4.89% & 0.86\n",
      "for 2019-05-26, MAE is:5.52 & sMAPE is:18.87% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 4.98% & 0.86\n",
      "for 2019-05-27, MAE is:3.00 & sMAPE is:8.48% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 5.01% & 0.86\n",
      "for 2019-05-28, MAE is:1.11 & sMAPE is:2.97% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 4.99% & 0.85\n",
      "for 2019-05-29, MAE is:1.46 & sMAPE is:3.93% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 4.99% & 0.85\n",
      "for 2019-05-30, MAE is:5.12 & sMAPE is:15.35% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 5.06% & 0.85\n",
      "for 2019-05-31, MAE is:2.09 & sMAPE is:5.89% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 5.06% & 0.85\n",
      "for 2019-06-01, MAE is:3.68 & sMAPE is:10.67% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 5.10% & 0.86\n",
      "for 2019-06-02, MAE is:4.09 & sMAPE is:12.90% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 5.15% & 0.86\n",
      "for 2019-06-03, MAE is:4.15 & sMAPE is:13.24% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 5.20% & 0.86\n",
      "for 2019-06-04, MAE is:2.39 & sMAPE is:6.72% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 5.21% & 0.86\n",
      "for 2019-06-05, MAE is:2.36 & sMAPE is:7.92% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 5.23% & 0.86\n",
      "for 2019-06-06, MAE is:2.53 & sMAPE is:8.32% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 5.25% & 0.86\n",
      "for 2019-06-07, MAE is:1.43 & sMAPE is:4.71% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 5.25% & 0.86\n",
      "for 2019-06-08, MAE is:13.10 & sMAPE is:66.39% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 5.63% & 0.86\n",
      "for 2019-06-09, MAE is:7.64 & sMAPE is:33.04% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 5.80% & 0.86\n",
      "for 2019-06-10, MAE is:1.75 & sMAPE is:5.84% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 5.80% & 0.86\n",
      "for 2019-06-11, MAE is:2.44 & sMAPE is:7.78% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 5.81% & 0.86\n",
      "for 2019-06-12, MAE is:1.71 & sMAPE is:5.35% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 5.81% & 0.85\n",
      "for 2019-06-13, MAE is:2.28 & sMAPE is:7.62% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 5.82% & 0.86\n",
      "for 2019-06-14, MAE is:1.56 & sMAPE is:4.96% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 5.82% & 0.86\n",
      "for 2019-06-15, MAE is:1.62 & sMAPE is:5.95% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 5.82% & 0.86\n",
      "for 2019-06-16, MAE is:1.81 & sMAPE is:6.46% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 5.82% & 0.86\n",
      "for 2019-06-17, MAE is:1.33 & sMAPE is:4.26% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 5.81% & 0.86\n",
      "for 2019-06-18, MAE is:1.10 & sMAPE is:3.40% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 5.80% & 0.86\n",
      "for 2019-06-19, MAE is:2.38 & sMAPE is:7.50% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 5.81% & 0.87\n",
      "for 2019-06-20, MAE is:1.54 & sMAPE is:4.88% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.80% & 0.87\n",
      "for 2019-06-21, MAE is:1.54 & sMAPE is:5.11% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.80% & 0.87\n",
      "for 2019-06-22, MAE is:1.16 & sMAPE is:3.89% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 5.79% & 0.86\n",
      "for 2019-06-23, MAE is:3.09 & sMAPE is:11.35% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 5.82% & 0.87\n",
      "for 2019-06-24, MAE is:2.36 & sMAPE is:7.71% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 5.83% & 0.87\n",
      "for 2019-06-25, MAE is:3.08 & sMAPE is:10.01% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.85% & 0.88\n",
      "for 2019-06-26, MAE is:2.46 & sMAPE is:7.91% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.87% & 0.88\n",
      "for 2019-06-27, MAE is:2.36 & sMAPE is:9.02% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.88% & 0.88\n",
      "for 2019-06-28, MAE is:1.90 & sMAPE is:6.29% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 5.89% & 0.89\n",
      "for 2019-06-29, MAE is:2.05 & sMAPE is:7.32% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 5.89% & 0.89\n",
      "for 2019-06-30, MAE is:4.60 & sMAPE is:20.30% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.97% & 0.89\n",
      "for 2019-07-01, MAE is:1.21 & sMAPE is:4.33% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.96% & 0.88\n",
      "for 2019-07-02, MAE is:2.04 & sMAPE is:7.70% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.97% & 0.88\n",
      "for 2019-07-03, MAE is:1.80 & sMAPE is:6.23% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 5.98% & 0.88\n",
      "for 2019-07-04, MAE is:1.18 & sMAPE is:4.18% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 5.97% & 0.88\n",
      "for 2019-07-05, MAE is:1.98 & sMAPE is:6.91% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 5.97% & 0.88\n",
      "for 2019-07-06, MAE is:1.49 & sMAPE is:5.35% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 5.97% & 0.88\n",
      "for 2019-07-07, MAE is:1.54 & sMAPE is:5.51% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.96% & 0.88\n",
      "for 2019-07-08, MAE is:1.22 & sMAPE is:3.96% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.95% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-09, MAE is:3.43 & sMAPE is:10.84% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.98% & 0.87\n",
      "for 2019-07-10, MAE is:2.26 & sMAPE is:7.10% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.99% & 0.87\n",
      "for 2019-07-11, MAE is:2.15 & sMAPE is:6.39% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.99% & 0.87\n",
      "for 2019-07-12, MAE is:3.61 & sMAPE is:10.41% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 6.01% & 0.87\n",
      "for 2019-07-13, MAE is:3.14 & sMAPE is:9.01% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 6.03% & 0.86\n",
      "for 2019-07-14, MAE is:2.06 & sMAPE is:5.82% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 6.03% & 0.86\n",
      "for 2019-07-15, MAE is:1.35 & sMAPE is:3.67% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 6.01% & 0.86\n",
      "for 2019-07-16, MAE is:1.62 & sMAPE is:4.41% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 6.00% & 0.86\n",
      "for 2019-07-17, MAE is:1.76 & sMAPE is:4.73% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 6.00% & 0.85\n",
      "for 2019-07-18, MAE is:1.09 & sMAPE is:2.88% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 5.98% & 0.85\n",
      "for 2019-07-19, MAE is:1.10 & sMAPE is:3.01% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 5.97% & 0.85\n",
      "for 2019-07-20, MAE is:1.96 & sMAPE is:5.29% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 5.96% & 0.86\n",
      "for 2019-07-21, MAE is:1.51 & sMAPE is:4.27% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 5.96% & 0.86\n",
      "for 2019-07-22, MAE is:0.80 & sMAPE is:2.15% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 5.94% & 0.86\n",
      "for 2019-07-23, MAE is:1.09 & sMAPE is:2.96% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 5.92% & 0.86\n",
      "for 2019-07-24, MAE is:1.76 & sMAPE is:4.77% & rMAE is:4.08 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 5.92% & 0.88\n",
      "for 2019-07-25, MAE is:1.81 & sMAPE is:4.80% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 5.91% & 0.89\n",
      "for 2019-07-26, MAE is:1.06 & sMAPE is:2.70% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 5.90% & 0.89\n",
      "for 2019-07-27, MAE is:1.27 & sMAPE is:3.44% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 5.88% & 0.89\n",
      "for 2019-07-28, MAE is:2.39 & sMAPE is:7.04% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 5.89% & 0.89\n",
      "for 2019-07-29, MAE is:0.83 & sMAPE is:2.19% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 5.87% & 0.89\n",
      "for 2019-07-30, MAE is:1.70 & sMAPE is:4.42% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 5.87% & 0.89\n",
      "for 2019-07-31, MAE is:0.59 & sMAPE is:1.51% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 5.84% & 0.89\n",
      "for 2019-08-01, MAE is:1.02 & sMAPE is:2.67% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 5.83% & 0.89\n",
      "for 2019-08-02, MAE is:0.72 & sMAPE is:1.81% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 5.81% & 0.89\n",
      "for 2019-08-03, MAE is:1.19 & sMAPE is:3.17% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 5.80% & 0.89\n",
      "for 2019-08-04, MAE is:0.91 & sMAPE is:2.36% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 5.78% & 0.88\n",
      "for 2019-08-05, MAE is:0.77 & sMAPE is:1.93% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 5.77% & 0.88\n",
      "for 2019-08-06, MAE is:0.62 & sMAPE is:1.57% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 5.75% & 0.88\n",
      "for 2019-08-07, MAE is:1.21 & sMAPE is:3.06% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.73% & 0.89\n",
      "for 2019-08-08, MAE is:1.43 & sMAPE is:3.71% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.72% & 0.89\n",
      "for 2019-08-09, MAE is:1.28 & sMAPE is:3.43% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.71% & 0.89\n",
      "for 2019-08-10, MAE is:1.27 & sMAPE is:3.70% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.71% & 0.88\n",
      "for 2019-08-11, MAE is:5.56 & sMAPE is:22.06% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.78% & 0.88\n",
      "for 2019-08-12, MAE is:1.74 & sMAPE is:5.17% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.78% & 0.88\n",
      "for 2019-08-13, MAE is:1.17 & sMAPE is:3.20% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.76% & 0.88\n",
      "for 2019-08-14, MAE is:1.60 & sMAPE is:4.74% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.76% & 0.87\n",
      "for 2019-08-15, MAE is:2.75 & sMAPE is:8.29% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.77% & 0.87\n",
      "for 2019-08-16, MAE is:1.56 & sMAPE is:4.73% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.77% & 0.87\n",
      "for 2019-08-17, MAE is:3.25 & sMAPE is:12.65% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.80% & 0.87\n",
      "for 2019-08-18, MAE is:1.64 & sMAPE is:4.95% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.79% & 0.87\n",
      "for 2019-08-19, MAE is:2.15 & sMAPE is:6.64% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.80% & 0.87\n",
      "for 2019-08-20, MAE is:1.26 & sMAPE is:3.79% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.79% & 0.87\n",
      "for 2019-08-21, MAE is:0.83 & sMAPE is:2.40% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.27 & 5.77% & 0.87\n",
      "for 2019-08-22, MAE is:1.65 & sMAPE is:4.93% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.27 & 5.77% & 0.87\n",
      "for 2019-08-23, MAE is:1.00 & sMAPE is:3.07% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 5.76% & 0.87\n",
      "for 2019-08-24, MAE is:0.82 & sMAPE is:2.59% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 5.74% & 0.86\n",
      "for 2019-08-25, MAE is:0.82 & sMAPE is:2.48% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 5.73% & 0.86\n",
      "for 2019-08-26, MAE is:0.65 & sMAPE is:1.94% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 5.72% & 0.86\n",
      "for 2019-08-27, MAE is:1.11 & sMAPE is:3.27% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 5.70% & 0.86\n",
      "for 2019-08-28, MAE is:0.91 & sMAPE is:2.76% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.69% & 0.86\n",
      "for 2019-08-29, MAE is:1.47 & sMAPE is:4.40% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.69% & 0.86\n",
      "for 2019-08-30, MAE is:0.86 & sMAPE is:2.74% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.67% & 0.86\n",
      "for 2019-08-31, MAE is:0.98 & sMAPE is:3.33% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.67% & 0.86\n",
      "for 2019-09-01, MAE is:1.41 & sMAPE is:4.73% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.66% & 0.86\n",
      "for 2019-09-02, MAE is:1.95 & sMAPE is:6.33% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.66% & 0.86\n",
      "for 2019-09-03, MAE is:1.85 & sMAPE is:6.21% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 5.67% & 0.86\n",
      "for 2019-09-04, MAE is:0.80 & sMAPE is:2.61% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 5.65% & 0.85\n",
      "for 2019-09-05, MAE is:2.31 & sMAPE is:7.86% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 5.66% & 0.85\n",
      "for 2019-09-06, MAE is:1.31 & sMAPE is:4.59% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.66% & 0.85\n",
      "for 2019-09-07, MAE is:0.96 & sMAPE is:3.25% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.65% & 0.85\n",
      "for 2019-09-08, MAE is:1.99 & sMAPE is:6.62% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.65% & 0.85\n",
      "for 2019-09-09, MAE is:1.65 & sMAPE is:5.28% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.65% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-10, MAE is:1.04 & sMAPE is:3.31% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.64% & 0.85\n",
      "for 2019-09-11, MAE is:1.52 & sMAPE is:4.97% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.64% & 0.86\n",
      "for 2019-09-12, MAE is:0.58 & sMAPE is:2.01% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.63% & 0.86\n",
      "for 2019-09-13, MAE is:1.09 & sMAPE is:3.64% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.62% & 0.85\n",
      "for 2019-09-14, MAE is:1.03 & sMAPE is:3.72% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.17 & 5.61% & 0.85\n",
      "for 2019-09-15, MAE is:4.12 & sMAPE is:18.82% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.66% & 0.85\n",
      "for 2019-09-16, MAE is:5.41 & sMAPE is:25.97% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.74% & 0.85\n",
      "for 2019-09-17, MAE is:2.62 & sMAPE is:9.35% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.75% & 0.85\n",
      "for 2019-09-18, MAE is:1.30 & sMAPE is:4.55% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.75% & 0.85\n",
      "for 2019-09-19, MAE is:0.74 & sMAPE is:2.50% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.74% & 0.85\n",
      "for 2019-09-20, MAE is:0.88 & sMAPE is:3.10% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.73% & 0.85\n",
      "for 2019-09-21, MAE is:2.18 & sMAPE is:7.58% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.73% & 0.85\n",
      "for 2019-09-22, MAE is:1.85 & sMAPE is:6.33% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.74% & 0.85\n",
      "for 2019-09-23, MAE is:1.01 & sMAPE is:3.32% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.73% & 0.85\n",
      "for 2019-09-24, MAE is:0.77 & sMAPE is:2.47% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.17 & 5.71% & 0.85\n",
      "for 2019-09-25, MAE is:0.74 & sMAPE is:2.39% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.17 & 5.70% & 0.84\n",
      "for 2019-09-26, MAE is:0.91 & sMAPE is:2.88% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 5.69% & 0.84\n",
      "for 2019-09-27, MAE is:1.74 & sMAPE is:5.46% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 5.69% & 0.84\n",
      "for 2019-09-28, MAE is:0.99 & sMAPE is:3.20% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 5.68% & 0.84\n",
      "for 2019-09-29, MAE is:2.10 & sMAPE is:6.92% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 5.69% & 0.84\n",
      "for 2019-09-30, MAE is:1.74 & sMAPE is:5.48% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 5.69% & 0.84\n",
      "for 2019-10-01, MAE is:1.01 & sMAPE is:3.03% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 5.68% & 0.84\n",
      "for 2019-10-02, MAE is:2.18 & sMAPE is:6.35% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 5.68% & 0.84\n",
      "for 2019-10-03, MAE is:1.44 & sMAPE is:4.08% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 5.67% & 0.84\n",
      "for 2019-10-04, MAE is:1.06 & sMAPE is:2.93% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.66% & 0.84\n",
      "for 2019-10-05, MAE is:1.03 & sMAPE is:2.85% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.65% & 0.83\n",
      "for 2019-10-06, MAE is:0.92 & sMAPE is:2.54% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.64% & 0.83\n",
      "for 2019-10-07, MAE is:4.94 & sMAPE is:11.82% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.66% & 0.83\n",
      "for 2019-10-08, MAE is:1.78 & sMAPE is:4.66% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.66% & 0.83\n",
      "for 2019-10-09, MAE is:3.09 & sMAPE is:8.08% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 5.67% & 0.83\n",
      "for 2019-10-10, MAE is:1.41 & sMAPE is:3.89% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.66% & 0.83\n",
      "for 2019-10-11, MAE is:0.70 & sMAPE is:2.10% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.65% & 0.83\n",
      "for 2019-10-12, MAE is:2.35 & sMAPE is:7.27% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.66% & 0.83\n",
      "for 2019-10-13, MAE is:1.29 & sMAPE is:3.88% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.65% & 0.83\n",
      "for 2019-10-14, MAE is:0.68 & sMAPE is:1.98% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.64% & 0.83\n",
      "for 2019-10-15, MAE is:0.95 & sMAPE is:2.80% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.63% & 0.83\n",
      "for 2019-10-16, MAE is:1.04 & sMAPE is:2.99% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.62% & 0.83\n",
      "for 2019-10-17, MAE is:2.03 & sMAPE is:5.68% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.62% & 0.83\n",
      "for 2019-10-18, MAE is:2.05 & sMAPE is:5.66% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.62% & 0.83\n",
      "for 2019-10-19, MAE is:1.59 & sMAPE is:4.63% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.61% & 0.83\n",
      "for 2019-10-20, MAE is:2.30 & sMAPE is:6.47% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.62% & 0.83\n",
      "for 2019-10-21, MAE is:0.80 & sMAPE is:2.14% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.61% & 0.83\n",
      "for 2019-10-22, MAE is:0.75 & sMAPE is:2.00% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.59% & 0.82\n",
      "for 2019-10-23, MAE is:1.12 & sMAPE is:3.01% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.58% & 0.82\n",
      "for 2019-10-24, MAE is:1.87 & sMAPE is:5.09% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.58% & 0.82\n",
      "for 2019-10-25, MAE is:1.84 & sMAPE is:5.17% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.58% & 0.83\n",
      "for 2019-10-26, MAE is:1.67 & sMAPE is:4.73% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.58% & 0.83\n",
      "for 2019-10-27, MAE is:1.62 & sMAPE is:4.38% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.57% & 0.83\n",
      "for 2019-10-28, MAE is:0.97 & sMAPE is:2.47% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.56% & 0.83\n",
      "for 2019-10-29, MAE is:1.34 & sMAPE is:3.39% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.56% & 0.83\n",
      "for 2019-10-30, MAE is:1.64 & sMAPE is:4.19% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.55% & 0.83\n",
      "for 2019-10-31, MAE is:1.24 & sMAPE is:3.19% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.54% & 0.83\n",
      "for 2019-11-01, MAE is:2.06 & sMAPE is:5.32% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.54% & 0.83\n",
      "for 2019-11-02, MAE is:1.94 & sMAPE is:5.34% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.54% & 0.84\n",
      "for 2019-11-03, MAE is:1.18 & sMAPE is:3.06% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.54% & 0.84\n",
      "for 2019-11-04, MAE is:0.89 & sMAPE is:2.20% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.52% & 0.84\n",
      "for 2019-11-05, MAE is:1.87 & sMAPE is:4.38% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.52% & 0.84\n",
      "for 2019-11-06, MAE is:11.32 & sMAPE is:21.78% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.57% & 0.84\n",
      "for 2019-11-07, MAE is:2.62 & sMAPE is:5.51% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.57% & 0.84\n",
      "for 2019-11-08, MAE is:4.12 & sMAPE is:8.69% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.58% & 0.83\n",
      "for 2019-11-09, MAE is:1.18 & sMAPE is:2.81% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.57% & 0.83\n",
      "for 2019-11-10, MAE is:2.31 & sMAPE is:5.28% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.57% & 0.83\n",
      "for 2019-11-11, MAE is:1.82 & sMAPE is:4.15% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.57% & 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-12, MAE is:2.67 & sMAPE is:6.33% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.57% & 0.83\n",
      "for 2019-11-13, MAE is:4.46 & sMAPE is:9.56% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.58% & 0.83\n",
      "for 2019-11-14, MAE is:3.59 & sMAPE is:7.64% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.59% & 0.84\n",
      "for 2019-11-15, MAE is:2.67 & sMAPE is:6.25% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.59% & 0.83\n",
      "for 2019-11-16, MAE is:1.22 & sMAPE is:3.08% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.58% & 0.83\n",
      "for 2019-11-17, MAE is:1.65 & sMAPE is:4.17% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.58% & 0.83\n",
      "for 2019-11-18, MAE is:1.35 & sMAPE is:3.22% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.57% & 0.83\n",
      "for 2019-11-19, MAE is:1.07 & sMAPE is:2.62% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.56% & 0.83\n",
      "for 2019-11-20, MAE is:3.17 & sMAPE is:7.02% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.57% & 0.83\n",
      "for 2019-11-21, MAE is:1.51 & sMAPE is:3.67% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.56% & 0.83\n",
      "for 2019-11-22, MAE is:1.41 & sMAPE is:3.51% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.56% & 0.83\n",
      "for 2019-11-23, MAE is:0.78 & sMAPE is:2.06% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.55% & 0.83\n",
      "for 2019-11-24, MAE is:1.29 & sMAPE is:3.32% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.54% & 0.83\n",
      "for 2019-11-25, MAE is:1.94 & sMAPE is:4.60% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.54% & 0.84\n",
      "for 2019-11-26, MAE is:2.91 & sMAPE is:6.50% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.54% & 0.84\n",
      "for 2019-11-27, MAE is:1.38 & sMAPE is:3.26% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.53% & 0.83\n",
      "for 2019-11-28, MAE is:1.64 & sMAPE is:3.97% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.53% & 0.84\n",
      "for 2019-11-29, MAE is:0.86 & sMAPE is:2.05% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.52% & 0.84\n",
      "for 2019-11-30, MAE is:1.37 & sMAPE is:3.21% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.51% & 0.84\n",
      "for 2019-12-01, MAE is:1.28 & sMAPE is:3.06% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.50% & 0.83\n",
      "for 2019-12-02, MAE is:2.49 & sMAPE is:5.52% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.50% & 0.84\n",
      "for 2019-12-03, MAE is:6.99 & sMAPE is:13.51% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.53% & 0.84\n",
      "for 2019-12-04, MAE is:1.63 & sMAPE is:3.99% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.52% & 0.84\n",
      "for 2019-12-05, MAE is:1.80 & sMAPE is:4.53% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.52% & 0.84\n",
      "for 2019-12-06, MAE is:1.04 & sMAPE is:2.72% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.51% & 0.84\n",
      "for 2019-12-07, MAE is:1.16 & sMAPE is:3.06% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.50% & 0.84\n",
      "for 2019-12-08, MAE is:1.14 & sMAPE is:3.03% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.50% & 0.84\n",
      "for 2019-12-09, MAE is:1.13 & sMAPE is:2.90% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.49% & 0.84\n",
      "for 2019-12-10, MAE is:3.31 & sMAPE is:7.69% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.49% & 0.83\n",
      "for 2019-12-11, MAE is:1.20 & sMAPE is:3.20% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.49% & 0.83\n",
      "for 2019-12-12, MAE is:1.58 & sMAPE is:4.07% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.48% & 0.84\n",
      "for 2019-12-13, MAE is:0.76 & sMAPE is:2.01% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.47% & 0.84\n",
      "for 2019-12-14, MAE is:1.10 & sMAPE is:3.07% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.47% & 0.84\n",
      "for 2019-12-15, MAE is:0.98 & sMAPE is:2.70% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.46% & 0.84\n",
      "for 2019-12-16, MAE is:2.39 & sMAPE is:6.10% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.46% & 0.84\n",
      "for 2019-12-17, MAE is:2.01 & sMAPE is:5.05% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.46% & 0.84\n",
      "for 2019-12-18, MAE is:1.35 & sMAPE is:3.52% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.45% & 0.84\n",
      "for 2019-12-19, MAE is:1.51 & sMAPE is:3.93% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.45% & 0.85\n",
      "for 2019-12-20, MAE is:1.01 & sMAPE is:2.74% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.44% & 0.85\n",
      "for 2019-12-21, MAE is:1.26 & sMAPE is:3.51% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.44% & 0.85\n",
      "for 2019-12-22, MAE is:1.93 & sMAPE is:5.44% & rMAE is:3.94 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.44% & 0.86\n",
      "for 2019-12-23, MAE is:1.26 & sMAPE is:3.35% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.43% & 0.85\n",
      "for 2019-12-24, MAE is:1.19 & sMAPE is:3.31% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.43% & 0.85\n",
      "for 2019-12-25, MAE is:1.34 & sMAPE is:3.69% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.42% & 0.85\n",
      "for 2019-12-26, MAE is:1.24 & sMAPE is:3.34% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.41% & 0.85\n",
      "for 2019-12-27, MAE is:1.08 & sMAPE is:2.85% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.41% & 0.85\n",
      "for 2019-12-28, MAE is:1.53 & sMAPE is:4.26% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.40% & 0.85\n",
      "for 2019-12-29, MAE is:1.25 & sMAPE is:3.74% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.40% & 0.85\n",
      "for 2019-12-30, MAE is:0.89 & sMAPE is:2.70% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.39% & 0.85\n",
      "for 2019-12-31, MAE is:1.46 & sMAPE is:4.34% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.39% & 0.85\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:04:12,983]\u001b[0m A new study created in RDB with name: NO_1_2020\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:04:32,843]\u001b[0m Trial 0 finished with value: 2.5462510158052214 and parameters: {'n_hidden': 3, 'learning_rate': 0.010835995408494324, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2853720159558452, 'dropout_rate_Layer_2': 0.05174132828233007, 'dropout_rate_Layer_3': 0.14258086772551268, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.1889688951771337e-05, 'l1_Layer_2': 0.00013623334171328726, 'l1_Layer_3': 5.4517643413168806e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 275, 'n_units_Layer_3': 120}. Best is trial 0 with value: 2.5462510158052214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.55 | sMAPE for Validation Set is: 6.67% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 17.36 | sMAPE for Test Set is: 112.16% | rMAE for Test Set is: 5.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:04:52,424]\u001b[0m Trial 2 finished with value: 2.546437451835007 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020205261372406116, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2734247761391417, 'dropout_rate_Layer_2': 0.1155233770419569, 'dropout_rate_Layer_3': 0.16011904344522307, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002665575490051061, 'l1_Layer_2': 0.00022373105690122374, 'l1_Layer_3': 0.045726956801765285, 'n_units_Layer_1': 165, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 0 with value: 2.5462510158052214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.55 | sMAPE for Validation Set is: 6.65% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 9.46 | sMAPE for Test Set is: 89.92% | rMAE for Test Set is: 2.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:05:25,653]\u001b[0m Trial 3 finished with value: 3.6689217581384894 and parameters: {'n_hidden': 4, 'learning_rate': 0.03615877652990965, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10814406512118024, 'dropout_rate_Layer_2': 0.2462293658782393, 'dropout_rate_Layer_3': 0.029735528014433223, 'dropout_rate_Layer_4': 0.26452030606367627, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00048473283064116363, 'l1_Layer_2': 0.018810195995362523, 'l1_Layer_3': 0.00019079690988229713, 'l1_Layer_4': 3.2196140789498645e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 165, 'n_units_Layer_3': 230, 'n_units_Layer_4': 85}. Best is trial 0 with value: 2.5462510158052214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 9.71% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 21.31 | sMAPE for Test Set is: 119.50% | rMAE for Test Set is: 6.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:05:30,678]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:06:15,547]\u001b[0m Trial 1 finished with value: 2.19051715295852 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009343705843144822, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019585206427367077, 'dropout_rate_Layer_2': 0.05773683117966, 'dropout_rate_Layer_3': 0.12241471359829098, 'dropout_rate_Layer_4': 0.23275785185396672, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.018674861672086655, 'l1_Layer_2': 1.6098566060704502e-05, 'l1_Layer_3': 0.0005014525819186414, 'l1_Layer_4': 0.00021248192559331617, 'n_units_Layer_1': 215, 'n_units_Layer_2': 125, 'n_units_Layer_3': 90, 'n_units_Layer_4': 55}. Best is trial 1 with value: 2.19051715295852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.19 | sMAPE for Validation Set is: 5.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 15.96 | sMAPE for Test Set is: 108.26% | rMAE for Test Set is: 5.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:06:17,913]\u001b[0m Trial 5 finished with value: 2.6906957915375354 and parameters: {'n_hidden': 4, 'learning_rate': 0.03211382348109119, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0016487118671183244, 'dropout_rate_Layer_2': 0.11581690197670183, 'dropout_rate_Layer_3': 0.37916651472869256, 'dropout_rate_Layer_4': 0.12307005886398233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00022902283521680032, 'l1_Layer_2': 0.002490267363868136, 'l1_Layer_3': 0.0003825141858247424, 'l1_Layer_4': 0.0001570120854067666, 'n_units_Layer_1': 80, 'n_units_Layer_2': 230, 'n_units_Layer_3': 215, 'n_units_Layer_4': 80}. Best is trial 1 with value: 2.19051715295852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.69 | sMAPE for Validation Set is: 7.14% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 19.88 | sMAPE for Test Set is: 117.80% | rMAE for Test Set is: 6.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:06:20,109]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:06:24,998]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:06:27,471]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:06:29,899]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:06:32,787]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:06:37,865]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:08:11,027]\u001b[0m Trial 13 finished with value: 2.16020480456077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005216635499921343, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09429929278358684, 'dropout_rate_Layer_2': 0.39089991902484295, 'dropout_rate_Layer_3': 0.2736803135169891, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.050883496269296474, 'l1_Layer_2': 6.0085506170928636e-05, 'l1_Layer_3': 0.003757893417127398, 'n_units_Layer_1': 265, 'n_units_Layer_2': 145, 'n_units_Layer_3': 130}. Best is trial 13 with value: 2.16020480456077.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 5.53% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 75.02% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:08:15,944]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:08:21,166]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:08:27,685]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:08:35,147]\u001b[0m Trial 11 finished with value: 4.2970701516362775 and parameters: {'n_hidden': 4, 'learning_rate': 0.03180725743793383, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38458341517343664, 'dropout_rate_Layer_2': 0.1878673455012579, 'dropout_rate_Layer_3': 0.18186291233227458, 'dropout_rate_Layer_4': 0.38182885407440464, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0550339941290516e-05, 'l1_Layer_2': 0.0006858533093167655, 'l1_Layer_3': 0.03479771768331672, 'l1_Layer_4': 1.2478047836916252e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 95, 'n_units_Layer_3': 60, 'n_units_Layer_4': 205}. Best is trial 13 with value: 2.16020480456077.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 10.78% | rMAE for Validation Set is: 1.29\n",
      "MAE for Test Set is: 15.25 | sMAPE for Test Set is: 107.15% | rMAE for Test Set is: 4.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:08:38,397]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:08:42,939]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:09:03,338]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:09:32,868]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:09:37,773]\u001b[0m Trial 20 finished with value: 2.0488160607623875 and parameters: {'n_hidden': 3, 'learning_rate': 0.003492617671085419, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28321295326028956, 'dropout_rate_Layer_2': 0.10911047919748551, 'dropout_rate_Layer_3': 0.12528847496299433, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003931173486952728, 'l1_Layer_2': 0.0025139762494166187, 'l1_Layer_3': 0.06051885170060305, 'n_units_Layer_1': 200, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 20 with value: 2.0488160607623875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.45 | sMAPE for Test Set is: 104.84% | rMAE for Test Set is: 4.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:09:40,462]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:09:44,792]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:09:47,500]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:09:57,525]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:00,691]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:02,879]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:08,121]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:13,068]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:13,203]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:24,197]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:27,285]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:29,386]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:33,717]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:41,444]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:44,437]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:10:51,692]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:11:00,581]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:11:03,781]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:11:08,356]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:11:37,507]\u001b[0m Trial 40 finished with value: 2.2445077450537374 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018671918833750416, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12935283120647037, 'dropout_rate_Layer_2': 0.04023686194443417, 'dropout_rate_Layer_3': 0.11807174302739437, 'dropout_rate_Layer_4': 0.27107946642905534, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004059496400413252, 'l1_Layer_2': 0.0002507701009192942, 'l1_Layer_3': 0.01450361576713002, 'l1_Layer_4': 0.005662763827834886, 'n_units_Layer_1': 240, 'n_units_Layer_2': 240, 'n_units_Layer_3': 265, 'n_units_Layer_4': 50}. Best is trial 20 with value: 2.0488160607623875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.24 | sMAPE for Validation Set is: 5.80% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.55 | sMAPE for Test Set is: 93.58% | rMAE for Test Set is: 3.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:11:42,770]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:11:43,141]\u001b[0m Trial 42 finished with value: 2.7615519730250035 and parameters: {'n_hidden': 3, 'learning_rate': 0.037161349066471686, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0394135621433529, 'dropout_rate_Layer_2': 0.03056115149466625, 'dropout_rate_Layer_3': 0.027403575815853953, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00287909105170159, 'l1_Layer_2': 0.016853415034145943, 'l1_Layer_3': 0.00034949567111962083, 'n_units_Layer_1': 105, 'n_units_Layer_2': 230, 'n_units_Layer_3': 105}. Best is trial 20 with value: 2.0488160607623875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.76 | sMAPE for Validation Set is: 7.13% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 18.71 | sMAPE for Test Set is: 114.58% | rMAE for Test Set is: 5.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:11:48,515]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:11:50,564]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:11:53,548]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:11:56,040]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:00,027]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:05,520]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:05,837]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:13,447]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:21,454]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:28,176]\u001b[0m Trial 52 finished with value: 4.332008765733885 and parameters: {'n_hidden': 3, 'learning_rate': 0.08462061446283689, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18158685293900706, 'dropout_rate_Layer_2': 0.1602925353523127, 'dropout_rate_Layer_3': 0.2110326746275377, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005284586853510117, 'l1_Layer_2': 0.002153361656261845, 'l1_Layer_3': 0.00019620897535560633, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 20 with value: 2.0488160607623875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 1.30\n",
      "MAE for Test Set is: 17.26 | sMAPE for Test Set is: 111.46% | rMAE for Test Set is: 5.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:12:33,513]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:35,798]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:38,824]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:43,569]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:46,501]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:53,316]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:12:55,109]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:13:00,359]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:13:00,673]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:13:09,744]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:13:15,180]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:13:19,831]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:13:20,131]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:13:27,149]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:13:32,196]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:13:36,240]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:13:41,297]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:13:41,549]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:14:11,186]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:14:15,513]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:14:15,923]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:14:30,227]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:14:32,900]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:14:35,412]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:15:07,562]\u001b[0m Trial 79 finished with value: 2.3219987179846737 and parameters: {'n_hidden': 3, 'learning_rate': 0.011780704170025125, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13996568648041505, 'dropout_rate_Layer_2': 0.25699906727608596, 'dropout_rate_Layer_3': 0.05064180564707477, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0006919330474487935, 'l1_Layer_2': 0.010028086184608183, 'l1_Layer_3': 0.051702165390345195, 'n_units_Layer_1': 225, 'n_units_Layer_2': 290, 'n_units_Layer_3': 275}. Best is trial 20 with value: 2.0488160607623875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.32 | sMAPE for Validation Set is: 6.00% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 16.72 | sMAPE for Test Set is: 109.84% | rMAE for Test Set is: 5.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:15:10,028]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:15:14,411]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:15:19,276]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:15:24,751]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:15:32,107]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:15:36,682]\u001b[0m Trial 76 finished with value: 1.9911018946894499 and parameters: {'n_hidden': 3, 'learning_rate': 0.002580944156629215, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23806166464345913, 'dropout_rate_Layer_2': 0.09273236277946549, 'dropout_rate_Layer_3': 0.12103738358922296, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04780943983530036, 'l1_Layer_2': 0.005084715871706754, 'l1_Layer_3': 0.013392276662383818, 'n_units_Layer_1': 210, 'n_units_Layer_2': 145, 'n_units_Layer_3': 290}. Best is trial 76 with value: 1.9911018946894499.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.73 | sMAPE for Test Set is: 108.02% | rMAE for Test Set is: 4.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:15:41,348]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:15:53,929]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:15:58,550]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:16:03,643]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:16:09,077]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:16:41,741]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:16:51,394]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:16:51,423]\u001b[0m Trial 85 finished with value: 2.2264323929479444 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005969811083802052, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10420639522217434, 'dropout_rate_Layer_2': 0.035473450002222226, 'dropout_rate_Layer_3': 0.1234354997599322, 'dropout_rate_Layer_4': 0.27017859052248006, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002084083087907926, 'l1_Layer_2': 6.680220407567067e-05, 'l1_Layer_3': 0.00558536518710566, 'l1_Layer_4': 0.003075801189519092, 'n_units_Layer_1': 225, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295, 'n_units_Layer_4': 55}. Best is trial 76 with value: 1.9911018946894499.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.23 | sMAPE for Validation Set is: 5.74% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 16.88 | sMAPE for Test Set is: 110.79% | rMAE for Test Set is: 5.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:17:10,204]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:17:12,843]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:17:13,121]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:17:18,419]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:17:18,602]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:17:24,095]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:17:43,676]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:17:46,834]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:17:48,942]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:18:01,174]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:18:25,672]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:18:30,735]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:18:42,705]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:18:55,038]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:18:55,245]\u001b[0m Trial 102 finished with value: 1.9850594778522659 and parameters: {'n_hidden': 4, 'learning_rate': 0.009493247371371765, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17128550298216083, 'dropout_rate_Layer_2': 0.12841338460689894, 'dropout_rate_Layer_3': 0.03800813311459353, 'dropout_rate_Layer_4': 0.3718328780116657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.007497854242802751, 'l1_Layer_2': 0.01841889192829677, 'l1_Layer_3': 0.00022439947524526075, 'l1_Layer_4': 0.0167743566944017, 'n_units_Layer_1': 235, 'n_units_Layer_2': 95, 'n_units_Layer_3': 205, 'n_units_Layer_4': 250}. Best is trial 102 with value: 1.9850594778522659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.92 | sMAPE for Test Set is: 104.97% | rMAE for Test Set is: 4.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:19:02,961]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:19:04,841]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:19:07,088]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:19:10,121]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:19:16,911]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:19:33,997]\u001b[0m Trial 111 finished with value: 3.536052788329524 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011101909205909872, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13377754347467868, 'dropout_rate_Layer_2': 0.2530006852722006, 'dropout_rate_Layer_3': 0.18878595976997117, 'dropout_rate_Layer_4': 0.318449415661858, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003946838002315341, 'l1_Layer_2': 0.024245053222853936, 'l1_Layer_3': 0.0008208622009436028, 'l1_Layer_4': 0.0002679458204244596, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 100, 'n_units_Layer_4': 280}. Best is trial 102 with value: 1.9850594778522659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 9.50% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 13.15 | sMAPE for Test Set is: 100.96% | rMAE for Test Set is: 4.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:19:36,959]\u001b[0m Trial 114 finished with value: 2.0582858259584653 and parameters: {'n_hidden': 3, 'learning_rate': 0.010353085909479337, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34822829047082826, 'dropout_rate_Layer_2': 0.09890079532993576, 'dropout_rate_Layer_3': 0.1366069170715654, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002860459042429432, 'l1_Layer_2': 0.003963336808460861, 'l1_Layer_3': 0.0010853276842229366, 'n_units_Layer_1': 205, 'n_units_Layer_2': 220, 'n_units_Layer_3': 265}. Best is trial 102 with value: 1.9850594778522659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.80 | sMAPE for Test Set is: 98.18% | rMAE for Test Set is: 3.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:19:39,002]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:19:42,038]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:19:45,998]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:19:46,267]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:19:53,672]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:20:03,141]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:20:17,608]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:20:17,882]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:20:24,921]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:20:39,880]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:21:07,700]\u001b[0m Trial 123 finished with value: 2.005895751930038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021567121667255074, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13450039157501123, 'dropout_rate_Layer_2': 0.14057551057586729, 'dropout_rate_Layer_3': 0.38423199540369224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003046518417810936, 'l1_Layer_2': 0.0010262394808164418, 'l1_Layer_3': 3.326607272655134e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190}. Best is trial 102 with value: 1.9850594778522659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.01 | sMAPE for Test Set is: 58.83% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:21:12,496]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:21:20,155]\u001b[0m Trial 126 finished with value: 1.9584829806215935 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011413268598606725, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16285398572235002, 'dropout_rate_Layer_2': 0.11393653360817649, 'dropout_rate_Layer_3': 0.1091599497020988, 'dropout_rate_Layer_4': 0.19145740949363532, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0077519906197228506, 'l1_Layer_2': 0.0015433690266493149, 'l1_Layer_3': 0.00013456445638074355, 'l1_Layer_4': 0.00022224686540410292, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 205, 'n_units_Layer_4': 90}. Best is trial 126 with value: 1.9584829806215935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.49 | sMAPE for Test Set is: 93.48% | rMAE for Test Set is: 3.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:21:27,210]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:21:30,210]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:21:34,418]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:21:34,441]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:21:39,719]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:21:39,846]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:21:45,992]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:21:48,703]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:21:51,150]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:21:53,600]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:22:25,162]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:22:37,928]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:22:42,892]\u001b[0m Trial 136 finished with value: 2.0594426878870533 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010360797075536442, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25722999976291444, 'dropout_rate_Layer_2': 0.058888839808546485, 'dropout_rate_Layer_3': 0.009624050345953677, 'dropout_rate_Layer_4': 0.1918938977255851, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.032958387863031284, 'l1_Layer_2': 0.0059233141542756555, 'l1_Layer_3': 0.0001683460600605055, 'l1_Layer_4': 0.0002438742571845072, 'n_units_Layer_1': 200, 'n_units_Layer_2': 245, 'n_units_Layer_3': 250, 'n_units_Layer_4': 295}. Best is trial 126 with value: 1.9584829806215935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.35% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.05 | sMAPE for Test Set is: 101.65% | rMAE for Test Set is: 4.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:22:45,273]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:22:50,665]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:23:20,343]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:23:28,549]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:23:32,466]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:23:37,433]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:23:37,665]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:23:42,630]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:23:42,684]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:23:47,602]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:23:47,700]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:23:53,840]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:03,621]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:09,039]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:13,723]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:14,296]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:19,318]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:21,813]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:25,059]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:30,041]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:34,018]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:37,484]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:37,531]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:44,110]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:44,207]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:51,745]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:51,775]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:24:59,363]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:25:17,551]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:25:21,714]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:25:26,666]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:25:34,458]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:25:38,876]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:25:43,866]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:25:49,070]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:25:54,578]\u001b[0m Trial 170 finished with value: 1.9085322832750429 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015856463479365047, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19418111315970335, 'dropout_rate_Layer_2': 0.10223551457234725, 'dropout_rate_Layer_3': 0.28363585542104863, 'dropout_rate_Layer_4': 0.3780001083292291, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.691229901817688e-05, 'l1_Layer_2': 0.004349439229664236, 'l1_Layer_3': 1.0088647248484134e-05, 'l1_Layer_4': 0.006548839521408707, 'n_units_Layer_1': 195, 'n_units_Layer_2': 145, 'n_units_Layer_3': 155, 'n_units_Layer_4': 245}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.62 | sMAPE for Test Set is: 109.69% | rMAE for Test Set is: 5.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:26:18,586]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:26:23,402]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:26:26,251]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:26:28,865]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:26:31,191]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:26:31,742]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:26:36,143]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:26:38,463]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:26:43,934]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:26:48,920]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:26:52,043]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:26:56,595]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:01,167]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:04,541]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:08,989]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:14,327]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:14,499]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:19,730]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:21,413]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:24,061]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:29,378]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:31,796]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:36,366]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:27:48,477]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:28:03,023]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:28:11,199]\u001b[0m Trial 202 finished with value: 2.187995679915728 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029787756438901082, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28814340989668896, 'dropout_rate_Layer_2': 0.05383310178657463, 'dropout_rate_Layer_3': 0.02260149647439779, 'dropout_rate_Layer_4': 0.11923440312598065, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04610492353042232, 'l1_Layer_2': 0.003075385150214555, 'l1_Layer_3': 0.00016327832096561898, 'l1_Layer_4': 0.0003772624765346254, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 210, 'n_units_Layer_4': 270}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.19 | sMAPE for Validation Set is: 5.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 13.57 | sMAPE for Test Set is: 103.11% | rMAE for Test Set is: 4.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:28:16,012]\u001b[0m Trial 203 finished with value: 33.96373026321498 and parameters: {'n_hidden': 4, 'learning_rate': 0.09003429695507388, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3163188607846072, 'dropout_rate_Layer_2': 0.006196129885155985, 'dropout_rate_Layer_3': 0.2880270839453048, 'dropout_rate_Layer_4': 0.3914881819613355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.727102767545696e-05, 'l1_Layer_2': 0.004583969891434811, 'l1_Layer_3': 1.0127643328094082e-05, 'l1_Layer_4': 0.0057155417911366165, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 145, 'n_units_Layer_4': 240}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.96 | sMAPE for Validation Set is: 148.26% | rMAE for Validation Set is: 10.22\n",
      "MAE for Test Set is: 5524.21 | sMAPE for Test Set is: 171.10% | rMAE for Test Set is: 1733.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:28:16,287]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:28:21,482]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:28:31,121]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:28:35,520]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:28:51,062]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:28:55,640]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:29:22,818]\u001b[0m Trial 207 finished with value: 2.1450506881184643 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010854067053247941, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22071131190226245, 'dropout_rate_Layer_2': 0.0015825232439339865, 'dropout_rate_Layer_3': 0.15494151952080648, 'dropout_rate_Layer_4': 0.23188502500269365, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005352979828093957, 'l1_Layer_2': 0.00016398304617589604, 'l1_Layer_3': 0.012668999900237982, 'l1_Layer_4': 0.016512734031388122, 'n_units_Layer_1': 215, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245, 'n_units_Layer_4': 100}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 5.52% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.57 | sMAPE for Test Set is: 94.68% | rMAE for Test Set is: 3.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:29:23,318]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:29:27,918]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:29:30,095]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:29:32,598]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:29:35,227]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:29:38,142]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:29:42,562]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:29:45,266]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:29:52,310]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:29:56,953]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:30:02,300]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:30:07,820]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:30:10,167]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:04,769]\u001b[0m Trial 225 finished with value: 2.0176628725133576 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015679456091776142, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18534919665355895, 'dropout_rate_Layer_2': 0.1881650697459535, 'dropout_rate_Layer_3': 0.13492211429216094, 'dropout_rate_Layer_4': 0.13811397235831363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.012160690104902562, 'l1_Layer_2': 0.005828481005919525, 'l1_Layer_3': 0.00014047026002960098, 'l1_Layer_4': 0.014316413758357118, 'n_units_Layer_1': 195, 'n_units_Layer_2': 215, 'n_units_Layer_3': 240, 'n_units_Layer_4': 245}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 16.58 | sMAPE for Test Set is: 109.50% | rMAE for Test Set is: 5.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:31:09,287]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:09,939]\u001b[0m Trial 217 finished with value: 2.0010539869312023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018349375706592128, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2661270567562623, 'dropout_rate_Layer_2': 0.08991958848325785, 'dropout_rate_Layer_3': 0.11021901527348353, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0036734243562490635, 'l1_Layer_2': 0.00499756044213867, 'l1_Layer_3': 0.030928394910796166, 'n_units_Layer_1': 220, 'n_units_Layer_2': 220, 'n_units_Layer_3': 290}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.85 | sMAPE for Test Set is: 105.90% | rMAE for Test Set is: 4.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:31:14,591]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:16,870]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:24,760]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:29,544]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:31,628]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:34,587]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:44,830]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:47,380]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:49,410]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:53,698]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:53,963]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:58,819]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:31:59,224]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:32:06,533]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:32:13,890]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:32:18,105]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:32:23,940]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:32:30,862]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:32:46,420]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:32:58,870]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:33:01,144]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:33:03,506]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:33:06,411]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:33:13,606]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:33:40,851]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:33:45,371]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:33:48,546]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:33:55,601]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:34:00,187]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:34:03,391]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:34:33,102]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:34:35,375]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:34:47,487]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:34:52,467]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:34:55,664]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:10,534]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:14,823]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:15,279]\u001b[0m Trial 259 finished with value: 2.015075279489798 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011235879874052612, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23727504888204992, 'dropout_rate_Layer_2': 0.2290440505643495, 'dropout_rate_Layer_3': 0.27440715412143996, 'dropout_rate_Layer_4': 0.3368041864153912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06951375740550318, 'l1_Layer_2': 0.0016583007656626664, 'l1_Layer_3': 0.00203498887785374, 'l1_Layer_4': 0.00012049083703852862, 'n_units_Layer_1': 125, 'n_units_Layer_2': 275, 'n_units_Layer_3': 165, 'n_units_Layer_4': 115}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.40% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.30 | sMAPE for Test Set is: 56.62% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:35:20,496]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:26,990]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:30,161]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:34,256]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:37,289]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:44,466]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:44,607]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:49,688]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:52,441]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:35:54,895]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:36:19,089]\u001b[0m Trial 276 finished with value: 2.3230277754696615 and parameters: {'n_hidden': 4, 'learning_rate': 0.005273120045720143, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06854462917797394, 'dropout_rate_Layer_2': 0.2168892833964387, 'dropout_rate_Layer_3': 0.1555746268207488, 'dropout_rate_Layer_4': 0.3261482818852327, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.6941926630110306e-05, 'l1_Layer_2': 0.028804682364326567, 'l1_Layer_3': 0.0013076251737526802, 'l1_Layer_4': 0.02292484685662286, 'n_units_Layer_1': 190, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300, 'n_units_Layer_4': 225}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.32 | sMAPE for Validation Set is: 6.02% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 97.95% | rMAE for Test Set is: 3.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:36:36,913]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:36:39,311]\u001b[0m Trial 275 finished with value: 1.9998421394092414 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011205594462720622, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2794376520780597, 'dropout_rate_Layer_2': 0.28736602703056574, 'dropout_rate_Layer_3': 0.3165188422025255, 'dropout_rate_Layer_4': 0.34823582029295136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03334200463931094, 'l1_Layer_2': 0.0013581019240804073, 'l1_Layer_3': 0.0033641984146436515, 'l1_Layer_4': 0.00010697655365275124, 'n_units_Layer_1': 115, 'n_units_Layer_2': 255, 'n_units_Layer_3': 230, 'n_units_Layer_4': 115}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.01 | sMAPE for Test Set is: 40.40% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:36:41,270]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:36:46,423]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:36:50,584]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:36:51,936]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:36:55,715]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:36:56,997]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:03,473]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:17,398]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:20,693]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:20,874]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:26,464]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:28,359]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:35,226]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:38,053]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:40,469]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:40,947]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:45,362]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:53,537]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:37:57,974]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:07,435]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:10,258]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:10,968]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:15,345]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:17,503]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:20,366]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:24,447]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:24,985]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:29,928]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:32,030]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:34,286]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:37,052]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:39,227]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:42,066]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:44,662]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:46,248]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:51,481]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:38:58,211]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:39:01,419]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:39:03,845]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:39:08,458]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:39:13,667]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:39:18,505]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:39:25,898]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:39:28,497]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:39:38,470]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:39:42,911]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:39:48,264]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:39:58,035]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:02,294]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:05,618]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:10,455]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:14,640]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:18,091]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:19,946]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:24,436]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:27,423]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:32,625]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:39,605]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:44,612]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:44,882]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:49,827]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:50,231]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:40:58,902]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:04,190]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:09,490]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:14,622]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:14,710]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:19,210]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:24,710]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:28,991]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:29,282]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:34,248]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:34,331]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:41,089]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:41,389]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:46,407]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:46,550]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:51,577]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:54,413]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:56,542]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:41:59,559]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:06,093]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:09,438]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:13,595]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:18,658]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:23,840]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:26,308]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:29,541]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:34,333]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:38,946]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:40,926]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:45,473]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:48,430]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:42:50,934]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:53,812]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:42:55,586]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:43:00,617]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:43:05,989]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:43:10,322]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:43:18,109]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:43:30,421]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:43:33,284]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:43:33,382]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:43:37,720]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:43:41,781]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:09,657]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:12,135]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:17,228]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:17,268]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:23,197]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:30,568]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:37,777]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:42,273]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:45,637]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:45,847]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:52,744]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:56,083]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:44:58,154]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:00,765]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:02,758]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:07,629]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:12,633]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:17,904]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:22,600]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:25,720]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:45:33,039]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:46:37,065]\u001b[0m Trial 399 finished with value: 1.9356455606677236 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005698592056611402, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34982140271404016, 'dropout_rate_Layer_2': 0.0010432021611045637, 'dropout_rate_Layer_3': 0.17144642157833365, 'dropout_rate_Layer_4': 0.2106381947381006, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06003447985707825, 'l1_Layer_2': 0.018609475544389992, 'l1_Layer_3': 4.438650540737451e-05, 'l1_Layer_4': 0.00028330642643694445, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 195, 'n_units_Layer_4': 255}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 86.61% | rMAE for Test Set is: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:46:40,174]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:46:45,023]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:46:52,019]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:46:55,340]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:47:00,208]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:47:47,104]\u001b[0m Trial 405 finished with value: 2.0419448508985436 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006623213682135235, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2966522901803381, 'dropout_rate_Layer_2': 0.2766889229034722, 'dropout_rate_Layer_3': 0.3535078450541482, 'dropout_rate_Layer_4': 0.20798614006224564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008530235416398665, 'l1_Layer_2': 0.004556532270368222, 'l1_Layer_3': 0.0010449906523249553, 'l1_Layer_4': 3.791185732115001e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190, 'n_units_Layer_4': 140}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.15 | sMAPE for Test Set is: 95.67% | rMAE for Test Set is: 3.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:48:06,677]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:48:23,428]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:48:55,899]\u001b[0m Trial 411 finished with value: 2.049781630310045 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006897571820117071, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29149259728494586, 'dropout_rate_Layer_2': 0.27260097689823937, 'dropout_rate_Layer_3': 0.34107926039867514, 'dropout_rate_Layer_4': 0.20684673249885735, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007347501334041466, 'l1_Layer_2': 0.0036862464281419267, 'l1_Layer_3': 0.0011832516090166162, 'l1_Layer_4': 3.06169967248679e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 285, 'n_units_Layer_3': 185, 'n_units_Layer_4': 135}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.37 | sMAPE for Test Set is: 102.50% | rMAE for Test Set is: 4.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:49:21,241]\u001b[0m Trial 414 finished with value: 2.0078048589198505 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008218749836478863, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2967104668697709, 'dropout_rate_Layer_2': 0.015189509180878698, 'dropout_rate_Layer_3': 0.17232592957772294, 'dropout_rate_Layer_4': 0.20839406944412645, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07941976574368317, 'l1_Layer_2': 0.006026569006448839, 'l1_Layer_3': 2.0177965206009085e-05, 'l1_Layer_4': 0.0002616406063395223, 'n_units_Layer_1': 145, 'n_units_Layer_2': 235, 'n_units_Layer_3': 210, 'n_units_Layer_4': 235}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.20 | sMAPE for Test Set is: 85.04% | rMAE for Test Set is: 2.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:49:25,698]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:49:30,943]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:49:35,385]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:49:48,716]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:49:52,948]\u001b[0m Trial 415 finished with value: 1.9412690267083368 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008127998639430733, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26486042379878233, 'dropout_rate_Layer_2': 0.015339402939472025, 'dropout_rate_Layer_3': 0.010613592152935045, 'dropout_rate_Layer_4': 0.21145171308532423, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07608028772808527, 'l1_Layer_2': 0.01481846645390012, 'l1_Layer_3': 0.00015811060105215565, 'l1_Layer_4': 0.00010502410246425314, 'n_units_Layer_1': 145, 'n_units_Layer_2': 260, 'n_units_Layer_3': 210, 'n_units_Layer_4': 235}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.24 | sMAPE for Test Set is: 89.31% | rMAE for Test Set is: 2.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:50:05,816]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:08,498]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:10,943]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:15,091]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:15,595]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:20,333]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:22,615]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:23,312]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:29,782]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:30,501]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:35,340]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:45,236]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:47,951]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:49,868]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:50:52,835]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:11,981]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:17,459]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:21,861]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:27,024]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:30,273]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:34,579]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:39,710]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:51:42,995]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:06,354]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:09,371]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:13,524]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:18,843]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:33,597]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:51,154]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:52:55,546]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:01,321]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:03,845]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:07,947]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:25,629]\u001b[0m Trial 454 finished with value: 2.601632067273671 and parameters: {'n_hidden': 4, 'learning_rate': 0.03545864615304346, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1602628973317407, 'dropout_rate_Layer_2': 0.21776359347143465, 'dropout_rate_Layer_3': 0.13043122301246715, 'dropout_rate_Layer_4': 0.09341579907238573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.05094366561884484, 'l1_Layer_2': 0.023317562289573747, 'l1_Layer_3': 2.0756017856120095e-05, 'l1_Layer_4': 0.004132151164295208, 'n_units_Layer_1': 180, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260, 'n_units_Layer_4': 300}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.60 | sMAPE for Validation Set is: 6.73% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 18.18 | sMAPE for Test Set is: 113.17% | rMAE for Test Set is: 5.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:53:37,338]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:42,980]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:47,888]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:53:59,775]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:54:02,645]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:54:07,141]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:54:07,509]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:54:47,289]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:54:54,560]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:09,096]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:14,247]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:19,441]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:23,885]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:33,861]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:36,987]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:55:41,985]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:56:01,210]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:56:03,976]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:57:20,296]\u001b[0m Trial 468 finished with value: 1.9485925174691825 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007774990624571519, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021592071554312503, 'dropout_rate_Layer_2': 0.0426780648105501, 'dropout_rate_Layer_3': 0.00857347865985026, 'dropout_rate_Layer_4': 0.21105549902919785, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.053169064353769245, 'l1_Layer_2': 0.01057375848778123, 'l1_Layer_3': 0.00018225692487866549, 'l1_Layer_4': 0.0003276412091540806, 'n_units_Layer_1': 170, 'n_units_Layer_2': 270, 'n_units_Layer_3': 185, 'n_units_Layer_4': 285}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.34 | sMAPE for Test Set is: 98.93% | rMAE for Test Set is: 3.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:57:27,795]\u001b[0m Trial 473 finished with value: 2.1634536235958506 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006860603889416226, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3099831745649002, 'dropout_rate_Layer_2': 0.2502511096104373, 'dropout_rate_Layer_3': 0.33697055391397424, 'dropout_rate_Layer_4': 0.24384347458546815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0017404370807208155, 'l1_Layer_2': 0.010073492762171586, 'l1_Layer_3': 0.0012142072656313309, 'l1_Layer_4': 0.00011813648750249884, 'n_units_Layer_1': 275, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160, 'n_units_Layer_4': 110}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 5.53% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 14.78 | sMAPE for Test Set is: 105.87% | rMAE for Test Set is: 4.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:57:35,175]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:57:40,535]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:57:52,305]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:04,343]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:07,140]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:09,471]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:11,167]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:17,159]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:20,519]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:24,601]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:29,685]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:34,444]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:37,652]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:58:52,318]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:01,893]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:04,722]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:07,079]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:20,967]\u001b[0m Trial 491 finished with value: 2.026127880938226 and parameters: {'n_hidden': 3, 'learning_rate': 0.00948458079941083, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1459309173644982, 'dropout_rate_Layer_2': 0.1864617137717888, 'dropout_rate_Layer_3': 0.03770458025259057, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0018254464347539825, 'l1_Layer_2': 0.034076913732601744, 'l1_Layer_3': 8.855762255316614e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 195, 'n_units_Layer_3': 195}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 15.07 | sMAPE for Test Set is: 106.45% | rMAE for Test Set is: 4.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:59:26,090]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:29,218]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:36,126]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:36,661]\u001b[0m Trial 492 finished with value: 2.196299073451946 and parameters: {'n_hidden': 3, 'learning_rate': 0.010070194690387413, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14452842104691452, 'dropout_rate_Layer_2': 0.07867973174215966, 'dropout_rate_Layer_3': 0.03363985637672419, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.1319448265583693e-05, 'l1_Layer_2': 0.037120957054397434, 'l1_Layer_3': 0.00022400374319019042, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 5.64% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 16.07 | sMAPE for Test Set is: 108.64% | rMAE for Test Set is: 5.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 07:59:41,742]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:42,048]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:49,770]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:49,929]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 07:59:57,526]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:02,509]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:05,259]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:11,931]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:19,911]\u001b[0m Trial 501 finished with value: 2.047011518842459 and parameters: {'n_hidden': 3, 'learning_rate': 0.008225570993332489, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13599188908879373, 'dropout_rate_Layer_2': 0.18930495932304184, 'dropout_rate_Layer_3': 0.047622568839681134, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001890569183596937, 'l1_Layer_2': 0.03982685243457579, 'l1_Layer_3': 8.894938790709692e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 190, 'n_units_Layer_3': 200}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:20,082]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 15.21 | sMAPE for Test Set is: 106.17% | rMAE for Test Set is: 4.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:00:30,060]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:34,866]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:40,073]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:40,120]\u001b[0m Trial 506 finished with value: 2.1363587147075154 and parameters: {'n_hidden': 3, 'learning_rate': 0.015317371458281272, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1222855638527735, 'dropout_rate_Layer_2': 0.16184583992963536, 'dropout_rate_Layer_3': 0.09284973935201629, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.006735016998773727, 'l1_Layer_2': 0.015338025682479654, 'l1_Layer_3': 0.00043283809907464476, 'n_units_Layer_1': 280, 'n_units_Layer_2': 225, 'n_units_Layer_3': 185}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 5.49% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 15.54 | sMAPE for Test Set is: 107.59% | rMAE for Test Set is: 4.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:00:45,707]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:45,841]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:51,764]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:00:53,824]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:01,023]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:05,701]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:08,476]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:13,785]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:18,482]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:43,004]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:45,969]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:01:55,254]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:10,389]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:14,976]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:25,250]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:29,623]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:34,797]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:45,163]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:49,645]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:52,597]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:02:59,469]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:04,402]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:07,295]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:11,788]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:16,850]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:21,547]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:26,493]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:31,468]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:38,948]\u001b[0m Trial 517 finished with value: 2.047947730911511 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006074703481404624, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3406976358056652, 'dropout_rate_Layer_2': 0.2749373135301808, 'dropout_rate_Layer_3': 0.3601812290290675, 'dropout_rate_Layer_4': 0.0581233000496674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014694307622224923, 'l1_Layer_2': 0.002473847492393967, 'l1_Layer_3': 0.0008600333182210019, 'l1_Layer_4': 9.079909551044766e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 240, 'n_units_Layer_3': 200, 'n_units_Layer_4': 90}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.01 | sMAPE for Test Set is: 84.09% | rMAE for Test Set is: 2.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:03:42,114]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:46,387]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:53,324]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:03:58,272]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:04:08,291]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:04:24,175]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:04:46,791]\u001b[0m Trial 544 finished with value: 1.926548410527533 and parameters: {'n_hidden': 4, 'learning_rate': 0.006420463300719288, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0848076844774081, 'dropout_rate_Layer_2': 0.14695932728701547, 'dropout_rate_Layer_3': 0.26202421305199375, 'dropout_rate_Layer_4': 0.007303408567571501, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011666518031243543, 'l1_Layer_2': 0.0070929119373249975, 'l1_Layer_3': 0.09469838308999712, 'l1_Layer_4': 0.04360970756988028, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155, 'n_units_Layer_4': 205}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 18.52 | sMAPE for Test Set is: 113.82% | rMAE for Test Set is: 5.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:04:51,095]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:04:56,156]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:01,050]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:40,472]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:45,225]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:05:50,414]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:06:47,349]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:06:50,155]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:06:52,472]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:07:29,399]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:07:42,327]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:07:47,790]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:08:31,665]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:08:36,489]\u001b[0m Trial 557 finished with value: 1.996645998262161 and parameters: {'n_hidden': 4, 'learning_rate': 0.001230079025544552, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3575671734692733, 'dropout_rate_Layer_2': 0.0011950580546276294, 'dropout_rate_Layer_3': 0.0013211885846940866, 'dropout_rate_Layer_4': 0.13899566800491253, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02741592228340794, 'l1_Layer_2': 0.00697529978729039, 'l1_Layer_3': 2.4963469307341877e-05, 'l1_Layer_4': 0.0005926852496983986, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170, 'n_units_Layer_4': 80}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.71 | sMAPE for Test Set is: 90.93% | rMAE for Test Set is: 3.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:08:39,316]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:08:44,122]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:08:58,686]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:03,265]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:19,405]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:38,986]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:45,828]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:09:55,906]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:00,406]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:05,315]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:10,498]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:17,699]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:23,050]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:30,099]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:33,183]\u001b[0m Trial 568 finished with value: 1.9425131161918854 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029682336536384947, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16257913248643183, 'dropout_rate_Layer_2': 0.13735162503571047, 'dropout_rate_Layer_3': 0.10795152901357315, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008324187167285039, 'l1_Layer_2': 0.0004129464423767088, 'l1_Layer_3': 1.5680863660899452e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 245, 'n_units_Layer_3': 300}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 95.48% | rMAE for Test Set is: 3.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:10:35,429]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:39,826]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:40,539]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:47,151]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:47,722]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:52,170]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:55,093]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:10:59,217]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:04,471]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:04,707]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:11,606]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:20,918]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:21,339]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:26,290]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:26,544]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:32,402]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:37,173]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:41,666]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:44,560]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:47,380]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:49,345]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:51,369]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:54,609]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:57,188]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:11:59,678]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:03,790]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:08,783]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:13,630]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:15,461]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:18,470]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:25,810]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:29,057]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:31,670]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:36,082]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:40,778]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:48,707]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:52,854]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:12:53,288]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:01,347]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:01,462]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:06,726]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:11,809]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:14,513]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:19,456]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:24,373]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:26,991]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:30,984]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:34,174]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:38,561]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:41,162]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:43,730]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:46,146]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:48,398]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:55,471]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:13:58,709]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:03,460]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:03,767]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:09,195]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:11,370]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:13,844]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:18,456]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:21,742]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:33,306]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:36,444]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:43,942]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:14:56,610]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:11,951]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:16,726]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:22,056]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:26,431]\u001b[0m Trial 635 finished with value: 1.9228187300062272 and parameters: {'n_hidden': 4, 'learning_rate': 0.000979184418454666, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008152488498745414, 'dropout_rate_Layer_2': 0.035847808121888834, 'dropout_rate_Layer_3': 0.02764562427390571, 'dropout_rate_Layer_4': 0.22281546551545267, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.028852239919598947, 'l1_Layer_2': 0.00444608315640565, 'l1_Layer_3': 2.7077392725620773e-05, 'l1_Layer_4': 0.00026088500864994267, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255, 'n_units_Layer_4': 245}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 95.44% | rMAE for Test Set is: 3.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:15:31,105]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:36,473]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:37,006]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:41,981]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:48,979]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:15:56,547]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:00,866]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:13,586]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:15,984]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:18,773]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:19,178]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:51,699]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:16:56,216]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:01,904]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:09,368]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:14,505]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:17:29,029]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:18:08,616]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:18:45,410]\u001b[0m Trial 661 finished with value: 1.9096801244036001 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007567625332805898, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006016916123913595, 'dropout_rate_Layer_2': 0.005789617251743314, 'dropout_rate_Layer_3': 0.03210890728665847, 'dropout_rate_Layer_4': 0.14470471191482281, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023032764700564902, 'l1_Layer_2': 0.0034210651930599283, 'l1_Layer_3': 0.00017287529644609295, 'l1_Layer_4': 0.0002441476759881107, 'n_units_Layer_1': 220, 'n_units_Layer_2': 280, 'n_units_Layer_3': 270, 'n_units_Layer_4': 255}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 4.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 96.75% | rMAE for Test Set is: 3.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:18:48,205]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:18:48,679]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:18:53,857]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:18:58,178]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:08,136]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:13,120]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:13,933]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:18,510]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:18,718]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:26,148]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:26,527]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:32,521]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:32,748]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:37,837]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:50,267]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:52,948]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:53,643]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:19:58,638]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:00,900]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:06,403]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:11,538]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:11,859]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:16,743]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:19,489]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:21,459]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:26,347]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:36,752]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:39,173]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:20:58,278]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:03,374]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:08,781]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:22,975]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:27,913]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:31,233]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:35,565]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:35,886]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:42,713]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:42,901]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:48,200]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:52,635]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:21:57,367]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:00,317]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:03,086]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:07,471]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:12,096]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:15,413]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:19,825]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:34,364]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:41,326]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:54,289]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:59,151]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:22:59,561]\u001b[0m Trial 702 finished with value: 1.946356212098283 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007838728740517476, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2822289649986513, 'dropout_rate_Layer_2': 0.022404666628364274, 'dropout_rate_Layer_3': 0.05026677249036357, 'dropout_rate_Layer_4': 0.14317467808554737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03575276409562825, 'l1_Layer_2': 0.018528698718558428, 'l1_Layer_3': 9.061708322009816e-05, 'l1_Layer_4': 0.00022680304245776585, 'n_units_Layer_1': 215, 'n_units_Layer_2': 290, 'n_units_Layer_3': 190, 'n_units_Layer_4': 220}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.14 | sMAPE for Test Set is: 80.79% | rMAE for Test Set is: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:23:04,936]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:12,075]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:17,275]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 5.53% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 14.57 | sMAPE for Test Set is: 104.76% | rMAE for Test Set is: 4.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:23:27,482]\u001b[0m Trial 716 finished with value: 2.1345974704539974 and parameters: {'n_hidden': 3, 'learning_rate': 0.008232465227849131, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13012446144725665, 'dropout_rate_Layer_2': 0.199196166376812, 'dropout_rate_Layer_3': 0.05571585596212426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00201562391198211, 'l1_Layer_2': 0.0473731529871634, 'l1_Layer_3': 0.0001013385814462879, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 200}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:32,135]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:36,784]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:41,885]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:46,835]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:53,842]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:23:59,422]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:04,079]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:09,532]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:13,854]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:19,008]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:24,108]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:27,327]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:31,662]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:34,437]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:38,876]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:39,352]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:43,695]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:24:48,600]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:16,176]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:16,309]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:24,702]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:30,021]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:30,104]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:35,947]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:42,766]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:45,847]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:50,276]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:25:57,858]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:09,820]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:14,726]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:20,388]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:23,150]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:27,518]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:34,878]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:39,828]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:26:57,031]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:00,306]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:02,994]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:06,111]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:10,907]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:16,091]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:20,540]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:27,628]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:33,208]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:40,048]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:44,890]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:50,492]\u001b[0m Trial 746 finished with value: 2.0057423988711682 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006168961798573208, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02208846760363936, 'dropout_rate_Layer_2': 0.2916405566843461, 'dropout_rate_Layer_3': 0.3387380764475921, 'dropout_rate_Layer_4': 0.18759406000256312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004062666827436707, 'l1_Layer_2': 0.0065253801475194904, 'l1_Layer_3': 0.009371445434210571, 'l1_Layer_4': 5.2065056793813424e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 275, 'n_units_Layer_3': 145, 'n_units_Layer_4': 125}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.25% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 12.19 | sMAPE for Test Set is: 98.44% | rMAE for Test Set is: 3.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:27:54,966]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:27:59,994]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:28:15,163]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:28:20,619]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:28:25,158]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:28:37,535]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:28:37,860]\u001b[0m Trial 767 finished with value: 2.0494818639311263 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007981336846204134, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35793824713662326, 'dropout_rate_Layer_2': 0.09126004846241301, 'dropout_rate_Layer_3': 0.2867372265550071, 'dropout_rate_Layer_4': 0.3171350502954772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.6511601283712404e-05, 'l1_Layer_2': 0.0012486848992038146, 'l1_Layer_3': 0.0020438519971406263, 'l1_Layer_4': 0.0001671240013430385, 'n_units_Layer_1': 90, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150, 'n_units_Layer_4': 125}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 80.38% | rMAE for Test Set is: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:28:47,221]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:28:52,223]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:28:52,660]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:07,127]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:11,827]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:22,047]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:25,014]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:29,146]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:32,398]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:37,293]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:41,572]\u001b[0m Trial 780 finished with value: 2.0840078213672175 and parameters: {'n_hidden': 3, 'learning_rate': 0.005518274181221468, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0011635778442163902, 'dropout_rate_Layer_2': 0.18908283191690994, 'dropout_rate_Layer_3': 0.0735923719521904, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008030777301865363, 'l1_Layer_2': 0.01944405814837596, 'l1_Layer_3': 6.860294733826815e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 190, 'n_units_Layer_3': 195}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 5.37% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.36 | sMAPE for Test Set is: 101.80% | rMAE for Test Set is: 4.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:29:46,747]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:51,685]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:29:58,922]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:03,785]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:11,138]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:16,484]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:21,036]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:33,707]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:30:58,863]\u001b[0m Trial 794 finished with value: 2.2938132737513137 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010558887440476655, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3525004430107348, 'dropout_rate_Layer_2': 0.30741865168536986, 'dropout_rate_Layer_3': 0.3576652138121661, 'dropout_rate_Layer_4': 0.31145896891278435, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.320422525653781e-05, 'l1_Layer_2': 0.0003880605496257111, 'l1_Layer_3': 0.006687646924674232, 'l1_Layer_4': 2.9569750376726552e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 270, 'n_units_Layer_3': 185, 'n_units_Layer_4': 130}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.29 | sMAPE for Validation Set is: 5.96% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 16.02 | sMAPE for Test Set is: 108.78% | rMAE for Test Set is: 5.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:31:03,708]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:31:20,804]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:31:42,746]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:31:46,167]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:31:47,807]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:31:53,608]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:31:58,253]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:15,360]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:20,788]\u001b[0m Trial 802 finished with value: 2.0299601983136077 and parameters: {'n_hidden': 3, 'learning_rate': 0.007591108567549837, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08935471110382609, 'dropout_rate_Layer_2': 0.13837164247326494, 'dropout_rate_Layer_3': 0.017809735327781455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.009118081851373921, 'l1_Layer_2': 0.01298695493075868, 'l1_Layer_3': 2.8176851908557416e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 195, 'n_units_Layer_3': 215}. Best is trial 170 with value: 1.9085322832750429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.90 | sMAPE for Test Set is: 103.42% | rMAE for Test Set is: 4.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:32:23,088]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:26,092]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:28,603]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:33,063]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:35,284]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:38,071]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:38,676]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:43,453]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:47,537]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:50,987]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:32:55,758]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:07,529]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:10,718]\u001b[0m Trial 812 finished with value: 1.9056329681620252 and parameters: {'n_hidden': 3, 'learning_rate': 0.007314130659616946, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05521974872032805, 'dropout_rate_Layer_2': 0.10123422885686492, 'dropout_rate_Layer_3': 0.022116383285802822, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.021328705495491908, 'l1_Layer_2': 0.012535700575774899, 'l1_Layer_3': 1.7479803804480533e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 215, 'n_units_Layer_3': 235}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 17.16 | sMAPE for Test Set is: 111.07% | rMAE for Test Set is: 5.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:33:15,043]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:19,761]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:24,787]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:47,251]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:33:56,505]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:34:36,437]\u001b[0m Trial 822 finished with value: 1.9549199272578435 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012443705978016546, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017619600099997308, 'dropout_rate_Layer_2': 0.05493900388769188, 'dropout_rate_Layer_3': 0.14321650317902618, 'dropout_rate_Layer_4': 0.15617621033875562, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02909589348645898, 'l1_Layer_2': 0.008208458754808148, 'l1_Layer_3': 0.0002656140752256447, 'l1_Layer_4': 0.00030840111832620157, 'n_units_Layer_1': 200, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270, 'n_units_Layer_4': 265}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.47 | sMAPE for Test Set is: 99.53% | rMAE for Test Set is: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:34:40,205]\u001b[0m Trial 821 finished with value: 1.921522375271973 and parameters: {'n_hidden': 3, 'learning_rate': 0.002222700129961489, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11699768491934141, 'dropout_rate_Layer_2': 0.038028253948560554, 'dropout_rate_Layer_3': 0.0641764178722268, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01620041051940357, 'l1_Layer_2': 0.0012115203991701572, 'l1_Layer_3': 0.0006684984490937562, 'n_units_Layer_1': 190, 'n_units_Layer_2': 245, 'n_units_Layer_3': 300}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 97.49% | rMAE for Test Set is: 3.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:34:40,634]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:34:48,185]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:34:52,565]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:35:02,738]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:35:10,710]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:35:13,250]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:35:25,144]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:35:28,130]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:35:45,366]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:12,247]\u001b[0m Trial 827 finished with value: 1.9498612508383102 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021733213581888577, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12788792649437375, 'dropout_rate_Layer_2': 0.022954955824971025, 'dropout_rate_Layer_3': 0.06131220533386454, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020308440720126747, 'l1_Layer_2': 0.0013725080440342332, 'l1_Layer_3': 0.001018971816130496, 'n_units_Layer_1': 190, 'n_units_Layer_2': 220, 'n_units_Layer_3': 300}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.11 | sMAPE for Test Set is: 101.48% | rMAE for Test Set is: 4.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:36:22,628]\u001b[0m Trial 833 finished with value: 2.0700434961709675 and parameters: {'n_hidden': 3, 'learning_rate': 0.007500620631998846, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09651767035566229, 'dropout_rate_Layer_2': 0.13521100040482825, 'dropout_rate_Layer_3': 0.015385334663698411, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.012289476817538262, 'l1_Layer_2': 0.009612359837082361, 'l1_Layer_3': 2.3779210832355948e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 210, 'n_units_Layer_3': 270}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 5.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 99.59% | rMAE for Test Set is: 3.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:36:22,855]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:30,683]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:33,206]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:36,118]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:38,555]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:50,376]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:36:50,858]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 96.24% | rMAE for Test Set is: 3.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:37:49,123]\u001b[0m Trial 842 finished with value: 1.9344271274207916 and parameters: {'n_hidden': 3, 'learning_rate': 0.001960583461860035, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11031883505757567, 'dropout_rate_Layer_2': 0.039987730922271175, 'dropout_rate_Layer_3': 0.03467693465773794, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012894037765199, 'l1_Layer_2': 0.0012840993688776627, 'l1_Layer_3': 0.0005333051559619163, 'n_units_Layer_1': 200, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:37:52,714]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:04,286]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:11,807]\u001b[0m Trial 841 finished with value: 1.9169092969255075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018160768689995386, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1013861754834898, 'dropout_rate_Layer_2': 0.041932862400723005, 'dropout_rate_Layer_3': 0.03895844758724306, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017402206081124288, 'l1_Layer_2': 0.0008263756759300192, 'l1_Layer_3': 0.0011640801209741945, 'n_units_Layer_1': 200, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.82 | sMAPE for Test Set is: 97.72% | rMAE for Test Set is: 3.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:38:12,303]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:17,606]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:24,967]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:27,089]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:29,536]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:32,155]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:34,364]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:36,585]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:39,455]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:42,080]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:44,944]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:49,702]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:38:54,808]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:39:01,994]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:39:08,961]\u001b[0m Trial 856 finished with value: 1.9233111145687285 and parameters: {'n_hidden': 3, 'learning_rate': 0.018292609819102253, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08582764274619709, 'dropout_rate_Layer_2': 0.10716350890260662, 'dropout_rate_Layer_3': 0.014927492190902895, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009804278560934758, 'l1_Layer_2': 0.009552952815332557, 'l1_Layer_3': 0.00012009278603981379, 'n_units_Layer_1': 235, 'n_units_Layer_2': 140, 'n_units_Layer_3': 210}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:39:09,126]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 19.45 | sMAPE for Test Set is: 114.39% | rMAE for Test Set is: 6.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:39:16,708]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:39:19,502]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:39:36,920]\u001b[0m Trial 864 finished with value: 2.2102832775630987 and parameters: {'n_hidden': 3, 'learning_rate': 0.048799901811543, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028124921432088973, 'dropout_rate_Layer_2': 0.106537468123903, 'dropout_rate_Layer_3': 0.08854885804396076, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010583089268179137, 'l1_Layer_2': 0.006514576517342911, 'l1_Layer_3': 0.0002728102599643707, 'n_units_Layer_1': 210, 'n_units_Layer_2': 125, 'n_units_Layer_3': 90}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.21 | sMAPE for Validation Set is: 5.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 15.99 | sMAPE for Test Set is: 108.12% | rMAE for Test Set is: 5.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:39:41,610]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:39:46,352]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:39:46,647]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:39:53,721]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:39:56,975]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:01,725]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:08,587]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:14,300]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:21,384]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:24,034]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:35,948]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:41,002]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:46,290]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:54,979]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:40:59,281]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:14,866]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:27,529]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:30,296]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:36,819]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:44,613]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:47,644]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:51,844]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:41:54,816]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:06,556]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:08,835]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:11,552]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:14,400]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:21,470]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:26,460]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:42:47,586]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:43:15,164]\u001b[0m Trial 890 finished with value: 2.048592689911969 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014198027214111463, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11285532744831768, 'dropout_rate_Layer_2': 0.04456158081239686, 'dropout_rate_Layer_3': 0.052242284008679404, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0348568756030515, 'l1_Layer_2': 0.0023255495417762962, 'l1_Layer_3': 0.0039395424450615404, 'n_units_Layer_1': 210, 'n_units_Layer_2': 220, 'n_units_Layer_3': 300}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.05 | sMAPE for Test Set is: 103.72% | rMAE for Test Set is: 4.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:43:20,127]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:43:40,401]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:43:47,895]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:43:54,829]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:44:17,210]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:44:23,097]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:44:25,557]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:44:30,103]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:44:38,014]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:44:42,979]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:44:54,494]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:45:00,151]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:45:02,337]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:45:02,886]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:45:10,111]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:45:22,668]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:45:34,905]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:45:47,560]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:46:02,089]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:46:06,359]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:46:06,804]\u001b[0m Trial 909 finished with value: 1.965747499474822 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011390398749176736, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3514696119634673, 'dropout_rate_Layer_2': 0.04722782394434011, 'dropout_rate_Layer_3': 0.03261839664662246, 'dropout_rate_Layer_4': 0.12567128469911867, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02074365452208527, 'l1_Layer_2': 0.00505093265292835, 'l1_Layer_3': 0.0002724228621289715, 'l1_Layer_4': 0.0003018787299081992, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275, 'n_units_Layer_4': 255}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.50 | sMAPE for Test Set is: 99.96% | rMAE for Test Set is: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:46:21,622]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:46:33,996]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:46:40,695]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:47:05,013]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:47:20,442]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:47:30,218]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:47:45,286]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:47:50,717]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:48:45,420]\u001b[0m Trial 925 finished with value: 2.0012888074231996 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012504899843570848, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36689437347366566, 'dropout_rate_Layer_2': 0.11883037421304966, 'dropout_rate_Layer_3': 0.03846735081776167, 'dropout_rate_Layer_4': 0.151033820728531, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014203346830914232, 'l1_Layer_2': 0.003683971841197784, 'l1_Layer_3': 0.0006434387849676099, 'l1_Layer_4': 0.00023227760146567726, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 260, 'n_units_Layer_4': 245}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.10 | sMAPE for Test Set is: 101.50% | rMAE for Test Set is: 4.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:49:07,436]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:49:12,557]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:49:24,933]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:49:29,945]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:49:35,697]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:49:38,342]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:49:49,900]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:50:00,117]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:50:03,081]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:50:19,458]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:51:09,462]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:51:13,997]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:51:24,768]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:51:29,279]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:51:34,363]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:51:54,254]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:51:59,058]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:52:43,679]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 5.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.44 | sMAPE for Test Set is: 104.41% | rMAE for Test Set is: 4.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:53:02,913]\u001b[0m Trial 944 finished with value: 2.067865282534665 and parameters: {'n_hidden': 3, 'learning_rate': 0.007513237606537624, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0956454183805086, 'dropout_rate_Layer_2': 0.11768942679499096, 'dropout_rate_Layer_3': 0.012606924238337714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.009464763038096756, 'l1_Layer_2': 0.013390092355267896, 'l1_Layer_3': 1.2210325854267458e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 200, 'n_units_Layer_3': 245}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:53:12,968]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:53:18,226]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:53:23,365]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:53:28,430]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:53:36,092]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:53:41,188]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:53:53,116]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:53:58,224]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:54:17,942]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:54:22,901]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:54:33,353]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:54:40,992]\u001b[0m Trial 953 finished with value: 1.9505254661925904 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009362992805129801, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30334597025122817, 'dropout_rate_Layer_2': 0.03581340899146426, 'dropout_rate_Layer_3': 0.026169806591531515, 'dropout_rate_Layer_4': 0.10451867390136449, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02064135565373037, 'l1_Layer_2': 0.00694662643269771, 'l1_Layer_3': 0.0002049825621039712, 'l1_Layer_4': 0.00039038114132448253, 'n_units_Layer_1': 210, 'n_units_Layer_2': 235, 'n_units_Layer_3': 195, 'n_units_Layer_4': 95}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.70 | sMAPE for Test Set is: 90.77% | rMAE for Test Set is: 3.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:54:43,618]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:54:47,860]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:54:48,199]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:54:58,359]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:03,171]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:06,292]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:13,276]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:23,390]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:30,617]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:35,281]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:40,677]\u001b[0m Trial 962 finished with value: 2.0052187601192486 and parameters: {'n_hidden': 3, 'learning_rate': 0.005723374646086183, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08927364472414304, 'dropout_rate_Layer_2': 0.14442215223624208, 'dropout_rate_Layer_3': 0.03389440563890862, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014093903941265069, 'l1_Layer_2': 0.010543836674980834, 'l1_Layer_3': 0.00015546016517470327, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.05 | sMAPE for Test Set is: 95.56% | rMAE for Test Set is: 3.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:55:52,899]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:55:57,803]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:56:44,709]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:56:49,754]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:56:56,806]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:56:59,765]\u001b[0m Trial 970 finished with value: 2.020370296464064 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012273324682074331, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2971294234576137, 'dropout_rate_Layer_2': 0.11138230804070379, 'dropout_rate_Layer_3': 0.02829808318281382, 'dropout_rate_Layer_4': 0.09756358378721375, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02413411932401335, 'l1_Layer_2': 0.005230246106079993, 'l1_Layer_3': 0.00016946008088792436, 'l1_Layer_4': 0.0002877473271526121, 'n_units_Layer_1': 215, 'n_units_Layer_2': 235, 'n_units_Layer_3': 185, 'n_units_Layer_4': 95}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 96.61% | rMAE for Test Set is: 3.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:57:04,077]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:57:12,368]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:57:17,226]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:57:19,264]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:57:26,624]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:57:42,043]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:57:50,979]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:58:26,625]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:58:58,053]\u001b[0m Trial 980 finished with value: 2.0107556383303424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017479390841984124, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09774315242632915, 'dropout_rate_Layer_2': 0.04941476760786996, 'dropout_rate_Layer_3': 0.02984396112564214, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01985063248296891, 'l1_Layer_2': 0.001974289951387532, 'l1_Layer_3': 0.0011160490184596464, 'n_units_Layer_1': 210, 'n_units_Layer_2': 210, 'n_units_Layer_3': 130}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.02 | sMAPE for Test Set is: 100.88% | rMAE for Test Set is: 4.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 08:59:01,266]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:59:08,257]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:59:10,769]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:59:18,246]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:59:25,447]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:59:30,945]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:59:38,689]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 08:59:41,304]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:00:00,593]\u001b[0m Trial 986 finished with value: 1.984987223250462 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020091729192959185, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11134817692675159, 'dropout_rate_Layer_2': 0.03410834374274674, 'dropout_rate_Layer_3': 0.03209139122513861, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025371944809183433, 'l1_Layer_2': 0.0015040236367485232, 'l1_Layer_3': 0.000661527448439455, 'n_units_Layer_1': 215, 'n_units_Layer_2': 205, 'n_units_Layer_3': 120}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.35 | sMAPE for Test Set is: 102.00% | rMAE for Test Set is: 4.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:00:08,298]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:00:13,177]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:00:15,975]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:00:20,136]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:00:20,294]\u001b[0m Trial 991 finished with value: 2.0320331057045937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023136999421913503, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11132132341114549, 'dropout_rate_Layer_2': 0.06232750311198586, 'dropout_rate_Layer_3': 0.05324991164001476, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018760231067284805, 'l1_Layer_2': 0.002330182361457723, 'l1_Layer_3': 0.0011638510050564026, 'n_units_Layer_1': 210, 'n_units_Layer_2': 210, 'n_units_Layer_3': 115}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 5.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 14.03 | sMAPE for Test Set is: 103.56% | rMAE for Test Set is: 4.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:00:27,873]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:00:28,114]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:00:43,203]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:01:23,407]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:01:48,590]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:01:51,010]\u001b[0m Trial 998 finished with value: 1.9804637988497202 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008454443503173974, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2964108125640085, 'dropout_rate_Layer_2': 0.11441406954737751, 'dropout_rate_Layer_3': 0.024155829055149906, 'dropout_rate_Layer_4': 0.10047392818527896, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.017809694028098833, 'l1_Layer_2': 0.022942934100247708, 'l1_Layer_3': 0.0001400044201317024, 'l1_Layer_4': 0.0002819622447286751, 'n_units_Layer_1': 220, 'n_units_Layer_2': 240, 'n_units_Layer_3': 185, 'n_units_Layer_4': 100}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.15 | sMAPE for Test Set is: 92.12% | rMAE for Test Set is: 3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:01:58,359]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:04,808]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:08,389]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:13,157]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:25,798]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:33,002]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:40,441]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:43,467]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:47,930]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:53,311]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:02:57,823]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:03:07,759]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:03:08,629]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:03:13,497]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:03:16,010]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:03:58,054]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:04:00,690]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:04:04,796]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:04:17,773]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:04:25,228]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:04:32,640]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:04:39,729]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:04:47,501]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:04:51,898]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:05:04,390]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:05:09,724]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:05:14,433]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:05:24,611]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:05:31,438]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:05:38,892]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:05:46,409]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:06:44,407]\u001b[0m Trial 1032 finished with value: 1.9807277138495134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016954444924359784, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1250282234409445, 'dropout_rate_Layer_2': 0.0573268825638756, 'dropout_rate_Layer_3': 0.08107320159830088, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.030114071139938373, 'l1_Layer_2': 0.0035488527271108983, 'l1_Layer_3': 0.00021251757464278598, 'n_units_Layer_1': 195, 'n_units_Layer_2': 220, 'n_units_Layer_3': 115}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 104.99% | rMAE for Test Set is: 4.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:06:58,924]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:07:41,155]\u001b[0m Trial 1036 finished with value: 1.9719001163983478 and parameters: {'n_hidden': 3, 'learning_rate': 0.001603651427261878, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12447300630024245, 'dropout_rate_Layer_2': 0.060109575202019185, 'dropout_rate_Layer_3': 0.07655313513051082, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03052248614411026, 'l1_Layer_2': 0.0034314118561393214, 'l1_Layer_3': 0.00034661319247552045, 'n_units_Layer_1': 195, 'n_units_Layer_2': 215, 'n_units_Layer_3': 90}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.07 | sMAPE for Test Set is: 103.82% | rMAE for Test Set is: 4.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:07:43,142]\u001b[0m Trial 1034 finished with value: 2.0338065297021988 and parameters: {'n_hidden': 4, 'learning_rate': 0.000820530646867709, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3550264697333307, 'dropout_rate_Layer_2': 0.25451593433042624, 'dropout_rate_Layer_3': 0.3536230727674621, 'dropout_rate_Layer_4': 0.24082998821179677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.34192927404206e-05, 'l1_Layer_2': 0.0007058217390166501, 'l1_Layer_3': 0.0005323318664673679, 'l1_Layer_4': 0.007449602243844329, 'n_units_Layer_1': 95, 'n_units_Layer_2': 300, 'n_units_Layer_3': 290, 'n_units_Layer_4': 130}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 5.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 17.27 | sMAPE for Test Set is: 111.08% | rMAE for Test Set is: 5.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:07:50,671]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:07:56,162]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:08:21,122]\u001b[0m Trial 1037 finished with value: 1.9583912003639687 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015795724956477978, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1392736331573479, 'dropout_rate_Layer_2': 0.05919373112452417, 'dropout_rate_Layer_3': 0.08276375331479964, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.030395336762522422, 'l1_Layer_2': 0.003603617885127226, 'l1_Layer_3': 0.00030133642741160093, 'n_units_Layer_1': 195, 'n_units_Layer_2': 215, 'n_units_Layer_3': 115}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.88 | sMAPE for Test Set is: 103.45% | rMAE for Test Set is: 4.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:08:28,073]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:08:43,522]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:08:45,895]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:08:55,657]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:08:56,176]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:09:03,142]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:09:13,727]\u001b[0m Trial 1045 finished with value: 2.3107199975409767 and parameters: {'n_hidden': 4, 'learning_rate': 0.01400770278784525, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10862780841508773, 'dropout_rate_Layer_2': 0.10598329292869113, 'dropout_rate_Layer_3': 0.3854816899177122, 'dropout_rate_Layer_4': 0.2955276937115773, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03113588264918569, 'l1_Layer_2': 0.026288766954498693, 'l1_Layer_3': 2.15239427216986e-05, 'l1_Layer_4': 0.00016693744033779737, 'n_units_Layer_1': 195, 'n_units_Layer_2': 105, 'n_units_Layer_3': 225, 'n_units_Layer_4': 225}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.31 | sMAPE for Validation Set is: 6.10% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.67 | sMAPE for Test Set is: 98.85% | rMAE for Test Set is: 3.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:09:18,604]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:09:23,545]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:09:35,094]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:10:22,894]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:10:37,927]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:10:39,741]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:10:57,563]\u001b[0m Trial 1053 finished with value: 2.058145342015243 and parameters: {'n_hidden': 3, 'learning_rate': 0.009089460298214391, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08659083843204617, 'dropout_rate_Layer_2': 0.13430563892316508, 'dropout_rate_Layer_3': 0.019870665881855404, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.010897642545438796, 'l1_Layer_2': 0.011783665901864698, 'l1_Layer_3': 1.6621949107027365e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.35 | sMAPE for Test Set is: 102.44% | rMAE for Test Set is: 4.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:11:02,497]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:11:59,313]\u001b[0m Trial 1054 finished with value: 1.9641838830986948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014164265657262273, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14040631938818224, 'dropout_rate_Layer_2': 0.06579954794185362, 'dropout_rate_Layer_3': 0.0726991087834836, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.046103778670711616, 'l1_Layer_2': 0.004188016185540524, 'l1_Layer_3': 0.00023753442092359532, 'n_units_Layer_1': 195, 'n_units_Layer_2': 225, 'n_units_Layer_3': 115}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.79 | sMAPE for Test Set is: 105.85% | rMAE for Test Set is: 4.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:12:16,680]\u001b[0m Trial 1056 finished with value: 1.9665207971008132 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013770889073291728, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14839981713057765, 'dropout_rate_Layer_2': 0.06828048024291558, 'dropout_rate_Layer_3': 0.07289025052047247, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.052880374763251865, 'l1_Layer_2': 0.0033048017398120376, 'l1_Layer_3': 0.00021680842470756195, 'n_units_Layer_1': 195, 'n_units_Layer_2': 225, 'n_units_Layer_3': 110}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.68 | sMAPE for Test Set is: 102.85% | rMAE for Test Set is: 4.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:12:19,847]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:12:29,278]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:12:48,623]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:12:49,115]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:12:58,712]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:13:13,889]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:13:21,478]\u001b[0m Trial 1063 finished with value: 1.9227521833094805 and parameters: {'n_hidden': 3, 'learning_rate': 0.004546897180807734, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07163767729585724, 'dropout_rate_Layer_2': 0.16809367417446486, 'dropout_rate_Layer_3': 0.031015920790221002, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015566697442048937, 'l1_Layer_2': 0.019775108844901024, 'l1_Layer_3': 3.727038038206956e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 250}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 78.82% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:13:24,390]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:13:33,493]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:13:41,241]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:13:48,598]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:13:55,895]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:13:59,186]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:14:03,726]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:14:08,245]\u001b[0m Trial 1068 finished with value: 1.9283848856547692 and parameters: {'n_hidden': 3, 'learning_rate': 0.004748896105242258, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06322684586286312, 'dropout_rate_Layer_2': 0.1778400605180035, 'dropout_rate_Layer_3': 0.03328340285567058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015162603629335003, 'l1_Layer_2': 0.03872383602257735, 'l1_Layer_3': 3.5662452580232356e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.15 | sMAPE for Test Set is: 92.63% | rMAE for Test Set is: 3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:14:13,672]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:14:21,340]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:05,841]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:18,483]\u001b[0m Trial 1075 finished with value: 1.9319637685203908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017133961273709706, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1316501540072456, 'dropout_rate_Layer_2': 0.055667199208221364, 'dropout_rate_Layer_3': 0.07033468698629525, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07578906646565226, 'l1_Layer_2': 0.0038192462074543125, 'l1_Layer_3': 0.00018553229616954326, 'n_units_Layer_1': 260, 'n_units_Layer_2': 225, 'n_units_Layer_3': 125}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 13.50 | sMAPE for Test Set is: 102.44% | rMAE for Test Set is: 4.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:15:23,174]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:23,470]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:28,801]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:48,332]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:15:53,251]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:16:00,902]\u001b[0m Trial 1080 finished with value: 1.9315307623669644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035150631599724564, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0506414208647708, 'dropout_rate_Layer_2': 0.16173214602666372, 'dropout_rate_Layer_3': 0.0333343068334202, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013937151517960376, 'l1_Layer_2': 0.01885369332371376, 'l1_Layer_3': 3.7542002008000293e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 260}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.73 | sMAPE for Test Set is: 82.91% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:16:06,073]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:16:13,013]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:16:18,378]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:16:25,301]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:16:33,527]\u001b[0m Trial 1084 finished with value: 1.9100855441066809 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035756603396516905, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05103814836150659, 'dropout_rate_Layer_2': 0.1606724731654599, 'dropout_rate_Layer_3': 0.03555407809901946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02189929658418932, 'l1_Layer_2': 0.019820588564163164, 'l1_Layer_3': 4.131296765397467e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 155, 'n_units_Layer_3': 270}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.87 | sMAPE for Test Set is: 83.72% | rMAE for Test Set is: 2.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:16:43,414]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:26,251]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:31,367]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:38,567]\u001b[0m Trial 1087 finished with value: 1.9545933032790597 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010607401067887576, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3022044733188283, 'dropout_rate_Layer_2': 0.04215888405148147, 'dropout_rate_Layer_3': 0.18436094557652016, 'dropout_rate_Layer_4': 0.15582219500477582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04209593215816451, 'l1_Layer_2': 0.007748838920357628, 'l1_Layer_3': 9.558642520347282e-05, 'l1_Layer_4': 0.00032439900935190126, 'n_units_Layer_1': 195, 'n_units_Layer_2': 280, 'n_units_Layer_3': 205, 'n_units_Layer_4': 285}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.24 | sMAPE for Test Set is: 89.52% | rMAE for Test Set is: 2.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:17:46,322]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:51,152]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:17:58,158]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:01,251]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:05,546]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:08,617]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:13,253]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:16,052]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:18,313]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:24,892]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:25,462]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:32,495]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:34,846]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:50,287]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:18:57,826]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:19:00,817]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:19:08,393]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:19:12,861]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:19:18,221]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:19:38,128]\u001b[0m Trial 1104 finished with value: 1.9495667592862025 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006402439716180612, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3436716028760282, 'dropout_rate_Layer_2': 0.036316474183812744, 'dropout_rate_Layer_3': 0.18001309965202397, 'dropout_rate_Layer_4': 0.19487849448061056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06914865044788845, 'l1_Layer_2': 0.006455713490037033, 'l1_Layer_3': 2.8835125946181372e-05, 'l1_Layer_4': 0.0002591256503418923, 'n_units_Layer_1': 85, 'n_units_Layer_2': 300, 'n_units_Layer_3': 205, 'n_units_Layer_4': 280}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.17 | sMAPE for Test Set is: 85.19% | rMAE for Test Set is: 2.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:19:42,835]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:19:47,552]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:19:55,970]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:20:06,401]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:20:33,743]\u001b[0m Trial 1115 finished with value: 1.9415332388567081 and parameters: {'n_hidden': 3, 'learning_rate': 0.001568472576327367, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12405866979533965, 'dropout_rate_Layer_2': 0.05055515092104312, 'dropout_rate_Layer_3': 0.05159064616189172, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07881459129132458, 'l1_Layer_2': 0.002812427741996589, 'l1_Layer_3': 0.00020371956332877888, 'n_units_Layer_1': 200, 'n_units_Layer_2': 235, 'n_units_Layer_3': 120}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.52 | sMAPE for Test Set is: 99.63% | rMAE for Test Set is: 3.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:20:38,439]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:20:43,873]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:20:48,662]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:21:05,340]\u001b[0m Trial 1116 finished with value: 1.9699179586485116 and parameters: {'n_hidden': 3, 'learning_rate': 0.001256196761897008, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12316193010470368, 'dropout_rate_Layer_2': 0.06199999891745713, 'dropout_rate_Layer_3': 0.06524018692641573, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.029104183924054897, 'l1_Layer_2': 0.002832167469884496, 'l1_Layer_3': 0.0002980021853573855, 'n_units_Layer_1': 205, 'n_units_Layer_2': 225, 'n_units_Layer_3': 110}. Best is trial 812 with value: 1.9056329681620252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.64 | sMAPE for Test Set is: 102.75% | rMAE for Test Set is: 4.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:21:11,298]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:21:15,869]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:21:35,534]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:21:40,610]\u001b[0m Trial 1123 finished with value: 1.891026773852343 and parameters: {'n_hidden': 3, 'learning_rate': 0.004807314590195655, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03717412409616887, 'dropout_rate_Layer_2': 0.16549800164542075, 'dropout_rate_Layer_3': 0.053197904561409805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01891028261629594, 'l1_Layer_2': 0.0734053046199148, 'l1_Layer_3': 3.8751270002518636e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 1123 with value: 1.891026773852343.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.39 | sMAPE for Test Set is: 89.50% | rMAE for Test Set is: 2.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:21:44,907]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:21:47,557]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:21:50,164]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:21:52,717]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:22:13,088]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:22:32,689]\u001b[0m Trial 1130 finished with value: 1.942204661653473 and parameters: {'n_hidden': 3, 'learning_rate': 0.005035100280583618, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03408079376433289, 'dropout_rate_Layer_2': 0.1722279482777753, 'dropout_rate_Layer_3': 0.07604987421645992, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02049596994177754, 'l1_Layer_2': 0.07856776460054848, 'l1_Layer_3': 5.223999313244533e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 1123 with value: 1.891026773852343.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.84 | sMAPE for Test Set is: 91.17% | rMAE for Test Set is: 3.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:22:39,847]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:22:40,146]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:22:47,549]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:23:07,084]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:23:34,799]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:23:52,589]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:13,179]\u001b[0m Trial 1135 finished with value: 1.9752897188072984 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016792741793544958, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13914279579135982, 'dropout_rate_Layer_2': 0.0488242222875291, 'dropout_rate_Layer_3': 0.07893276275013274, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07691999339917782, 'l1_Layer_2': 0.003669319194090885, 'l1_Layer_3': 0.00021581356077133757, 'n_units_Layer_1': 270, 'n_units_Layer_2': 215, 'n_units_Layer_3': 125}. Best is trial 1123 with value: 1.891026773852343.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.62 | sMAPE for Test Set is: 102.93% | rMAE for Test Set is: 4.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:24:18,026]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:26,120]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:30,599]\u001b[0m Trial 1137 finished with value: 1.935492419752551 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012784900542434341, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16335479186640695, 'dropout_rate_Layer_2': 0.04365580163599644, 'dropout_rate_Layer_3': 0.06965849205489882, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07949503112139997, 'l1_Layer_2': 0.0005396322917680816, 'l1_Layer_3': 0.0002878429693640844, 'n_units_Layer_1': 190, 'n_units_Layer_2': 215, 'n_units_Layer_3': 110}. Best is trial 1123 with value: 1.891026773852343.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.08 | sMAPE for Test Set is: 88.65% | rMAE for Test Set is: 2.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:24:33,264]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:38,283]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:41,066]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:45,290]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:48,372]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:52,506]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:24:55,650]\u001b[0m Trial 1141 finished with value: 1.8741611376909797 and parameters: {'n_hidden': 3, 'learning_rate': 0.004577650431403123, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0376827276157942, 'dropout_rate_Layer_2': 0.17747977536158147, 'dropout_rate_Layer_3': 0.07819170547990524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.020234862341349732, 'l1_Layer_2': 0.0794044088911393, 'l1_Layer_3': 5.0623434851690226e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 10.24 | sMAPE for Test Set is: 92.46% | rMAE for Test Set is: 3.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:24:57,368]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:00,588]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:02,990]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:07,274]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:09,838]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:12,786]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:15,325]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:15,509]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:23,413]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:36,232]\u001b[0m Trial 1155 finished with value: 1.9274809101662378 and parameters: {'n_hidden': 3, 'learning_rate': 0.004596810905219277, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009661164428526818, 'dropout_rate_Layer_2': 0.195920063907177, 'dropout_rate_Layer_3': 0.05234859259198407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04942569184847732, 'l1_Layer_2': 0.09861781027877418, 'l1_Layer_3': 3.660567741069872e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.77 | sMAPE for Test Set is: 91.32% | rMAE for Test Set is: 3.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:25:41,670]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:48,578]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:25:52,461]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:26:23,723]\u001b[0m Trial 1157 finished with value: 1.9724389000844684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016616561652853792, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13085510284537824, 'dropout_rate_Layer_2': 0.04935516164421301, 'dropout_rate_Layer_3': 0.07001026525921883, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07030374244466858, 'l1_Layer_2': 0.004318422814569366, 'l1_Layer_3': 0.00026424965642890796, 'n_units_Layer_1': 190, 'n_units_Layer_2': 215, 'n_units_Layer_3': 95}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.17 | sMAPE for Test Set is: 101.40% | rMAE for Test Set is: 4.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:26:38,933]\u001b[0m Trial 1161 finished with value: 2.0176590869679796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022238979594264257, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1749306106217564, 'dropout_rate_Layer_2': 0.07518813123174316, 'dropout_rate_Layer_3': 0.0846010653566444, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05060775760394613, 'l1_Layer_2': 0.003120768800291765, 'l1_Layer_3': 0.00015243209790092438, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 120}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.95 | sMAPE for Test Set is: 103.46% | rMAE for Test Set is: 4.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:26:41,344]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:26:48,417]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:26:53,831]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:27:38,931]\u001b[0m Trial 1166 finished with value: 1.9602871448012482 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015168121493128043, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16695534343721788, 'dropout_rate_Layer_2': 0.0732697404750448, 'dropout_rate_Layer_3': 0.08568290098650763, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05252176321401487, 'l1_Layer_2': 0.003384603967190537, 'l1_Layer_3': 0.00015063765826321988, 'n_units_Layer_1': 250, 'n_units_Layer_2': 210, 'n_units_Layer_3': 80}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.87 | sMAPE for Test Set is: 103.34% | rMAE for Test Set is: 4.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:27:56,261]\u001b[0m Trial 1163 finished with value: 1.9686600788478748 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015147285604553621, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17837185068911626, 'dropout_rate_Layer_2': 0.08010575912955832, 'dropout_rate_Layer_3': 0.08584541961564206, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05347930793604953, 'l1_Layer_2': 0.0036972579329654955, 'l1_Layer_3': 0.00017607648579101172, 'n_units_Layer_1': 270, 'n_units_Layer_2': 210, 'n_units_Layer_3': 95}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:27:56,398]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.05 | sMAPE for Test Set is: 103.89% | rMAE for Test Set is: 4.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:28:02,478]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:28:09,981]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:28:27,073]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:28:46,629]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:29:09,651]\u001b[0m Trial 1173 finished with value: 1.8841007795591374 and parameters: {'n_hidden': 3, 'learning_rate': 0.003092251708344122, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009640953816951993, 'dropout_rate_Layer_2': 0.19631553304400814, 'dropout_rate_Layer_3': 0.048568214636474316, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03899769605232227, 'l1_Layer_2': 0.06390847086575326, 'l1_Layer_3': 3.627903359733987e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.94% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.86 | sMAPE for Test Set is: 83.55% | rMAE for Test Set is: 2.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:29:14,017]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:29:23,867]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:29:29,253]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:29:44,591]\u001b[0m Trial 1174 finished with value: 1.8905666390832803 and parameters: {'n_hidden': 3, 'learning_rate': 0.003001890122594385, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014335595895901332, 'dropout_rate_Layer_2': 0.19931859376509142, 'dropout_rate_Layer_3': 0.05889426394569903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05466224685885449, 'l1_Layer_2': 0.09519004443382113, 'l1_Layer_3': 2.2393230778555832e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 96.42% | rMAE for Test Set is: 3.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:30:26,347]\u001b[0m Trial 1177 finished with value: 1.9603682841402197 and parameters: {'n_hidden': 3, 'learning_rate': 0.001189486867073652, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17260945426958302, 'dropout_rate_Layer_2': 0.07474793314862699, 'dropout_rate_Layer_3': 0.07551880792431397, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07697758219703674, 'l1_Layer_2': 0.002914162951686774, 'l1_Layer_3': 0.00018051184600789867, 'n_units_Layer_1': 275, 'n_units_Layer_2': 205, 'n_units_Layer_3': 85}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.28 | sMAPE for Test Set is: 101.88% | rMAE for Test Set is: 4.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:30:31,082]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:30:40,439]\u001b[0m Trial 1178 finished with value: 2.009073680375098 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013783332065487835, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17650402739009846, 'dropout_rate_Layer_2': 0.07533038672504709, 'dropout_rate_Layer_3': 0.07701882335168457, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07764351462722534, 'l1_Layer_2': 0.0028428061558761937, 'l1_Layer_3': 0.00016563551467466874, 'n_units_Layer_1': 265, 'n_units_Layer_2': 205, 'n_units_Layer_3': 80}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.42 | sMAPE for Test Set is: 102.33% | rMAE for Test Set is: 4.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:30:45,338]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:30:50,297]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:30:53,719]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:30:57,845]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:31:15,572]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:31:45,350]\u001b[0m Trial 1186 finished with value: 1.8965879664074772 and parameters: {'n_hidden': 3, 'learning_rate': 0.003101943333329156, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00660878229434176, 'dropout_rate_Layer_2': 0.22601545325747685, 'dropout_rate_Layer_3': 0.0818492485444581, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.059982814087349304, 'l1_Layer_2': 0.05996356944172965, 'l1_Layer_3': 1.678418839304628e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 165, 'n_units_Layer_3': 285}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 90.85% | rMAE for Test Set is: 3.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:31:50,437]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:31:51,490]\u001b[0m Trial 1184 finished with value: 1.9727639420294452 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013231141303317933, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18567626390927605, 'dropout_rate_Layer_2': 0.08135194189093511, 'dropout_rate_Layer_3': 0.0911833526988773, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0797553865873601, 'l1_Layer_2': 0.005137810555918653, 'l1_Layer_3': 0.00019208412474497187, 'n_units_Layer_1': 270, 'n_units_Layer_2': 200, 'n_units_Layer_3': 85}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.69 | sMAPE for Test Set is: 102.87% | rMAE for Test Set is: 4.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:32:00,893]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:32:12,504]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:32:16,076]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:32:20,408]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:32:24,880]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:32:42,916]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:33:07,408]\u001b[0m Trial 1195 finished with value: 1.9081063736572836 and parameters: {'n_hidden': 3, 'learning_rate': 0.003138742806002743, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014122764364593133, 'dropout_rate_Layer_2': 0.2281673283797856, 'dropout_rate_Layer_3': 0.09946527800356324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07101821475932885, 'l1_Layer_2': 0.0662910040678881, 'l1_Layer_3': 2.1937682006597505e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.79 | sMAPE for Test Set is: 91.28% | rMAE for Test Set is: 3.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:33:25,518]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:33:29,975]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:33:53,248]\u001b[0m Trial 1198 finished with value: 1.910104880581577 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030519456696873025, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014128058883880912, 'dropout_rate_Layer_2': 0.2291605979319201, 'dropout_rate_Layer_3': 0.11680373207219552, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0672443832732059, 'l1_Layer_2': 0.06471345624822059, 'l1_Layer_3': 2.256910640789827e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.88 | sMAPE for Test Set is: 87.84% | rMAE for Test Set is: 2.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:34:14,788]\u001b[0m Trial 1196 finished with value: 1.9216467200089211 and parameters: {'n_hidden': 3, 'learning_rate': 0.00116752711080057, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15938995779295367, 'dropout_rate_Layer_2': 0.08565791410890257, 'dropout_rate_Layer_3': 0.07581725856148264, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07730348943900418, 'l1_Layer_2': 0.005372252510662448, 'l1_Layer_3': 0.00014065324789609473, 'n_units_Layer_1': 275, 'n_units_Layer_2': 205, 'n_units_Layer_3': 85}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:34:14,943]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 13.74 | sMAPE for Test Set is: 103.03% | rMAE for Test Set is: 4.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:34:21,643]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:34:21,679]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:35:09,002]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:35:15,970]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:35:21,095]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:35:30,428]\u001b[0m Trial 1203 finished with value: 1.9658936704692451 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011934009656017867, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16206185972746923, 'dropout_rate_Layer_2': 0.08711842912951276, 'dropout_rate_Layer_3': 0.07974671919627906, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08023334335487078, 'l1_Layer_2': 0.006906565552741302, 'l1_Layer_3': 0.00015444226696285975, 'n_units_Layer_1': 265, 'n_units_Layer_2': 205, 'n_units_Layer_3': 85}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.01 | sMAPE for Test Set is: 103.79% | rMAE for Test Set is: 4.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:36:25,952]\u001b[0m Trial 1206 finished with value: 1.9549043542890352 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012163731123927383, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18311556202600618, 'dropout_rate_Layer_2': 0.07304592515729341, 'dropout_rate_Layer_3': 0.0701490234255651, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07610318612730702, 'l1_Layer_2': 0.006443908383080298, 'l1_Layer_3': 0.000217313703708698, 'n_units_Layer_1': 285, 'n_units_Layer_2': 205, 'n_units_Layer_3': 95}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.01 | sMAPE for Test Set is: 103.79% | rMAE for Test Set is: 4.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:36:30,583]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:36:33,195]\u001b[0m Trial 1207 finished with value: 1.9280667732636576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011581828807090615, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15727477222473804, 'dropout_rate_Layer_2': 0.08851740334360209, 'dropout_rate_Layer_3': 0.09531856070175043, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07923581520235443, 'l1_Layer_2': 0.006522799936343587, 'l1_Layer_3': 0.00022020024659938635, 'n_units_Layer_1': 270, 'n_units_Layer_2': 200, 'n_units_Layer_3': 95}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 14.39 | sMAPE for Test Set is: 104.83% | rMAE for Test Set is: 4.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:36:38,126]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:36:42,577]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:36:45,778]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:37:09,879]\u001b[0m Trial 1213 finished with value: 1.913233657571413 and parameters: {'n_hidden': 3, 'learning_rate': 0.003171989925199008, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014454935487948826, 'dropout_rate_Layer_2': 0.24071533712876977, 'dropout_rate_Layer_3': 0.114547437202801, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06359028653515607, 'l1_Layer_2': 0.061847112170714584, 'l1_Layer_3': 2.1727285183497555e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.55 | sMAPE for Test Set is: 86.55% | rMAE for Test Set is: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:37:14,782]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:37:18,053]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:37:41,975]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:38:23,768]\u001b[0m Trial 1217 finished with value: 1.898769494355058 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024115293744775557, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0152999554621066, 'dropout_rate_Layer_2': 0.2532554736239937, 'dropout_rate_Layer_3': 0.09544891734000586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06081944631413868, 'l1_Layer_2': 0.060978150215926584, 'l1_Layer_3': 1.6286163966154805e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.39 | sMAPE for Test Set is: 89.39% | rMAE for Test Set is: 2.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:38:27,123]\u001b[0m Trial 1210 finished with value: 1.9969351982670789 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007283316564541432, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17020296281144603, 'dropout_rate_Layer_2': 0.04831430583838793, 'dropout_rate_Layer_3': 0.3180276744181253, 'dropout_rate_Layer_4': 0.25437426894904724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0023401552955299655, 'l1_Layer_2': 0.00019299185199118376, 'l1_Layer_3': 0.0013905773732886446, 'l1_Layer_4': 2.472802566168557e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290, 'n_units_Layer_4': 100}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.54 | sMAPE for Test Set is: 97.07% | rMAE for Test Set is: 3.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:38:31,280]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:38:36,271]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:38:41,806]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:38:44,693]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:38:49,268]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:38:54,000]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:39:04,299]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:39:53,223]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:40:00,965]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:40:08,308]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:40:36,212]\u001b[0m Trial 1229 finished with value: 1.8908330579665344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028767780329714988, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0004323136415946612, 'dropout_rate_Layer_2': 0.26173831703962913, 'dropout_rate_Layer_3': 0.09919851321582279, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07045382803856748, 'l1_Layer_2': 0.07101562173270233, 'l1_Layer_3': 1.2070970482616193e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.25 | sMAPE for Test Set is: 89.16% | rMAE for Test Set is: 2.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:40:41,103]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:40:53,286]\u001b[0m Trial 1219 finished with value: 1.977343967089662 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007322248887115438, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06238081130657904, 'dropout_rate_Layer_2': 0.04577561043991257, 'dropout_rate_Layer_3': 0.33161641518929974, 'dropout_rate_Layer_4': 0.2548559799788739, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0019950053591232496, 'l1_Layer_2': 0.00024831542921451423, 'l1_Layer_3': 0.0013733537207746924, 'l1_Layer_4': 2.6704179685941182e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290, 'n_units_Layer_4': 100}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.11 | sMAPE for Test Set is: 103.94% | rMAE for Test Set is: 4.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:41:06,422]\u001b[0m Trial 1231 finished with value: 1.9006954425673246 and parameters: {'n_hidden': 3, 'learning_rate': 0.003951200419211109, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0020716342841683444, 'dropout_rate_Layer_2': 0.2589079909372892, 'dropout_rate_Layer_3': 0.09472381429317525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03744223524423348, 'l1_Layer_2': 0.04720353941501383, 'l1_Layer_3': 1.1392681808919395e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.99% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 77.95% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:41:17,826]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:41:50,887]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:42:13,267]\u001b[0m Trial 1235 finished with value: 1.9043624318689385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023833384892865484, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0026786193115152217, 'dropout_rate_Layer_2': 0.2924487525418047, 'dropout_rate_Layer_3': 0.09102468015216873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08156055272630591, 'l1_Layer_2': 0.07556367552791111, 'l1_Layer_3': 1.174315134237816e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 78.56% | rMAE for Test Set is: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:42:31,087]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:42:38,358]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:42:58,531]\u001b[0m Trial 1233 finished with value: 2.034720764089119 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007717743655150592, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05676440309433872, 'dropout_rate_Layer_2': 0.10273899993709742, 'dropout_rate_Layer_3': 0.3303171213618072, 'dropout_rate_Layer_4': 0.2543515677465465, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0022181876180988854, 'l1_Layer_2': 0.0002417579474692214, 'l1_Layer_3': 0.0013267596428732482, 'l1_Layer_4': 2.3565541471038775e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280, 'n_units_Layer_4': 95}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.50 | sMAPE for Test Set is: 96.54% | rMAE for Test Set is: 3.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:43:18,703]\u001b[0m Trial 1238 finished with value: 1.890716867739928 and parameters: {'n_hidden': 3, 'learning_rate': 0.002506626797483214, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0004862551077472674, 'dropout_rate_Layer_2': 0.29719787080467835, 'dropout_rate_Layer_3': 0.09441489558426842, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08391915053041643, 'l1_Layer_2': 0.07886801256934185, 'l1_Layer_3': 1.0646586045172212e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.42 | sMAPE for Test Set is: 96.03% | rMAE for Test Set is: 3.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:44:11,773]\u001b[0m Trial 1239 finished with value: 1.969450928725344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012751702238952202, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15700598578513628, 'dropout_rate_Layer_2': 0.02856609112707341, 'dropout_rate_Layer_3': 0.07906316617577865, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08185378595546512, 'l1_Layer_2': 0.005317526699567303, 'l1_Layer_3': 0.00014948787061631148, 'n_units_Layer_1': 270, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.14 | sMAPE for Test Set is: 101.42% | rMAE for Test Set is: 4.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:44:16,629]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:01,200]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:05,324]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:07,885]\u001b[0m Trial 1241 finished with value: 1.946422764176097 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012438552504360576, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15908365992091633, 'dropout_rate_Layer_2': 0.08423347597288856, 'dropout_rate_Layer_3': 0.07758770176048582, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07787685875188674, 'l1_Layer_2': 0.0052264881576794785, 'l1_Layer_3': 0.00012045939687430555, 'n_units_Layer_1': 270, 'n_units_Layer_2': 200, 'n_units_Layer_3': 95}. Best is trial 1141 with value: 1.8741611376909797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.89 | sMAPE for Test Set is: 103.55% | rMAE for Test Set is: 4.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:45:17,940]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:25,555]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:35,801]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:45:40,759]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:46:10,133]\u001b[0m Trial 1249 finished with value: 1.869752717626384 and parameters: {'n_hidden': 3, 'learning_rate': 0.002443905261194524, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0007636870303881094, 'dropout_rate_Layer_2': 0.30187288953263386, 'dropout_rate_Layer_3': 0.08759487035329389, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.049819053395184956, 'l1_Layer_2': 0.08217488725370511, 'l1_Layer_3': 1.2036293647729933e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.34 | sMAPE for Test Set is: 81.37% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:46:33,162]\u001b[0m Trial 1250 finished with value: 1.8889841924743724 and parameters: {'n_hidden': 3, 'learning_rate': 0.002430160844828881, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0004867918849734655, 'dropout_rate_Layer_2': 0.2937733135962377, 'dropout_rate_Layer_3': 0.09436694376500518, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09884948803640624, 'l1_Layer_2': 0.08321245270529226, 'l1_Layer_3': 1.203068027827881e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 84.09% | rMAE for Test Set is: 2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:46:37,457]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:46:47,750]\u001b[0m Trial 1246 finished with value: 1.985845302185755 and parameters: {'n_hidden': 3, 'learning_rate': 0.00118429280080994, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16263258899805935, 'dropout_rate_Layer_2': 0.026433114787720664, 'dropout_rate_Layer_3': 0.09294555038106314, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06520897208116254, 'l1_Layer_2': 0.005231634352593616, 'l1_Layer_3': 0.00011222136959176031, 'n_units_Layer_1': 275, 'n_units_Layer_2': 190, 'n_units_Layer_3': 95}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.84 | sMAPE for Test Set is: 103.55% | rMAE for Test Set is: 4.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:46:50,964]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:47:00,607]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:47:47,418]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:47:55,474]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:05,698]\u001b[0m Trial 1252 finished with value: 1.940302014785994 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012707137391374211, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1628178176272855, 'dropout_rate_Layer_2': 0.025227565710281015, 'dropout_rate_Layer_3': 0.08765289911785448, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06573309155193797, 'l1_Layer_2': 0.005095442838501554, 'l1_Layer_3': 0.00015110456334096372, 'n_units_Layer_1': 275, 'n_units_Layer_2': 190, 'n_units_Layer_3': 105}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 13.68 | sMAPE for Test Set is: 102.95% | rMAE for Test Set is: 4.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:48:11,898]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:19,383]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:20,468]\u001b[0m Trial 1257 finished with value: 1.9058446505660234 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027947269750916736, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0019208685260659903, 'dropout_rate_Layer_2': 0.3014917655396037, 'dropout_rate_Layer_3': 0.08550068387326294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09202610884849949, 'l1_Layer_2': 0.07970351083163277, 'l1_Layer_3': 1.265024708910205e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 83.80% | rMAE for Test Set is: 2.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:48:24,735]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:27,188]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:30,209]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:48:36,775]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:49:08,554]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:49:12,916]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:49:30,474]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:49:37,915]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:49:55,956]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:49:58,701]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:50:13,024]\u001b[0m Trial 1267 finished with value: 1.9838820798348227 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013216636352372585, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18749078059342603, 'dropout_rate_Layer_2': 0.07887072246891316, 'dropout_rate_Layer_3': 0.08270285394545879, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07204893332019888, 'l1_Layer_2': 0.006748142399843384, 'l1_Layer_3': 0.00026087564638338273, 'n_units_Layer_1': 285, 'n_units_Layer_2': 200, 'n_units_Layer_3': 95}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.74 | sMAPE for Test Set is: 105.82% | rMAE for Test Set is: 4.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:50:16,068]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:50:28,033]\u001b[0m Trial 1271 finished with value: 1.897043790359959 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024097369036313624, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02516620861059609, 'dropout_rate_Layer_2': 0.2930583198696756, 'dropout_rate_Layer_3': 0.09522499568045281, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04989601532868275, 'l1_Layer_2': 0.05148100066793152, 'l1_Layer_3': 1.0748988090588334e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.99% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 78.31% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:50:38,179]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:50:47,667]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:50:52,515]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:51:10,130]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:51:13,069]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:51:20,310]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:51:20,357]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:51:26,769]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:51:31,792]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:51:42,129]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:51:47,449]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:51:52,149]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:52:06,471]\u001b[0m Trial 1282 finished with value: 1.8829413213498987 and parameters: {'n_hidden': 3, 'learning_rate': 0.00252179717416262, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03556431828504383, 'dropout_rate_Layer_2': 0.25875152760424375, 'dropout_rate_Layer_3': 0.07984522431155802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.035357573019486416, 'l1_Layer_2': 0.09724911721066037, 'l1_Layer_3': 1.0212208219638066e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 130, 'n_units_Layer_3': 290}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.94% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.49 | sMAPE for Test Set is: 89.82% | rMAE for Test Set is: 2.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:52:11,299]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:52:19,118]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:52:26,524]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:52:38,570]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:53:03,848]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:53:08,871]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:53:16,143]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:53:33,754]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:53:36,712]\u001b[0m Trial 1289 finished with value: 1.9871302946630578 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006241158805116816, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08239444109387725, 'dropout_rate_Layer_2': 0.10607928801896868, 'dropout_rate_Layer_3': 0.29618107039944197, 'dropout_rate_Layer_4': 0.3020945778372756, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0018953604537987796, 'l1_Layer_2': 0.00041322070374495115, 'l1_Layer_3': 0.0005872742189796844, 'l1_Layer_4': 1.544883334485273e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280, 'n_units_Layer_4': 90}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 87.94% | rMAE for Test Set is: 2.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:54:08,811]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:11,610]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:13,694]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:19,096]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:25,724]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:28,248]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:31,124]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:31,744]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:36,830]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:51,891]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:54:54,519]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:11,938]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:16,508]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:21,335]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:39,428]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:55:57,210]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:56:03,752]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:56:22,359]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:56:29,950]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:56:35,004]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:57:05,180]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:57:09,442]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:57:12,769]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:57:21,936]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:57:27,360]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:57:34,840]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:58:19,239]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:58:29,569]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:58:36,799]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:59:10,420]\u001b[0m Trial 1322 finished with value: 1.9402987354250152 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013181404262479228, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18390408239327352, 'dropout_rate_Layer_2': 0.03455832502386881, 'dropout_rate_Layer_3': 0.05812446662783802, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.053171134691849045, 'l1_Layer_2': 0.008369595812795873, 'l1_Layer_3': 0.00015897123432981298, 'n_units_Layer_1': 250, 'n_units_Layer_2': 195, 'n_units_Layer_3': 105}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 14.23 | sMAPE for Test Set is: 104.38% | rMAE for Test Set is: 4.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 09:59:17,251]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:59:22,384]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:59:22,487]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:59:30,734]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 09:59:33,678]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:00:02,672]\u001b[0m Trial 1330 finished with value: 1.9011296349797169 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023221490849363114, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03160241200498824, 'dropout_rate_Layer_2': 0.254562274285058, 'dropout_rate_Layer_3': 0.07521331285145497, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.037975309410596236, 'l1_Layer_2': 0.05099139278054974, 'l1_Layer_3': 1.4759639648241889e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 130, 'n_units_Layer_3': 290}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.99% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.49 | sMAPE for Test Set is: 86.21% | rMAE for Test Set is: 2.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:00:11,045]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:00:15,643]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:00:18,672]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:00:28,657]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:00:35,511]\u001b[0m Trial 1331 finished with value: 1.9558085443098898 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015095349364308522, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15937711130164828, 'dropout_rate_Layer_2': 0.038056081239557844, 'dropout_rate_Layer_3': 0.056216236970676924, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0525982008306463, 'l1_Layer_2': 0.006787769865133781, 'l1_Layer_3': 0.00012172831486702164, 'n_units_Layer_1': 245, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.08 | sMAPE for Test Set is: 104.03% | rMAE for Test Set is: 4.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:00:40,470]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:00:43,822]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:00:53,047]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:01:10,274]\u001b[0m Trial 1336 finished with value: 1.874573774479843 and parameters: {'n_hidden': 3, 'learning_rate': 0.00200911645980546, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021494644307275355, 'dropout_rate_Layer_2': 0.31948141346448106, 'dropout_rate_Layer_3': 0.06739209766309873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05381726385652391, 'l1_Layer_2': 0.08622595475406844, 'l1_Layer_3': 1.8136169589729508e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 10.05 | sMAPE for Test Set is: 91.55% | rMAE for Test Set is: 3.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:01:18,237]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:01:45,858]\u001b[0m Trial 1340 finished with value: 1.995455685070329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012251699429655476, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16840293037048823, 'dropout_rate_Layer_2': 0.03888900353151652, 'dropout_rate_Layer_3': 0.049662766443573904, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05580879989926478, 'l1_Layer_2': 0.008745191409269213, 'l1_Layer_3': 0.00010813066252875619, 'n_units_Layer_1': 245, 'n_units_Layer_2': 195, 'n_units_Layer_3': 105}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.24 | sMAPE for Test Set is: 104.51% | rMAE for Test Set is: 4.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:01:50,550]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:01:55,731]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:00,848]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:06,072]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:13,288]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:16,122]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:22,810]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:27,480]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:32,611]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:38,129]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:45,398]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:02:58,063]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:02,874]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:08,372]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:11,123]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:35,523]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:40,608]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:03:45,931]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:04:43,563]\u001b[0m Trial 1356 finished with value: 2.005073589954519 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007641385349273033, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1735991091010005, 'dropout_rate_Layer_2': 0.1440577113754847, 'dropout_rate_Layer_3': 0.2623349751735995, 'dropout_rate_Layer_4': 0.2262083423248958, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006834535723753724, 'l1_Layer_2': 0.0009337114536480789, 'l1_Layer_3': 0.0014713114051247648, 'l1_Layer_4': 1.9072255414991108e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 130, 'n_units_Layer_3': 300, 'n_units_Layer_4': 145}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.97 | sMAPE for Test Set is: 52.14% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:04:43,923]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:04:51,832]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:04:56,679]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:00,023]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:04,149]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:14,095]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:19,056]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:24,389]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:26,796]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:36,435]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:41,298]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:05:53,721]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:06:04,241]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:06:27,058]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:06:33,755]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:06:38,941]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:06:46,409]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:07:03,522]\u001b[0m Trial 1375 finished with value: 1.9951512898368768 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016186458172312824, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1364423969763154, 'dropout_rate_Layer_2': 0.06723223922931851, 'dropout_rate_Layer_3': 0.08040870448212642, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09957479491222461, 'l1_Layer_2': 0.0032757015019571527, 'l1_Layer_3': 0.00018920639020674143, 'n_units_Layer_1': 270, 'n_units_Layer_2': 215, 'n_units_Layer_3': 110}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.53 | sMAPE for Test Set is: 102.58% | rMAE for Test Set is: 4.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:07:11,768]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:07:22,021]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:07:31,757]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:07:36,917]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:07:39,881]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:07:58,837]\u001b[0m Trial 1379 finished with value: 1.9724929500380932 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008235428526521461, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13701044303296667, 'dropout_rate_Layer_2': 0.06163701687813559, 'dropout_rate_Layer_3': 0.057082932039798, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09917842235832619, 'l1_Layer_2': 0.0005008728440711997, 'l1_Layer_3': 0.0003375062418461833, 'n_units_Layer_1': 255, 'n_units_Layer_2': 240, 'n_units_Layer_3': 100}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.93 | sMAPE for Test Set is: 91.95% | rMAE for Test Set is: 3.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:07:59,435]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:08:07,165]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:08:15,083]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:08:17,254]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:08:38,464]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:08:55,947]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:09:01,113]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:09:06,502]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:09:11,221]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:10:00,746]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:10:10,488]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:10:13,873]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:10:14,016]\u001b[0m Trial 1393 finished with value: 1.9995454924066642 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015541876133589052, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17653652400573355, 'dropout_rate_Layer_2': 0.04918461522808455, 'dropout_rate_Layer_3': 0.06335146766704798, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08052878292416027, 'l1_Layer_2': 0.0036803160429427326, 'l1_Layer_3': 9.183310864498008e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 215, 'n_units_Layer_3': 75}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.90 | sMAPE for Test Set is: 103.54% | rMAE for Test Set is: 4.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:10:32,180]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:10:42,428]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:10:47,166]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:10:54,665]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:11:02,595]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:11:42,346]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:11:49,491]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:11:55,292]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:12:02,288]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:12:07,519]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:12:12,691]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:12:29,889]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:12:32,793]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:12:35,638]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:12:45,218]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:12:56,502]\u001b[0m Trial 1411 finished with value: 1.8908594813160395 and parameters: {'n_hidden': 3, 'learning_rate': 0.002447584459983118, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027623455578965846, 'dropout_rate_Layer_2': 0.34401368301378976, 'dropout_rate_Layer_3': 0.08189573567711916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09817145956077881, 'l1_Layer_2': 0.09938191558437229, 'l1_Layer_3': 1.7022084871247732e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.00 | sMAPE for Test Set is: 91.59% | rMAE for Test Set is: 3.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:13:03,218]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:11,520]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:19,317]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:23,895]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:33,364]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:53,707]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:13:54,403]\u001b[0m Trial 1420 finished with value: 1.9026523234502344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017985129822730597, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02512275160322067, 'dropout_rate_Layer_2': 0.34149378267443503, 'dropout_rate_Layer_3': 0.08175290121790621, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09255968589371229, 'l1_Layer_2': 0.0766644466485279, 'l1_Layer_3': 1.0095907216844082e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.99% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.71 | sMAPE for Test Set is: 83.07% | rMAE for Test Set is: 2.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:14:01,702]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:14:01,748]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:14:08,466]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:14:13,553]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:14:53,087]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:14:55,989]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:15:12,920]\u001b[0m Trial 1426 finished with value: 1.8821130248465796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015212337518065904, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.039395997101964945, 'dropout_rate_Layer_2': 0.29651106908177893, 'dropout_rate_Layer_3': 0.13945013183390487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03777138289316628, 'l1_Layer_2': 0.07175407932270403, 'l1_Layer_3': 1.727837520256678e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 170, 'n_units_Layer_3': 265}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 13.30 | sMAPE for Test Set is: 101.64% | rMAE for Test Set is: 4.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:15:18,516]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:15:23,266]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:15:23,442]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:15:32,109]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:15:46,283]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:15:58,890]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:16:03,888]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:16:09,108]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:16:23,996]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:16:31,091]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:16:56,225]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:16:59,241]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:17:13,715]\u001b[0m Trial 1439 finished with value: 2.0036200880604755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016023431883503048, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19154629687269675, 'dropout_rate_Layer_2': 0.0581373411712537, 'dropout_rate_Layer_3': 0.07473248874858801, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07429239748166176, 'l1_Layer_2': 0.004570526005688694, 'l1_Layer_3': 0.00032592240837833384, 'n_units_Layer_1': 260, 'n_units_Layer_2': 205, 'n_units_Layer_3': 85}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.60 | sMAPE for Test Set is: 102.83% | rMAE for Test Set is: 4.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:17:23,979]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:17:28,726]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:17:35,920]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:17:40,901]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:17:48,460]\u001b[0m Trial 1441 finished with value: 1.8931160971128298 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013556870091139823, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03693002405305657, 'dropout_rate_Layer_2': 0.3129060960893603, 'dropout_rate_Layer_3': 0.14179272237533513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03643778007769019, 'l1_Layer_2': 0.070222534671185, 'l1_Layer_3': 1.8045251716884394e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 170, 'n_units_Layer_3': 265}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.23 | sMAPE for Test Set is: 88.96% | rMAE for Test Set is: 2.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:18:12,794]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:18:28,078]\u001b[0m Trial 1446 finished with value: 1.888245145559755 and parameters: {'n_hidden': 3, 'learning_rate': 0.001576359812032557, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0381242791074866, 'dropout_rate_Layer_2': 0.31029036939679466, 'dropout_rate_Layer_3': 0.1218594271661082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03391009876197669, 'l1_Layer_2': 0.07307267278395824, 'l1_Layer_3': 1.842426309430598e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.90% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.95 | sMAPE for Test Set is: 108.09% | rMAE for Test Set is: 5.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:18:30,769]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:18:35,334]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:18:45,451]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:18:47,574]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:18:52,420]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:18:55,823]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:19:03,134]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:19:10,743]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:19:27,635]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:19:32,524]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:19:35,035]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:19:42,469]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:19:50,414]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:19:54,949]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:20:00,131]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:20:27,008]\u001b[0m Trial 1461 finished with value: 1.9673329549306378 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017443858448221647, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.204480982626458, 'dropout_rate_Layer_2': 0.08556445812331899, 'dropout_rate_Layer_3': 0.05042085450289128, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03325070718948338, 'l1_Layer_2': 0.0034478417973373247, 'l1_Layer_3': 0.0001365966199929659, 'n_units_Layer_1': 195, 'n_units_Layer_2': 220, 'n_units_Layer_3': 105}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.50 | sMAPE for Test Set is: 104.93% | rMAE for Test Set is: 4.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:20:37,158]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:20:47,289]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:20:54,341]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:20:54,726]\u001b[0m Trial 1464 finished with value: 1.9698862969986333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015101328784574597, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15811381613436343, 'dropout_rate_Layer_2': 0.07330790770505202, 'dropout_rate_Layer_3': 0.05192136116011283, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06322123219953996, 'l1_Layer_2': 0.0038071139737765997, 'l1_Layer_3': 0.00014062528774123125, 'n_units_Layer_1': 275, 'n_units_Layer_2': 250, 'n_units_Layer_3': 105}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.42 | sMAPE for Test Set is: 105.05% | rMAE for Test Set is: 4.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:21:05,647]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:21:13,733]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:21:30,711]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:21:37,926]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:21:50,207]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:21:54,805]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:02,627]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:12,473]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:15,008]\u001b[0m Trial 1470 finished with value: 1.9813322274511755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018799427411500256, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1631541073975989, 'dropout_rate_Layer_2': 0.08232638899650017, 'dropout_rate_Layer_3': 0.04874541178132535, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0675359175687229, 'l1_Layer_2': 0.0042478463114611785, 'l1_Layer_3': 0.0001364920286170836, 'n_units_Layer_1': 290, 'n_units_Layer_2': 255, 'n_units_Layer_3': 105}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.72 | sMAPE for Test Set is: 105.68% | rMAE for Test Set is: 4.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:22:22,491]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:24,650]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:32,056]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:34,955]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:39,931]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:44,250]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:49,063]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:57,025]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:22:57,623]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:23:05,012]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:23:05,258]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:23:13,285]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:23:15,802]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:23:58,529]\u001b[0m Trial 1490 finished with value: 2.024691317432197 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018402680065565565, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2096839553794667, 'dropout_rate_Layer_2': 0.08792558297203122, 'dropout_rate_Layer_3': 0.05946768029291352, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.044385480434659286, 'l1_Layer_2': 0.003933179080753672, 'l1_Layer_3': 0.00013462373341103224, 'n_units_Layer_1': 270, 'n_units_Layer_2': 200, 'n_units_Layer_3': 120}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.88 | sMAPE for Test Set is: 103.43% | rMAE for Test Set is: 4.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:24:07,819]\u001b[0m Trial 1491 finished with value: 1.904455728149059 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012884887930451534, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0380511447673531, 'dropout_rate_Layer_2': 0.28877552993474476, 'dropout_rate_Layer_3': 0.110291593107143, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07450428699547144, 'l1_Layer_2': 0.04072295634601448, 'l1_Layer_3': 3.0139503178192347e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 255}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.94% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.52 | sMAPE for Test Set is: 107.23% | rMAE for Test Set is: 4.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:24:10,329]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:24:42,557]\u001b[0m Trial 1493 finished with value: 1.992992494332724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012740830746210776, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1647836875475344, 'dropout_rate_Layer_2': 0.07903457114066571, 'dropout_rate_Layer_3': 0.06175991230992204, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05918245703999731, 'l1_Layer_2': 0.0009874697334733686, 'l1_Layer_3': 0.0001767184855629586, 'n_units_Layer_1': 265, 'n_units_Layer_2': 250, 'n_units_Layer_3': 95}. Best is trial 1249 with value: 1.869752717626384.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 97.18% | rMAE for Test Set is: 3.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:24:55,398]\u001b[0m Trial 1494 finished with value: 1.8535564346153646 and parameters: {'n_hidden': 3, 'learning_rate': 0.001992326434671911, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012591592317848368, 'dropout_rate_Layer_2': 0.33496413407620773, 'dropout_rate_Layer_3': 0.12348261646782276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.027407605609214764, 'l1_Layer_2': 0.08590124805245362, 'l1_Layer_3': 1.8669031201940842e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295}. Best is trial 1494 with value: 1.8535564346153646.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 4.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 10.77 | sMAPE for Test Set is: 94.08% | rMAE for Test Set is: 3.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 10:25:05,114]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:25:16,597]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:25:21,691]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:25:31,527]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 10:25:39,730]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-01-01, MAE is:2.32 & sMAPE is:7.16% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 7.16% & 0.45\n",
      "for 2020-01-02, MAE is:1.81 & sMAPE is:5.66% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 6.41% & 0.38\n",
      "for 2020-01-03, MAE is:1.66 & sMAPE is:5.50% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :1.93 & 6.11% & 0.31\n",
      "for 2020-01-04, MAE is:0.92 & sMAPE is:3.13% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :1.68 & 5.36% & 0.27\n",
      "for 2020-01-05, MAE is:1.22 & sMAPE is:3.95% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :1.59 & 5.08% & 0.31\n",
      "for 2020-01-06, MAE is:1.50 & sMAPE is:4.78% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :1.57 & 5.03% & 0.33\n",
      "for 2020-01-07, MAE is:1.32 & sMAPE is:4.39% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :1.53 & 4.94% & 0.34\n",
      "for 2020-01-08, MAE is:2.15 & sMAPE is:8.18% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :1.61 & 5.34% & 0.36\n",
      "for 2020-01-09, MAE is:1.93 & sMAPE is:6.80% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :1.65 & 5.51% & 0.39\n",
      "for 2020-01-10, MAE is:0.92 & sMAPE is:3.31% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :1.57 & 5.29% & 0.42\n",
      "for 2020-01-11, MAE is:1.95 & sMAPE is:7.45% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :1.61 & 5.48% & 0.43\n",
      "for 2020-01-12, MAE is:0.97 & sMAPE is:3.87% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :1.56 & 5.35% & 0.41\n",
      "for 2020-01-13, MAE is:1.05 & sMAPE is:3.95% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :1.52 & 5.24% & 0.40\n",
      "for 2020-01-14, MAE is:2.84 & sMAPE is:11.18% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :1.61 & 5.67% & 0.41\n",
      "for 2020-01-15, MAE is:1.26 & sMAPE is:5.07% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :1.59 & 5.63% & 0.42\n",
      "for 2020-01-16, MAE is:1.20 & sMAPE is:4.79% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :1.56 & 5.57% & 0.42\n",
      "for 2020-01-17, MAE is:1.25 & sMAPE is:5.01% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :1.54 & 5.54% & 0.41\n",
      "for 2020-01-18, MAE is:1.38 & sMAPE is:5.72% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :1.54 & 5.55% & 0.43\n",
      "for 2020-01-19, MAE is:1.46 & sMAPE is:6.17% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :1.53 & 5.58% & 0.45\n",
      "for 2020-01-20, MAE is:2.26 & sMAPE is:9.42% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :1.57 & 5.77% & 0.45\n",
      "for 2020-01-21, MAE is:2.44 & sMAPE is:11.06% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :1.61 & 6.03% & 0.47\n",
      "for 2020-01-22, MAE is:0.86 & sMAPE is:3.90% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :1.58 & 5.93% & 0.46\n",
      "for 2020-01-23, MAE is:3.14 & sMAPE is:14.19% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :1.64 & 6.29% & 0.48\n",
      "for 2020-01-24, MAE is:1.98 & sMAPE is:9.66% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :1.66 & 6.43% & 0.47\n",
      "for 2020-01-25, MAE is:0.83 & sMAPE is:3.95% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :1.62 & 6.33% & 0.47\n",
      "for 2020-01-26, MAE is:2.02 & sMAPE is:9.65% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :1.64 & 6.46% & 0.48\n",
      "for 2020-01-27, MAE is:2.66 & sMAPE is:12.01% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :1.68 & 6.66% & 0.50\n",
      "for 2020-01-28, MAE is:1.39 & sMAPE is:6.35% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :1.67 & 6.65% & 0.56\n",
      "for 2020-01-29, MAE is:0.70 & sMAPE is:3.32% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :1.63 & 6.54% & 0.57\n",
      "for 2020-01-30, MAE is:0.80 & sMAPE is:3.89% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :1.61 & 6.45% & 0.58\n",
      "for 2020-01-31, MAE is:3.13 & sMAPE is:15.51% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :1.66 & 6.74% & 0.65\n",
      "for 2020-02-01, MAE is:3.90 & sMAPE is:21.47% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :1.73 & 7.20% & 0.65\n",
      "for 2020-02-02, MAE is:2.78 & sMAPE is:15.23% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :1.76 & 7.44% & 0.66\n",
      "for 2020-02-03, MAE is:2.43 & sMAPE is:12.49% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :1.78 & 7.59% & 0.68\n",
      "for 2020-02-04, MAE is:1.90 & sMAPE is:9.75% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :1.78 & 7.65% & 0.68\n",
      "for 2020-02-05, MAE is:4.54 & sMAPE is:23.49% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :1.86 & 8.09% & 0.70\n",
      "for 2020-02-06, MAE is:2.77 & sMAPE is:15.68% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :1.88 & 8.30% & 0.69\n",
      "for 2020-02-07, MAE is:3.94 & sMAPE is:21.69% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :1.94 & 8.65% & 0.71\n",
      "for 2020-02-08, MAE is:4.66 & sMAPE is:29.11% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :2.01 & 9.18% & 0.74\n",
      "for 2020-02-09, MAE is:5.92 & sMAPE is:41.58% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 9.99% & 0.75\n",
      "for 2020-02-10, MAE is:5.58 & sMAPE is:38.21% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 10.67% & 0.75\n",
      "for 2020-02-11, MAE is:3.93 & sMAPE is:27.02% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 11.06% & 0.75\n",
      "for 2020-02-12, MAE is:4.43 & sMAPE is:29.08% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 11.48% & 0.76\n",
      "for 2020-02-13, MAE is:4.07 & sMAPE is:26.17% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 11.82% & 0.77\n",
      "for 2020-02-14, MAE is:3.04 & sMAPE is:20.58% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 12.01% & 0.78\n",
      "for 2020-02-15, MAE is:3.59 & sMAPE is:27.00% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 12.34% & 0.80\n",
      "for 2020-02-16, MAE is:6.72 & sMAPE is:54.54% & rMAE is:2.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 13.24% & 0.85\n",
      "for 2020-02-17, MAE is:5.64 & sMAPE is:42.25% & rMAE is:4.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 13.84% & 0.92\n",
      "for 2020-02-18, MAE is:4.76 & sMAPE is:36.47% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.57 & 14.30% & 0.95\n",
      "for 2020-02-19, MAE is:4.18 & sMAPE is:31.86% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.60 & 14.65% & 0.97\n",
      "for 2020-02-20, MAE is:5.71 & sMAPE is:43.94% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :2.66 & 15.23% & 0.99\n",
      "for 2020-02-21, MAE is:7.82 & sMAPE is:60.50% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :2.76 & 16.10% & 1.01\n",
      "for 2020-02-22, MAE is:6.78 & sMAPE is:59.64% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :2.84 & 16.92% & 1.02\n",
      "for 2020-02-23, MAE is:5.60 & sMAPE is:51.55% & rMAE is:6.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.89 & 17.56% & 1.13\n",
      "for 2020-02-24, MAE is:5.13 & sMAPE is:41.08% & rMAE is:4.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 17.99% & 1.20\n",
      "for 2020-02-25, MAE is:5.69 & sMAPE is:43.84% & rMAE is:7.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 18.45% & 1.31\n",
      "for 2020-02-26, MAE is:4.31 & sMAPE is:34.55% & rMAE is:5.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 18.73% & 1.40\n",
      "for 2020-02-27, MAE is:3.79 & sMAPE is:29.14% & rMAE is:3.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 18.91% & 1.44\n",
      "for 2020-02-28, MAE is:4.84 & sMAPE is:36.46% & rMAE is:2.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 19.21% & 1.46\n",
      "for 2020-02-29, MAE is:4.63 & sMAPE is:37.20% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 19.51% & 1.47\n",
      "for 2020-03-01, MAE is:4.66 & sMAPE is:38.67% & rMAE is:3.05 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 19.82% & 1.50\n",
      "for 2020-03-02, MAE is:5.53 & sMAPE is:42.21% & rMAE is:13.09 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 20.18% & 1.69\n",
      "for 2020-03-03, MAE is:3.97 & sMAPE is:33.44% & rMAE is:10.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.15 & 20.39% & 1.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-04, MAE is:4.73 & sMAPE is:38.42% & rMAE is:12.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.18 & 20.68% & 2.00\n",
      "for 2020-03-05, MAE is:5.13 & sMAPE is:40.15% & rMAE is:5.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 20.98% & 2.05\n",
      "for 2020-03-06, MAE is:3.39 & sMAPE is:26.16% & rMAE is:3.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 21.05% & 2.07\n",
      "for 2020-03-07, MAE is:5.09 & sMAPE is:39.29% & rMAE is:14.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.24 & 21.33% & 2.25\n",
      "for 2020-03-08, MAE is:5.93 & sMAPE is:47.90% & rMAE is:12.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 21.72% & 2.40\n",
      "for 2020-03-09, MAE is:5.31 & sMAPE is:42.07% & rMAE is:15.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 22.01% & 2.59\n",
      "for 2020-03-10, MAE is:4.66 & sMAPE is:39.08% & rMAE is:10.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 22.26% & 2.70\n",
      "for 2020-03-11, MAE is:4.91 & sMAPE is:42.90% & rMAE is:5.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 22.55% & 2.74\n",
      "for 2020-03-12, MAE is:5.19 & sMAPE is:46.81% & rMAE is:3.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 22.88% & 2.74\n",
      "for 2020-03-13, MAE is:5.37 & sMAPE is:49.13% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 23.24% & 2.73\n",
      "for 2020-03-14, MAE is:6.39 & sMAPE is:55.25% & rMAE is:3.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 23.68% & 2.74\n",
      "for 2020-03-15, MAE is:7.93 & sMAPE is:73.03% & rMAE is:3.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 24.33% & 2.74\n",
      "for 2020-03-16, MAE is:5.62 & sMAPE is:51.14% & rMAE is:3.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 24.69% & 2.75\n",
      "for 2020-03-17, MAE is:6.41 & sMAPE is:59.86% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :3.57 & 25.14% & 2.75\n",
      "for 2020-03-18, MAE is:7.24 & sMAPE is:69.24% & rMAE is:3.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.61 & 25.71% & 2.76\n",
      "for 2020-03-19, MAE is:6.39 & sMAPE is:62.63% & rMAE is:4.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 26.18% & 2.78\n",
      "for 2020-03-20, MAE is:5.79 & sMAPE is:55.42% & rMAE is:7.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 26.54% & 2.83\n",
      "for 2020-03-21, MAE is:6.19 & sMAPE is:58.07% & rMAE is:7.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 26.93% & 2.89\n",
      "for 2020-03-22, MAE is:7.19 & sMAPE is:70.63% & rMAE is:12.96 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 27.46% & 3.02\n",
      "for 2020-03-23, MAE is:6.17 & sMAPE is:57.81% & rMAE is:8.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 27.83% & 3.09\n",
      "for 2020-03-24, MAE is:7.05 & sMAPE is:67.86% & rMAE is:11.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 28.31% & 3.19\n",
      "for 2020-03-25, MAE is:6.84 & sMAPE is:68.18% & rMAE is:25.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 28.78% & 3.45\n",
      "for 2020-03-26, MAE is:6.03 & sMAPE is:62.20% & rMAE is:18.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 29.16% & 3.62\n",
      "for 2020-03-27, MAE is:6.96 & sMAPE is:72.09% & rMAE is:5.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 29.66% & 3.64\n",
      "for 2020-03-28, MAE is:7.27 & sMAPE is:81.87% & rMAE is:3.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 30.25% & 3.63\n",
      "for 2020-03-29, MAE is:7.02 & sMAPE is:84.20% & rMAE is:4.07 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 30.86% & 3.64\n",
      "for 2020-03-30, MAE is:6.37 & sMAPE is:66.79% & rMAE is:5.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 31.26% & 3.65\n",
      "for 2020-03-31, MAE is:7.00 & sMAPE is:80.11% & rMAE is:4.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 31.79% & 3.66\n",
      "for 2020-04-01, MAE is:8.07 & sMAPE is:89.88% & rMAE is:4.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 32.42% & 3.67\n",
      "for 2020-04-02, MAE is:8.24 & sMAPE is:94.86% & rMAE is:3.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 33.10% & 3.67\n",
      "for 2020-04-03, MAE is:6.83 & sMAPE is:91.76% & rMAE is:3.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 33.72% & 3.67\n",
      "for 2020-04-04, MAE is:7.90 & sMAPE is:93.18% & rMAE is:9.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 34.35% & 3.73\n",
      "for 2020-04-05, MAE is:9.02 & sMAPE is:102.01% & rMAE is:9.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 35.05% & 3.79\n",
      "for 2020-04-06, MAE is:8.47 & sMAPE is:98.46% & rMAE is:4.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 35.70% & 3.80\n",
      "for 2020-04-07, MAE is:6.66 & sMAPE is:85.97% & rMAE is:8.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 36.22% & 3.84\n",
      "for 2020-04-08, MAE is:7.64 & sMAPE is:91.24% & rMAE is:18.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 36.77% & 3.99\n",
      "for 2020-04-09, MAE is:7.53 & sMAPE is:89.81% & rMAE is:58.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 37.30% & 4.53\n",
      "for 2020-04-10, MAE is:7.90 & sMAPE is:88.74% & rMAE is:8.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 37.81% & 4.58\n",
      "for 2020-04-11, MAE is:7.61 & sMAPE is:86.84% & rMAE is:17.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 38.29% & 4.70\n",
      "for 2020-04-12, MAE is:8.67 & sMAPE is:105.89% & rMAE is:16.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 38.95% & 4.82\n",
      "for 2020-04-13, MAE is:9.19 & sMAPE is:132.61% & rMAE is:4.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 39.85% & 4.82\n",
      "for 2020-04-14, MAE is:7.37 & sMAPE is:88.26% & rMAE is:29.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 40.31% & 5.05\n",
      "for 2020-04-15, MAE is:7.52 & sMAPE is:91.03% & rMAE is:33.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 40.79% & 5.31\n",
      "for 2020-04-16, MAE is:9.04 & sMAPE is:100.57% & rMAE is:22.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 41.35% & 5.47\n",
      "for 2020-04-17, MAE is:7.49 & sMAPE is:86.41% & rMAE is:81.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 41.77% & 6.17\n",
      "for 2020-04-18, MAE is:7.14 & sMAPE is:82.72% & rMAE is:53.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 42.14% & 6.60\n",
      "for 2020-04-19, MAE is:7.94 & sMAPE is:90.25% & rMAE is:8.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 42.58% & 6.62\n",
      "for 2020-04-20, MAE is:7.97 & sMAPE is:89.28% & rMAE is:3.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 43.00% & 6.59\n",
      "for 2020-04-21, MAE is:6.89 & sMAPE is:85.40% & rMAE is:18.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 43.38% & 6.69\n",
      "for 2020-04-22, MAE is:7.57 & sMAPE is:84.80% & rMAE is:10.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 43.74% & 6.73\n",
      "for 2020-04-23, MAE is:8.40 & sMAPE is:91.81% & rMAE is:17.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 44.17% & 6.83\n",
      "for 2020-04-24, MAE is:7.27 & sMAPE is:85.64% & rMAE is:82.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 44.53% & 7.49\n",
      "for 2020-04-25, MAE is:7.69 & sMAPE is:88.38% & rMAE is:36.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 44.90% & 7.74\n",
      "for 2020-04-26, MAE is:6.63 & sMAPE is:81.16% & rMAE is:44.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 45.21% & 8.06\n",
      "for 2020-04-27, MAE is:7.71 & sMAPE is:84.22% & rMAE is:13.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 45.55% & 8.11\n",
      "for 2020-04-28, MAE is:7.91 & sMAPE is:84.24% & rMAE is:9.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 45.87% & 8.12\n",
      "for 2020-04-29, MAE is:4.36 & sMAPE is:57.90% & rMAE is:7.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 45.97% & 8.11\n",
      "for 2020-04-30, MAE is:4.49 & sMAPE is:60.50% & rMAE is:17.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 46.09% & 8.19\n",
      "for 2020-05-01, MAE is:7.18 & sMAPE is:82.54% & rMAE is:21.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 46.39% & 8.30\n",
      "for 2020-05-02, MAE is:3.84 & sMAPE is:50.22% & rMAE is:4.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 46.42% & 8.27\n",
      "for 2020-05-03, MAE is:5.94 & sMAPE is:67.31% & rMAE is:5.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 46.59% & 8.25\n",
      "for 2020-05-04, MAE is:3.67 & sMAPE is:43.39% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 46.56% & 8.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-05, MAE is:5.31 & sMAPE is:55.10% & rMAE is:3.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 46.63% & 8.17\n",
      "for 2020-05-06, MAE is:2.96 & sMAPE is:35.39% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 46.54% & 8.12\n",
      "for 2020-05-07, MAE is:1.67 & sMAPE is:19.79% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 46.33% & 8.06\n",
      "for 2020-05-08, MAE is:5.40 & sMAPE is:51.07% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 46.37% & 8.01\n",
      "for 2020-05-09, MAE is:2.73 & sMAPE is:28.82% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 46.24% & 7.96\n",
      "for 2020-05-10, MAE is:3.31 & sMAPE is:36.39% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 46.16% & 7.91\n",
      "for 2020-05-11, MAE is:5.44 & sMAPE is:51.20% & rMAE is:3.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 46.20% & 7.88\n",
      "for 2020-05-12, MAE is:3.41 & sMAPE is:29.08% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 46.07% & 7.83\n",
      "for 2020-05-13, MAE is:1.27 & sMAPE is:8.58% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 45.79% & 7.77\n",
      "for 2020-05-14, MAE is:1.33 & sMAPE is:9.34% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 45.52% & 7.72\n",
      "for 2020-05-15, MAE is:3.23 & sMAPE is:22.84% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 45.35% & 7.66\n",
      "for 2020-05-16, MAE is:5.29 & sMAPE is:44.07% & rMAE is:4.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 45.34% & 7.64\n",
      "for 2020-05-17, MAE is:1.16 & sMAPE is:11.23% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 45.10% & 7.59\n",
      "for 2020-05-18, MAE is:1.66 & sMAPE is:13.25% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 44.87% & 7.53\n",
      "for 2020-05-19, MAE is:0.58 & sMAPE is:4.82% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 44.58% & 7.48\n",
      "for 2020-05-20, MAE is:2.73 & sMAPE is:23.60% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 44.43% & 7.43\n",
      "for 2020-05-21, MAE is:6.14 & sMAPE is:52.53% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 44.49% & 7.39\n",
      "for 2020-05-22, MAE is:5.45 & sMAPE is:54.37% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 44.56% & 7.34\n",
      "for 2020-05-23, MAE is:4.57 & sMAPE is:74.64% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 44.77% & 7.30\n",
      "for 2020-05-24, MAE is:5.48 & sMAPE is:116.25% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 45.26% & 7.25\n",
      "for 2020-05-25, MAE is:4.42 & sMAPE is:62.38% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 45.38% & 7.21\n",
      "for 2020-05-26, MAE is:9.11 & sMAPE is:149.29% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 46.08% & 7.16\n",
      "for 2020-05-27, MAE is:7.34 & sMAPE is:134.70% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 46.68% & 7.12\n",
      "for 2020-05-28, MAE is:6.88 & sMAPE is:124.97% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 47.21% & 7.08\n",
      "for 2020-05-29, MAE is:5.83 & sMAPE is:109.41% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 47.62% & 7.04\n",
      "for 2020-05-30, MAE is:6.65 & sMAPE is:119.28% & rMAE is:3.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 48.10% & 7.02\n",
      "for 2020-05-31, MAE is:7.12 & sMAPE is:136.23% & rMAE is:6.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 48.68% & 7.01\n",
      "for 2020-06-01, MAE is:6.81 & sMAPE is:128.47% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 49.20% & 6.98\n",
      "for 2020-06-02, MAE is:7.06 & sMAPE is:139.44% & rMAE is:201.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 49.79% & 8.25\n",
      "for 2020-06-03, MAE is:5.71 & sMAPE is:133.33% & rMAE is:15.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 50.32% & 8.30\n",
      "for 2020-06-04, MAE is:6.44 & sMAPE is:133.39% & rMAE is:13.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 50.86% & 8.33\n",
      "for 2020-06-05, MAE is:5.72 & sMAPE is:129.95% & rMAE is:6.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 51.36% & 8.32\n",
      "for 2020-06-06, MAE is:5.08 & sMAPE is:129.97% & rMAE is:5.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 51.86% & 8.30\n",
      "for 2020-06-07, MAE is:5.01 & sMAPE is:119.21% & rMAE is:8.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 52.28% & 8.31\n",
      "for 2020-06-08, MAE is:5.82 & sMAPE is:124.29% & rMAE is:18.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 52.73% & 8.37\n",
      "for 2020-06-09, MAE is:5.00 & sMAPE is:118.78% & rMAE is:22.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 53.14% & 8.45\n",
      "for 2020-06-10, MAE is:4.50 & sMAPE is:110.32% & rMAE is:11.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 53.49% & 8.47\n",
      "for 2020-06-11, MAE is:4.63 & sMAPE is:113.23% & rMAE is:26.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 53.86% & 8.58\n",
      "for 2020-06-12, MAE is:5.10 & sMAPE is:130.91% & rMAE is:26.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 54.33% & 8.69\n",
      "for 2020-06-13, MAE is:4.21 & sMAPE is:123.61% & rMAE is:14.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 54.75% & 8.72\n",
      "for 2020-06-14, MAE is:6.49 & sMAPE is:145.71% & rMAE is:13.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 55.30% & 8.75\n",
      "for 2020-06-15, MAE is:6.95 & sMAPE is:140.43% & rMAE is:22.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 55.81% & 8.84\n",
      "for 2020-06-16, MAE is:6.19 & sMAPE is:135.49% & rMAE is:25.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 56.28% & 8.94\n",
      "for 2020-06-17, MAE is:5.51 & sMAPE is:124.69% & rMAE is:30.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 56.69% & 9.07\n",
      "for 2020-06-18, MAE is:7.57 & sMAPE is:142.85% & rMAE is:27.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 57.19% & 9.18\n",
      "for 2020-06-19, MAE is:6.13 & sMAPE is:135.70% & rMAE is:37.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 57.65% & 9.34\n",
      "for 2020-06-20, MAE is:8.06 & sMAPE is:148.62% & rMAE is:81.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 58.18% & 9.76\n",
      "for 2020-06-21, MAE is:5.19 & sMAPE is:132.69% & rMAE is:37.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 58.61% & 9.92\n",
      "for 2020-06-22, MAE is:6.62 & sMAPE is:140.34% & rMAE is:95.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 59.08% & 10.41\n",
      "for 2020-06-23, MAE is:5.28 & sMAPE is:129.51% & rMAE is:129.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 59.49% & 11.09\n",
      "for 2020-06-24, MAE is:6.37 & sMAPE is:136.52% & rMAE is:32.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 59.92% & 11.21\n",
      "for 2020-06-25, MAE is:6.79 & sMAPE is:140.60% & rMAE is:84.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 60.38% & 11.63\n",
      "for 2020-06-26, MAE is:4.54 & sMAPE is:121.98% & rMAE is:121.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 60.72% & 12.25\n",
      "for 2020-06-27, MAE is:6.22 & sMAPE is:153.89% & rMAE is:13.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 61.25% & 12.25\n",
      "for 2020-06-28, MAE is:7.45 & sMAPE is:161.62% & rMAE is:17.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 61.80% & 12.28\n",
      "for 2020-06-29, MAE is:5.75 & sMAPE is:145.46% & rMAE is:17.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 62.27% & 12.31\n",
      "for 2020-06-30, MAE is:7.25 & sMAPE is:152.72% & rMAE is:23.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 62.76% & 12.38\n",
      "for 2020-07-01, MAE is:7.24 & sMAPE is:152.83% & rMAE is:20.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 63.25% & 12.42\n",
      "for 2020-07-02, MAE is:5.76 & sMAPE is:135.32% & rMAE is:63.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 63.65% & 12.70\n",
      "for 2020-07-03, MAE is:5.74 & sMAPE is:139.58% & rMAE is:27.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 64.06% & 12.78\n",
      "for 2020-07-04, MAE is:5.37 & sMAPE is:134.92% & rMAE is:15.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 64.44% & 12.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-05, MAE is:7.46 & sMAPE is:158.47% & rMAE is:35.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 64.94% & 12.91\n",
      "for 2020-07-06, MAE is:5.65 & sMAPE is:153.75% & rMAE is:17.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 65.41% & 12.94\n",
      "for 2020-07-07, MAE is:7.09 & sMAPE is:155.72% & rMAE is:25.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 65.89% & 13.00\n",
      "for 2020-07-08, MAE is:4.66 & sMAPE is:127.02% & rMAE is:20.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 66.21% & 13.04\n",
      "for 2020-07-09, MAE is:4.92 & sMAPE is:121.91% & rMAE is:24.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 66.50% & 13.10\n",
      "for 2020-07-10, MAE is:4.87 & sMAPE is:121.48% & rMAE is:14.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 66.79% & 13.11\n",
      "for 2020-07-11, MAE is:6.08 & sMAPE is:132.23% & rMAE is:23.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 67.13% & 13.17\n",
      "for 2020-07-12, MAE is:6.39 & sMAPE is:134.06% & rMAE is:11.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 67.47% & 13.16\n",
      "for 2020-07-13, MAE is:7.00 & sMAPE is:137.74% & rMAE is:10.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 67.83% & 13.14\n",
      "for 2020-07-14, MAE is:5.98 & sMAPE is:131.32% & rMAE is:11.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 68.16% & 13.14\n",
      "for 2020-07-15, MAE is:6.36 & sMAPE is:133.96% & rMAE is:28.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 68.49% & 13.21\n",
      "for 2020-07-16, MAE is:6.07 & sMAPE is:132.16% & rMAE is:227.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 68.81% & 14.30\n",
      "for 2020-07-17, MAE is:7.00 & sMAPE is:139.03% & rMAE is:182.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 69.17% & 15.14\n",
      "for 2020-07-18, MAE is:6.34 & sMAPE is:136.67% & rMAE is:71.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 69.50% & 15.42\n",
      "for 2020-07-19, MAE is:6.22 & sMAPE is:134.25% & rMAE is:129.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 69.83% & 15.99\n",
      "for 2020-07-20, MAE is:6.83 & sMAPE is:138.69% & rMAE is:95.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 70.17% & 16.39\n",
      "for 2020-07-21, MAE is:6.26 & sMAPE is:134.72% & rMAE is:134.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 70.49% & 16.97\n",
      "for 2020-07-22, MAE is:5.80 & sMAPE is:130.98% & rMAE is:154.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 70.78% & 17.64\n",
      "for 2020-07-23, MAE is:6.51 & sMAPE is:134.64% & rMAE is:211.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 71.09% & 18.59\n",
      "for 2020-07-24, MAE is:6.06 & sMAPE is:132.62% & rMAE is:372.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 71.39% & 20.31\n",
      "for 2020-07-25, MAE is:5.77 & sMAPE is:130.53% & rMAE is:86.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 71.68% & 20.62\n",
      "for 2020-07-26, MAE is:5.96 & sMAPE is:134.25% & rMAE is:91.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 71.98% & 20.96\n",
      "for 2020-07-27, MAE is:6.57 & sMAPE is:136.84% & rMAE is:750.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 72.29% & 24.45\n",
      "for 2020-07-28, MAE is:6.33 & sMAPE is:138.03% & rMAE is:68.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 72.60% & 24.66\n",
      "for 2020-07-29, MAE is:6.86 & sMAPE is:148.77% & rMAE is:20.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 72.96% & 24.64\n",
      "for 2020-07-30, MAE is:6.30 & sMAPE is:143.51% & rMAE is:19.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 73.30% & 24.62\n",
      "for 2020-07-31, MAE is:5.85 & sMAPE is:137.81% & rMAE is:27.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 73.60% & 24.63\n",
      "for 2020-08-01, MAE is:6.08 & sMAPE is:149.61% & rMAE is:11.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 73.95% & 24.57\n",
      "for 2020-08-02, MAE is:6.70 & sMAPE is:152.64% & rMAE is:16.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 74.32% & 24.53\n",
      "for 2020-08-03, MAE is:6.49 & sMAPE is:142.52% & rMAE is:32.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 74.64% & 24.57\n",
      "for 2020-08-04, MAE is:6.04 & sMAPE is:140.59% & rMAE is:42.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 74.94% & 24.65\n",
      "for 2020-08-05, MAE is:6.33 & sMAPE is:147.88% & rMAE is:32.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 75.27% & 24.68\n",
      "for 2020-08-06, MAE is:6.50 & sMAPE is:144.52% & rMAE is:53.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 75.59% & 24.82\n",
      "for 2020-08-07, MAE is:5.26 & sMAPE is:134.63% & rMAE is:71.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 75.86% & 25.03\n",
      "for 2020-08-08, MAE is:5.49 & sMAPE is:137.79% & rMAE is:21.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 76.14% & 25.02\n",
      "for 2020-08-09, MAE is:5.91 & sMAPE is:150.99% & rMAE is:27.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 76.48% & 25.03\n",
      "for 2020-08-10, MAE is:6.76 & sMAPE is:152.50% & rMAE is:26.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 76.82% & 25.03\n",
      "for 2020-08-11, MAE is:6.58 & sMAPE is:135.67% & rMAE is:22.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 77.08% & 25.02\n",
      "for 2020-08-12, MAE is:6.27 & sMAPE is:125.64% & rMAE is:8.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 77.30% & 24.95\n",
      "for 2020-08-13, MAE is:6.45 & sMAPE is:120.07% & rMAE is:6.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 77.48% & 24.87\n",
      "for 2020-08-14, MAE is:4.93 & sMAPE is:100.71% & rMAE is:3.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 77.59% & 24.78\n",
      "for 2020-08-15, MAE is:7.10 & sMAPE is:137.07% & rMAE is:17.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 77.85% & 24.75\n",
      "for 2020-08-16, MAE is:5.07 & sMAPE is:113.19% & rMAE is:4.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 78.00% & 24.66\n",
      "for 2020-08-17, MAE is:4.12 & sMAPE is:81.04% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 78.02% & 24.56\n",
      "for 2020-08-18, MAE is:4.40 & sMAPE is:72.08% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 77.99% & 24.46\n",
      "for 2020-08-19, MAE is:4.76 & sMAPE is:75.91% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 77.98% & 24.36\n",
      "for 2020-08-20, MAE is:5.94 & sMAPE is:90.28% & rMAE is:4.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 78.03% & 24.28\n",
      "for 2020-08-21, MAE is:3.44 & sMAPE is:62.39% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 77.97% & 24.18\n",
      "for 2020-08-22, MAE is:4.41 & sMAPE is:79.79% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 77.97% & 24.09\n",
      "for 2020-08-23, MAE is:4.47 & sMAPE is:82.45% & rMAE is:3.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 77.99% & 24.01\n",
      "for 2020-08-24, MAE is:6.94 & sMAPE is:97.99% & rMAE is:6.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 78.08% & 23.93\n",
      "for 2020-08-25, MAE is:4.09 & sMAPE is:63.77% & rMAE is:3.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 78.02% & 23.85\n",
      "for 2020-08-26, MAE is:3.49 & sMAPE is:52.78% & rMAE is:2.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 77.91% & 23.76\n",
      "for 2020-08-27, MAE is:2.72 & sMAPE is:36.00% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 77.74% & 23.67\n",
      "for 2020-08-28, MAE is:0.83 & sMAPE is:9.73% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 77.46% & 23.57\n",
      "for 2020-08-29, MAE is:0.39 & sMAPE is:4.17% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 77.15% & 23.47\n",
      "for 2020-08-30, MAE is:0.25 & sMAPE is:2.04% & rMAE is:0.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 76.84% & 23.38\n",
      "for 2020-08-31, MAE is:0.52 & sMAPE is:3.54% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 76.54% & 23.28\n",
      "for 2020-09-01, MAE is:3.39 & sMAPE is:21.10% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 76.32% & 23.19\n",
      "for 2020-09-02, MAE is:1.67 & sMAPE is:9.67% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 76.05% & 23.09\n",
      "for 2020-09-03, MAE is:1.34 & sMAPE is:7.60% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 75.77% & 23.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-04, MAE is:0.64 & sMAPE is:4.02% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 75.48% & 22.91\n",
      "for 2020-09-05, MAE is:0.57 & sMAPE is:3.98% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 75.19% & 22.81\n",
      "for 2020-09-06, MAE is:2.56 & sMAPE is:18.28% & rMAE is:5.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 74.96% & 22.74\n",
      "for 2020-09-07, MAE is:1.43 & sMAPE is:10.80% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 74.71% & 22.66\n",
      "for 2020-09-08, MAE is:2.89 & sMAPE is:22.34% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 74.50% & 22.57\n",
      "for 2020-09-09, MAE is:2.60 & sMAPE is:19.81% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 74.28% & 22.48\n",
      "for 2020-09-10, MAE is:2.61 & sMAPE is:20.36% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 74.07% & 22.39\n",
      "for 2020-09-11, MAE is:0.95 & sMAPE is:7.56% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 73.81% & 22.31\n",
      "for 2020-09-12, MAE is:0.41 & sMAPE is:3.63% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 73.54% & 22.22\n",
      "for 2020-09-13, MAE is:2.80 & sMAPE is:25.92% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 73.35% & 22.14\n",
      "for 2020-09-14, MAE is:1.28 & sMAPE is:9.72% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 73.11% & 22.06\n",
      "for 2020-09-15, MAE is:0.79 & sMAPE is:6.22% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 72.85% & 21.98\n",
      "for 2020-09-16, MAE is:2.79 & sMAPE is:21.79% & rMAE is:6.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 72.65% & 21.92\n",
      "for 2020-09-17, MAE is:1.67 & sMAPE is:14.81% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 72.43% & 21.84\n",
      "for 2020-09-18, MAE is:3.46 & sMAPE is:33.71% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 72.28% & 21.76\n",
      "for 2020-09-19, MAE is:4.36 & sMAPE is:48.66% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 72.19% & 21.69\n",
      "for 2020-09-20, MAE is:3.55 & sMAPE is:44.78% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 72.09% & 21.61\n",
      "for 2020-09-21, MAE is:2.46 & sMAPE is:30.25% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 71.93% & 21.53\n",
      "for 2020-09-22, MAE is:3.18 & sMAPE is:39.63% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 71.81% & 21.45\n",
      "for 2020-09-23, MAE is:2.71 & sMAPE is:34.13% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 71.67% & 21.37\n",
      "for 2020-09-24, MAE is:3.26 & sMAPE is:43.45% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 71.56% & 21.29\n",
      "for 2020-09-25, MAE is:3.56 & sMAPE is:53.61% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 71.50% & 21.22\n",
      "for 2020-09-26, MAE is:4.78 & sMAPE is:89.52% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 71.56% & 21.14\n",
      "for 2020-09-27, MAE is:5.42 & sMAPE is:114.04% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 71.72% & 21.07\n",
      "for 2020-09-28, MAE is:5.35 & sMAPE is:116.04% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 71.88% & 21.00\n",
      "for 2020-09-29, MAE is:5.18 & sMAPE is:114.01% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 72.04% & 20.92\n",
      "for 2020-09-30, MAE is:5.07 & sMAPE is:114.08% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 72.19% & 20.85\n",
      "for 2020-10-01, MAE is:4.52 & sMAPE is:97.26% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 72.28% & 20.78\n",
      "for 2020-10-02, MAE is:3.56 & sMAPE is:69.59% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 72.27% & 20.71\n",
      "for 2020-10-03, MAE is:3.33 & sMAPE is:72.02% & rMAE is:5.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 72.27% & 20.66\n",
      "for 2020-10-04, MAE is:2.75 & sMAPE is:55.97% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 72.21% & 20.59\n",
      "for 2020-10-05, MAE is:1.84 & sMAPE is:27.90% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 72.05% & 20.52\n",
      "for 2020-10-06, MAE is:1.44 & sMAPE is:21.04% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 71.87% & 20.45\n",
      "for 2020-10-07, MAE is:0.70 & sMAPE is:10.12% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 71.65% & 20.37\n",
      "for 2020-10-08, MAE is:0.55 & sMAPE is:6.99% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 71.42% & 20.30\n",
      "for 2020-10-09, MAE is:3.65 & sMAPE is:36.37% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 71.30% & 20.23\n",
      "for 2020-10-10, MAE is:3.48 & sMAPE is:32.74% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 71.16% & 20.16\n",
      "for 2020-10-11, MAE is:6.67 & sMAPE is:50.55% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 71.09% & 20.09\n",
      "for 2020-10-12, MAE is:1.77 & sMAPE is:10.52% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 70.88% & 20.02\n",
      "for 2020-10-13, MAE is:1.88 & sMAPE is:10.66% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 70.67% & 19.95\n",
      "for 2020-10-14, MAE is:3.11 & sMAPE is:17.24% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 70.48% & 19.89\n",
      "for 2020-10-15, MAE is:2.62 & sMAPE is:14.10% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 70.29% & 19.82\n",
      "for 2020-10-16, MAE is:7.50 & sMAPE is:28.67% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 70.14% & 19.75\n",
      "for 2020-10-17, MAE is:1.38 & sMAPE is:7.41% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 69.93% & 19.68\n",
      "for 2020-10-18, MAE is:1.39 & sMAPE is:7.88% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 69.72% & 19.62\n",
      "for 2020-10-19, MAE is:6.69 & sMAPE is:19.64% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 69.54% & 19.55\n",
      "for 2020-10-20, MAE is:2.47 & sMAPE is:11.83% & rMAE is:2.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 69.35% & 19.50\n",
      "for 2020-10-21, MAE is:1.24 & sMAPE is:7.05% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 69.14% & 19.43\n",
      "for 2020-10-22, MAE is:2.43 & sMAPE is:17.05% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 68.96% & 19.37\n",
      "for 2020-10-23, MAE is:6.61 & sMAPE is:27.67% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 68.82% & 19.31\n",
      "for 2020-10-24, MAE is:0.38 & sMAPE is:2.63% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 68.60% & 19.24\n",
      "for 2020-10-25, MAE is:3.49 & sMAPE is:32.24% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 68.48% & 19.18\n",
      "for 2020-10-26, MAE is:1.94 & sMAPE is:14.22% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 68.30% & 19.12\n",
      "for 2020-10-27, MAE is:1.80 & sMAPE is:14.10% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 68.12% & 19.05\n",
      "for 2020-10-28, MAE is:2.01 & sMAPE is:25.29% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 67.98% & 18.99\n",
      "for 2020-10-29, MAE is:2.48 & sMAPE is:24.58% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 67.83% & 18.93\n",
      "for 2020-10-30, MAE is:0.71 & sMAPE is:7.36% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 67.63% & 18.87\n",
      "for 2020-10-31, MAE is:0.82 & sMAPE is:10.44% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 67.45% & 18.81\n",
      "for 2020-11-01, MAE is:1.63 & sMAPE is:30.85% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 67.33% & 18.75\n",
      "for 2020-11-02, MAE is:3.08 & sMAPE is:75.50% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 67.35% & 18.69\n",
      "for 2020-11-03, MAE is:2.29 & sMAPE is:52.18% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 67.30% & 18.63\n",
      "for 2020-11-04, MAE is:2.42 & sMAPE is:51.61% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 67.25% & 18.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-05, MAE is:3.41 & sMAPE is:84.47% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 67.31% & 18.51\n",
      "for 2020-11-06, MAE is:2.30 & sMAPE is:51.57% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 67.26% & 18.45\n",
      "for 2020-11-07, MAE is:2.71 & sMAPE is:56.75% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 67.22% & 18.39\n",
      "for 2020-11-08, MAE is:0.60 & sMAPE is:11.49% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 67.05% & 18.34\n",
      "for 2020-11-09, MAE is:0.51 & sMAPE is:7.49% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 66.86% & 18.28\n",
      "for 2020-11-10, MAE is:0.87 & sMAPE is:10.90% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 66.68% & 18.22\n",
      "for 2020-11-11, MAE is:0.38 & sMAPE is:4.98% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 66.48% & 18.17\n",
      "for 2020-11-12, MAE is:0.39 & sMAPE is:6.42% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 66.29% & 18.11\n",
      "for 2020-11-13, MAE is:1.73 & sMAPE is:36.71% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 66.20% & 18.05\n",
      "for 2020-11-14, MAE is:2.06 & sMAPE is:54.26% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 66.16% & 18.00\n",
      "for 2020-11-15, MAE is:3.19 & sMAPE is:97.29% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 66.26% & 17.95\n",
      "for 2020-11-16, MAE is:3.56 & sMAPE is:113.93% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 66.41% & 17.90\n",
      "for 2020-11-17, MAE is:2.83 & sMAPE is:102.49% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 66.52% & 17.84\n",
      "for 2020-11-18, MAE is:3.46 & sMAPE is:128.30% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 66.71% & 17.79\n",
      "for 2020-11-19, MAE is:3.68 & sMAPE is:132.32% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 66.92% & 17.73\n",
      "for 2020-11-20, MAE is:3.05 & sMAPE is:99.38% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 67.02% & 17.68\n",
      "for 2020-11-21, MAE is:3.80 & sMAPE is:129.86% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 67.21% & 17.64\n",
      "for 2020-11-22, MAE is:3.57 & sMAPE is:122.21% & rMAE is:6.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 67.38% & 17.60\n",
      "for 2020-11-23, MAE is:2.70 & sMAPE is:86.26% & rMAE is:4.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 67.43% & 17.56\n",
      "for 2020-11-24, MAE is:2.06 & sMAPE is:60.97% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 67.41% & 17.51\n",
      "for 2020-11-25, MAE is:2.41 & sMAPE is:72.36% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 67.43% & 17.47\n",
      "for 2020-11-26, MAE is:0.80 & sMAPE is:21.18% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 67.29% & 17.41\n",
      "for 2020-11-27, MAE is:2.63 & sMAPE is:38.60% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 67.20% & 17.36\n",
      "for 2020-11-28, MAE is:4.90 & sMAPE is:57.82% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 67.18% & 17.31\n",
      "for 2020-11-29, MAE is:4.98 & sMAPE is:46.42% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 67.11% & 17.26\n",
      "for 2020-11-30, MAE is:1.99 & sMAPE is:15.62% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 66.96% & 17.21\n",
      "for 2020-12-01, MAE is:2.74 & sMAPE is:19.85% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 66.82% & 17.16\n",
      "for 2020-12-02, MAE is:2.54 & sMAPE is:16.87% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 66.67% & 17.11\n",
      "for 2020-12-03, MAE is:5.29 & sMAPE is:34.13% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 66.57% & 17.06\n",
      "for 2020-12-04, MAE is:4.53 & sMAPE is:27.36% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 66.46% & 17.01\n",
      "for 2020-12-05, MAE is:3.99 & sMAPE is:22.42% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 66.33% & 16.96\n",
      "for 2020-12-06, MAE is:2.41 & sMAPE is:13.40% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 66.17% & 16.91\n",
      "for 2020-12-07, MAE is:2.09 & sMAPE is:13.07% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 66.02% & 16.87\n",
      "for 2020-12-08, MAE is:3.41 & sMAPE is:17.36% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 65.88% & 16.82\n",
      "for 2020-12-09, MAE is:12.17 & sMAPE is:29.28% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 65.77% & 16.77\n",
      "for 2020-12-10, MAE is:18.11 & sMAPE is:37.72% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 65.69% & 16.73\n",
      "for 2020-12-11, MAE is:5.16 & sMAPE is:20.96% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 65.56% & 16.68\n",
      "for 2020-12-12, MAE is:2.55 & sMAPE is:11.99% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 65.41% & 16.64\n",
      "for 2020-12-13, MAE is:2.14 & sMAPE is:9.94% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 65.25% & 16.59\n",
      "for 2020-12-14, MAE is:1.06 & sMAPE is:4.76% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 65.07% & 16.54\n",
      "for 2020-12-15, MAE is:1.31 & sMAPE is:5.84% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 64.90% & 16.50\n",
      "for 2020-12-16, MAE is:1.59 & sMAPE is:6.76% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 64.74% & 16.45\n",
      "for 2020-12-17, MAE is:2.95 & sMAPE is:13.11% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 64.59% & 16.40\n",
      "for 2020-12-18, MAE is:1.42 & sMAPE is:7.17% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 64.43% & 16.36\n",
      "for 2020-12-19, MAE is:1.28 & sMAPE is:7.35% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 64.27% & 16.31\n",
      "for 2020-12-20, MAE is:2.33 & sMAPE is:15.45% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 64.13% & 16.27\n",
      "for 2020-12-21, MAE is:3.74 & sMAPE is:22.19% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 64.01% & 16.23\n",
      "for 2020-12-22, MAE is:3.84 & sMAPE is:28.63% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 63.91% & 16.18\n",
      "for 2020-12-23, MAE is:3.57 & sMAPE is:20.20% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 63.79% & 16.14\n",
      "for 2020-12-24, MAE is:2.86 & sMAPE is:18.58% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 63.67% & 16.10\n",
      "for 2020-12-25, MAE is:4.66 & sMAPE is:26.17% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 63.56% & 16.06\n",
      "for 2020-12-26, MAE is:3.07 & sMAPE is:18.17% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 63.44% & 16.01\n",
      "for 2020-12-27, MAE is:6.92 & sMAPE is:65.90% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 63.44% & 15.97\n",
      "for 2020-12-28, MAE is:7.85 & sMAPE is:50.59% & rMAE is:4.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 63.41% & 15.94\n",
      "for 2020-12-29, MAE is:3.53 & sMAPE is:17.43% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 63.28% & 15.90\n",
      "for 2020-12-30, MAE is:2.37 & sMAPE is:10.39% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 63.14% & 15.86\n",
      "for 2020-12-31, MAE is:3.35 & sMAPE is:13.93% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 63.00% & 15.81\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:50:32,734]\u001b[0m A new study created in RDB with name: NO_1_2021\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 80.31% | rMAE for Validation Set is: 2.24\n",
      "MAE for Test Set is: 65.19 | sMAPE for Test Set is: 141.56% | rMAE for Test Set is: 3.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:51:09,217]\u001b[0m Trial 1 finished with value: 7.152487417502655 and parameters: {'n_hidden': 4, 'learning_rate': 0.003724289400567601, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.328604706159494, 'dropout_rate_Layer_2': 0.20021844926570878, 'dropout_rate_Layer_3': 0.04134531809117044, 'dropout_rate_Layer_4': 0.3834345673103598, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0019274374389999366, 'l1_Layer_2': 1.0306157958610294e-05, 'l1_Layer_3': 0.0011028695836111774, 'l1_Layer_4': 1.9929142705995118e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 115, 'n_units_Layer_3': 205, 'n_units_Layer_4': 235}. Best is trial 1 with value: 7.152487417502655.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:51:15,050]\u001b[0m Trial 0 finished with value: 18.139144496917726 and parameters: {'n_hidden': 3, 'learning_rate': 0.05006379719332263, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12229707207258499, 'dropout_rate_Layer_2': 0.20481165137936688, 'dropout_rate_Layer_3': 0.13187719848061272, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.656013626771888e-05, 'l1_Layer_2': 0.04033719849975258, 'l1_Layer_3': 0.019700364422939175, 'n_units_Layer_1': 125, 'n_units_Layer_2': 250, 'n_units_Layer_3': 245}. Best is trial 1 with value: 7.152487417502655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.14 | sMAPE for Validation Set is: 113.03% | rMAE for Validation Set is: 5.69\n",
      "MAE for Test Set is: 34.18 | sMAPE for Test Set is: 46.07% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:51:47,349]\u001b[0m Trial 3 finished with value: 14.892216037380111 and parameters: {'n_hidden': 3, 'learning_rate': 0.007896869961926858, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17939007509334737, 'dropout_rate_Layer_2': 0.29515965957720985, 'dropout_rate_Layer_3': 0.2954682555133787, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03754111054234222, 'l1_Layer_2': 0.00013061418077364015, 'l1_Layer_3': 0.01360986278205472, 'n_units_Layer_1': 90, 'n_units_Layer_2': 135, 'n_units_Layer_3': 130}. Best is trial 1 with value: 7.152487417502655.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.89 | sMAPE for Validation Set is: 105.71% | rMAE for Validation Set is: 4.67\n",
      "MAE for Test Set is: 35.62 | sMAPE for Test Set is: 48.87% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:52:07,053]\u001b[0m Trial 4 finished with value: 4.79923091719963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017547134120106406, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22158947657275455, 'dropout_rate_Layer_2': 0.29208243941225376, 'dropout_rate_Layer_3': 0.17954501145128737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00015640533997378695, 'l1_Layer_2': 0.00012167553718416827, 'l1_Layer_3': 0.008568619964297867, 'n_units_Layer_1': 225, 'n_units_Layer_2': 190, 'n_units_Layer_3': 295}. Best is trial 4 with value: 4.79923091719963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 66.04% | rMAE for Validation Set is: 1.51\n",
      "MAE for Test Set is: 49.43 | sMAPE for Test Set is: 84.14% | rMAE for Test Set is: 2.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:52:27,678]\u001b[0m Trial 5 finished with value: 9.395956703452123 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006681890381339941, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3490099360228712, 'dropout_rate_Layer_2': 0.025270642881098794, 'dropout_rate_Layer_3': 0.1821573696321356, 'dropout_rate_Layer_4': 0.04132370216269008, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4015063490602221e-05, 'l1_Layer_2': 4.6165578405508374e-05, 'l1_Layer_3': 1.0240942431819206e-05, 'l1_Layer_4': 0.0002870370135500563, 'n_units_Layer_1': 285, 'n_units_Layer_2': 120, 'n_units_Layer_3': 205, 'n_units_Layer_4': 180}. Best is trial 4 with value: 4.79923091719963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.40 | sMAPE for Validation Set is: 88.42% | rMAE for Validation Set is: 2.95\n",
      "MAE for Test Set is: 59.93 | sMAPE for Test Set is: 120.24% | rMAE for Test Set is: 3.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:52:32,144]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:52:39,364]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:52:46,995]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:52:49,083]\u001b[0m Trial 2 finished with value: 2.060841098259806 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005960944037086228, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00017849694810689876, 'dropout_rate_Layer_2': 0.06886737990244077, 'dropout_rate_Layer_3': 0.351612676488394, 'dropout_rate_Layer_4': 0.016159369548038073, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0343718476403766, 'l1_Layer_2': 0.09684301889952188, 'l1_Layer_3': 0.0003479152070065926, 'l1_Layer_4': 0.00010538100748452161, 'n_units_Layer_1': 275, 'n_units_Layer_2': 250, 'n_units_Layer_3': 290, 'n_units_Layer_4': 60}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 46.49% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 19.04 | sMAPE for Test Set is: 22.23% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:52:56,618]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:52:56,765]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:53:03,618]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:53:08,651]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:53:11,839]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:53:16,464]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:53:16,887]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:53:31,223]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:53:42,225]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:53:49,703]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:53:58,944]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:54:06,621]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:54:21,675]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:54:28,552]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:54:38,546]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:54:46,604]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:06,463]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:21,542]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:28,551]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:36,290]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:41,885]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:48,772]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:54,420]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:55:59,161]\u001b[0m Trial 18 finished with value: 3.684027619628908 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005672394594327396, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012878878540591776, 'dropout_rate_Layer_2': 0.10426828359269598, 'dropout_rate_Layer_3': 0.38346632719833496, 'dropout_rate_Layer_4': 0.3174727479002187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.01817928561225317, 'l1_Layer_2': 0.013751988506939539, 'l1_Layer_3': 0.0003989157402169786, 'l1_Layer_4': 2.5349008658461742e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 135, 'n_units_Layer_3': 165, 'n_units_Layer_4': 145}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 56.26% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 15.54 | sMAPE for Test Set is: 17.92% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:56:03,416]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:56:06,663]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:56:06,899]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:56:14,483]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:56:19,576]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:56:22,577]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:56:22,707]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:56:31,868]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:56:37,110]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:56:42,401]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:17,721]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:22,623]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:27,300]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:32,410]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:45,082]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:57:56,178]\u001b[0m Trial 40 finished with value: 6.079514229457026 and parameters: {'n_hidden': 3, 'learning_rate': 0.000546037751238149, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023754344992877652, 'dropout_rate_Layer_2': 0.14857022010452545, 'dropout_rate_Layer_3': 0.3963852607103375, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007966880305165708, 'l1_Layer_2': 1.415116230032302e-05, 'l1_Layer_3': 1.1042877186807995e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 55, 'n_units_Layer_3': 190}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 73.93% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 62.78 | sMAPE for Test Set is: 131.14% | rMAE for Test Set is: 3.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:57:56,796]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:06,519]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:06,683]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:18,936]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:27,682]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:30,530]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:36,092]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:43,323]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:50,088]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:58:55,097]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:59:00,460]\u001b[0m Trial 58 finished with value: 5.772420372799136 and parameters: {'n_hidden': 3, 'learning_rate': 0.002900382037559345, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3965682078308626, 'dropout_rate_Layer_2': 0.3813199290719687, 'dropout_rate_Layer_3': 0.21943534387535393, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00821325963667628, 'l1_Layer_2': 0.08508485796953638, 'l1_Layer_3': 5.499909443840159e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 250}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 73.49% | rMAE for Validation Set is: 1.81\n",
      "MAE for Test Set is: 29.20 | sMAPE for Test Set is: 35.92% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:59:00,674]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:59:07,844]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:59:12,749]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:59:19,924]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:59:27,822]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:59:37,711]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:59:47,890]\u001b[0m Trial 61 finished with value: 5.483460201707945 and parameters: {'n_hidden': 3, 'learning_rate': 0.00151131814588229, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06423043878157891, 'dropout_rate_Layer_2': 0.23763416213141425, 'dropout_rate_Layer_3': 0.3254847169588564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00914554943002435, 'l1_Layer_2': 0.0033591723072786367, 'l1_Layer_3': 5.67185562864871e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 70.05% | rMAE for Validation Set is: 1.72\n",
      "MAE for Test Set is: 52.38 | sMAPE for Test Set is: 96.28% | rMAE for Test Set is: 3.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 11:59:52,626]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 11:59:57,241]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:10,234]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:16,620]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:23,020]\u001b[0m Trial 70 finished with value: 5.944924267854752 and parameters: {'n_hidden': 3, 'learning_rate': 0.001390420710593314, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0658243224429314, 'dropout_rate_Layer_2': 0.26178485689757774, 'dropout_rate_Layer_3': 0.3150553499730597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018126979814742872, 'l1_Layer_2': 0.004053226602320405, 'l1_Layer_3': 6.69351707755578e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 76.11% | rMAE for Validation Set is: 1.87\n",
      "MAE for Test Set is: 67.93 | sMAPE for Test Set is: 155.86% | rMAE for Test Set is: 3.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:00:32,786]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:38,418]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:45,588]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:51,462]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:51,492]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:00:59,500]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:04,142]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:14,309]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:24,302]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:29,445]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:33,831]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:38,778]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:44,076]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:48,899]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:51,120]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:01:56,595]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:02:28,932]\u001b[0m Trial 89 finished with value: 4.2903342708295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007462567561226954, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2617229039000646, 'dropout_rate_Layer_2': 0.07284430618496038, 'dropout_rate_Layer_3': 0.25103070612360645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010856834323513592, 'l1_Layer_2': 0.0017087815404211956, 'l1_Layer_3': 0.0029562662178650766, 'n_units_Layer_1': 285, 'n_units_Layer_2': 195, 'n_units_Layer_3': 195}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 74.09% | rMAE for Validation Set is: 1.35\n",
      "MAE for Test Set is: 35.63 | sMAPE for Test Set is: 51.35% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:02:31,843]\u001b[0m Trial 88 finished with value: 4.18444659483383 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005428117588933243, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26121537723964444, 'dropout_rate_Layer_2': 0.03224163452224543, 'dropout_rate_Layer_3': 0.2540379343734842, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001163575972133798, 'l1_Layer_2': 0.002252037222976948, 'l1_Layer_3': 0.003065624320471561, 'n_units_Layer_1': 290, 'n_units_Layer_2': 200, 'n_units_Layer_3': 200}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 59.11% | rMAE for Validation Set is: 1.31\n",
      "MAE for Test Set is: 35.65 | sMAPE for Test Set is: 49.97% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:02:38,548]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:02:46,512]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:02:51,299]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:02:58,741]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:03:11,841]\u001b[0m Trial 90 finished with value: 4.09065042398863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005669836137600091, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2670597412618994, 'dropout_rate_Layer_2': 0.031025724777299972, 'dropout_rate_Layer_3': 0.2590022817471772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010915657715856782, 'l1_Layer_2': 0.0012050131054816393, 'l1_Layer_3': 0.003203735130392328, 'n_units_Layer_1': 295, 'n_units_Layer_2': 195, 'n_units_Layer_3': 195}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 58.44% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 30.65 | sMAPE for Test Set is: 41.56% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:03:16,658]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:03:21,072]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:03:23,614]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:03:28,748]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:03:34,263]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:03:46,670]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:03:54,043]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:04:00,927]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:04:08,853]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:04:21,310]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:04:27,863]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:04:33,234]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:04:40,290]\u001b[0m Trial 104 finished with value: 5.551021791309146 and parameters: {'n_hidden': 4, 'learning_rate': 0.002221086150162405, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14131279995997154, 'dropout_rate_Layer_2': 0.015241484413223032, 'dropout_rate_Layer_3': 0.06428995984314399, 'dropout_rate_Layer_4': 0.08067558978549508, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.71106780050115e-05, 'l1_Layer_2': 0.0001323283647764852, 'l1_Layer_3': 0.0006258206728101861, 'l1_Layer_4': 3.9392297221161614e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 105, 'n_units_Layer_3': 100, 'n_units_Layer_4': 120}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 72.61% | rMAE for Validation Set is: 1.74\n",
      "MAE for Test Set is: 48.88 | sMAPE for Test Set is: 85.41% | rMAE for Test Set is: 2.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:04:48,283]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:05:08,214]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:05:12,609]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:05:19,899]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:05:27,679]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:05:40,483]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:05:45,760]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:05:57,291]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:06:09,492]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:06:17,562]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:06:24,322]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:06:34,083]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:06:46,479]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:06:54,667]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:07:01,363]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:07:09,056]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:07:16,687]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:07:17,228]\u001b[0m Trial 109 finished with value: 2.3579001973996916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009416701474682738, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08787070404734731, 'dropout_rate_Layer_2': 0.32978940486115904, 'dropout_rate_Layer_3': 0.32252863548485294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04609364305257278, 'l1_Layer_2': 0.020338368611447662, 'l1_Layer_3': 3.2222951749164035e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 165, 'n_units_Layer_3': 75}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.36 | sMAPE for Validation Set is: 41.63% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 14.87 | sMAPE for Test Set is: 16.94% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:07:54,874]\u001b[0m Trial 126 finished with value: 7.539277449827452 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005937736042976359, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1870185946475588, 'dropout_rate_Layer_2': 0.28501963381015843, 'dropout_rate_Layer_3': 0.32208397030688046, 'dropout_rate_Layer_4': 0.0491654199862107, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003595553155269902, 'l1_Layer_2': 0.037681041100112916, 'l1_Layer_3': 0.006386291433261848, 'l1_Layer_4': 2.4974030938679632e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230, 'n_units_Layer_4': 75}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.54 | sMAPE for Validation Set is: 82.06% | rMAE for Validation Set is: 2.37\n",
      "MAE for Test Set is: 62.63 | sMAPE for Test Set is: 130.47% | rMAE for Test Set is: 3.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:08:02,120]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:07,483]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:15,232]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:30,038]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:39,744]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:08:52,877]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:02,219]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:07,304]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:07,395]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:19,839]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:19,952]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:40,174]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:51,994]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:09:57,056]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:02,683]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:09,594]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:15,225]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:19,584]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:22,584]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:27,841]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:10:51,394]\u001b[0m Trial 146 finished with value: 4.2303620189092115 and parameters: {'n_hidden': 3, 'learning_rate': 0.00098772411412272, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35425577332079583, 'dropout_rate_Layer_2': 0.1277305306126239, 'dropout_rate_Layer_3': 0.1481158458785308, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.067765048932804e-05, 'l1_Layer_2': 0.000658184974766625, 'l1_Layer_3': 0.00012031089328791978, 'n_units_Layer_1': 175, 'n_units_Layer_2': 295, 'n_units_Layer_3': 110}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 56.96% | rMAE for Validation Set is: 1.33\n",
      "MAE for Test Set is: 47.71 | sMAPE for Test Set is: 80.96% | rMAE for Test Set is: 2.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:10:56,578]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:11:06,168]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:11:15,823]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:11:40,566]\u001b[0m Trial 152 finished with value: 4.779062460622193 and parameters: {'n_hidden': 3, 'learning_rate': 0.001020658128041297, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39152421409848104, 'dropout_rate_Layer_2': 0.12676597060261913, 'dropout_rate_Layer_3': 0.14289181484339045, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.790352250938556e-05, 'l1_Layer_2': 0.000653838915441159, 'l1_Layer_3': 9.166307075980204e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 285, 'n_units_Layer_3': 100}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 62.77% | rMAE for Validation Set is: 1.50\n",
      "MAE for Test Set is: 56.28 | sMAPE for Test Set is: 107.91% | rMAE for Test Set is: 3.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:11:50,160]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:11:53,315]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:12:01,055]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:12:10,705]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:12:13,454]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:12:45,987]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:12:48,878]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:12:55,623]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:13:03,216]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:13:18,024]\u001b[0m Trial 160 finished with value: 4.185789189601564 and parameters: {'n_hidden': 3, 'learning_rate': 0.000836897305807624, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.314795070673249, 'dropout_rate_Layer_2': 0.024380157376425463, 'dropout_rate_Layer_3': 0.04936164697871043, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.047882297662021e-05, 'l1_Layer_2': 0.0005236113761981874, 'l1_Layer_3': 1.174391239197309e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 240, 'n_units_Layer_3': 110}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 53.94% | rMAE for Validation Set is: 1.31\n",
      "MAE for Test Set is: 49.48 | sMAPE for Test Set is: 86.02% | rMAE for Test Set is: 2.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:13:20,807]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:13:30,902]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:13:36,011]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:13:40,950]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:13:52,394]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:13:57,343]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:07,696]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:12,689]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:20,370]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:27,304]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:27,863]\u001b[0m Trial 168 finished with value: 4.089445209737828 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007697547567000068, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26426868634134976, 'dropout_rate_Layer_2': 0.004040141592497947, 'dropout_rate_Layer_3': 0.0559217941682372, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00020929928424400334, 'l1_Layer_2': 0.0002996543577501758, 'l1_Layer_3': 0.0014610252821057827, 'n_units_Layer_1': 270, 'n_units_Layer_2': 235, 'n_units_Layer_3': 165}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 54.96% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 48.75 | sMAPE for Test Set is: 84.99% | rMAE for Test Set is: 2.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:14:33,839]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:38,100]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:41,221]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:45,310]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:14:52,769]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:15:00,001]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:15:07,349]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:15:18,194]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:15:24,914]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:15:32,385]\u001b[0m Trial 181 finished with value: 6.923908689188093 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005578647892659662, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2661204696733148, 'dropout_rate_Layer_2': 0.3707287582894742, 'dropout_rate_Layer_3': 0.3035772310085184, 'dropout_rate_Layer_4': 0.08313407070123699, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0008080863332574537, 'l1_Layer_2': 0.07825477234778143, 'l1_Layer_3': 3.812862285353414e-05, 'l1_Layer_4': 6.613641009025116e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285, 'n_units_Layer_4': 105}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 79.38% | rMAE for Validation Set is: 2.17\n",
      "MAE for Test Set is: 64.09 | sMAPE for Test Set is: 136.85% | rMAE for Test Set is: 3.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:15:38,206]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:15:55,295]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:04,873]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:15,223]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:30,691]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:32,412]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:39,399]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:39,669]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:44,724]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:47,144]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:16:54,185]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:02,392]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:04,424]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:11,855]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:21,582]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:26,890]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:27,164]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:35,376]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:40,332]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:45,087]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:50,109]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:17:50,331]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:00,678]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:09,047]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:13,941]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:21,595]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:25,749]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:31,346]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:35,927]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:18:45,954]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:19:04,894]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:19:21,973]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:19:32,266]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:19:39,447]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:19:54,221]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:19:56,780]\u001b[0m Trial 213 finished with value: 6.4045568118376535 and parameters: {'n_hidden': 3, 'learning_rate': 0.000594226105532583, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04351979575943703, 'dropout_rate_Layer_2': 0.25131074635023737, 'dropout_rate_Layer_3': 0.327702259111605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.01884544760275832, 'l1_Layer_2': 0.00011169107679853438, 'l1_Layer_3': 0.0011568669865144748, 'n_units_Layer_1': 290, 'n_units_Layer_2': 135, 'n_units_Layer_3': 160}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 77.58% | rMAE for Validation Set is: 2.01\n",
      "MAE for Test Set is: 66.84 | sMAPE for Test Set is: 150.00% | rMAE for Test Set is: 3.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:20:06,416]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:20:09,157]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:20:12,538]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:20:23,936]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:20:28,895]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:20:43,620]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:20:53,002]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:21:07,849]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:21:13,117]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:21:57,922]\u001b[0m Trial 229 finished with value: 6.885383784524134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008062256865916203, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.059590012541395135, 'dropout_rate_Layer_2': 0.24109237925710691, 'dropout_rate_Layer_3': 0.32920102901120085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.06959641510487351, 'l1_Layer_2': 1.2595290433985771e-05, 'l1_Layer_3': 0.0003070632238639261, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 145}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 95.28% | rMAE for Validation Set is: 2.16\n",
      "MAE for Test Set is: 72.68 | sMAPE for Test Set is: 182.04% | rMAE for Test Set is: 4.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:22:03,301]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:17,872]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:23,190]\u001b[0m Trial 227 finished with value: 4.601671440209381 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005936540630677787, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09115723939182864, 'dropout_rate_Layer_2': 0.3135632996727391, 'dropout_rate_Layer_3': 0.36597445181223387, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03152271026675949, 'l1_Layer_2': 0.00013165980249929473, 'l1_Layer_3': 0.0003662021672423215, 'n_units_Layer_1': 260, 'n_units_Layer_2': 115, 'n_units_Layer_3': 195}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:23,320]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 61.55% | rMAE for Validation Set is: 1.44\n",
      "MAE for Test Set is: 52.62 | sMAPE for Test Set is: 96.70% | rMAE for Test Set is: 3.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:22:30,158]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:37,251]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:46,442]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:48,465]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:22:59,160]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:23:04,840]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:23:11,544]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:23:14,478]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:23:48,506]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:23:49,148]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:02,575]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:03,072]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:15,786]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:20,074]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:27,994]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:38,484]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:44,819]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:49,775]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:24:54,957]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:25:00,188]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:25:07,190]\u001b[0m Trial 247 finished with value: 6.789440729479714 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009005050623189986, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06707770102641225, 'dropout_rate_Layer_2': 0.28799726582467977, 'dropout_rate_Layer_3': 0.3319422708179411, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.026348612933287986, 'l1_Layer_2': 2.8458701404440182e-05, 'l1_Layer_3': 0.00023200478750992298, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 125}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.79 | sMAPE for Validation Set is: 93.02% | rMAE for Validation Set is: 2.13\n",
      "MAE for Test Set is: 72.18 | sMAPE for Test Set is: 179.26% | rMAE for Test Set is: 4.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:25:25,318]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:25:30,031]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:25:39,598]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:25:39,761]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:25:50,103]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:25:57,597]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:02,449]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:07,616]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:12,210]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:14,614]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:21,922]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:26,901]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:30,203]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:35,154]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:26:50,012]\u001b[0m Trial 264 finished with value: 5.934537492269925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014520538565767015, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1498188484413125, 'dropout_rate_Layer_2': 0.28750463059506975, 'dropout_rate_Layer_3': 0.2977360708887995, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014062581077528951, 'l1_Layer_2': 3.2227885025295374e-05, 'l1_Layer_3': 0.00022815465574547696, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 120}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 74.93% | rMAE for Validation Set is: 1.86\n",
      "MAE for Test Set is: 65.77 | sMAPE for Test Set is: 145.25% | rMAE for Test Set is: 3.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:26:56,690]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:06,945]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:14,082]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:19,134]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:24,569]\u001b[0m Trial 270 finished with value: 4.269222545616169 and parameters: {'n_hidden': 3, 'learning_rate': 0.001094884083661722, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35090336202396655, 'dropout_rate_Layer_2': 0.21687644919642343, 'dropout_rate_Layer_3': 0.09018112495672242, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.5190230649096073e-05, 'l1_Layer_2': 0.00043489110674545023, 'l1_Layer_3': 3.614735183256147e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 57.10% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 51.72 | sMAPE for Test Set is: 94.16% | rMAE for Test Set is: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:27:32,037]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:34,596]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:39,545]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:44,246]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:51,444]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:56,659]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:27:56,974]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:07,430]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:07,431]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:16,631]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:21,781]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:24,342]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:31,893]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:36,006]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:43,548]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:28:43,932]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:01,697]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:06,948]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:09,248]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:13,624]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:18,944]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:19,643]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:27,053]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:31,499]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:37,164]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:37,451]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:46,150]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:46,493]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:58,813]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:29:58,889]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:07,138]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:11,523]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:14,696]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:22,182]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:26,290]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:28,164]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:34,181]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:44,125]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:50,880]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:51,357]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:56,713]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:30:59,054]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:13,584]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:18,318]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:23,900]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:32,363]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:32,729]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:40,463]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:50,228]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:51,016]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:56,530]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:31:59,230]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:32:08,134]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:32:10,820]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:32:13,890]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:32:18,541]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:32:43,612]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:32:50,698]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:33:01,105]\u001b[0m Trial 330 finished with value: 6.9578441507786435 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010548338439751639, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.061649086685858334, 'dropout_rate_Layer_2': 0.205441460214505, 'dropout_rate_Layer_3': 0.32420392955491495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.08917205208032059, 'l1_Layer_2': 1.0828562952996136e-05, 'l1_Layer_3': 5.864163739674506e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 96.17% | rMAE for Validation Set is: 2.18\n",
      "MAE for Test Set is: 72.94 | sMAPE for Test Set is: 183.94% | rMAE for Test Set is: 4.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:33:11,297]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:33:25,734]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:33:30,537]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:33:30,660]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:33:42,504]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:33:42,694]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:33:50,653]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:33:56,507]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:33:58,906]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:05,193]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:10,615]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:12,799]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:15,667]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:23,474]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:28,053]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:35,014]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:45,077]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:50,284]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:34:56,989]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:35:04,939]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:35:09,620]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:35:17,269]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:35:22,394]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:35:50,009]\u001b[0m Trial 357 finished with value: 4.2980096855873064 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010935560987127722, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3582279779809726, 'dropout_rate_Layer_2': 0.2531959284412375, 'dropout_rate_Layer_3': 0.02837483297142694, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.000107677488693e-05, 'l1_Layer_2': 0.000569211271658602, 'l1_Layer_3': 2.339448630820113e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 165, 'n_units_Layer_3': 65}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 56.53% | rMAE for Validation Set is: 1.35\n",
      "MAE for Test Set is: 46.37 | sMAPE for Test Set is: 78.43% | rMAE for Test Set is: 2.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:35:55,038]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:36:02,592]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:36:10,388]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:36:20,004]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:36:24,638]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:36:31,636]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:36:37,110]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:37:08,710]\u001b[0m Trial 365 finished with value: 4.8712691862586475 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006579331677324968, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34107082949387324, 'dropout_rate_Layer_2': 0.2244882837796693, 'dropout_rate_Layer_3': 0.1008594035498579, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.7738252631850025e-05, 'l1_Layer_2': 0.0011103282479661759, 'l1_Layer_3': 1.709284728103372e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 255, 'n_units_Layer_3': 100}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 62.92% | rMAE for Validation Set is: 1.53\n",
      "MAE for Test Set is: 46.27 | sMAPE for Test Set is: 76.67% | rMAE for Test Set is: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:37:16,226]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:37:21,098]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:37:38,450]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:37:56,825]\u001b[0m Trial 351 finished with value: 2.4076559837119604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006247579540235146, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026287082543022967, 'dropout_rate_Layer_2': 0.1584574198108686, 'dropout_rate_Layer_3': 0.3388384667231927, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016560315992738685, 'l1_Layer_2': 2.7504485903613206e-05, 'l1_Layer_3': 0.0002165051305281194, 'n_units_Layer_1': 230, 'n_units_Layer_2': 145, 'n_units_Layer_3': 125}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.41 | sMAPE for Validation Set is: 55.45% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 23.47 | sMAPE for Test Set is: 27.29% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:38:06,575]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:38:13,838]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:38:31,460]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:38:35,820]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:38:41,145]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:38:50,495]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:38:55,993]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:38:58,715]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:08,101]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:10,945]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:13,320]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:20,508]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:27,940]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:35,948]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:40,935]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:45,819]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:39:50,775]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:00,380]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:03,435]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:18,239]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:18,613]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:26,056]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:26,233]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:36,911]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:37,293]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:47,346]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:40:51,815]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:04,226]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:09,646]\u001b[0m Trial 394 finished with value: 4.085358320600254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008027279638218066, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2183028135924119, 'dropout_rate_Layer_2': 0.034626471940910494, 'dropout_rate_Layer_3': 0.2563500314792458, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00037147315523398494, 'l1_Layer_2': 0.0005813668958347971, 'l1_Layer_3': 0.0038123480517960957, 'n_units_Layer_1': 260, 'n_units_Layer_2': 195, 'n_units_Layer_3': 220}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 62.14% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 49.90 | sMAPE for Test Set is: 88.51% | rMAE for Test Set is: 2.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:41:18,927]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:24,865]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:43,932]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:44,372]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:55,046]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:57,463]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:41:59,866]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:42:07,318]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:42:07,562]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:42:15,219]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:42:27,039]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:42:30,014]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:42:37,351]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:42:55,368]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:43:00,354]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:43:10,826]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:43:48,014]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:44:05,579]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:44:10,868]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:44:17,696]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:44:18,069]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:44:26,470]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:44:33,588]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:44:46,466]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:44:58,354]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:45:05,928]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:45:21,713]\u001b[0m Trial 425 finished with value: 6.032749185535569 and parameters: {'n_hidden': 3, 'learning_rate': 0.000503075133200599, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.334915418570615, 'dropout_rate_Layer_2': 0.14339326424871898, 'dropout_rate_Layer_3': 0.28343660867085474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00036249729884709923, 'l1_Layer_2': 0.00014242020463062552, 'l1_Layer_3': 3.582578211689676e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 160, 'n_units_Layer_3': 120}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 76.26% | rMAE for Validation Set is: 1.89\n",
      "MAE for Test Set is: 67.80 | sMAPE for Test Set is: 154.69% | rMAE for Test Set is: 3.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:45:28,491]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:45:36,602]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:45:41,056]\u001b[0m Trial 423 finished with value: 6.394990462876073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008595004802230348, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.061556462315039535, 'dropout_rate_Layer_2': 0.20870034259340625, 'dropout_rate_Layer_3': 0.32618133571169805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04773587176874555, 'l1_Layer_2': 1.157829535123159e-05, 'l1_Layer_3': 6.215228514131827e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 85.52% | rMAE for Validation Set is: 2.01\n",
      "MAE for Test Set is: 72.87 | sMAPE for Test Set is: 182.22% | rMAE for Test Set is: 4.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:45:46,377]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:45:51,504]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:46:01,807]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:46:26,870]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:46:43,708]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:46:50,959]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:46:54,335]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:02,137]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:09,263]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:11,867]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:18,558]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:21,826]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:29,276]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:34,056]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:41,258]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:46,860]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:51,909]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:47:58,695]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:48:06,541]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:48:16,202]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:48:22,027]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:48:28,734]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:48:33,657]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:48:43,505]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:48:46,825]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:48:51,207]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:48:55,640]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:01,303]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:06,069]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:11,444]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:16,478]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:20,698]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:28,038]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:35,675]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:38,484]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:43,222]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:45,993]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:49:48,494]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:50:00,057]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:50:00,670]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:50:07,712]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:50:30,972]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:50:42,890]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:50:46,009]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:50:53,511]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:50:58,303]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:50:58,772]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:05,968]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:06,188]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:14,889]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:21,573]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:27,513]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:34,588]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:39,275]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:47,068]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:52,628]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:51:54,945]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:00,255]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:04,887]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:12,697]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:17,445]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:20,012]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:35,464]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:43,122]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:47,799]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:52:54,975]\u001b[0m Trial 491 finished with value: 4.166319553926933 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011092057096382698, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37853770412491383, 'dropout_rate_Layer_2': 0.22125545615744313, 'dropout_rate_Layer_3': 0.027750284998931275, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.946785923073163e-05, 'l1_Layer_2': 0.0006042990955592969, 'l1_Layer_3': 1.3900276363173807e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 52.52% | rMAE for Validation Set is: 1.31\n",
      "MAE for Test Set is: 44.42 | sMAPE for Test Set is: 71.74% | rMAE for Test Set is: 2.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:53:09,971]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:53:15,669]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:53:23,085]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:53:27,702]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:53:35,111]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:53:42,111]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:53:47,681]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:00,042]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:05,277]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:10,483]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:15,374]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:23,073]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:30,254]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:34,881]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:39,994]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:44,876]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:50,125]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:54:55,144]\u001b[0m Trial 496 finished with value: 3.509724587511578 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011657268763238865, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10460115871800292, 'dropout_rate_Layer_2': 0.34628144414315254, 'dropout_rate_Layer_3': 0.31722790756095165, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0646545318019946, 'l1_Layer_2': 2.5184235992270428e-05, 'l1_Layer_3': 5.351467624456993e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.51 | sMAPE for Validation Set is: 81.43% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 17.79 | sMAPE for Test Set is: 20.50% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:54:59,638]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:04,953]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:09,370]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:12,160]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:22,500]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:27,477]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:32,166]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:37,496]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:42,278]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:42,674]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:50,811]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:55:51,294]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:01,132]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:08,354]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:16,626]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:21,912]\u001b[0m Trial 526 finished with value: 6.018057652053283 and parameters: {'n_hidden': 3, 'learning_rate': 0.001932741845201273, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32496843079392235, 'dropout_rate_Layer_2': 0.022920916140398772, 'dropout_rate_Layer_3': 0.04685689618633756, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 6.0193643815438974e-05, 'l1_Layer_2': 7.963521869250926e-05, 'l1_Layer_3': 1.3303427421859526e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 290, 'n_units_Layer_3': 75}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 76.34% | rMAE for Validation Set is: 1.89\n",
      "MAE for Test Set is: 68.01 | sMAPE for Test Set is: 155.78% | rMAE for Test Set is: 3.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 12:56:26,218]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:28,877]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:36,677]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:41,015]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:56:51,357]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:57:10,839]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:57:20,734]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:57:25,340]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:57:30,639]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:57:33,210]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:57:40,303]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:57:48,036]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:57:52,937]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:57:53,091]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:02,614]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:02,795]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:10,994]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:16,093]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:21,079]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:26,333]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:33,392]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:33,733]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:56,683]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:58:56,762]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:05,206]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:05,666]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:14,150]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:14,355]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:24,134]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:24,343]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:32,258]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:39,356]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:44,610]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 12:59:54,339]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:04,334]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:10,271]\u001b[0m Trial 561 finished with value: 4.975445207913052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010908113919690036, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10813455098316344, 'dropout_rate_Layer_2': 0.15679485955915123, 'dropout_rate_Layer_3': 0.021802187271070625, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001961148607222025, 'l1_Layer_2': 0.00110494335785095, 'l1_Layer_3': 1.8723496019762167e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 240, 'n_units_Layer_3': 95}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 65.96% | rMAE for Validation Set is: 1.56\n",
      "MAE for Test Set is: 63.98 | sMAPE for Test Set is: 137.82% | rMAE for Test Set is: 3.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:00:14,467]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:19,927]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:24,743]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:31,912]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:37,485]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:44,530]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:51,907]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:00:52,119]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:02,331]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:05,347]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:12,791]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:19,547]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:23,001]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:32,550]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:35,560]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:42,322]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:47,679]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:50,064]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:01:57,422]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:01,956]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:05,150]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:09,528]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:15,049]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:34,728]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:46,587]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:51,956]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:02:57,338]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:01,765]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:09,666]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:13,977]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:21,427]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:27,131]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:34,400]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:44,710]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:03:51,765]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:04,493]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:07,767]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:17,287]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:20,140]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:24,611]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:27,277]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:32,470]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:39,341]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:42,675]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:54,688]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:04:59,916]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:05:00,247]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:05:13,225]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:05:20,101]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:05:20,326]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:05:30,238]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:05:34,561]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:05:39,544]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:05:57,436]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:06:22,580]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:06:27,586]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:06:34,886]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:06:38,009]\u001b[0m Trial 618 finished with value: 4.650119681419491 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013413810587904584, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12975144825326504, 'dropout_rate_Layer_2': 0.3232991586092137, 'dropout_rate_Layer_3': 0.2500463646114276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025368880092753725, 'l1_Layer_2': 0.030330673127116785, 'l1_Layer_3': 1.256860927208047e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 175, 'n_units_Layer_3': 55}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 60.69% | rMAE for Validation Set is: 1.46\n",
      "MAE for Test Set is: 53.62 | sMAPE for Test Set is: 102.69% | rMAE for Test Set is: 3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:06:42,165]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:06:46,919]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:06:51,905]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:06:57,854]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:07:07,126]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:07:12,016]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:07:17,676]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:07:19,807]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:07:31,905]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:07:44,878]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:07:49,689]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:07:55,136]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:00,243]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:16,797]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:24,804]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:29,410]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:32,311]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:37,415]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:46,760]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:51,194]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:08:56,311]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:09:01,801]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:09:34,195]\u001b[0m Trial 645 finished with value: 4.265513201345004 and parameters: {'n_hidden': 3, 'learning_rate': 0.00115734655220422, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21383586877338806, 'dropout_rate_Layer_2': 0.23842968643815818, 'dropout_rate_Layer_3': 0.09148327317554628, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.991322168000446e-05, 'l1_Layer_2': 0.004304436333337928, 'l1_Layer_3': 0.0012980156868187735, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 75}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 56.58% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 52.04 | sMAPE for Test Set is: 94.57% | rMAE for Test Set is: 3.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:09:41,801]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:09:48,437]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:10:26,737]\u001b[0m Trial 646 finished with value: 6.5282612763651 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015540316292974707, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15069359497335946, 'dropout_rate_Layer_2': 0.31880243962796756, 'dropout_rate_Layer_3': 0.25722413721709053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014305049554521, 'l1_Layer_2': 0.02046959725525857, 'l1_Layer_3': 1.2284644716525393e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 180, 'n_units_Layer_3': 55}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 87.86% | rMAE for Validation Set is: 2.05\n",
      "MAE for Test Set is: 71.09 | sMAPE for Test Set is: 173.16% | rMAE for Test Set is: 4.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:10:33,486]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:10:43,578]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:10:48,753]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:10:53,511]\u001b[0m Trial 648 finished with value: 3.7703420772171725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013372870008012505, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12770262027543278, 'dropout_rate_Layer_2': 0.3229332033899639, 'dropout_rate_Layer_3': 0.2651600157074405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008440803359695099, 'l1_Layer_2': 0.01792053056732481, 'l1_Layer_3': 1.2603545821740818e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 180, 'n_units_Layer_3': 55}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 57.04% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 19.69 | sMAPE for Test Set is: 22.74% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:10:58,575]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:11:04,054]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:11:10,824]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:11:38,312]\u001b[0m Trial 656 finished with value: 3.896248051130534 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009977526128006962, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19470216476359659, 'dropout_rate_Layer_2': 0.22978210881507027, 'dropout_rate_Layer_3': 0.08926478503892535, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.071310270865328e-05, 'l1_Layer_2': 0.0007972478781755033, 'l1_Layer_3': 0.0011442715763464398, 'n_units_Layer_1': 185, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 53.29% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 47.84 | sMAPE for Test Set is: 81.84% | rMAE for Test Set is: 2.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:11:45,319]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:11:48,714]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:11:55,683]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:12:03,046]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:12:13,074]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:12:18,912]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:12:28,453]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:12:35,980]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:12:49,130]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:12:53,433]\u001b[0m Trial 658 finished with value: 5.827942526499872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015896492169864525, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1570796751096475, 'dropout_rate_Layer_2': 0.31954559394243875, 'dropout_rate_Layer_3': 0.26724355900792846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00706954726482962, 'l1_Layer_2': 0.011691838554972987, 'l1_Layer_3': 1.9901870633502068e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 170, 'n_units_Layer_3': 50}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 74.11% | rMAE for Validation Set is: 1.83\n",
      "MAE for Test Set is: 67.89 | sMAPE for Test Set is: 154.74% | rMAE for Test Set is: 3.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:13:01,603]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:13:06,319]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:13:13,348]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:13:24,293]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:13:36,303]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:13:56,196]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:14:06,542]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:14:36,075]\u001b[0m Trial 672 finished with value: 5.149209112138138 and parameters: {'n_hidden': 3, 'learning_rate': 0.001608967512909486, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00854913423582239, 'dropout_rate_Layer_2': 0.3134446164460756, 'dropout_rate_Layer_3': 0.2681904382320089, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008875004515718784, 'l1_Layer_2': 0.011360977514989828, 'l1_Layer_3': 1.5851968748601443e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 50}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 69.23% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 20.24 | sMAPE for Test Set is: 22.90% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:14:51,245]\u001b[0m Trial 674 finished with value: 5.713281454178836 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014106327441867107, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14545263410311085, 'dropout_rate_Layer_2': 0.3373970439608716, 'dropout_rate_Layer_3': 0.24963091416602395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005325749825585924, 'l1_Layer_2': 0.01175399679664897, 'l1_Layer_3': 1.0064176223097159e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 74.25% | rMAE for Validation Set is: 1.79\n",
      "MAE for Test Set is: 67.80 | sMAPE for Test Set is: 156.18% | rMAE for Test Set is: 3.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:14:58,017]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:05,451]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:12,146]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:25,231]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:25,667]\u001b[0m Trial 675 finished with value: 5.803378124336678 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015616291158936926, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14892115616210785, 'dropout_rate_Layer_2': 0.3294167355923492, 'dropout_rate_Layer_3': 0.2758624388726088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005937737292121774, 'l1_Layer_2': 0.010657473110593872, 'l1_Layer_3': 2.8329902542730737e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 74.88% | rMAE for Validation Set is: 1.82\n",
      "MAE for Test Set is: 68.17 | sMAPE for Test Set is: 156.71% | rMAE for Test Set is: 3.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:15:31,624]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:40,845]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:48,162]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:53,832]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:15:53,974]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:01,616]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:06,560]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:18,528]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:26,169]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:31,599]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:16:43,793]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 65.72% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 49.19 | sMAPE for Test Set is: 84.30% | rMAE for Test Set is: 2.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:17:11,674]\u001b[0m Trial 692 finished with value: 5.01836480015389 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009534162338849438, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2114027320220828, 'dropout_rate_Layer_2': 0.031343237132571415, 'dropout_rate_Layer_3': 0.11905833280149442, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001029656947049608, 'l1_Layer_2': 0.00042302014774886037, 'l1_Layer_3': 1.638864959113864e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 280, 'n_units_Layer_3': 115}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:18,585]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:19,111]\u001b[0m Trial 691 finished with value: 6.009949004578169 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018783296784891511, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14813244968205605, 'dropout_rate_Layer_2': 0.32686996063795953, 'dropout_rate_Layer_3': 0.2704203319038321, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003908377809730432, 'l1_Layer_2': 0.008386228759693052, 'l1_Layer_3': 1.806165866894071e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 55}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 77.62% | rMAE for Validation Set is: 1.89\n",
      "MAE for Test Set is: 70.33 | sMAPE for Test Set is: 167.34% | rMAE for Test Set is: 4.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:17:26,883]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:31,927]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:36,281]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:43,376]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:51,039]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:58,831]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:17:59,130]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:18:16,879]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:18:17,121]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:18:26,357]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:18:31,023]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:18:38,262]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:18:43,637]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:18:51,282]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:18:56,138]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:19:18,962]\u001b[0m Trial 706 finished with value: 6.585275704705173 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015839237011337382, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14738895978605818, 'dropout_rate_Layer_2': 0.3411229013679763, 'dropout_rate_Layer_3': 0.27417428882833267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008709587487928437, 'l1_Layer_2': 0.011822791955760604, 'l1_Layer_3': 1.3294892631909039e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 88.55% | rMAE for Validation Set is: 2.07\n",
      "MAE for Test Set is: 72.03 | sMAPE for Test Set is: 177.84% | rMAE for Test Set is: 4.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:19:34,097]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:20:00,942]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:20:21,503]\u001b[0m Trial 712 finished with value: 6.584863821872428 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015693264747425025, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1499386658067423, 'dropout_rate_Layer_2': 0.34165862081957055, 'dropout_rate_Layer_3': 0.2458694434183327, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007967238427032116, 'l1_Layer_2': 0.007661336191622455, 'l1_Layer_3': 1.7708824572221037e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 195, 'n_units_Layer_3': 50}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 88.91% | rMAE for Validation Set is: 2.07\n",
      "MAE for Test Set is: 71.91 | sMAPE for Test Set is: 177.41% | rMAE for Test Set is: 4.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:20:25,349]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:20:29,027]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:20:38,498]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:20:44,144]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:20:48,879]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:20:59,190]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:21,658]\u001b[0m Trial 715 finished with value: 5.932424478170046 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014326016456560418, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13855646453413922, 'dropout_rate_Layer_2': 0.3519488416024168, 'dropout_rate_Layer_3': 0.24378551554570735, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011510045105168157, 'l1_Layer_2': 0.005534201532763369, 'l1_Layer_3': 2.456185591684896e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 200, 'n_units_Layer_3': 50}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 76.35% | rMAE for Validation Set is: 1.86\n",
      "MAE for Test Set is: 69.36 | sMAPE for Test Set is: 162.27% | rMAE for Test Set is: 4.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:21:29,868]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:38,976]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:44,467]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:54,303]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:21:59,526]\u001b[0m Trial 720 finished with value: 6.0745612512037725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014943902011749044, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15159327211411674, 'dropout_rate_Layer_2': 0.3507046392633507, 'dropout_rate_Layer_3': 0.2475308745168754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011729409274964731, 'l1_Layer_2': 0.005510525432794728, 'l1_Layer_3': 2.4890567375248635e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 200, 'n_units_Layer_3': 50}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 78.09% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 68.34 | sMAPE for Test Set is: 158.08% | rMAE for Test Set is: 3.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:22:08,437]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:13,918]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:16,809]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:19,030]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:23,610]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:31,674]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:38,625]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:48,285]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:53,929]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:22:58,698]\u001b[0m Trial 730 finished with value: 4.283089432440484 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008861821708110586, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38400861694730276, 'dropout_rate_Layer_2': 0.025418584737630284, 'dropout_rate_Layer_3': 0.1291051304318234, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00012963859439252663, 'l1_Layer_2': 0.001601118047336604, 'l1_Layer_3': 2.236582682413685e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 300, 'n_units_Layer_3': 85}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 59.92% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 57.66 | sMAPE for Test Set is: 117.25% | rMAE for Test Set is: 3.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:23:16,359]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:23:23,002]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:23:33,049]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:23:43,874]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:23:48,855]\u001b[0m Trial 736 finished with value: 6.0574611935752785 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012806885873364589, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13732948199515438, 'dropout_rate_Layer_2': 0.3639086903011326, 'dropout_rate_Layer_3': 0.2668308975471458, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01111819798746632, 'l1_Layer_2': 0.003996745457556167, 'l1_Layer_3': 2.5600848478581508e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 79.30% | rMAE for Validation Set is: 1.90\n",
      "MAE for Test Set is: 69.97 | sMAPE for Test Set is: 166.76% | rMAE for Test Set is: 4.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:23:53,621]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:24:01,327]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:24:05,874]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:24:10,738]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:24:15,892]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:24:25,812]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:24:30,629]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:24:46,018]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:24:52,504]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:25:32,006]\u001b[0m Trial 746 finished with value: 6.462948163341568 and parameters: {'n_hidden': 3, 'learning_rate': 0.001260951042739129, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007558740048050169, 'dropout_rate_Layer_2': 0.35958829546643906, 'dropout_rate_Layer_3': 0.29181460860285513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013431422087154254, 'l1_Layer_2': 0.0036881621255025624, 'l1_Layer_3': 3.878209024214914e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 200, 'n_units_Layer_3': 65}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 86.45% | rMAE for Validation Set is: 2.03\n",
      "MAE for Test Set is: 71.75 | sMAPE for Test Set is: 176.33% | rMAE for Test Set is: 4.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:25:37,421]\u001b[0m Trial 750 finished with value: 5.698147894726269 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014287718890641469, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15122750565184814, 'dropout_rate_Layer_2': 0.3223916290904132, 'dropout_rate_Layer_3': 0.25400896180864535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012685184776005018, 'l1_Layer_2': 0.005620847019821615, 'l1_Layer_3': 3.5451443357169686e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 55}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 73.96% | rMAE for Validation Set is: 1.79\n",
      "MAE for Test Set is: 68.73 | sMAPE for Test Set is: 160.18% | rMAE for Test Set is: 3.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:26:07,880]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:26:27,161]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:26:37,493]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:26:44,463]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:26:51,426]\u001b[0m Trial 753 finished with value: 6.034522074112321 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014114721483230812, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17493272812825933, 'dropout_rate_Layer_2': 0.32682428415097103, 'dropout_rate_Layer_3': 0.2636155123442836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008749087213066133, 'l1_Layer_2': 0.004290698084904623, 'l1_Layer_3': 2.840494844404933e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 195, 'n_units_Layer_3': 50}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 77.87% | rMAE for Validation Set is: 1.89\n",
      "MAE for Test Set is: 69.79 | sMAPE for Test Set is: 164.78% | rMAE for Test Set is: 4.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:26:54,910]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:26:59,524]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:27:07,083]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:27:07,496]\u001b[0m Trial 756 finished with value: 5.748493857594031 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013466437655266497, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27054393256865933, 'dropout_rate_Layer_2': 0.22782248028410734, 'dropout_rate_Layer_3': 0.09284472382423772, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001483401183848823, 'l1_Layer_2': 0.0031116890676828332, 'l1_Layer_3': 0.0059870230590116655, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 65}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 73.69% | rMAE for Validation Set is: 1.80\n",
      "MAE for Test Set is: 66.44 | sMAPE for Test Set is: 148.14% | rMAE for Test Set is: 3.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:27:16,654]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:27:29,569]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:27:36,898]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:27:56,681]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:27:57,195]\u001b[0m Trial 761 finished with value: 5.534920975824915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011697179944241717, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1625720883752374, 'dropout_rate_Layer_2': 0.32206314673883807, 'dropout_rate_Layer_3': 0.2648600903249231, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00895563266919227, 'l1_Layer_2': 0.004471646091022111, 'l1_Layer_3': 2.625490927934081e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 195, 'n_units_Layer_3': 50}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 72.01% | rMAE for Validation Set is: 1.74\n",
      "MAE for Test Set is: 61.84 | sMAPE for Test Set is: 131.20% | rMAE for Test Set is: 3.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:28:04,243]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:28:09,575]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:28:11,934]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:28:16,589]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:28:36,848]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:28:57,217]\u001b[0m Trial 768 finished with value: 3.7046283889299705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011523724939718372, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1589377234835029, 'dropout_rate_Layer_2': 0.32746747736027054, 'dropout_rate_Layer_3': 0.25221931704814576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008472890531784311, 'l1_Layer_2': 0.004350525048486506, 'l1_Layer_3': 2.3040468733236425e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 55}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 57.03% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 52.02 | sMAPE for Test Set is: 98.64% | rMAE for Test Set is: 3.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:29:01,790]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:29:26,184]\u001b[0m Trial 771 finished with value: 4.867406692559672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011539840461281669, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16352418420574522, 'dropout_rate_Layer_2': 0.34917971092514904, 'dropout_rate_Layer_3': 0.22636948135193052, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00611215156024484, 'l1_Layer_2': 0.002735749829671402, 'l1_Layer_3': 2.152830003657763e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 195, 'n_units_Layer_3': 55}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 66.77% | rMAE for Validation Set is: 1.53\n",
      "MAE for Test Set is: 50.37 | sMAPE for Test Set is: 91.59% | rMAE for Test Set is: 2.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:29:43,691]\u001b[0m Trial 773 finished with value: 6.3811159941130695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011488950690142815, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18988795590712895, 'dropout_rate_Layer_2': 0.3251404029256698, 'dropout_rate_Layer_3': 0.2535951346410863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006568193168398788, 'l1_Layer_2': 0.003052996272908168, 'l1_Layer_3': 2.2461195320823426e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 195, 'n_units_Layer_3': 60}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 84.78% | rMAE for Validation Set is: 2.00\n",
      "MAE for Test Set is: 71.42 | sMAPE for Test Set is: 174.13% | rMAE for Test Set is: 4.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:29:46,361]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:29:46,820]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:29:51,856]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:29:58,586]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:30:00,985]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:30:04,181]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:30:11,057]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:30:13,153]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:30:16,330]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:31:03,456]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:31:06,111]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:31:11,475]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:31:16,168]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:31:20,749]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:31:28,574]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:31:28,824]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:31:36,550]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:31:41,666]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:31:46,538]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:31:53,679]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:03,365]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:07,975]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:08,073]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:14,175]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:14,271]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:24,210]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:24,312]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:29,986]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:34,957]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:39,556]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:40,347]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:45,119]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:50,327]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:53,055]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:55,580]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:32:59,947]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:33:19,523]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:33:37,427]\u001b[0m Trial 809 finished with value: 5.770324934694426 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015019802408491754, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15248915712619523, 'dropout_rate_Layer_2': 0.32774666982428075, 'dropout_rate_Layer_3': 0.24000480630257398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008404160507807679, 'l1_Layer_2': 0.003874768579003925, 'l1_Layer_3': 2.8972380849503443e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 55}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 74.42% | rMAE for Validation Set is: 1.81\n",
      "MAE for Test Set is: 67.52 | sMAPE for Test Set is: 154.02% | rMAE for Test Set is: 3.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:34:04,324]\u001b[0m Trial 812 finished with value: 4.803509756639087 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012306480054273998, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1480846421673938, 'dropout_rate_Layer_2': 0.30396901273743504, 'dropout_rate_Layer_3': 0.25924294576612633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00469975035688705, 'l1_Layer_2': 0.0030839967766105245, 'l1_Layer_3': 2.955799952338372e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 190, 'n_units_Layer_3': 55}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 66.06% | rMAE for Validation Set is: 1.51\n",
      "MAE for Test Set is: 57.22 | sMAPE for Test Set is: 115.09% | rMAE for Test Set is: 3.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:34:09,477]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:34:19,198]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:34:21,359]\u001b[0m Trial 813 finished with value: 5.818527594161675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014313228255957871, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15153453454874566, 'dropout_rate_Layer_2': 0.3053315704724478, 'dropout_rate_Layer_3': 0.2611125628265223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009355131476623011, 'l1_Layer_2': 0.003368220987412311, 'l1_Layer_3': 2.865097752037432e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 75.47% | rMAE for Validation Set is: 1.83\n",
      "MAE for Test Set is: 69.01 | sMAPE for Test Set is: 161.02% | rMAE for Test Set is: 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:34:29,307]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:34:36,226]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:34:41,258]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:34:41,354]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:34:53,697]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:34:58,902]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:35:06,005]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:35:15,775]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:35:21,081]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:35:26,193]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:35:33,346]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:35:41,347]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:35:45,505]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:35:51,155]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:35:55,381]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:36:01,203]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:36:03,067]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:36:10,936]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:36:15,529]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:36:20,585]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:36:25,420]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:36:32,661]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:36:38,024]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:36:52,404]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:37:07,649]\u001b[0m Trial 838 finished with value: 6.083284400025228 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012231916138586933, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1397547907121522, 'dropout_rate_Layer_2': 0.33456189122497976, 'dropout_rate_Layer_3': 0.26519299507461136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009518545379677102, 'l1_Layer_2': 0.004197114106540971, 'l1_Layer_3': 3.028699741704578e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 195, 'n_units_Layer_3': 60}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 79.64% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 70.93 | sMAPE for Test Set is: 170.80% | rMAE for Test Set is: 4.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:37:12,538]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:37:31,850]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:37:39,853]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:37:52,203]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:37:59,549]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:37:59,872]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:38:07,636]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:38:10,851]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:38:15,877]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:38:22,892]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:38:27,916]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:38:32,695]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:38:40,140]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:38:44,779]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:38:45,279]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:38:50,909]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:38:58,284]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:39:02,570]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:39:08,257]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:39:35,513]\u001b[0m Trial 857 finished with value: 4.485087868323897 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011019029386167875, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1406396910465975, 'dropout_rate_Layer_2': 0.32109268560676796, 'dropout_rate_Layer_3': 0.2629468727228499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008173173019695517, 'l1_Layer_2': 0.003038493510056181, 'l1_Layer_3': 5.16143706802852e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 190, 'n_units_Layer_3': 65}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 61.48% | rMAE for Validation Set is: 1.41\n",
      "MAE for Test Set is: 52.30 | sMAPE for Test Set is: 97.31% | rMAE for Test Set is: 3.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:39:41,987]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:39:50,115]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:39:54,470]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:39:57,679]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:39:57,790]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:40:05,489]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:40:08,138]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:40:14,698]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:40:18,181]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:40:23,184]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:40:32,582]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:40:42,436]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:40:52,330]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:40:59,146]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:02,088]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:16,994]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:22,058]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:27,166]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:34,609]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:37,312]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:42,139]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:44,823]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:47,254]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:51,344]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:56,031]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:41:56,489]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:42:08,842]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:42:17,034]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:42:19,641]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:42:36,500]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:42:44,015]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:42:51,712]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:43:03,033]\u001b[0m Trial 891 finished with value: 6.212572438240937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016069043029911358, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016376797627781676, 'dropout_rate_Layer_2': 0.33603042928215354, 'dropout_rate_Layer_3': 0.2713597598897266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006901899165321341, 'l1_Layer_2': 0.007676357898232246, 'l1_Layer_3': 3.40614587982264e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 190, 'n_units_Layer_3': 65}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 81.89% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 70.90 | sMAPE for Test Set is: 171.49% | rMAE for Test Set is: 4.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:43:11,041]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:43:18,693]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:43:25,789]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:43:31,131]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:43:38,982]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:43:41,318]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:43:58,205]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:44:05,768]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:44:08,978]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:44:13,300]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:44:15,505]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:44:35,325]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:44:40,924]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:44:47,741]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:44:54,688]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:45:04,583]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:45:05,059]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:45:10,354]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:45:14,960]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:45:56,428]\u001b[0m Trial 914 finished with value: 5.962429834437128 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013780432255711698, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16812180640970298, 'dropout_rate_Layer_2': 0.3470063055288107, 'dropout_rate_Layer_3': 0.22421249956742084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008291393621082362, 'l1_Layer_2': 0.014109961785572193, 'l1_Layer_3': 4.192813405773539e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 130, 'n_units_Layer_3': 60}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 76.03% | rMAE for Validation Set is: 1.87\n",
      "MAE for Test Set is: 68.71 | sMAPE for Test Set is: 159.07% | rMAE for Test Set is: 3.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:46:01,662]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:46:06,294]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:46:25,858]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:46:30,851]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:46:36,720]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:46:43,418]\u001b[0m Trial 913 finished with value: 4.448051525222669 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013851463086451466, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.000756965032037489, 'dropout_rate_Layer_2': 0.34703463473299845, 'dropout_rate_Layer_3': 0.22729407369980995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018079562901824345, 'l1_Layer_2': 0.013664209208244424, 'l1_Layer_3': 1.9040943539681205e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 64.29% | rMAE for Validation Set is: 1.40\n",
      "MAE for Test Set is: 18.34 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:46:51,115]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:46:55,955]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:47:03,915]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:47:04,356]\u001b[0m Trial 920 finished with value: 4.262401690630306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010882372794656335, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.122778979465235, 'dropout_rate_Layer_2': 0.15514345557263542, 'dropout_rate_Layer_3': 0.01798964460433007, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00023601053645341084, 'l1_Layer_2': 0.0011250683576472802, 'l1_Layer_3': 2.057072953350446e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 240, 'n_units_Layer_3': 95}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 58.90% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 42.81 | sMAPE for Test Set is: 68.73% | rMAE for Test Set is: 2.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:47:12,087]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:47:16,627]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:47:22,126]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:47:26,579]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:47:32,610]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:48:09,360]\u001b[0m Trial 929 finished with value: 6.149059343840528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012057008913211916, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01566862821146154, 'dropout_rate_Layer_2': 0.34045940613716547, 'dropout_rate_Layer_3': 0.22482496273511848, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.022457501436452185, 'l1_Layer_2': 0.013300601856474607, 'l1_Layer_3': 3.522865448249998e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 125, 'n_units_Layer_3': 65}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 80.51% | rMAE for Validation Set is: 1.93\n",
      "MAE for Test Set is: 70.40 | sMAPE for Test Set is: 168.60% | rMAE for Test Set is: 4.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:48:13,818]\u001b[0m Trial 930 finished with value: 6.507468464954539 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013406806699764763, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0007086095699937543, 'dropout_rate_Layer_2': 0.3566803027879739, 'dropout_rate_Layer_3': 0.2233910722515829, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.021021016715426548, 'l1_Layer_2': 0.011940301663407316, 'l1_Layer_3': 5.926421078469865e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 130, 'n_units_Layer_3': 75}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 87.24% | rMAE for Validation Set is: 2.04\n",
      "MAE for Test Set is: 71.69 | sMAPE for Test Set is: 175.96% | rMAE for Test Set is: 4.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:48:19,217]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:48:26,527]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:48:33,797]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:48:33,881]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:48:41,969]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:48:46,180]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:48:48,792]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:48:58,550]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:48:58,825]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:49:09,363]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:49:14,491]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:49:18,950]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:49:26,084]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:49:34,360]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:49:36,565]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:49:41,409]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:49:46,476]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:49:48,995]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:50:06,363]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:50:08,846]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:50:16,074]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:50:21,011]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:50:35,998]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:50:53,154]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:51:02,340]\u001b[0m Trial 955 finished with value: 4.966767284347707 and parameters: {'n_hidden': 3, 'learning_rate': 0.000875925485377652, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3107155747338249, 'dropout_rate_Layer_2': 0.19876676290090375, 'dropout_rate_Layer_3': 0.0001780217994004421, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001327443615380876, 'l1_Layer_2': 0.0003529659061968902, 'l1_Layer_3': 0.0029823571823033293, 'n_units_Layer_1': 185, 'n_units_Layer_2': 295, 'n_units_Layer_3': 90}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 65.94% | rMAE for Validation Set is: 1.56\n",
      "MAE for Test Set is: 49.48 | sMAPE for Test Set is: 88.00% | rMAE for Test Set is: 2.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:51:12,043]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:51:15,337]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:51:22,553]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:51:22,718]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:51:31,274]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:51:35,792]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:51:40,883]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:51:48,347]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:52:00,918]\u001b[0m Trial 963 finished with value: 5.052767247199569 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009891730145006822, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27692890252353286, 'dropout_rate_Layer_2': 0.1778197526904539, 'dropout_rate_Layer_3': 0.025908926500525495, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010136406166078579, 'l1_Layer_2': 0.0003007481567275337, 'l1_Layer_3': 0.002310062570417989, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 95}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 67.43% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 51.46 | sMAPE for Test Set is: 92.97% | rMAE for Test Set is: 2.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:52:08,485]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:52:08,736]\u001b[0m Trial 965 finished with value: 5.819731626608022 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011113452405635649, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0706118741506532, 'dropout_rate_Layer_2': 0.1755105710854132, 'dropout_rate_Layer_3': 0.023863291000428014, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010430159124220646, 'l1_Layer_2': 0.00038409969967880475, 'l1_Layer_3': 0.0042312110016596415, 'n_units_Layer_1': 190, 'n_units_Layer_2': 295, 'n_units_Layer_3': 95}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 74.98% | rMAE for Validation Set is: 1.83\n",
      "MAE for Test Set is: 67.83 | sMAPE for Test Set is: 155.18% | rMAE for Test Set is: 3.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:52:16,519]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:52:19,524]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:52:26,168]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:52:29,001]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:52:34,227]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:52:38,626]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:52:43,842]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:52:48,938]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:53:00,928]\u001b[0m Trial 972 finished with value: 3.641426455307139 and parameters: {'n_hidden': 3, 'learning_rate': 0.000660052968916742, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2890212427945197, 'dropout_rate_Layer_2': 0.20541640861537303, 'dropout_rate_Layer_3': 0.008472898546474948, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.4086545322215794e-05, 'l1_Layer_2': 0.00044111588806821305, 'l1_Layer_3': 0.000672134267977533, 'n_units_Layer_1': 200, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 48.70% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 39.84 | sMAPE for Test Set is: 61.94% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:53:03,868]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:53:05,823]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:53:11,384]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:53:13,783]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:53:18,253]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:53:23,176]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:53:28,156]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:53:35,866]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:53:55,082]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:01,938]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:07,052]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:12,600]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:13,022]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:18,622]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:21,428]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:26,335]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:31,261]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:35,661]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:41,022]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:41,289]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:48,566]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:48,657]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:54:58,032]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:55:03,069]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:55:16,245]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:55:21,475]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:55:27,984]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:55:35,988]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:55:42,880]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:55:57,963]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:56:05,875]\u001b[0m Trial 1005 finished with value: 4.892552429527292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005015295035844089, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33828997400600463, 'dropout_rate_Layer_2': 0.19456575681973537, 'dropout_rate_Layer_3': 0.3893505778391272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.066603635824919e-05, 'l1_Layer_2': 0.009366922978209033, 'l1_Layer_3': 3.691863008029457e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 200, 'n_units_Layer_3': 275}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 68.00% | rMAE for Validation Set is: 1.54\n",
      "MAE for Test Set is: 19.51 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:56:13,037]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:56:23,021]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:56:38,074]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:56:44,844]\u001b[0m Trial 1007 finished with value: 5.9637494558776645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014296456522630758, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.151639697227352, 'dropout_rate_Layer_2': 0.28005137791625856, 'dropout_rate_Layer_3': 0.3105784592616632, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007056535607908158, 'l1_Layer_2': 0.01250746872108837, 'l1_Layer_3': 2.6280627001775812e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 55}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 76.96% | rMAE for Validation Set is: 1.87\n",
      "MAE for Test Set is: 70.03 | sMAPE for Test Set is: 166.07% | rMAE for Test Set is: 4.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:56:45,101]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:56:55,991]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:57:03,437]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:57:30,765]\u001b[0m Trial 1015 finished with value: 6.886348840918051 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005025109789286097, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24949897783630526, 'dropout_rate_Layer_2': 0.20505333692039263, 'dropout_rate_Layer_3': 0.37457938897219156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.509578805617708e-05, 'l1_Layer_2': 0.01888490677421318, 'l1_Layer_3': 2.8706317916465132e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 200, 'n_units_Layer_3': 275}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 79.20% | rMAE for Validation Set is: 2.16\n",
      "MAE for Test Set is: 20.81 | sMAPE for Test Set is: 24.02% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:57:35,163]\u001b[0m Trial 1013 finished with value: 3.637554262678382 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013194747039969388, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12184350241189484, 'dropout_rate_Layer_2': 0.33425576131687773, 'dropout_rate_Layer_3': 0.2626768329159507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035032008750171843, 'l1_Layer_2': 0.03017677455624986, 'l1_Layer_3': 4.793627582706495e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 140, 'n_units_Layer_3': 65}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 51.57% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 36.59 | sMAPE for Test Set is: 55.76% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:57:42,463]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:57:49,967]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:58:05,354]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:58:10,495]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:58:12,472]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:58:27,636]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:58:32,025]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:58:51,841]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:58:57,900]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:58:58,247]\u001b[0m Trial 1023 finished with value: 5.108661203305812 and parameters: {'n_hidden': 3, 'learning_rate': 0.001146781370987793, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3106454649542353, 'dropout_rate_Layer_2': 0.2201025768177434, 'dropout_rate_Layer_3': 0.08922838871844369, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.3820854827900464e-05, 'l1_Layer_2': 0.00025564233188960807, 'l1_Layer_3': 4.505546707650969e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 280, 'n_units_Layer_3': 80}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 66.47% | rMAE for Validation Set is: 1.60\n",
      "MAE for Test Set is: 39.17 | sMAPE for Test Set is: 58.30% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:59:07,215]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:59:17,425]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:59:28,089]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:59:35,079]\u001b[0m Trial 1026 finished with value: 6.469116333148605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005038889012736808, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.238469021930289, 'dropout_rate_Layer_2': 0.19783335316728007, 'dropout_rate_Layer_3': 0.37995946394300717, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.431610457879527e-05, 'l1_Layer_2': 0.0098558788782839, 'l1_Layer_3': 2.7310629905053252e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 195, 'n_units_Layer_3': 270}. Best is trial 2 with value: 2.060841098259806.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 77.13% | rMAE for Validation Set is: 2.03\n",
      "MAE for Test Set is: 20.60 | sMAPE for Test Set is: 23.53% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 13:59:50,140]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 13:59:55,619]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:00:05,294]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:00:15,004]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:00:22,380]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:00:30,151]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:00:37,158]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:01:06,884]\u001b[0m Trial 1038 finished with value: 1.9211960766859484 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005029254076119707, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2414460890123552, 'dropout_rate_Layer_2': 0.21981591045113977, 'dropout_rate_Layer_3': 0.3718839007068746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5816595556599803e-05, 'l1_Layer_2': 0.015265275511243053, 'l1_Layer_3': 2.8368996648238568e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 210, 'n_units_Layer_3': 270}. Best is trial 1038 with value: 1.9211960766859484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 31.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.40 | sMAPE for Test Set is: 27.03% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:01:12,052]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:01:17,330]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:01:26,130]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:01:41,190]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:01:58,709]\u001b[0m Trial 1031 finished with value: 2.9596881855784907 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012784730713176675, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08990049316391457, 'dropout_rate_Layer_2': 0.04794516125526935, 'dropout_rate_Layer_3': 0.2678961001831369, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003553479012743998, 'l1_Layer_2': 0.0447380064846687, 'l1_Layer_3': 2.1240946434828935e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 190, 'n_units_Layer_3': 50}. Best is trial 1038 with value: 1.9211960766859484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.96 | sMAPE for Validation Set is: 50.51% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 15.37 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:02:06,670]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:02:07,224]\u001b[0m Trial 1043 finished with value: 4.569258110608175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008955430965884064, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3393212940053013, 'dropout_rate_Layer_2': 0.20590374176397172, 'dropout_rate_Layer_3': 0.003707562612537376, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.796554184039679e-05, 'l1_Layer_2': 0.0008571738808576177, 'l1_Layer_3': 8.10983109587934e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 185, 'n_units_Layer_3': 115}. Best is trial 1038 with value: 1.9211960766859484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 59.38% | rMAE for Validation Set is: 1.43\n",
      "MAE for Test Set is: 54.55 | sMAPE for Test Set is: 102.71% | rMAE for Test Set is: 3.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:02:17,201]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:02:27,236]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:02:30,036]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:02:39,492]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:02:39,710]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:03:03,082]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:03:03,196]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:03:11,771]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:03:28,679]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:03:34,326]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:03:41,005]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:03:46,469]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:04:05,849]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:04:23,444]\u001b[0m Trial 1052 finished with value: 6.163283224881746 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013806128750245734, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13104109669819733, 'dropout_rate_Layer_2': 0.33952875737183896, 'dropout_rate_Layer_3': 0.2621196561068719, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008687409790331567, 'l1_Layer_2': 0.019736690469425586, 'l1_Layer_3': 2.877358479111981e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 1038 with value: 1.9211960766859484.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 80.41% | rMAE for Validation Set is: 1.93\n",
      "MAE for Test Set is: 71.72 | sMAPE for Test Set is: 174.91% | rMAE for Test Set is: 4.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:04:25,952]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:04:34,985]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:04:37,670]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:04:42,773]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:04:45,867]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:04:50,605]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:04:55,830]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:05:05,573]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:05:10,446]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:05:15,654]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:05:20,598]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:05:25,507]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:05:30,530]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:05:37,135]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:05:42,347]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:05:47,826]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:05:54,805]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:06:02,062]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:06:21,868]\u001b[0m Trial 1070 finished with value: 1.4787929722345403 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005717461800763021, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25566869036837864, 'dropout_rate_Layer_2': 0.17857200321197772, 'dropout_rate_Layer_3': 0.3849202596350474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.768753350348669e-05, 'l1_Layer_2': 0.011301820265848915, 'l1_Layer_3': 2.2822056008145712e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 190, 'n_units_Layer_3': 280}. Best is trial 1070 with value: 1.4787929722345403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 31.84% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 10.64 | sMAPE for Test Set is: 13.41% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:06:27,646]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:06:35,229]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:06:49,914]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:06:54,881]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:07:09,648]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:07:14,725]\u001b[0m Trial 1082 finished with value: 4.362609300887974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008440723327728981, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2538403920879753, 'dropout_rate_Layer_2': 0.21688802978267488, 'dropout_rate_Layer_3': 0.0006430159584244789, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.7793880151746226e-05, 'l1_Layer_2': 0.0011285989845520499, 'l1_Layer_3': 1.588135998043763e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 105}. Best is trial 1070 with value: 1.4787929722345403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 53.35% | rMAE for Validation Set is: 1.37\n",
      "MAE for Test Set is: 56.44 | sMAPE for Test Set is: 109.02% | rMAE for Test Set is: 3.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:07:26,331]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:07:31,947]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:07:41,828]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:07:49,402]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:07:49,450]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:07:58,309]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:08:04,891]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:08:05,151]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:08:15,519]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:08:17,940]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:08:27,200]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:08:29,901]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:08:37,624]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:08:43,145]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:08:48,029]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:08:54,569]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:09:00,191]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:09:04,987]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:09:29,871]\u001b[0m Trial 1098 finished with value: 1.5506863455359194 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005493674034648436, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2492673846595698, 'dropout_rate_Layer_2': 0.20403180275404553, 'dropout_rate_Layer_3': 0.38231795782044675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.288220082099961e-05, 'l1_Layer_2': 0.009529611153953918, 'l1_Layer_3': 1.226085006211254e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 280}. Best is trial 1070 with value: 1.4787929722345403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 28.62% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.19 | sMAPE for Test Set is: 16.20% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:09:34,842]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:09:41,944]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:09:49,382]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:10:33,854]\u001b[0m Trial 1106 finished with value: 1.5309023880758283 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006128537722156716, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22423122620170446, 'dropout_rate_Layer_2': 0.19727834828004512, 'dropout_rate_Layer_3': 0.3785677648846217, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.474802265069945e-05, 'l1_Layer_2': 0.009458651735429075, 'l1_Layer_3': 1.398914876882006e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 180, 'n_units_Layer_3': 280}. Best is trial 1070 with value: 1.4787929722345403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 33.44% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 13.92% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:10:44,257]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:11:07,578]\u001b[0m Trial 1107 finished with value: 1.400188344552172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005006341952975789, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2581888069780262, 'dropout_rate_Layer_2': 0.22157109141916503, 'dropout_rate_Layer_3': 0.3662449852638507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8253850553702487e-05, 'l1_Layer_2': 0.00873950989791844, 'l1_Layer_3': 1.2870680897504246e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 1107 with value: 1.400188344552172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 27.97% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.36 | sMAPE for Test Set is: 12.93% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:11:16,984]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:11:26,205]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:11:28,979]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:11:43,609]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:11:51,721]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:12:01,359]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:12:08,873]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:12:13,851]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:12:18,963]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:12:53,103]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:12:53,637]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:13:13,876]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:13:34,052]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:14:09,302]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:14:26,454]\u001b[0m Trial 1122 finished with value: 1.4047519171394984 and parameters: {'n_hidden': 3, 'learning_rate': 0.000505286867581793, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21660451210451775, 'dropout_rate_Layer_2': 0.22382114354549745, 'dropout_rate_Layer_3': 0.3630660054494997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013138733883437677, 'l1_Layer_2': 0.008164950646591462, 'l1_Layer_3': 1.2417007249232478e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 175, 'n_units_Layer_3': 260}. Best is trial 1107 with value: 1.400188344552172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 27.88% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 11.90 | sMAPE for Test Set is: 15.74% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:14:33,685]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:14:50,387]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:15:06,058]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:15:20,948]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:15:25,631]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:15:33,091]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:16:05,283]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:16:12,427]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:16:32,668]\u001b[0m Trial 1131 finished with value: 1.5568390395497502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005022849420347001, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21380569657886078, 'dropout_rate_Layer_2': 0.22357324493316796, 'dropout_rate_Layer_3': 0.3617435441030912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001623502985953073, 'l1_Layer_2': 0.008303724735296968, 'l1_Layer_3': 1.2601427038403142e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 175, 'n_units_Layer_3': 260}. Best is trial 1107 with value: 1.400188344552172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 36.98% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 10.48 | sMAPE for Test Set is: 13.27% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:16:42,631]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:17:10,124]\u001b[0m Trial 1135 finished with value: 4.279303268504536 and parameters: {'n_hidden': 3, 'learning_rate': 0.00109454295663239, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24193301849643348, 'dropout_rate_Layer_2': 0.18729381242131346, 'dropout_rate_Layer_3': 0.025404115504453945, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.78402211563631e-05, 'l1_Layer_2': 0.0008350798425463241, 'l1_Layer_3': 1.9669775561856938e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 175, 'n_units_Layer_3': 65}. Best is trial 1107 with value: 1.400188344552172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 59.05% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 38.31 | sMAPE for Test Set is: 58.83% | rMAE for Test Set is: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:17:27,263]\u001b[0m Trial 1133 finished with value: 1.4511410232071622 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005003389934022037, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1988089281987494, 'dropout_rate_Layer_2': 0.22847215044849556, 'dropout_rate_Layer_3': 0.36252207704114986, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001662255390540741, 'l1_Layer_2': 0.008453005743133372, 'l1_Layer_3': 1.0135052953736236e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 175, 'n_units_Layer_3': 260}. Best is trial 1107 with value: 1.400188344552172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 25.80% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 10.27 | sMAPE for Test Set is: 12.79% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:17:36,691]\u001b[0m Trial 1136 finished with value: 4.998379916567544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010935648923108602, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24199401752567787, 'dropout_rate_Layer_2': 0.18986177600423246, 'dropout_rate_Layer_3': 0.022311848851610708, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.848070939324943e-05, 'l1_Layer_2': 0.00080797619202915, 'l1_Layer_3': 2.5491248515179715e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 1107 with value: 1.400188344552172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 66.47% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 60.70 | sMAPE for Test Set is: 129.90% | rMAE for Test Set is: 3.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:17:52,128]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:18:09,178]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:18:12,047]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:18:19,490]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:18:24,835]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:18:56,786]\u001b[0m Trial 1141 finished with value: 5.8459189734241965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014402020340982488, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016708809844692845, 'dropout_rate_Layer_2': 0.3014781790641251, 'dropout_rate_Layer_3': 0.2522012154297606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00989350615196367, 'l1_Layer_2': 0.013165340963194432, 'l1_Layer_3': 2.304998614136268e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 190, 'n_units_Layer_3': 50}. Best is trial 1107 with value: 1.400188344552172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 76.07% | rMAE for Validation Set is: 1.83\n",
      "MAE for Test Set is: 68.95 | sMAPE for Test Set is: 161.51% | rMAE for Test Set is: 3.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:19:01,984]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:19:13,843]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:19:21,070]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:19:39,118]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:19:39,214]\u001b[0m Trial 1143 finished with value: 1.4321918835716811 and parameters: {'n_hidden': 3, 'learning_rate': 0.000504323031049022, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19061324172038696, 'dropout_rate_Layer_2': 0.21618393222351096, 'dropout_rate_Layer_3': 0.3653425555522807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001110634259713684, 'l1_Layer_2': 0.007802126191774545, 'l1_Layer_3': 1.2049090858683015e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 1107 with value: 1.400188344552172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 31.57% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.25 | sMAPE for Test Set is: 12.87% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:20:18,184]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:20:45,130]\u001b[0m Trial 1148 finished with value: 1.424014553958991 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005560845802341661, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2006107854149718, 'dropout_rate_Layer_2': 0.23414316127595222, 'dropout_rate_Layer_3': 0.37321838249783734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013340653665514437, 'l1_Layer_2': 0.006055549690244295, 'l1_Layer_3': 1.4127385694769261e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 1107 with value: 1.400188344552172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 25.59% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.56 | sMAPE for Test Set is: 15.10% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:20:50,340]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:21:07,269]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:21:17,196]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:21:20,608]\u001b[0m Trial 1150 finished with value: 1.442153802706878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005026346689339209, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1929625828796389, 'dropout_rate_Layer_2': 0.22861136910609375, 'dropout_rate_Layer_3': 0.36940285239422543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000190836658795963, 'l1_Layer_2': 0.009264289017718027, 'l1_Layer_3': 1.0077991163205921e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 1107 with value: 1.400188344552172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 27.59% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 14.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:21:27,553]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:21:32,124]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:21:49,628]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:22:08,959]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:22:31,107]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:22:41,443]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:23:18,646]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:23:40,425]\u001b[0m Trial 1159 finished with value: 1.3220854133640796 and parameters: {'n_hidden': 3, 'learning_rate': 0.000555192962417466, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18524782100142342, 'dropout_rate_Layer_2': 0.2244560365795725, 'dropout_rate_Layer_3': 0.3594507335690693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010611262115323378, 'l1_Layer_2': 0.009687367899381925, 'l1_Layer_3': 1.5464735384595324e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 270}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.32 | sMAPE for Validation Set is: 23.08% | rMAE for Validation Set is: 0.41\n",
      "MAE for Test Set is: 10.16 | sMAPE for Test Set is: 12.75% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:23:45,598]\u001b[0m Trial 1162 finished with value: 4.53401382478139 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009990560270983994, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25464413743630676, 'dropout_rate_Layer_2': 0.20432861219920037, 'dropout_rate_Layer_3': 0.029825694574471703, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.3755284141927593e-05, 'l1_Layer_2': 0.0005069514287128398, 'l1_Layer_3': 1.9568278005951355e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 65}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 61.62% | rMAE for Validation Set is: 1.42\n",
      "MAE for Test Set is: 43.14 | sMAPE for Test Set is: 68.84% | rMAE for Test Set is: 2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:23:50,956]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:24:00,558]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:24:10,247]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:24:10,750]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:24:20,959]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:24:30,879]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:24:35,334]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:24:50,145]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:24:52,580]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:25:00,143]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:25:10,296]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:25:19,432]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:25:26,706]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:25:34,611]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:25:41,563]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:25:46,681]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:25:47,101]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:26:11,329]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:26:16,133]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:26:30,302]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:26:35,175]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:26:47,864]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:26:52,978]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:26:57,818]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:27:02,763]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:27:25,265]\u001b[0m Trial 1189 finished with value: 4.4294091839579215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014092247901620527, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24462009263745885, 'dropout_rate_Layer_2': 0.19022628514599385, 'dropout_rate_Layer_3': 0.022974199517000662, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.4322886913611443e-05, 'l1_Layer_2': 0.000672114859045636, 'l1_Layer_3': 0.0010171635036747807, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 65}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 63.70% | rMAE for Validation Set is: 1.39\n",
      "MAE for Test Set is: 38.85 | sMAPE for Test Set is: 57.43% | rMAE for Test Set is: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:27:50,338]\u001b[0m Trial 1190 finished with value: 4.2205956462501595 and parameters: {'n_hidden': 3, 'learning_rate': 0.001401328620356394, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2546934342526772, 'dropout_rate_Layer_2': 0.18429933871674098, 'dropout_rate_Layer_3': 0.027009732330243397, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.370155644606331e-05, 'l1_Layer_2': 0.0006612102169120725, 'l1_Layer_3': 0.001038325431120851, 'n_units_Layer_1': 240, 'n_units_Layer_2': 160, 'n_units_Layer_3': 60}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 71.21% | rMAE for Validation Set is: 1.32\n",
      "MAE for Test Set is: 36.30 | sMAPE for Test Set is: 51.62% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:27:56,805]\u001b[0m Trial 1188 finished with value: 1.4185782912772014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005463873223707595, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17829403799008658, 'dropout_rate_Layer_2': 0.20694855817592273, 'dropout_rate_Layer_3': 0.35704088856727606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002248151348960978, 'l1_Layer_2': 0.011192203781424447, 'l1_Layer_3': 1.1753636996224188e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 255}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 24.19% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.45 | sMAPE for Test Set is: 14.85% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:28:02,151]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 61.39% | rMAE for Validation Set is: 1.42\n",
      "MAE for Test Set is: 50.26 | sMAPE for Test Set is: 88.88% | rMAE for Test Set is: 2.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:28:23,490]\u001b[0m Trial 1193 finished with value: 4.520937372115661 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015572807369144577, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2566448674666504, 'dropout_rate_Layer_2': 0.18806970294227318, 'dropout_rate_Layer_3': 0.02631152088078649, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.3997944425447122e-05, 'l1_Layer_2': 0.0006714259579774039, 'l1_Layer_3': 0.0010238562094167917, 'n_units_Layer_1': 245, 'n_units_Layer_2': 165, 'n_units_Layer_3': 60}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:28:29,021]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:28:49,114]\u001b[0m Trial 1192 finished with value: 1.555185025478562 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006031740296703498, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1979368843262431, 'dropout_rate_Layer_2': 0.21527098306749862, 'dropout_rate_Layer_3': 0.3807780858231385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021436008268888328, 'l1_Layer_2': 0.005709925796416624, 'l1_Layer_3': 1.1553010347188771e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 175, 'n_units_Layer_3': 255}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 34.52% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 10.50 | sMAPE for Test Set is: 13.24% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:28:58,650]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:29:06,612]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:29:13,040]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:29:18,739]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:29:31,095]\u001b[0m Trial 1197 finished with value: 3.9294750603225452 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013305919049938662, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2555072851088765, 'dropout_rate_Layer_2': 0.18601242762057366, 'dropout_rate_Layer_3': 0.03733183800180932, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.358507335188558e-05, 'l1_Layer_2': 0.0006599707772414437, 'l1_Layer_3': 0.0011197601245799304, 'n_units_Layer_1': 245, 'n_units_Layer_2': 155, 'n_units_Layer_3': 60}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 55.55% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 35.99 | sMAPE for Test Set is: 52.22% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:29:33,735]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:29:48,385]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:29:53,235]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:29:57,156]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:30:02,881]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:30:10,229]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:30:19,613]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:30:29,701]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:31:17,021]\u001b[0m Trial 1207 finished with value: 1.417625250234342 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006111743917763344, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17008341446644387, 'dropout_rate_Layer_2': 0.19959204808811135, 'dropout_rate_Layer_3': 0.3716230022801823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023730404951487295, 'l1_Layer_2': 0.013825385514137768, 'l1_Layer_3': 1.6171039759112606e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 23.53% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 11.33 | sMAPE for Test Set is: 14.60% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:31:26,858]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:31:34,448]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:32:11,904]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:32:50,505]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:33:07,710]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:33:20,704]\u001b[0m Trial 1209 finished with value: 1.7384104353338898 and parameters: {'n_hidden': 3, 'learning_rate': 0.001323759686185721, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16484116122831455, 'dropout_rate_Layer_2': 0.3230170930606132, 'dropout_rate_Layer_3': 0.24733760101666777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00978991784778808, 'l1_Layer_2': 0.00803485362331291, 'l1_Layer_3': 0.000764731394365075, 'n_units_Layer_1': 260, 'n_units_Layer_2': 205, 'n_units_Layer_3': 50}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.74 | sMAPE for Validation Set is: 45.16% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.19 | sMAPE for Test Set is: 17.10% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:33:28,191]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:33:37,697]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:33:44,434]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:33:54,674]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:34:02,131]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:34:02,335]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:34:21,747]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:34:27,300]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:34:49,777]\u001b[0m Trial 1224 finished with value: 4.663756255702968 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014739941568148414, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2529436219481938, 'dropout_rate_Layer_2': 0.18413185197345014, 'dropout_rate_Layer_3': 0.024871404510145106, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.392594317233687e-05, 'l1_Layer_2': 0.00044039667629134044, 'l1_Layer_3': 0.0009779512723583578, 'n_units_Layer_1': 235, 'n_units_Layer_2': 165, 'n_units_Layer_3': 50}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 62.58% | rMAE for Validation Set is: 1.46\n",
      "MAE for Test Set is: 55.04 | sMAPE for Test Set is: 102.53% | rMAE for Test Set is: 3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:35:14,047]\u001b[0m Trial 1225 finished with value: 4.380618644790065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013139040377488358, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2600515240334676, 'dropout_rate_Layer_2': 0.1916943083605771, 'dropout_rate_Layer_3': 0.03306231738683365, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.4955132091580516e-05, 'l1_Layer_2': 0.0005125502359729258, 'l1_Layer_3': 0.0012084987373173108, 'n_units_Layer_1': 240, 'n_units_Layer_2': 140, 'n_units_Layer_3': 65}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 55.63% | rMAE for Validation Set is: 1.37\n",
      "MAE for Test Set is: 45.86 | sMAPE for Test Set is: 75.23% | rMAE for Test Set is: 2.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:35:18,889]\u001b[0m Trial 1221 finished with value: 6.3030345259193155 and parameters: {'n_hidden': 3, 'learning_rate': 0.000882025015299349, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17040232189125437, 'dropout_rate_Layer_2': 0.3019012838571199, 'dropout_rate_Layer_3': 0.26896401273681436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006494770836251622, 'l1_Layer_2': 0.09550398048798417, 'l1_Layer_3': 0.000408982357220324, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 55}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 82.91% | rMAE for Validation Set is: 1.98\n",
      "MAE for Test Set is: 71.20 | sMAPE for Test Set is: 173.64% | rMAE for Test Set is: 4.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:35:23,870]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:35:31,384]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:36:08,105]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:36:11,304]\u001b[0m Trial 1228 finished with value: 1.4620879417982648 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005568470779460396, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20514254278912794, 'dropout_rate_Layer_2': 0.23140072631793313, 'dropout_rate_Layer_3': 0.38165414617478527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011214771692605675, 'l1_Layer_2': 0.009839936773465396, 'l1_Layer_3': 1.7290081423077403e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 170, 'n_units_Layer_3': 255}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 28.20% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 10.55 | sMAPE for Test Set is: 13.18% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:36:23,478]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:36:26,223]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:36:46,194]\u001b[0m Trial 1232 finished with value: 4.578181971822111 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014150588533354245, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24505410629001792, 'dropout_rate_Layer_2': 0.1613597773463825, 'dropout_rate_Layer_3': 0.02126024205635941, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.0127758689587146e-05, 'l1_Layer_2': 0.0009905244106464188, 'l1_Layer_3': 0.0006822576912566958, 'n_units_Layer_1': 240, 'n_units_Layer_2': 135, 'n_units_Layer_3': 60}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 57.94% | rMAE for Validation Set is: 1.44\n",
      "MAE for Test Set is: 54.77 | sMAPE for Test Set is: 103.48% | rMAE for Test Set is: 3.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:37:01,197]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:37:12,995]\u001b[0m Trial 1234 finished with value: 3.6600075204204163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012522558094537999, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2760577727731988, 'dropout_rate_Layer_2': 0.1893586885108766, 'dropout_rate_Layer_3': 0.035839414414990195, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.7851663615084786e-05, 'l1_Layer_2': 0.000714232757510037, 'l1_Layer_3': 0.0016035051213061794, 'n_units_Layer_1': 260, 'n_units_Layer_2': 145, 'n_units_Layer_3': 55}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 56.98% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 39.57 | sMAPE for Test Set is: 59.33% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:37:22,244]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:37:29,784]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:37:45,197]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:37:59,827]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:38:09,785]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:38:16,657]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:38:22,353]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:38:34,559]\u001b[0m Trial 1240 finished with value: 4.5672750588951265 and parameters: {'n_hidden': 3, 'learning_rate': 0.001245081184470772, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28454218297219736, 'dropout_rate_Layer_2': 0.15417611174086515, 'dropout_rate_Layer_3': 0.035406321667877605, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.159037686796313e-05, 'l1_Layer_2': 0.0007793702761153103, 'l1_Layer_3': 0.0016406665335113287, 'n_units_Layer_1': 260, 'n_units_Layer_2': 145, 'n_units_Layer_3': 50}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 62.42% | rMAE for Validation Set is: 1.43\n",
      "MAE for Test Set is: 44.72 | sMAPE for Test Set is: 72.36% | rMAE for Test Set is: 2.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:38:51,946]\u001b[0m Trial 1243 finished with value: 4.617813668674274 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012806598595119542, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2806526029617259, 'dropout_rate_Layer_2': 0.17773217543777473, 'dropout_rate_Layer_3': 0.03644422518589628, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.302579723303529e-05, 'l1_Layer_2': 0.0008054068680696209, 'l1_Layer_3': 0.0014912227428736445, 'n_units_Layer_1': 260, 'n_units_Layer_2': 140, 'n_units_Layer_3': 50}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:38:52,096]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 61.26% | rMAE for Validation Set is: 1.45\n",
      "MAE for Test Set is: 42.14 | sMAPE for Test Set is: 65.39% | rMAE for Test Set is: 2.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:39:04,010]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:39:09,471]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:39:26,537]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:39:31,523]\u001b[0m Trial 1247 finished with value: 4.48553246787885 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014132502295745985, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2598476618707391, 'dropout_rate_Layer_2': 0.18662500237052618, 'dropout_rate_Layer_3': 0.027372171573964946, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.002044392695078864, 'l1_Layer_2': 0.0006643976467162113, 'l1_Layer_3': 0.0009682909677842564, 'n_units_Layer_1': 240, 'n_units_Layer_2': 155, 'n_units_Layer_3': 60}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 61.27% | rMAE for Validation Set is: 1.41\n",
      "MAE for Test Set is: 46.08 | sMAPE for Test Set is: 78.23% | rMAE for Test Set is: 2.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:39:36,832]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:39:41,192]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:39:46,278]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:39:51,159]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:40:07,826]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:40:13,462]\u001b[0m Trial 1253 finished with value: 4.052933304151563 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013346983242414313, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2657886965154501, 'dropout_rate_Layer_2': 0.19394558231378145, 'dropout_rate_Layer_3': 0.016959177061293337, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0026579939045198045, 'l1_Layer_2': 0.0009297430557866651, 'l1_Layer_3': 0.0008792003121793123, 'n_units_Layer_1': 255, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 56.41% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 41.42 | sMAPE for Test Set is: 64.08% | rMAE for Test Set is: 2.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:40:18,153]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:40:23,478]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:40:30,507]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:40:38,697]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:40:42,952]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:40:50,527]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:40:55,729]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:41:03,047]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:41:12,980]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:41:20,454]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:41:59,493]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:42:29,845]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:42:37,382]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:42:39,681]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:42:59,643]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:43:06,947]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:43:12,008]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:43:21,195]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:43:24,316]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:43:33,726]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:43:41,312]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:43:50,819]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:43:58,297]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:44:03,515]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:44:05,539]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:44:14,876]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:44:30,457]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:44:47,773]\u001b[0m Trial 1280 finished with value: 5.5171448903384865 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018324767970108048, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1505281056884506, 'dropout_rate_Layer_2': 0.3257234404159468, 'dropout_rate_Layer_3': 0.2671909679669952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006750023060512296, 'l1_Layer_2': 0.01071791308266181, 'l1_Layer_3': 2.0209737604464356e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 190, 'n_units_Layer_3': 50}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 71.37% | rMAE for Validation Set is: 1.73\n",
      "MAE for Test Set is: 62.53 | sMAPE for Test Set is: 133.44% | rMAE for Test Set is: 3.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:44:54,834]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:45:04,987]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:45:22,178]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:45:29,493]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:45:44,102]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:45:51,375]\u001b[0m Trial 1286 finished with value: 1.4891709407161275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006112483338571999, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1576614041740275, 'dropout_rate_Layer_2': 0.2049292089814325, 'dropout_rate_Layer_3': 0.3895453473574285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012887874851347556, 'l1_Layer_2': 0.013963526837131956, 'l1_Layer_3': 1.1949812327169823e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 165, 'n_units_Layer_3': 265}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 31.16% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.22 | sMAPE for Test Set is: 14.53% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:46:01,511]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:46:08,538]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:46:16,221]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:46:28,415]\u001b[0m Trial 1291 finished with value: 4.050462952116599 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014139779949634559, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26010330425606476, 'dropout_rate_Layer_2': 0.18566091285404254, 'dropout_rate_Layer_3': 0.023971263773648024, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.169376187373614e-05, 'l1_Layer_2': 0.0007001202922112816, 'l1_Layer_3': 0.000986521253699841, 'n_units_Layer_1': 240, 'n_units_Layer_2': 155, 'n_units_Layer_3': 60}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 54.43% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 40.20 | sMAPE for Test Set is: 60.04% | rMAE for Test Set is: 2.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:46:35,855]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:46:46,281]\u001b[0m Trial 1293 finished with value: 4.152848412690333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014807459650318666, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26120099128832797, 'dropout_rate_Layer_2': 0.17861588693992914, 'dropout_rate_Layer_3': 0.02432053375577776, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0021312465373603956, 'l1_Layer_2': 0.0006201638510361023, 'l1_Layer_3': 0.0007090880231407436, 'n_units_Layer_1': 240, 'n_units_Layer_2': 155, 'n_units_Layer_3': 60}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 83.38% | rMAE for Validation Set is: 1.30\n",
      "MAE for Test Set is: 39.40 | sMAPE for Test Set is: 60.68% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:46:53,649]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:46:58,595]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:47:12,775]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:47:15,564]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:47:50,386]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:47:55,225]\u001b[0m Trial 1299 finished with value: 5.931861213336084 and parameters: {'n_hidden': 3, 'learning_rate': 0.001241320942566133, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13818698521741454, 'dropout_rate_Layer_2': 0.31362324446265455, 'dropout_rate_Layer_3': 0.26235261341355814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07379729207853841, 'l1_Layer_2': 0.003938303772533521, 'l1_Layer_3': 3.81847594858888e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 165, 'n_units_Layer_3': 70}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 77.02% | rMAE for Validation Set is: 1.86\n",
      "MAE for Test Set is: 69.57 | sMAPE for Test Set is: 164.08% | rMAE for Test Set is: 4.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:47:59,446]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:48:04,608]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:48:05,035]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:48:15,001]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:48:24,299]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:48:39,779]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:48:54,391]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:49:01,180]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:49:06,929]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:49:21,714]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:49:26,800]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:49:31,903]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:49:44,032]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:50:06,434]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:50:11,705]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:50:31,150]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:50:38,540]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:50:45,535]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:50:59,921]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:51:05,239]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:51:10,687]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:51:20,282]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:51:29,794]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:51:42,392]\u001b[0m Trial 1314 finished with value: 1.572570318118388 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005493853941769652, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19604234644205012, 'dropout_rate_Layer_2': 0.23990936633647786, 'dropout_rate_Layer_3': 0.041761661865476245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011460363006742907, 'l1_Layer_2': 0.013485067744752085, 'l1_Layer_3': 2.0758829995838304e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 175, 'n_units_Layer_3': 255}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 30.45% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 10.39 | sMAPE for Test Set is: 13.07% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:51:45,464]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:51:50,407]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:52:00,018]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:52:00,368]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:52:12,812]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:52:29,365]\u001b[0m Trial 1329 finished with value: 4.198176763027823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013057310350033484, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2912723783586405, 'dropout_rate_Layer_2': 0.0347054777092343, 'dropout_rate_Layer_3': 0.04783706352881796, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00011313867469532007, 'l1_Layer_2': 0.0003296791025008357, 'l1_Layer_3': 0.0008756749346613802, 'n_units_Layer_1': 225, 'n_units_Layer_2': 170, 'n_units_Layer_3': 80}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 57.41% | rMAE for Validation Set is: 1.32\n",
      "MAE for Test Set is: 39.21 | sMAPE for Test Set is: 57.19% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:52:37,175]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:52:44,702]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:52:49,627]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:52:54,640]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:52:59,353]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:52:59,639]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:53:12,156]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:53:21,853]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:53:22,240]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:53:30,772]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:53:35,719]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:53:43,537]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:54:18,530]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:54:23,453]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:54:32,944]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:54:47,562]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:54:57,588]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:55:02,716]\u001b[0m Trial 1343 finished with value: 1.4024937194188711 and parameters: {'n_hidden': 3, 'learning_rate': 0.000605831153257763, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19687426476081196, 'dropout_rate_Layer_2': 0.18543538437065174, 'dropout_rate_Layer_3': 0.0331005054392995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9714184890989757e-05, 'l1_Layer_2': 0.008259234603642036, 'l1_Layer_3': 1.1664580688160766e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 175, 'n_units_Layer_3': 280}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 36.09% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 10.29 | sMAPE for Test Set is: 12.99% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:55:07,932]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:55:17,033]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:55:20,129]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:55:29,360]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:55:39,283]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:55:49,614]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:55:49,840]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:56:02,660]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:56:17,197]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:56:22,822]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:56:34,776]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:56:35,017]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:56:47,806]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:56:55,851]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:57:05,804]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:57:12,912]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:57:12,983]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:57:22,859]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:57:24,938]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:57:41,563]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:57:44,509]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:57:52,045]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:57:52,234]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:58:31,316]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:58:31,414]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:58:38,844]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:58:48,679]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:59:00,657]\u001b[0m Trial 1374 finished with value: 4.337705046565738 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013233349360158798, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26295315924253704, 'dropout_rate_Layer_2': 0.02594305269910524, 'dropout_rate_Layer_3': 0.03164242803437835, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010246588782691625, 'l1_Layer_2': 0.0005272247342958747, 'l1_Layer_3': 0.000946664949489096, 'n_units_Layer_1': 225, 'n_units_Layer_2': 155, 'n_units_Layer_3': 75}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 58.86% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 45.97 | sMAPE for Test Set is: 75.65% | rMAE for Test Set is: 2.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:59:07,943]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:59:18,202]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:59:37,567]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 14:59:50,642]\u001b[0m Trial 1379 finished with value: 5.969278122920511 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013277124148539762, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13049376525569148, 'dropout_rate_Layer_2': 0.33823953224569436, 'dropout_rate_Layer_3': 0.28163512905336563, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008502501924416877, 'l1_Layer_2': 0.014009002205922612, 'l1_Layer_3': 2.333886156196012e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 60}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 77.71% | rMAE for Validation Set is: 1.87\n",
      "MAE for Test Set is: 69.27 | sMAPE for Test Set is: 162.94% | rMAE for Test Set is: 4.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 14:59:57,487]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:00:12,487]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:00:21,959]\u001b[0m Trial 1383 finished with value: 4.395908995627692 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013257658330583532, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2757178596347718, 'dropout_rate_Layer_2': 0.03437917769144483, 'dropout_rate_Layer_3': 0.009430860249969909, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 9.199007381127223e-05, 'l1_Layer_2': 0.00027242137641053687, 'l1_Layer_3': 0.003547139019461434, 'n_units_Layer_1': 215, 'n_units_Layer_2': 160, 'n_units_Layer_3': 80}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 62.08% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 46.32 | sMAPE for Test Set is: 74.67% | rMAE for Test Set is: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:00:31,820]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:00:41,820]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:00:41,870]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:00:57,609]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:00:57,722]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:01:08,141]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:01:08,772]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:01:18,209]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:01:35,038]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:01:44,816]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:01:55,315]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:02:05,107]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:02:12,520]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:02:15,186]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:02:30,105]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:02:34,200]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:02:53,901]\u001b[0m Trial 1400 finished with value: 4.0184826572002805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009329058397667862, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22147430587020567, 'dropout_rate_Layer_2': 0.051262217384793585, 'dropout_rate_Layer_3': 0.02835373841308514, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.467606137333896e-05, 'l1_Layer_2': 0.00033191092623062, 'l1_Layer_3': 0.0006978383190947668, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 195}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 57.37% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 42.52 | sMAPE for Test Set is: 65.47% | rMAE for Test Set is: 2.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:02:59,496]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:03:08,879]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:03:18,362]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:03:26,650]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:03:48,624]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:04:28,362]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:04:38,011]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:04:43,231]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:04:52,764]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:05:00,663]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:05:10,631]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:05:19,457]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:05:29,505]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:05:36,962]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:05:42,637]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:05:49,116]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:05:52,077]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:06:01,702]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:06:09,345]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:06:16,030]\u001b[0m Trial 1419 finished with value: 3.89022894823832 and parameters: {'n_hidden': 3, 'learning_rate': 0.001008312335924271, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2110283433952155, 'dropout_rate_Layer_2': 0.05462588825430342, 'dropout_rate_Layer_3': 0.028887930874818127, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.442713073701138e-05, 'l1_Layer_2': 0.0003188657622302783, 'l1_Layer_3': 0.0005110579108836543, 'n_units_Layer_1': 225, 'n_units_Layer_2': 175, 'n_units_Layer_3': 205}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 66.85% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 37.83 | sMAPE for Test Set is: 56.36% | rMAE for Test Set is: 2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:06:25,732]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:06:28,800]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:06:35,580]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:06:41,145]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:06:47,788]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:06:51,203]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:07:00,366]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:07:10,911]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:07:30,531]\u001b[0m Trial 1430 finished with value: 4.340260008555268 and parameters: {'n_hidden': 3, 'learning_rate': 0.000946335224130071, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21897215306074908, 'dropout_rate_Layer_2': 0.04416547333155993, 'dropout_rate_Layer_3': 0.02874595804324446, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.779115590882939e-05, 'l1_Layer_2': 0.0003230824622392683, 'l1_Layer_3': 0.0006064034313099015, 'n_units_Layer_1': 220, 'n_units_Layer_2': 175, 'n_units_Layer_3': 200}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 79.70% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 37.31 | sMAPE for Test Set is: 54.45% | rMAE for Test Set is: 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:07:35,319]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:07:39,564]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:07:42,212]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:07:47,463]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:07:54,389]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:08:04,614]\u001b[0m Trial 1433 finished with value: 4.0968131811920285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010064509641786947, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2170343899193623, 'dropout_rate_Layer_2': 0.05512256624929457, 'dropout_rate_Layer_3': 0.019937268552346753, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.683808254979104e-05, 'l1_Layer_2': 0.0002826195254874456, 'l1_Layer_3': 0.0006397906066403832, 'n_units_Layer_1': 235, 'n_units_Layer_2': 175, 'n_units_Layer_3': 195}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 56.95% | rMAE for Validation Set is: 1.29\n",
      "MAE for Test Set is: 41.16 | sMAPE for Test Set is: 62.86% | rMAE for Test Set is: 2.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:08:16,936]\u001b[0m Trial 1436 finished with value: 3.880641401713799 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009812272503723905, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2003205631000764, 'dropout_rate_Layer_2': 0.052872989906841736, 'dropout_rate_Layer_3': 0.01995244334986504, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.056028806829767e-05, 'l1_Layer_2': 0.0003316358218550439, 'l1_Layer_3': 0.0005149953571473628, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 190}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 53.79% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 33.27 | sMAPE for Test Set is: 45.02% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:08:24,401]\u001b[0m Trial 1437 finished with value: 3.985598466724517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009948635093398562, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21629829957380692, 'dropout_rate_Layer_2': 0.052787788979724276, 'dropout_rate_Layer_3': 0.019610744430607365, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.503690949855094e-05, 'l1_Layer_2': 0.00025086442607101235, 'l1_Layer_3': 0.0005345842945148691, 'n_units_Layer_1': 235, 'n_units_Layer_2': 180, 'n_units_Layer_3': 195}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 54.37% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 50.69 | sMAPE for Test Set is: 89.10% | rMAE for Test Set is: 2.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:08:31,087]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:08:39,303]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:08:46,272]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:08:49,178]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:08:58,374]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:09:11,028]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:09:18,319]\u001b[0m Trial 1443 finished with value: 3.945486069392887 and parameters: {'n_hidden': 3, 'learning_rate': 0.001008809433926915, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21061617996037757, 'dropout_rate_Layer_2': 0.052955508368052885, 'dropout_rate_Layer_3': 0.02235239735291599, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.497115709001554e-05, 'l1_Layer_2': 0.00020570995422203298, 'l1_Layer_3': 0.000509176786411096, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 195}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:09:18,435]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.95 | sMAPE for Validation Set is: 65.68% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 35.76 | sMAPE for Test Set is: 52.23% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:09:34,825]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:09:44,562]\u001b[0m Trial 1447 finished with value: 4.001958198689388 and parameters: {'n_hidden': 3, 'learning_rate': 0.000997769767930246, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20823431023304007, 'dropout_rate_Layer_2': 0.05296128631122526, 'dropout_rate_Layer_3': 0.013954437275903345, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.600370490715726e-05, 'l1_Layer_2': 0.00019732642055565142, 'l1_Layer_3': 0.00039430984596478625, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 58.75% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 40.04 | sMAPE for Test Set is: 61.80% | rMAE for Test Set is: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:09:50,463]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:10:09,970]\u001b[0m Trial 1449 finished with value: 4.059036401825694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009414483803752902, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20895544830506058, 'dropout_rate_Layer_2': 0.06481376722800575, 'dropout_rate_Layer_3': 0.015372037168859012, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.827258000047352e-05, 'l1_Layer_2': 0.00017315101931443243, 'l1_Layer_3': 0.0003966225989322332, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 190}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 59.26% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 37.39 | sMAPE for Test Set is: 55.04% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:10:24,437]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:10:30,127]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:10:42,132]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:10:47,147]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:10:47,605]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:10:54,249]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:10:59,627]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:11:11,483]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:11:16,261]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:11:22,077]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:11:28,518]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:11:34,166]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:11:51,437]\u001b[0m Trial 1462 finished with value: 3.7251115064598284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008891769622966572, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20390704119432668, 'dropout_rate_Layer_2': 0.05217097188459183, 'dropout_rate_Layer_3': 0.018244006142478897, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.7905374496062445e-05, 'l1_Layer_2': 0.0002068864026438026, 'l1_Layer_3': 0.00047708317557243804, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 200}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 50.60% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 52.06 | sMAPE for Test Set is: 93.52% | rMAE for Test Set is: 3.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:11:54,588]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:12:00,541]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:12:08,643]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:12:33,789]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:12:48,147]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:12:55,313]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:12:55,532]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:13:03,729]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:13:04,119]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:13:20,318]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:13:27,740]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:14:27,596]\u001b[0m Trial 1473 finished with value: 1.4227148093337825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005015459435566478, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26965237113491086, 'dropout_rate_Layer_2': 0.2609993349492731, 'dropout_rate_Layer_3': 0.3737996234958859, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019059491075519266, 'l1_Layer_2': 0.004479354797476873, 'l1_Layer_3': 1.1949545333861324e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 25.08% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.35 | sMAPE for Test Set is: 12.78% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 15:14:49,004]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:14:59,323]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:15:06,258]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:15:21,443]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:15:44,336]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:15:53,708]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:16:01,431]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:16:04,000]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:16:13,266]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:16:23,205]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:16:28,859]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:16:31,872]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:16:38,225]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:16:46,287]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:16:50,721]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:00,271]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:08,415]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:22,739]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:30,355]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:45,612]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:52,543]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:17:58,029]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:18:07,007]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:18:16,969]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 15:18:26,947]\u001b[0m Trial 1490 finished with value: 1.403512310490095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005459557200736727, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23827603041172507, 'dropout_rate_Layer_2': 0.24251155215699685, 'dropout_rate_Layer_3': 0.3734094200193059, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002533616908334042, 'l1_Layer_2': 0.0053607784458860365, 'l1_Layer_3': 1.7235696131202223e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 170, 'n_units_Layer_3': 265}. Best is trial 1159 with value: 1.3220854133640796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 25.74% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 11.74 | sMAPE for Test Set is: 15.44% | rMAE for Test Set is: 0.68\n",
      "for 2021-01-01, MAE is:2.50 & sMAPE is:9.92% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 9.92% & 0.36\n",
      "for 2021-01-02, MAE is:1.12 & sMAPE is:4.20% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :1.81 & 7.06% & 0.24\n",
      "for 2021-01-03, MAE is:1.14 & sMAPE is:4.44% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :1.59 & 6.19% & 0.18\n",
      "for 2021-01-04, MAE is:15.97 & sMAPE is:40.49% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 14.76% & 0.31\n",
      "for 2021-01-05, MAE is:13.20 & sMAPE is:29.18% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 17.65% & 0.36\n",
      "for 2021-01-06, MAE is:7.51 & sMAPE is:18.13% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 17.73% & 0.37\n",
      "for 2021-01-07, MAE is:27.57 & sMAPE is:46.75% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.86 & 21.87% & 0.41\n",
      "for 2021-01-08, MAE is:22.91 & sMAPE is:30.34% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :11.49 & 22.93% & 0.41\n",
      "for 2021-01-09, MAE is:6.60 & sMAPE is:12.18% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :10.95 & 21.74% & 0.39\n",
      "for 2021-01-10, MAE is:8.03 & sMAPE is:18.34% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.66 & 21.40% & 0.40\n",
      "for 2021-01-11, MAE is:4.88 & sMAPE is:11.68% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.13 & 20.51% & 0.41\n",
      "for 2021-01-12, MAE is:10.85 & sMAPE is:25.16% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :10.19 & 20.90% & 0.54\n",
      "for 2021-01-13, MAE is:4.78 & sMAPE is:11.45% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.77 & 20.17% & 0.56\n",
      "for 2021-01-14, MAE is:28.50 & sMAPE is:45.30% & rMAE is:6.07 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 21.97% & 0.95\n",
      "for 2021-01-15, MAE is:16.59 & sMAPE is:23.38% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :11.48 & 22.06% & 1.02\n",
      "for 2021-01-16, MAE is:6.79 & sMAPE is:12.17% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 21.45% & 1.05\n",
      "for 2021-01-17, MAE is:5.17 & sMAPE is:9.60% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.83 & 20.75% & 1.02\n",
      "for 2021-01-18, MAE is:7.81 & sMAPE is:14.10% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :10.66 & 20.38% & 1.00\n",
      "for 2021-01-19, MAE is:5.77 & sMAPE is:13.17% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 20.00% & 1.01\n",
      "for 2021-01-20, MAE is:6.77 & sMAPE is:18.56% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :10.22 & 19.93% & 1.00\n",
      "for 2021-01-21, MAE is:6.29 & sMAPE is:20.22% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.04 & 19.94% & 0.96\n",
      "for 2021-01-22, MAE is:5.26 & sMAPE is:18.43% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 19.87% & 0.93\n",
      "for 2021-01-23, MAE is:9.89 & sMAPE is:25.97% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 20.14% & 0.91\n",
      "for 2021-01-24, MAE is:8.34 & sMAPE is:17.56% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :9.76 & 20.03% & 0.95\n",
      "for 2021-01-25, MAE is:14.31 & sMAPE is:24.71% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 20.22% & 0.99\n",
      "for 2021-01-26, MAE is:11.44 & sMAPE is:19.52% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 20.19% & 0.98\n",
      "for 2021-01-27, MAE is:7.84 & sMAPE is:13.79% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.92 & 19.95% & 0.96\n",
      "for 2021-01-28, MAE is:6.80 & sMAPE is:11.97% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 19.67% & 0.93\n",
      "for 2021-01-29, MAE is:7.64 & sMAPE is:14.37% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.73 & 19.49% & 0.91\n",
      "for 2021-01-30, MAE is:5.30 & sMAPE is:10.83% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.59 & 19.20% & 0.90\n",
      "for 2021-01-31, MAE is:5.43 & sMAPE is:11.05% & rMAE is:3.19 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 18.93% & 0.97\n",
      "for 2021-02-01, MAE is:38.21 & sMAPE is:41.84% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 19.65% & 0.99\n",
      "for 2021-02-02, MAE is:19.50 & sMAPE is:27.31% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.63 & 19.88% & 1.00\n",
      "for 2021-02-03, MAE is:10.09 & sMAPE is:18.71% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :10.61 & 19.85% & 1.01\n",
      "for 2021-02-04, MAE is:15.30 & sMAPE is:26.28% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.75 & 20.03% & 1.03\n",
      "for 2021-02-05, MAE is:30.58 & sMAPE is:33.18% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 20.40% & 1.04\n",
      "for 2021-02-06, MAE is:4.35 & sMAPE is:9.37% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 20.10% & 1.04\n",
      "for 2021-02-07, MAE is:5.46 & sMAPE is:12.62% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.96 & 19.90% & 1.03\n",
      "for 2021-02-08, MAE is:10.97 & sMAPE is:19.37% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.96 & 19.89% & 1.02\n",
      "for 2021-02-09, MAE is:19.42 & sMAPE is:28.24% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 20.10% & 1.03\n",
      "for 2021-02-10, MAE is:17.62 & sMAPE is:24.64% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.33 & 20.21% & 1.03\n",
      "for 2021-02-11, MAE is:39.57 & sMAPE is:37.46% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :12.00 & 20.62% & 1.02\n",
      "for 2021-02-12, MAE is:28.86 & sMAPE is:30.43% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :12.39 & 20.85% & 1.06\n",
      "for 2021-02-13, MAE is:5.92 & sMAPE is:10.83% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :12.25 & 20.62% & 1.06\n",
      "for 2021-02-14, MAE is:8.42 & sMAPE is:16.95% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :12.16 & 20.54% & 1.06\n",
      "for 2021-02-15, MAE is:17.88 & sMAPE is:23.81% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :12.29 & 20.61% & 1.08\n",
      "for 2021-02-16, MAE is:7.82 & sMAPE is:13.53% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :12.19 & 20.46% & 1.07\n",
      "for 2021-02-17, MAE is:6.23 & sMAPE is:12.32% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :12.07 & 20.29% & 1.05\n",
      "for 2021-02-18, MAE is:8.66 & sMAPE is:18.33% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :12.00 & 20.25% & 1.03\n",
      "for 2021-02-19, MAE is:5.74 & sMAPE is:12.00% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :11.87 & 20.08% & 1.02\n",
      "for 2021-02-20, MAE is:6.17 & sMAPE is:15.69% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.76 & 20.00% & 1.00\n",
      "for 2021-02-21, MAE is:3.81 & sMAPE is:10.65% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.61 & 19.82% & 0.99\n",
      "for 2021-02-22, MAE is:3.83 & sMAPE is:9.27% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :11.46 & 19.62% & 0.98\n",
      "for 2021-02-23, MAE is:1.26 & sMAPE is:3.28% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 19.32% & 0.96\n",
      "for 2021-02-24, MAE is:3.40 & sMAPE is:10.86% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 19.16% & 0.95\n",
      "for 2021-02-25, MAE is:2.93 & sMAPE is:9.40% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :10.98 & 18.99% & 0.93\n",
      "for 2021-02-26, MAE is:2.74 & sMAPE is:8.91% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.84 & 18.81% & 0.92\n",
      "for 2021-02-27, MAE is:7.04 & sMAPE is:22.02% & rMAE is:3.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.77 & 18.87% & 0.96\n",
      "for 2021-02-28, MAE is:2.49 & sMAPE is:7.45% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :10.63 & 18.67% & 0.95\n",
      "for 2021-03-01, MAE is:6.40 & sMAPE is:18.31% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 18.67% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-02, MAE is:7.74 & sMAPE is:18.89% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 18.67% & 0.98\n",
      "for 2021-03-03, MAE is:5.16 & sMAPE is:11.95% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 18.56% & 0.97\n",
      "for 2021-03-04, MAE is:7.14 & sMAPE is:18.42% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 18.56% & 0.97\n",
      "for 2021-03-05, MAE is:8.69 & sMAPE is:17.82% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 18.55% & 0.96\n",
      "for 2021-03-06, MAE is:3.61 & sMAPE is:9.47% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 18.41% & 0.97\n",
      "for 2021-03-07, MAE is:2.59 & sMAPE is:6.86% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.13 & 18.23% & 0.97\n",
      "for 2021-03-08, MAE is:17.09 & sMAPE is:30.79% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 18.42% & 0.97\n",
      "for 2021-03-09, MAE is:10.53 & sMAPE is:18.53% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 18.42% & 0.96\n",
      "for 2021-03-10, MAE is:7.39 & sMAPE is:15.92% & rMAE is:3.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 18.39% & 1.00\n",
      "for 2021-03-11, MAE is:5.08 & sMAPE is:13.81% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :10.12 & 18.32% & 1.00\n",
      "for 2021-03-12, MAE is:1.85 & sMAPE is:5.04% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :10.01 & 18.13% & 0.99\n",
      "for 2021-03-13, MAE is:0.94 & sMAPE is:2.59% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.88 & 17.92% & 0.98\n",
      "for 2021-03-14, MAE is:3.47 & sMAPE is:9.48% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.79 & 17.80% & 0.99\n",
      "for 2021-03-15, MAE is:3.32 & sMAPE is:7.32% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 17.66% & 0.98\n",
      "for 2021-03-16, MAE is:7.28 & sMAPE is:15.22% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :9.67 & 17.63% & 0.98\n",
      "for 2021-03-17, MAE is:7.35 & sMAPE is:14.07% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :9.64 & 17.58% & 0.98\n",
      "for 2021-03-18, MAE is:3.89 & sMAPE is:8.00% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 17.46% & 0.97\n",
      "for 2021-03-19, MAE is:1.94 & sMAPE is:4.72% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :9.47 & 17.29% & 0.96\n",
      "for 2021-03-20, MAE is:2.98 & sMAPE is:7.81% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 17.17% & 0.96\n",
      "for 2021-03-21, MAE is:3.62 & sMAPE is:10.29% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 17.09% & 0.98\n",
      "for 2021-03-22, MAE is:2.52 & sMAPE is:5.84% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 16.95% & 0.99\n",
      "for 2021-03-23, MAE is:3.01 & sMAPE is:6.33% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.16 & 16.82% & 0.98\n",
      "for 2021-03-24, MAE is:1.51 & sMAPE is:3.98% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.06 & 16.66% & 0.97\n",
      "for 2021-03-25, MAE is:1.59 & sMAPE is:4.06% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.98 & 16.51% & 0.96\n",
      "for 2021-03-26, MAE is:2.00 & sMAPE is:5.27% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 16.38% & 0.96\n",
      "for 2021-03-27, MAE is:2.55 & sMAPE is:7.19% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 16.28% & 0.96\n",
      "for 2021-03-28, MAE is:2.44 & sMAPE is:6.74% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.75 & 16.17% & 0.96\n",
      "for 2021-03-29, MAE is:1.34 & sMAPE is:3.71% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 16.02% & 0.95\n",
      "for 2021-03-30, MAE is:2.18 & sMAPE is:5.73% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 15.91% & 0.95\n",
      "for 2021-03-31, MAE is:2.90 & sMAPE is:7.54% & rMAE is:2.91 ||| daily mean of MAE & sMAPE & rMAE till now are :8.53 & 15.82% & 0.97\n",
      "for 2021-04-01, MAE is:4.08 & sMAPE is:10.82% & rMAE is:5.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 15.76% & 1.02\n",
      "for 2021-04-02, MAE is:7.12 & sMAPE is:24.53% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 15.86% & 1.02\n",
      "for 2021-04-03, MAE is:5.92 & sMAPE is:17.23% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 15.87% & 1.03\n",
      "for 2021-04-04, MAE is:10.50 & sMAPE is:44.02% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 16.17% & 1.03\n",
      "for 2021-04-05, MAE is:11.29 & sMAPE is:62.30% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 16.66% & 1.03\n",
      "for 2021-04-06, MAE is:12.08 & sMAPE is:37.51% & rMAE is:2.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 16.87% & 1.05\n",
      "for 2021-04-07, MAE is:11.22 & sMAPE is:23.93% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 16.95% & 1.05\n",
      "for 2021-04-08, MAE is:9.47 & sMAPE is:17.74% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 16.95% & 1.05\n",
      "for 2021-04-09, MAE is:1.40 & sMAPE is:3.80% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 16.82% & 1.04\n",
      "for 2021-04-10, MAE is:3.75 & sMAPE is:9.67% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 16.75% & 1.04\n",
      "for 2021-04-11, MAE is:1.79 & sMAPE is:4.50% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 16.63% & 1.03\n",
      "for 2021-04-12, MAE is:5.57 & sMAPE is:12.92% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 16.59% & 1.03\n",
      "for 2021-04-13, MAE is:2.49 & sMAPE is:5.68% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.29 & 16.49% & 1.02\n",
      "for 2021-04-14, MAE is:14.45 & sMAPE is:23.22% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 16.55% & 1.02\n",
      "for 2021-04-15, MAE is:12.31 & sMAPE is:19.30% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 16.58% & 1.02\n",
      "for 2021-04-16, MAE is:7.56 & sMAPE is:13.27% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 16.55% & 1.02\n",
      "for 2021-04-17, MAE is:2.56 & sMAPE is:5.46% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 16.44% & 1.01\n",
      "for 2021-04-18, MAE is:2.17 & sMAPE is:4.54% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 16.33% & 1.00\n",
      "for 2021-04-19, MAE is:3.17 & sMAPE is:6.44% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 16.24% & 1.00\n",
      "for 2021-04-20, MAE is:1.80 & sMAPE is:3.93% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 16.13% & 1.00\n",
      "for 2021-04-21, MAE is:5.15 & sMAPE is:11.69% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 16.09% & 0.99\n",
      "for 2021-04-22, MAE is:3.67 & sMAPE is:8.94% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.10 & 16.03% & 0.98\n",
      "for 2021-04-23, MAE is:3.35 & sMAPE is:7.60% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 15.95% & 0.98\n",
      "for 2021-04-24, MAE is:4.60 & sMAPE is:10.38% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 15.90% & 0.98\n",
      "for 2021-04-25, MAE is:4.64 & sMAPE is:10.70% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 15.86% & 0.98\n",
      "for 2021-04-26, MAE is:13.28 & sMAPE is:24.32% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 15.93% & 0.99\n",
      "for 2021-04-27, MAE is:5.73 & sMAPE is:10.07% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 15.88% & 0.98\n",
      "for 2021-04-28, MAE is:8.49 & sMAPE is:14.36% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 15.87% & 0.98\n",
      "for 2021-04-29, MAE is:6.32 & sMAPE is:11.17% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 15.83% & 0.98\n",
      "for 2021-04-30, MAE is:8.47 & sMAPE is:14.95% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 15.82% & 0.98\n",
      "for 2021-05-01, MAE is:2.83 & sMAPE is:5.70% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 15.74% & 0.97\n",
      "for 2021-05-02, MAE is:5.29 & sMAPE is:11.59% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 15.70% & 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-03, MAE is:10.91 & sMAPE is:18.02% & rMAE is:2.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 15.72% & 0.99\n",
      "for 2021-05-04, MAE is:13.48 & sMAPE is:26.00% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 15.80% & 1.00\n",
      "for 2021-05-05, MAE is:4.88 & sMAPE is:9.85% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 15.76% & 0.99\n",
      "for 2021-05-06, MAE is:12.61 & sMAPE is:21.04% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 15.80% & 0.99\n",
      "for 2021-05-07, MAE is:8.70 & sMAPE is:12.92% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 15.78% & 0.99\n",
      "for 2021-05-08, MAE is:6.39 & sMAPE is:12.26% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 15.75% & 0.99\n",
      "for 2021-05-09, MAE is:12.15 & sMAPE is:28.61% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 15.85% & 1.00\n",
      "for 2021-05-10, MAE is:3.72 & sMAPE is:7.58% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 15.78% & 0.99\n",
      "for 2021-05-11, MAE is:5.36 & sMAPE is:10.43% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 15.74% & 0.99\n",
      "for 2021-05-12, MAE is:2.92 & sMAPE is:5.66% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 15.67% & 0.99\n",
      "for 2021-05-13, MAE is:2.30 & sMAPE is:4.52% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 15.58% & 0.98\n",
      "for 2021-05-14, MAE is:2.60 & sMAPE is:5.24% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 15.51% & 0.97\n",
      "for 2021-05-15, MAE is:1.85 & sMAPE is:3.84% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 15.42% & 0.97\n",
      "for 2021-05-16, MAE is:13.96 & sMAPE is:38.49% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 15.59% & 0.97\n",
      "for 2021-05-17, MAE is:10.13 & sMAPE is:20.93% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 15.63% & 0.98\n",
      "for 2021-05-18, MAE is:4.79 & sMAPE is:8.98% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 15.58% & 0.99\n",
      "for 2021-05-19, MAE is:2.61 & sMAPE is:4.90% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 15.50% & 1.00\n",
      "for 2021-05-20, MAE is:2.36 & sMAPE is:4.58% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 15.43% & 1.00\n",
      "for 2021-05-21, MAE is:17.33 & sMAPE is:50.26% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 15.67% & 1.00\n",
      "for 2021-05-22, MAE is:21.27 & sMAPE is:96.78% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 16.24% & 1.00\n",
      "for 2021-05-23, MAE is:15.68 & sMAPE is:59.28% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 16.54% & 1.00\n",
      "for 2021-05-24, MAE is:10.14 & sMAPE is:26.38% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 16.61% & 1.00\n",
      "for 2021-05-25, MAE is:5.42 & sMAPE is:11.14% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 16.58% & 1.00\n",
      "for 2021-05-26, MAE is:5.28 & sMAPE is:10.96% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 16.54% & 1.00\n",
      "for 2021-05-27, MAE is:1.45 & sMAPE is:2.85% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 16.44% & 1.00\n",
      "for 2021-05-28, MAE is:3.05 & sMAPE is:6.07% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 16.37% & 0.99\n",
      "for 2021-05-29, MAE is:6.36 & sMAPE is:15.05% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 16.36% & 0.99\n",
      "for 2021-05-30, MAE is:12.55 & sMAPE is:35.74% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 16.49% & 0.99\n",
      "for 2021-05-31, MAE is:8.73 & sMAPE is:17.94% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 16.50% & 0.99\n",
      "for 2021-06-01, MAE is:4.45 & sMAPE is:9.42% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 16.46% & 0.99\n",
      "for 2021-06-02, MAE is:5.74 & sMAPE is:11.91% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 16.43% & 0.99\n",
      "for 2021-06-03, MAE is:3.67 & sMAPE is:7.54% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 16.37% & 0.99\n",
      "for 2021-06-04, MAE is:5.05 & sMAPE is:10.17% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 16.33% & 1.00\n",
      "for 2021-06-05, MAE is:1.26 & sMAPE is:2.71% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 16.24% & 0.99\n",
      "for 2021-06-06, MAE is:1.13 & sMAPE is:2.56% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 16.15% & 0.99\n",
      "for 2021-06-07, MAE is:7.29 & sMAPE is:14.39% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 16.14% & 1.00\n",
      "for 2021-06-08, MAE is:5.85 & sMAPE is:11.12% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 16.11% & 1.00\n",
      "for 2021-06-09, MAE is:2.63 & sMAPE is:4.81% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 16.04% & 0.99\n",
      "for 2021-06-10, MAE is:3.02 & sMAPE is:5.56% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 15.98% & 0.99\n",
      "for 2021-06-11, MAE is:1.29 & sMAPE is:2.49% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 15.89% & 0.99\n",
      "for 2021-06-12, MAE is:12.91 & sMAPE is:43.02% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 16.06% & 0.99\n",
      "for 2021-06-13, MAE is:23.24 & sMAPE is:106.22% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 16.61% & 0.99\n",
      "for 2021-06-14, MAE is:14.06 & sMAPE is:35.08% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 16.72% & 1.00\n",
      "for 2021-06-15, MAE is:1.75 & sMAPE is:3.75% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 16.64% & 0.99\n",
      "for 2021-06-16, MAE is:2.27 & sMAPE is:4.97% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 16.57% & 0.99\n",
      "for 2021-06-17, MAE is:3.79 & sMAPE is:8.66% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 16.53% & 0.98\n",
      "for 2021-06-18, MAE is:1.11 & sMAPE is:2.70% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 16.44% & 0.98\n",
      "for 2021-06-19, MAE is:0.92 & sMAPE is:2.33% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 16.36% & 0.97\n",
      "for 2021-06-20, MAE is:2.44 & sMAPE is:6.74% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 16.30% & 0.97\n",
      "for 2021-06-21, MAE is:1.45 & sMAPE is:3.42% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 16.23% & 0.96\n",
      "for 2021-06-22, MAE is:3.20 & sMAPE is:7.57% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 16.18% & 0.97\n",
      "for 2021-06-23, MAE is:3.83 & sMAPE is:8.69% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 16.14% & 0.97\n",
      "for 2021-06-24, MAE is:2.65 & sMAPE is:5.79% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 16.08% & 0.97\n",
      "for 2021-06-25, MAE is:1.84 & sMAPE is:4.06% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 16.01% & 0.97\n",
      "for 2021-06-26, MAE is:3.34 & sMAPE is:7.38% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 15.96% & 0.96\n",
      "for 2021-06-27, MAE is:4.80 & sMAPE is:10.72% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 15.93% & 0.96\n",
      "for 2021-06-28, MAE is:3.69 & sMAPE is:7.43% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 15.88% & 0.96\n",
      "for 2021-06-29, MAE is:2.17 & sMAPE is:4.20% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 15.82% & 0.95\n",
      "for 2021-06-30, MAE is:2.12 & sMAPE is:4.21% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 15.75% & 0.95\n",
      "for 2021-07-01, MAE is:1.40 & sMAPE is:2.88% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 15.68% & 0.95\n",
      "for 2021-07-02, MAE is:3.62 & sMAPE is:7.23% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 15.64% & 0.95\n",
      "for 2021-07-03, MAE is:2.80 & sMAPE is:5.61% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 15.58% & 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-04, MAE is:5.01 & sMAPE is:9.66% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 15.55% & 0.95\n",
      "for 2021-07-05, MAE is:2.11 & sMAPE is:3.73% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 15.49% & 0.94\n",
      "for 2021-07-06, MAE is:0.99 & sMAPE is:1.79% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 15.41% & 0.94\n",
      "for 2021-07-07, MAE is:1.22 & sMAPE is:2.21% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 15.34% & 0.94\n",
      "for 2021-07-08, MAE is:1.48 & sMAPE is:2.61% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 15.28% & 0.93\n",
      "for 2021-07-09, MAE is:2.69 & sMAPE is:4.85% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.22% & 0.93\n",
      "for 2021-07-10, MAE is:1.51 & sMAPE is:2.67% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 15.16% & 0.93\n",
      "for 2021-07-11, MAE is:2.13 & sMAPE is:3.81% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 15.10% & 0.93\n",
      "for 2021-07-12, MAE is:1.14 & sMAPE is:1.97% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 15.03% & 0.93\n",
      "for 2021-07-13, MAE is:1.71 & sMAPE is:2.92% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 14.97% & 0.92\n",
      "for 2021-07-14, MAE is:1.91 & sMAPE is:3.25% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 14.91% & 0.92\n",
      "for 2021-07-15, MAE is:1.79 & sMAPE is:3.04% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 14.85% & 0.92\n",
      "for 2021-07-16, MAE is:1.75 & sMAPE is:2.95% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 14.79% & 0.92\n",
      "for 2021-07-17, MAE is:5.09 & sMAPE is:9.66% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 14.76% & 0.92\n",
      "for 2021-07-18, MAE is:15.71 & sMAPE is:44.61% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 14.91% & 0.92\n",
      "for 2021-07-19, MAE is:11.35 & sMAPE is:21.15% & rMAE is:3.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 14.94% & 0.93\n",
      "for 2021-07-20, MAE is:1.43 & sMAPE is:2.45% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 14.88% & 0.93\n",
      "for 2021-07-21, MAE is:3.24 & sMAPE is:5.60% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 14.83% & 0.93\n",
      "for 2021-07-22, MAE is:1.17 & sMAPE is:2.04% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 14.77% & 0.93\n",
      "for 2021-07-23, MAE is:1.83 & sMAPE is:3.17% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 14.71% & 0.93\n",
      "for 2021-07-24, MAE is:1.04 & sMAPE is:1.83% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 14.65% & 0.93\n",
      "for 2021-07-25, MAE is:3.66 & sMAPE is:6.65% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 14.61% & 0.93\n",
      "for 2021-07-26, MAE is:2.00 & sMAPE is:3.51% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 14.56% & 0.92\n",
      "for 2021-07-27, MAE is:1.25 & sMAPE is:2.19% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 14.50% & 0.93\n",
      "for 2021-07-28, MAE is:0.98 & sMAPE is:1.68% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 14.44% & 0.92\n",
      "for 2021-07-29, MAE is:6.54 & sMAPE is:12.95% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 14.43% & 0.92\n",
      "for 2021-07-30, MAE is:2.80 & sMAPE is:5.24% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 14.39% & 0.92\n",
      "for 2021-07-31, MAE is:10.63 & sMAPE is:22.60% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 14.43% & 0.92\n",
      "for 2021-08-01, MAE is:6.41 & sMAPE is:12.20% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 14.41% & 0.93\n",
      "for 2021-08-02, MAE is:1.07 & sMAPE is:1.89% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.36% & 0.93\n",
      "for 2021-08-03, MAE is:3.09 & sMAPE is:5.44% & rMAE is:5.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.31% & 0.95\n",
      "for 2021-08-04, MAE is:2.60 & sMAPE is:4.39% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 14.27% & 0.95\n",
      "for 2021-08-05, MAE is:3.54 & sMAPE is:5.96% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 14.23% & 0.94\n",
      "for 2021-08-06, MAE is:1.85 & sMAPE is:3.08% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 14.18% & 0.94\n",
      "for 2021-08-07, MAE is:2.51 & sMAPE is:4.21% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 14.13% & 0.94\n",
      "for 2021-08-08, MAE is:21.14 & sMAPE is:58.67% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 14.34% & 0.94\n",
      "for 2021-08-09, MAE is:11.27 & sMAPE is:19.62% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.36% & 0.94\n",
      "for 2021-08-10, MAE is:5.75 & sMAPE is:8.68% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.33% & 0.94\n",
      "for 2021-08-11, MAE is:6.02 & sMAPE is:8.79% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.31% & 0.94\n",
      "for 2021-08-12, MAE is:2.59 & sMAPE is:3.70% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 14.26% & 0.93\n",
      "for 2021-08-13, MAE is:2.22 & sMAPE is:3.16% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 14.21% & 0.93\n",
      "for 2021-08-14, MAE is:5.55 & sMAPE is:8.26% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 14.19% & 0.93\n",
      "for 2021-08-15, MAE is:7.77 & sMAPE is:11.79% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 14.18% & 0.93\n",
      "for 2021-08-16, MAE is:3.30 & sMAPE is:4.67% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 14.13% & 0.92\n",
      "for 2021-08-17, MAE is:6.24 & sMAPE is:10.57% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 14.12% & 0.92\n",
      "for 2021-08-18, MAE is:3.63 & sMAPE is:5.12% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 14.08% & 0.93\n",
      "for 2021-08-19, MAE is:3.85 & sMAPE is:5.23% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 14.04% & 0.93\n",
      "for 2021-08-20, MAE is:6.25 & sMAPE is:8.24% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 14.02% & 0.93\n",
      "for 2021-08-21, MAE is:3.94 & sMAPE is:5.20% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 13.98% & 0.92\n",
      "for 2021-08-22, MAE is:4.18 & sMAPE is:5.50% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 13.94% & 0.92\n",
      "for 2021-08-23, MAE is:2.59 & sMAPE is:3.26% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 13.90% & 0.92\n",
      "for 2021-08-24, MAE is:2.06 & sMAPE is:2.62% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 13.85% & 0.91\n",
      "for 2021-08-25, MAE is:3.68 & sMAPE is:4.80% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 13.81% & 0.91\n",
      "for 2021-08-26, MAE is:4.78 & sMAPE is:5.82% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 13.78% & 0.91\n",
      "for 2021-08-27, MAE is:3.26 & sMAPE is:3.76% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 13.74% & 0.91\n",
      "for 2021-08-28, MAE is:2.63 & sMAPE is:3.18% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 13.69% & 0.91\n",
      "for 2021-08-29, MAE is:4.77 & sMAPE is:5.75% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 13.66% & 0.91\n",
      "for 2021-08-30, MAE is:16.33 & sMAPE is:16.67% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 13.67% & 0.91\n",
      "for 2021-08-31, MAE is:11.86 & sMAPE is:10.88% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 13.66% & 0.90\n",
      "for 2021-09-01, MAE is:9.29 & sMAPE is:8.73% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 13.64% & 0.90\n",
      "for 2021-09-02, MAE is:6.75 & sMAPE is:6.60% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 13.61% & 0.90\n",
      "for 2021-09-03, MAE is:5.44 & sMAPE is:5.57% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 13.58% & 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-04, MAE is:6.07 & sMAPE is:6.32% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 13.55% & 0.90\n",
      "for 2021-09-05, MAE is:7.62 & sMAPE is:7.77% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 13.53% & 0.90\n",
      "for 2021-09-06, MAE is:12.55 & sMAPE is:10.69% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 13.51% & 0.90\n",
      "for 2021-09-07, MAE is:7.27 & sMAPE is:6.52% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 13.49% & 0.89\n",
      "for 2021-09-08, MAE is:4.24 & sMAPE is:4.03% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 13.45% & 0.89\n",
      "for 2021-09-09, MAE is:2.43 & sMAPE is:2.33% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 13.40% & 0.89\n",
      "for 2021-09-10, MAE is:4.31 & sMAPE is:4.11% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 13.37% & 0.89\n",
      "for 2021-09-11, MAE is:2.91 & sMAPE is:2.81% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 13.33% & 0.89\n",
      "for 2021-09-12, MAE is:7.61 & sMAPE is:7.76% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 13.30% & 0.89\n",
      "for 2021-09-13, MAE is:2.48 & sMAPE is:2.41% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 13.26% & 0.88\n",
      "for 2021-09-14, MAE is:8.48 & sMAPE is:7.25% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 13.24% & 0.88\n",
      "for 2021-09-15, MAE is:2.95 & sMAPE is:2.64% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 13.20% & 0.88\n",
      "for 2021-09-16, MAE is:10.60 & sMAPE is:8.96% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 13.18% & 0.88\n",
      "for 2021-09-17, MAE is:3.92 & sMAPE is:3.21% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 13.14% & 0.88\n",
      "for 2021-09-18, MAE is:7.90 & sMAPE is:6.77% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 13.12% & 0.88\n",
      "for 2021-09-19, MAE is:19.67 & sMAPE is:20.22% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 13.14% & 0.88\n",
      "for 2021-09-20, MAE is:12.75 & sMAPE is:11.50% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 13.14% & 0.88\n",
      "for 2021-09-21, MAE is:4.84 & sMAPE is:4.13% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 13.10% & 0.88\n",
      "for 2021-09-22, MAE is:4.87 & sMAPE is:4.37% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 13.07% & 0.88\n",
      "for 2021-09-23, MAE is:10.95 & sMAPE is:10.72% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 13.06% & 0.88\n",
      "for 2021-09-24, MAE is:7.11 & sMAPE is:7.09% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 13.04% & 0.88\n",
      "for 2021-09-25, MAE is:10.24 & sMAPE is:9.70% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 13.03% & 0.88\n",
      "for 2021-09-26, MAE is:4.59 & sMAPE is:4.34% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 13.00% & 0.88\n",
      "for 2021-09-27, MAE is:4.07 & sMAPE is:3.84% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 12.96% & 0.88\n",
      "for 2021-09-28, MAE is:6.80 & sMAPE is:6.33% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 12.94% & 0.88\n",
      "for 2021-09-29, MAE is:6.85 & sMAPE is:6.68% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 12.91% & 0.88\n",
      "for 2021-09-30, MAE is:10.92 & sMAPE is:12.07% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 12.91% & 0.88\n",
      "for 2021-10-01, MAE is:13.97 & sMAPE is:17.51% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 12.93% & 0.88\n",
      "for 2021-10-02, MAE is:13.52 & sMAPE is:18.54% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 12.95% & 0.88\n",
      "for 2021-10-03, MAE is:38.55 & sMAPE is:87.88% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 13.22% & 0.88\n",
      "for 2021-10-04, MAE is:20.06 & sMAPE is:24.84% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 13.26% & 0.88\n",
      "for 2021-10-05, MAE is:6.92 & sMAPE is:7.33% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 13.24% & 0.88\n",
      "for 2021-10-06, MAE is:12.65 & sMAPE is:12.82% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 13.24% & 0.88\n",
      "for 2021-10-07, MAE is:18.91 & sMAPE is:17.02% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 13.25% & 0.88\n",
      "for 2021-10-08, MAE is:7.54 & sMAPE is:6.50% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 13.23% & 0.88\n",
      "for 2021-10-09, MAE is:5.52 & sMAPE is:4.89% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 13.20% & 0.87\n",
      "for 2021-10-10, MAE is:4.82 & sMAPE is:4.40% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 13.17% & 0.87\n",
      "for 2021-10-11, MAE is:5.98 & sMAPE is:5.37% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 13.14% & 0.87\n",
      "for 2021-10-12, MAE is:9.58 & sMAPE is:8.27% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 13.12% & 0.87\n",
      "for 2021-10-13, MAE is:19.55 & sMAPE is:15.65% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 13.13% & 0.87\n",
      "for 2021-10-14, MAE is:21.13 & sMAPE is:19.19% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 13.15% & 0.87\n",
      "for 2021-10-15, MAE is:12.43 & sMAPE is:13.85% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 13.16% & 0.87\n",
      "for 2021-10-16, MAE is:7.03 & sMAPE is:7.24% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 13.13% & 0.86\n",
      "for 2021-10-17, MAE is:5.03 & sMAPE is:4.65% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 13.11% & 0.87\n",
      "for 2021-10-18, MAE is:26.18 & sMAPE is:18.35% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 13.12% & 0.87\n",
      "for 2021-10-19, MAE is:42.18 & sMAPE is:29.23% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 13.18% & 0.87\n",
      "for 2021-10-20, MAE is:37.08 & sMAPE is:42.64% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 13.28% & 0.87\n",
      "for 2021-10-21, MAE is:9.95 & sMAPE is:15.42% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 13.29% & 0.87\n",
      "for 2021-10-22, MAE is:3.39 & sMAPE is:3.77% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 13.25% & 0.87\n",
      "for 2021-10-23, MAE is:24.80 & sMAPE is:23.23% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 13.29% & 0.87\n",
      "for 2021-10-24, MAE is:18.43 & sMAPE is:19.25% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 13.31% & 0.87\n",
      "for 2021-10-25, MAE is:9.29 & sMAPE is:9.13% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 13.29% & 0.87\n",
      "for 2021-10-26, MAE is:6.50 & sMAPE is:6.66% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 13.27% & 0.86\n",
      "for 2021-10-27, MAE is:14.66 & sMAPE is:16.83% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 13.28% & 0.86\n",
      "for 2021-10-28, MAE is:4.66 & sMAPE is:5.95% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 13.26% & 0.86\n",
      "for 2021-10-29, MAE is:4.98 & sMAPE is:6.21% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 13.24% & 0.86\n",
      "for 2021-10-30, MAE is:5.57 & sMAPE is:7.46% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 13.22% & 0.86\n",
      "for 2021-10-31, MAE is:9.20 & sMAPE is:14.01% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 13.22% & 0.86\n",
      "for 2021-11-01, MAE is:13.19 & sMAPE is:22.04% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 13.25% & 0.86\n",
      "for 2021-11-02, MAE is:16.58 & sMAPE is:20.12% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 13.27% & 0.86\n",
      "for 2021-11-03, MAE is:8.20 & sMAPE is:8.39% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 13.26% & 0.86\n",
      "for 2021-11-04, MAE is:16.59 & sMAPE is:16.45% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 13.27% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-05, MAE is:12.00 & sMAPE is:12.79% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 13.26% & 0.86\n",
      "for 2021-11-06, MAE is:6.35 & sMAPE is:7.83% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 13.25% & 0.86\n",
      "for 2021-11-07, MAE is:9.95 & sMAPE is:15.94% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 13.26% & 0.86\n",
      "for 2021-11-08, MAE is:47.79 & sMAPE is:40.13% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 13.34% & 0.86\n",
      "for 2021-11-09, MAE is:32.83 & sMAPE is:32.80% & rMAE is:3.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 13.40% & 0.87\n",
      "for 2021-11-10, MAE is:8.84 & sMAPE is:10.32% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 13.39% & 0.87\n",
      "for 2021-11-11, MAE is:3.53 & sMAPE is:3.84% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 13.36% & 0.87\n",
      "for 2021-11-12, MAE is:4.56 & sMAPE is:5.06% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 13.34% & 0.87\n",
      "for 2021-11-13, MAE is:4.18 & sMAPE is:4.55% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 13.31% & 0.86\n",
      "for 2021-11-14, MAE is:6.64 & sMAPE is:7.06% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 13.29% & 0.86\n",
      "for 2021-11-15, MAE is:3.90 & sMAPE is:3.90% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 13.26% & 0.86\n",
      "for 2021-11-16, MAE is:3.60 & sMAPE is:3.79% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 13.23% & 0.86\n",
      "for 2021-11-17, MAE is:6.38 & sMAPE is:6.80% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 13.21% & 0.86\n",
      "for 2021-11-18, MAE is:3.60 & sMAPE is:3.95% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 13.18% & 0.86\n",
      "for 2021-11-19, MAE is:6.40 & sMAPE is:7.49% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 13.16% & 0.86\n",
      "for 2021-11-20, MAE is:4.15 & sMAPE is:4.88% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 13.14% & 0.86\n",
      "for 2021-11-21, MAE is:5.32 & sMAPE is:5.71% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 13.12% & 0.86\n",
      "for 2021-11-22, MAE is:28.57 & sMAPE is:22.00% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 13.14% & 0.86\n",
      "for 2021-11-23, MAE is:11.88 & sMAPE is:10.80% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 13.14% & 0.86\n",
      "for 2021-11-24, MAE is:9.55 & sMAPE is:8.86% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 13.12% & 0.86\n",
      "for 2021-11-25, MAE is:6.21 & sMAPE is:5.58% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 13.10% & 0.86\n",
      "for 2021-11-26, MAE is:8.39 & sMAPE is:7.37% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 13.08% & 0.85\n",
      "for 2021-11-27, MAE is:33.11 & sMAPE is:22.44% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 13.11% & 0.85\n",
      "for 2021-11-28, MAE is:43.00 & sMAPE is:25.25% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 13.15% & 0.85\n",
      "for 2021-11-29, MAE is:86.08 & sMAPE is:35.70% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 13.22% & 0.85\n",
      "for 2021-11-30, MAE is:90.97 & sMAPE is:52.83% & rMAE is:3.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 13.33% & 0.86\n",
      "for 2021-12-01, MAE is:27.77 & sMAPE is:21.22% & rMAE is:2.96 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 13.36% & 0.86\n",
      "for 2021-12-02, MAE is:63.69 & sMAPE is:34.70% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.60 & 13.42% & 0.86\n",
      "for 2021-12-03, MAE is:34.21 & sMAPE is:21.96% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 13.45% & 0.87\n",
      "for 2021-12-04, MAE is:5.61 & sMAPE is:4.25% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 13.42% & 0.86\n",
      "for 2021-12-05, MAE is:14.99 & sMAPE is:11.61% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 13.41% & 0.86\n",
      "for 2021-12-06, MAE is:27.66 & sMAPE is:14.93% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.75 & 13.42% & 0.86\n",
      "for 2021-12-07, MAE is:37.82 & sMAPE is:21.38% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 13.44% & 0.86\n",
      "for 2021-12-08, MAE is:12.34 & sMAPE is:9.53% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 13.43% & 0.86\n",
      "for 2021-12-09, MAE is:4.96 & sMAPE is:3.83% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 13.40% & 0.86\n",
      "for 2021-12-10, MAE is:17.36 & sMAPE is:10.69% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 13.39% & 0.86\n",
      "for 2021-12-11, MAE is:27.64 & sMAPE is:16.33% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 13.40% & 0.86\n",
      "for 2021-12-12, MAE is:20.50 & sMAPE is:14.92% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.94 & 13.41% & 0.86\n",
      "for 2021-12-13, MAE is:6.85 & sMAPE is:4.92% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.94 & 13.38% & 0.86\n",
      "for 2021-12-14, MAE is:71.90 & sMAPE is:33.33% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.12 & 13.44% & 0.86\n",
      "for 2021-12-15, MAE is:38.62 & sMAPE is:26.31% & rMAE is:4.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 13.48% & 0.88\n",
      "for 2021-12-16, MAE is:24.48 & sMAPE is:17.18% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :9.25 & 13.49% & 0.88\n",
      "for 2021-12-17, MAE is:23.30 & sMAPE is:13.45% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 13.49% & 0.88\n",
      "for 2021-12-18, MAE is:14.30 & sMAPE is:9.05% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 13.47% & 0.87\n",
      "for 2021-12-19, MAE is:15.01 & sMAPE is:10.10% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 13.47% & 0.87\n",
      "for 2021-12-20, MAE is:148.61 & sMAPE is:56.41% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 13.59% & 0.87\n",
      "for 2021-12-21, MAE is:133.08 & sMAPE is:36.06% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 13.65% & 0.87\n",
      "for 2021-12-22, MAE is:72.45 & sMAPE is:25.20% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 13.68% & 0.87\n",
      "for 2021-12-23, MAE is:32.49 & sMAPE is:13.40% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.29 & 13.68% & 0.87\n",
      "for 2021-12-24, MAE is:31.93 & sMAPE is:15.51% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 13.69% & 0.87\n",
      "for 2021-12-25, MAE is:17.65 & sMAPE is:9.15% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 13.67% & 0.87\n",
      "for 2021-12-26, MAE is:18.73 & sMAPE is:10.08% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 13.66% & 0.87\n",
      "for 2021-12-27, MAE is:24.48 & sMAPE is:13.25% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 13.66% & 0.87\n",
      "for 2021-12-28, MAE is:47.05 & sMAPE is:27.62% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 13.70% & 0.87\n",
      "for 2021-12-29, MAE is:21.04 & sMAPE is:12.53% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 13.70% & 0.87\n",
      "for 2021-12-30, MAE is:24.78 & sMAPE is:16.53% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.61 & 13.71% & 0.86\n",
      "for 2021-12-31, MAE is:9.50 & sMAPE is:7.03% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :10.60 & 13.69% & 0.86\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:45:25,123]\u001b[0m A new study created in RDB with name: NO_1_2022\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:45:53,120]\u001b[0m Trial 1 finished with value: 38.75577953928232 and parameters: {'n_hidden': 4, 'learning_rate': 0.0973477103893813, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07502033247844064, 'dropout_rate_Layer_2': 0.14704482713456205, 'dropout_rate_Layer_3': 0.23402746411166775, 'dropout_rate_Layer_4': 0.016089956353556725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08391093143675604, 'l1_Layer_2': 0.0009043307122111911, 'l1_Layer_3': 1.961799409877147e-05, 'l1_Layer_4': 0.010429784954695178, 'n_units_Layer_1': 295, 'n_units_Layer_2': 105, 'n_units_Layer_3': 60, 'n_units_Layer_4': 50}. Best is trial 1 with value: 38.75577953928232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.76 | sMAPE for Validation Set is: 54.70% | rMAE for Validation Set is: 2.24\n",
      "MAE for Test Set is: 156.91 | sMAPE for Test Set is: 123.97% | rMAE for Test Set is: 2.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:46:22,318]\u001b[0m Trial 2 finished with value: 27.150877248832415 and parameters: {'n_hidden': 4, 'learning_rate': 0.04739147315601457, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24065422986255755, 'dropout_rate_Layer_2': 0.26767731846982645, 'dropout_rate_Layer_3': 0.3031086812255178, 'dropout_rate_Layer_4': 0.1033721055815339, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.985058871597765e-05, 'l1_Layer_2': 0.0003143949946240317, 'l1_Layer_3': 0.012347721288721133, 'l1_Layer_4': 0.049755832476715195, 'n_units_Layer_1': 80, 'n_units_Layer_2': 200, 'n_units_Layer_3': 120, 'n_units_Layer_4': 75}. Best is trial 2 with value: 27.150877248832415.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.15 | sMAPE for Validation Set is: 32.59% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 139.54 | sMAPE for Test Set is: 100.21% | rMAE for Test Set is: 2.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:46:26,722]\u001b[0m Trial 0 finished with value: 28.351406194386755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009084023547991681, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05274877966575238, 'dropout_rate_Layer_2': 0.15842483921847467, 'dropout_rate_Layer_3': 0.1266690761616515, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010613641803830873, 'l1_Layer_2': 5.762501961039176e-05, 'l1_Layer_3': 1.7797155509455108e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 105}. Best is trial 2 with value: 27.150877248832415.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.35 | sMAPE for Validation Set is: 34.66% | rMAE for Validation Set is: 1.64\n",
      "MAE for Test Set is: 139.31 | sMAPE for Test Set is: 100.03% | rMAE for Test Set is: 2.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:46:31,465]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:46:34,370]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:46:36,892]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:46:37,480]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:46:42,614]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:46:47,674]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:19,781]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:24,650]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:47:46,476]\u001b[0m Trial 8 finished with value: 34.29270528082964 and parameters: {'n_hidden': 4, 'learning_rate': 0.024834990266437842, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28995051125752824, 'dropout_rate_Layer_2': 0.24689449976545852, 'dropout_rate_Layer_3': 0.27748113385228024, 'dropout_rate_Layer_4': 0.09949489927673594, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0010797593251528118, 'l1_Layer_2': 0.008662184587666103, 'l1_Layer_3': 0.024109881127037422, 'l1_Layer_4': 0.03708106998618107, 'n_units_Layer_1': 90, 'n_units_Layer_2': 160, 'n_units_Layer_3': 65, 'n_units_Layer_4': 260}. Best is trial 2 with value: 27.150877248832415.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.29 | sMAPE for Validation Set is: 45.39% | rMAE for Validation Set is: 1.99\n",
      "MAE for Test Set is: 150.11 | sMAPE for Test Set is: 114.14% | rMAE for Test Set is: 2.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:47:56,716]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:48:01,270]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:48:05,985]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:48:31,456]\u001b[0m Trial 16 finished with value: 34.21470665878424 and parameters: {'n_hidden': 4, 'learning_rate': 0.024369808266247524, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25245837558605594, 'dropout_rate_Layer_2': 0.13422710395218881, 'dropout_rate_Layer_3': 0.010344320321331237, 'dropout_rate_Layer_4': 0.07544367611254624, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0002570743186342314, 'l1_Layer_2': 0.0001585079355416767, 'l1_Layer_3': 0.019914860735573497, 'l1_Layer_4': 0.012470493966404069, 'n_units_Layer_1': 65, 'n_units_Layer_2': 115, 'n_units_Layer_3': 270, 'n_units_Layer_4': 295}. Best is trial 2 with value: 27.150877248832415.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.21 | sMAPE for Validation Set is: 45.05% | rMAE for Validation Set is: 1.98\n",
      "MAE for Test Set is: 150.56 | sMAPE for Test Set is: 114.94% | rMAE for Test Set is: 2.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:48:40,593]\u001b[0m Trial 12 finished with value: 30.384228308533825 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007837289289346907, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2248940746897175, 'dropout_rate_Layer_2': 0.05127184774246776, 'dropout_rate_Layer_3': 0.06855183239004754, 'dropout_rate_Layer_4': 0.3053081320567097, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0026040748914334185, 'l1_Layer_2': 0.00014482397443276221, 'l1_Layer_3': 2.764789849879179e-05, 'l1_Layer_4': 0.007550705480298683, 'n_units_Layer_1': 80, 'n_units_Layer_2': 140, 'n_units_Layer_3': 90, 'n_units_Layer_4': 285}. Best is trial 2 with value: 27.150877248832415.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.38 | sMAPE for Validation Set is: 38.00% | rMAE for Validation Set is: 1.76\n",
      "MAE for Test Set is: 143.87 | sMAPE for Test Set is: 105.86% | rMAE for Test Set is: 2.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:48:43,882]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:48:58,512]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:08,888]\u001b[0m Trial 17 finished with value: 24.079958746233462 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014181269762200035, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1821627200267583, 'dropout_rate_Layer_2': 0.37650146053815126, 'dropout_rate_Layer_3': 0.10313320966432614, 'dropout_rate_Layer_4': 0.00525043375196228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00045705485335025643, 'l1_Layer_2': 1.0777686836142447e-05, 'l1_Layer_3': 0.005308951492009144, 'l1_Layer_4': 0.00015709333055834653, 'n_units_Layer_1': 130, 'n_units_Layer_2': 105, 'n_units_Layer_3': 205, 'n_units_Layer_4': 120}. Best is trial 17 with value: 24.079958746233462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.08 | sMAPE for Validation Set is: 27.94% | rMAE for Validation Set is: 1.39\n",
      "MAE for Test Set is: 130.61 | sMAPE for Test Set is: 89.65% | rMAE for Test Set is: 2.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:49:20,754]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:23,417]\u001b[0m Trial 20 finished with value: 27.73883340636667 and parameters: {'n_hidden': 4, 'learning_rate': 0.012232819665480716, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1551235598155799, 'dropout_rate_Layer_2': 0.15229811775508165, 'dropout_rate_Layer_3': 0.12649923579167638, 'dropout_rate_Layer_4': 0.38147774656815625, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.1759377006685795e-05, 'l1_Layer_2': 0.0012862575482902507, 'l1_Layer_3': 1.1130030048359514e-05, 'l1_Layer_4': 0.00021930011239763692, 'n_units_Layer_1': 125, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285, 'n_units_Layer_4': 300}. Best is trial 17 with value: 24.079958746233462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.74 | sMAPE for Validation Set is: 34.03% | rMAE for Validation Set is: 1.61\n",
      "MAE for Test Set is: 137.77 | sMAPE for Test Set is: 98.50% | rMAE for Test Set is: 2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:49:27,847]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:30,813]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:38,665]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:40,943]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:46,037]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:50,973]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:51,150]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:58,835]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:49:58,881]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:05,882]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:06,224]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:13,033]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:47,488]\u001b[0m Trial 33 finished with value: 11.819950274373346 and parameters: {'n_hidden': 4, 'learning_rate': 0.010926017114635036, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3660910431563203, 'dropout_rate_Layer_2': 0.31707677162286607, 'dropout_rate_Layer_3': 0.2488423514085923, 'dropout_rate_Layer_4': 0.15418796861884113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5168264474604715e-05, 'l1_Layer_2': 0.00019080845025496948, 'l1_Layer_3': 0.052205344233206614, 'l1_Layer_4': 9.35547769744567e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 300, 'n_units_Layer_3': 135, 'n_units_Layer_4': 105}. Best is trial 33 with value: 11.819950274373346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.82 | sMAPE for Validation Set is: 14.81% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 38.09 | sMAPE for Test Set is: 23.39% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:50:52,770]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:57,858]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:50:57,964]\u001b[0m Trial 35 finished with value: 10.539957290130843 and parameters: {'n_hidden': 3, 'learning_rate': 0.010673745089829989, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016882941255909216, 'dropout_rate_Layer_2': 0.0640693390391406, 'dropout_rate_Layer_3': 0.17165324083458255, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.024643156403937896, 'l1_Layer_2': 0.06825470228997847, 'l1_Layer_3': 0.003657527624177775, 'n_units_Layer_1': 105, 'n_units_Layer_2': 215, 'n_units_Layer_3': 125}. Best is trial 35 with value: 10.539957290130843.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.54 | sMAPE for Validation Set is: 13.31% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.61 | sMAPE for Test Set is: 18.43% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:51:07,603]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:07,722]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:14,523]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:14,631]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:23,473]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:30,852]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:35,694]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:41,515]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:43,983]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:48,089]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:50,997]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:51,363]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:51:58,877]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:03,246]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:09,787]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:14,093]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:18,555]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:23,792]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:29,352]\u001b[0m Trial 52 finished with value: 10.84620482559311 and parameters: {'n_hidden': 3, 'learning_rate': 0.014427157427793401, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03334964151492225, 'dropout_rate_Layer_2': 0.09503781452385276, 'dropout_rate_Layer_3': 0.1956506686295492, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09474015440826375, 'l1_Layer_2': 0.051340370499664736, 'l1_Layer_3': 0.005239591106989592, 'n_units_Layer_1': 75, 'n_units_Layer_2': 215, 'n_units_Layer_3': 55}. Best is trial 35 with value: 10.539957290130843.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.85 | sMAPE for Validation Set is: 13.70% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 27.72 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:52:36,038]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:39,245]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:44,184]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:51,217]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:52:56,622]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:53:01,975]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:53:17,011]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:53:21,478]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:53:28,903]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:53:34,199]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:53:43,726]\u001b[0m Trial 59 finished with value: 30.74186272899976 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027997038633920707, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.046455847684781795, 'dropout_rate_Layer_2': 0.10039933328187348, 'dropout_rate_Layer_3': 0.23351261814474042, 'dropout_rate_Layer_4': 0.26153180498149736, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 5.435772335259065e-05, 'l1_Layer_2': 5.2187833665242166e-05, 'l1_Layer_3': 1.803798996992767e-05, 'l1_Layer_4': 0.04054987892899491, 'n_units_Layer_1': 125, 'n_units_Layer_2': 135, 'n_units_Layer_3': 130, 'n_units_Layer_4': 215}. Best is trial 35 with value: 10.539957290130843.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.74 | sMAPE for Validation Set is: 38.72% | rMAE for Validation Set is: 1.78\n",
      "MAE for Test Set is: 143.70 | sMAPE for Test Set is: 105.66% | rMAE for Test Set is: 2.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:53:48,943]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:53:53,844]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:13,678]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:19,004]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.77 | sMAPE for Validation Set is: 13.53% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.70 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:54:20,842]\u001b[0m Trial 70 finished with value: 10.77479076970667 and parameters: {'n_hidden': 3, 'learning_rate': 0.010852140251833661, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.060968752406407534, 'dropout_rate_Layer_2': 0.04893716841176876, 'dropout_rate_Layer_3': 0.27850276715484396, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01506381732138983, 'l1_Layer_2': 0.00010845084422704425, 'l1_Layer_3': 0.0004299022918555224, 'n_units_Layer_1': 255, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115}. Best is trial 35 with value: 10.539957290130843.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:25,055]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:29,882]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:32,359]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:36,725]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:38,995]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:41,528]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:44,046]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:47,104]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:51,122]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:58,768]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:54:58,965]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:08,228]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:11,743]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:18,269]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:21,601]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:21,758]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:28,652]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:32,012]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:36,283]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:42,139]\u001b[0m Trial 89 finished with value: 30.753147443970267 and parameters: {'n_hidden': 3, 'learning_rate': 0.0073701755932937115, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1399749085592017, 'dropout_rate_Layer_2': 0.08181095403918062, 'dropout_rate_Layer_3': 0.08946265908738399, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005396939757172379, 'l1_Layer_2': 0.002621568931052848, 'l1_Layer_3': 0.092568800664955, 'n_units_Layer_1': 50, 'n_units_Layer_2': 105, 'n_units_Layer_3': 250}. Best is trial 35 with value: 10.539957290130843.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.75 | sMAPE for Validation Set is: 38.65% | rMAE for Validation Set is: 1.78\n",
      "MAE for Test Set is: 144.97 | sMAPE for Test Set is: 107.24% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:55:47,176]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:54,300]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:55:57,415]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:12,561]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:16,817]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:19,889]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:21,917]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:26,594]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:34,465]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:41,440]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:51,799]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:56:57,156]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:57:04,543]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:57:08,805]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:57:13,792]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:57:23,971]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:57:31,411]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:58:26,524]\u001b[0m Trial 102 finished with value: 10.264103907837326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0042610038416829735, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0368886060403737, 'dropout_rate_Layer_2': 0.022392271789873887, 'dropout_rate_Layer_3': 0.10888922404371439, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018083126447908135, 'l1_Layer_2': 0.0008553641500486864, 'l1_Layer_3': 0.005910174489328339, 'n_units_Layer_1': 50, 'n_units_Layer_2': 295, 'n_units_Layer_3': 50}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.26 | sMAPE for Validation Set is: 12.84% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.74 | sMAPE for Test Set is: 17.44% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 19:58:33,497]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:58:36,536]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:58:43,089]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:58:47,890]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:58:53,828]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:58:58,596]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:03,850]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:08,852]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:13,826]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:25,855]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:33,763]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:45,569]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:48,680]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:55,138]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 19:59:55,505]\u001b[0m Trial 122 finished with value: 10.884130211249412 and parameters: {'n_hidden': 4, 'learning_rate': 0.031878557285005917, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0865261437230108, 'dropout_rate_Layer_2': 0.39871226450229713, 'dropout_rate_Layer_3': 0.3049973507597259, 'dropout_rate_Layer_4': 0.3654907457095927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001824285703745975, 'l1_Layer_2': 0.001317504910868276, 'l1_Layer_3': 0.0009720781082255504, 'l1_Layer_4': 0.06348487638106888, 'n_units_Layer_1': 140, 'n_units_Layer_2': 55, 'n_units_Layer_3': 50, 'n_units_Layer_4': 135}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.88 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 31.49 | sMAPE for Test Set is: 19.99% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:00:02,433]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:00:04,117]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:00:13,320]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:00:18,272]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:00:23,160]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:00:43,207]\u001b[0m Trial 132 finished with value: 24.876490312208674 and parameters: {'n_hidden': 3, 'learning_rate': 0.0895319280014048, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3414716349224447, 'dropout_rate_Layer_2': 0.18278215278308083, 'dropout_rate_Layer_3': 0.01729864824214964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003515734220617722, 'l1_Layer_2': 2.903401158489365e-05, 'l1_Layer_3': 5.73126330155519e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 165, 'n_units_Layer_3': 230}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.88 | sMAPE for Validation Set is: 32.94% | rMAE for Validation Set is: 1.44\n",
      "MAE for Test Set is: 99.43 | sMAPE for Test Set is: 62.45% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:00:46,609]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:00:49,209]\u001b[0m Trial 129 finished with value: 27.950160528880925 and parameters: {'n_hidden': 4, 'learning_rate': 0.016615069049865608, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17657609950680558, 'dropout_rate_Layer_2': 0.13702769244602134, 'dropout_rate_Layer_3': 0.35100222172134, 'dropout_rate_Layer_4': 0.18177996198491422, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00010913408753020016, 'l1_Layer_2': 0.0002917810545701502, 'l1_Layer_3': 7.86740012450597e-05, 'l1_Layer_4': 4.622058640390526e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 205, 'n_units_Layer_4': 80}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.95 | sMAPE for Validation Set is: 33.95% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 139.60 | sMAPE for Test Set is: 100.50% | rMAE for Test Set is: 2.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:00:51,031]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:00:58,632]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:00:58,826]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:05,573]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:08,840]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:12,719]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:17,670]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:25,485]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:30,932]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:35,173]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:40,716]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:45,747]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:01:52,250]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:02:09,580]\u001b[0m Trial 148 finished with value: 10.846550881831561 and parameters: {'n_hidden': 3, 'learning_rate': 0.017357754276206543, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031760308522238614, 'dropout_rate_Layer_2': 0.1040213572175181, 'dropout_rate_Layer_3': 0.12301433303326664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05018227744375238, 'l1_Layer_2': 0.05378011863738048, 'l1_Layer_3': 1.117837367860858e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 190, 'n_units_Layer_3': 105}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.85 | sMAPE for Validation Set is: 13.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 29.31 | sMAPE for Test Set is: 18.79% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:02:14,719]\u001b[0m Trial 142 finished with value: 11.654408358817216 and parameters: {'n_hidden': 3, 'learning_rate': 0.015061092963151912, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24460932730593873, 'dropout_rate_Layer_2': 0.10983964502408958, 'dropout_rate_Layer_3': 0.02289566181395583, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002270730671524907, 'l1_Layer_2': 0.0017299393559175728, 'l1_Layer_3': 0.00011405334009793904, 'n_units_Layer_1': 160, 'n_units_Layer_2': 130, 'n_units_Layer_3': 240}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.65 | sMAPE for Validation Set is: 14.84% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 39.15 | sMAPE for Test Set is: 22.49% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:02:22,441]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:02:27,968]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:02:43,281]\u001b[0m Trial 149 finished with value: 11.130695567317515 and parameters: {'n_hidden': 3, 'learning_rate': 0.01772290892190827, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11437186683174304, 'dropout_rate_Layer_2': 0.3973711313581502, 'dropout_rate_Layer_3': 0.3968695692572541, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2956173316151086e-05, 'l1_Layer_2': 0.0011321438048936048, 'l1_Layer_3': 0.0006480986483998341, 'n_units_Layer_1': 50, 'n_units_Layer_2': 240, 'n_units_Layer_3': 270}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.13 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 31.17 | sMAPE for Test Set is: 19.81% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:02:46,074]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:03:00,350]\u001b[0m Trial 152 finished with value: 11.338805396081796 and parameters: {'n_hidden': 3, 'learning_rate': 0.02361772677565136, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12363371419403246, 'dropout_rate_Layer_2': 0.39983446551526786, 'dropout_rate_Layer_3': 0.39389053170639915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1265514489501053e-05, 'l1_Layer_2': 0.0009340876999478324, 'l1_Layer_3': 0.0004422431224914526, 'n_units_Layer_1': 50, 'n_units_Layer_2': 60, 'n_units_Layer_3': 285}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.34 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 30.27 | sMAPE for Test Set is: 19.49% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:03:03,132]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:03:05,738]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:03:12,760]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:03:22,476]\u001b[0m Trial 154 finished with value: 11.323411099799742 and parameters: {'n_hidden': 3, 'learning_rate': 0.018663418440116736, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09997586729712617, 'dropout_rate_Layer_2': 0.3963411319545532, 'dropout_rate_Layer_3': 0.38919989083740686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1856336924492498e-05, 'l1_Layer_2': 0.0011263216199720871, 'l1_Layer_3': 0.0005316398665711038, 'n_units_Layer_1': 55, 'n_units_Layer_2': 235, 'n_units_Layer_3': 300}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.32 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 33.53 | sMAPE for Test Set is: 21.11% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:03:32,528]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:03:42,197]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:03:47,185]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:03:50,299]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:03:57,292]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:04,527]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:11,716]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:12,534]\u001b[0m Trial 160 finished with value: 11.561594671199664 and parameters: {'n_hidden': 4, 'learning_rate': 0.01133750059406951, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34022089861193805, 'dropout_rate_Layer_2': 0.17773035629301157, 'dropout_rate_Layer_3': 0.34740674685389716, 'dropout_rate_Layer_4': 0.3933168666685805, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003103773095947678, 'l1_Layer_2': 0.0036508922217046995, 'l1_Layer_3': 0.003032453799260382, 'l1_Layer_4': 0.0011672171212969622, 'n_units_Layer_1': 155, 'n_units_Layer_2': 230, 'n_units_Layer_3': 90, 'n_units_Layer_4': 120}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.56 | sMAPE for Validation Set is: 14.81% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 31.50 | sMAPE for Test Set is: 19.83% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:04:30,461]\u001b[0m Trial 166 finished with value: 25.55902375812637 and parameters: {'n_hidden': 3, 'learning_rate': 0.039907024456257136, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1493470723924598, 'dropout_rate_Layer_2': 0.32558219999669447, 'dropout_rate_Layer_3': 0.3209847582047268, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.056771354087956e-05, 'l1_Layer_2': 0.00419916614552179, 'l1_Layer_3': 0.00019882102924829022, 'n_units_Layer_1': 125, 'n_units_Layer_2': 215, 'n_units_Layer_3': 210}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.56 | sMAPE for Validation Set is: 32.27% | rMAE for Validation Set is: 1.48\n",
      "MAE for Test Set is: 117.00 | sMAPE for Test Set is: 75.59% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:04:33,491]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:36,339]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:40,292]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:50,657]\u001b[0m Trial 170 finished with value: 12.216791368045842 and parameters: {'n_hidden': 3, 'learning_rate': 0.02933329669027071, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04639287361387315, 'dropout_rate_Layer_2': 0.09439928880720172, 'dropout_rate_Layer_3': 0.15821104487988022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.048836695605575166, 'l1_Layer_2': 0.07049486325557695, 'l1_Layer_3': 1.2092725588839352e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 220, 'n_units_Layer_3': 120}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.22 | sMAPE for Validation Set is: 15.87% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 32.81 | sMAPE for Test Set is: 21.01% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:04:53,805]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:04:57,918]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:05:20,797]\u001b[0m Trial 174 finished with value: 10.613080330276846 and parameters: {'n_hidden': 3, 'learning_rate': 0.008766022969374187, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17162312309716168, 'dropout_rate_Layer_2': 0.07856244972493866, 'dropout_rate_Layer_3': 0.0723545279262233, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004023475240691899, 'l1_Layer_2': 0.002466484871016472, 'l1_Layer_3': 0.06249841825130573, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 260}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.61 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.12 | sMAPE for Test Set is: 18.20% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:05:23,720]\u001b[0m Trial 172 finished with value: 10.468840373952075 and parameters: {'n_hidden': 3, 'learning_rate': 0.008285951050987941, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17182151393418593, 'dropout_rate_Layer_2': 0.10691788587384696, 'dropout_rate_Layer_3': 0.07521046666965846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004072597526126377, 'l1_Layer_2': 0.0032973573471550685, 'l1_Layer_3': 0.00012091173660819194, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 260}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.47 | sMAPE for Validation Set is: 13.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.42 | sMAPE for Test Set is: 17.69% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:05:25,859]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:05:28,587]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:05:35,814]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:05:55,357]\u001b[0m Trial 177 finished with value: 10.4190379918221 and parameters: {'n_hidden': 3, 'learning_rate': 0.009268700905985328, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13405843420064387, 'dropout_rate_Layer_2': 0.07552938014401593, 'dropout_rate_Layer_3': 0.07594771100505154, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013935224829933386, 'l1_Layer_2': 0.004220970960743621, 'l1_Layer_3': 0.00014270272816700426, 'n_units_Layer_1': 105, 'n_units_Layer_2': 135, 'n_units_Layer_3': 260}. Best is trial 102 with value: 10.264103907837326.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.42 | sMAPE for Validation Set is: 13.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.01 | sMAPE for Test Set is: 17.52% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:05:58,600]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:08,554]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:18,436]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:41,049]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:43,750]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:48,356]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:06:55,170]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:07:02,572]\u001b[0m Trial 182 finished with value: 10.115143820515781 and parameters: {'n_hidden': 3, 'learning_rate': 0.014738007968662991, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11016937533301677, 'dropout_rate_Layer_2': 0.11111637916038403, 'dropout_rate_Layer_3': 0.07014212275421232, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014061466961038363, 'l1_Layer_2': 0.007194153478965814, 'l1_Layer_3': 0.00013783226309596288, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 260}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.12 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.07 | sMAPE for Test Set is: 17.47% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:07:07,918]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:07:14,949]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:07:29,773]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:07:34,623]\u001b[0m Trial 188 finished with value: 10.425735954909795 and parameters: {'n_hidden': 3, 'learning_rate': 0.01540474331575297, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10942948560307184, 'dropout_rate_Layer_2': 0.041257559136629, 'dropout_rate_Layer_3': 0.07530550728161897, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015049314723158504, 'l1_Layer_2': 0.021661618244753517, 'l1_Layer_3': 0.0001333980065086276, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 260}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.43 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.63 | sMAPE for Test Set is: 17.84% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:07:44,471]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:07:55,048]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:07:59,108]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:05,971]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:08,880]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:13,614]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:16,420]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:21,245]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:33,316]\u001b[0m Trial 192 finished with value: 11.642977922517716 and parameters: {'n_hidden': 4, 'learning_rate': 0.006934264507878429, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006369302726399184, 'dropout_rate_Layer_2': 0.28192177379552286, 'dropout_rate_Layer_3': 0.2031880457858168, 'dropout_rate_Layer_4': 0.39616579830805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001398971327765145, 'l1_Layer_2': 0.09818806290931237, 'l1_Layer_3': 0.002359056288097224, 'l1_Layer_4': 1.1607650839365938e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 280, 'n_units_Layer_3': 115, 'n_units_Layer_4': 160}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.64 | sMAPE for Validation Set is: 14.62% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 37.17 | sMAPE for Test Set is: 22.90% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:08:36,736]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:38,708]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:41,196]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:46,542]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:48,730]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:53,340]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:08:58,189]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:09:01,081]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:09:29,781]\u001b[0m Trial 209 finished with value: 10.416710167978954 and parameters: {'n_hidden': 3, 'learning_rate': 0.011267697097213866, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03178642649127297, 'dropout_rate_Layer_2': 0.06536860476417561, 'dropout_rate_Layer_3': 0.15274507353778063, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031157473986069576, 'l1_Layer_2': 0.035988367487030944, 'l1_Layer_3': 0.0008157482296654169, 'n_units_Layer_1': 90, 'n_units_Layer_2': 140, 'n_units_Layer_3': 225}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.42 | sMAPE for Validation Set is: 13.03% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.38 | sMAPE for Test Set is: 17.80% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:09:59,724]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:10:03,913]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:10:14,175]\u001b[0m Trial 205 finished with value: 11.480116710147824 and parameters: {'n_hidden': 4, 'learning_rate': 0.010951400037143554, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39549225971683005, 'dropout_rate_Layer_2': 0.23890378384739963, 'dropout_rate_Layer_3': 0.2801603831898503, 'dropout_rate_Layer_4': 0.39386350331592856, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01640692366845276, 'l1_Layer_2': 0.0007320657287477764, 'l1_Layer_3': 0.000369264895851975, 'l1_Layer_4': 0.00023250618286798895, 'n_units_Layer_1': 275, 'n_units_Layer_2': 280, 'n_units_Layer_3': 105, 'n_units_Layer_4': 110}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.48 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 42.05 | sMAPE for Test Set is: 25.10% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:10:30,871]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:10:41,036]\u001b[0m Trial 213 finished with value: 10.293589392214514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0086374648681594, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049632312821018765, 'dropout_rate_Layer_2': 0.04606405676985541, 'dropout_rate_Layer_3': 0.1576723036157794, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004000290628222626, 'l1_Layer_2': 0.015144367416171069, 'l1_Layer_3': 0.00031938857202740405, 'n_units_Layer_1': 110, 'n_units_Layer_2': 145, 'n_units_Layer_3': 260}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.29 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.10 | sMAPE for Test Set is: 17.61% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:10:44,252]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:04,497]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:28,056]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:11:57,920]\u001b[0m Trial 218 finished with value: 10.567709497366538 and parameters: {'n_hidden': 3, 'learning_rate': 0.011278591646181738, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060579884188531025, 'dropout_rate_Layer_2': 0.04921330665348174, 'dropout_rate_Layer_3': 0.19550084187613725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005144113204740557, 'l1_Layer_2': 0.010064721559566548, 'l1_Layer_3': 0.0006626723150979464, 'n_units_Layer_1': 95, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.57 | sMAPE for Validation Set is: 13.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.48 | sMAPE for Test Set is: 17.97% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:12:13,898]\u001b[0m Trial 219 finished with value: 10.795368301606489 and parameters: {'n_hidden': 3, 'learning_rate': 0.021758303550581393, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03883822686812425, 'dropout_rate_Layer_2': 0.023797538392390793, 'dropout_rate_Layer_3': 0.15658002399027007, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.020161252475542412, 'l1_Layer_2': 0.03624257729973756, 'l1_Layer_3': 0.00017815340256510648, 'n_units_Layer_1': 125, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.80 | sMAPE for Validation Set is: 13.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 28.27 | sMAPE for Test Set is: 18.31% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:12:30,410]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:37,696]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:40,960]\u001b[0m Trial 216 finished with value: 12.260063313452227 and parameters: {'n_hidden': 4, 'learning_rate': 0.004391862966054724, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3287427806632081, 'dropout_rate_Layer_2': 0.24690573640012387, 'dropout_rate_Layer_3': 0.287522356850522, 'dropout_rate_Layer_4': 0.3984457753938028, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01675772466463255, 'l1_Layer_2': 0.0008016513942452226, 'l1_Layer_3': 6.560967136110591e-05, 'l1_Layer_4': 0.005040372214801021, 'n_units_Layer_1': 205, 'n_units_Layer_2': 275, 'n_units_Layer_3': 100, 'n_units_Layer_4': 180}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.26 | sMAPE for Validation Set is: 16.10% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 32.10 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:12:42,959]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:47,767]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:50,945]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:55,304]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:12:55,973]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:00,537]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:02,503]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:05,113]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:07,487]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:10,551]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:13,035]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:18,687]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:23,451]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:24,698]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:30,966]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:35,834]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:40,042]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:13:54,283]\u001b[0m Trial 236 finished with value: 10.6641910955937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0066568081496835635, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006752320030864456, 'dropout_rate_Layer_2': 0.06684786126337106, 'dropout_rate_Layer_3': 0.21823687271472306, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023146328932121827, 'l1_Layer_2': 0.04803874078203936, 'l1_Layer_3': 9.499732213092748e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 225}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.66 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 27.65 | sMAPE for Test Set is: 18.03% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:13:57,407]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:03,936]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:08,763]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:11,651]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:14,079]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:16,611]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:18,670]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:23,511]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:23,641]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:29,092]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:33,942]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:38,323]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:45,413]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:48,625]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:51,250]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:51,332]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:14:58,016]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:10,746]\u001b[0m Trial 257 finished with value: 10.808534769647837 and parameters: {'n_hidden': 3, 'learning_rate': 0.01925870458959178, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08775331260173756, 'dropout_rate_Layer_2': 0.05101896968083921, 'dropout_rate_Layer_3': 0.0990579200596323, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0041539716635838175, 'l1_Layer_2': 0.010098988830034746, 'l1_Layer_3': 0.00029293967694782737, 'n_units_Layer_1': 100, 'n_units_Layer_2': 140, 'n_units_Layer_3': 255}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.81 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 28.28 | sMAPE for Test Set is: 18.38% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:15:14,615]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:24,431]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:45,157]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:47,299]\u001b[0m Trial 260 finished with value: 11.46272617486602 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026719387020922468, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13506039484398294, 'dropout_rate_Layer_2': 0.24620542679834553, 'dropout_rate_Layer_3': 0.3554108610246189, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.435987682530957e-05, 'l1_Layer_2': 0.0019204245544143963, 'l1_Layer_3': 0.0001526989448803178, 'n_units_Layer_1': 135, 'n_units_Layer_2': 100, 'n_units_Layer_3': 180}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.46 | sMAPE for Validation Set is: 14.72% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 32.75 | sMAPE for Test Set is: 20.91% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:15:55,091]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:15:59,600]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:06,906]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:12,487]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:17,158]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:21,302]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:29,238]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:33,816]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:34,108]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:40,770]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:46,233]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:53,466]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:16:58,303]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:02,734]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:07,556]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:07,725]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:15,408]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:15,453]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:21,816]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:21,914]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:29,210]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:46,981]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:49,834]\u001b[0m Trial 283 finished with value: 11.320387906983798 and parameters: {'n_hidden': 3, 'learning_rate': 0.015243407998146096, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09683765410061924, 'dropout_rate_Layer_2': 0.3906722685409014, 'dropout_rate_Layer_3': 0.39331671346436387, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0899553631721519e-05, 'l1_Layer_2': 0.0007737159060850445, 'l1_Layer_3': 0.0004374965300536388, 'n_units_Layer_1': 50, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.32 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 32.24 | sMAPE for Test Set is: 20.44% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:17:54,030]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:56,446]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:17:59,779]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:07,260]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:09,517]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:14,662]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:18,833]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:23,723]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:26,555]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:36,576]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:41,059]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:45,430]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:54,517]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:18:59,668]\u001b[0m Trial 295 finished with value: 11.31335824688498 and parameters: {'n_hidden': 3, 'learning_rate': 0.012591621554138384, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07683254690929386, 'dropout_rate_Layer_2': 0.3706141229673961, 'dropout_rate_Layer_3': 0.3519316538943663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0536928695694523e-05, 'l1_Layer_2': 0.0005670916558615513, 'l1_Layer_3': 0.0010859430742540834, 'n_units_Layer_1': 70, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.31 | sMAPE for Validation Set is: 14.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 30.53 | sMAPE for Test Set is: 19.70% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:19:03,340]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:15,778]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:38,701]\u001b[0m Trial 301 finished with value: 10.793702933464195 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021347982824689673, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19045358634771378, 'dropout_rate_Layer_2': 0.39345006963289064, 'dropout_rate_Layer_3': 0.29829909805792687, 'dropout_rate_Layer_4': 0.14719976147401498, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.047190988629401465, 'l1_Layer_2': 0.0002113230661733705, 'l1_Layer_3': 0.027719670607501325, 'l1_Layer_4': 0.0008716581767577773, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 125, 'n_units_Layer_4': 130}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.79 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 28.02 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:19:44,131]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:44,377]\u001b[0m Trial 302 finished with value: 11.150972323728451 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021365730534486918, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3631269674251511, 'dropout_rate_Layer_2': 0.3933621910420373, 'dropout_rate_Layer_3': 0.2983617979652557, 'dropout_rate_Layer_4': 0.17479025052964514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05511404508737886, 'l1_Layer_2': 5.214342040380506e-05, 'l1_Layer_3': 0.0007180501549346665, 'l1_Layer_4': 0.0007368238677472458, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 225, 'n_units_Layer_4': 130}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.15 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 32.69 | sMAPE for Test Set is: 20.48% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:19:51,244]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:54,380]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:19:57,296]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:13,626]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:26,681]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:29,589]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:34,047]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:43,632]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:46,631]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:50,613]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:20:51,020]\u001b[0m Trial 309 finished with value: 10.527450384782902 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014155278164353984, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17194933891708666, 'dropout_rate_Layer_2': 0.38981965919507294, 'dropout_rate_Layer_3': 0.30038832663706866, 'dropout_rate_Layer_4': 0.21340456967096189, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05478221758649869, 'l1_Layer_2': 1.503960523342317e-05, 'l1_Layer_3': 0.0006627655917273925, 'l1_Layer_4': 0.0006376662500445926, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220, 'n_units_Layer_4': 140}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.53 | sMAPE for Validation Set is: 13.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.40 | sMAPE for Test Set is: 17.70% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:20:55,929]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:01,129]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:07,385]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:10,825]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:17,284]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:22,374]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:27,228]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:30,441]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:34,272]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:37,016]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:40,922]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:46,117]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:21:50,555]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:03,709]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:10,484]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:17,854]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:36,893]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:43,497]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:22:46,753]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:06,718]\u001b[0m Trial 332 finished with value: 10.474988268997862 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009316661103433646, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.051953002095576316, 'dropout_rate_Layer_2': 0.3255790070350144, 'dropout_rate_Layer_3': 0.05666477859924299, 'dropout_rate_Layer_4': 0.2698721604195274, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.030320905924701477, 'l1_Layer_2': 9.083873661266518e-05, 'l1_Layer_3': 4.0170129013514156e-05, 'l1_Layer_4': 0.0003199189395642404, 'n_units_Layer_1': 75, 'n_units_Layer_2': 245, 'n_units_Layer_3': 275, 'n_units_Layer_4': 200}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.47 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.60 | sMAPE for Test Set is: 17.64% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:23:24,069]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:33,474]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:38,006]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:38,848]\u001b[0m Trial 335 finished with value: 10.77557632365484 and parameters: {'n_hidden': 3, 'learning_rate': 0.011758818139626332, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18334945892792448, 'dropout_rate_Layer_2': 0.3677351149017128, 'dropout_rate_Layer_3': 0.3032302023433353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3809721713755353e-05, 'l1_Layer_2': 0.0004941354038824746, 'l1_Layer_3': 0.001124708325194363, 'n_units_Layer_1': 105, 'n_units_Layer_2': 260, 'n_units_Layer_3': 50}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.78 | sMAPE for Validation Set is: 13.57% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.28 | sMAPE for Test Set is: 18.85% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:23:46,289]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:51,063]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:23:55,476]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:01,268]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:03,805]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:10,747]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:15,338]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:35,511]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:45,602]\u001b[0m Trial 347 finished with value: 10.356866503161427 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022356919919235456, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06464466063568425, 'dropout_rate_Layer_2': 0.3795315499764769, 'dropout_rate_Layer_3': 0.0735518585985527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026214595649235947, 'l1_Layer_2': 5.21357301908298e-05, 'l1_Layer_3': 2.0363468064215738e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 240, 'n_units_Layer_3': 270}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.36 | sMAPE for Validation Set is: 12.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 26.89 | sMAPE for Test Set is: 17.35% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:24:45,918]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:24:57,044]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:01,972]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:05,209]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:27,113]\u001b[0m Trial 350 finished with value: 10.381982246617367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012924565001530065, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06469374247933743, 'dropout_rate_Layer_2': 0.3337846573011542, 'dropout_rate_Layer_3': 0.07757150302987964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008900931101243561, 'l1_Layer_2': 0.00011173107936678164, 'l1_Layer_3': 2.950444833842016e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.38 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.30 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:25:29,690]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:32,194]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:25:36,953]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:29,008]\u001b[0m Trial 357 finished with value: 10.20745192810144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012657931270874802, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06275460882288321, 'dropout_rate_Layer_2': 0.327012623705888, 'dropout_rate_Layer_3': 0.06269251980747455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007513224025694628, 'l1_Layer_2': 9.877011675490767e-05, 'l1_Layer_3': 3.391624204172418e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.21 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.69 | sMAPE for Test Set is: 17.40% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:26:33,981]\u001b[0m Trial 356 finished with value: 10.23745888989731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007305285886479387, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06369644148486397, 'dropout_rate_Layer_2': 0.3286470143356825, 'dropout_rate_Layer_3': 0.04871062459078265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006730937207011114, 'l1_Layer_2': 3.277526423662772e-05, 'l1_Layer_3': 2.4301845537857283e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 215, 'n_units_Layer_3': 275}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.24 | sMAPE for Validation Set is: 12.74% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.71 | sMAPE for Test Set is: 17.33% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:26:36,490]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:26:56,424]\u001b[0m Trial 360 finished with value: 10.657187482373898 and parameters: {'n_hidden': 3, 'learning_rate': 0.007605877339424635, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04652530077129279, 'dropout_rate_Layer_2': 0.10865310693845343, 'dropout_rate_Layer_3': 0.08729810591358264, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002686957259822042, 'l1_Layer_2': 0.017942803194208157, 'l1_Layer_3': 6.826616500831701e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 180, 'n_units_Layer_3': 135}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.66 | sMAPE for Validation Set is: 13.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.16 | sMAPE for Test Set is: 18.31% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:26:58,903]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:03,207]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:05,967]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:06,395]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:14,863]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:21,825]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:21,917]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:28,653]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:35,421]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:40,946]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:43,579]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:43,724]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:51,229]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:51,381]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:27:59,083]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:28:11,941]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:28:16,879]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:28:51,531]\u001b[0m Trial 374 finished with value: 10.276237656719415 and parameters: {'n_hidden': 3, 'learning_rate': 0.00075440088150644, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08244040438054745, 'dropout_rate_Layer_2': 0.2942951729082298, 'dropout_rate_Layer_3': 0.04798487713077337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005303092903351426, 'l1_Layer_2': 7.117292171178746e-05, 'l1_Layer_3': 1.0262422946158437e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 240, 'n_units_Layer_3': 285}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.28 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 26.99 | sMAPE for Test Set is: 17.51% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:28:58,841]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:12,181]\u001b[0m Trial 378 finished with value: 10.278688133610915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007409262946971336, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07686466370762493, 'dropout_rate_Layer_2': 0.2880650422546713, 'dropout_rate_Layer_3': 0.05223275875175854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006304189804683553, 'l1_Layer_2': 8.097010274952608e-05, 'l1_Layer_3': 1.0541899071197118e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 240, 'n_units_Layer_3': 285}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.28 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 26.95 | sMAPE for Test Set is: 17.32% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:29:17,052]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:22,047]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:32,044]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:39,288]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:39,379]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:46,302]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:49,355]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:29:56,264]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:01,564]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:08,834]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:10,983]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:15,833]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:19,104]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:23,609]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:26,638]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:33,614]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:38,130]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:50,761]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:30:53,584]\u001b[0m Trial 396 finished with value: 11.336617718471052 and parameters: {'n_hidden': 3, 'learning_rate': 0.01744476789087126, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11472705684100389, 'dropout_rate_Layer_2': 0.37851207384316327, 'dropout_rate_Layer_3': 0.33946764976669563, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.944819640649883e-05, 'l1_Layer_2': 0.0012526915026541455, 'l1_Layer_3': 0.000822757208716127, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.34 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 30.32 | sMAPE for Test Set is: 19.48% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:30:58,040]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:01,158]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:05,491]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:08,545]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:10,229]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:13,325]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:13,748]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:18,982]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:21,896]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:43,976]\u001b[0m Trial 407 finished with value: 10.675505542826164 and parameters: {'n_hidden': 3, 'learning_rate': 0.007681980975170069, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.177669507730572, 'dropout_rate_Layer_2': 0.05830277766706715, 'dropout_rate_Layer_3': 0.09304900022174514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002113335950921727, 'l1_Layer_2': 0.019262720752186976, 'l1_Layer_3': 0.0007360951802849066, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 215}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.68 | sMAPE for Validation Set is: 13.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.28 | sMAPE for Test Set is: 18.30% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:31:49,095]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:54,649]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:31:57,971]\u001b[0m Trial 409 finished with value: 10.879794505206343 and parameters: {'n_hidden': 3, 'learning_rate': 0.011251798636510891, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0892454549684008, 'dropout_rate_Layer_2': 0.30259046762693975, 'dropout_rate_Layer_3': 0.37484152951503447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.591854305477526e-05, 'l1_Layer_2': 0.00020975373305105513, 'l1_Layer_3': 0.00010323253288888747, 'n_units_Layer_1': 90, 'n_units_Layer_2': 250, 'n_units_Layer_3': 100}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.88 | sMAPE for Validation Set is: 13.75% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 29.70 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:32:02,301]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:07,672]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:12,905]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:13,220]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:17,826]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:20,495]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:22,638]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:23,078]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:28,230]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:30,475]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:33,010]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:35,457]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:40,205]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:42,776]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:45,099]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:47,664]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:50,242]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:52,492]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:32:55,488]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:33:30,431]\u001b[0m Trial 431 finished with value: 10.359414672887082 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016151312635799067, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023805196885659567, 'dropout_rate_Layer_2': 0.35525400470733165, 'dropout_rate_Layer_3': 0.11593235024895468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008148020447463723, 'l1_Layer_2': 3.162986394071595e-05, 'l1_Layer_3': 1.752552836957791e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 235, 'n_units_Layer_3': 240}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.36 | sMAPE for Validation Set is: 12.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.16 | sMAPE for Test Set is: 17.71% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:33:35,673]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:33:38,131]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:33:45,261]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:33:57,817]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:00,768]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:09,875]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:13,186]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:27,024]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:31,367]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:33,871]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:38,480]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:42,890]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:47,850]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:50,951]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:34:55,414]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:02,706]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:05,953]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:15,422]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:28,027]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:33,221]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:38,330]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:35:43,177]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:08,644]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:23,042]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:27,752]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:30,878]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:35,383]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:39,483]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:43,790]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:36:49,317]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:37:35,969]\u001b[0m Trial 463 finished with value: 10.166069578476238 and parameters: {'n_hidden': 3, 'learning_rate': 0.00256571894428738, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025409191663013288, 'dropout_rate_Layer_2': 0.3002047299975489, 'dropout_rate_Layer_3': 0.039239655888824075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010402977015382434, 'l1_Layer_2': 7.578767913473846e-05, 'l1_Layer_3': 1.5583083428815678e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.17 | sMAPE for Validation Set is: 12.65% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.68 | sMAPE for Test Set is: 17.20% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:37:38,932]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:37:43,696]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:37:47,972]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:37:51,306]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:20,553]\u001b[0m Trial 468 finished with value: 10.547022814626358 and parameters: {'n_hidden': 3, 'learning_rate': 0.003276770526837174, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008350927119011586, 'dropout_rate_Layer_2': 0.27271933859415554, 'dropout_rate_Layer_3': 0.037648515162012106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013829610707054608, 'l1_Layer_2': 6.96285280810132e-05, 'l1_Layer_3': 1.4096352298075219e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.55 | sMAPE for Validation Set is: 13.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.59 | sMAPE for Test Set is: 18.01% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:38:23,738]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:23,799]\u001b[0m Trial 432 finished with value: 10.701377239982065 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005698840298683613, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03787757327079466, 'dropout_rate_Layer_2': 0.304186545525174, 'dropout_rate_Layer_3': 0.3725466599827636, 'dropout_rate_Layer_4': 0.09877551196977657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.693407149786113e-05, 'l1_Layer_2': 0.00022147509628211805, 'l1_Layer_3': 8.657781414101634e-05, 'l1_Layer_4': 0.015214880485456779, 'n_units_Layer_1': 115, 'n_units_Layer_2': 205, 'n_units_Layer_3': 85, 'n_units_Layer_4': 120}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.70 | sMAPE for Validation Set is: 13.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 27.70 | sMAPE for Test Set is: 17.79% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:38:31,981]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:32,073]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:39,663]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:38:46,416]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:08,342]\u001b[0m Trial 473 finished with value: 10.425485367233307 and parameters: {'n_hidden': 3, 'learning_rate': 0.002434833815283637, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03761371949041502, 'dropout_rate_Layer_2': 0.2965768557793916, 'dropout_rate_Layer_3': 0.10381633058002579, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006766850427790893, 'l1_Layer_2': 2.1611299985622677e-05, 'l1_Layer_3': 1.9155273275470563e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 290}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.43 | sMAPE for Validation Set is: 13.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.32 | sMAPE for Test Set is: 17.83% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:39:13,702]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:20,507]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:22,979]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:23,443]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:30,718]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:39:38,890]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:15,045]\u001b[0m Trial 481 finished with value: 10.439473893646865 and parameters: {'n_hidden': 3, 'learning_rate': 0.009396314594418665, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04956409820660519, 'dropout_rate_Layer_2': 0.019540125505597365, 'dropout_rate_Layer_3': 0.1840874103984752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001100979376168246, 'l1_Layer_2': 0.0562795537986789, 'l1_Layer_3': 0.013556793281050132, 'n_units_Layer_1': 55, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.44 | sMAPE for Validation Set is: 13.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.21 | sMAPE for Test Set is: 17.69% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:40:25,571]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:30,238]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:37,350]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:42,287]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:40:42,687]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:09,381]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:14,623]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:19,079]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:25,951]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:41,436]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:46,209]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:46,511]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:41:54,777]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:07,409]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:10,531]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:16,036]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:21,060]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:25,473]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:37,461]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:42:46,887]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:00,147]\u001b[0m Trial 503 finished with value: 10.75386190484578 and parameters: {'n_hidden': 3, 'learning_rate': 0.007090687117178907, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05326386516440935, 'dropout_rate_Layer_2': 0.0488927873611911, 'dropout_rate_Layer_3': 0.22972952757071108, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04283855092318793, 'l1_Layer_2': 0.005411164333418482, 'l1_Layer_3': 0.0003580245903965461, 'n_units_Layer_1': 110, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.75 | sMAPE for Validation Set is: 13.48% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.05 | sMAPE for Test Set is: 18.01% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:43:07,014]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:11,055]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:24,069]\u001b[0m Trial 500 finished with value: 10.236560715892018 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008637502898195937, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04999320505582963, 'dropout_rate_Layer_2': 0.25263701757461965, 'dropout_rate_Layer_3': 0.06199057765775237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002493061308095913, 'l1_Layer_2': 7.89627331574672e-05, 'l1_Layer_3': 1.0027802443019593e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 250, 'n_units_Layer_3': 240}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.24 | sMAPE for Validation Set is: 12.60% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.60 | sMAPE for Test Set is: 17.18% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:43:24,673]\u001b[0m Trial 506 finished with value: 34.4738401302501 and parameters: {'n_hidden': 4, 'learning_rate': 0.005035878441258202, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11731265198810698, 'dropout_rate_Layer_2': 0.34311053449337947, 'dropout_rate_Layer_3': 0.3736758935646156, 'dropout_rate_Layer_4': 0.05038895673319249, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.426884711547241e-05, 'l1_Layer_2': 0.000374363798652606, 'l1_Layer_3': 0.0003033349062300452, 'l1_Layer_4': 0.015871353140477492, 'n_units_Layer_1': 95, 'n_units_Layer_2': 230, 'n_units_Layer_3': 70, 'n_units_Layer_4': 175}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.47 | sMAPE for Validation Set is: 45.52% | rMAE for Validation Set is: 2.00\n",
      "MAE for Test Set is: 151.30 | sMAPE for Test Set is: 115.99% | rMAE for Test Set is: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:43:31,766]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:31,808]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:38,191]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:45,976]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:43:50,500]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:04,494]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:09,922]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:14,545]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:21,657]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:21,783]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:27,151]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:29,447]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:34,238]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:48,314]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:44:59,225]\u001b[0m Trial 520 finished with value: 10.610374998762177 and parameters: {'n_hidden': 3, 'learning_rate': 0.009612612439105392, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06276756954652596, 'dropout_rate_Layer_2': 0.12262665655600662, 'dropout_rate_Layer_3': 0.11788748524580828, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02145982863791195, 'l1_Layer_2': 0.02998542286003274, 'l1_Layer_3': 0.005685097356923848, 'n_units_Layer_1': 275, 'n_units_Layer_2': 235, 'n_units_Layer_3': 280}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.61 | sMAPE for Validation Set is: 13.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.29 | sMAPE for Test Set is: 17.56% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:45:18,378]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:25,630]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:34,249]\u001b[0m Trial 523 finished with value: 10.688809730531561 and parameters: {'n_hidden': 3, 'learning_rate': 0.008813411123805317, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.054439149931130484, 'dropout_rate_Layer_2': 0.1531867990077972, 'dropout_rate_Layer_3': 0.10548668918816274, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01498355634304516, 'l1_Layer_2': 0.0283336022333015, 'l1_Layer_3': 0.0002364925526156656, 'n_units_Layer_1': 270, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.69 | sMAPE for Validation Set is: 13.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 27.17 | sMAPE for Test Set is: 17.59% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:45:46,392]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:51,711]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:56,497]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:45:56,640]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:05,218]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:05,348]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:13,721]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:13,834]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:19,726]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:19,848]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:27,224]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:31,998]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:35,024]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:39,955]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:46:56,469]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:47:08,965]\u001b[0m Trial 535 finished with value: 10.647662752478261 and parameters: {'n_hidden': 4, 'learning_rate': 0.021900483599693495, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15725147914336204, 'dropout_rate_Layer_2': 0.3844554087108882, 'dropout_rate_Layer_3': 0.06748184365378604, 'dropout_rate_Layer_4': 0.1471062770961206, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5867488730183638e-05, 'l1_Layer_2': 0.00019550282292941308, 'l1_Layer_3': 0.00030877304343389876, 'l1_Layer_4': 0.00027901572373475347, 'n_units_Layer_1': 60, 'n_units_Layer_2': 205, 'n_units_Layer_3': 60, 'n_units_Layer_4': 55}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.65 | sMAPE for Validation Set is: 13.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.81 | sMAPE for Test Set is: 18.98% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:47:13,869]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:47:38,575]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:06,603]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:13,436]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:26,440]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:31,429]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:38,090]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:53,088]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:48:59,192]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:05,901]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:08,077]\u001b[0m Trial 541 finished with value: 10.205604556499248 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036453362526750912, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15723681532133987, 'dropout_rate_Layer_2': 0.39838784940864025, 'dropout_rate_Layer_3': 0.39509801071783585, 'dropout_rate_Layer_4': 0.15230735622369898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001163025664956036, 'l1_Layer_2': 0.00021589250136926804, 'l1_Layer_3': 0.000127371678695474, 'l1_Layer_4': 0.00029691773055274504, 'n_units_Layer_1': 60, 'n_units_Layer_2': 205, 'n_units_Layer_3': 60, 'n_units_Layer_4': 50}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.21 | sMAPE for Validation Set is: 12.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.86 | sMAPE for Test Set is: 17.83% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:49:10,741]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:13,190]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:17,865]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:18,091]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:25,570]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:25,704]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:31,958]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:39,120]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:43,677]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:49:48,353]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:01,239]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:08,036]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:12,631]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:15,993]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:22,881]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:26,054]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:28,737]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:33,755]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:33,875]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:39,172]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:43,783]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:43,965]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:51,601]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:56,661]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:50:59,778]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:02,238]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:09,354]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:16,617]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:19,584]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:24,459]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:28,917]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:51:55,559]\u001b[0m Trial 584 finished with value: 10.495559178029138 and parameters: {'n_hidden': 3, 'learning_rate': 0.011067018887210435, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02243396766792958, 'dropout_rate_Layer_2': 0.0008939353631974185, 'dropout_rate_Layer_3': 0.13059826365563337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07148515673865503, 'l1_Layer_2': 0.03769856069602191, 'l1_Layer_3': 0.039197476917588084, 'n_units_Layer_1': 155, 'n_units_Layer_2': 250, 'n_units_Layer_3': 55}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.50 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 26.91 | sMAPE for Test Set is: 17.44% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:51:59,807]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:13,059]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:17,585]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:30,348]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:37,557]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:52:42,638]\u001b[0m Trial 586 finished with value: 10.38219258428286 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015470790584546175, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12580212708982808, 'dropout_rate_Layer_2': 0.35235931669341153, 'dropout_rate_Layer_3': 0.022762041199380377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005795427170542677, 'l1_Layer_2': 1.3914525576707207e-05, 'l1_Layer_3': 1.2610892594322785e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 215, 'n_units_Layer_3': 265}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.38 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.40 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:52:53,002]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:02,320]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:09,847]\u001b[0m Trial 590 finished with value: 10.691576409579655 and parameters: {'n_hidden': 3, 'learning_rate': 0.009887662528552475, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0816921655377764, 'dropout_rate_Layer_2': 0.05304522618725402, 'dropout_rate_Layer_3': 0.09725465930242366, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002678663204312695, 'l1_Layer_2': 0.0097737998333532, 'l1_Layer_3': 0.00025239186337449617, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 255}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.69 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 27.77 | sMAPE for Test Set is: 18.07% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:53:14,423]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:24,763]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:34,286]\u001b[0m Trial 593 finished with value: 10.387651217707488 and parameters: {'n_hidden': 3, 'learning_rate': 0.006980834345511441, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07075519658041445, 'dropout_rate_Layer_2': 0.05278659840589381, 'dropout_rate_Layer_3': 0.2190952439459816, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004796532869931988, 'l1_Layer_2': 0.015149019030136605, 'l1_Layer_3': 0.0007378435634034969, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 265}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.39 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.07 | sMAPE for Test Set is: 17.58% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:53:39,544]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:42,552]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:44,444]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:49,587]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:55,129]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:53:57,440]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:02,213]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:06,729]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:09,261]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:14,037]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:14,720]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:19,411]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:21,819]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:22,176]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:27,504]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:32,079]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:34,807]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:39,689]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:54:54,891]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:02,202]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:08,000]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:11,343]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:14,245]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:18,753]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:24,146]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:26,978]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:27,081]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:35,433]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:43,668]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:48,895]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:53,562]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:58,582]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:55:58,876]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:03,633]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:06,552]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:10,773]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:16,083]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:20,553]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:27,996]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:32,964]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:37,721]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:42,911]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:47,844]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:48,697]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:56:55,602]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:01,329]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:06,019]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:09,139]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:12,857]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:18,650]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:23,536]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:40,607]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:45,327]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:49,554]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:54,693]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:57:59,630]\u001b[0m Trial 647 finished with value: 10.286862549320057 and parameters: {'n_hidden': 3, 'learning_rate': 0.007436210813709279, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08634658521162672, 'dropout_rate_Layer_2': 0.03475651942280909, 'dropout_rate_Layer_3': 0.0907225830213835, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006983050509360081, 'l1_Layer_2': 0.015362058639855238, 'l1_Layer_3': 0.00019908460484314086, 'n_units_Layer_1': 80, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.29 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.12 | sMAPE for Test Set is: 17.58% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:57:59,968]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:08,617]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:33,776]\u001b[0m Trial 653 finished with value: 10.678152839280598 and parameters: {'n_hidden': 3, 'learning_rate': 0.005119284449111361, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05153003572632965, 'dropout_rate_Layer_2': 0.15165360524610566, 'dropout_rate_Layer_3': 0.13250338221882987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04161816740551922, 'l1_Layer_2': 0.032858853833688334, 'l1_Layer_3': 3.7471122000901156e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 90, 'n_units_Layer_3': 270}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.68 | sMAPE for Validation Set is: 13.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 27.66 | sMAPE for Test Set is: 17.83% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 20:58:38,712]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:41,999]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:46,494]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:51,109]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:51,451]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:58:56,892]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:03,670]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:14,251]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:19,418]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:24,330]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:38,384]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 20:59:50,602]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:02,655]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:08,047]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:08,368]\u001b[0m Trial 665 finished with value: 10.646007366624405 and parameters: {'n_hidden': 3, 'learning_rate': 0.005518933572629856, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021997957421720636, 'dropout_rate_Layer_2': 0.143186528488095, 'dropout_rate_Layer_3': 0.14611990916129125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.045671727716901304, 'l1_Layer_2': 0.04357495821080603, 'l1_Layer_3': 4.369615010994842e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 85, 'n_units_Layer_3': 270}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.65 | sMAPE for Validation Set is: 13.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 27.49 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:00:19,376]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:42,288]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:46,859]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:51,746]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:00:59,208]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:04,120]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:05,082]\u001b[0m Trial 671 finished with value: 10.800981976981495 and parameters: {'n_hidden': 3, 'learning_rate': 0.004288715604214325, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0589774406828226, 'dropout_rate_Layer_2': 0.1394562395924227, 'dropout_rate_Layer_3': 0.14251696460019128, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.041940963082356716, 'l1_Layer_2': 0.020055957584131492, 'l1_Layer_3': 3.979978716382895e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.80 | sMAPE for Validation Set is: 13.52% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 28.33 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:01:10,311]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:15,135]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:18,393]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:24,986]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:30,770]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:37,248]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:42,333]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:01:53,184]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:03,041]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:09,776]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:15,287]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:25,232]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:29,581]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:36,681]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:44,066]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:02:59,021]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:03:06,171]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:04:04,119]\u001b[0m Trial 693 finished with value: 10.603350189455838 and parameters: {'n_hidden': 3, 'learning_rate': 0.004156995886398916, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010619238405752969, 'dropout_rate_Layer_2': 0.1479314061646949, 'dropout_rate_Layer_3': 0.13617668738697292, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03489274411802532, 'l1_Layer_2': 0.029731937528756337, 'l1_Layer_3': 7.531920138420337e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.60 | sMAPE for Validation Set is: 13.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.46 | sMAPE for Test Set is: 17.69% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:05:00,979]\u001b[0m Trial 695 finished with value: 11.40244459827963 and parameters: {'n_hidden': 4, 'learning_rate': 0.05140199773192359, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18676469784134564, 'dropout_rate_Layer_2': 0.3657558155485467, 'dropout_rate_Layer_3': 0.19307410198011413, 'dropout_rate_Layer_4': 0.34232954904738433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5580516356278732e-05, 'l1_Layer_2': 0.0006979456225893947, 'l1_Layer_3': 0.0005188131143776349, 'l1_Layer_4': 9.182865658723119e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 80, 'n_units_Layer_3': 75, 'n_units_Layer_4': 160}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.40 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 33.46 | sMAPE for Test Set is: 20.79% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:05:08,036]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:15,423]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:25,346]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:30,312]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:05:40,828]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:05,616]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:13,231]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:19,819]\u001b[0m Trial 702 finished with value: 24.96944991271589 and parameters: {'n_hidden': 4, 'learning_rate': 0.015532042013032115, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10359837420296573, 'dropout_rate_Layer_2': 0.32318697416604997, 'dropout_rate_Layer_3': 0.24844505325447055, 'dropout_rate_Layer_4': 0.12375537867546357, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.8151052904142684e-05, 'l1_Layer_2': 0.0002004261860877034, 'l1_Layer_3': 0.00012290117306142575, 'l1_Layer_4': 2.6325355790926495e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 250, 'n_units_Layer_3': 90, 'n_units_Layer_4': 195}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.97 | sMAPE for Validation Set is: 30.73% | rMAE for Validation Set is: 1.45\n",
      "MAE for Test Set is: 124.60 | sMAPE for Test Set is: 83.24% | rMAE for Test Set is: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:06:22,623]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:31,953]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:39,965]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:44,520]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:49,381]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:06:57,082]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:06,639]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:12,167]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:17,467]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:22,020]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:25,790]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:27,902]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:34,941]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:36,959]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:41,646]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:48,650]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:48,873]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:54,222]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:07:57,136]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:00,934]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:05,234]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:08,568]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:13,227]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:13,657]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:24,296]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:40,952]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:48,388]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:08:58,262]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:04,020]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:10,747]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:18,041]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:21,261]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:26,004]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:28,642]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:32,867]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:38,201]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:38,347]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:45,992]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:09:53,053]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:10:29,648]\u001b[0m Trial 742 finished with value: 10.665614127473459 and parameters: {'n_hidden': 3, 'learning_rate': 0.011004336639527285, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20789109525174626, 'dropout_rate_Layer_2': 0.26716776405542464, 'dropout_rate_Layer_3': 0.11889631312755333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.262759333479043e-05, 'l1_Layer_2': 0.00032373387859646694, 'l1_Layer_3': 0.0003708571436467142, 'n_units_Layer_1': 50, 'n_units_Layer_2': 265, 'n_units_Layer_3': 95}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.67 | sMAPE for Validation Set is: 13.39% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.44 | sMAPE for Test Set is: 18.36% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:10:35,428]\u001b[0m Trial 744 finished with value: 10.887228207064297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016297243284452028, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002767621899955816, 'dropout_rate_Layer_2': 0.26268580366955696, 'dropout_rate_Layer_3': 0.1021487921575943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4101119898620366e-05, 'l1_Layer_2': 0.001207854171816831, 'l1_Layer_3': 0.0003891065676403626, 'n_units_Layer_1': 155, 'n_units_Layer_2': 210, 'n_units_Layer_3': 165}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.89 | sMAPE for Validation Set is: 13.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 30.04 | sMAPE for Test Set is: 19.24% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:10:41,780]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:10:59,182]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:06,894]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:07,486]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:15,901]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:22,328]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:32,755]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:37,395]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:11:45,201]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:02,579]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:06,361]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:22,685]\u001b[0m Trial 755 finished with value: 10.788795564871705 and parameters: {'n_hidden': 3, 'learning_rate': 0.01395025307007128, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2361329822431329, 'dropout_rate_Layer_2': 0.20802709962921298, 'dropout_rate_Layer_3': 0.04634874880037734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.001814869078269e-05, 'l1_Layer_2': 0.0003803023504703154, 'l1_Layer_3': 0.000702665956809291, 'n_units_Layer_1': 50, 'n_units_Layer_2': 265, 'n_units_Layer_3': 80}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.79 | sMAPE for Validation Set is: 13.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.44 | sMAPE for Test Set is: 18.79% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:12:37,655]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:12:42,448]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:02,413]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:08,961]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:14,645]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:19,566]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:24,017]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:29,126]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:36,676]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:13:57,123]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:04,748]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:17,381]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:46,672]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:52,290]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:14:57,000]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:15:07,430]\u001b[0m Trial 761 finished with value: 10.253658988728871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008026059865548057, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008299146625140178, 'dropout_rate_Layer_2': 0.17404455138074432, 'dropout_rate_Layer_3': 0.22211572037146066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019916075971872908, 'l1_Layer_2': 1.0089051434937116e-05, 'l1_Layer_3': 4.485645038490848e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 215, 'n_units_Layer_3': 255}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.25 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.91 | sMAPE for Test Set is: 17.47% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:15:12,190]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:15:19,181]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:15:34,424]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:15:46,291]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:15:53,629]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:15:59,351]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:16:13,763]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:16:18,657]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:16:25,895]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:16:30,979]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:03,480]\u001b[0m Trial 776 finished with value: 10.297694754804757 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009722595366292073, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 2.871451143604542e-05, 'dropout_rate_Layer_2': 0.16903826727044338, 'dropout_rate_Layer_3': 0.23680626368668253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019856064281892497, 'l1_Layer_2': 1.2710140354960203e-05, 'l1_Layer_3': 6.556474963025798e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 210, 'n_units_Layer_3': 245}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.30 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.01 | sMAPE for Test Set is: 17.58% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:17:31,027]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:31,300]\u001b[0m Trial 785 finished with value: 10.506255665447016 and parameters: {'n_hidden': 3, 'learning_rate': 0.002981170489579795, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017862458934379308, 'dropout_rate_Layer_2': 0.2998762082032753, 'dropout_rate_Layer_3': 0.07247162729600397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006659127123667429, 'l1_Layer_2': 1.3472449371351201e-05, 'l1_Layer_3': 1.205150085053788e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 170, 'n_units_Layer_3': 300}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.51 | sMAPE for Validation Set is: 13.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.34 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:17:39,386]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:46,415]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:17:55,859]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:00,259]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:05,600]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:15,213]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:22,698]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:22,773]\u001b[0m Trial 788 finished with value: 10.702498154116299 and parameters: {'n_hidden': 3, 'learning_rate': 0.010663130386937357, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24192792065131868, 'dropout_rate_Layer_2': 0.18802212460323087, 'dropout_rate_Layer_3': 0.0005146898839702152, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.597614998916668e-05, 'l1_Layer_2': 0.0003408006872854522, 'l1_Layer_3': 0.0001834605155312163, 'n_units_Layer_1': 50, 'n_units_Layer_2': 265, 'n_units_Layer_3': 100}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.70 | sMAPE for Validation Set is: 13.52% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.53 | sMAPE for Test Set is: 18.40% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:18:30,641]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:38,275]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:18:50,535]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:19:18,736]\u001b[0m Trial 796 finished with value: 10.600733964030303 and parameters: {'n_hidden': 3, 'learning_rate': 0.014007270281739736, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23905314508649703, 'dropout_rate_Layer_2': 0.18117768876511436, 'dropout_rate_Layer_3': 0.04844131000940021, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.702255290053685e-05, 'l1_Layer_2': 0.00033171767323513944, 'l1_Layer_3': 0.0007130120179333425, 'n_units_Layer_1': 50, 'n_units_Layer_2': 285, 'n_units_Layer_3': 80}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.60 | sMAPE for Validation Set is: 13.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.05 | sMAPE for Test Set is: 18.07% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:19:30,520]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:19:41,183]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:19:53,588]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:20:00,208]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:20:10,028]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:20:32,998]\u001b[0m Trial 803 finished with value: 10.635382397791972 and parameters: {'n_hidden': 3, 'learning_rate': 0.009912502233489209, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2649857019676107, 'dropout_rate_Layer_2': 0.1900681196464953, 'dropout_rate_Layer_3': 0.029365171796560348, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.213660283453906e-05, 'l1_Layer_2': 0.0003047420782030105, 'l1_Layer_3': 0.0002306709343636417, 'n_units_Layer_1': 65, 'n_units_Layer_2': 290, 'n_units_Layer_3': 95}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.64 | sMAPE for Validation Set is: 13.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.29 | sMAPE for Test Set is: 18.28% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:20:57,279]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:21:02,396]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:21:10,264]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:21:21,840]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:21:27,585]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:21:32,050]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:21:36,955]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:21:39,738]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:21:44,732]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:21:53,508]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:22:09,309]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:22:16,134]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:22:48,682]\u001b[0m Trial 815 finished with value: 10.584143344099518 and parameters: {'n_hidden': 3, 'learning_rate': 0.0060107663974890745, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2746133089250401, 'dropout_rate_Layer_2': 0.1770680030127032, 'dropout_rate_Layer_3': 0.0024690640455028445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.2322154944682e-05, 'l1_Layer_2': 0.00029743793637954194, 'l1_Layer_3': 0.0002320026243535008, 'n_units_Layer_1': 65, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.58 | sMAPE for Validation Set is: 13.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.48 | sMAPE for Test Set is: 18.29% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:23:02,653]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:23:13,153]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:23:18,437]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:23:25,271]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:23:32,854]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:23:38,203]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:23:49,882]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:23:55,555]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:24:02,163]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:24:15,264]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:24:22,798]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:24:29,273]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:24:47,052]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:24:54,580]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:25:08,635]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:25:38,434]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:25:43,393]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:25:51,218]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:25:58,285]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:26:02,864]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:26:08,377]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:26:26,474]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:27:05,262]\u001b[0m Trial 840 finished with value: 10.732024358211284 and parameters: {'n_hidden': 3, 'learning_rate': 0.007127444449569665, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3123746778404136, 'dropout_rate_Layer_2': 0.18094898197169115, 'dropout_rate_Layer_3': 0.08077384646236578, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002922171344631682, 'l1_Layer_2': 0.00014044589468304927, 'l1_Layer_3': 0.00022534106010459626, 'n_units_Layer_1': 60, 'n_units_Layer_2': 295, 'n_units_Layer_3': 120}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.73 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.02 | sMAPE for Test Set is: 18.57% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:27:10,675]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:27:22,682]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:27:30,243]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:27:42,442]\u001b[0m Trial 837 finished with value: 10.274665123266436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007041536163009273, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006496486028474299, 'dropout_rate_Layer_2': 0.18387341631648618, 'dropout_rate_Layer_3': 0.18224721002929611, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012064339911755353, 'l1_Layer_2': 2.8446224323141058e-05, 'l1_Layer_3': 5.2880875497745856e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 195, 'n_units_Layer_3': 250}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.27 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 26.60 | sMAPE for Test Set is: 17.29% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:27:48,057]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:27:54,879]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:28:40,088]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:28:46,855]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:28:52,485]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:28:57,229]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:29:04,124]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:29:18,389]\u001b[0m Trial 846 finished with value: 10.28062423469856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006854567031954659, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018344408761162726, 'dropout_rate_Layer_2': 0.19292532167184467, 'dropout_rate_Layer_3': 0.18797479807745066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007798109471550707, 'l1_Layer_2': 3.65469032057543e-05, 'l1_Layer_3': 5.592694695930214e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 240}. Best is trial 182 with value: 10.115143820515781.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.28 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 26.63 | sMAPE for Test Set is: 17.40% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:29:23,536]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:29:30,794]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:29:58,246]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:30:10,434]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:30:17,326]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:31:58,715]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:32:05,903]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:32:10,436]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:32:30,940]\u001b[0m Trial 858 finished with value: 10.10777689473811 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006722669868573516, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03382334415382776, 'dropout_rate_Layer_2': 0.0650025824875846, 'dropout_rate_Layer_3': 0.18252673136724015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018288635912406099, 'l1_Layer_2': 3.541361837505369e-05, 'l1_Layer_3': 6.818562512839535e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 235}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.11 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.16 | sMAPE for Test Set is: 16.98% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:32:35,426]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:32:40,945]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:32:45,947]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:32:59,693]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:33:04,977]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:33:10,162]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:33:14,723]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:33:19,889]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:33:20,332]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:33:26,495]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:33:36,171]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:33:48,096]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:33:53,595]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:33:58,755]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:34:05,967]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:34:26,059]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:34:33,009]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:34:38,225]\u001b[0m Trial 871 finished with value: 10.229119150065843 and parameters: {'n_hidden': 3, 'learning_rate': 0.009055054399791018, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31985845934286405, 'dropout_rate_Layer_2': 0.1254330033637203, 'dropout_rate_Layer_3': 0.0623684069260751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012580101415435232, 'l1_Layer_2': 6.444804838073437e-05, 'l1_Layer_3': 6.845910356960713e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 280, 'n_units_Layer_3': 110}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.23 | sMAPE for Validation Set is: 12.89% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.58 | sMAPE for Test Set is: 17.80% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:34:42,474]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:34:47,243]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:34:47,824]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:34:55,226]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:35:02,820]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:35:09,858]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:35:12,918]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:35:19,602]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:35:25,207]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:35:29,666]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:35:37,729]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:35:44,412]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:35:52,128]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:35:58,004]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:36:08,010]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:36:22,344]\u001b[0m Trial 883 finished with value: 10.114946184469114 and parameters: {'n_hidden': 3, 'learning_rate': 0.008290776697601475, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32385310248413895, 'dropout_rate_Layer_2': 0.12795019324070625, 'dropout_rate_Layer_3': 0.05530961709051183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011634105614965321, 'l1_Layer_2': 7.724827942904088e-05, 'l1_Layer_3': 6.517147336072014e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 280, 'n_units_Layer_3': 110}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.11 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.83 | sMAPE for Test Set is: 17.78% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:36:27,034]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:36:31,988]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:36:36,849]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:36:41,565]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:36:42,073]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:36:47,388]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:36:56,885]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:04,530]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:11,282]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:11,883]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:19,606]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:20,304]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:25,805]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:35,638]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:39,483]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:43,016]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:48,243]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:54,703]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:37:59,985]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:38:26,465]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:38:26,593]\u001b[0m Trial 911 finished with value: 10.478955945533526 and parameters: {'n_hidden': 3, 'learning_rate': 0.008118589446113371, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3451764023831666, 'dropout_rate_Layer_2': 0.17244519168455794, 'dropout_rate_Layer_3': 0.05770696075760118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001861523646018845, 'l1_Layer_2': 6.966207288490758e-05, 'l1_Layer_3': 4.0971006871077144e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 280, 'n_units_Layer_3': 115}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.48 | sMAPE for Validation Set is: 13.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.94 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:38:36,290]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:38:43,470]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:38:48,300]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:38:53,400]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:38:58,495]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:39:06,123]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:39:13,799]\u001b[0m Trial 917 finished with value: 10.673733599092708 and parameters: {'n_hidden': 3, 'learning_rate': 0.008085863718547064, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36992115655217667, 'dropout_rate_Layer_2': 0.09220701182960661, 'dropout_rate_Layer_3': 0.061994345792572916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021901828895345976, 'l1_Layer_2': 2.5327265995306452e-05, 'l1_Layer_3': 4.2994907655394064e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 145}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.67 | sMAPE for Validation Set is: 13.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.06 | sMAPE for Test Set is: 18.67% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:39:19,025]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:39:25,575]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:39:30,854]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:39:40,292]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:39:45,452]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:39:51,086]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:39:58,105]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:00,884]\u001b[0m Trial 923 finished with value: 10.601523788104068 and parameters: {'n_hidden': 3, 'learning_rate': 0.006311159038581978, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36711779532661515, 'dropout_rate_Layer_2': 0.17481371052887884, 'dropout_rate_Layer_3': 0.055269895004962634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005478189321259587, 'l1_Layer_2': 7.072911393639018e-05, 'l1_Layer_3': 4.257402991039772e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 110}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.60 | sMAPE for Validation Set is: 13.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.33 | sMAPE for Test Set is: 18.63% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:40:03,186]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:08,155]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:08,377]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:16,170]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:21,551]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:28,081]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:35,229]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:38,101]\u001b[0m Trial 935 finished with value: 27.64622414106763 and parameters: {'n_hidden': 3, 'learning_rate': 0.006004276891980428, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34995513443560494, 'dropout_rate_Layer_2': 0.17097023176392204, 'dropout_rate_Layer_3': 0.005143714454197784, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006090921061537505, 'l1_Layer_2': 6.62781413977399e-05, 'l1_Layer_3': 1.955772014572301e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.65 | sMAPE for Validation Set is: 34.82% | rMAE for Validation Set is: 1.60\n",
      "MAE for Test Set is: 128.97 | sMAPE for Test Set is: 87.96% | rMAE for Test Set is: 2.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:40:40,462]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:42,945]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:47,891]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:50,806]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:53,650]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:57,524]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:40:58,243]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:41:05,989]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:41:13,023]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:41:13,324]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:41:24,750]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:42:23,511]\u001b[0m Trial 951 finished with value: 10.145766391851826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013975439970596026, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011470554612016121, 'dropout_rate_Layer_2': 0.2926726964036092, 'dropout_rate_Layer_3': 0.023674599563961753, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006039410818613757, 'l1_Layer_2': 0.0002126053504694848, 'l1_Layer_3': 1.94601628081752e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 220, 'n_units_Layer_3': 270}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.15 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.61 | sMAPE for Test Set is: 17.29% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:42:33,662]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:42:38,814]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:42:44,442]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:42:51,868]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:43:04,227]\u001b[0m Trial 950 finished with value: 10.17414073609329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005512682253016024, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04345792445002099, 'dropout_rate_Layer_2': 0.1315340761700592, 'dropout_rate_Layer_3': 0.19460462700996084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018332630167499097, 'l1_Layer_2': 3.9000126996481385e-05, 'l1_Layer_3': 3.5171087649676775e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 210, 'n_units_Layer_3': 250}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.17 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.50 | sMAPE for Test Set is: 17.20% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:43:08,886]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:43:09,499]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:43:17,502]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:43:40,051]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:43:47,216]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:43:52,477]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:43:52,769]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:00,431]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:00,682]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:09,096]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:13,690]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:14,377]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:19,581]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:24,578]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:33,672]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:36,186]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:39,105]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:44,068]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:49,277]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:54,195]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:44:54,277]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:45:03,461]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:45:09,076]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:45:18,434]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:45:23,626]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:45:30,713]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:46:03,034]\u001b[0m Trial 982 finished with value: 10.185622352665808 and parameters: {'n_hidden': 3, 'learning_rate': 0.00856242089410156, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12516701914011724, 'dropout_rate_Layer_2': 0.031257450207644394, 'dropout_rate_Layer_3': 0.22086106967997782, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0062316547784668705, 'l1_Layer_2': 0.020336044423691964, 'l1_Layer_3': 0.0019216234960366904, 'n_units_Layer_1': 80, 'n_units_Layer_2': 110, 'n_units_Layer_3': 280}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.19 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.77 | sMAPE for Test Set is: 17.32% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:46:07,888]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.53 | sMAPE for Validation Set is: 13.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 28.26 | sMAPE for Test Set is: 18.19% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:46:12,387]\u001b[0m Trial 983 finished with value: 10.53177805085422 and parameters: {'n_hidden': 3, 'learning_rate': 0.005432197866367452, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3229074112931226, 'dropout_rate_Layer_2': 0.197657208603666, 'dropout_rate_Layer_3': 0.05719266699013885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018115475449267864, 'l1_Layer_2': 4.121432745977205e-05, 'l1_Layer_3': 5.663196853480146e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 300, 'n_units_Layer_3': 110}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:46:17,769]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:46:22,423]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:46:27,364]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:46:32,606]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:46:32,651]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:46:40,895]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:46:45,634]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:46:51,499]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:47:18,397]\u001b[0m Trial 990 finished with value: 10.656688116462538 and parameters: {'n_hidden': 3, 'learning_rate': 0.006664840330655615, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32536733033793336, 'dropout_rate_Layer_2': 0.20375415238708844, 'dropout_rate_Layer_3': 0.0954784172795562, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019147900240939195, 'l1_Layer_2': 4.718346066193637e-05, 'l1_Layer_3': 5.25910063034327e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 300, 'n_units_Layer_3': 110}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.66 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.91 | sMAPE for Test Set is: 18.50% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:47:28,276]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:47:33,179]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:47:37,955]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:47:47,421]\u001b[0m Trial 994 finished with value: 10.408654409742445 and parameters: {'n_hidden': 3, 'learning_rate': 0.005347202725461035, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3195374533622066, 'dropout_rate_Layer_2': 0.2059825815857598, 'dropout_rate_Layer_3': 0.055696745337229875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029197196886427036, 'l1_Layer_2': 4.021161769472541e-05, 'l1_Layer_3': 3.601141473496705e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 300, 'n_units_Layer_3': 110}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.41 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.53 | sMAPE for Test Set is: 17.74% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:47:52,384]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:47:57,150]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:48:02,086]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:48:04,528]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:48:09,453]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:48:09,914]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:48:16,390]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:48:16,546]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:48:24,032]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:48:48,866]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:48:53,952]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:48:54,003]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:01,289]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:05,357]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:10,630]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:15,339]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:20,783]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:28,331]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:33,466]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:40,278]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:42,112]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:47,379]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:48,025]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:55,763]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:49:56,002]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:50:04,091]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:50:04,389]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:50:11,837]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:50:16,285]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:50:19,140]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:50:26,020]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:50:36,155]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:51:08,861]\u001b[0m Trial 1028 finished with value: 10.309340875677112 and parameters: {'n_hidden': 3, 'learning_rate': 0.004311039750366643, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30693508468243025, 'dropout_rate_Layer_2': 0.11756186480046224, 'dropout_rate_Layer_3': 0.0842686923920341, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013299537115135887, 'l1_Layer_2': 1.8726110632378513e-05, 'l1_Layer_3': 2.4418926386233247e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 300, 'n_units_Layer_3': 120}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.31 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.56 | sMAPE for Test Set is: 17.78% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:51:13,583]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:51:18,145]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:51:23,861]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:51:30,421]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:51:33,317]\u001b[0m Trial 1031 finished with value: 10.42019880191796 and parameters: {'n_hidden': 3, 'learning_rate': 0.004508062815690232, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3052171221642167, 'dropout_rate_Layer_2': 0.10878996373436452, 'dropout_rate_Layer_3': 0.013574941713674918, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010267028391964476, 'l1_Layer_2': 1.908151632104345e-05, 'l1_Layer_3': 6.658495766453974e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 300, 'n_units_Layer_3': 120}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.42 | sMAPE for Validation Set is: 13.03% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.38 | sMAPE for Test Set is: 17.93% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:51:37,995]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:51:38,293]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:51:44,198]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:51:53,764]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:51:58,616]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:04,197]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:10,832]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:10,895]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:18,847]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:18,894]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:25,963]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:26,098]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:33,810]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:39,117]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:46,218]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:53,749]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:52:56,499]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:01,225]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:11,324]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:18,362]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:23,780]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:28,530]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:36,263]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:39,128]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:43,595]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:46,867]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:51,169]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:51,681]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:53:59,743]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:04,677]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:05,010]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:11,979]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:16,570]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:21,676]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:27,217]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:31,698]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:34,164]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:41,296]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:44,572]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:54,224]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:54:59,148]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:06,232]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:11,884]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:14,249]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:16,872]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:21,235]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:24,038]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:24,347]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:33,171]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:38,771]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:41,797]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:45,957]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:49,244]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:55:55,718]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:56:03,448]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:56:06,165]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:56:09,110]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:56:11,581]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:56:16,298]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:56:18,238]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:56:56,058]\u001b[0m Trial 1097 finished with value: 10.154930011733285 and parameters: {'n_hidden': 3, 'learning_rate': 0.004949236745272673, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3500697140051041, 'dropout_rate_Layer_2': 0.12456137456376598, 'dropout_rate_Layer_3': 0.03768831996769804, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007658787070581707, 'l1_Layer_2': 2.855505462139867e-05, 'l1_Layer_3': 3.4118135293099235e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.15 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.47 | sMAPE for Test Set is: 18.12% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:57:01,454]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:57:08,196]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:57:13,701]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:57:14,228]\u001b[0m Trial 1096 finished with value: 10.118873045564364 and parameters: {'n_hidden': 3, 'learning_rate': 0.003268635762818899, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01751928085778214, 'dropout_rate_Layer_2': 0.2626343597491067, 'dropout_rate_Layer_3': 0.07440356492353176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00949707087429949, 'l1_Layer_2': 1.4189048017233841e-05, 'l1_Layer_3': 1.0173042714526444e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 160, 'n_units_Layer_3': 300}. Best is trial 858 with value: 10.10777689473811.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.12 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.42 | sMAPE for Test Set is: 17.18% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:57:23,384]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:57:25,883]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:57:35,760]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:57:40,328]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:57:48,289]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:57:53,066]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:00,109]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:07,883]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:12,887]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:18,446]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:28,075]\u001b[0m Trial 1103 finished with value: 10.03978889744153 and parameters: {'n_hidden': 3, 'learning_rate': 0.002205812215318565, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005809665518325471, 'dropout_rate_Layer_2': 0.2659743039760252, 'dropout_rate_Layer_3': 0.09549666345656295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008813055179638147, 'l1_Layer_2': 1.8512589890401186e-05, 'l1_Layer_3': 2.184633931140362e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.04 | sMAPE for Validation Set is: 12.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.35 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 21:58:30,785]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:37,481]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:39,454]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:42,784]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:46,846]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:47,398]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:53,703]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:58:58,121]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:59:00,610]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:59:34,897]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:59:39,879]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:59:45,454]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:59:52,576]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 21:59:57,237]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:00:01,903]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:00:09,873]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:00:21,860]\u001b[0m Trial 1121 finished with value: 10.149017652674983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007234168009079291, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1223307600576023, 'dropout_rate_Layer_2': 0.19268652794918328, 'dropout_rate_Layer_3': 0.18884459843498114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002192479762126208, 'l1_Layer_2': 1.7905603784389597e-05, 'l1_Layer_3': 6.38062551298827e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 265, 'n_units_Layer_3': 225}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.15 | sMAPE for Validation Set is: 12.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.22 | sMAPE for Test Set is: 17.04% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:00:29,065]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:00:29,810]\u001b[0m Trial 1129 finished with value: 28.643579182811283 and parameters: {'n_hidden': 3, 'learning_rate': 0.004997599369240801, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3512496907725601, 'dropout_rate_Layer_2': 0.12547891116101695, 'dropout_rate_Layer_3': 0.10175446786532388, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004565369119614656, 'l1_Layer_2': 1.0747173819249744e-05, 'l1_Layer_3': 1.7377621110385735e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 155}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.64 | sMAPE for Validation Set is: 35.83% | rMAE for Validation Set is: 1.66\n",
      "MAE for Test Set is: 135.08 | sMAPE for Test Set is: 95.03% | rMAE for Test Set is: 2.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:00:35,145]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:00:35,682]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:00:42,687]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:00:46,124]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:00:52,694]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:03,003]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:08,548]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:13,380]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:17,876]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:21,353]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:25,705]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:26,037]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:35,688]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:46,208]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:48,983]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:51,325]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:56,227]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:01:56,524]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:02,719]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:05,200]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:10,070]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:10,323]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:16,354]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:36,511]\u001b[0m Trial 1155 finished with value: 10.290229054269844 and parameters: {'n_hidden': 3, 'learning_rate': 0.010048413922925372, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05107976131016715, 'dropout_rate_Layer_2': 0.07189546921911026, 'dropout_rate_Layer_3': 0.21564584511738494, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02961623973335466, 'l1_Layer_2': 0.02378716025973248, 'l1_Layer_3': 0.00020963495566934714, 'n_units_Layer_1': 175, 'n_units_Layer_2': 190, 'n_units_Layer_3': 225}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.29 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.82 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:02:38,145]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:43,963]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:48,055]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:53,663]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:53,770]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:59,402]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:02:59,526]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:07,445]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:07,492]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:15,554]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:18,686]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:21,040]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:25,367]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:26,037]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:32,120]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:34,770]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:37,173]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:41,478]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:41,898]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:47,513]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:51,873]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:54,647]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:03:59,675]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:04:06,528]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:04:06,984]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:04:11,896]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:04:23,541]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:04:29,162]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:04:51,170]\u001b[0m Trial 1181 finished with value: 10.16065468182555 and parameters: {'n_hidden': 3, 'learning_rate': 0.002596257903837882, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37863998250503456, 'dropout_rate_Layer_2': 0.1213152367992531, 'dropout_rate_Layer_3': 0.1335839431746909, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001862069361079401, 'l1_Layer_2': 9.008645593472665e-05, 'l1_Layer_3': 5.27307764139323e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 295, 'n_units_Layer_3': 140}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.16 | sMAPE for Validation Set is: 12.68% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.77 | sMAPE for Test Set is: 17.86% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:05:11,460]\u001b[0m Trial 1185 finished with value: 10.800517306727405 and parameters: {'n_hidden': 3, 'learning_rate': 0.012068653197132937, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05442872345796122, 'dropout_rate_Layer_2': 0.2058238287463747, 'dropout_rate_Layer_3': 0.1579671761852715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002972697258199006, 'l1_Layer_2': 0.0448543998495104, 'l1_Layer_3': 1.1962327747685853e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 185, 'n_units_Layer_3': 140}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.80 | sMAPE for Validation Set is: 13.67% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 27.85 | sMAPE for Test Set is: 18.06% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:05:15,995]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.09 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.82 | sMAPE for Test Set is: 17.77% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:05:19,302]\u001b[0m Trial 1184 finished with value: 10.087617301505816 and parameters: {'n_hidden': 3, 'learning_rate': 0.00515929813130524, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31534919155594227, 'dropout_rate_Layer_2': 0.07966860263765776, 'dropout_rate_Layer_3': 0.03360037158911875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020854763329131894, 'l1_Layer_2': 4.190076858822875e-05, 'l1_Layer_3': 7.63542653678748e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 140}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:05:23,975]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:05:28,952]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:05:33,294]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:05:36,262]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:05:40,873]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:05:43,704]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:05:48,229]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:05:52,847]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:01,026]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:05,699]\u001b[0m Trial 1193 finished with value: 25.381984914401386 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035853952400674936, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3793545671393444, 'dropout_rate_Layer_2': 0.07392051457249388, 'dropout_rate_Layer_3': 0.07444984408908065, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023071801453992494, 'l1_Layer_2': 9.18187256174683e-05, 'l1_Layer_3': 1.0012237990302744e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.38 | sMAPE for Validation Set is: 32.43% | rMAE for Validation Set is: 1.47\n",
      "MAE for Test Set is: 114.67 | sMAPE for Test Set is: 73.23% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:06:05,949]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:11,648]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:11,962]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:19,097]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:28,873]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:32,002]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:36,435]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:36,636]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:45,408]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:48,280]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:54,838]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:06:58,187]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:07:00,399]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:07:04,515]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:07:14,423]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:07:16,943]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:07:24,183]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:07:29,058]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:07:32,224]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:07:36,756]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:07:42,484]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:08:03,757]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:08:08,195]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:08:16,310]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:08:28,764]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:08:43,496]\u001b[0m Trial 1221 finished with value: 10.289357905165888 and parameters: {'n_hidden': 3, 'learning_rate': 0.005527146389958792, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07763890821993845, 'dropout_rate_Layer_2': 0.03594521424506433, 'dropout_rate_Layer_3': 0.0930432794029993, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.058429357298693314, 'l1_Layer_2': 0.02368049890590344, 'l1_Layer_3': 0.0002813344512696469, 'n_units_Layer_1': 115, 'n_units_Layer_2': 170, 'n_units_Layer_3': 280}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.29 | sMAPE for Validation Set is: 12.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.43 | sMAPE for Test Set is: 18.13% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:08:48,784]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:08:53,787]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:08:59,598]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:09:08,668]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:09:11,905]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:09:16,703]\u001b[0m Trial 1223 finished with value: 10.321705432177923 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032093572107642562, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013821575577519956, 'dropout_rate_Layer_2': 0.2856294696993828, 'dropout_rate_Layer_3': 0.09528933116519663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005718484797496022, 'l1_Layer_2': 2.0105127739720387e-05, 'l1_Layer_3': 1.69388260888242e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 195, 'n_units_Layer_3': 295}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.32 | sMAPE for Validation Set is: 12.80% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 26.99 | sMAPE for Test Set is: 17.53% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:09:16,972]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:09:24,066]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:09:25,845]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:09:33,039]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:09:38,172]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:09:45,327]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:09:48,701]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:09:57,630]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:10:00,525]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:10:29,705]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:10:34,660]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:10:38,063]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:10:42,395]\u001b[0m Trial 1238 finished with value: 10.264923777997607 and parameters: {'n_hidden': 3, 'learning_rate': 0.008590569744046475, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3926700935304181, 'dropout_rate_Layer_2': 0.1050546961076508, 'dropout_rate_Layer_3': 0.17451687141998543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014045705181116357, 'l1_Layer_2': 3.258044792749374e-05, 'l1_Layer_3': 4.7377669294075115e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.26 | sMAPE for Validation Set is: 12.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.20 | sMAPE for Test Set is: 17.50% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:10:47,032]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:10:49,941]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:10:52,578]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:10:55,197]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:10:57,466]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:11:02,317]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:11:07,037]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:11:19,526]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:11:24,898]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:11:31,725]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:11:39,680]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:11:44,157]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:11:49,158]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:11:56,118]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:01,357]\u001b[0m Trial 1250 finished with value: 10.22786588930773 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023543958640605545, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39599756373607203, 'dropout_rate_Layer_2': 0.10665580082706944, 'dropout_rate_Layer_3': 0.15157101100891485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008085869101670037, 'l1_Layer_2': 3.154261889965055e-05, 'l1_Layer_3': 5.064505859215701e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.23 | sMAPE for Validation Set is: 12.92% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.64 | sMAPE for Test Set is: 18.28% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:12:08,670]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:10,638]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:16,089]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:18,604]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:23,101]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:27,572]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:30,436]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:35,346]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:40,058]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:42,485]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:46,831]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:47,294]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:59,006]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:12:59,665]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:07,127]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:07,269]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:16,418]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:16,529]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:24,189]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:30,711]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:30,844]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:38,395]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:39,009]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:44,327]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:47,124]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:13:51,412]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:14:01,473]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:14:06,398]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:14:24,193]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:14:29,253]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:14:36,398]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:14:41,786]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:14:46,409]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:14:51,711]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:14:59,903]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:15:07,199]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:15:12,029]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:15:37,073]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:15:41,722]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:15:46,913]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:15:51,611]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:15:56,268]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:15:58,829]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:16:03,524]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:16:03,944]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:16:09,944]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:16:14,974]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:16:22,258]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:16:26,814]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:16:36,700]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:16:44,767]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:16:49,748]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:16:54,631]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:17:02,510]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:17:09,005]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:17:14,878]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:17:19,811]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:17:36,610]\u001b[0m Trial 1308 finished with value: 10.145067156297978 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030076191787009572, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3111530526877434, 'dropout_rate_Layer_2': 0.1025414569179011, 'dropout_rate_Layer_3': 0.1397423457626169, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013097431083663202, 'l1_Layer_2': 2.275350172470159e-05, 'l1_Layer_3': 5.362808400202347e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.15 | sMAPE for Validation Set is: 12.68% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.55 | sMAPE for Test Set is: 17.74% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:17:42,113]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:17:49,212]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:17:56,392]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:18:00,864]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:18:05,814]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:18:11,585]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:18:18,748]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:18:33,106]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:18:33,699]\u001b[0m Trial 1315 finished with value: 10.066140043793222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0044532635757434935, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33571768762874454, 'dropout_rate_Layer_2': 0.06320989820739106, 'dropout_rate_Layer_3': 0.13420235921222332, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014463015860528483, 'l1_Layer_2': 4.733150221002225e-05, 'l1_Layer_3': 3.591119576964854e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 295, 'n_units_Layer_3': 150}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.07 | sMAPE for Validation Set is: 12.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.51 | sMAPE for Test Set is: 17.71% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:18:39,933]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:18:42,743]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:18:47,900]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:18:54,891]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:00,121]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:00,391]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:06,272]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:06,612]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:13,532]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:17,769]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:21,192]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:25,710]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:26,207]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:32,687]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:32,749]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:41,390]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:42,029]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:48,511]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:55,459]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:19:58,630]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:00,584]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:05,661]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:10,435]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:16,073]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:20,946]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:25,306]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:30,466]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:35,421]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:45,690]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:50,048]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:50,524]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:56,356]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:20:58,898]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:21:03,676]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:21:05,710]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:21:12,561]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:21:20,521]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:21:25,734]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:21:33,044]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:21:38,181]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:21:45,301]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:21:50,704]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:21:54,371]\u001b[0m Trial 1359 finished with value: 10.425235104791723 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030877944643355752, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35944707502145273, 'dropout_rate_Layer_2': 0.06923271475510609, 'dropout_rate_Layer_3': 0.13814642035978766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011422853097182958, 'l1_Layer_2': 4.9138746293322e-05, 'l1_Layer_3': 1.5264285468181827e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 155}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.43 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.90 | sMAPE for Test Set is: 17.97% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:21:58,890]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:22:03,435]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:22:08,271]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:22:11,038]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:22:15,463]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:22:25,493]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:22:31,024]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:22:38,273]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:22:40,946]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:22:48,081]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:22:52,855]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:22:58,710]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:23:05,288]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:23:14,984]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:23:20,299]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:23:23,111]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:23:25,534]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:23:30,098]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:23:35,533]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:23:45,362]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:23:52,259]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:23:57,441]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:24:05,054]\u001b[0m Trial 1384 finished with value: 10.246626374237588 and parameters: {'n_hidden': 3, 'learning_rate': 0.003774236087485348, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3900606156769877, 'dropout_rate_Layer_2': 0.06375635447204503, 'dropout_rate_Layer_3': 0.12796461489897631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003932073631437714, 'l1_Layer_2': 1.4554650430630464e-05, 'l1_Layer_3': 8.887943452124848e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 250, 'n_units_Layer_3': 165}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.25 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.70 | sMAPE for Test Set is: 17.75% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:24:09,542]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:24:27,079]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:24:31,614]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:24:36,981]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:24:42,697]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:24:47,638]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:24:54,236]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:24:59,985]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:25:05,215]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:25:12,095]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:25:17,100]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:25:20,344]\u001b[0m Trial 1392 finished with value: 10.114830403043792 and parameters: {'n_hidden': 3, 'learning_rate': 0.006551290872701641, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0936401930882608, 'dropout_rate_Layer_2': 0.02180032514581143, 'dropout_rate_Layer_3': 0.02888801413464091, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002789573002905822, 'l1_Layer_2': 0.006182436156955742, 'l1_Layer_3': 9.601244219807614e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 220}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.11 | sMAPE for Validation Set is: 12.68% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.56 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:25:25,316]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:25:25,677]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:25:32,581]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:25:34,950]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:25:37,348]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:25:42,736]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:25:50,264]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:02,204]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:11,390]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:14,601]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:16,920]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:22,090]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:26,786]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:31,452]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:34,508]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:39,331]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:44,509]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:51,879]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:26:58,820]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:27:09,435]\u001b[0m Trial 1418 finished with value: 10.616010003001108 and parameters: {'n_hidden': 3, 'learning_rate': 0.003328613901086539, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001563509771751197, 'dropout_rate_Layer_2': 0.26935271125594307, 'dropout_rate_Layer_3': 0.36671038995073785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012298112868834206, 'l1_Layer_2': 8.009419970391247e-05, 'l1_Layer_3': 1.4559679718197088e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 240, 'n_units_Layer_3': 300}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.62 | sMAPE for Validation Set is: 13.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.65 | sMAPE for Test Set is: 17.99% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:27:19,371]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:27:24,549]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:27:53,302]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:00,575]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:00,791]\u001b[0m Trial 1422 finished with value: 10.256223356293123 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014176311119780676, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38983338283618413, 'dropout_rate_Layer_2': 0.04495635391576096, 'dropout_rate_Layer_3': 0.2067215683476093, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000416521113132169, 'l1_Layer_2': 1.5037914246278802e-05, 'l1_Layer_3': 0.00011871933471644469, 'n_units_Layer_1': 170, 'n_units_Layer_2': 240, 'n_units_Layer_3': 165}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.26 | sMAPE for Validation Set is: 12.85% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.23 | sMAPE for Test Set is: 18.14% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:28:07,961]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:12,143]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:14,998]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:18,044]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:20,490]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:23,188]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:28,057]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:42,667]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:47,185]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:53,100]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:55,338]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:28:59,597]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:29:12,036]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:29:19,497]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:29:24,522]\u001b[0m Trial 1439 finished with value: 10.49734224248421 and parameters: {'n_hidden': 3, 'learning_rate': 0.002544857535979889, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009132863868893793, 'dropout_rate_Layer_2': 0.27837848589008873, 'dropout_rate_Layer_3': 0.10329926035989666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00990405007770401, 'l1_Layer_2': 2.6115128730310537e-05, 'l1_Layer_3': 1.5373397454544967e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 210, 'n_units_Layer_3': 180}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.50 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.61 | sMAPE for Test Set is: 17.87% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:29:27,063]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:29:34,372]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:29:34,478]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:29:42,948]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:29:43,429]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:29:48,860]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:29:49,355]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:29:54,550]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:29:56,678]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:03,183]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:05,052]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:10,055]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:12,964]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:19,256]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:24,565]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:35,018]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:39,738]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:39,853]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:47,661]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:47,838]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:54,024]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:30:59,048]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:31:46,122]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:31:53,554]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:01,304]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:04,532]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:09,403]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:13,869]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:19,377]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:24,508]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:26,283]\u001b[0m Trial 1463 finished with value: 10.055853991313132 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012620977058130803, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38716892526996455, 'dropout_rate_Layer_2': 0.06476794951604761, 'dropout_rate_Layer_3': 0.11073611824205726, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007079892739568273, 'l1_Layer_2': 5.7118318064808464e-05, 'l1_Layer_3': 0.00011566444014742431, 'n_units_Layer_1': 180, 'n_units_Layer_2': 250, 'n_units_Layer_3': 170}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.06 | sMAPE for Validation Set is: 12.78% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.22 | sMAPE for Test Set is: 17.57% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:32:31,478]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:36,147]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:41,673]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:48,642]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:53,620]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:32:58,625]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:33:01,791]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:33:08,450]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:33:11,637]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:33:21,216]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:33:26,167]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:33:33,298]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:33:40,670]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:33:45,431]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:34:02,932]\u001b[0m Trial 1486 finished with value: 10.48143975070513 and parameters: {'n_hidden': 3, 'learning_rate': 0.00840665641536763, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12329302728538251, 'dropout_rate_Layer_2': 0.10138173577759528, 'dropout_rate_Layer_3': 0.07936624786899141, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003920794090942604, 'l1_Layer_2': 0.027338522249721265, 'l1_Layer_3': 0.0013480484100790821, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.48 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.44 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:34:03,227]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:34:11,407]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:34:12,001]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:34:17,561]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:34:19,927]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:34:24,924]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:34:29,503]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:34:34,659]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:34:42,350]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:35:02,641]\u001b[0m Trial 1497 finished with value: 10.48174689136626 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032444208987128078, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37262138881148477, 'dropout_rate_Layer_2': 0.08238779120705958, 'dropout_rate_Layer_3': 0.1410092945943885, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000402842818229455, 'l1_Layer_2': 4.489691083021548e-05, 'l1_Layer_3': 0.00011791279658591461, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.48 | sMAPE for Validation Set is: 13.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 30.63 | sMAPE for Test Set is: 19.40% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-01 22:35:09,520]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-01 22:35:20,059]\u001b[0m Trial 1498 finished with value: 10.411057961559829 and parameters: {'n_hidden': 3, 'learning_rate': 0.002055787684445974, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38942036341281594, 'dropout_rate_Layer_2': 0.04745766430626729, 'dropout_rate_Layer_3': 0.12598979534232055, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023605291759985666, 'l1_Layer_2': 4.559931047986901e-05, 'l1_Layer_3': 8.438871847424014e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 245, 'n_units_Layer_3': 185}. Best is trial 1103 with value: 10.03978889744153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.41 | sMAPE for Validation Set is: 13.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.31 | sMAPE for Test Set is: 18.74% | rMAE for Test Set is: 0.53\n",
      "for 2022-01-01, MAE is:13.72 & sMAPE is:10.44% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :13.72 & 10.44% & 0.19\n",
      "for 2022-01-02, MAE is:17.06 & sMAPE is:14.05% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :15.39 & 12.24% & 0.21\n",
      "for 2022-01-03, MAE is:14.24 & sMAPE is:11.51% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :15.01 & 12.00% & 0.24\n",
      "for 2022-01-04, MAE is:18.05 & sMAPE is:12.67% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :15.77 & 12.17% & 0.57\n",
      "for 2022-01-05, MAE is:7.08 & sMAPE is:5.42% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :14.03 & 10.82% & 0.50\n",
      "for 2022-01-06, MAE is:49.66 & sMAPE is:28.09% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :19.97 & 13.70% & 0.59\n",
      "for 2022-01-07, MAE is:25.72 & sMAPE is:15.09% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :20.79 & 13.90% & 0.66\n",
      "for 2022-01-08, MAE is:13.19 & sMAPE is:8.99% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :19.84 & 13.28% & 0.65\n",
      "for 2022-01-09, MAE is:26.00 & sMAPE is:17.84% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :20.53 & 13.79% & 0.68\n",
      "for 2022-01-10, MAE is:43.48 & sMAPE is:20.88% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :22.82 & 14.50% & 0.68\n",
      "for 2022-01-11, MAE is:8.44 & sMAPE is:5.54% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :21.51 & 13.68% & 0.69\n",
      "for 2022-01-12, MAE is:8.83 & sMAPE is:6.32% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :20.46 & 13.07% & 0.70\n",
      "for 2022-01-13, MAE is:5.17 & sMAPE is:3.97% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :19.28 & 12.37% & 0.66\n",
      "for 2022-01-14, MAE is:6.79 & sMAPE is:5.26% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :18.39 & 11.86% & 0.63\n",
      "for 2022-01-15, MAE is:21.34 & sMAPE is:13.94% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :18.59 & 12.00% & 0.69\n",
      "for 2022-01-16, MAE is:13.13 & sMAPE is:9.82% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :18.24 & 11.86% & 0.67\n",
      "for 2022-01-17, MAE is:7.07 & sMAPE is:5.21% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :17.59 & 11.47% & 0.64\n",
      "for 2022-01-18, MAE is:25.83 & sMAPE is:14.99% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :18.05 & 11.67% & 0.67\n",
      "for 2022-01-19, MAE is:5.23 & sMAPE is:3.93% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :17.37 & 11.26% & 0.71\n",
      "for 2022-01-20, MAE is:3.67 & sMAPE is:2.81% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :16.69 & 10.84% & 0.71\n",
      "for 2022-01-21, MAE is:9.41 & sMAPE is:7.00% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :16.34 & 10.66% & 0.72\n",
      "for 2022-01-22, MAE is:7.04 & sMAPE is:5.15% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :15.92 & 10.41% & 0.71\n",
      "for 2022-01-23, MAE is:3.74 & sMAPE is:2.75% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :15.39 & 10.07% & 0.69\n",
      "for 2022-01-24, MAE is:3.36 & sMAPE is:2.52% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :14.89 & 9.76% & 0.68\n",
      "for 2022-01-25, MAE is:22.05 & sMAPE is:14.61% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :15.17 & 9.95% & 0.69\n",
      "for 2022-01-26, MAE is:11.88 & sMAPE is:8.49% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :15.05 & 9.90% & 0.74\n",
      "for 2022-01-27, MAE is:3.60 & sMAPE is:2.81% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 9.63% & 0.74\n",
      "for 2022-01-28, MAE is:12.71 & sMAPE is:9.70% & rMAE is:4.63 ||| daily mean of MAE & sMAPE & rMAE till now are :14.55 & 9.64% & 0.88\n",
      "for 2022-01-29, MAE is:22.44 & sMAPE is:21.46% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :14.83 & 10.04% & 0.88\n",
      "for 2022-01-30, MAE is:11.50 & sMAPE is:9.46% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :14.72 & 10.02% & 0.87\n",
      "for 2022-01-31, MAE is:35.26 & sMAPE is:21.70% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :15.38 & 10.40% & 0.88\n",
      "for 2022-02-01, MAE is:19.05 & sMAPE is:12.66% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :15.49 & 10.47% & 0.87\n",
      "for 2022-02-02, MAE is:10.19 & sMAPE is:7.61% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :15.33 & 10.38% & 0.87\n",
      "for 2022-02-03, MAE is:10.89 & sMAPE is:7.26% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :15.20 & 10.29% & 0.86\n",
      "for 2022-02-04, MAE is:11.69 & sMAPE is:8.93% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :15.10 & 10.25% & 0.86\n",
      "for 2022-02-05, MAE is:4.03 & sMAPE is:3.45% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :14.79 & 10.06% & 0.84\n",
      "for 2022-02-06, MAE is:7.13 & sMAPE is:6.76% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :14.59 & 9.98% & 0.84\n",
      "for 2022-02-07, MAE is:5.99 & sMAPE is:4.99% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.36 & 9.84% & 0.82\n",
      "for 2022-02-08, MAE is:4.56 & sMAPE is:3.67% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :14.11 & 9.69% & 0.81\n",
      "for 2022-02-09, MAE is:6.80 & sMAPE is:5.42% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :13.93 & 9.58% & 0.80\n",
      "for 2022-02-10, MAE is:5.73 & sMAPE is:4.80% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :13.73 & 9.46% & 0.78\n",
      "for 2022-02-11, MAE is:7.03 & sMAPE is:5.62% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :13.57 & 9.37% & 0.80\n",
      "for 2022-02-12, MAE is:9.76 & sMAPE is:8.38% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :13.48 & 9.35% & 0.82\n",
      "for 2022-02-13, MAE is:5.98 & sMAPE is:5.66% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :13.31 & 9.26% & 0.81\n",
      "for 2022-02-14, MAE is:4.73 & sMAPE is:4.39% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :13.12 & 9.16% & 0.80\n",
      "for 2022-02-15, MAE is:5.90 & sMAPE is:5.33% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :12.96 & 9.07% & 0.79\n",
      "for 2022-02-16, MAE is:4.27 & sMAPE is:3.99% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :12.78 & 8.96% & 0.78\n",
      "for 2022-02-17, MAE is:3.18 & sMAPE is:3.08% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :12.58 & 8.84% & 0.77\n",
      "for 2022-02-18, MAE is:9.25 & sMAPE is:8.73% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :12.51 & 8.84% & 0.77\n",
      "for 2022-02-19, MAE is:5.71 & sMAPE is:5.47% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :12.37 & 8.77% & 0.76\n",
      "for 2022-02-20, MAE is:4.61 & sMAPE is:4.64% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :12.22 & 8.69% & 0.77\n",
      "for 2022-02-21, MAE is:4.17 & sMAPE is:3.94% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :12.07 & 8.60% & 0.78\n",
      "for 2022-02-22, MAE is:15.84 & sMAPE is:13.06% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :12.14 & 8.68% & 0.79\n",
      "for 2022-02-23, MAE is:5.79 & sMAPE is:5.28% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :12.02 & 8.62% & 0.81\n",
      "for 2022-02-24, MAE is:9.55 & sMAPE is:8.65% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :11.97 & 8.62% & 0.80\n",
      "for 2022-02-25, MAE is:12.80 & sMAPE is:10.86% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :11.99 & 8.66% & 0.80\n",
      "for 2022-02-26, MAE is:19.94 & sMAPE is:15.45% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :12.13 & 8.78% & 0.80\n",
      "for 2022-02-27, MAE is:7.55 & sMAPE is:5.64% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :12.05 & 8.73% & 0.79\n",
      "for 2022-02-28, MAE is:7.46 & sMAPE is:5.37% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :11.97 & 8.67% & 0.78\n",
      "for 2022-03-01, MAE is:10.36 & sMAPE is:7.38% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :11.94 & 8.65% & 0.77\n",
      "for 2022-03-02, MAE is:10.96 & sMAPE is:7.52% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :11.93 & 8.63% & 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-03, MAE is:16.72 & sMAPE is:10.98% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :12.01 & 8.67% & 0.76\n",
      "for 2022-03-04, MAE is:48.92 & sMAPE is:24.27% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :12.59 & 8.91% & 0.76\n",
      "for 2022-03-05, MAE is:12.19 & sMAPE is:6.88% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :12.59 & 8.88% & 0.75\n",
      "for 2022-03-06, MAE is:12.84 & sMAPE is:7.05% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :12.59 & 8.85% & 0.74\n",
      "for 2022-03-07, MAE is:51.39 & sMAPE is:17.87% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :13.18 & 8.99% & 0.74\n",
      "for 2022-03-08, MAE is:75.29 & sMAPE is:25.98% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :14.10 & 9.25% & 0.74\n",
      "for 2022-03-09, MAE is:19.23 & sMAPE is:8.76% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :14.18 & 9.24% & 0.73\n",
      "for 2022-03-10, MAE is:13.74 & sMAPE is:6.60% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :14.17 & 9.20% & 0.72\n",
      "for 2022-03-11, MAE is:17.84 & sMAPE is:8.69% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :14.23 & 9.19% & 0.72\n",
      "for 2022-03-12, MAE is:11.62 & sMAPE is:6.14% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :14.19 & 9.15% & 0.74\n",
      "for 2022-03-13, MAE is:16.71 & sMAPE is:9.82% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :14.22 & 9.16% & 0.74\n",
      "for 2022-03-14, MAE is:18.54 & sMAPE is:9.91% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :14.28 & 9.17% & 0.73\n",
      "for 2022-03-15, MAE is:19.63 & sMAPE is:8.96% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :14.36 & 9.17% & 0.73\n",
      "for 2022-03-16, MAE is:18.63 & sMAPE is:9.18% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :14.41 & 9.17% & 0.73\n",
      "for 2022-03-17, MAE is:8.05 & sMAPE is:4.46% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :14.33 & 9.10% & 0.72\n",
      "for 2022-03-18, MAE is:5.62 & sMAPE is:3.15% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :14.22 & 9.03% & 0.72\n",
      "for 2022-03-19, MAE is:17.90 & sMAPE is:10.32% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :14.26 & 9.04% & 0.73\n",
      "for 2022-03-20, MAE is:6.17 & sMAPE is:3.73% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :14.16 & 8.98% & 0.72\n",
      "for 2022-03-21, MAE is:10.30 & sMAPE is:5.84% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :14.11 & 8.94% & 0.72\n",
      "for 2022-03-22, MAE is:15.94 & sMAPE is:8.22% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :14.13 & 8.93% & 0.72\n",
      "for 2022-03-23, MAE is:22.21 & sMAPE is:10.75% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :14.23 & 8.95% & 0.73\n",
      "for 2022-03-24, MAE is:7.39 & sMAPE is:3.87% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :14.15 & 8.89% & 0.73\n",
      "for 2022-03-25, MAE is:10.94 & sMAPE is:5.85% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :14.11 & 8.85% & 0.74\n",
      "for 2022-03-26, MAE is:9.31 & sMAPE is:5.10% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :14.06 & 8.81% & 0.74\n",
      "for 2022-03-27, MAE is:12.75 & sMAPE is:6.95% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :14.04 & 8.79% & 0.74\n",
      "for 2022-03-28, MAE is:7.67 & sMAPE is:4.19% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :13.97 & 8.73% & 0.74\n",
      "for 2022-03-29, MAE is:15.77 & sMAPE is:7.91% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :13.99 & 8.72% & 0.75\n",
      "for 2022-03-30, MAE is:20.56 & sMAPE is:9.57% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :14.06 & 8.73% & 0.76\n",
      "for 2022-03-31, MAE is:19.83 & sMAPE is:9.00% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :14.13 & 8.74% & 0.76\n",
      "for 2022-04-01, MAE is:10.92 & sMAPE is:5.61% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :14.09 & 8.70% & 0.77\n",
      "for 2022-04-02, MAE is:6.21 & sMAPE is:3.37% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.00 & 8.65% & 0.78\n",
      "for 2022-04-03, MAE is:11.12 & sMAPE is:6.05% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :13.97 & 8.62% & 0.79\n",
      "for 2022-04-04, MAE is:11.78 & sMAPE is:6.46% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :13.95 & 8.59% & 0.79\n",
      "for 2022-04-05, MAE is:11.32 & sMAPE is:6.44% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :13.92 & 8.57% & 0.78\n",
      "for 2022-04-06, MAE is:12.06 & sMAPE is:6.56% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :13.90 & 8.55% & 0.78\n",
      "for 2022-04-07, MAE is:10.39 & sMAPE is:5.86% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :13.87 & 8.52% & 0.77\n",
      "for 2022-04-08, MAE is:8.53 & sMAPE is:4.99% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :13.81 & 8.49% & 0.77\n",
      "for 2022-04-09, MAE is:8.27 & sMAPE is:4.86% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :13.76 & 8.45% & 0.77\n",
      "for 2022-04-10, MAE is:8.54 & sMAPE is:5.11% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :13.70 & 8.42% & 0.76\n",
      "for 2022-04-11, MAE is:20.35 & sMAPE is:10.96% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :13.77 & 8.44% & 0.77\n",
      "for 2022-04-12, MAE is:10.56 & sMAPE is:5.73% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :13.74 & 8.42% & 0.77\n",
      "for 2022-04-13, MAE is:9.31 & sMAPE is:5.22% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :13.70 & 8.38% & 0.77\n",
      "for 2022-04-14, MAE is:12.05 & sMAPE is:6.48% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :13.68 & 8.37% & 0.77\n",
      "for 2022-04-15, MAE is:12.40 & sMAPE is:6.61% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :13.67 & 8.35% & 0.77\n",
      "for 2022-04-16, MAE is:21.51 & sMAPE is:12.68% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :13.74 & 8.39% & 0.77\n",
      "for 2022-04-17, MAE is:29.11 & sMAPE is:19.84% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :13.89 & 8.50% & 0.78\n",
      "for 2022-04-18, MAE is:39.23 & sMAPE is:29.46% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :14.12 & 8.69% & 0.78\n",
      "for 2022-04-19, MAE is:33.82 & sMAPE is:18.23% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :14.30 & 8.78% & 0.79\n",
      "for 2022-04-20, MAE is:9.58 & sMAPE is:5.13% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :14.26 & 8.75% & 0.79\n",
      "for 2022-04-21, MAE is:7.11 & sMAPE is:3.79% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :14.19 & 8.70% & 0.79\n",
      "for 2022-04-22, MAE is:14.96 & sMAPE is:9.18% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :14.20 & 8.71% & 0.80\n",
      "for 2022-04-23, MAE is:15.50 & sMAPE is:10.00% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :14.21 & 8.72% & 0.80\n",
      "for 2022-04-24, MAE is:46.09 & sMAPE is:34.60% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 8.94% & 0.80\n",
      "for 2022-04-25, MAE is:47.86 & sMAPE is:26.30% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :14.78 & 9.09% & 0.80\n",
      "for 2022-04-26, MAE is:10.89 & sMAPE is:5.77% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :14.75 & 9.07% & 0.80\n",
      "for 2022-04-27, MAE is:9.39 & sMAPE is:4.54% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :14.70 & 9.03% & 0.80\n",
      "for 2022-04-28, MAE is:16.48 & sMAPE is:7.63% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :14.72 & 9.02% & 0.80\n",
      "for 2022-04-29, MAE is:16.53 & sMAPE is:7.54% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :14.73 & 9.00% & 0.80\n",
      "for 2022-04-30, MAE is:11.42 & sMAPE is:5.71% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :14.71 & 8.98% & 0.79\n",
      "for 2022-05-01, MAE is:13.77 & sMAPE is:7.17% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :14.70 & 8.96% & 0.79\n",
      "for 2022-05-02, MAE is:9.11 & sMAPE is:4.40% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :14.65 & 8.92% & 0.79\n",
      "for 2022-05-03, MAE is:14.32 & sMAPE is:6.48% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :14.65 & 8.90% & 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-04, MAE is:15.39 & sMAPE is:6.74% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :14.65 & 8.89% & 0.79\n",
      "for 2022-05-05, MAE is:9.41 & sMAPE is:4.19% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 8.85% & 0.79\n",
      "for 2022-05-06, MAE is:13.32 & sMAPE is:6.09% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :14.60 & 8.83% & 0.79\n",
      "for 2022-05-07, MAE is:10.96 & sMAPE is:5.60% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :14.57 & 8.80% & 0.80\n",
      "for 2022-05-08, MAE is:19.59 & sMAPE is:10.86% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 8.82% & 0.81\n",
      "for 2022-05-09, MAE is:9.35 & sMAPE is:4.72% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :14.57 & 8.79% & 0.81\n",
      "for 2022-05-10, MAE is:15.47 & sMAPE is:7.99% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :14.58 & 8.78% & 0.81\n",
      "for 2022-05-11, MAE is:19.90 & sMAPE is:11.04% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 8.80% & 0.81\n",
      "for 2022-05-12, MAE is:29.71 & sMAPE is:19.30% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :14.73 & 8.88% & 0.81\n",
      "for 2022-05-13, MAE is:35.09 & sMAPE is:28.95% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :14.89 & 9.03% & 0.80\n",
      "for 2022-05-14, MAE is:32.46 & sMAPE is:29.70% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :15.02 & 9.18% & 0.80\n",
      "for 2022-05-15, MAE is:35.07 & sMAPE is:28.65% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :15.17 & 9.33% & 0.80\n",
      "for 2022-05-16, MAE is:16.10 & sMAPE is:9.58% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :15.17 & 9.33% & 0.80\n",
      "for 2022-05-17, MAE is:7.17 & sMAPE is:4.04% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :15.12 & 9.29% & 0.80\n",
      "for 2022-05-18, MAE is:8.00 & sMAPE is:4.42% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :15.06 & 9.25% & 0.80\n",
      "for 2022-05-19, MAE is:12.11 & sMAPE is:6.45% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :15.04 & 9.23% & 0.80\n",
      "for 2022-05-20, MAE is:6.22 & sMAPE is:3.42% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.98 & 9.19% & 0.79\n",
      "for 2022-05-21, MAE is:40.22 & sMAPE is:28.63% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :15.16 & 9.33% & 0.80\n",
      "for 2022-05-22, MAE is:18.54 & sMAPE is:12.09% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :15.18 & 9.35% & 0.80\n",
      "for 2022-05-23, MAE is:9.69 & sMAPE is:5.50% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :15.14 & 9.32% & 0.80\n",
      "for 2022-05-24, MAE is:38.32 & sMAPE is:33.77% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :15.30 & 9.49% & 0.80\n",
      "for 2022-05-25, MAE is:14.74 & sMAPE is:10.07% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :15.30 & 9.50% & 0.80\n",
      "for 2022-05-26, MAE is:89.71 & sMAPE is:107.71% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :15.81 & 10.17% & 0.80\n",
      "for 2022-05-27, MAE is:58.57 & sMAPE is:90.77% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :16.10 & 10.72% & 0.79\n",
      "for 2022-05-28, MAE is:62.51 & sMAPE is:149.06% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :16.42 & 11.65% & 0.79\n",
      "for 2022-05-29, MAE is:57.78 & sMAPE is:51.60% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :16.69 & 11.92% & 0.80\n",
      "for 2022-05-30, MAE is:26.71 & sMAPE is:16.50% & rMAE is:2.53 ||| daily mean of MAE & sMAPE & rMAE till now are :16.76 & 11.95% & 0.82\n",
      "for 2022-05-31, MAE is:17.34 & sMAPE is:10.45% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :16.76 & 11.94% & 0.81\n",
      "for 2022-06-01, MAE is:13.82 & sMAPE is:8.01% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :16.74 & 11.91% & 0.81\n",
      "for 2022-06-02, MAE is:5.91 & sMAPE is:3.64% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :16.67 & 11.86% & 0.81\n",
      "for 2022-06-03, MAE is:8.79 & sMAPE is:5.55% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :16.62 & 11.82% & 0.80\n",
      "for 2022-06-04, MAE is:15.41 & sMAPE is:10.65% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :16.61 & 11.81% & 0.80\n",
      "for 2022-06-05, MAE is:19.54 & sMAPE is:13.91% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :16.63 & 11.83% & 0.81\n",
      "for 2022-06-06, MAE is:64.18 & sMAPE is:70.96% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :16.94 & 12.20% & 0.81\n",
      "for 2022-06-07, MAE is:37.10 & sMAPE is:25.17% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :17.06 & 12.28% & 0.82\n",
      "for 2022-06-08, MAE is:21.02 & sMAPE is:15.71% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :17.09 & 12.31% & 0.82\n",
      "for 2022-06-09, MAE is:18.07 & sMAPE is:11.60% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :17.09 & 12.30% & 0.82\n",
      "for 2022-06-10, MAE is:9.99 & sMAPE is:6.90% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :17.05 & 12.27% & 0.82\n",
      "for 2022-06-11, MAE is:23.82 & sMAPE is:27.47% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :17.09 & 12.36% & 0.82\n",
      "for 2022-06-12, MAE is:40.13 & sMAPE is:50.46% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :17.23 & 12.60% & 0.82\n",
      "for 2022-06-13, MAE is:27.28 & sMAPE is:22.06% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :17.29 & 12.65% & 0.81\n",
      "for 2022-06-14, MAE is:13.22 & sMAPE is:9.49% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :17.27 & 12.63% & 0.81\n",
      "for 2022-06-15, MAE is:14.27 & sMAPE is:9.31% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :17.25 & 12.61% & 0.81\n",
      "for 2022-06-16, MAE is:25.32 & sMAPE is:15.11% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :17.30 & 12.63% & 0.82\n",
      "for 2022-06-17, MAE is:23.46 & sMAPE is:13.70% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :17.34 & 12.64% & 0.82\n",
      "for 2022-06-18, MAE is:10.73 & sMAPE is:8.36% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :17.30 & 12.61% & 0.81\n",
      "for 2022-06-19, MAE is:21.47 & sMAPE is:17.40% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :17.32 & 12.64% & 0.81\n",
      "for 2022-06-20, MAE is:24.23 & sMAPE is:15.20% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :17.36 & 12.65% & 0.81\n",
      "for 2022-06-21, MAE is:12.89 & sMAPE is:7.94% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :17.34 & 12.63% & 0.81\n",
      "for 2022-06-22, MAE is:10.34 & sMAPE is:6.42% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :17.30 & 12.59% & 0.81\n",
      "for 2022-06-23, MAE is:10.68 & sMAPE is:6.95% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :17.26 & 12.56% & 0.81\n",
      "for 2022-06-24, MAE is:6.72 & sMAPE is:4.85% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :17.20 & 12.51% & 0.81\n",
      "for 2022-06-25, MAE is:4.04 & sMAPE is:2.75% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :17.12 & 12.46% & 0.80\n",
      "for 2022-06-26, MAE is:17.55 & sMAPE is:14.14% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :17.13 & 12.47% & 0.81\n",
      "for 2022-06-27, MAE is:11.89 & sMAPE is:7.67% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :17.10 & 12.44% & 0.81\n",
      "for 2022-06-28, MAE is:6.24 & sMAPE is:4.15% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :17.04 & 12.39% & 0.81\n",
      "for 2022-06-29, MAE is:7.93 & sMAPE is:5.13% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :16.99 & 12.35% & 0.81\n",
      "for 2022-06-30, MAE is:14.78 & sMAPE is:9.27% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :16.97 & 12.34% & 0.81\n",
      "for 2022-07-01, MAE is:11.50 & sMAPE is:6.92% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :16.94 & 12.31% & 0.80\n",
      "for 2022-07-02, MAE is:11.31 & sMAPE is:7.50% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :16.91 & 12.28% & 0.81\n",
      "for 2022-07-03, MAE is:18.15 & sMAPE is:14.01% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :16.92 & 12.29% & 0.81\n",
      "for 2022-07-04, MAE is:6.93 & sMAPE is:4.48% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :16.86 & 12.25% & 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-05, MAE is:8.59 & sMAPE is:5.50% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :16.82 & 12.21% & 0.81\n",
      "for 2022-07-06, MAE is:7.71 & sMAPE is:4.85% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :16.77 & 12.17% & 0.81\n",
      "for 2022-07-07, MAE is:4.48 & sMAPE is:2.78% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :16.71 & 12.12% & 0.81\n",
      "for 2022-07-08, MAE is:3.67 & sMAPE is:2.27% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :16.64 & 12.07% & 0.81\n",
      "for 2022-07-09, MAE is:53.66 & sMAPE is:48.78% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :16.83 & 12.26% & 0.81\n",
      "for 2022-07-10, MAE is:57.36 & sMAPE is:67.49% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :17.04 & 12.55% & 0.81\n",
      "for 2022-07-11, MAE is:50.84 & sMAPE is:33.81% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :17.22 & 12.66% & 0.82\n",
      "for 2022-07-12, MAE is:16.96 & sMAPE is:9.76% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :17.22 & 12.65% & 0.82\n",
      "for 2022-07-13, MAE is:9.51 & sMAPE is:5.61% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :17.18 & 12.61% & 0.82\n",
      "for 2022-07-14, MAE is:9.36 & sMAPE is:5.35% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :17.14 & 12.57% & 0.82\n",
      "for 2022-07-15, MAE is:10.22 & sMAPE is:6.44% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :17.10 & 12.54% & 0.83\n",
      "for 2022-07-16, MAE is:55.93 & sMAPE is:62.24% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :17.30 & 12.80% & 0.83\n",
      "for 2022-07-17, MAE is:26.37 & sMAPE is:19.02% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :17.35 & 12.83% & 0.83\n",
      "for 2022-07-18, MAE is:6.54 & sMAPE is:4.00% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :17.29 & 12.78% & 0.82\n",
      "for 2022-07-19, MAE is:4.63 & sMAPE is:2.89% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :17.23 & 12.73% & 0.82\n",
      "for 2022-07-20, MAE is:5.35 & sMAPE is:3.38% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :17.17 & 12.69% & 0.82\n",
      "for 2022-07-21, MAE is:26.23 & sMAPE is:14.16% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :17.21 & 12.69% & 0.82\n",
      "for 2022-07-22, MAE is:9.02 & sMAPE is:5.11% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :17.17 & 12.66% & 0.82\n",
      "for 2022-07-23, MAE is:6.20 & sMAPE is:3.86% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :17.12 & 12.61% & 0.82\n",
      "for 2022-07-24, MAE is:27.17 & sMAPE is:21.13% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :17.17 & 12.66% & 0.82\n",
      "for 2022-07-25, MAE is:9.11 & sMAPE is:5.57% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :17.13 & 12.62% & 0.82\n",
      "for 2022-07-26, MAE is:19.85 & sMAPE is:13.12% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :17.14 & 12.62% & 0.82\n",
      "for 2022-07-27, MAE is:22.45 & sMAPE is:13.44% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :17.17 & 12.63% & 0.82\n",
      "for 2022-07-28, MAE is:42.11 & sMAPE is:22.90% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :17.29 & 12.68% & 0.83\n",
      "for 2022-07-29, MAE is:16.63 & sMAPE is:8.27% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :17.29 & 12.66% & 0.82\n",
      "for 2022-07-30, MAE is:10.15 & sMAPE is:4.96% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :17.25 & 12.62% & 0.82\n",
      "for 2022-07-31, MAE is:11.55 & sMAPE is:5.61% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :17.22 & 12.59% & 0.82\n",
      "for 2022-08-01, MAE is:9.48 & sMAPE is:4.43% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :17.19 & 12.55% & 0.82\n",
      "for 2022-08-02, MAE is:30.05 & sMAPE is:13.44% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :17.25 & 12.55% & 0.81\n",
      "for 2022-08-03, MAE is:22.15 & sMAPE is:9.72% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :17.27 & 12.54% & 0.81\n",
      "for 2022-08-04, MAE is:8.33 & sMAPE is:3.57% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :17.23 & 12.50% & 0.81\n",
      "for 2022-08-05, MAE is:7.54 & sMAPE is:3.18% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :17.19 & 12.45% & 0.81\n",
      "for 2022-08-06, MAE is:24.75 & sMAPE is:12.62% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :17.22 & 12.45% & 0.81\n",
      "for 2022-08-07, MAE is:36.45 & sMAPE is:17.72% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :17.31 & 12.48% & 0.81\n",
      "for 2022-08-08, MAE is:29.50 & sMAPE is:11.03% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :17.36 & 12.47% & 0.81\n",
      "for 2022-08-09, MAE is:11.23 & sMAPE is:4.19% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :17.34 & 12.43% & 0.80\n",
      "for 2022-08-10, MAE is:9.16 & sMAPE is:3.55% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :17.30 & 12.39% & 0.80\n",
      "for 2022-08-11, MAE is:9.21 & sMAPE is:3.59% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :17.26 & 12.36% & 0.80\n",
      "for 2022-08-12, MAE is:27.05 & sMAPE is:9.65% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :17.31 & 12.34% & 0.80\n",
      "for 2022-08-13, MAE is:11.61 & sMAPE is:4.56% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :17.28 & 12.31% & 0.80\n",
      "for 2022-08-14, MAE is:16.48 & sMAPE is:6.52% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :17.28 & 12.28% & 0.80\n",
      "for 2022-08-15, MAE is:16.32 & sMAPE is:6.07% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :17.27 & 12.26% & 0.80\n",
      "for 2022-08-16, MAE is:42.03 & sMAPE is:12.96% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :17.38 & 12.26% & 0.80\n",
      "for 2022-08-17, MAE is:39.15 & sMAPE is:12.29% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :17.48 & 12.26% & 0.80\n",
      "for 2022-08-18, MAE is:46.80 & sMAPE is:13.92% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :17.60 & 12.27% & 0.80\n",
      "for 2022-08-19, MAE is:48.29 & sMAPE is:13.38% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :17.74 & 12.27% & 0.79\n",
      "for 2022-08-20, MAE is:22.35 & sMAPE is:6.41% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :17.76 & 12.25% & 0.79\n",
      "for 2022-08-21, MAE is:48.67 & sMAPE is:16.59% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :17.89 & 12.26% & 0.79\n",
      "for 2022-08-22, MAE is:28.93 & sMAPE is:7.66% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :17.94 & 12.24% & 0.79\n",
      "for 2022-08-23, MAE is:59.77 & sMAPE is:14.34% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :18.11 & 12.25% & 0.79\n",
      "for 2022-08-24, MAE is:39.26 & sMAPE is:9.07% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :18.20 & 12.24% & 0.79\n",
      "for 2022-08-25, MAE is:50.01 & sMAPE is:11.17% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :18.34 & 12.24% & 0.78\n",
      "for 2022-08-26, MAE is:27.97 & sMAPE is:5.92% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :18.38 & 12.21% & 0.78\n",
      "for 2022-08-27, MAE is:47.25 & sMAPE is:9.76% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :18.50 & 12.20% & 0.78\n",
      "for 2022-08-28, MAE is:48.56 & sMAPE is:10.14% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :18.62 & 12.19% & 0.78\n",
      "for 2022-08-29, MAE is:80.59 & sMAPE is:14.32% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :18.88 & 12.20% & 0.78\n",
      "for 2022-08-30, MAE is:80.65 & sMAPE is:12.66% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :19.14 & 12.20% & 0.77\n",
      "for 2022-08-31, MAE is:56.64 & sMAPE is:9.28% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :19.29 & 12.19% & 0.77\n",
      "for 2022-09-01, MAE is:49.18 & sMAPE is:8.59% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :19.41 & 12.17% & 0.77\n",
      "for 2022-09-02, MAE is:128.52 & sMAPE is:28.31% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :19.86 & 12.24% & 0.77\n",
      "for 2022-09-03, MAE is:74.91 & sMAPE is:20.15% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :20.08 & 12.27% & 0.77\n",
      "for 2022-09-04, MAE is:112.19 & sMAPE is:35.15% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :20.46 & 12.36% & 0.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-05, MAE is:82.39 & sMAPE is:22.26% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :20.71 & 12.40% & 0.77\n",
      "for 2022-09-06, MAE is:85.29 & sMAPE is:21.41% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :20.97 & 12.44% & 0.77\n",
      "for 2022-09-07, MAE is:35.93 & sMAPE is:7.86% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :21.03 & 12.42% & 0.77\n",
      "for 2022-09-08, MAE is:35.68 & sMAPE is:8.21% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :21.08 & 12.41% & 0.77\n",
      "for 2022-09-09, MAE is:73.90 & sMAPE is:21.28% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :21.29 & 12.44% & 0.77\n",
      "for 2022-09-10, MAE is:46.67 & sMAPE is:11.72% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :21.39 & 12.44% & 0.77\n",
      "for 2022-09-11, MAE is:37.66 & sMAPE is:9.45% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :21.46 & 12.43% & 0.76\n",
      "for 2022-09-12, MAE is:45.25 & sMAPE is:11.01% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :21.55 & 12.42% & 0.76\n",
      "for 2022-09-13, MAE is:41.76 & sMAPE is:11.13% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :21.63 & 12.42% & 0.76\n",
      "for 2022-09-14, MAE is:42.50 & sMAPE is:10.23% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :21.71 & 12.41% & 0.76\n",
      "for 2022-09-15, MAE is:46.82 & sMAPE is:13.10% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :21.81 & 12.41% & 0.76\n",
      "for 2022-09-16, MAE is:76.69 & sMAPE is:25.95% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :22.02 & 12.46% & 0.76\n",
      "for 2022-09-17, MAE is:85.77 & sMAPE is:36.31% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :22.27 & 12.55% & 0.76\n",
      "for 2022-09-18, MAE is:166.31 & sMAPE is:99.99% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :22.82 & 12.89% & 0.76\n",
      "for 2022-09-19, MAE is:125.70 & sMAPE is:52.76% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :23.21 & 13.04% & 0.76\n",
      "for 2022-09-20, MAE is:86.95 & sMAPE is:25.31% & rMAE is:3.34 ||| daily mean of MAE & sMAPE & rMAE till now are :23.45 & 13.09% & 0.77\n",
      "for 2022-09-21, MAE is:47.39 & sMAPE is:12.38% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :23.54 & 13.09% & 0.77\n",
      "for 2022-09-22, MAE is:35.31 & sMAPE is:9.50% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :23.59 & 13.07% & 0.77\n",
      "for 2022-09-23, MAE is:19.14 & sMAPE is:5.52% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :23.57 & 13.04% & 0.77\n",
      "for 2022-09-24, MAE is:15.73 & sMAPE is:4.66% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :23.54 & 13.01% & 0.77\n",
      "for 2022-09-25, MAE is:36.69 & sMAPE is:12.83% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :23.59 & 13.01% & 0.77\n",
      "for 2022-09-26, MAE is:62.49 & sMAPE is:26.32% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :23.73 & 13.06% & 0.77\n",
      "for 2022-09-27, MAE is:36.88 & sMAPE is:13.62% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :23.78 & 13.06% & 0.77\n",
      "for 2022-09-28, MAE is:12.11 & sMAPE is:4.21% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :23.74 & 13.03% & 0.77\n",
      "for 2022-09-29, MAE is:37.97 & sMAPE is:12.11% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :23.79 & 13.03% & 0.77\n",
      "for 2022-09-30, MAE is:54.21 & sMAPE is:20.72% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :23.90 & 13.05% & 0.77\n",
      "for 2022-10-01, MAE is:175.20 & sMAPE is:108.57% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :24.46 & 13.40% & 0.77\n",
      "for 2022-10-02, MAE is:76.04 & sMAPE is:50.56% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :24.64 & 13.54% & 0.77\n",
      "for 2022-10-03, MAE is:78.33 & sMAPE is:37.21% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :24.84 & 13.62% & 0.77\n",
      "for 2022-10-04, MAE is:58.44 & sMAPE is:28.08% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :24.96 & 13.68% & 0.77\n",
      "for 2022-10-05, MAE is:135.99 & sMAPE is:122.78% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :25.36 & 14.07% & 0.77\n",
      "for 2022-10-06, MAE is:49.57 & sMAPE is:119.61% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :25.45 & 14.45% & 0.77\n",
      "for 2022-10-07, MAE is:37.53 & sMAPE is:95.50% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :25.49 & 14.74% & 0.76\n",
      "for 2022-10-08, MAE is:14.14 & sMAPE is:32.30% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :25.45 & 14.80% & 0.76\n",
      "for 2022-10-09, MAE is:45.48 & sMAPE is:66.62% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :25.52 & 14.98% & 0.76\n",
      "for 2022-10-10, MAE is:46.71 & sMAPE is:40.28% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :25.59 & 15.07% & 0.76\n",
      "for 2022-10-11, MAE is:36.24 & sMAPE is:23.14% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :25.63 & 15.10% & 0.76\n",
      "for 2022-10-12, MAE is:41.01 & sMAPE is:24.74% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :25.69 & 15.13% & 0.76\n",
      "for 2022-10-13, MAE is:76.91 & sMAPE is:40.48% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :25.87 & 15.22% & 0.76\n",
      "for 2022-10-14, MAE is:26.68 & sMAPE is:13.06% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :25.87 & 15.22% & 0.76\n",
      "for 2022-10-15, MAE is:25.62 & sMAPE is:16.04% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :25.87 & 15.22% & 0.75\n",
      "for 2022-10-16, MAE is:44.85 & sMAPE is:38.44% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :25.93 & 15.30% & 0.76\n",
      "for 2022-10-17, MAE is:24.30 & sMAPE is:17.52% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :25.93 & 15.31% & 0.76\n",
      "for 2022-10-18, MAE is:19.62 & sMAPE is:12.12% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :25.91 & 15.30% & 0.76\n",
      "for 2022-10-19, MAE is:16.35 & sMAPE is:10.67% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :25.87 & 15.28% & 0.76\n",
      "for 2022-10-20, MAE is:21.20 & sMAPE is:16.69% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :25.86 & 15.28% & 0.76\n",
      "for 2022-10-21, MAE is:23.45 & sMAPE is:15.96% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :25.85 & 15.29% & 0.76\n",
      "for 2022-10-22, MAE is:9.77 & sMAPE is:6.96% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :25.79 & 15.26% & 0.76\n",
      "for 2022-10-23, MAE is:29.29 & sMAPE is:26.65% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :25.81 & 15.30% & 0.76\n",
      "for 2022-10-24, MAE is:22.38 & sMAPE is:28.76% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :25.79 & 15.34% & 0.75\n",
      "for 2022-10-25, MAE is:26.25 & sMAPE is:25.70% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :25.80 & 15.38% & 0.75\n",
      "for 2022-10-26, MAE is:17.30 & sMAPE is:14.83% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :25.77 & 15.38% & 0.75\n",
      "for 2022-10-27, MAE is:13.94 & sMAPE is:12.59% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :25.73 & 15.37% & 0.75\n",
      "for 2022-10-28, MAE is:12.32 & sMAPE is:12.12% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :25.68 & 15.36% & 0.75\n",
      "for 2022-10-29, MAE is:10.07 & sMAPE is:9.86% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :25.63 & 15.34% & 0.75\n",
      "for 2022-10-30, MAE is:20.32 & sMAPE is:17.84% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :25.61 & 15.35% & 0.75\n",
      "for 2022-10-31, MAE is:28.81 & sMAPE is:21.75% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :25.62 & 15.37% & 0.75\n",
      "for 2022-11-01, MAE is:48.58 & sMAPE is:55.33% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :25.70 & 15.50% & 0.75\n",
      "for 2022-11-02, MAE is:26.27 & sMAPE is:42.09% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :25.70 & 15.58% & 0.75\n",
      "for 2022-11-03, MAE is:21.87 & sMAPE is:28.35% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :25.69 & 15.63% & 0.75\n",
      "for 2022-11-04, MAE is:11.15 & sMAPE is:16.55% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :25.64 & 15.63% & 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-05, MAE is:17.35 & sMAPE is:34.06% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :25.62 & 15.69% & 0.75\n",
      "for 2022-11-06, MAE is:9.60 & sMAPE is:27.50% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :25.56 & 15.73% & 0.74\n",
      "for 2022-11-07, MAE is:17.26 & sMAPE is:50.05% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :25.54 & 15.84% & 0.74\n",
      "for 2022-11-08, MAE is:14.73 & sMAPE is:30.87% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :25.50 & 15.89% & 0.74\n",
      "for 2022-11-09, MAE is:13.59 & sMAPE is:36.18% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :25.46 & 15.95% & 0.74\n",
      "for 2022-11-10, MAE is:14.01 & sMAPE is:45.95% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :25.43 & 16.05% & 0.74\n",
      "for 2022-11-11, MAE is:15.47 & sMAPE is:162.83% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :25.40 & 16.51% & 0.74\n",
      "for 2022-11-12, MAE is:2.76 & sMAPE is:105.66% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :25.32 & 16.79% & 0.74\n",
      "for 2022-11-13, MAE is:21.55 & sMAPE is:137.09% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :25.31 & 17.17% & 0.74\n",
      "for 2022-11-14, MAE is:33.45 & sMAPE is:79.63% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :25.34 & 17.37% & 0.74\n",
      "for 2022-11-15, MAE is:26.97 & sMAPE is:57.29% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :25.34 & 17.49% & 0.75\n",
      "for 2022-11-16, MAE is:4.95 & sMAPE is:18.05% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :25.28 & 17.50% & 0.75\n",
      "for 2022-11-17, MAE is:29.52 & sMAPE is:80.07% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :25.29 & 17.69% & 0.75\n",
      "for 2022-11-18, MAE is:73.58 & sMAPE is:100.85% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :25.44 & 17.95% & 0.75\n",
      "for 2022-11-19, MAE is:73.13 & sMAPE is:57.78% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :25.59 & 18.07% & 0.75\n",
      "for 2022-11-20, MAE is:16.41 & sMAPE is:10.96% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :25.56 & 18.05% & 0.74\n",
      "for 2022-11-21, MAE is:43.16 & sMAPE is:21.60% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :25.62 & 18.06% & 0.74\n",
      "for 2022-11-22, MAE is:30.67 & sMAPE is:19.84% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :25.63 & 18.07% & 0.74\n",
      "for 2022-11-23, MAE is:15.57 & sMAPE is:10.83% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :25.60 & 18.05% & 0.74\n",
      "for 2022-11-24, MAE is:53.40 & sMAPE is:37.34% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :25.69 & 18.10% & 0.74\n",
      "for 2022-11-25, MAE is:36.13 & sMAPE is:20.04% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :25.72 & 18.11% & 0.74\n",
      "for 2022-11-26, MAE is:14.95 & sMAPE is:8.07% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :25.69 & 18.08% & 0.74\n",
      "for 2022-11-27, MAE is:27.84 & sMAPE is:18.96% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :25.69 & 18.08% & 0.74\n",
      "for 2022-11-28, MAE is:48.59 & sMAPE is:26.90% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :25.76 & 18.11% & 0.74\n",
      "for 2022-11-29, MAE is:181.00 & sMAPE is:65.11% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :26.23 & 18.25% & 0.74\n",
      "for 2022-11-30, MAE is:82.89 & sMAPE is:24.32% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :26.40 & 18.27% & 0.74\n",
      "for 2022-12-01, MAE is:56.98 & sMAPE is:16.92% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :26.49 & 18.26% & 0.74\n",
      "for 2022-12-02, MAE is:40.64 & sMAPE is:12.77% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :26.53 & 18.25% & 0.74\n",
      "for 2022-12-03, MAE is:18.81 & sMAPE is:7.22% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :26.51 & 18.21% & 0.74\n",
      "for 2022-12-04, MAE is:28.63 & sMAPE is:10.79% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :26.51 & 18.19% & 0.74\n",
      "for 2022-12-05, MAE is:47.20 & sMAPE is:17.29% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :26.57 & 18.19% & 0.74\n",
      "for 2022-12-06, MAE is:77.88 & sMAPE is:24.81% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :26.73 & 18.21% & 0.74\n",
      "for 2022-12-07, MAE is:45.65 & sMAPE is:14.10% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :26.78 & 18.20% & 0.74\n",
      "for 2022-12-08, MAE is:72.01 & sMAPE is:19.31% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :26.91 & 18.20% & 0.74\n",
      "for 2022-12-09, MAE is:73.64 & sMAPE is:18.90% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :27.05 & 18.20% & 0.74\n",
      "for 2022-12-10, MAE is:30.36 & sMAPE is:8.72% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :27.06 & 18.18% & 0.74\n",
      "for 2022-12-11, MAE is:21.63 & sMAPE is:6.40% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :27.04 & 18.14% & 0.74\n",
      "for 2022-12-12, MAE is:108.05 & sMAPE is:26.33% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :27.28 & 18.17% & 0.74\n",
      "for 2022-12-13, MAE is:94.49 & sMAPE is:21.73% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :27.47 & 18.18% & 0.74\n",
      "for 2022-12-14, MAE is:101.73 & sMAPE is:23.88% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :27.68 & 18.19% & 0.74\n",
      "for 2022-12-15, MAE is:48.72 & sMAPE is:12.92% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :27.74 & 18.18% & 0.75\n",
      "for 2022-12-16, MAE is:74.92 & sMAPE is:18.82% & rMAE is:2.78 ||| daily mean of MAE & sMAPE & rMAE till now are :27.88 & 18.18% & 0.76\n",
      "for 2022-12-17, MAE is:82.18 & sMAPE is:28.93% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :28.03 & 18.21% & 0.76\n",
      "for 2022-12-18, MAE is:44.59 & sMAPE is:21.10% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :28.08 & 18.22% & 0.75\n",
      "for 2022-12-19, MAE is:34.69 & sMAPE is:18.73% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :28.10 & 18.22% & 0.75\n",
      "for 2022-12-20, MAE is:26.17 & sMAPE is:15.55% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :28.09 & 18.21% & 0.75\n",
      "for 2022-12-21, MAE is:18.47 & sMAPE is:8.63% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :28.07 & 18.18% & 0.75\n",
      "for 2022-12-22, MAE is:17.27 & sMAPE is:9.41% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :28.04 & 18.16% & 0.75\n",
      "for 2022-12-23, MAE is:22.16 & sMAPE is:12.19% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :28.02 & 18.14% & 0.75\n",
      "for 2022-12-24, MAE is:37.37 & sMAPE is:24.98% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :28.05 & 18.16% & 0.74\n",
      "for 2022-12-25, MAE is:10.19 & sMAPE is:8.60% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :28.00 & 18.14% & 0.74\n",
      "for 2022-12-26, MAE is:21.11 & sMAPE is:20.63% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :27.98 & 18.14% & 0.74\n",
      "for 2022-12-27, MAE is:15.82 & sMAPE is:11.91% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :27.94 & 18.12% & 0.74\n",
      "for 2022-12-28, MAE is:14.15 & sMAPE is:12.69% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :27.91 & 18.11% & 0.74\n",
      "for 2022-12-29, MAE is:23.04 & sMAPE is:29.60% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :27.89 & 18.14% & 0.74\n",
      "for 2022-12-30, MAE is:17.37 & sMAPE is:22.57% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :27.86 & 18.15% & 0.74\n",
      "for 2022-12-31, MAE is:43.47 & sMAPE is:47.41% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :27.91 & 18.23% & 0.74\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version - Run on Laptop)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:45:22,933]\u001b[0m A new study created in RDB with name: NO_1_2023\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:46:36,785]\u001b[0m Trial 0 finished with value: 57.49169717459705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005682530365619416, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12920992064876544, 'dropout_rate_Layer_2': 0.028851910967416617, 'dropout_rate_Layer_3': 0.3160984151145935, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022710697506055305, 'l1_Layer_2': 0.0004734786951162693, 'l1_Layer_3': 1.5808670200369992e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 210, 'n_units_Layer_3': 285}. Best is trial 0 with value: 57.49169717459705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.49 | sMAPE for Validation Set is: 29.86% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 13.77 | sMAPE for Test Set is: 18.43% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:46:48,986]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:46:55,588]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:47:15,633]\u001b[0m Trial 4 finished with value: 72.72347049462617 and parameters: {'n_hidden': 4, 'learning_rate': 0.004844456032675852, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16376901499538243, 'dropout_rate_Layer_2': 0.3545711181324415, 'dropout_rate_Layer_3': 0.1727487473683, 'dropout_rate_Layer_4': 0.09429956672897354, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011206798498417357, 'l1_Layer_2': 0.005302198215747829, 'l1_Layer_3': 9.043163577982647e-05, 'l1_Layer_4': 0.00031500755756983645, 'n_units_Layer_1': 135, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170, 'n_units_Layer_4': 200}. Best is trial 0 with value: 57.49169717459705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.72 | sMAPE for Validation Set is: 42.52% | rMAE for Validation Set is: 1.32\n",
      "MAE for Test Set is: 42.54 | sMAPE for Test Set is: 71.92% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:47:23,291]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:47:28,065]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:47:32,610]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:47:37,617]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:47:42,657]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:47:49,897]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:47:54,706]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:47:59,551]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:48:04,708]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:48:11,892]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:48:17,339]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:48:42,899]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:48:45,982]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:48:50,860]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:48:55,409]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:49:02,998]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:49:05,637]\u001b[0m Trial 1 finished with value: 62.626966975728116 and parameters: {'n_hidden': 4, 'learning_rate': 0.001963180709431211, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18659634582257692, 'dropout_rate_Layer_2': 0.14780576545061833, 'dropout_rate_Layer_3': 0.15186820765162704, 'dropout_rate_Layer_4': 0.2267031302003685, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001367984197419708, 'l1_Layer_2': 2.7559473957360936e-05, 'l1_Layer_3': 0.012057400761132884, 'l1_Layer_4': 8.620416709425194e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155, 'n_units_Layer_4': 270}. Best is trial 0 with value: 57.49169717459705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.63 | sMAPE for Validation Set is: 33.28% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 15.86 | sMAPE for Test Set is: 20.39% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:49:10,851]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:49:13,781]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:49:17,975]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:49:23,043]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:49:28,595]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:49:35,582]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:49:42,618]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:49:50,277]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:50:00,065]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:50:09,840]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:50:15,126]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:50:19,846]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:50:24,762]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:50:42,791]\u001b[0m Trial 23 finished with value: 75.50355971777905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010105670354458717, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1718124437702512, 'dropout_rate_Layer_2': 0.17821357546865824, 'dropout_rate_Layer_3': 0.15791817822213772, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0006957164992854046, 'l1_Layer_2': 0.0010343080005345104, 'l1_Layer_3': 0.006158654155076857, 'n_units_Layer_1': 230, 'n_units_Layer_2': 295, 'n_units_Layer_3': 180}. Best is trial 0 with value: 57.49169717459705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.50 | sMAPE for Validation Set is: 40.39% | rMAE for Validation Set is: 1.37\n",
      "MAE for Test Set is: 14.35 | sMAPE for Test Set is: 19.49% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:50:49,257]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:50:59,367]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:51:08,924]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:51:29,207]\u001b[0m Trial 35 finished with value: 47.41503035646577 and parameters: {'n_hidden': 4, 'learning_rate': 0.0037905552503443097, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19151181890692212, 'dropout_rate_Layer_2': 0.3208284572296445, 'dropout_rate_Layer_3': 0.0006319083845420792, 'dropout_rate_Layer_4': 0.11193082892712516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009478375635227628, 'l1_Layer_2': 4.2790935527056093e-05, 'l1_Layer_3': 4.00378386930293e-05, 'l1_Layer_4': 0.0001001791034542673, 'n_units_Layer_1': 245, 'n_units_Layer_2': 275, 'n_units_Layer_3': 190, 'n_units_Layer_4': 220}. Best is trial 35 with value: 47.41503035646577.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.42 | sMAPE for Validation Set is: 25.43% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 17.37 | sMAPE for Test Set is: 21.67% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:51:34,255]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:51:39,330]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:52:03,676]\u001b[0m Trial 39 finished with value: 78.67930262640645 and parameters: {'n_hidden': 3, 'learning_rate': 0.00553137297932834, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3140198106459192, 'dropout_rate_Layer_2': 0.009495253384817028, 'dropout_rate_Layer_3': 0.037726018193576794, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010396876754120493, 'l1_Layer_2': 0.000687191798028618, 'l1_Layer_3': 2.6242690656486954e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190}. Best is trial 35 with value: 47.41503035646577.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.68 | sMAPE for Validation Set is: 43.16% | rMAE for Validation Set is: 1.43\n",
      "MAE for Test Set is: 20.22 | sMAPE for Test Set is: 25.01% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:52:09,611]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:52:09,822]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:52:19,650]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:52:19,995]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:52:35,891]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:52:35,976]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:52:47,799]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:52:50,317]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:52:55,179]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:52:57,909]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:00,332]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:02,459]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:07,764]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:10,278]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:12,952]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:17,587]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:21,940]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:23,837]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:27,314]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:29,569]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:31,928]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:41,648]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:49,499]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:53:56,606]\u001b[0m Trial 64 finished with value: 119.32763622089476 and parameters: {'n_hidden': 4, 'learning_rate': 0.07263863404305146, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19859387012034269, 'dropout_rate_Layer_2': 0.37421489669984737, 'dropout_rate_Layer_3': 0.05943494514637848, 'dropout_rate_Layer_4': 0.09846387517946563, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00017268269013553592, 'l1_Layer_2': 0.010367610360363676, 'l1_Layer_3': 2.8155955520306993e-05, 'l1_Layer_4': 0.0006025951834683746, 'n_units_Layer_1': 75, 'n_units_Layer_2': 130, 'n_units_Layer_3': 160, 'n_units_Layer_4': 200}. Best is trial 35 with value: 47.41503035646577.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 119.33 | sMAPE for Validation Set is: 78.15% | rMAE for Validation Set is: 2.17\n",
      "MAE for Test Set is: 29.55 | sMAPE for Test Set is: 39.88% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:53:56,927]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:54:15,427]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:54:21,367]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:54:25,770]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:54:33,218]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:54:36,157]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:54:42,971]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 108.89 | sMAPE for Validation Set is: 67.34% | rMAE for Validation Set is: 1.98\n",
      "MAE for Test Set is: 20.59 | sMAPE for Test Set is: 28.53% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:54:44,510]\u001b[0m Trial 68 finished with value: 108.89128069309332 and parameters: {'n_hidden': 3, 'learning_rate': 0.019789623286118576, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2226632707058828, 'dropout_rate_Layer_2': 0.24939662737411947, 'dropout_rate_Layer_3': 0.05512657694022614, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.010426308075358326, 'l1_Layer_2': 0.00024356929431953458, 'l1_Layer_3': 1.1032494453267427e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295}. Best is trial 35 with value: 47.41503035646577.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:54:53,342]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:55:23,613]\u001b[0m Trial 74 finished with value: 28.113392963411645 and parameters: {'n_hidden': 3, 'learning_rate': 0.005737265978927732, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19972555799514893, 'dropout_rate_Layer_2': 0.08033430995761473, 'dropout_rate_Layer_3': 0.2064303638063384, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01719345578386721, 'l1_Layer_2': 0.0002249232693628553, 'l1_Layer_3': 1.0076542621351768e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140}. Best is trial 74 with value: 28.113392963411645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.11 | sMAPE for Validation Set is: 18.28% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.91 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:55:30,497]\u001b[0m Trial 76 finished with value: 27.085791194230268 and parameters: {'n_hidden': 3, 'learning_rate': 0.005725894014740133, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26485540753999326, 'dropout_rate_Layer_2': 0.19659368785287024, 'dropout_rate_Layer_3': 0.20524229316507175, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01916588391306568, 'l1_Layer_2': 0.00014065733918951827, 'l1_Layer_3': 0.0003052356388886886, 'n_units_Layer_1': 140, 'n_units_Layer_2': 185, 'n_units_Layer_3': 140}. Best is trial 76 with value: 27.085791194230268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.09 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.85 | sMAPE for Test Set is: 18.50% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:55:40,762]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:55:50,809]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:56:13,253]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:56:18,528]\u001b[0m Trial 80 finished with value: 29.925559643922128 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055754766065600645, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3135576082601531, 'dropout_rate_Layer_2': 0.09575716125163106, 'dropout_rate_Layer_3': 0.2145858755680092, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06841540158070637, 'l1_Layer_2': 0.00019482583006498564, 'l1_Layer_3': 1.285039026906294e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 155, 'n_units_Layer_3': 115}. Best is trial 76 with value: 27.085791194230268.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.93 | sMAPE for Validation Set is: 19.32% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.37 | sMAPE for Test Set is: 18.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:56:21,200]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:56:46,789]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:56:49,225]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:56:56,022]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:57:46,055]\u001b[0m Trial 83 finished with value: 26.707680304028248 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010935684087202894, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14297384993938694, 'dropout_rate_Layer_2': 0.23088857557253, 'dropout_rate_Layer_3': 0.1950060930819708, 'dropout_rate_Layer_4': 0.21351891901505118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017291448228542883, 'l1_Layer_2': 0.0005959082639743548, 'l1_Layer_3': 0.0017395278698353318, 'l1_Layer_4': 4.05511890446302e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 270, 'n_units_Layer_3': 260, 'n_units_Layer_4': 170}. Best is trial 83 with value: 26.707680304028248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.71 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.35 | sMAPE for Test Set is: 17.91% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:57:53,942]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:57:56,679]\u001b[0m Trial 86 finished with value: 27.720115350757897 and parameters: {'n_hidden': 4, 'learning_rate': 0.001121151929505713, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2950961855640452, 'dropout_rate_Layer_2': 0.14644974749716433, 'dropout_rate_Layer_3': 0.21193353374213134, 'dropout_rate_Layer_4': 0.33169672558053087, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.01359913693223595, 'l1_Layer_2': 0.0012412330406987367, 'l1_Layer_3': 1.467014098823131e-05, 'l1_Layer_4': 0.00013709217550033002, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 80, 'n_units_Layer_4': 280}. Best is trial 83 with value: 26.707680304028248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.72 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.11 | sMAPE for Test Set is: 17.99% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:58:00,907]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:58:03,246]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:58:05,624]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:58:08,200]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:58:25,084]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:58:35,473]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:58:40,308]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:58:42,734]\u001b[0m Trial 93 finished with value: 29.203992624509272 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016522279181798484, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31060609997282507, 'dropout_rate_Layer_2': 0.17367457506787048, 'dropout_rate_Layer_3': 0.23809175601740665, 'dropout_rate_Layer_4': 0.27607518760737837, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.09712633958141953, 'l1_Layer_2': 0.000536708426740737, 'l1_Layer_3': 2.3563557141975714e-05, 'l1_Layer_4': 7.61056631689536e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 130, 'n_units_Layer_4': 280}. Best is trial 83 with value: 26.707680304028248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.20 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.18 | sMAPE for Test Set is: 19.06% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 00:58:59,720]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:59:02,781]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:59:27,866]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:59:35,306]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:59:35,452]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 00:59:52,996]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:00:00,908]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:00:07,992]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:00:15,154]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:00:22,615]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:00:25,793]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:00:30,725]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:00:30,767]\u001b[0m Trial 102 finished with value: 27.755049907040114 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006967426194319213, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32238018803667556, 'dropout_rate_Layer_2': 0.017934992566386695, 'dropout_rate_Layer_3': 0.23604307867624186, 'dropout_rate_Layer_4': 0.35059672454136936, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06504616924912664, 'l1_Layer_2': 0.0008253722579948754, 'l1_Layer_3': 1.5968611258782587e-05, 'l1_Layer_4': 0.0005464936218042061, 'n_units_Layer_1': 220, 'n_units_Layer_2': 140, 'n_units_Layer_3': 85, 'n_units_Layer_4': 285}. Best is trial 83 with value: 26.707680304028248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.76 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.69 | sMAPE for Test Set is: 18.21% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:00:39,196]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:00:51,414]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:00:59,051]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:01:14,714]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:01:19,130]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:01:22,221]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:01:36,362]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:02:41,158]\u001b[0m Trial 113 finished with value: 71.46043528600778 and parameters: {'n_hidden': 3, 'learning_rate': 0.001216595222265823, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3580059260728463, 'dropout_rate_Layer_2': 0.3506770739435071, 'dropout_rate_Layer_3': 0.09367519517449462, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.8817927012681284e-05, 'l1_Layer_2': 0.0004601603168381638, 'l1_Layer_3': 0.000965082853283248, 'n_units_Layer_1': 275, 'n_units_Layer_2': 240, 'n_units_Layer_3': 270}. Best is trial 83 with value: 26.707680304028248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.46 | sMAPE for Validation Set is: 37.92% | rMAE for Validation Set is: 1.30\n",
      "MAE for Test Set is: 27.42 | sMAPE for Test Set is: 29.65% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:02:46,334]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:02:50,505]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:03:43,478]\u001b[0m Trial 120 finished with value: 27.165479818737936 and parameters: {'n_hidden': 3, 'learning_rate': 0.004184569848660047, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28316331043435655, 'dropout_rate_Layer_2': 0.15494710799052858, 'dropout_rate_Layer_3': 0.37417020082513214, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015796755701443503, 'l1_Layer_2': 0.07352992683894978, 'l1_Layer_3': 1.339114148034341e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 145, 'n_units_Layer_3': 125}. Best is trial 83 with value: 26.707680304028248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.17 | sMAPE for Validation Set is: 17.63% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.47 | sMAPE for Test Set is: 18.28% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:03:50,225]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:03:55,257]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:04:30,489]\u001b[0m Trial 117 finished with value: 73.4573277237473 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007414140979898801, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17326285465669558, 'dropout_rate_Layer_2': 0.19504682142714524, 'dropout_rate_Layer_3': 0.31792658383739647, 'dropout_rate_Layer_4': 0.26464753162169197, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00021689529222518173, 'l1_Layer_2': 4.4754770642988225e-05, 'l1_Layer_3': 0.0006348682641363932, 'l1_Layer_4': 0.00011937665993668347, 'n_units_Layer_1': 180, 'n_units_Layer_2': 140, 'n_units_Layer_3': 100, 'n_units_Layer_4': 170}. Best is trial 83 with value: 26.707680304028248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.46 | sMAPE for Validation Set is: 39.39% | rMAE for Validation Set is: 1.33\n",
      "MAE for Test Set is: 15.38 | sMAPE for Test Set is: 20.86% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:04:35,199]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:04:35,268]\u001b[0m Trial 123 finished with value: 27.300972714176066 and parameters: {'n_hidden': 3, 'learning_rate': 0.006195933305851456, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2539897307085555, 'dropout_rate_Layer_2': 0.11462524349919187, 'dropout_rate_Layer_3': 0.18903747205435945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006681517927336517, 'l1_Layer_2': 0.00041320391291070646, 'l1_Layer_3': 2.091640807507053e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 170, 'n_units_Layer_3': 115}. Best is trial 83 with value: 26.707680304028248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.30 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.04 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:04:42,549]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:04:47,350]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:04:47,835]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:05:36,921]\u001b[0m Trial 129 finished with value: 33.07814310187512 and parameters: {'n_hidden': 3, 'learning_rate': 0.005001773914819829, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1368907593629723, 'dropout_rate_Layer_2': 0.3181583223551505, 'dropout_rate_Layer_3': 0.0071770520394277785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1394614620300565e-05, 'l1_Layer_2': 0.00020617893838559403, 'l1_Layer_3': 3.927148962286604e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 290, 'n_units_Layer_3': 120}. Best is trial 83 with value: 26.707680304028248.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.08 | sMAPE for Validation Set is: 21.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.92 | sMAPE for Test Set is: 23.81% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:05:43,756]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:05:51,818]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:05:54,637]\u001b[0m Trial 128 finished with value: 26.63818848971881 and parameters: {'n_hidden': 3, 'learning_rate': 0.003511121809014094, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23809560618321032, 'dropout_rate_Layer_2': 0.1727169869258469, 'dropout_rate_Layer_3': 0.2010842797278014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03640707125135004, 'l1_Layer_2': 0.0004301313829803622, 'l1_Layer_3': 1.467813771657004e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 125, 'n_units_Layer_3': 115}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.64 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.72 | sMAPE for Test Set is: 17.43% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:06:06,270]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:06:18,935]\u001b[0m Trial 132 finished with value: 27.009069382612708 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032680503550906637, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22014788352507936, 'dropout_rate_Layer_2': 0.18846331998844298, 'dropout_rate_Layer_3': 0.11310172404698035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015492034638794743, 'l1_Layer_2': 7.028275864589136e-05, 'l1_Layer_3': 1.74875435336983e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 145, 'n_units_Layer_3': 105}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.01 | sMAPE for Validation Set is: 17.48% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.92 | sMAPE for Test Set is: 17.51% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:06:31,077]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:06:38,785]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:06:48,992]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:06:58,290]\u001b[0m Trial 134 finished with value: 27.089574662875425 and parameters: {'n_hidden': 3, 'learning_rate': 0.003073897745446347, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21939644707084474, 'dropout_rate_Layer_2': 0.18919774242665877, 'dropout_rate_Layer_3': 0.18108441062749164, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0062645193474661, 'l1_Layer_2': 0.0006034620208428618, 'l1_Layer_3': 2.0929712593015373e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 170, 'n_units_Layer_3': 105}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:06:58,439]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.09 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.41 | sMAPE for Test Set is: 18.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:07:06,459]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:07:10,938]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:07:23,499]\u001b[0m Trial 141 finished with value: 32.70450032246402 and parameters: {'n_hidden': 3, 'learning_rate': 0.021068487364995347, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39771697407999745, 'dropout_rate_Layer_2': 0.3093021174755304, 'dropout_rate_Layer_3': 0.20483383409880584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030093606301391297, 'l1_Layer_2': 4.921984951757009e-05, 'l1_Layer_3': 0.008298257022046748, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 70}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.70 | sMAPE for Validation Set is: 21.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 17.30 | sMAPE for Test Set is: 23.72% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:07:28,556]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:07:45,432]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:08:07,135]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:08:14,204]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:08:37,407]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:08:41,660]\u001b[0m Trial 145 finished with value: 27.24925754648125 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012742112510768441, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23605324432604852, 'dropout_rate_Layer_2': 0.23157002723310383, 'dropout_rate_Layer_3': 0.19508728522966878, 'dropout_rate_Layer_4': 0.1642352139609885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05530202212308, 'l1_Layer_2': 0.0003588583637808596, 'l1_Layer_3': 0.0004215611295973068, 'l1_Layer_4': 0.004894544755460836, 'n_units_Layer_1': 70, 'n_units_Layer_2': 210, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.25 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.29 | sMAPE for Test Set is: 17.90% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:08:47,285]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:09:01,787]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:09:11,843]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:09:26,732]\u001b[0m Trial 148 finished with value: 27.035226937088442 and parameters: {'n_hidden': 3, 'learning_rate': 0.003597729302959672, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23753254527075338, 'dropout_rate_Layer_2': 0.1850113478739621, 'dropout_rate_Layer_3': 0.22733691323449942, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012632930923210477, 'l1_Layer_2': 0.0010618555112197367, 'l1_Layer_3': 2.4219355586728326e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.04 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.86 | sMAPE for Test Set is: 17.57% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:09:28,872]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:09:38,373]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:09:38,736]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:09:45,968]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:09:55,501]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:10:01,381]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:10:08,077]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:10:25,641]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:10:45,784]\u001b[0m Trial 160 finished with value: 27.53062518482324 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023670919375412647, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.215963357461139, 'dropout_rate_Layer_2': 0.16492764535652787, 'dropout_rate_Layer_3': 0.20900694792505076, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009303060862256176, 'l1_Layer_2': 0.0005195264528430417, 'l1_Layer_3': 2.1708420581732696e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 140}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.53 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.70 | sMAPE for Test Set is: 18.50% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:10:58,289]\u001b[0m Trial 161 finished with value: 27.772049729441136 and parameters: {'n_hidden': 3, 'learning_rate': 0.004943957941195727, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2612902064854786, 'dropout_rate_Layer_2': 0.2002424756741999, 'dropout_rate_Layer_3': 0.21126143162849859, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.045512955074722104, 'l1_Layer_2': 0.0016485769824490235, 'l1_Layer_3': 2.5740051078802498e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 200, 'n_units_Layer_3': 140}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.77 | sMAPE for Validation Set is: 17.96% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.64 | sMAPE for Test Set is: 18.50% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:11:58,074]\u001b[0m Trial 163 finished with value: 26.959326889315687 and parameters: {'n_hidden': 3, 'learning_rate': 0.002757376874200292, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2383519515834015, 'dropout_rate_Layer_2': 0.20037807299286664, 'dropout_rate_Layer_3': 0.13689379917466027, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009112761941109437, 'l1_Layer_2': 0.0016825400810772813, 'l1_Layer_3': 3.8412540511284206e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 205, 'n_units_Layer_3': 125}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.96 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.73 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:12:20,197]\u001b[0m Trial 162 finished with value: 57.882678969560175 and parameters: {'n_hidden': 4, 'learning_rate': 0.0099043043481576, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2049401740361564, 'dropout_rate_Layer_2': 0.367521726527924, 'dropout_rate_Layer_3': 0.3312152023076146, 'dropout_rate_Layer_4': 0.3742098784547885, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.03182116188110865, 'l1_Layer_2': 0.003962132968208457, 'l1_Layer_3': 0.000278139775235164, 'l1_Layer_4': 8.22162421021757e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60, 'n_units_Layer_4': 175}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.88 | sMAPE for Validation Set is: 30.22% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 18.60 | sMAPE for Test Set is: 22.84% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:12:32,554]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:12:32,620]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:12:43,190]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:12:44,724]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:12:47,932]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:12:50,430]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:12:56,981]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:12:58,209]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:05,335]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:09,320]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:14,004]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:19,848]\u001b[0m Trial 174 finished with value: 95.79366701081925 and parameters: {'n_hidden': 4, 'learning_rate': 0.023690806367996958, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2884883646146414, 'dropout_rate_Layer_2': 0.22245819734961444, 'dropout_rate_Layer_3': 0.04539104876094555, 'dropout_rate_Layer_4': 0.17948192023025944, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.277930686492305e-05, 'l1_Layer_2': 0.009085955072041648, 'l1_Layer_3': 0.027301835476026163, 'l1_Layer_4': 0.007282336259383534, 'n_units_Layer_1': 190, 'n_units_Layer_2': 300, 'n_units_Layer_3': 95, 'n_units_Layer_4': 210}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 95.79 | sMAPE for Validation Set is: 56.07% | rMAE for Validation Set is: 1.74\n",
      "MAE for Test Set is: 15.42 | sMAPE for Test Set is: 20.30% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:13:24,505]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:24,648]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:32,836]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:37,707]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:39,111]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:47,887]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:50,090]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:52,814]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:13:57,331]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:14:04,781]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:14:12,049]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:14:16,681]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:14:27,291]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 87.50 | sMAPE for Validation Set is: 49.51% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 20.58 | sMAPE for Test Set is: 24.51% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:14:29,665]\u001b[0m Trial 185 finished with value: 87.50404776323218 and parameters: {'n_hidden': 4, 'learning_rate': 0.053386601918968615, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31720750576485013, 'dropout_rate_Layer_2': 0.07111585752875507, 'dropout_rate_Layer_3': 0.15046249478266321, 'dropout_rate_Layer_4': 0.23493528483095305, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0015381262882466263, 'l1_Layer_2': 0.016545274344043678, 'l1_Layer_3': 0.010081860920870591, 'l1_Layer_4': 0.00664653180301371, 'n_units_Layer_1': 60, 'n_units_Layer_2': 220, 'n_units_Layer_3': 100, 'n_units_Layer_4': 160}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:14:32,461]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:14:39,867]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:14:44,602]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:15:06,947]\u001b[0m Trial 191 finished with value: 28.273419803791654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035302022058466263, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23981419413894722, 'dropout_rate_Layer_2': 0.1790306679484609, 'dropout_rate_Layer_3': 0.2199944661913245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002288570435545213, 'l1_Layer_2': 0.003664593135209924, 'l1_Layer_3': 2.6148011323267422e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 115, 'n_units_Layer_3': 90}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.27 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.31 | sMAPE for Test Set is: 19.19% | rMAE for Test Set is: 0.67\n",
      "MAE for Validation Set is: 73.77 | sMAPE for Validation Set is: 40.19% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 19.33 | sMAPE for Test Set is: 24.19% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:15:33,430]\u001b[0m Trial 195 finished with value: 73.76939921516181 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018076147467886096, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36256014147966575, 'dropout_rate_Layer_2': 0.30748359151753957, 'dropout_rate_Layer_3': 0.2542560780414059, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023812651480997144, 'l1_Layer_2': 2.5340643666408786e-05, 'l1_Layer_3': 0.00013236240607222778, 'n_units_Layer_1': 110, 'n_units_Layer_2': 200, 'n_units_Layer_3': 150}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:15:41,362]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:15:53,503]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:16:32,760]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:16:35,724]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:16:36,074]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:16:45,781]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:16:55,847]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:17:10,271]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:17:13,041]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:17:17,604]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:17:25,261]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:17:30,102]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:17:44,783]\u001b[0m Trial 208 finished with value: 67.43734069706231 and parameters: {'n_hidden': 3, 'learning_rate': 0.07042483727407044, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39906861530051146, 'dropout_rate_Layer_2': 0.19260822532932764, 'dropout_rate_Layer_3': 0.3381143486281703, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0712787062509537e-05, 'l1_Layer_2': 5.5980685424100164e-05, 'l1_Layer_3': 0.00044209199553341344, 'n_units_Layer_1': 230, 'n_units_Layer_2': 215, 'n_units_Layer_3': 195}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.44 | sMAPE for Validation Set is: 36.30% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 49.67 | sMAPE for Test Set is: 46.00% | rMAE for Test Set is: 2.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:17:51,908]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:17:52,581]\u001b[0m Trial 207 finished with value: 51.93459753643978 and parameters: {'n_hidden': 3, 'learning_rate': 0.07560514060403344, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3992057073237819, 'dropout_rate_Layer_2': 0.2135591683573563, 'dropout_rate_Layer_3': 0.3418961875579131, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005026000008692447, 'l1_Layer_2': 6.91822561721973e-05, 'l1_Layer_3': 0.0004230421924755335, 'n_units_Layer_1': 230, 'n_units_Layer_2': 215, 'n_units_Layer_3': 190}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.93 | sMAPE for Validation Set is: 28.31% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 22.06 | sMAPE for Test Set is: 26.39% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:17:57,480]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:18:04,405]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:18:09,561]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:18:21,545]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:18:28,790]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:18:37,351]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:18:39,803]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:18:42,240]\u001b[0m Trial 212 finished with value: 27.340115182972482 and parameters: {'n_hidden': 3, 'learning_rate': 0.006675925710575616, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.300867078461312, 'dropout_rate_Layer_2': 0.19852046251135724, 'dropout_rate_Layer_3': 0.2320573128893237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01000743282618648, 'l1_Layer_2': 0.009923098408141871, 'l1_Layer_3': 0.007481521980881155, 'n_units_Layer_1': 190, 'n_units_Layer_2': 160, 'n_units_Layer_3': 140}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.34 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.47 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:18:46,476]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:18:56,577]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:19:01,129]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:19:04,421]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:19:08,656]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:19:29,120]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:19:33,911]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:19:36,570]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:19:43,038]\u001b[0m Trial 223 finished with value: 27.32251372351216 and parameters: {'n_hidden': 4, 'learning_rate': 0.003854915362841989, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19318147078136916, 'dropout_rate_Layer_2': 0.18030420491413884, 'dropout_rate_Layer_3': 0.07433412228013708, 'dropout_rate_Layer_4': 0.14010334240827146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04678712760226997, 'l1_Layer_2': 0.0001891203592862867, 'l1_Layer_3': 0.0005409037750425997, 'l1_Layer_4': 0.00012514418068676746, 'n_units_Layer_1': 50, 'n_units_Layer_2': 210, 'n_units_Layer_3': 190, 'n_units_Layer_4': 280}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.32 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.63 | sMAPE for Test Set is: 18.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:19:43,265]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:19:52,733]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:19:57,280]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:20:02,167]\u001b[0m Trial 228 finished with value: 68.56257705516212 and parameters: {'n_hidden': 3, 'learning_rate': 0.0549200272679536, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39474711789193473, 'dropout_rate_Layer_2': 0.18574909958706448, 'dropout_rate_Layer_3': 0.34055709870957657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014929389376116165, 'l1_Layer_2': 2.9508781143539636e-05, 'l1_Layer_3': 0.0005054192138586682, 'n_units_Layer_1': 225, 'n_units_Layer_2': 215, 'n_units_Layer_3': 190}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.56 | sMAPE for Validation Set is: 37.08% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 45.68 | sMAPE for Test Set is: 43.62% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:20:07,530]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:20:15,391]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:20:19,682]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:20:25,035]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:20:37,323]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:20:46,884]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:20:52,635]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:20:57,149]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:21:12,149]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:21:16,676]\u001b[0m Trial 236 finished with value: 26.930724149864705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030623911728237287, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2947661578758147, 'dropout_rate_Layer_2': 0.3583073531341174, 'dropout_rate_Layer_3': 0.21742399875045892, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006066202156664815, 'l1_Layer_2': 0.0042901829276362135, 'l1_Layer_3': 0.0002674082422780395, 'n_units_Layer_1': 250, 'n_units_Layer_2': 180, 'n_units_Layer_3': 235}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.93 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.02 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:21:22,365]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:21:26,665]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:21:31,432]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:21:33,695]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:21:37,154]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:21:41,382]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:21:46,303]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:21:54,015]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:21:57,438]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:21:59,875]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:22:01,801]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:22:04,737]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:22:16,199]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:22:21,559]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:22:21,694]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:22:30,640]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:22:32,788]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:22:35,440]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:22:45,550]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:22:50,569]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:22:54,943]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:23:00,291]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:23:04,769]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:23:09,949]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:23:17,910]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:23:22,942]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:23:37,885]\u001b[0m Trial 268 finished with value: 65.7038539299108 and parameters: {'n_hidden': 3, 'learning_rate': 0.011468596720157655, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37604804028292177, 'dropout_rate_Layer_2': 0.21084059465414381, 'dropout_rate_Layer_3': 0.31136040229902295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002594674278787065, 'l1_Layer_2': 2.1399635014093652e-05, 'l1_Layer_3': 0.0024432365830244587, 'n_units_Layer_1': 275, 'n_units_Layer_2': 165, 'n_units_Layer_3': 210}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.70 | sMAPE for Validation Set is: 35.30% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 39.52 | sMAPE for Test Set is: 39.00% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:24:33,029]\u001b[0m Trial 259 finished with value: 29.601798525957648 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005237732188084784, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010493641217566102, 'dropout_rate_Layer_2': 0.39108031911583385, 'dropout_rate_Layer_3': 0.004808577190940855, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1381560273636107e-05, 'l1_Layer_2': 0.00015913413157293564, 'l1_Layer_3': 1.2544154811930836e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 125, 'n_units_Layer_3': 50}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.60 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 15.85 | sMAPE for Test Set is: 20.90% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:25:34,758]\u001b[0m Trial 269 finished with value: 30.40726141296952 and parameters: {'n_hidden': 3, 'learning_rate': 0.004678192168242828, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02077696589218299, 'dropout_rate_Layer_2': 0.3947610583188051, 'dropout_rate_Layer_3': 0.013324253864870156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.019897002218759e-05, 'l1_Layer_2': 0.00016858478270148988, 'l1_Layer_3': 1.0729151066726765e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 50}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.41 | sMAPE for Validation Set is: 19.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 18.24 | sMAPE for Test Set is: 23.78% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:25:37,847]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:26:11,919]\u001b[0m Trial 270 finished with value: 29.447175933022738 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005244453811401238, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 6.911889975153018e-05, 'dropout_rate_Layer_2': 0.39725928291075396, 'dropout_rate_Layer_3': 0.005550990067241722, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3623805345585455e-05, 'l1_Layer_2': 0.00013194899587772244, 'l1_Layer_3': 1.0080098806516498e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 135, 'n_units_Layer_3': 55}. Best is trial 128 with value: 26.63818848971881.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.45 | sMAPE for Validation Set is: 19.23% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 16.03 | sMAPE for Test Set is: 21.42% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:26:19,302]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:26:38,812]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:26:45,493]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:27:00,479]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:27:54,186]\u001b[0m Trial 276 finished with value: 26.498031956767687 and parameters: {'n_hidden': 4, 'learning_rate': 0.000589025204625353, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2776184288640986, 'dropout_rate_Layer_2': 0.19295940919049484, 'dropout_rate_Layer_3': 0.04090648276345838, 'dropout_rate_Layer_4': 0.1393004752965321, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07992663873544692, 'l1_Layer_2': 0.0003691813458018779, 'l1_Layer_3': 0.0005027513584481324, 'l1_Layer_4': 5.015259420512088e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 240, 'n_units_Layer_3': 135, 'n_units_Layer_4': 300}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.50 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.12 | sMAPE for Test Set is: 17.75% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:27:56,849]\u001b[0m Trial 277 finished with value: 29.725781107161964 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005844013239132974, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0010222662507545542, 'dropout_rate_Layer_2': 0.37781455411754855, 'dropout_rate_Layer_3': 0.1497482747327274, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.7358630742641095e-05, 'l1_Layer_2': 0.002880133541681755, 'l1_Layer_3': 7.454318559475043e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.73 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 16.34 | sMAPE for Test Set is: 21.73% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:28:02,565]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:28:14,951]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:28:35,127]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:28:43,949]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:28:54,425]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:28:59,413]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:29:04,632]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:29:16,062]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:29:21,068]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:29:24,526]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:29:29,548]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:29:36,750]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:29:43,390]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:29:53,972]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:29:58,909]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:30:00,751]\u001b[0m Trial 292 finished with value: 77.35264007132368 and parameters: {'n_hidden': 3, 'learning_rate': 0.023479108702697787, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33199252485238895, 'dropout_rate_Layer_2': 0.3754829667462313, 'dropout_rate_Layer_3': 0.19745831342298137, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.153771531389578e-05, 'l1_Layer_2': 0.00011371933289545883, 'l1_Layer_3': 0.00027798275189211977, 'n_units_Layer_1': 290, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.35 | sMAPE for Validation Set is: 41.85% | rMAE for Validation Set is: 1.40\n",
      "MAE for Test Set is: 21.22 | sMAPE for Test Set is: 25.07% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:30:05,968]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:30:10,349]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:30:20,352]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:30:30,673]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:30:40,503]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:30:48,172]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:31:48,169]\u001b[0m Trial 299 finished with value: 27.144994338573245 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006424052618060047, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31165666821756033, 'dropout_rate_Layer_2': 0.16932680486224172, 'dropout_rate_Layer_3': 0.07265207305583096, 'dropout_rate_Layer_4': 0.13732184634614258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06678175836266646, 'l1_Layer_2': 0.000578591584201983, 'l1_Layer_3': 0.0009358160731236764, 'l1_Layer_4': 2.3227756766357556e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 275, 'n_units_Layer_3': 70, 'n_units_Layer_4': 290}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.14 | sMAPE for Validation Set is: 17.63% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.75 | sMAPE for Test Set is: 18.36% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:31:52,439]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:31:55,270]\u001b[0m Trial 301 finished with value: 27.095994956291367 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005445490199819964, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30241277850528536, 'dropout_rate_Layer_2': 0.15670451339165586, 'dropout_rate_Layer_3': 0.06491707153760412, 'dropout_rate_Layer_4': 0.1365822661839154, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0736792134163705, 'l1_Layer_2': 0.0006243631796003338, 'l1_Layer_3': 0.0008357876435301305, 'l1_Layer_4': 2.8857342079650774e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 275, 'n_units_Layer_3': 115, 'n_units_Layer_4': 295}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.10 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.18 | sMAPE for Test Set is: 17.86% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:31:57,525]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:32:00,034]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:32:20,585]\u001b[0m Trial 306 finished with value: 71.2523738865546 and parameters: {'n_hidden': 4, 'learning_rate': 0.002331090118335827, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22961258422664, 'dropout_rate_Layer_2': 0.36958962591124006, 'dropout_rate_Layer_3': 0.21766528855823863, 'dropout_rate_Layer_4': 0.02481168962922813, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.634935565249101e-05, 'l1_Layer_2': 8.85548535167907e-05, 'l1_Layer_3': 0.0004755870327735644, 'l1_Layer_4': 0.029431020271959075, 'n_units_Layer_1': 280, 'n_units_Layer_2': 115, 'n_units_Layer_3': 200, 'n_units_Layer_4': 290}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.25 | sMAPE for Validation Set is: 38.54% | rMAE for Validation Set is: 1.29\n",
      "MAE for Test Set is: 17.29 | sMAPE for Test Set is: 21.59% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:32:25,025]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:32:29,873]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:32:54,658]\u001b[0m Trial 309 finished with value: 43.93153269772312 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032757853137442045, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03190848209277952, 'dropout_rate_Layer_2': 0.28427838725370963, 'dropout_rate_Layer_3': 0.3853416923387835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0039930866491998725, 'l1_Layer_2': 0.07833669753462844, 'l1_Layer_3': 7.416290404428815e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 235, 'n_units_Layer_3': 275}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.93 | sMAPE for Validation Set is: 23.63% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 17.83 | sMAPE for Test Set is: 22.11% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:32:58,214]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:33:05,450]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:33:17,382]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:34:54,001]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:35:02,043]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:35:09,521]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:35:13,651]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:35:18,586]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:35:24,237]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:36:26,151]\u001b[0m Trial 305 finished with value: 89.35316199827128 and parameters: {'n_hidden': 4, 'learning_rate': 0.002995305306568351, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.288872029024795, 'dropout_rate_Layer_2': 0.2609445203187947, 'dropout_rate_Layer_3': 0.28359744571351997, 'dropout_rate_Layer_4': 0.09673529769479404, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.264737388626499e-05, 'l1_Layer_2': 0.004241954444347839, 'l1_Layer_3': 0.00022368558282582688, 'l1_Layer_4': 0.023477637377163126, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 285, 'n_units_Layer_4': 200}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 89.35 | sMAPE for Validation Set is: 50.80% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 17.74 | sMAPE for Test Set is: 22.64% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:36:33,005]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:37:32,141]\u001b[0m Trial 319 finished with value: 27.979440058534152 and parameters: {'n_hidden': 4, 'learning_rate': 0.001039561852789233, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29780850800827013, 'dropout_rate_Layer_2': 0.10793373472540618, 'dropout_rate_Layer_3': 0.17557307608312556, 'dropout_rate_Layer_4': 0.13193382835965864, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.438583479912802e-05, 'l1_Layer_2': 0.0016402843141134107, 'l1_Layer_3': 0.0021607894860699215, 'l1_Layer_4': 3.9041620007039485e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 275, 'n_units_Layer_3': 65, 'n_units_Layer_4': 290}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.98 | sMAPE for Validation Set is: 18.25% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.75 | sMAPE for Test Set is: 18.52% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:37:32,425]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:37:40,630]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:37:45,030]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:37:47,653]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:37:54,744]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:37:57,309]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:38:04,247]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:38:07,320]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:38:12,107]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:38:17,090]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:38:22,502]\u001b[0m Trial 326 finished with value: 31.065995584426645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005133587291221747, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07436586052195324, 'dropout_rate_Layer_2': 0.3929381383411315, 'dropout_rate_Layer_3': 0.30886346516868846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013086742353593018, 'l1_Layer_2': 7.858239927131114e-05, 'l1_Layer_3': 0.000489489972673173, 'n_units_Layer_1': 300, 'n_units_Layer_2': 115, 'n_units_Layer_3': 220}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.07 | sMAPE for Validation Set is: 19.56% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 16.86 | sMAPE for Test Set is: 21.94% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:38:26,487]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:38:32,040]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:38:37,274]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:38:39,955]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:38:49,328]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:38:51,768]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:39:20,950]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:39:24,229]\u001b[0m Trial 339 finished with value: 41.50877482483617 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031066668184452383, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004547204766907901, 'dropout_rate_Layer_2': 0.2867463317292051, 'dropout_rate_Layer_3': 0.3969081291031373, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0036962148321949715, 'l1_Layer_2': 0.07842781506911499, 'l1_Layer_3': 8.017306027387113e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 240, 'n_units_Layer_3': 245}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.51 | sMAPE for Validation Set is: 22.53% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 16.18 | sMAPE for Test Set is: 20.61% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:39:31,413]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:39:38,302]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:39:43,374]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:39:48,765]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:39:58,584]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:40:07,937]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:40:20,689]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:40:23,140]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:40:28,071]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:40:30,695]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:40:35,469]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:40:38,166]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:40:43,349]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:40:45,799]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:40:58,382]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:41:03,056]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:41:08,912]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:41:13,470]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:41:16,357]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:41:25,252]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:41:38,028]\u001b[0m Trial 358 finished with value: 74.89525375319177 and parameters: {'n_hidden': 4, 'learning_rate': 0.07099956083734327, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37700295673340695, 'dropout_rate_Layer_2': 0.16934147510457054, 'dropout_rate_Layer_3': 0.366687717458843, 'dropout_rate_Layer_4': 0.26967795634002745, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03341501765349004, 'l1_Layer_2': 0.09793719457144771, 'l1_Layer_3': 3.2717930299508095e-05, 'l1_Layer_4': 0.0033884220989414443, 'n_units_Layer_1': 195, 'n_units_Layer_2': 120, 'n_units_Layer_3': 100, 'n_units_Layer_4': 65}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.90 | sMAPE for Validation Set is: 40.05% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 55.75 | sMAPE for Test Set is: 50.15% | rMAE for Test Set is: 2.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:41:42,797]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:41:49,999]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:41:50,176]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:41:57,932]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:01,981]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:05,345]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:07,500]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:10,006]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:12,714]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:17,171]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:21,681]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:27,239]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:31,745]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:36,184]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:44,354]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:42:56,281]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:43:20,202]\u001b[0m Trial 373 finished with value: 27.603832058609925 and parameters: {'n_hidden': 3, 'learning_rate': 0.017142807863903042, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11345545835030786, 'dropout_rate_Layer_2': 0.13219397472369052, 'dropout_rate_Layer_3': 0.3331953663303805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00037081235264275504, 'l1_Layer_2': 0.00402252598782788, 'l1_Layer_3': 0.011811658193088397, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 275}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.60 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.05 | sMAPE for Test Set is: 21.25% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:43:35,200]\u001b[0m Trial 378 finished with value: 27.589272044735036 and parameters: {'n_hidden': 3, 'learning_rate': 0.017311818231467976, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11621060547166778, 'dropout_rate_Layer_2': 0.21258578530740968, 'dropout_rate_Layer_3': 0.2562580973075471, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004094636659096025, 'l1_Layer_2': 0.0025872633588886053, 'l1_Layer_3': 0.0014978417970848833, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 135}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.59 | sMAPE for Validation Set is: 18.06% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.28 | sMAPE for Test Set is: 19.99% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:43:44,130]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:44:04,700]\u001b[0m Trial 381 finished with value: 60.454055063256114 and parameters: {'n_hidden': 3, 'learning_rate': 0.004947307314705094, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39055913522671243, 'dropout_rate_Layer_2': 0.29274969332770634, 'dropout_rate_Layer_3': 0.3952117915460237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06083270619102772, 'l1_Layer_2': 0.08865794036612247, 'l1_Layer_3': 0.003736106500539155, 'n_units_Layer_1': 140, 'n_units_Layer_2': 165, 'n_units_Layer_3': 240}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.45 | sMAPE for Validation Set is: 31.31% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 17.09 | sMAPE for Test Set is: 21.43% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:44:35,095]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:44:41,995]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:44:46,892]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:44:54,947]\u001b[0m Trial 379 finished with value: 27.549543175757265 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008223449805892777, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08138382506097763, 'dropout_rate_Layer_2': 0.21014650137052465, 'dropout_rate_Layer_3': 0.05839698717772451, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.352181881163178e-05, 'l1_Layer_2': 0.001575146756734051, 'l1_Layer_3': 3.136342935954951e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 155, 'n_units_Layer_3': 80}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.55 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.33 | sMAPE for Test Set is: 18.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:45:02,624]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:45:20,219]\u001b[0m Trial 385 finished with value: 32.156669978260766 and parameters: {'n_hidden': 3, 'learning_rate': 0.008435330467016566, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1310313743263799, 'dropout_rate_Layer_2': 0.13024432130512958, 'dropout_rate_Layer_3': 0.2229823985431503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004515175032909975, 'l1_Layer_2': 0.004057429492795328, 'l1_Layer_3': 0.014516426631851587, 'n_units_Layer_1': 300, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.16 | sMAPE for Validation Set is: 20.61% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 16.23 | sMAPE for Test Set is: 22.79% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:45:24,827]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:45:27,059]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:45:31,740]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:45:37,117]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:45:56,786]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:02,639]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:06,993]\u001b[0m Trial 390 finished with value: 43.868055721657896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014468403534352338, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007350849452844057, 'dropout_rate_Layer_2': 0.1329512029989649, 'dropout_rate_Layer_3': 0.11230462913282441, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004126619463237961, 'l1_Layer_2': 0.027269962523757112, 'l1_Layer_3': 7.2516366748401e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 255, 'n_units_Layer_3': 245}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.87 | sMAPE for Validation Set is: 23.33% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 14.59 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:46:14,925]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:29,312]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:37,601]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:46:57,387]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:00,327]\u001b[0m Trial 397 finished with value: 28.38926221852418 and parameters: {'n_hidden': 3, 'learning_rate': 0.000949936138831788, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08342701879590095, 'dropout_rate_Layer_2': 0.1734855111172191, 'dropout_rate_Layer_3': 0.1525450901667605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.5382370755912956e-05, 'l1_Layer_2': 0.0016383923606631005, 'l1_Layer_3': 4.104331864168419e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 170, 'n_units_Layer_3': 85}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.39 | sMAPE for Validation Set is: 18.40% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.41 | sMAPE for Test Set is: 19.27% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:47:22,449]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:22,843]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:27,785]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:47,376]\u001b[0m Trial 401 finished with value: 28.366580039494753 and parameters: {'n_hidden': 3, 'learning_rate': 0.009952727110129575, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17175627101792285, 'dropout_rate_Layer_2': 0.13632280559771126, 'dropout_rate_Layer_3': 0.25327296071580574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014016557710168792, 'l1_Layer_2': 0.014805670989224733, 'l1_Layer_3': 0.029095029561816203, 'n_units_Layer_1': 300, 'n_units_Layer_2': 285, 'n_units_Layer_3': 285}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:47:47,389]\u001b[0m Trial 403 finished with value: 28.32875752005275 and parameters: {'n_hidden': 3, 'learning_rate': 0.009257619392207667, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16332520524253974, 'dropout_rate_Layer_2': 0.10006207149984696, 'dropout_rate_Layer_3': 0.2564340214478974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002491619300456929, 'l1_Layer_2': 0.01371047219760013, 'l1_Layer_3': 0.03626456441460907, 'n_units_Layer_1': 285, 'n_units_Layer_2': 290, 'n_units_Layer_3': 280}. Best is trial 276 with value: 26.498031956767687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.37 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.20 | sMAPE for Test Set is: 19.32% | rMAE for Test Set is: 0.67\n",
      "MAE for Validation Set is: 28.33 | sMAPE for Validation Set is: 18.24% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.21 | sMAPE for Test Set is: 19.30% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:47:56,688]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:01,579]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:06,849]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:12,632]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:31,117]\u001b[0m Trial 406 finished with value: 26.318019674303812 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036063720207179014, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23909114563933728, 'dropout_rate_Layer_2': 0.1705646103413741, 'dropout_rate_Layer_3': 0.21369122512277947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01614801307001517, 'l1_Layer_2': 0.0001663050225291061, 'l1_Layer_3': 6.914848010883292e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 145, 'n_units_Layer_3': 150}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.32 | sMAPE for Validation Set is: 17.22% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.71 | sMAPE for Test Set is: 17.40% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:48:35,644]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:41,066]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:45,773]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:50,980]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:48:53,832]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:49:00,967]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:49:01,133]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:49:17,825]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:49:20,340]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:49:25,233]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:49:35,778]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:50:05,497]\u001b[0m Trial 421 finished with value: 27.220538556947606 and parameters: {'n_hidden': 3, 'learning_rate': 0.006086279006329005, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11098653422715467, 'dropout_rate_Layer_2': 0.011427105492669398, 'dropout_rate_Layer_3': 0.23464800154896287, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009152646582202006, 'l1_Layer_2': 0.00048080794948363655, 'l1_Layer_3': 9.323625272793659e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.22 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.10 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:50:10,024]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:50:14,697]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:51:41,395]\u001b[0m Trial 420 finished with value: 27.08140601108416 and parameters: {'n_hidden': 4, 'learning_rate': 0.000597966081868852, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2839026254235024, 'dropout_rate_Layer_2': 0.17339065416717536, 'dropout_rate_Layer_3': 0.07551863953071956, 'dropout_rate_Layer_4': 0.14409788491382355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07951697758381143, 'l1_Layer_2': 0.00034926572432019163, 'l1_Layer_3': 0.0005155202423223011, 'l1_Layer_4': 6.480598330614274e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 80, 'n_units_Layer_4': 300}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.08 | sMAPE for Validation Set is: 17.59% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.45 | sMAPE for Test Set is: 18.07% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:52:05,831]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:52:10,976]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:52:21,650]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:52:25,801]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:52:51,419]\u001b[0m Trial 429 finished with value: 29.284701943910324 and parameters: {'n_hidden': 3, 'learning_rate': 0.015077426956482056, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07088098469420326, 'dropout_rate_Layer_2': 0.13772638108651367, 'dropout_rate_Layer_3': 0.2549083480392575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003839152055578175, 'l1_Layer_2': 0.006986727687210172, 'l1_Layer_3': 0.01190158298120261, 'n_units_Layer_1': 300, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.28 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.31 | sMAPE for Test Set is: 19.09% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:53:36,227]\u001b[0m Trial 430 finished with value: 27.115966407539016 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027780234407384376, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19215593209795614, 'dropout_rate_Layer_2': 0.12577507533294868, 'dropout_rate_Layer_3': 0.3493634461231908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014691102403682573, 'l1_Layer_2': 0.0004871246457301172, 'l1_Layer_3': 2.8538698726547755e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 285, 'n_units_Layer_3': 100}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.12 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.42 | sMAPE for Test Set is: 18.04% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:53:41,073]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:53:45,241]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:53:50,828]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:53:51,324]\u001b[0m Trial 424 finished with value: 27.2963255116449 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005747990541631308, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2844064703473618, 'dropout_rate_Layer_2': 0.17382151463124995, 'dropout_rate_Layer_3': 0.07407043478714527, 'dropout_rate_Layer_4': 0.14553315544757017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0808180072188563, 'l1_Layer_2': 0.00035546868840509894, 'l1_Layer_3': 0.0003435531953798696, 'l1_Layer_4': 0.0029195873667815196, 'n_units_Layer_1': 125, 'n_units_Layer_2': 255, 'n_units_Layer_3': 80, 'n_units_Layer_4': 300}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.30 | sMAPE for Validation Set is: 17.72% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.29 | sMAPE for Test Set is: 18.07% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:54:03,797]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:22,895]\u001b[0m Trial 434 finished with value: 28.771255054209707 and parameters: {'n_hidden': 3, 'learning_rate': 0.01487537122630711, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07530366970492317, 'dropout_rate_Layer_2': 0.1394985406565348, 'dropout_rate_Layer_3': 0.2538936995751714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00037395062864534716, 'l1_Layer_2': 0.00663254445593765, 'l1_Layer_3': 0.010946882714593474, 'n_units_Layer_1': 300, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.77 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 19.17% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:54:26,178]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:30,233]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:35,996]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:40,388]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:54:48,134]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:03,127]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:07,537]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:11,109]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:15,776]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:20,972]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:22,608]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:27,991]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:30,336]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:34,968]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:40,050]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:55:45,366]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:56:09,393]\u001b[0m Trial 453 finished with value: 29.63345669190977 and parameters: {'n_hidden': 3, 'learning_rate': 0.015000148693525226, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07526781684204992, 'dropout_rate_Layer_2': 0.09425480235321132, 'dropout_rate_Layer_3': 0.2661614036805666, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001740985520714521, 'l1_Layer_2': 0.0066869072143588195, 'l1_Layer_3': 0.021160673337927684, 'n_units_Layer_1': 290, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.63 | sMAPE for Validation Set is: 18.95% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.83 | sMAPE for Test Set is: 19.92% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:56:14,522]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:56:24,359]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:56:28,770]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:57:01,822]\u001b[0m Trial 457 finished with value: 28.412812222559808 and parameters: {'n_hidden': 3, 'learning_rate': 0.019094539132868894, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03476708021987783, 'dropout_rate_Layer_2': 0.1075849147611401, 'dropout_rate_Layer_3': 0.2501538402564259, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00039936689425595895, 'l1_Layer_2': 0.02246987502579398, 'l1_Layer_3': 0.06404966302618814, 'n_units_Layer_1': 285, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.41 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.72 | sMAPE for Test Set is: 19.22% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:57:09,099]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:57:33,893]\u001b[0m Trial 451 finished with value: 26.85915699021111 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008433999857824178, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27829251054314935, 'dropout_rate_Layer_2': 0.19152429348472574, 'dropout_rate_Layer_3': 0.07648314438640835, 'dropout_rate_Layer_4': 0.16695286113367372, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04550740236347554, 'l1_Layer_2': 0.00011988297143213547, 'l1_Layer_3': 0.07419057153273254, 'l1_Layer_4': 0.0034309355742806595, 'n_units_Layer_1': 115, 'n_units_Layer_2': 260, 'n_units_Layer_3': 105, 'n_units_Layer_4': 275}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.86 | sMAPE for Validation Set is: 17.42% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.64 | sMAPE for Test Set is: 20.09% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:57:39,031]\u001b[0m Trial 459 finished with value: 26.94379680002868 and parameters: {'n_hidden': 3, 'learning_rate': 0.002373016902821866, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17346105379657178, 'dropout_rate_Layer_2': 0.16979673507983462, 'dropout_rate_Layer_3': 0.25230632143839604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06480343032316126, 'l1_Layer_2': 0.0002546230615765295, 'l1_Layer_3': 2.6530485662069587e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.94 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.87 | sMAPE for Test Set is: 17.56% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:57:43,499]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:57:47,947]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:57:58,322]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:58:23,735]\u001b[0m Trial 461 finished with value: 28.330011759330443 and parameters: {'n_hidden': 3, 'learning_rate': 0.021525414254228173, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002460108758831722, 'dropout_rate_Layer_2': 0.1110971910005258, 'dropout_rate_Layer_3': 0.24819851231932435, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005919040003109096, 'l1_Layer_2': 0.0256782018074936, 'l1_Layer_3': 0.06376489100592117, 'n_units_Layer_1': 255, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.33 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.33 | sMAPE for Test Set is: 19.79% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:58:55,099]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:04,759]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:08,666]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 01:59:25,406]\u001b[0m Trial 468 finished with value: 88.74678630841288 and parameters: {'n_hidden': 4, 'learning_rate': 0.07495556848818083, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06242833069767405, 'dropout_rate_Layer_2': 0.2347230638765395, 'dropout_rate_Layer_3': 0.06569516298994418, 'dropout_rate_Layer_4': 0.2605056521752094, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017140740108607445, 'l1_Layer_2': 0.004269825090336688, 'l1_Layer_3': 4.454988269209867e-05, 'l1_Layer_4': 1.9073554900531285e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 165, 'n_units_Layer_3': 80, 'n_units_Layer_4': 85}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 88.75 | sMAPE for Validation Set is: 49.84% | rMAE for Validation Set is: 1.61\n",
      "MAE for Test Set is: 28.33 | sMAPE for Test Set is: 32.24% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 01:59:30,419]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:03,071]\u001b[0m Trial 470 finished with value: 28.630639097980282 and parameters: {'n_hidden': 3, 'learning_rate': 0.020617581738821267, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01482342527700889, 'dropout_rate_Layer_2': 0.10941956899539679, 'dropout_rate_Layer_3': 0.2922524132156865, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006753635185621234, 'l1_Layer_2': 0.02518677473099406, 'l1_Layer_3': 0.06323205250031474, 'n_units_Layer_1': 255, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.63 | sMAPE for Validation Set is: 18.71% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 13.51 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:00:07,968]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:13,069]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:16,454]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:27,585]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:41,816]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:46,912]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:52,087]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:00:56,512]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:01,801]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:09,541]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:15,032]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:16,755]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:19,766]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:22,001]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:28,899]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:31,345]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:34,137]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:36,533]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:39,391]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:44,089]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:44,266]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:54,036]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:01:54,397]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:01,965]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:02,169]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:07,781]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:07,903]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:13,467]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:15,718]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:20,433]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:28,757]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.25 | sMAPE for Validation Set is: 17.57% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.35 | sMAPE for Test Set is: 18.85% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:02:57,490]\u001b[0m Trial 501 finished with value: 27.248059034087806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0063861704334140105, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11597174398972115, 'dropout_rate_Layer_2': 0.005554579538787313, 'dropout_rate_Layer_3': 0.22761513422405683, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09364064060707053, 'l1_Layer_2': 0.00034941012829871413, 'l1_Layer_3': 0.0016657494817073604, 'n_units_Layer_1': 135, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:02:57,906]\u001b[0m Trial 502 finished with value: 28.96623018750987 and parameters: {'n_hidden': 3, 'learning_rate': 0.02468082215114866, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 2.13676358167365e-05, 'dropout_rate_Layer_2': 0.11043444549714336, 'dropout_rate_Layer_3': 0.1882104363017915, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016980328072859545, 'l1_Layer_2': 0.03601938290459953, 'l1_Layer_3': 0.029607031830674913, 'n_units_Layer_1': 290, 'n_units_Layer_2': 290, 'n_units_Layer_3': 245}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.97 | sMAPE for Validation Set is: 19.15% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.25 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:03:38,519]\u001b[0m Trial 503 finished with value: 29.002988830298687 and parameters: {'n_hidden': 3, 'learning_rate': 0.023258700017371257, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027334684678594193, 'dropout_rate_Layer_2': 0.05274977721347505, 'dropout_rate_Layer_3': 0.2506838720964144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002873247824949048, 'l1_Layer_2': 0.0553112480370897, 'l1_Layer_3': 0.08074503555744919, 'n_units_Layer_1': 80, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.00 | sMAPE for Validation Set is: 19.26% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 19.92% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:03:48,853]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:03:51,847]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:04:03,692]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:04:08,978]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:04:16,226]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:04:51,041]\u001b[0m Trial 507 finished with value: 26.96237051660678 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007493571343940236, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2779632019010544, 'dropout_rate_Layer_2': 0.20072457970917776, 'dropout_rate_Layer_3': 0.09059739910456119, 'dropout_rate_Layer_4': 0.15893608104468038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07882682756115902, 'l1_Layer_2': 0.0005230311769889997, 'l1_Layer_3': 0.00026803098348357756, 'l1_Layer_4': 0.00015806233450517832, 'n_units_Layer_1': 105, 'n_units_Layer_2': 220, 'n_units_Layer_3': 190, 'n_units_Layer_4': 295}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.96 | sMAPE for Validation Set is: 17.49% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.37 | sMAPE for Test Set is: 17.98% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:05:23,350]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:05:30,793]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:05:35,814]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:05:48,429]\u001b[0m Trial 510 finished with value: 28.503883200082473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007049483701389472, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05217788367293924, 'dropout_rate_Layer_2': 0.17196922799512498, 'dropout_rate_Layer_3': 0.057034024412711784, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4912148096450476e-05, 'l1_Layer_2': 0.0007646695238960351, 'l1_Layer_3': 2.4842147169256576e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 150, 'n_units_Layer_3': 75}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.50 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.19 | sMAPE for Test Set is: 20.11% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:06:00,525]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:05,368]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:10,113]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:13,198]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:20,209]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:22,877]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:27,552]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:34,472]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:06:41,057]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:07:14,823]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:07:20,438]\u001b[0m Trial 524 finished with value: 26.715858797607478 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017732871464379726, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27142785881563924, 'dropout_rate_Layer_2': 0.010509334892597533, 'dropout_rate_Layer_3': 0.2615302932621847, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011046294018951248, 'l1_Layer_2': 0.0010142273738883022, 'l1_Layer_3': 3.240998365680624e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 200, 'n_units_Layer_3': 210}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.72 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.09 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:07:22,835]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:07:27,837]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:07:32,390]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:08:06,272]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:08:11,447]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:08:16,132]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:08:29,065]\u001b[0m Trial 526 finished with value: 27.847370527252366 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008911359969738512, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10395579378898925, 'dropout_rate_Layer_2': 0.16680951358642937, 'dropout_rate_Layer_3': 0.04900393118590543, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.879346389966323e-05, 'l1_Layer_2': 0.0006782635486563447, 'l1_Layer_3': 2.9421415349975447e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 80}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.85 | sMAPE for Validation Set is: 18.31% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.03 | sMAPE for Test Set is: 20.19% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:08:40,764]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:08:43,998]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:08:54,016]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:08:58,859]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:18,682]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:23,223]\u001b[0m Trial 535 finished with value: 29.450607508511965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038262581431817728, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15737811765287416, 'dropout_rate_Layer_2': 0.06787769220383753, 'dropout_rate_Layer_3': 0.16722778492423282, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.692134521610708e-05, 'l1_Layer_2': 0.0010532780108964057, 'l1_Layer_3': 0.00010171478849985232, 'n_units_Layer_1': 225, 'n_units_Layer_2': 200, 'n_units_Layer_3': 110}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:23,242]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.45 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.86 | sMAPE for Test Set is: 19.61% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:09:28,674]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:33,399]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:47,841]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:54,922]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:09:58,320]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:02,771]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:07,792]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:12,853]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:18,405]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:22,483]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:28,176]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:38,394]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:10:47,786]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:02,290]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:02,606]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:10,591]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:19,865]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:25,454]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:30,617]\u001b[0m Trial 554 finished with value: 29.636141466932372 and parameters: {'n_hidden': 3, 'learning_rate': 0.04000858555016361, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04584202370694907, 'dropout_rate_Layer_2': 0.15741319552682562, 'dropout_rate_Layer_3': 0.27732736566756505, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009297261691612257, 'l1_Layer_2': 0.044056677173951835, 'l1_Layer_3': 0.023245022625010308, 'n_units_Layer_1': 260, 'n_units_Layer_2': 300, 'n_units_Layer_3': 270}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.64 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 15.08 | sMAPE for Test Set is: 20.18% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:11:33,004]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:37,120]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:45,069]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:11:50,335]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:04,630]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:09,777]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:12:20,099]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:13:26,482]\u001b[0m Trial 561 finished with value: 27.11272166655051 and parameters: {'n_hidden': 3, 'learning_rate': 0.000912085483991247, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10128972242644474, 'dropout_rate_Layer_2': 0.14228156421785432, 'dropout_rate_Layer_3': 0.10603934598042507, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003987946994965323, 'l1_Layer_2': 0.030151478713413157, 'l1_Layer_3': 2.7997841608687546e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.11 | sMAPE for Validation Set is: 17.65% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.81 | sMAPE for Test Set is: 18.63% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:13:33,017]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:13:48,689]\u001b[0m Trial 568 finished with value: 29.532783560610792 and parameters: {'n_hidden': 3, 'learning_rate': 0.020285655948022976, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09531413522488691, 'dropout_rate_Layer_2': 0.11473388037217165, 'dropout_rate_Layer_3': 0.32964602889667055, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013260309407286959, 'l1_Layer_2': 0.025862761146663506, 'l1_Layer_3': 0.07287288371941147, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 295}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.53 | sMAPE for Validation Set is: 19.38% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.68 | sMAPE for Test Set is: 20.62% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:13:52,990]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:27,023]\u001b[0m Trial 570 finished with value: 28.181012058370715 and parameters: {'n_hidden': 3, 'learning_rate': 0.012601929396489997, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03324154380586833, 'dropout_rate_Layer_2': 0.05508908577831036, 'dropout_rate_Layer_3': 0.29869647288436607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000519833633850206, 'l1_Layer_2': 0.009100232419696461, 'l1_Layer_3': 0.04217333804830395, 'n_units_Layer_1': 290, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.18 | sMAPE for Validation Set is: 18.47% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.71 | sMAPE for Test Set is: 18.48% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:14:38,283]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:41,003]\u001b[0m Trial 566 finished with value: 27.083113263818806 and parameters: {'n_hidden': 3, 'learning_rate': 0.002113549034989517, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09468527805356512, 'dropout_rate_Layer_2': 0.15192597296874974, 'dropout_rate_Layer_3': 0.10739998435694456, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00038174393757475333, 'l1_Layer_2': 0.035908819579807655, 'l1_Layer_3': 2.6544042190195133e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 225, 'n_units_Layer_3': 75}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.08 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.18 | sMAPE for Test Set is: 19.31% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:14:44,842]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:14:47,711]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:04,878]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:09,644]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:15,170]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:22,779]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:29,475]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:29,838]\u001b[0m Trial 573 finished with value: 27.746202148720766 and parameters: {'n_hidden': 3, 'learning_rate': 0.012796750950980361, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05938745630559401, 'dropout_rate_Layer_2': 0.05099811913881321, 'dropout_rate_Layer_3': 0.2438242050691748, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002042568061919497, 'l1_Layer_2': 0.017897920373010107, 'l1_Layer_3': 0.03800818200397274, 'n_units_Layer_1': 290, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.75 | sMAPE for Validation Set is: 18.06% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.97 | sMAPE for Test Set is: 19.49% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:15:37,557]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:40,434]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:45,324]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:46,460]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:15:55,452]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:20,821]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:32,413]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:38,109]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:44,832]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:52,199]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:16:57,142]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:02,085]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:06,770]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:19,414]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:24,419]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:30,035]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:34,591]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:41,845]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:47,552]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:54,453]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:17:59,833]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:18:03,993]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:18:08,906]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:18:13,744]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:18:19,172]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:18:54,812]\u001b[0m Trial 587 finished with value: 27.211139251286756 and parameters: {'n_hidden': 3, 'learning_rate': 0.001034055941981352, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2915891893444156, 'dropout_rate_Layer_2': 0.18878627524398253, 'dropout_rate_Layer_3': 0.04990025443929721, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01736593385363361, 'l1_Layer_2': 0.0007148134704124966, 'l1_Layer_3': 0.0007794584949951647, 'n_units_Layer_1': 85, 'n_units_Layer_2': 265, 'n_units_Layer_3': 105}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.21 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.48 | sMAPE for Test Set is: 18.30% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:19:12,417]\u001b[0m Trial 606 finished with value: 30.413015511655274 and parameters: {'n_hidden': 3, 'learning_rate': 0.01244232535316028, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15937549625426692, 'dropout_rate_Layer_2': 0.015621686598437094, 'dropout_rate_Layer_3': 0.2665747281242697, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009067984636115569, 'l1_Layer_2': 0.0026135640416625836, 'l1_Layer_3': 0.01752312269319157, 'n_units_Layer_1': 270, 'n_units_Layer_2': 240, 'n_units_Layer_3': 265}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.41 | sMAPE for Validation Set is: 19.46% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 15.57 | sMAPE for Test Set is: 21.35% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:19:16,855]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:22,812]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:26,859]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:32,181]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:39,661]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:51,132]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:19:57,987]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:20:05,667]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:20:10,609]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:00,616]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:05,345]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:09,535]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:14,796]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:19,791]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:27,250]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:34,653]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:39,532]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:44,768]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:52,156]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:57,002]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:21:59,736]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:09,360]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:13,663]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:13,853]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:19,669]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:24,008]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:31,146]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:52,119]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:22:59,628]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:07,167]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:21,982]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:30,394]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:42,511]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:23:47,333]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:03,065]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:08,392]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:12,921]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:16,870]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:21,838]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:29,953]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:35,826]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:24:42,628]\u001b[0m Trial 642 finished with value: 28.595379006216646 and parameters: {'n_hidden': 3, 'learning_rate': 0.007051455581619869, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05963455279018579, 'dropout_rate_Layer_2': 0.04541712100647656, 'dropout_rate_Layer_3': 0.24592543463546446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004787686507940083, 'l1_Layer_2': 0.00989655440513331, 'l1_Layer_3': 0.03268077811714327, 'n_units_Layer_1': 285, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.60 | sMAPE for Validation Set is: 18.41% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.05 | sMAPE for Test Set is: 18.72% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:24:47,901]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:00,631]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:07,310]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:12,038]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:16,841]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:27,904]\u001b[0m Trial 651 finished with value: 29.723221062444008 and parameters: {'n_hidden': 3, 'learning_rate': 0.030467907659179696, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029987163823304595, 'dropout_rate_Layer_2': 0.097757201236198, 'dropout_rate_Layer_3': 0.214708675585023, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002084635018911479, 'l1_Layer_2': 0.07582289681251225, 'l1_Layer_3': 0.07547413874996524, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 260}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.72 | sMAPE for Validation Set is: 19.16% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 15.39 | sMAPE for Test Set is: 19.82% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:25:37,846]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:42,739]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:50,702]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:25:53,290]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:10,757]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:22,990]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:27,150]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:29,766]\u001b[0m Trial 660 finished with value: 29.880948942110532 and parameters: {'n_hidden': 3, 'learning_rate': 0.015964620033996346, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2204257457148884, 'dropout_rate_Layer_2': 0.08097404009148298, 'dropout_rate_Layer_3': 0.2814135183091249, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012286730123474218, 'l1_Layer_2': 0.01707893574505999, 'l1_Layer_3': 0.024278012473068895, 'n_units_Layer_1': 290, 'n_units_Layer_2': 290, 'n_units_Layer_3': 275}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.88 | sMAPE for Validation Set is: 19.22% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 16.61 | sMAPE for Test Set is: 20.95% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:26:37,088]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:41,559]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:43,816]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:46,388]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:50,665]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:51,459]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:58,511]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:26:59,186]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:10,555]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:15,805]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:30,524]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:46,464]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:46,925]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:27:59,669]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:28:04,621]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:28:14,357]\u001b[0m Trial 677 finished with value: 27.86534530710686 and parameters: {'n_hidden': 3, 'learning_rate': 0.009680374858579071, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09286090733701537, 'dropout_rate_Layer_2': 0.022243402070351165, 'dropout_rate_Layer_3': 0.2673150823052832, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008666791184938577, 'l1_Layer_2': 0.000824062250851154, 'l1_Layer_3': 1.4217604626564908e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.87 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.39 | sMAPE for Test Set is: 18.34% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:28:21,197]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:39,777]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:29:42,443]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:30:21,032]\u001b[0m Trial 683 finished with value: 26.6154915024071 and parameters: {'n_hidden': 3, 'learning_rate': 0.005018507309864324, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37261950283742723, 'dropout_rate_Layer_2': 0.008679503672848747, 'dropout_rate_Layer_3': 0.24646038407467222, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011659312453261917, 'l1_Layer_2': 0.0004923560342372057, 'l1_Layer_3': 3.797253765369041e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 155, 'n_units_Layer_3': 230}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.62 | sMAPE for Validation Set is: 17.35% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.12 | sMAPE for Test Set is: 17.90% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:30:28,386]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:30:31,864]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:30:43,368]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:30:45,887]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:30:48,455]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:30:53,288]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:30:56,286]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:31:01,470]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:31:28,349]\u001b[0m Trial 692 finished with value: 27.026517643725413 and parameters: {'n_hidden': 3, 'learning_rate': 0.009183598749529495, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11353411288290682, 'dropout_rate_Layer_2': 0.029848317777919332, 'dropout_rate_Layer_3': 0.35171755352322215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009200718377691743, 'l1_Layer_2': 0.0017877906858875833, 'l1_Layer_3': 2.506405418978919e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 265}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.03 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.64 | sMAPE for Test Set is: 18.79% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:32:12,100]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:17,201]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:22,403]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:24,768]\u001b[0m Trial 693 finished with value: 27.719082242472435 and parameters: {'n_hidden': 3, 'learning_rate': 0.001348196847943096, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13832519491421916, 'dropout_rate_Layer_2': 0.07943718484012718, 'dropout_rate_Layer_3': 0.031531971407012804, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.358646604839374e-05, 'l1_Layer_2': 0.0003799856669006261, 'l1_Layer_3': 2.020680914657173e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 250, 'n_units_Layer_3': 130}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.72 | sMAPE for Validation Set is: 18.31% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.58 | sMAPE for Test Set is: 19.71% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:32:31,901]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:37,201]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:37,497]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:44,620]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:47,158]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:49,937]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:52,419]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:32:57,736]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:33:04,615]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:33:07,521]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:33:19,475]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:33:19,902]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:33:27,018]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:33:37,317]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:06,899]\u001b[0m Trial 710 finished with value: 27.073759924142276 and parameters: {'n_hidden': 3, 'learning_rate': 0.004683433964196439, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3853509688115131, 'dropout_rate_Layer_2': 0.06123393253962938, 'dropout_rate_Layer_3': 0.32011220845982935, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03555140692448287, 'l1_Layer_2': 0.0005827726769985552, 'l1_Layer_3': 3.5148319699526424e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.07 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.42 | sMAPE for Test Set is: 17.96% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:34:12,312]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:16,574]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:21,551]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:31,592]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:34,136]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:36,781]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:39,326]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:42,063]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:48,906]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:51,900]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:54,034]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:56,175]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:34:59,687]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:04,119]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:18,793]\u001b[0m Trial 724 finished with value: 28.01576280550584 and parameters: {'n_hidden': 3, 'learning_rate': 0.008176648318936075, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16085289734765112, 'dropout_rate_Layer_2': 0.02726580104187852, 'dropout_rate_Layer_3': 0.3573367175430287, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006010210641080379, 'l1_Layer_2': 0.0004374948557658118, 'l1_Layer_3': 2.2003289080345334e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 300, 'n_units_Layer_3': 270}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.02 | sMAPE for Validation Set is: 18.47% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 19.85% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:35:29,099]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:33,574]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:39,349]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:44,326]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:48,812]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:53,486]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:35:56,789]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:03,962]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:10,977]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:16,396]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:23,913]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:28,685]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:39,314]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:49,647]\u001b[0m Trial 730 finished with value: 27.10953998888782 and parameters: {'n_hidden': 3, 'learning_rate': 0.001036782791230234, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34963722472737063, 'dropout_rate_Layer_2': 0.046089094123206685, 'dropout_rate_Layer_3': 0.253830843605601, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014357726486295547, 'l1_Layer_2': 0.006018567477813317, 'l1_Layer_3': 3.432661821864765e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 130, 'n_units_Layer_3': 225}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.11 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.65 | sMAPE for Test Set is: 18.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:36:53,628]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:36:58,444]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:13,760]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:19,340]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:19,642]\u001b[0m Trial 743 finished with value: 27.701500928120016 and parameters: {'n_hidden': 3, 'learning_rate': 0.007846758544060318, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13734584820298112, 'dropout_rate_Layer_2': 0.022737138210624806, 'dropout_rate_Layer_3': 0.3274145078743386, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005776733391370853, 'l1_Layer_2': 0.0004279800223606832, 'l1_Layer_3': 2.4759439622523834e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.70 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.71 | sMAPE for Test Set is: 18.39% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:37:29,877]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:39,565]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:44,776]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:51,672]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:37:59,851]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:04,005]\u001b[0m Trial 746 finished with value: 27.20540827200011 and parameters: {'n_hidden': 3, 'learning_rate': 0.007292616106853476, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13055776796093455, 'dropout_rate_Layer_2': 0.023834971842183042, 'dropout_rate_Layer_3': 0.3526198471362394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0076253439807613295, 'l1_Layer_2': 0.0004987096326438687, 'l1_Layer_3': 3.2470660363463225e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 300, 'n_units_Layer_3': 145}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.21 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 14.02 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:38:06,860]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:11,431]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:16,662]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:22,016]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:24,735]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:29,657]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:36,607]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:43,541]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:47,069]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:47,424]\u001b[0m Trial 753 finished with value: 27.655566000129255 and parameters: {'n_hidden': 3, 'learning_rate': 0.010392533251971422, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35803084595871765, 'dropout_rate_Layer_2': 0.1487038833188623, 'dropout_rate_Layer_3': 0.19381690349805025, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005864623471416505, 'l1_Layer_2': 0.00018027763221345564, 'l1_Layer_3': 0.00014061432082213994, 'n_units_Layer_1': 260, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.66 | sMAPE for Validation Set is: 17.96% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.69 | sMAPE for Test Set is: 18.47% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:38:52,840]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:57,311]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:38:59,359]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:39:02,442]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:39:11,879]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:39:12,246]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:39:19,977]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:39:24,106]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:39:34,586]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:39:54,703]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:39:59,382]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:02,439]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:07,123]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:12,294]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:14,606]\u001b[0m Trial 770 finished with value: 26.53559899385859 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021199865033095138, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21174766391411648, 'dropout_rate_Layer_2': 0.3231309074408575, 'dropout_rate_Layer_3': 0.21444415359127192, 'dropout_rate_Layer_4': 0.265008341091119, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.017943899936248186, 'l1_Layer_2': 0.00036043287102211093, 'l1_Layer_3': 1.720227374178015e-05, 'l1_Layer_4': 0.00028583538134171874, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 95, 'n_units_Layer_4': 300}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.54 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.91 | sMAPE for Test Set is: 17.54% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:40:17,053]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:22,237]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:24,680]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:29,315]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:31,947]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:34,566]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:41,363]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:46,343]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:40:53,910]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:01,827]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:06,281]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:11,488]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:15,997]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:24,340]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:29,085]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:42,126]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:47,620]\u001b[0m Trial 790 finished with value: 28.31835755611932 and parameters: {'n_hidden': 3, 'learning_rate': 0.003944468222437569, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30963051851385404, 'dropout_rate_Layer_2': 0.22772154491815405, 'dropout_rate_Layer_3': 0.36038226722795863, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002163533009813513, 'l1_Layer_2': 0.0007104515050041663, 'l1_Layer_3': 3.1408786382337945e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.32 | sMAPE for Validation Set is: 18.18% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.69 | sMAPE for Test Set is: 18.47% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:41:51,791]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:41:57,099]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:42:02,104]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:42:41,724]\u001b[0m Trial 797 finished with value: 26.95667515433645 and parameters: {'n_hidden': 3, 'learning_rate': 0.002800667190060137, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2828473980721798, 'dropout_rate_Layer_2': 0.2801951748029282, 'dropout_rate_Layer_3': 0.2298969711281641, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009606182348543345, 'l1_Layer_2': 0.001478906936979767, 'l1_Layer_3': 1.4264219142091554e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 130}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.96 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.26 | sMAPE for Test Set is: 18.16% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:42:44,103]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:42:51,625]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:43:01,575]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:43:21,147]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:43:24,266]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:43:31,413]\u001b[0m Trial 799 finished with value: 27.2333603927987 and parameters: {'n_hidden': 3, 'learning_rate': 0.002700862785362615, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2794353882991253, 'dropout_rate_Layer_2': 0.3274460994322883, 'dropout_rate_Layer_3': 0.08902580963912629, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008659137751193998, 'l1_Layer_2': 0.0015283748976605358, 'l1_Layer_3': 1.1842850661075776e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 140}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.23 | sMAPE for Validation Set is: 17.47% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.31 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:43:41,009]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:43:41,568]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:43:51,312]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:44:08,765]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:44:30,990]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:44:35,948]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:44:45,635]\u001b[0m Trial 808 finished with value: 27.278573783983507 and parameters: {'n_hidden': 3, 'learning_rate': 0.003536656356699859, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2648921801229713, 'dropout_rate_Layer_2': 0.31382299741677044, 'dropout_rate_Layer_3': 0.22558997113319085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006309720796028655, 'l1_Layer_2': 0.0019313221069934099, 'l1_Layer_3': 1.0635507231393261e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 55, 'n_units_Layer_3': 125}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.28 | sMAPE for Validation Set is: 17.71% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.55 | sMAPE for Test Set is: 18.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:44:57,975]\u001b[0m Trial 810 finished with value: 27.191079373041124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0062828513405873, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12245489651695211, 'dropout_rate_Layer_2': 0.06385537174822117, 'dropout_rate_Layer_3': 0.3327214450625641, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01097001872402209, 'l1_Layer_2': 0.00021796651000699442, 'l1_Layer_3': 1.8677756695961225e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 295, 'n_units_Layer_3': 155}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.19 | sMAPE for Validation Set is: 17.71% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.56 | sMAPE for Test Set is: 18.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:45:03,405]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:45:25,383]\u001b[0m Trial 812 finished with value: 26.568908512014033 and parameters: {'n_hidden': 3, 'learning_rate': 0.004574664790068403, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12693499467959687, 'dropout_rate_Layer_2': 0.03799785118065306, 'dropout_rate_Layer_3': 0.3592783916195451, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.019138833034246648, 'l1_Layer_2': 0.0002597266460899189, 'l1_Layer_3': 2.201501591178986e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 295, 'n_units_Layer_3': 160}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.57 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.02 | sMAPE for Test Set is: 17.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:45:38,264]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:45:38,837]\u001b[0m Trial 813 finished with value: 27.851769685464973 and parameters: {'n_hidden': 3, 'learning_rate': 0.003948366762268652, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2648881598411604, 'dropout_rate_Layer_2': 0.33092466932706077, 'dropout_rate_Layer_3': 0.23225615834855304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007180814352823695, 'l1_Layer_2': 0.00156126904614045, 'l1_Layer_3': 1.2125664766227308e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 120}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.85 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.56 | sMAPE for Test Set is: 18.61% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:45:58,853]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:46:31,227]\u001b[0m Trial 815 finished with value: 26.973262995204 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009795075835222925, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2870412005773812, 'dropout_rate_Layer_2': 0.17607396179934728, 'dropout_rate_Layer_3': 0.043039524977308015, 'dropout_rate_Layer_4': 0.14513083583225223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08326630730477828, 'l1_Layer_2': 0.0029323328722908044, 'l1_Layer_3': 0.000259606386818198, 'l1_Layer_4': 4.414290891383012e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 60, 'n_units_Layer_4': 300}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.97 | sMAPE for Validation Set is: 17.49% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.45 | sMAPE for Test Set is: 18.09% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:46:36,109]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:46:44,203]\u001b[0m Trial 817 finished with value: 26.599706994457176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033870270997667855, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27795574722473126, 'dropout_rate_Layer_2': 0.33317457826422614, 'dropout_rate_Layer_3': 0.0879370572684206, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00794398569625631, 'l1_Layer_2': 0.0013258499359384691, 'l1_Layer_3': 1.2121016045975053e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 60, 'n_units_Layer_3': 120}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.60 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.22 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:46:50,977]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:46:56,216]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:46:59,047]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:01,733]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:09,399]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:16,259]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:21,339]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:23,934]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:26,242]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:33,572]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:45,698]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:53,940]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:47:58,323]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:48:03,700]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:48:05,610]\u001b[0m Trial 828 finished with value: 26.782847883361125 and parameters: {'n_hidden': 3, 'learning_rate': 0.002853414943700301, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2707601774400191, 'dropout_rate_Layer_2': 0.33088933501989454, 'dropout_rate_Layer_3': 0.08396005475193696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008790695403899406, 'l1_Layer_2': 0.0012736258905785298, 'l1_Layer_3': 1.3219830291460433e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 50, 'n_units_Layer_3': 125}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.78 | sMAPE for Validation Set is: 17.47% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.24 | sMAPE for Test Set is: 17.93% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:48:44,758]\u001b[0m Trial 835 finished with value: 27.018503305987494 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032226277267026486, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2627915514790617, 'dropout_rate_Layer_2': 0.33555243863145284, 'dropout_rate_Layer_3': 0.09168995099077702, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006040338635230798, 'l1_Layer_2': 0.001165808638530189, 'l1_Layer_3': 1.1586544924461688e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 50, 'n_units_Layer_3': 120}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.02 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.16 | sMAPE for Test Set is: 17.88% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:48:53,038]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:49:08,094]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:49:12,370]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:49:20,415]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:49:22,411]\u001b[0m Trial 834 finished with value: 27.39416060306229 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013346910750227146, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2036647539287583, 'dropout_rate_Layer_2': 0.20765798561463117, 'dropout_rate_Layer_3': 0.19217450470467767, 'dropout_rate_Layer_4': 0.14760905509168987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0405691879441048, 'l1_Layer_2': 0.0013030463413785918, 'l1_Layer_3': 5.6601846993213144e-05, 'l1_Layer_4': 3.560718548031405e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 230, 'n_units_Layer_3': 185, 'n_units_Layer_4': 285}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.39 | sMAPE for Validation Set is: 17.90% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.49 | sMAPE for Test Set is: 18.37% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:49:33,096]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:49:52,473]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:50:02,739]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:50:20,133]\u001b[0m Trial 842 finished with value: 28.084476102823654 and parameters: {'n_hidden': 3, 'learning_rate': 0.000762448463512194, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11875276375232165, 'dropout_rate_Layer_2': 0.16474470030621394, 'dropout_rate_Layer_3': 0.0564845390217894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.173059310960416e-05, 'l1_Layer_2': 0.0006386416548769534, 'l1_Layer_3': 3.366558300757642e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 210, 'n_units_Layer_3': 85}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.08 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.31 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:50:34,322]\u001b[0m Trial 844 finished with value: 27.42625819875708 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025333661477882807, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2637577737451868, 'dropout_rate_Layer_2': 0.3370282032320101, 'dropout_rate_Layer_3': 0.08278250141372197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004738222406596052, 'l1_Layer_2': 0.0012942847262504588, 'l1_Layer_3': 1.0273896878856738e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 50, 'n_units_Layer_3': 115}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.43 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.65 | sMAPE for Test Set is: 18.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:50:39,398]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:50:44,358]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:50:57,104]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:50:59,817]\u001b[0m Trial 845 finished with value: 61.12919605252463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023705671005864208, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2522124501539399, 'dropout_rate_Layer_2': 0.034958151430043355, 'dropout_rate_Layer_3': 0.2994233347783635, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.021176721189852903, 'l1_Layer_2': 0.0014708620244992638, 'l1_Layer_3': 0.00016459870911660516, 'n_units_Layer_1': 200, 'n_units_Layer_2': 205, 'n_units_Layer_3': 165}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.13 | sMAPE for Validation Set is: 31.87% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 23.79 | sMAPE for Test Set is: 27.16% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:51:05,181]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:51:05,495]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:51:22,541]\u001b[0m Trial 851 finished with value: 28.51882587320534 and parameters: {'n_hidden': 3, 'learning_rate': 0.017252122665994084, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3604659161297137, 'dropout_rate_Layer_2': 0.08579098588796083, 'dropout_rate_Layer_3': 0.12217343776050116, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008840981366987724, 'l1_Layer_2': 0.009445824610123318, 'l1_Layer_3': 0.0005918363862957887, 'n_units_Layer_1': 125, 'n_units_Layer_2': 115, 'n_units_Layer_3': 195}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.52 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.04 | sMAPE for Test Set is: 19.17% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:51:23,222]\u001b[0m Trial 852 finished with value: 28.85045127583616 and parameters: {'n_hidden': 3, 'learning_rate': 0.017245189652355126, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2946846120559314, 'dropout_rate_Layer_2': 0.08390202579414519, 'dropout_rate_Layer_3': 0.12430089531792977, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007616363623845105, 'l1_Layer_2': 0.008328590578460478, 'l1_Layer_3': 0.0006014062619853336, 'n_units_Layer_1': 125, 'n_units_Layer_2': 115, 'n_units_Layer_3': 135}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.85 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.27 | sMAPE for Test Set is: 19.38% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:51:30,282]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:51:43,066]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:51:50,016]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:51:58,007]\u001b[0m Trial 853 finished with value: 26.64761170163612 and parameters: {'n_hidden': 3, 'learning_rate': 0.005025200888842773, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12285070939296065, 'dropout_rate_Layer_2': 0.017569646638486782, 'dropout_rate_Layer_3': 0.34526363450039455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018915741987667333, 'l1_Layer_2': 0.0006948969529749624, 'l1_Layer_3': 2.373169948178473e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 295, 'n_units_Layer_3': 135}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.65 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.15 | sMAPE for Test Set is: 17.75% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:52:29,815]\u001b[0m Trial 858 finished with value: 28.363466256674887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010566043381871621, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39819880522858947, 'dropout_rate_Layer_2': 0.1690695785243535, 'dropout_rate_Layer_3': 0.1714009626610956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006853413864864159, 'l1_Layer_2': 0.0010049002720775753, 'l1_Layer_3': 5.192475071856037e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 255, 'n_units_Layer_3': 180}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.36 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.75 | sMAPE for Test Set is: 18.34% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:52:32,354]\u001b[0m Trial 857 finished with value: 26.62849420491433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031877932863189967, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27784858756588354, 'dropout_rate_Layer_2': 0.33517909128219125, 'dropout_rate_Layer_3': 0.09412739320529094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004207963968633659, 'l1_Layer_2': 0.0013643024365672315, 'l1_Layer_3': 1.282950996870412e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 65, 'n_units_Layer_3': 115}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.63 | sMAPE for Validation Set is: 17.41% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.08 | sMAPE for Test Set is: 17.79% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:52:34,479]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:52:37,584]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:52:48,936]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:52:52,230]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:52:59,886]\u001b[0m Trial 860 finished with value: 26.495480112530004 and parameters: {'n_hidden': 3, 'learning_rate': 0.005496262443786057, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12573636894011883, 'dropout_rate_Layer_2': 0.017987267079359437, 'dropout_rate_Layer_3': 0.34280279461384167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01594562170007315, 'l1_Layer_2': 0.000681664187054274, 'l1_Layer_3': 1.147245957837589e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.50 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.08 | sMAPE for Test Set is: 18.20% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:53:06,796]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:53:11,778]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:53:16,769]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:53:34,017]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:53:34,481]\u001b[0m Trial 864 finished with value: 26.8846997662352 and parameters: {'n_hidden': 3, 'learning_rate': 0.003065496466853889, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28832001957108383, 'dropout_rate_Layer_2': 0.3021716390005931, 'dropout_rate_Layer_3': 0.09274812355991398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004258352466824463, 'l1_Layer_2': 0.0010222089673401404, 'l1_Layer_3': 1.6610056792635345e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 110}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.88 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.20 | sMAPE for Test Set is: 18.21% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:53:40,837]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:54:16,566]\u001b[0m Trial 871 finished with value: 26.616028340873996 and parameters: {'n_hidden': 3, 'learning_rate': 0.002991974379545046, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2885279069258786, 'dropout_rate_Layer_2': 0.28426536912974654, 'dropout_rate_Layer_3': 0.08433351737868755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008664737266856752, 'l1_Layer_2': 0.0011059681688684868, 'l1_Layer_3': 1.0006014021008013e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 60, 'n_units_Layer_3': 110}. Best is trial 406 with value: 26.318019674303812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.62 | sMAPE for Validation Set is: 17.29% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.14 | sMAPE for Test Set is: 17.74% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:54:19,355]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:54:21,463]\u001b[0m Trial 869 finished with value: 26.291752786816165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026115440293973447, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2824722000322841, 'dropout_rate_Layer_2': 0.3043345002060806, 'dropout_rate_Layer_3': 0.08981461215399167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004360838451380026, 'l1_Layer_2': 0.0010493539454995882, 'l1_Layer_3': 1.0009004375872544e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 75, 'n_units_Layer_3': 105}. Best is trial 869 with value: 26.291752786816165.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.29 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.92 | sMAPE for Test Set is: 17.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:54:23,781]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:54:26,797]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:54:28,810]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:54:38,558]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:54:54,380]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:55:08,700]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:55:11,779]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:55:29,075]\u001b[0m Trial 876 finished with value: 26.233420275972538 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024059916526033313, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2750696582769306, 'dropout_rate_Layer_2': 0.2942367589594189, 'dropout_rate_Layer_3': 0.09983069762893773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004522156226453052, 'l1_Layer_2': 0.0009749691309152456, 'l1_Layer_3': 1.1753244861367662e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 105}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.23 | sMAPE for Validation Set is: 17.07% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.05 | sMAPE for Test Set is: 17.61% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:55:33,687]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:55:38,376]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:55:56,747]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:56:01,924]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:56:04,380]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:56:26,335]\u001b[0m Trial 884 finished with value: 26.631411800992776 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028422970467332637, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27791961726755404, 'dropout_rate_Layer_2': 0.30207481200221803, 'dropout_rate_Layer_3': 0.10784428597135494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004437249333385296, 'l1_Layer_2': 0.001981387811777927, 'l1_Layer_3': 1.1595610177573143e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 55, 'n_units_Layer_3': 115}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.63 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.19 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:56:31,754]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:56:58,742]\u001b[0m Trial 887 finished with value: 29.48518027370425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013035880795169523, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21971981851068967, 'dropout_rate_Layer_2': 0.13193138815904304, 'dropout_rate_Layer_3': 0.02201824192747226, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010020115850885114, 'l1_Layer_2': 0.00027873503311410234, 'l1_Layer_3': 1.635743435043351e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 205, 'n_units_Layer_3': 75}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.49 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 15.03 | sMAPE for Test Set is: 19.69% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:57:23,395]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:57:30,895]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:57:47,947]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:58:08,098]\u001b[0m Trial 890 finished with value: 26.275008213192617 and parameters: {'n_hidden': 4, 'learning_rate': 0.001003609553498675, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24095579834418093, 'dropout_rate_Layer_2': 0.19580521371030896, 'dropout_rate_Layer_3': 0.06120045337904666, 'dropout_rate_Layer_4': 0.11860013058523379, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04254426480825162, 'l1_Layer_2': 0.0004527715706054686, 'l1_Layer_3': 0.0005314649983879285, 'l1_Layer_4': 0.00019600494059258578, 'n_units_Layer_1': 85, 'n_units_Layer_2': 230, 'n_units_Layer_3': 115, 'n_units_Layer_4': 290}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.28 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.14 | sMAPE for Test Set is: 17.84% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:58:10,661]\u001b[0m Trial 893 finished with value: 26.841132834366135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036472600019895655, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12703766102204225, 'dropout_rate_Layer_2': 0.00040629564643169386, 'dropout_rate_Layer_3': 0.3465959179095247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06133971321556945, 'l1_Layer_2': 0.0006590157791535682, 'l1_Layer_3': 1.0161890724952107e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 285, 'n_units_Layer_3': 140}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.84 | sMAPE for Validation Set is: 17.48% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.05 | sMAPE for Test Set is: 17.92% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:58:13,543]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:58:15,298]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:58:18,264]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:58:25,535]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:59:09,948]\u001b[0m Trial 896 finished with value: 26.586511259432502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022825213934412818, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28747572150287704, 'dropout_rate_Layer_2': 0.2747385009404849, 'dropout_rate_Layer_3': 0.11334354598569657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00854695598548044, 'l1_Layer_2': 0.0009233689025503508, 'l1_Layer_3': 1.6272535036816588e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 60, 'n_units_Layer_3': 100}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.59 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.19 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:59:17,127]\u001b[0m Trial 899 finished with value: 28.495933979474405 and parameters: {'n_hidden': 3, 'learning_rate': 0.002151281259864508, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09601631965971362, 'dropout_rate_Layer_2': 0.2006633673951822, 'dropout_rate_Layer_3': 0.062489529402758745, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.416982503031842e-05, 'l1_Layer_2': 0.0009450860698049767, 'l1_Layer_3': 2.6710839617816997e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 240, 'n_units_Layer_3': 100}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.50 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.17 | sMAPE for Test Set is: 20.50% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 02:59:22,463]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:59:25,493]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:59:35,631]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:59:45,275]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:59:48,454]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 02:59:57,973]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:00:05,007]\u001b[0m Trial 903 finished with value: 26.821282947948077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025724675559878735, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2864813972676701, 'dropout_rate_Layer_2': 0.2776143944354451, 'dropout_rate_Layer_3': 0.11829500101711823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00830299997256476, 'l1_Layer_2': 0.0014910621444969457, 'l1_Layer_3': 1.3646430781280528e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 65, 'n_units_Layer_3': 105}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.82 | sMAPE for Validation Set is: 17.48% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.22 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:00:10,437]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:00:15,821]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:00:23,070]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:00:40,430]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:01:10,565]\u001b[0m Trial 911 finished with value: 26.517135946906034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022206159288311496, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2959327831648976, 'dropout_rate_Layer_2': 0.2718871074124287, 'dropout_rate_Layer_3': 0.10608116769989778, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007273959791947295, 'l1_Layer_2': 0.0011469070399711815, 'l1_Layer_3': 1.3832158428563185e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 55, 'n_units_Layer_3': 100}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.52 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.09 | sMAPE for Test Set is: 17.80% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:01:22,314]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:01:22,355]\u001b[0m Trial 912 finished with value: 26.35704863372573 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022740588140645504, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29524851995277684, 'dropout_rate_Layer_2': 0.2660531114288118, 'dropout_rate_Layer_3': 0.10529072162439544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007341660082843363, 'l1_Layer_2': 0.0011731966987937167, 'l1_Layer_3': 1.3998835515205667e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 55, 'n_units_Layer_3': 100}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.36 | sMAPE for Validation Set is: 17.11% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.96 | sMAPE for Test Set is: 17.61% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:01:28,071]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:01:32,493]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:01:42,283]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:01:47,790]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:01:57,572]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:02:20,399]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:02:28,046]\u001b[0m Trial 920 finished with value: 26.999427266935623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024032114364972755, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29204434597361156, 'dropout_rate_Layer_2': 0.2662713374146612, 'dropout_rate_Layer_3': 0.10293248429074679, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007273629860044107, 'l1_Layer_2': 0.0011842370119197147, 'l1_Layer_3': 1.4640621576597061e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 60, 'n_units_Layer_3': 95}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.00 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.30 | sMAPE for Test Set is: 18.08% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:02:30,637]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:02:37,903]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:02:40,302]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:02:44,795]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:02:52,247]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:02:59,943]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:03:07,170]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:03:21,404]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:03:28,891]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:03:33,492]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:03:41,247]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:03:51,559]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:03:56,486]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:03:59,459]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:04:04,480]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:04:05,034]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:04:17,051]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:04:46,498]\u001b[0m Trial 939 finished with value: 26.66183806599297 and parameters: {'n_hidden': 3, 'learning_rate': 0.002411863852902024, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28923409582039733, 'dropout_rate_Layer_2': 0.28329671686214686, 'dropout_rate_Layer_3': 0.08663183444693098, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01030024463992892, 'l1_Layer_2': 0.0009045478506578902, 'l1_Layer_3': 1.1766266326741343e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.66 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.26 | sMAPE for Test Set is: 17.92% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:04:51,074]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:04:54,045]\u001b[0m Trial 938 finished with value: 26.56684441736512 and parameters: {'n_hidden': 3, 'learning_rate': 0.002421213754904634, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30419536900404864, 'dropout_rate_Layer_2': 0.27160009146975445, 'dropout_rate_Layer_3': 0.09103222130039912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005513398927850668, 'l1_Layer_2': 0.0009585727195411787, 'l1_Layer_3': 1.1980914513106007e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.57 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.04 | sMAPE for Test Set is: 17.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:05:24,041]\u001b[0m Trial 942 finished with value: 26.566771635225592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021352996147254283, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2923466010966048, 'dropout_rate_Layer_2': 0.2748973005441994, 'dropout_rate_Layer_3': 0.08576668118738512, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005030015383397551, 'l1_Layer_2': 0.0009363751762668973, 'l1_Layer_3': 1.0153017227021602e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.57 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.03 | sMAPE for Test Set is: 17.66% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:05:28,239]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:05:36,179]\u001b[0m Trial 941 finished with value: 26.434107835073604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021378488012915096, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30370768624909183, 'dropout_rate_Layer_2': 0.2842925232137185, 'dropout_rate_Layer_3': 0.07506021714138805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005131345105642603, 'l1_Layer_2': 0.0008091983527925619, 'l1_Layer_3': 1.2026924540547608e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 80, 'n_units_Layer_3': 110}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.43 | sMAPE for Validation Set is: 17.35% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.99 | sMAPE for Test Set is: 17.83% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:06:06,582]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:06:08,823]\u001b[0m Trial 944 finished with value: 26.417256726254635 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019678480468611394, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30132537255124736, 'dropout_rate_Layer_2': 0.28301381621502303, 'dropout_rate_Layer_3': 0.08492729125647022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004731028372796779, 'l1_Layer_2': 0.0010736352052931513, 'l1_Layer_3': 1.0203908951669632e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.42 | sMAPE for Validation Set is: 17.29% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.07 | sMAPE for Test Set is: 17.79% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:06:16,209]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:06:23,258]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:06:28,112]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:06:35,593]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:06:35,759]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:06:43,398]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:06:58,443]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:07:15,711]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:07:18,961]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:07:43,423]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:07:55,334]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:02,784]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:10,125]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:13,088]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:20,282]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:26,876]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:08:32,587]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:04,557]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:09,290]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:14,018]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:14,230]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:19,952]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:20,368]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:27,483]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:30,397]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:32,976]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:33,251]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:39,432]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:46,405]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:49,502]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:09:55,777]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:10:00,727]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:10:33,536]\u001b[0m Trial 979 finished with value: 26.42211071555397 and parameters: {'n_hidden': 3, 'learning_rate': 0.004956169536252222, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13161848030919115, 'dropout_rate_Layer_2': 0.02112240398417523, 'dropout_rate_Layer_3': 0.30632775523106714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01958290147167806, 'l1_Layer_2': 0.0007214763666394938, 'l1_Layer_3': 1.5817648176882347e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 270, 'n_units_Layer_3': 115}. Best is trial 876 with value: 26.233420275972538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.42 | sMAPE for Validation Set is: 17.17% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.95 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:10:43,106]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:10:43,665]\u001b[0m Trial 973 finished with value: 26.161108346444937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020141256624150936, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2998818231688826, 'dropout_rate_Layer_2': 0.2943233052131713, 'dropout_rate_Layer_3': 0.08268149607793707, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006660142054089475, 'l1_Layer_2': 0.000963968763424721, 'l1_Layer_3': 1.3716580189407452e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.16 | sMAPE for Validation Set is: 17.13% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 12.69 | sMAPE for Test Set is: 17.45% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:10:49,974]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:10:54,647]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:10:54,746]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:11:00,191]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:11:04,809]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:11:07,286]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:11:36,957]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:11:40,026]\u001b[0m Trial 988 finished with value: 27.93552139381235 and parameters: {'n_hidden': 3, 'learning_rate': 0.004693443765479283, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37625118219703513, 'dropout_rate_Layer_2': 0.05188398048847195, 'dropout_rate_Layer_3': 0.3408273455718376, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04736515951355577, 'l1_Layer_2': 0.0004955814275259533, 'l1_Layer_3': 2.3424770022070224e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.94 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.96 | sMAPE for Test Set is: 18.52% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:11:41,823]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:11:53,733]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:11:53,935]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:01,076]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:05,296]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:09,986]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:10,034]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:15,301]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:15,420]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:25,206]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:27,729]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:36,783]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:37,475]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:12:44,376]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:07,209]\u001b[0m Trial 1004 finished with value: 27.22586927671561 and parameters: {'n_hidden': 3, 'learning_rate': 0.0052847232605797816, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11255630664367243, 'dropout_rate_Layer_2': 0.008853384710690325, 'dropout_rate_Layer_3': 0.3235222141925018, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01865583716885288, 'l1_Layer_2': 0.00040707870017720073, 'l1_Layer_3': 1.5422831130627828e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 265, 'n_units_Layer_3': 90}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.23 | sMAPE for Validation Set is: 17.66% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.65 | sMAPE for Test Set is: 18.30% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:13:09,682]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:12,108]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:16,039]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:21,282]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:21,686]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:28,476]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:33,619]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:49,230]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:51,812]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:54,196]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:13:56,844]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:01,919]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:06,434]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:09,116]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:11,325]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:21,146]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:29,018]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:34,009]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:38,665]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:43,981]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:51,132]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:14:56,472]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:15:01,131]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:15:03,866]\u001b[0m Trial 1020 finished with value: 26.698550201248192 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020793398204224005, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3499500181395414, 'dropout_rate_Layer_2': 0.05669534345753957, 'dropout_rate_Layer_3': 0.2976629020961194, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018808339627745405, 'l1_Layer_2': 0.0009067835202321042, 'l1_Layer_3': 4.3389349706356315e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 190, 'n_units_Layer_3': 200}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.70 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.38 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:15:08,819]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:15:16,211]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:15:53,757]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:15:56,426]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:16:13,329]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:16:23,224]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:16:28,156]\u001b[0m Trial 1031 finished with value: 27.087739190612982 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005599736090969247, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2677416674163589, 'dropout_rate_Layer_2': 0.1752397658301275, 'dropout_rate_Layer_3': 0.08297232637015704, 'dropout_rate_Layer_4': 0.12393897111229754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.040147195887721136, 'l1_Layer_2': 0.00012398551444904363, 'l1_Layer_3': 0.0005249358605283755, 'l1_Layer_4': 0.00042460766903626413, 'n_units_Layer_1': 125, 'n_units_Layer_2': 220, 'n_units_Layer_3': 145, 'n_units_Layer_4': 290}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.09 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.91 | sMAPE for Test Set is: 17.71% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:16:33,070]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:16:35,948]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:16:41,546]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:16:45,936]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:16:51,004]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:16:53,973]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:16:59,046]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:17:03,549]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:17:08,227]\u001b[0m Trial 1038 finished with value: 26.937271391617855 and parameters: {'n_hidden': 3, 'learning_rate': 0.00518583943437749, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.120413963200902, 'dropout_rate_Layer_2': 0.03774136992992892, 'dropout_rate_Layer_3': 0.30833872557571845, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012381084897347462, 'l1_Layer_2': 0.00045965382629168056, 'l1_Layer_3': 2.063285442242089e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 120}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.94 | sMAPE for Validation Set is: 17.58% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.30 | sMAPE for Test Set is: 18.08% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:17:08,580]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:17:14,187]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:17:20,365]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:17:32,619]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:17:33,465]\u001b[0m Trial 1046 finished with value: 26.781417654729424 and parameters: {'n_hidden': 3, 'learning_rate': 0.005017771822121124, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1203962704473209, 'dropout_rate_Layer_2': 0.2451784555635865, 'dropout_rate_Layer_3': 0.3379995927189251, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011400865571774573, 'l1_Layer_2': 0.0005179695015452413, 'l1_Layer_3': 1.1495537836480113e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 100}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.78 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.21 | sMAPE for Test Set is: 17.89% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:17:47,932]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:17:50,219]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:17:52,995]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:17:55,369]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:00,833]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:08,386]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:12,424]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:25,221]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:30,104]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:35,294]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:40,477]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:40,853]\u001b[0m Trial 1057 finished with value: 26.775521953961704 and parameters: {'n_hidden': 3, 'learning_rate': 0.004684053779609392, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1071008479251067, 'dropout_rate_Layer_2': 0.2198060023727342, 'dropout_rate_Layer_3': 0.3087763213274906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01503263034270061, 'l1_Layer_2': 0.00038554965160546474, 'l1_Layer_3': 1.866569661386427e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 120}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.78 | sMAPE for Validation Set is: 17.42% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.01 | sMAPE for Test Set is: 17.71% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:18:48,298]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:18:50,479]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:00,908]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:09,820]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:33,924]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:41,415]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:19:58,279]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:03,705]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:09,261]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:09,354]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:16,302]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:24,208]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:26,830]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:43,872]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:49,135]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:20:54,781]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:02,200]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:06,316]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:11,707]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:18,986]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:23,641]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:41,530]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:48,829]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:21:55,109]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:22:00,404]\u001b[0m Trial 1078 finished with value: 59.05488844333081 and parameters: {'n_hidden': 3, 'learning_rate': 0.002283430472551434, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3383761873131849, 'dropout_rate_Layer_2': 0.004532180733336916, 'dropout_rate_Layer_3': 0.2950221733656623, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0026724004201693873, 'l1_Layer_2': 0.0026386700269458475, 'l1_Layer_3': 1.998918861857084e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 225, 'n_units_Layer_3': 210}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.05 | sMAPE for Validation Set is: 30.53% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 23.19 | sMAPE for Test Set is: 26.51% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:22:17,503]\u001b[0m Trial 1086 finished with value: 70.13270853442963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021473742357404056, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33755474520681705, 'dropout_rate_Layer_2': 0.004825595945622754, 'dropout_rate_Layer_3': 0.2992369808122075, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002680131360074437, 'l1_Layer_2': 0.00247358481884858, 'l1_Layer_3': 2.1603193408690823e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 225, 'n_units_Layer_3': 210}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.13 | sMAPE for Validation Set is: 37.01% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 17.44 | sMAPE for Test Set is: 21.89% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:22:44,714]\u001b[0m Trial 1087 finished with value: 26.6528311116025 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026788551847408706, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2808587314858797, 'dropout_rate_Layer_2': 0.3209917877967252, 'dropout_rate_Layer_3': 0.08534379321290433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005256149759147798, 'l1_Layer_2': 0.0017467442634339404, 'l1_Layer_3': 1.353062050927364e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 80, 'n_units_Layer_3': 120}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.65 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.12 | sMAPE for Test Set is: 18.05% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:22:49,842]\u001b[0m Trial 1088 finished with value: 26.493186576418594 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023381845056019953, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28224879663845176, 'dropout_rate_Layer_2': 0.30523207826906096, 'dropout_rate_Layer_3': 0.12769455261765822, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0033685011423473916, 'l1_Layer_2': 0.000844560433636071, 'l1_Layer_3': 1.0026529551826506e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 80, 'n_units_Layer_3': 120}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.49 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.99 | sMAPE for Test Set is: 17.69% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:22:56,925]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:23:01,902]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:23:02,220]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:23:15,923]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:24:10,350]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:24:22,452]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:24:34,749]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:24:35,199]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:24:42,501]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:24:59,277]\u001b[0m Trial 1098 finished with value: 26.929937472374522 and parameters: {'n_hidden': 3, 'learning_rate': 0.004283959120566757, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13106257078697076, 'dropout_rate_Layer_2': 0.2145824809098338, 'dropout_rate_Layer_3': 0.3595020789065354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.025614385266225975, 'l1_Layer_2': 0.0012646251337809417, 'l1_Layer_3': 1.662378778278739e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 290, 'n_units_Layer_3': 125}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.93 | sMAPE for Validation Set is: 17.46% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.22 | sMAPE for Test Set is: 17.98% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:25:05,110]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:25:09,144]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:25:14,516]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.89 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.08 | sMAPE for Test Set is: 17.68% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:25:16,274]\u001b[0m Trial 1099 finished with value: 26.885350602971773 and parameters: {'n_hidden': 3, 'learning_rate': 0.006208856965532509, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06939596050329395, 'dropout_rate_Layer_2': 0.21379254894579836, 'dropout_rate_Layer_3': 0.3148606776331811, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018644427427943425, 'l1_Layer_2': 0.0012291551984065863, 'l1_Layer_3': 1.6384055253471053e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:25:34,693]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.90 | sMAPE for Validation Set is: 42.63% | rMAE for Validation Set is: 1.41\n",
      "MAE for Test Set is: 16.62 | sMAPE for Test Set is: 21.41% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:25:56,940]\u001b[0m Trial 1103 finished with value: 77.90490392463666 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006870721778960752, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29356983518157403, 'dropout_rate_Layer_2': 0.212456749164988, 'dropout_rate_Layer_3': 0.20746773256253967, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.012265659268137023, 'l1_Layer_2': 0.001100743745281416, 'l1_Layer_3': 1.1039961663918349e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 145, 'n_units_Layer_3': 230}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:26:06,304]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:26:09,622]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:26:18,807]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:26:23,739]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:26:48,099]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:26:52,441]\u001b[0m Trial 1110 finished with value: 26.897426778523727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041413955153512495, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06563939255226511, 'dropout_rate_Layer_2': 0.20467430659943997, 'dropout_rate_Layer_3': 0.06274680284023101, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.036779595704784986, 'l1_Layer_2': 0.0014313527097946093, 'l1_Layer_3': 2.9888866969085758e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.90 | sMAPE for Validation Set is: 17.57% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.39 | sMAPE for Test Set is: 18.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:26:59,543]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:02,998]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:09,552]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:14,841]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:15,034]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:20,181]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:23,354]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:27,310]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:35,174]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:37,797]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:40,913]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:27:50,705]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:07,234]\u001b[0m Trial 1123 finished with value: 26.874520158468016 and parameters: {'n_hidden': 3, 'learning_rate': 0.004084718034788056, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0864191069408487, 'dropout_rate_Layer_2': 0.18914368124418263, 'dropout_rate_Layer_3': 0.3753978457606527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.045730289404917315, 'l1_Layer_2': 0.0012381981811029742, 'l1_Layer_3': 1.7770343621484227e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.87 | sMAPE for Validation Set is: 17.42% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.22 | sMAPE for Test Set is: 17.96% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:28:10,713]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:17,956]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.61 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.31 | sMAPE for Test Set is: 17.89% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:28:27,258]\u001b[0m Trial 1124 finished with value: 26.609868835711392 and parameters: {'n_hidden': 3, 'learning_rate': 0.003976898218679146, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07273903348228661, 'dropout_rate_Layer_2': 0.20581608308717006, 'dropout_rate_Layer_3': 0.3131619334000415, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.047755908805960735, 'l1_Layer_2': 0.0014120848341519579, 'l1_Layer_3': 2.8610098240823515e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:30,785]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:35,039]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:40,215]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:43,361]\u001b[0m Trial 1127 finished with value: 26.98060774676516 and parameters: {'n_hidden': 3, 'learning_rate': 0.004103228715320577, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0657594853501887, 'dropout_rate_Layer_2': 0.20411750769597264, 'dropout_rate_Layer_3': 0.11540579505673654, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.048332935136419536, 'l1_Layer_2': 0.001305938622253575, 'l1_Layer_3': 2.8664350660924717e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.98 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.60 | sMAPE for Test Set is: 18.19% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:28:47,317]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:49,777]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:52,887]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:28:57,291]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:00,458]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:12,266]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:17,777]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:18,166]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:23,651]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:23,934]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:31,288]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:32,209]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:36,985]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:44,238]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:51,532]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:29:56,846]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:30:03,778]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:30:23,599]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:30:26,459]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:30:30,491]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:30:38,650]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:31:07,717]\u001b[0m Trial 1153 finished with value: 29.091760018178203 and parameters: {'n_hidden': 4, 'learning_rate': 0.008109525189169176, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2723834545276637, 'dropout_rate_Layer_2': 0.08836413219897205, 'dropout_rate_Layer_3': 0.3438977079096577, 'dropout_rate_Layer_4': 0.3908942766057373, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09335799708967404, 'l1_Layer_2': 0.0001294156764633275, 'l1_Layer_3': 0.00011215624822553114, 'l1_Layer_4': 1.2403704695513771e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 165, 'n_units_Layer_4': 55}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.09 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.99 | sMAPE for Test Set is: 20.04% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:31:11,087]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:31:15,601]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:31:18,466]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:31:22,753]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:31:25,989]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:31:35,684]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:32:05,550]\u001b[0m Trial 1159 finished with value: 26.41362518260488 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025400056885626224, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08912540634331417, 'dropout_rate_Layer_2': 0.19139541825328368, 'dropout_rate_Layer_3': 0.01337047702505162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0418640372206873, 'l1_Layer_2': 0.001191184925735019, 'l1_Layer_3': 1.6710039347902175e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 110}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.41 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.00 | sMAPE for Test Set is: 17.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:32:11,122]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:32:15,142]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:32:17,713]\u001b[0m Trial 1160 finished with value: 26.49032137670442 and parameters: {'n_hidden': 3, 'learning_rate': 0.003503428443737693, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07064009756327577, 'dropout_rate_Layer_2': 0.18410807544264735, 'dropout_rate_Layer_3': 0.01261725782535588, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.025294109360580318, 'l1_Layer_2': 0.0021520199795611694, 'l1_Layer_3': 1.8031574538099443e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 280, 'n_units_Layer_3': 110}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.49 | sMAPE for Validation Set is: 17.29% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.10 | sMAPE for Test Set is: 17.76% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:32:32,382]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:32:48,401]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:32:50,447]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:32:53,502]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:32:57,587]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:33:05,326]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:33:19,866]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:33:20,929]\u001b[0m Trial 1166 finished with value: 81.49453498673006 and parameters: {'n_hidden': 4, 'learning_rate': 0.03728590099016886, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2050942515165617, 'dropout_rate_Layer_2': 0.032875863986626425, 'dropout_rate_Layer_3': 0.2500997689692252, 'dropout_rate_Layer_4': 0.14637801108174991, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005523238224992617, 'l1_Layer_2': 5.879931223441523e-05, 'l1_Layer_3': 0.0003382175192385573, 'l1_Layer_4': 0.07723616560933788, 'n_units_Layer_1': 275, 'n_units_Layer_2': 210, 'n_units_Layer_3': 145, 'n_units_Layer_4': 300}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 81.49 | sMAPE for Validation Set is: 45.10% | rMAE for Validation Set is: 1.48\n",
      "MAE for Test Set is: 30.87 | sMAPE for Test Set is: 33.05% | rMAE for Test Set is: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:33:30,400]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:33:35,275]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:33:54,738]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:02,737]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:20,128]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:24,875]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:32,302]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:44,456]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:50,053]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:34:54,503]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:35:22,551]\u001b[0m Trial 1182 finished with value: 26.96786471818412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022402948318758944, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06949090933411255, 'dropout_rate_Layer_2': 0.18771052234790267, 'dropout_rate_Layer_3': 0.003575624618462824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04247146109398011, 'l1_Layer_2': 0.0020305945643836927, 'l1_Layer_3': 1.6960237824883312e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 285, 'n_units_Layer_3': 110}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.97 | sMAPE for Validation Set is: 17.47% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.32 | sMAPE for Test Set is: 17.99% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:35:26,686]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:35:34,781]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:36:04,055]\u001b[0m Trial 1185 finished with value: 26.764132517115588 and parameters: {'n_hidden': 3, 'learning_rate': 0.002495812149082975, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.053383608224303034, 'dropout_rate_Layer_2': 0.19736344030440306, 'dropout_rate_Layer_3': 0.14164304438394484, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03581842796029909, 'l1_Layer_2': 0.0011943926535589668, 'l1_Layer_3': 1.275371868878735e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 280, 'n_units_Layer_3': 105}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.76 | sMAPE for Validation Set is: 17.36% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.05 | sMAPE for Test Set is: 17.86% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:36:39,010]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:36:50,629]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:36:55,659]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:37:03,581]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:37:10,456]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:37:14,131]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:37:26,368]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:37:50,877]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:03,725]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:05,808]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:10,849]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:13,904]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:23,466]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:28,050]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:28,661]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:33,406]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:37,747]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:38:48,337]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:39:05,142]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:39:10,398]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:39:15,717]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:39:26,081]\u001b[0m Trial 1204 finished with value: 26.95782714675703 and parameters: {'n_hidden': 3, 'learning_rate': 0.003352068233903158, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2632433340846268, 'dropout_rate_Layer_2': 0.2969785606170849, 'dropout_rate_Layer_3': 0.06811562672488922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0034961496367519307, 'l1_Layer_2': 0.001876947312214884, 'l1_Layer_3': 1.167469674124205e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.96 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.32 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:39:37,915]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:39:45,772]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:39:48,272]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:39:50,635]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:39:53,123]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:39:55,546]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:40:05,456]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:40:10,392]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:40:10,897]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:40:15,736]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:40:18,022]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:40:25,100]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:40:33,100]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:41:07,491]\u001b[0m Trial 1219 finished with value: 28.847490941665693 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007739982952467892, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12374133232937481, 'dropout_rate_Layer_2': 0.16478951749151768, 'dropout_rate_Layer_3': 0.06764156696282805, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.6702947809992506e-05, 'l1_Layer_2': 0.000841428128130347, 'l1_Layer_3': 0.0780818454651664, 'n_units_Layer_1': 245, 'n_units_Layer_2': 195, 'n_units_Layer_3': 80}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.85 | sMAPE for Validation Set is: 18.54% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.21 | sMAPE for Test Set is: 19.03% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:41:12,722]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:41:20,043]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:41:23,192]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:41:27,801]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:41:37,383]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:41:42,696]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:41:52,639]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:42:05,090]\u001b[0m Trial 1226 finished with value: 26.99205002102106 and parameters: {'n_hidden': 3, 'learning_rate': 0.004307658378896997, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3753643305871106, 'dropout_rate_Layer_2': 0.06779241595210606, 'dropout_rate_Layer_3': 0.32498506342714123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03344565305814916, 'l1_Layer_2': 0.0006217002655818082, 'l1_Layer_3': 4.714433558632297e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.99 | sMAPE for Validation Set is: 17.65% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.76 | sMAPE for Test Set is: 18.77% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:42:09,779]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:42:13,228]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:42:32,243]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:42:37,228]\u001b[0m Trial 1229 finished with value: 26.557043280294042 and parameters: {'n_hidden': 3, 'learning_rate': 0.002297749030017934, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25558899260066, 'dropout_rate_Layer_2': 0.2706905021409426, 'dropout_rate_Layer_3': 0.0713602776589015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025389932612418175, 'l1_Layer_2': 0.00092444788178872, 'l1_Layer_3': 2.1121860029661243e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 60, 'n_units_Layer_3': 110}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.56 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.13 | sMAPE for Test Set is: 18.20% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:42:39,842]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:42:41,767]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:42:44,462]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:42:46,927]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:42:51,737]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:43:16,640]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:43:19,925]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:43:22,502]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:43:29,858]\u001b[0m Trial 1239 finished with value: 26.605177537273875 and parameters: {'n_hidden': 3, 'learning_rate': 0.00315804038736573, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07594741742491211, 'dropout_rate_Layer_2': 0.36501108798516685, 'dropout_rate_Layer_3': 0.07942894496800418, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.029220293185222623, 'l1_Layer_2': 0.0033521051750011154, 'l1_Layer_3': 5.279942301404432e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 290, 'n_units_Layer_3': 130}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.61 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.15 | sMAPE for Test Set is: 17.75% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:43:39,262]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:43:44,120]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:43:54,220]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:43:54,824]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:02,711]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:05,415]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:10,276]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:12,748]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:15,463]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:20,244]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:20,498]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:28,442]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:35,923]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:40,898]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:44:42,757]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:45:14,824]\u001b[0m Trial 1257 finished with value: 26.650436254998382 and parameters: {'n_hidden': 3, 'learning_rate': 0.003674269122173806, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04097749039351804, 'dropout_rate_Layer_2': 0.19332366468151307, 'dropout_rate_Layer_3': 0.15575415010898777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026529175966211523, 'l1_Layer_2': 0.0011758505354806294, 'l1_Layer_3': 2.047625968241506e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 285, 'n_units_Layer_3': 135}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.65 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.20 | sMAPE for Test Set is: 17.87% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:45:22,547]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:45:25,667]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:45:29,805]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:46:12,769]\u001b[0m Trial 1258 finished with value: 28.25239982994354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006339562285655533, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11246364313403724, 'dropout_rate_Layer_2': 0.18821404406770897, 'dropout_rate_Layer_3': 0.014628602548688339, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.76215966189456e-05, 'l1_Layer_2': 0.0010920645498692621, 'l1_Layer_3': 3.905683335519967e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.25 | sMAPE for Validation Set is: 18.27% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 19.26% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:46:17,409]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:46:22,822]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:46:26,878]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:46:27,770]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:46:32,552]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:46:49,366]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:46:53,909]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:46:59,139]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:47:03,986]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:47:08,531]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:47:20,662]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:47:26,423]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:47:43,205]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:47:54,186]\u001b[0m Trial 1275 finished with value: 27.479357572957127 and parameters: {'n_hidden': 3, 'learning_rate': 0.003432551227068046, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36543300965091247, 'dropout_rate_Layer_2': 0.06817556475905945, 'dropout_rate_Layer_3': 0.3119358802091444, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05365888657150296, 'l1_Layer_2': 0.00023687974719656954, 'l1_Layer_3': 4.8117242438747016e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.48 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.38 | sMAPE for Test Set is: 18.22% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:48:01,134]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:14,144]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:17,157]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:27,001]\u001b[0m Trial 1276 finished with value: 26.497413513422902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028232446872000537, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2879259568225972, 'dropout_rate_Layer_2': 0.3022124412100347, 'dropout_rate_Layer_3': 0.09146831245702543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007977431334735469, 'l1_Layer_2': 0.0007799331487657473, 'l1_Layer_3': 1.5786528566238227e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 70, 'n_units_Layer_3': 100}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.50 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.24 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:48:31,475]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:39,628]\u001b[0m Trial 1280 finished with value: 26.918275712016463 and parameters: {'n_hidden': 3, 'learning_rate': 0.004675373284591803, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05412577474661409, 'dropout_rate_Layer_2': 0.3531639202971702, 'dropout_rate_Layer_3': 0.09206972844656228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015525166548311464, 'l1_Layer_2': 0.001228391363819869, 'l1_Layer_3': 1.456814631969302e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 95}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.92 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.58 | sMAPE for Test Set is: 18.19% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:48:44,126]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:48,656]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:49,707]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:54,018]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:48:56,618]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:49:02,776]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:49:09,191]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:49:32,184]\u001b[0m Trial 1287 finished with value: 26.55193922756992 and parameters: {'n_hidden': 3, 'learning_rate': 0.002841993749484703, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27566337678591557, 'dropout_rate_Layer_2': 0.2861623077705482, 'dropout_rate_Layer_3': 0.08759672987468975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005008467823367237, 'l1_Layer_2': 0.0009646014466116186, 'l1_Layer_3': 1.1692898955570193e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 90, 'n_units_Layer_3': 95}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.55 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.01 | sMAPE for Test Set is: 17.65% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:49:36,249]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:49:41,603]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:49:47,066]\u001b[0m Trial 1290 finished with value: 26.75794992139497 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029200692575914312, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31753309906383703, 'dropout_rate_Layer_2': 0.031588594394613506, 'dropout_rate_Layer_3': 0.27668451570844593, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.022389915660931122, 'l1_Layer_2': 0.0007393496847225289, 'l1_Layer_3': 0.00014634679211799728, 'n_units_Layer_1': 75, 'n_units_Layer_2': 50, 'n_units_Layer_3': 200}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.76 | sMAPE for Validation Set is: 17.52% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.86 | sMAPE for Test Set is: 18.77% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:49:51,128]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:49:56,454]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:50:14,011]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:50:26,462]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:50:28,714]\u001b[0m Trial 1296 finished with value: 27.055731267375762 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029498741971351414, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3121774566880019, 'dropout_rate_Layer_2': 0.028375687620688234, 'dropout_rate_Layer_3': 0.2764616274932624, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02307132498826817, 'l1_Layer_2': 0.000369345630313594, 'l1_Layer_3': 0.00023505254922957967, 'n_units_Layer_1': 300, 'n_units_Layer_2': 50, 'n_units_Layer_3': 205}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.06 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.07 | sMAPE for Test Set is: 17.65% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:50:36,163]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:50:38,670]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:50:43,007]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:50:45,620]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:50:48,778]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:02,975]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:07,089]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:12,182]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:17,346]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:21,941]\u001b[0m Trial 1304 finished with value: 27.883344957739727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008456050892271488, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04544435214369639, 'dropout_rate_Layer_2': 0.14004419492364445, 'dropout_rate_Layer_3': 0.07239113448828999, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003437776877977968, 'l1_Layer_2': 0.0006008713325886469, 'l1_Layer_3': 1.969432627744602e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 55}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.88 | sMAPE for Validation Set is: 18.21% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.14 | sMAPE for Test Set is: 19.13% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:51:24,817]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:26,969]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:29,650]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:32,864]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:40,028]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:42,759]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:45,210]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:49,906]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:51:51,900]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:52:32,172]\u001b[0m Trial 1317 finished with value: 57.90423580936269 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026582356600588337, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3218727614718148, 'dropout_rate_Layer_2': 0.04286559639973225, 'dropout_rate_Layer_3': 0.2603504051568434, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01684972759640862, 'l1_Layer_2': 0.0023614135453499355, 'l1_Layer_3': 0.0003575795519966983, 'n_units_Layer_1': 70, 'n_units_Layer_2': 90, 'n_units_Layer_3': 220}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.90 | sMAPE for Validation Set is: 30.21% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 24.73 | sMAPE for Test Set is: 27.49% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:52:37,873]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:52:40,374]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:52:42,318]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:52:44,836]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:52:51,841]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:52:52,152]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:52:58,524]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:08,521]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:12,691]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:16,032]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:21,173]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:28,358]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:35,431]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:38,365]\u001b[0m Trial 1326 finished with value: 26.99124613178842 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031258186283347747, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30130342750844835, 'dropout_rate_Layer_2': 0.29595380231423374, 'dropout_rate_Layer_3': 0.0980736534285085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004928437506854969, 'l1_Layer_2': 0.0008707281265680435, 'l1_Layer_3': 1.1669964031818937e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 90, 'n_units_Layer_3': 85}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.99 | sMAPE for Validation Set is: 17.47% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.65 | sMAPE for Test Set is: 18.22% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:53:46,235]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:53,430]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:53:58,560]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:13,446]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:20,151]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:28,474]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:35,855]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:47,972]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:50,417]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:55,032]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:54:55,757]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:01,152]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:03,559]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:06,620]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:08,799]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:11,585]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:20,835]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:28,508]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:33,060]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:38,893]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:43,094]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:43,511]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:55:48,530]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:56:00,855]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:56:05,588]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:56:15,817]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:56:20,606]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:56:29,921]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:56:35,125]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:56:47,879]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:57:02,943]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:57:09,746]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:57:13,004]\u001b[0m Trial 1363 finished with value: 26.951694130656108 and parameters: {'n_hidden': 3, 'learning_rate': 0.003904409179185044, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07517188308874131, 'dropout_rate_Layer_2': 0.2109947422637548, 'dropout_rate_Layer_3': 0.04516613063752513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04607093648851371, 'l1_Layer_2': 0.0031872799373474686, 'l1_Layer_3': 2.3861929948092698e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 285, 'n_units_Layer_3': 125}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.95 | sMAPE for Validation Set is: 17.52% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.32 | sMAPE for Test Set is: 17.94% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:57:15,760]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:57:18,060]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:57:27,746]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:57:42,491]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:57:45,559]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:57:57,590]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:02,006]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:07,489]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:15,115]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:19,510]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:37,083]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:41,611]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:47,075]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:52,507]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:58:57,800]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:59:01,787]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:59:07,541]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:59:12,021]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:59:19,713]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:59:24,175]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 03:59:53,947]\u001b[0m Trial 1386 finished with value: 26.606890951291813 and parameters: {'n_hidden': 3, 'learning_rate': 0.004202845420928178, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06446766688227161, 'dropout_rate_Layer_2': 0.20325908019229702, 'dropout_rate_Layer_3': 0.058393275201809175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03619151055770314, 'l1_Layer_2': 0.0015354749462048799, 'l1_Layer_3': 1.7104495688914984e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.61 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.00 | sMAPE for Test Set is: 17.67% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 03:59:58,786]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:00:23,908]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:00:56,875]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:01:21,961]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:01:28,732]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:01:54,112]\u001b[0m Trial 1390 finished with value: 26.491327034164517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024245967338521125, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2954649511429795, 'dropout_rate_Layer_2': 0.32686580326855946, 'dropout_rate_Layer_3': 0.07470101531257804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008609824456931984, 'l1_Layer_2': 0.0018679199600512696, 'l1_Layer_3': 1.7910845285437517e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 90, 'n_units_Layer_3': 105}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.49 | sMAPE for Validation Set is: 17.46% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.94 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:02:24,155]\u001b[0m Trial 1392 finished with value: 26.200751889692118 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022248793840359484, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25811463945690866, 'dropout_rate_Layer_2': 0.29926212065329555, 'dropout_rate_Layer_3': 0.08149594519262825, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007854185981742439, 'l1_Layer_2': 0.0011428386750628127, 'l1_Layer_3': 1.0008458756940845e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 90, 'n_units_Layer_3': 115}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.20 | sMAPE for Validation Set is: 17.11% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.70 | sMAPE for Test Set is: 17.45% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:02:26,875]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:02:27,024]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:02:34,420]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:02:44,435]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:02:47,325]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:02:50,053]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:02:55,383]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:03:02,126]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:03:12,208]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:03:16,901]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:03:19,997]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:03:34,034]\u001b[0m Trial 1402 finished with value: 26.892442058845386 and parameters: {'n_hidden': 3, 'learning_rate': 0.00452164372279767, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07778711311675783, 'dropout_rate_Layer_2': 0.23040338860215281, 'dropout_rate_Layer_3': 0.027085796571631626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09382105992040017, 'l1_Layer_2': 0.001116849825928999, 'l1_Layer_3': 1.478564916094707e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 295, 'n_units_Layer_3': 95}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.89 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.31 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:03:51,117]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:03:56,409]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:03,314]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:10,916]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:18,589]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:26,199]\u001b[0m Trial 1405 finished with value: 27.96513558412398 and parameters: {'n_hidden': 3, 'learning_rate': 0.001709927186972234, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0127091452263111, 'dropout_rate_Layer_2': 0.12790643823706305, 'dropout_rate_Layer_3': 0.08948258352629088, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003090077274119898, 'l1_Layer_2': 0.0025523857879250714, 'l1_Layer_3': 7.188282349518219e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.97 | sMAPE for Validation Set is: 18.38% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.53 | sMAPE for Test Set is: 22.09% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:04:31,277]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:35,856]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:04:51,143]\u001b[0m Trial 1412 finished with value: 26.791472357912216 and parameters: {'n_hidden': 3, 'learning_rate': 0.005710264354440119, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1043010154458177, 'dropout_rate_Layer_2': 0.20114727497186513, 'dropout_rate_Layer_3': 0.18551141266729332, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03491144419776364, 'l1_Layer_2': 0.0006640404451449929, 'l1_Layer_3': 1.1559102199893006e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 135, 'n_units_Layer_3': 110}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.79 | sMAPE for Validation Set is: 17.41% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.21 | sMAPE for Test Set is: 17.98% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:04:55,556]\u001b[0m Trial 1414 finished with value: 28.33099864630282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008587448039853867, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.033480068328526055, 'dropout_rate_Layer_2': 0.18027753131267835, 'dropout_rate_Layer_3': 0.12323220288540519, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4035644287734792e-05, 'l1_Layer_2': 0.0003436767628069238, 'l1_Layer_3': 2.090832263288862e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 105, 'n_units_Layer_3': 50}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.33 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 14.32 | sMAPE for Test Set is: 18.94% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:04:58,856]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:05:20,424]\u001b[0m Trial 1417 finished with value: 172.86995911530724 and parameters: {'n_hidden': 4, 'learning_rate': 0.09383616781676507, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3505107675994533, 'dropout_rate_Layer_2': 0.02330652099448864, 'dropout_rate_Layer_3': 0.2241225116028208, 'dropout_rate_Layer_4': 0.0063646383409403096, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007106610967892213, 'l1_Layer_2': 0.0007962306353468009, 'l1_Layer_3': 7.737447740858189e-05, 'l1_Layer_4': 0.0035756970993257265, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 50, 'n_units_Layer_4': 95}. Best is trial 973 with value: 26.161108346444937.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 172.87 | sMAPE for Validation Set is: 151.01% | rMAE for Validation Set is: 3.14\n",
      "MAE for Test Set is: 70.19 | sMAPE for Test Set is: 121.63% | rMAE for Test Set is: 3.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:05:27,764]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:05:38,621]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:05:43,061]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:05:48,685]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:05:53,370]\u001b[0m Trial 1416 finished with value: 26.02263774444826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022672375281401216, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2968733499270143, 'dropout_rate_Layer_2': 0.317658681248969, 'dropout_rate_Layer_3': 0.08036123658418416, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008127683663495009, 'l1_Layer_2': 0.0006848657890566131, 'l1_Layer_3': 2.183161615155046e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 90, 'n_units_Layer_3': 100}. Best is trial 1416 with value: 26.02263774444826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.02 | sMAPE for Validation Set is: 17.03% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 12.81 | sMAPE for Test Set is: 17.55% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:05:58,140]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:05:59,188]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:06:05,738]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:06:08,902]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:06:13,445]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:06:18,703]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:06:23,055]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:06:33,832]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:06:43,458]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:06:50,966]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:06:56,074]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:07:01,596]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:07:06,208]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:07:13,406]\u001b[0m Trial 1426 finished with value: 27.66915987018545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017172329276750465, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0090060281665027, 'dropout_rate_Layer_2': 0.12630680264412683, 'dropout_rate_Layer_3': 0.09067486403553268, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024834488891932022, 'l1_Layer_2': 0.003148582295648493, 'l1_Layer_3': 4.8722216588923986e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75}. Best is trial 1416 with value: 26.02263774444826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.67 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.78 | sMAPE for Test Set is: 21.26% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:07:18,111]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:07:23,140]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:07:28,940]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:07:38,162]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:07:48,813]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:07:53,769]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:08:08,754]\u001b[0m Trial 1440 finished with value: 26.494709947087028 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022777375411051726, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2599080096933191, 'dropout_rate_Layer_2': 0.301755550827574, 'dropout_rate_Layer_3': 0.07270059252936004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007843872756754635, 'l1_Layer_2': 0.0011380480096143382, 'l1_Layer_3': 1.8785014829638474e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 90, 'n_units_Layer_3': 115}. Best is trial 1416 with value: 26.02263774444826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.49 | sMAPE for Validation Set is: 17.42% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.44 | sMAPE for Test Set is: 18.40% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:08:15,330]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:08:22,858]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:08:33,427]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:08:38,277]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:08:44,868]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:08:57,378]\u001b[0m Trial 1443 finished with value: 25.929107497388866 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022900541809683784, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25958743727788747, 'dropout_rate_Layer_2': 0.23323055677961674, 'dropout_rate_Layer_3': 0.09047966780424418, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0041761937405832275, 'l1_Layer_2': 0.0009157535493030554, 'l1_Layer_3': 1.4425806861488318e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 90, 'n_units_Layer_3': 95}. Best is trial 1443 with value: 25.929107497388866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.93 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 12.50 | sMAPE for Test Set is: 17.20% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:08:57,856]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:04,046]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:08,984]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:20,979]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:30,498]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:36,044]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:40,508]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:47,833]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:53,064]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:09:58,074]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:03,176]\u001b[0m Trial 1452 finished with value: 27.354828311726592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012466587421400119, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2780043511006463, 'dropout_rate_Layer_2': 0.39723184748656604, 'dropout_rate_Layer_3': 0.28632214667055, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009502646813264751, 'l1_Layer_2': 0.005066313140471985, 'l1_Layer_3': 0.00016259922383161587, 'n_units_Layer_1': 85, 'n_units_Layer_2': 240, 'n_units_Layer_3': 300}. Best is trial 1443 with value: 25.929107497388866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.35 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.13 | sMAPE for Test Set is: 17.80% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:10:05,243]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:10,061]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:17,949]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:18,434]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:25,784]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:28,067]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:30,757]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:33,208]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:38,343]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:10:55,942]\u001b[0m Trial 1468 finished with value: 27.063684337607537 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035304840868375133, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10609565584485772, 'dropout_rate_Layer_2': 0.18391967709959864, 'dropout_rate_Layer_3': 0.3146382044726768, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.048272643698587206, 'l1_Layer_2': 0.0007798010097079431, 'l1_Layer_3': 1.3723953908536458e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 265, 'n_units_Layer_3': 100}. Best is trial 1443 with value: 25.929107497388866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.06 | sMAPE for Validation Set is: 17.65% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.32 | sMAPE for Test Set is: 18.18% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:11:03,268]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:08,769]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:13,660]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:16,563]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:21,563]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:25,602]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:29,127]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:38,677]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:47,427]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:49,956]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:11:57,167]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:04,083]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:11,572]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:18,466]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:23,358]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:28,368]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:31,788]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:37,190]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:37,225]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:44,029]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:46,461]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:51,311]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:55,855]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:12:56,356]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:13:02,016]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:13:14,352]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:13:31,791]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:13:36,040]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 04:13:38,987]\u001b[0m Trial 1495 finished with value: 55.61131265693536 and parameters: {'n_hidden': 3, 'learning_rate': 0.005620439936136537, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24420380330017377, 'dropout_rate_Layer_2': 0.2606292397372298, 'dropout_rate_Layer_3': 0.3653433180859147, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010992850011854807, 'l1_Layer_2': 0.018283330356248913, 'l1_Layer_3': 0.00011300465372456384, 'n_units_Layer_1': 235, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 1443 with value: 25.929107497388866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.61 | sMAPE for Validation Set is: 28.91% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 17.29 | sMAPE for Test Set is: 22.06% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 04:13:39,395]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-01-01, MAE is:12.50 & sMAPE is:12.27% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :12.50 & 12.27% & 0.70\n",
      "for 2023-01-02, MAE is:28.14 & sMAPE is:21.47% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :20.32 & 16.87% & 0.75\n",
      "for 2023-01-03, MAE is:14.79 & sMAPE is:10.19% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :18.48 & 14.64% & 0.90\n",
      "for 2023-01-04, MAE is:17.61 & sMAPE is:16.61% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :18.26 & 15.14% & 1.06\n",
      "for 2023-01-05, MAE is:25.42 & sMAPE is:18.94% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :19.69 & 15.90% & 0.97\n",
      "for 2023-01-06, MAE is:17.46 & sMAPE is:14.73% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :19.32 & 15.70% & 0.93\n",
      "for 2023-01-07, MAE is:24.75 & sMAPE is:24.33% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :20.09 & 16.94% & 0.94\n",
      "for 2023-01-08, MAE is:39.26 & sMAPE is:72.37% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :22.49 & 23.86% & 0.96\n",
      "for 2023-01-09, MAE is:43.95 & sMAPE is:39.13% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :24.87 & 25.56% & 1.11\n",
      "for 2023-01-10, MAE is:19.65 & sMAPE is:16.80% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :24.35 & 24.68% & 1.08\n",
      "for 2023-01-11, MAE is:33.78 & sMAPE is:44.90% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :25.21 & 26.52% & 1.15\n",
      "for 2023-01-12, MAE is:24.42 & sMAPE is:37.74% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :25.14 & 27.46% & 1.09\n",
      "for 2023-01-13, MAE is:27.43 & sMAPE is:43.37% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :25.32 & 28.68% & 1.06\n",
      "for 2023-01-14, MAE is:13.10 & sMAPE is:16.74% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :24.45 & 27.83% & 1.05\n",
      "for 2023-01-15, MAE is:32.12 & sMAPE is:60.88% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :24.96 & 30.03% & 1.15\n",
      "for 2023-01-16, MAE is:43.16 & sMAPE is:38.40% & rMAE is:3.39 ||| daily mean of MAE & sMAPE & rMAE till now are :26.10 & 30.55% & 1.29\n",
      "for 2023-01-17, MAE is:11.88 & sMAPE is:9.53% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :25.26 & 29.32% & 1.26\n",
      "for 2023-01-18, MAE is:8.29 & sMAPE is:6.34% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :24.32 & 28.04% & 1.20\n",
      "for 2023-01-19, MAE is:24.98 & sMAPE is:18.43% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :24.35 & 27.54% & 1.16\n",
      "for 2023-01-20, MAE is:21.96 & sMAPE is:15.41% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :24.23 & 26.93% & 1.12\n",
      "for 2023-01-21, MAE is:8.91 & sMAPE is:6.18% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :23.50 & 25.94% & 1.07\n",
      "for 2023-01-22, MAE is:19.26 & sMAPE is:13.71% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :23.31 & 25.39% & 1.03\n",
      "for 2023-01-23, MAE is:48.60 & sMAPE is:27.05% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :24.41 & 25.46% & 1.03\n",
      "for 2023-01-24, MAE is:35.73 & sMAPE is:19.92% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :24.88 & 25.23% & 1.02\n",
      "for 2023-01-25, MAE is:12.37 & sMAPE is:9.26% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :24.38 & 24.59% & 1.06\n",
      "for 2023-01-26, MAE is:4.89 & sMAPE is:3.99% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :23.63 & 23.80% & 1.03\n",
      "for 2023-01-27, MAE is:25.14 & sMAPE is:17.10% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :23.69 & 23.55% & 1.03\n",
      "for 2023-01-28, MAE is:7.46 & sMAPE is:6.60% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :23.11 & 22.94% & 1.00\n",
      "for 2023-01-29, MAE is:11.00 & sMAPE is:11.27% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :22.69 & 22.54% & 0.98\n",
      "for 2023-01-30, MAE is:8.42 & sMAPE is:11.65% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :22.21 & 22.18% & 0.95\n",
      "for 2023-01-31, MAE is:7.45 & sMAPE is:7.88% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :21.74 & 21.72% & 0.92\n",
      "for 2023-02-01, MAE is:7.87 & sMAPE is:8.31% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :21.30 & 21.30% & 0.90\n",
      "for 2023-02-02, MAE is:44.91 & sMAPE is:37.10% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :22.02 & 21.78% & 0.93\n",
      "for 2023-02-03, MAE is:20.08 & sMAPE is:17.78% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :21.96 & 21.66% & 0.92\n",
      "for 2023-02-04, MAE is:22.18 & sMAPE is:18.65% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :21.97 & 21.57% & 0.92\n",
      "for 2023-02-05, MAE is:6.71 & sMAPE is:5.86% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :21.55 & 21.14% & 0.91\n",
      "for 2023-02-06, MAE is:28.09 & sMAPE is:19.20% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :21.72 & 21.08% & 0.90\n",
      "for 2023-02-07, MAE is:5.83 & sMAPE is:4.68% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :21.30 & 20.65% & 0.88\n",
      "for 2023-02-08, MAE is:11.26 & sMAPE is:10.17% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :21.05 & 20.38% & 0.88\n",
      "for 2023-02-09, MAE is:9.84 & sMAPE is:10.47% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :20.77 & 20.13% & 0.86\n",
      "for 2023-02-10, MAE is:10.78 & sMAPE is:12.20% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :20.52 & 19.94% & 0.86\n",
      "for 2023-02-11, MAE is:10.14 & sMAPE is:12.10% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :20.28 & 19.75% & 0.84\n",
      "for 2023-02-12, MAE is:13.31 & sMAPE is:13.93% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :20.11 & 19.62% & 0.86\n",
      "for 2023-02-13, MAE is:5.16 & sMAPE is:5.04% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :19.77 & 19.29% & 0.84\n",
      "for 2023-02-14, MAE is:25.10 & sMAPE is:18.82% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :19.89 & 19.28% & 0.85\n",
      "for 2023-02-15, MAE is:10.83 & sMAPE is:9.10% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :19.69 & 19.06% & 0.86\n",
      "for 2023-02-16, MAE is:13.80 & sMAPE is:12.56% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :19.57 & 18.92% & 0.85\n",
      "for 2023-02-17, MAE is:15.17 & sMAPE is:16.84% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :19.48 & 18.87% & 0.87\n",
      "for 2023-02-18, MAE is:19.93 & sMAPE is:23.70% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :19.49 & 18.97% & 0.89\n",
      "for 2023-02-19, MAE is:6.12 & sMAPE is:6.32% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :19.22 & 18.72% & 0.89\n",
      "for 2023-02-20, MAE is:23.72 & sMAPE is:31.40% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :19.31 & 18.97% & 0.89\n",
      "for 2023-02-21, MAE is:24.80 & sMAPE is:27.72% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :19.41 & 19.14% & 0.88\n",
      "for 2023-02-22, MAE is:4.29 & sMAPE is:4.00% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :19.13 & 18.85% & 0.88\n",
      "for 2023-02-23, MAE is:5.10 & sMAPE is:4.98% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :18.87 & 18.59% & 0.87\n",
      "for 2023-02-24, MAE is:7.29 & sMAPE is:7.37% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :18.66 & 18.39% & 0.87\n",
      "for 2023-02-25, MAE is:7.69 & sMAPE is:8.89% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :18.46 & 18.22% & 0.87\n",
      "for 2023-02-26, MAE is:12.63 & sMAPE is:12.97% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :18.36 & 18.13% & 0.88\n",
      "for 2023-02-27, MAE is:12.48 & sMAPE is:11.01% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :18.26 & 18.01% & 0.87\n",
      "for 2023-02-28, MAE is:4.92 & sMAPE is:4.55% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :18.03 & 17.78% & 0.86\n",
      "for 2023-03-01, MAE is:9.80 & sMAPE is:7.93% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :17.89 & 17.61% & 0.86\n",
      "for 2023-03-02, MAE is:9.08 & sMAPE is:7.90% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :17.75 & 17.45% & 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-03, MAE is:9.59 & sMAPE is:9.22% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :17.62 & 17.32% & 0.88\n",
      "for 2023-03-04, MAE is:8.70 & sMAPE is:8.90% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :17.48 & 17.19% & 0.88\n",
      "for 2023-03-05, MAE is:11.93 & sMAPE is:9.53% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :17.39 & 17.07% & 0.88\n",
      "for 2023-03-06, MAE is:19.71 & sMAPE is:13.95% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :17.43 & 17.02% & 0.87\n",
      "for 2023-03-07, MAE is:15.15 & sMAPE is:13.84% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :17.39 & 16.97% & 0.88\n",
      "for 2023-03-08, MAE is:26.60 & sMAPE is:21.08% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :17.53 & 17.03% & 0.89\n",
      "for 2023-03-09, MAE is:8.46 & sMAPE is:6.77% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :17.40 & 16.88% & 0.88\n",
      "for 2023-03-10, MAE is:7.61 & sMAPE is:6.66% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :17.25 & 16.73% & 0.88\n",
      "for 2023-03-11, MAE is:6.87 & sMAPE is:7.09% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :17.11 & 16.60% & 0.88\n",
      "for 2023-03-12, MAE is:7.88 & sMAPE is:8.32% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :16.98 & 16.48% & 0.88\n",
      "for 2023-03-13, MAE is:10.87 & sMAPE is:12.62% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :16.89 & 16.43% & 0.87\n",
      "for 2023-03-14, MAE is:6.15 & sMAPE is:6.69% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :16.74 & 16.29% & 0.86\n",
      "for 2023-03-15, MAE is:9.94 & sMAPE is:9.18% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :16.65 & 16.20% & 0.85\n",
      "for 2023-03-16, MAE is:13.54 & sMAPE is:13.07% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :16.61 & 16.16% & 0.85\n",
      "for 2023-03-17, MAE is:5.61 & sMAPE is:6.15% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :16.47 & 16.02% & 0.84\n",
      "for 2023-03-18, MAE is:5.22 & sMAPE is:5.53% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :16.32 & 15.89% & 0.85\n",
      "for 2023-03-19, MAE is:4.35 & sMAPE is:4.63% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :16.17 & 15.74% & 0.85\n",
      "for 2023-03-20, MAE is:7.05 & sMAPE is:7.18% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :16.05 & 15.63% & 0.84\n",
      "for 2023-03-21, MAE is:9.22 & sMAPE is:9.15% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :15.96 & 15.55% & 0.84\n",
      "for 2023-03-22, MAE is:9.51 & sMAPE is:11.20% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :15.89 & 15.50% & 0.83\n",
      "for 2023-03-23, MAE is:9.81 & sMAPE is:13.82% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :15.81 & 15.48% & 0.83\n",
      "for 2023-03-24, MAE is:7.69 & sMAPE is:10.43% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :15.71 & 15.42% & 0.82\n",
      "for 2023-03-25, MAE is:11.07 & sMAPE is:24.01% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :15.66 & 15.52% & 0.82\n",
      "for 2023-03-26, MAE is:9.86 & sMAPE is:12.58% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :15.59 & 15.49% & 0.82\n",
      "for 2023-03-27, MAE is:10.84 & sMAPE is:12.17% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :15.53 & 15.45% & 0.82\n",
      "for 2023-03-28, MAE is:16.51 & sMAPE is:14.47% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :15.55 & 15.44% & 0.82\n",
      "for 2023-03-29, MAE is:11.13 & sMAPE is:9.43% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :15.50 & 15.37% & 0.81\n",
      "for 2023-03-30, MAE is:15.20 & sMAPE is:15.66% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :15.49 & 15.37% & 0.81\n",
      "for 2023-03-31, MAE is:8.03 & sMAPE is:7.95% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :15.41 & 15.29% & 0.81\n",
      "for 2023-04-01, MAE is:3.69 & sMAPE is:4.49% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :15.28 & 15.17% & 0.80\n",
      "for 2023-04-02, MAE is:4.98 & sMAPE is:5.23% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :15.17 & 15.06% & 0.80\n",
      "for 2023-04-03, MAE is:19.61 & sMAPE is:17.42% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :15.22 & 15.09% & 0.80\n",
      "for 2023-04-04, MAE is:10.22 & sMAPE is:8.13% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :15.16 & 15.01% & 0.80\n",
      "for 2023-04-05, MAE is:8.12 & sMAPE is:6.59% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :15.09 & 14.93% & 0.80\n",
      "for 2023-04-06, MAE is:6.95 & sMAPE is:6.48% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :15.00 & 14.84% & 0.79\n",
      "for 2023-04-07, MAE is:5.69 & sMAPE is:5.61% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :14.91 & 14.74% & 0.79\n",
      "for 2023-04-08, MAE is:7.61 & sMAPE is:7.48% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :14.83 & 14.67% & 0.78\n",
      "for 2023-04-09, MAE is:14.68 & sMAPE is:16.30% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :14.83 & 14.68% & 0.79\n",
      "for 2023-04-10, MAE is:48.31 & sMAPE is:75.55% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :15.17 & 15.29% & 0.79\n",
      "for 2023-04-11, MAE is:30.83 & sMAPE is:61.89% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :15.32 & 15.75% & 0.79\n",
      "for 2023-04-12, MAE is:7.69 & sMAPE is:8.06% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :15.25 & 15.68% & 0.78\n",
      "for 2023-04-13, MAE is:8.57 & sMAPE is:9.22% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :15.18 & 15.62% & 0.78\n",
      "for 2023-04-14, MAE is:3.79 & sMAPE is:3.74% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :15.07 & 15.50% & 0.78\n",
      "for 2023-04-15, MAE is:9.43 & sMAPE is:9.70% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :15.02 & 15.45% & 0.78\n",
      "for 2023-04-16, MAE is:3.69 & sMAPE is:3.76% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :14.91 & 15.34% & 0.78\n",
      "for 2023-04-17, MAE is:12.96 & sMAPE is:11.23% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :14.89 & 15.30% & 0.77\n",
      "for 2023-04-18, MAE is:10.74 & sMAPE is:10.40% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :14.86 & 15.25% & 0.77\n",
      "for 2023-04-19, MAE is:11.52 & sMAPE is:12.34% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :14.82 & 15.23% & 0.77\n",
      "for 2023-04-20, MAE is:5.05 & sMAPE is:5.33% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :14.74 & 15.14% & 0.77\n",
      "for 2023-04-21, MAE is:10.46 & sMAPE is:11.63% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :14.70 & 15.10% & 0.77\n",
      "for 2023-04-22, MAE is:14.65 & sMAPE is:18.99% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :14.70 & 15.14% & 0.78\n",
      "for 2023-04-23, MAE is:17.61 & sMAPE is:23.25% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :14.72 & 15.21% & 0.78\n",
      "for 2023-04-24, MAE is:8.27 & sMAPE is:8.48% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :14.67 & 15.15% & 0.78\n",
      "for 2023-04-25, MAE is:11.10 & sMAPE is:12.11% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :14.64 & 15.13% & 0.78\n",
      "for 2023-04-26, MAE is:7.42 & sMAPE is:7.89% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :14.57 & 15.06% & 0.78\n",
      "for 2023-04-27, MAE is:12.41 & sMAPE is:11.44% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :14.55 & 15.03% & 0.78\n",
      "for 2023-04-28, MAE is:7.01 & sMAPE is:6.76% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 14.96% & 0.78\n",
      "for 2023-04-29, MAE is:10.00 & sMAPE is:10.79% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :14.45 & 14.93% & 0.78\n",
      "for 2023-04-30, MAE is:16.00 & sMAPE is:19.48% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :14.47 & 14.97% & 0.79\n",
      "for 2023-05-01, MAE is:12.06 & sMAPE is:13.11% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :14.45 & 14.95% & 0.79\n",
      "for 2023-05-02, MAE is:9.04 & sMAPE is:8.90% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :14.40 & 14.90% & 0.78\n",
      "for 2023-05-03, MAE is:11.21 & sMAPE is:11.28% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :14.38 & 14.87% & 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-04, MAE is:12.84 & sMAPE is:14.05% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :14.36 & 14.86% & 0.79\n",
      "for 2023-05-05, MAE is:14.92 & sMAPE is:16.73% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :14.37 & 14.88% & 0.79\n",
      "for 2023-05-06, MAE is:9.97 & sMAPE is:13.05% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :14.33 & 14.86% & 0.79\n",
      "for 2023-05-07, MAE is:13.98 & sMAPE is:19.65% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :14.33 & 14.90% & 0.79\n",
      "for 2023-05-08, MAE is:6.64 & sMAPE is:7.56% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :14.27 & 14.84% & 0.79\n",
      "for 2023-05-09, MAE is:6.58 & sMAPE is:8.05% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :14.21 & 14.79% & 0.79\n",
      "for 2023-05-10, MAE is:5.45 & sMAPE is:7.01% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :14.14 & 14.73% & 0.78\n",
      "for 2023-05-11, MAE is:4.28 & sMAPE is:4.92% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :14.07 & 14.66% & 0.78\n",
      "for 2023-05-12, MAE is:5.72 & sMAPE is:7.08% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :14.00 & 14.60% & 0.78\n",
      "for 2023-05-13, MAE is:17.08 & sMAPE is:35.61% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :14.03 & 14.76% & 0.78\n",
      "for 2023-05-14, MAE is:21.72 & sMAPE is:47.53% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :14.09 & 15.00% & 0.78\n",
      "for 2023-05-15, MAE is:6.11 & sMAPE is:7.84% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :14.03 & 14.95% & 0.78\n",
      "for 2023-05-16, MAE is:21.51 & sMAPE is:38.20% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :14.08 & 15.12% & 0.78\n",
      "for 2023-05-17, MAE is:24.20 & sMAPE is:71.08% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :14.15 & 15.53% & 0.78\n",
      "for 2023-05-18, MAE is:15.02 & sMAPE is:22.60% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :14.16 & 15.58% & 0.78\n",
      "for 2023-05-19, MAE is:12.99 & sMAPE is:16.90% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :14.15 & 15.59% & 0.79\n",
      "for 2023-05-20, MAE is:34.69 & sMAPE is:74.69% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :14.30 & 16.01% & 0.80\n",
      "for 2023-05-21, MAE is:33.34 & sMAPE is:96.70% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.43 & 16.58% & 0.80\n",
      "for 2023-05-22, MAE is:11.21 & sMAPE is:16.83% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :14.41 & 16.59% & 0.81\n",
      "for 2023-05-23, MAE is:15.15 & sMAPE is:34.75% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :14.42 & 16.71% & 0.81\n",
      "for 2023-05-24, MAE is:16.45 & sMAPE is:26.57% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :14.43 & 16.78% & 0.81\n",
      "for 2023-05-25, MAE is:15.30 & sMAPE is:36.39% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :14.44 & 16.92% & 0.81\n",
      "for 2023-05-26, MAE is:16.20 & sMAPE is:45.67% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :14.45 & 17.11% & 0.80\n",
      "for 2023-05-27, MAE is:16.67 & sMAPE is:56.41% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :14.46 & 17.38% & 0.81\n",
      "for 2023-05-28, MAE is:24.05 & sMAPE is:79.93% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :14.53 & 17.80% & 0.82\n",
      "for 2023-05-29, MAE is:24.68 & sMAPE is:78.35% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :14.60 & 18.21% & 0.82\n",
      "for 2023-05-30, MAE is:5.13 & sMAPE is:8.46% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :14.53 & 18.14% & 0.81\n",
      "for 2023-05-31, MAE is:13.36 & sMAPE is:39.21% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :14.53 & 18.28% & 0.81\n",
      "for 2023-06-01, MAE is:8.65 & sMAPE is:22.70% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 18.31% & 0.82\n",
      "for 2023-06-02, MAE is:3.43 & sMAPE is:6.54% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :14.42 & 18.24% & 0.81\n",
      "for 2023-06-03, MAE is:15.08 & sMAPE is:48.40% & rMAE is:4.55 ||| daily mean of MAE & sMAPE & rMAE till now are :14.42 & 18.43% & 0.84\n",
      "for 2023-06-04, MAE is:12.64 & sMAPE is:38.13% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :14.41 & 18.56% & 0.84\n",
      "for 2023-06-05, MAE is:3.40 & sMAPE is:6.90% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :14.34 & 18.48% & 0.83\n",
      "for 2023-06-06, MAE is:2.72 & sMAPE is:5.61% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :14.26 & 18.40% & 0.83\n",
      "for 2023-06-07, MAE is:13.75 & sMAPE is:24.80% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :14.26 & 18.44% & 0.83\n",
      "for 2023-06-08, MAE is:8.36 & sMAPE is:15.66% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :14.22 & 18.43% & 0.83\n",
      "for 2023-06-09, MAE is:1.41 & sMAPE is:2.51% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :14.14 & 18.33% & 0.83\n",
      "for 2023-06-10, MAE is:15.31 & sMAPE is:42.00% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :14.15 & 18.47% & 0.84\n",
      "for 2023-06-11, MAE is:21.74 & sMAPE is:71.88% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :14.20 & 18.80% & 0.84\n",
      "for 2023-06-12, MAE is:3.94 & sMAPE is:6.31% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :14.13 & 18.73% & 0.84\n",
      "for 2023-06-13, MAE is:4.57 & sMAPE is:7.39% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :14.08 & 18.66% & 0.84\n",
      "for 2023-06-14, MAE is:6.40 & sMAPE is:9.58% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :14.03 & 18.60% & 0.84\n",
      "for 2023-06-15, MAE is:10.20 & sMAPE is:13.34% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :14.01 & 18.57% & 0.83\n",
      "for 2023-06-16, MAE is:4.39 & sMAPE is:5.48% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :13.95 & 18.49% & 0.83\n",
      "for 2023-06-17, MAE is:6.11 & sMAPE is:8.95% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :13.90 & 18.44% & 0.83\n",
      "for 2023-06-18, MAE is:9.96 & sMAPE is:16.33% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :13.88 & 18.42% & 0.82\n",
      "for 2023-06-19, MAE is:6.88 & sMAPE is:8.36% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :13.84 & 18.36% & 0.82\n",
      "for 2023-06-20, MAE is:2.12 & sMAPE is:2.72% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :13.77 & 18.27% & 0.82\n",
      "for 2023-06-21, MAE is:2.17 & sMAPE is:2.74% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :13.70 & 18.18% & 0.81\n",
      "for 2023-06-22, MAE is:2.11 & sMAPE is:2.80% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :13.63 & 18.09% & 0.81\n",
      "for 2023-06-23, MAE is:5.08 & sMAPE is:7.21% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :13.59 & 18.03% & 0.81\n",
      "for 2023-06-24, MAE is:19.43 & sMAPE is:44.56% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :13.62 & 18.18% & 0.81\n",
      "for 2023-06-25, MAE is:17.22 & sMAPE is:55.43% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :13.64 & 18.39% & 0.81\n",
      "for 2023-06-26, MAE is:10.41 & sMAPE is:16.40% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :13.62 & 18.38% & 0.80\n",
      "for 2023-06-27, MAE is:7.80 & sMAPE is:11.58% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :13.59 & 18.34% & 0.80\n",
      "for 2023-06-28, MAE is:6.82 & sMAPE is:8.61% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :13.55 & 18.29% & 0.80\n",
      "for 2023-06-29, MAE is:9.18 & sMAPE is:12.90% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :13.53 & 18.26% & 0.81\n",
      "for 2023-06-30, MAE is:4.08 & sMAPE is:5.97% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :13.47 & 18.19% & 0.81\n",
      "CPU times: total: 2d 12h 36min 1s\n",
      "Wall time: 1d 19h 4min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
