{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 'ES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:38:08,178]\u001b[0m A new study created in RDB with name: ES_2018\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:38:34,365]\u001b[0m Trial 0 finished with value: 4.900392708796141 and parameters: {'n_hidden': 3, 'learning_rate': 0.005222175578104897, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2657189860269357, 'dropout_rate_Layer_2': 0.22670542559371004, 'dropout_rate_Layer_3': 0.17574874207680558, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023600578899056757, 'l1_Layer_2': 2.2703010692053853e-05, 'l1_Layer_3': 0.015583660667972905, 'n_units_Layer_1': 215, 'n_units_Layer_2': 210, 'n_units_Layer_3': 190}. Best is trial 0 with value: 4.900392708796141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 9.82% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 10.61% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:38:37,339]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:38:47,450]\u001b[0m Trial 3 finished with value: 7.602958865849445 and parameters: {'n_hidden': 4, 'learning_rate': 0.02141415029148754, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10397412864595657, 'dropout_rate_Layer_2': 0.22127835954209238, 'dropout_rate_Layer_3': 0.19243453033684205, 'dropout_rate_Layer_4': 0.22102894312673685, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.002722462474395313, 'l1_Layer_2': 1.8510293513842816e-05, 'l1_Layer_3': 1.2657402696235237e-05, 'l1_Layer_4': 9.938073088105933e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270, 'n_units_Layer_4': 300}. Best is trial 0 with value: 4.900392708796141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.60 | sMAPE for Validation Set is: 15.01% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 7.78 | sMAPE for Test Set is: 15.19% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:38:50,095]\u001b[0m Trial 2 finished with value: 4.755069388259945 and parameters: {'n_hidden': 3, 'learning_rate': 0.014886122003228438, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18753873687785566, 'dropout_rate_Layer_2': 0.2848198324419443, 'dropout_rate_Layer_3': 0.1889185411585279, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008640246326709539, 'l1_Layer_2': 0.059151596889441174, 'l1_Layer_3': 0.00039185236515697013, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 95}. Best is trial 2 with value: 4.755069388259945.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 9.78% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 10.69% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:38:52,930]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:39:01,205]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:39:04,955]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:39:10,456]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:39:15,519]\u001b[0m Trial 7 finished with value: 6.68259633342203 and parameters: {'n_hidden': 4, 'learning_rate': 0.05138256511445467, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07630197572474895, 'dropout_rate_Layer_2': 0.1905066341934533, 'dropout_rate_Layer_3': 0.1669812731389592, 'dropout_rate_Layer_4': 0.37910121125094554, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002135919477345258, 'l1_Layer_2': 0.003657073332691324, 'l1_Layer_3': 0.00024488639603958875, 'l1_Layer_4': 7.431817172919564e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250, 'n_units_Layer_4': 80}. Best is trial 2 with value: 4.755069388259945.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.68 | sMAPE for Validation Set is: 13.13% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 8.92 | sMAPE for Test Set is: 17.14% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:39:19,810]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:39:22,881]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:39:33,203]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:39:40,089]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:40:06,243]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:40:11,127]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:40:11,911]\u001b[0m Trial 14 finished with value: 4.324615735701344 and parameters: {'n_hidden': 3, 'learning_rate': 0.020805633766141963, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030996036661902072, 'dropout_rate_Layer_2': 0.3723160535884005, 'dropout_rate_Layer_3': 0.14092279933125865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.51370817631296e-05, 'l1_Layer_2': 0.004150759251650277, 'l1_Layer_3': 0.00021573179368190192, 'n_units_Layer_1': 170, 'n_units_Layer_2': 130, 'n_units_Layer_3': 190}. Best is trial 14 with value: 4.324615735701344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 8.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 9.53% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:40:19,632]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:40:22,126]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:40:28,847]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:40:34,022]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:40:37,578]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:40:40,097]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:40:50,702]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:40:51,813]\u001b[0m Trial 5 finished with value: 4.632423384855579 and parameters: {'n_hidden': 3, 'learning_rate': 0.002275310987919708, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24112561817333159, 'dropout_rate_Layer_2': 0.11244777200078437, 'dropout_rate_Layer_3': 0.12313530870207799, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.664482302618268e-05, 'l1_Layer_2': 1.0422047119935769e-05, 'l1_Layer_3': 0.0001652176384021352, 'n_units_Layer_1': 130, 'n_units_Layer_2': 130, 'n_units_Layer_3': 115}. Best is trial 14 with value: 4.324615735701344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 9.36% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 10.18% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:40:58,440]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:01,432]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:04,061]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:11,555]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:16,384]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:16,427]\u001b[0m Trial 1 finished with value: 5.127269013926969 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012364567151829928, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3948239679758713, 'dropout_rate_Layer_2': 0.15014566764580667, 'dropout_rate_Layer_3': 0.036346844261301706, 'dropout_rate_Layer_4': 0.38162436316458415, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.5848526309916002e-05, 'l1_Layer_2': 6.623665567465863e-05, 'l1_Layer_3': 5.220115943909656e-05, 'l1_Layer_4': 0.0008182455808367555, 'n_units_Layer_1': 265, 'n_units_Layer_2': 95, 'n_units_Layer_3': 170, 'n_units_Layer_4': 110}. Best is trial 14 with value: 4.324615735701344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 10.31% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 5.35 | sMAPE for Test Set is: 10.77% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:41:19,211]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:21,876]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:23,875]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:24,408]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:26,212]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:28,370]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:32,790]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:33,061]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:33,094]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:39,728]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:44,591]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:47,439]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:48,564]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:49,248]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:54,783]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:58,337]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:03,056]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:07,311]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:11,065]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:13,775]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:16,137]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:18,695]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:18,960]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:26,039]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:27,748]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:28,565]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:28,997]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:33,865]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:36,222]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:42,521]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:42,685]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:43,647]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:52,020]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:54,576]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:43:00,303]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:43:08,167]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:43:18,263]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:43:31,210]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:43:36,746]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:43:41,434]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:43:41,904]\u001b[0m Trial 62 finished with value: 5.122774922115177 and parameters: {'n_hidden': 3, 'learning_rate': 0.015935556099069777, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01867845269413182, 'dropout_rate_Layer_2': 0.31535347332428654, 'dropout_rate_Layer_3': 0.26336122696701214, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005543092377721321, 'l1_Layer_2': 0.004707212039677046, 'l1_Layer_3': 0.008144072876451662, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260}. Best is trial 14 with value: 4.324615735701344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 10.28% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 5.50 | sMAPE for Test Set is: 10.97% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:43:52,842]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:43:56,852]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:04,038]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:06,510]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:09,853]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:16,229]\u001b[0m Trial 63 finished with value: 4.6079398463158645 and parameters: {'n_hidden': 4, 'learning_rate': 0.000565918773140905, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23057327736559674, 'dropout_rate_Layer_2': 0.14187387671336507, 'dropout_rate_Layer_3': 0.13946068883743243, 'dropout_rate_Layer_4': 0.2030464552406271, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01813686425862337, 'l1_Layer_2': 0.000655052566697624, 'l1_Layer_3': 0.0432465899690837, 'l1_Layer_4': 1.7653755248528954e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 180, 'n_units_Layer_4': 70}. Best is trial 14 with value: 4.324615735701344.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 9.78% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 9.66% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:44:19,358]\u001b[0m Trial 68 finished with value: 3.945927707114477 and parameters: {'n_hidden': 3, 'learning_rate': 0.004335968928018936, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3429073442051691, 'dropout_rate_Layer_2': 0.015684433602137383, 'dropout_rate_Layer_3': 0.2016203602616579, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002545880842266834, 'l1_Layer_2': 0.0002625828285897512, 'l1_Layer_3': 1.5707609451327536e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 130, 'n_units_Layer_3': 165}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.95 | sMAPE for Validation Set is: 8.29% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 8.45% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:44:24,477]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:25,253]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:30,523]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:31,061]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:35,339]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:39,750]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:41,237]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:44,993]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:46,467]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:48,578]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:51,616]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:52,629]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:53,556]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:58,389]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:00,120]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:01,805]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:05,518]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:07,100]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:12,318]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:19,128]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:33,598]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:38,958]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:45,122]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:45,843]\u001b[0m Trial 98 finished with value: 4.587582119661115 and parameters: {'n_hidden': 4, 'learning_rate': 0.00179138065415469, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.044509709262869714, 'dropout_rate_Layer_2': 0.25878078972489565, 'dropout_rate_Layer_3': 0.2556707292183747, 'dropout_rate_Layer_4': 0.2308086268310617, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00806650761779066, 'l1_Layer_2': 2.72362842544434e-05, 'l1_Layer_3': 0.04098223519299301, 'l1_Layer_4': 3.535009551381002e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 235, 'n_units_Layer_3': 150, 'n_units_Layer_4': 285}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 9.69% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 9.61% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:45:49,069]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:50,699]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:55,169]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:03,177]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:09,322]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:11,014]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:14,502]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:18,521]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:23,823]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:25,582]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:29,059]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:31,911]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:33,828]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:36,929]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:44,544]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:44,955]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:52,765]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:53,095]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:46:58,533]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:02,857]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:05,166]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:09,110]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:11,233]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:11,463]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:16,703]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:22,976]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:27,044]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:29,847]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:33,136]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:47,532]\u001b[0m Trial 92 finished with value: 4.164982065470746 and parameters: {'n_hidden': 3, 'learning_rate': 0.015540633808242572, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3856100843284208, 'dropout_rate_Layer_2': 0.003952510560524286, 'dropout_rate_Layer_3': 0.0008515892344576892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014437890258572024, 'l1_Layer_2': 0.006834112761613275, 'l1_Layer_3': 0.001260017926568524, 'n_units_Layer_1': 200, 'n_units_Layer_2': 55, 'n_units_Layer_3': 210}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 8.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 9.15% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:47:50,566]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:53,132]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:48:00,608]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:48:18,935]\u001b[0m Trial 134 finished with value: 4.915183745100957 and parameters: {'n_hidden': 3, 'learning_rate': 0.00665166282085746, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23303847719352536, 'dropout_rate_Layer_2': 0.06753147872778009, 'dropout_rate_Layer_3': 0.2881350124448449, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.467506358707744e-05, 'l1_Layer_2': 0.0009434785843499171, 'l1_Layer_3': 0.002433615980872976, 'n_units_Layer_1': 265, 'n_units_Layer_2': 140, 'n_units_Layer_3': 95}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 10.09% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 10.57% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:48:23,680]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:48:27,578]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:48:33,965]\u001b[0m Trial 140 finished with value: 6.539133112133103 and parameters: {'n_hidden': 3, 'learning_rate': 0.05092586792859061, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19062550930175964, 'dropout_rate_Layer_2': 0.33548439874497493, 'dropout_rate_Layer_3': 0.23753587885526545, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.0671108380621104e-05, 'l1_Layer_2': 1.0967497388710775e-05, 'l1_Layer_3': 0.00020707300339192831, 'n_units_Layer_1': 185, 'n_units_Layer_2': 155, 'n_units_Layer_3': 140}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 7.39 | sMAPE for Test Set is: 14.45% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:48:36,868]\u001b[0m Trial 138 finished with value: 4.609230704964651 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017883759836404378, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007553401697765439, 'dropout_rate_Layer_2': 0.18019532279262956, 'dropout_rate_Layer_3': 0.2016491075557827, 'dropout_rate_Layer_4': 0.37748070073794193, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07634091288212153, 'l1_Layer_2': 0.00024203024938415833, 'l1_Layer_3': 0.025524883399056973, 'l1_Layer_4': 9.835516997834107e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 185, 'n_units_Layer_4': 245}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 9.70% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 9.75% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:48:38,851]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:48:41,238]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:48:44,039]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:48:46,570]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:48:49,212]\u001b[0m Trial 136 finished with value: 4.650181769234731 and parameters: {'n_hidden': 4, 'learning_rate': 0.003994682990164086, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08900325869923854, 'dropout_rate_Layer_2': 0.217276620927216, 'dropout_rate_Layer_3': 0.2339897540729037, 'dropout_rate_Layer_4': 0.3034709098741795, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00025864737226774206, 'l1_Layer_2': 0.008051993994932553, 'l1_Layer_3': 4.1143061139787205e-05, 'l1_Layer_4': 9.078327729203268e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 150, 'n_units_Layer_3': 210, 'n_units_Layer_4': 300}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 9.60% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 9.75% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:48:49,380]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:48:49,963]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:48:56,431]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:48:58,642]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:00,411]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:02,460]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:04,606]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:06,040]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:08,911]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:11,578]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:12,584]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:13,573]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:18,504]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:18,930]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:19,724]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:24,211]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:26,551]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:27,000]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:29,352]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:33,429]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:34,155]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:34,429]\u001b[0m Trial 143 finished with value: 4.165654286929793 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035144518466743682, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012463506976944608, 'dropout_rate_Layer_2': 0.17765587357589108, 'dropout_rate_Layer_3': 0.2529457329000085, 'dropout_rate_Layer_4': 0.37658409679550964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.0493029027621464e-05, 'l1_Layer_2': 0.0002012241480400154, 'l1_Layer_3': 0.027322997219525802, 'l1_Layer_4': 0.0002760959454796031, 'n_units_Layer_1': 85, 'n_units_Layer_2': 295, 'n_units_Layer_3': 180, 'n_units_Layer_4': 175}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 8.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 8.92% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:49:34,925]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:41,368]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:43,195]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:43,264]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:44,638]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:50,556]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:50,687]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:51,721]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:52,266]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:58,773]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:58,941]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:01,645]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:03,175]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:07,264]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:11,269]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:14,665]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:18,248]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:18,561]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:26,995]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:38,447]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:42,548]\u001b[0m Trial 182 finished with value: 19.816605121268015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0864522678373729, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3931025471680492, 'dropout_rate_Layer_2': 0.003988697276543499, 'dropout_rate_Layer_3': 0.03816039681781205, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029878631906224873, 'l1_Layer_2': 0.0004625151978586058, 'l1_Layer_3': 0.0022571869627266445, 'n_units_Layer_1': 235, 'n_units_Layer_2': 60, 'n_units_Layer_3': 250}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.82 | sMAPE for Validation Set is: 44.56% | rMAE for Validation Set is: 2.91\n",
      "MAE for Test Set is: 25.80 | sMAPE for Test Set is: 55.62% | rMAE for Test Set is: 3.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:50:45,269]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:45,440]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:46,239]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:52,012]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:54,079]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:51:07,846]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:51:11,018]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:51:15,769]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:51:21,049]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:51:29,737]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 9.84% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 10.66% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:51:31,115]\u001b[0m Trial 189 finished with value: 4.8919765575327245 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026171977233849972, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12282364122711376, 'dropout_rate_Layer_2': 0.2673739582500114, 'dropout_rate_Layer_3': 0.26331995107921236, 'dropout_rate_Layer_4': 0.3767899340138432, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00217153734689087, 'l1_Layer_2': 2.8906975051313948e-05, 'l1_Layer_3': 0.00022207843027526055, 'l1_Layer_4': 0.00023126958006889603, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 235, 'n_units_Layer_4': 150}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:51:43,718]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:51:44,276]\u001b[0m Trial 195 finished with value: 4.164029350920097 and parameters: {'n_hidden': 3, 'learning_rate': 0.007316989433094657, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29641337289772174, 'dropout_rate_Layer_2': 0.06583535724515566, 'dropout_rate_Layer_3': 0.27611809810364474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.977399435847815e-05, 'l1_Layer_2': 0.02749030448244081, 'l1_Layer_3': 5.773386857401844e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 90, 'n_units_Layer_3': 145}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 8.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.47 | sMAPE for Test Set is: 9.19% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:51:54,432]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:51:58,770]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:05,117]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:08,931]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:09,200]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:16,559]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:17,349]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:20,683]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:29,812]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:35,785]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:38,988]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:43,108]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:47,083]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:55,198]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:52:59,692]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 9.74% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 9.74% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:53:02,576]\u001b[0m Trial 211 finished with value: 4.674589472367555 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018462169428649943, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13651269447205755, 'dropout_rate_Layer_2': 0.17717250612991178, 'dropout_rate_Layer_3': 0.22287232111514335, 'dropout_rate_Layer_4': 0.20615475228831598, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07989805895680674, 'l1_Layer_2': 0.00013379409402103349, 'l1_Layer_3': 0.08006166869540177, 'l1_Layer_4': 1.4947110457917658e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 240, 'n_units_Layer_3': 300, 'n_units_Layer_4': 255}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:05,874]\u001b[0m Trial 203 finished with value: 4.420995558360436 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005104264899708224, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034313765672791006, 'dropout_rate_Layer_2': 0.3576173454444217, 'dropout_rate_Layer_3': 0.27388842493372695, 'dropout_rate_Layer_4': 0.3264700344776105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011398652515198792, 'l1_Layer_2': 2.4661805236283786e-05, 'l1_Layer_3': 7.751711063067363e-05, 'l1_Layer_4': 0.0002996662629698932, 'n_units_Layer_1': 170, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285, 'n_units_Layer_4': 195}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 8.89% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.73 | sMAPE for Test Set is: 9.44% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:53:06,075]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:07,456]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:13,923]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:14,375]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:14,902]\u001b[0m Trial 205 finished with value: 4.6233020920904435 and parameters: {'n_hidden': 4, 'learning_rate': 0.001067381093699265, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18115372322005746, 'dropout_rate_Layer_2': 0.18586601943760842, 'dropout_rate_Layer_3': 0.20831303314968844, 'dropout_rate_Layer_4': 0.221801665464643, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.05153505481183551, 'l1_Layer_2': 0.00012218693270247535, 'l1_Layer_3': 0.02990400182089695, 'l1_Layer_4': 0.0006285527019591266, 'n_units_Layer_1': 110, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275, 'n_units_Layer_4': 235}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 9.66% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 9.69% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:53:25,250]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:30,383]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:32,086]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:35,131]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:36,662]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:40,802]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:40,970]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:42,110]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:46,577]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:47,387]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:52,888]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:56,760]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:53:59,299]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:02,331]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:02,913]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:06,421]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:07,075]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:11,309]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:17,318]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:19,667]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:21,209]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:26,851]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:32,666]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:36,656]\u001b[0m Trial 222 finished with value: 4.310856049962106 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005096692908802095, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.060660358180097254, 'dropout_rate_Layer_2': 0.3179920351180654, 'dropout_rate_Layer_3': 0.25021617661534074, 'dropout_rate_Layer_4': 0.3707904932496813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010155518142124212, 'l1_Layer_2': 1.4718147505627443e-05, 'l1_Layer_3': 4.29315419502853e-05, 'l1_Layer_4': 0.00013492700577144316, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 295, 'n_units_Layer_4': 155}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 8.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.60 | sMAPE for Test Set is: 9.19% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:54:37,225]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:56,585]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:02,359]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:07,933]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:18,300]\u001b[0m Trial 249 finished with value: 4.4993817564850636 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009870494805657474, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16739583813810938, 'dropout_rate_Layer_2': 0.06308602631014476, 'dropout_rate_Layer_3': 0.18688709138081858, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005821085437836145, 'l1_Layer_2': 0.0220927019364193, 'l1_Layer_3': 4.8937747404743316e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 105, 'n_units_Layer_3': 135}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 9.24% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 9.74% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:55:20,694]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:27,028]\u001b[0m Trial 238 finished with value: 4.726998352285205 and parameters: {'n_hidden': 3, 'learning_rate': 0.006406168946067739, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21045455716966477, 'dropout_rate_Layer_2': 0.10549860798803463, 'dropout_rate_Layer_3': 0.2427954465960941, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009501442602071928, 'l1_Layer_2': 5.0830102111463476e-05, 'l1_Layer_3': 0.0013760332948918477, 'n_units_Layer_1': 285, 'n_units_Layer_2': 95, 'n_units_Layer_3': 70}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 9.54% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 10.12% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:55:38,844]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:41,741]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:43,931]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:48,011]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:49,618]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:55,033]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:56,596]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:59,911]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:00,131]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:04,740]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:05,394]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:10,080]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:12,620]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:16,696]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:21,342]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:26,493]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:31,632]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:33,530]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:50,238]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:50,865]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:54,371]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:56,409]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:56:59,788]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:02,805]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:06,468]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:09,527]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:12,738]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:22,738]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:24,897]\u001b[0m Trial 270 finished with value: 4.124060908607043 and parameters: {'n_hidden': 3, 'learning_rate': 0.012676029483425076, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33750967847128116, 'dropout_rate_Layer_2': 0.04537191936445568, 'dropout_rate_Layer_3': 0.07417058045143869, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.69273373471706e-05, 'l1_Layer_2': 0.02070775759951372, 'l1_Layer_3': 3.117273584084075e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 68 with value: 3.945927707114477.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 8.60% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 8.92% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:57:27,399]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:30,327]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:34,920]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:37,786]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:41,920]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:44,717]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:44,886]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:50,883]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:54,433]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:59,819]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:58:00,551]\u001b[0m Trial 272 finished with value: 3.8964186563038967 and parameters: {'n_hidden': 4, 'learning_rate': 0.001244483536029667, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04520473496912094, 'dropout_rate_Layer_2': 0.2004715099697078, 'dropout_rate_Layer_3': 0.22592212073111428, 'dropout_rate_Layer_4': 0.2614267562412926, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0023497391289005617, 'l1_Layer_2': 0.00013329312115548168, 'l1_Layer_3': 0.002327966254258673, 'l1_Layer_4': 0.00029790101233304414, 'n_units_Layer_1': 140, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260, 'n_units_Layer_4': 285}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 8.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.98 | sMAPE for Test Set is: 8.31% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:58:02,950]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:58:14,535]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:58:17,961]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:58:32,900]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:58:36,630]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:58:39,111]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:58:44,880]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:58:50,623]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:58:58,932]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:59:03,342]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:59:05,891]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:59:31,553]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:59:37,332]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:59:59,727]\u001b[0m Trial 289 finished with value: 4.148903724991854 and parameters: {'n_hidden': 3, 'learning_rate': 0.010693462347686861, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34252977097029247, 'dropout_rate_Layer_2': 0.0421027693760168, 'dropout_rate_Layer_3': 0.24863235878859513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.772005397300271e-05, 'l1_Layer_2': 0.0816582455745775, 'l1_Layer_3': 3.0504131714293638e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 185}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 8.60% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.77 | sMAPE for Test Set is: 9.74% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:00:02,877]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:06,312]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:09,122]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:09,666]\u001b[0m Trial 296 finished with value: 4.721051239660999 and parameters: {'n_hidden': 4, 'learning_rate': 0.000872235400766685, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00973833741313599, 'dropout_rate_Layer_2': 0.2803371860063492, 'dropout_rate_Layer_3': 0.24087375343175982, 'dropout_rate_Layer_4': 0.19916816238131668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000560420540449658, 'l1_Layer_2': 1.3221827430351631e-05, 'l1_Layer_3': 4.226105238147713e-05, 'l1_Layer_4': 4.194990767559487e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 175, 'n_units_Layer_3': 170, 'n_units_Layer_4': 155}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 9.54% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 9.84% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:00:15,850]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:21,248]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:24,290]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:26,303]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:30,774]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:32,618]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:32,773]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:38,694]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:38,960]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:45,365]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:45,615]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:51,552]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:54,966]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:58,040]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:01:01,681]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:01:07,656]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:01:11,991]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:01:16,577]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:01:30,059]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:01:33,583]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:02:09,908]\u001b[0m Trial 332 finished with value: 4.619041473470364 and parameters: {'n_hidden': 3, 'learning_rate': 0.02284326187282213, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32151393719801485, 'dropout_rate_Layer_2': 0.173495967152158, 'dropout_rate_Layer_3': 0.07369480204896807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3468770825448415e-05, 'l1_Layer_2': 0.045766407706585945, 'l1_Layer_3': 1.1097589161707865e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 115, 'n_units_Layer_3': 280}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 9.80% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 10.01% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:02:12,925]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:02:20,127]\u001b[0m Trial 313 finished with value: 3.955328783402896 and parameters: {'n_hidden': 3, 'learning_rate': 0.021280257751020625, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3107641130340645, 'dropout_rate_Layer_2': 0.03781648629046566, 'dropout_rate_Layer_3': 0.07475128216808924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1848223973665277e-05, 'l1_Layer_2': 0.002213816610918681, 'l1_Layer_3': 1.0203109071625642e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 110, 'n_units_Layer_3': 280}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 8.35% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 8.93% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:02:23,133]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:02:26,269]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:02:31,380]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:02:34,285]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:02:40,019]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:02:43,121]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:02:46,374]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:02:50,225]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:02:59,490]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:02,494]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:05,385]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:07,929]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:11,579]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:17,980]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:20,744]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:21,926]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:31,484]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:36,752]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:39,929]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:43,170]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:46,336]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:53,301]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:04:00,561]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:04:23,136]\u001b[0m Trial 354 finished with value: 4.046765666776086 and parameters: {'n_hidden': 3, 'learning_rate': 0.013263872840644243, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3617405871585907, 'dropout_rate_Layer_2': 0.09098925314769626, 'dropout_rate_Layer_3': 0.1067506313322665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018608770076917179, 'l1_Layer_2': 0.00016655250988270346, 'l1_Layer_3': 0.00011641741101515288, 'n_units_Layer_1': 145, 'n_units_Layer_2': 80, 'n_units_Layer_3': 165}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 8.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 8.99% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:04:27,869]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:04:47,581]\u001b[0m Trial 357 finished with value: 4.071928909521973 and parameters: {'n_hidden': 3, 'learning_rate': 0.056574319069132524, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3597609044637227, 'dropout_rate_Layer_2': 0.08765979662894403, 'dropout_rate_Layer_3': 0.22937273067130076, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6772789592456882e-05, 'l1_Layer_2': 0.00018851787173697096, 'l1_Layer_3': 0.00011505484086398707, 'n_units_Layer_1': 145, 'n_units_Layer_2': 75, 'n_units_Layer_3': 160}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 8.52% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 9.78% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:04:52,481]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:04:56,015]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:05:04,961]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:05:08,303]\u001b[0m Trial 360 finished with value: 4.426185976784102 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006074436139027066, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19186831987203753, 'dropout_rate_Layer_2': 0.14927373130560054, 'dropout_rate_Layer_3': 0.265142118809917, 'dropout_rate_Layer_4': 0.24423195891581123, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009119113803500016, 'l1_Layer_2': 0.0035015420216279896, 'l1_Layer_3': 0.00013634890273439565, 'l1_Layer_4': 0.00013635632267938922, 'n_units_Layer_1': 200, 'n_units_Layer_2': 170, 'n_units_Layer_3': 165, 'n_units_Layer_4': 110}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 8.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 9.55% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:05:19,760]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:05:28,499]\u001b[0m Trial 361 finished with value: 4.002662881916906 and parameters: {'n_hidden': 3, 'learning_rate': 0.012028897934618822, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3669558924283157, 'dropout_rate_Layer_2': 0.10034552072633085, 'dropout_rate_Layer_3': 0.10089676090121895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004123953414793625, 'l1_Layer_2': 0.0010271246545199395, 'l1_Layer_3': 0.00012662580682104463, 'n_units_Layer_1': 145, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 8.38% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 9.12% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:05:29,321]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:05:39,836]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:05:44,406]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:05:44,507]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:05:49,344]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:05:51,594]\u001b[0m Trial 363 finished with value: 4.474858853652713 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006259727602523564, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21770147786272326, 'dropout_rate_Layer_2': 0.1416940770024963, 'dropout_rate_Layer_3': 0.2591759828650265, 'dropout_rate_Layer_4': 0.030055039546136142, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0022525783016993112, 'l1_Layer_2': 5.188540291305821e-05, 'l1_Layer_3': 0.00013470100495979108, 'l1_Layer_4': 1.5660842351480823e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 140, 'n_units_Layer_3': 290, 'n_units_Layer_4': 155}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 9.06% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 9.65% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:05:55,620]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:05:56,046]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:05:59,550]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:02,533]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:08,066]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:12,993]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:15,013]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:19,581]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:22,393]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:25,955]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:27,897]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:31,865]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:31,894]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:38,361]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:38,470]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:46,931]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:06:49,623]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:07:01,468]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:07:03,946]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:07:06,114]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:07:08,680]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:07:12,568]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:07:17,669]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:07:34,981]\u001b[0m Trial 387 finished with value: 3.9706387829247802 and parameters: {'n_hidden': 3, 'learning_rate': 0.008120580548949053, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26377773629922563, 'dropout_rate_Layer_2': 0.11969441415497506, 'dropout_rate_Layer_3': 0.14941289836378324, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004285719737548129, 'l1_Layer_2': 0.0009821438731849573, 'l1_Layer_3': 0.0003614435136331276, 'n_units_Layer_1': 295, 'n_units_Layer_2': 145, 'n_units_Layer_3': 120}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 8.38% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 9.27% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:07:40,130]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:07:51,734]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:07:54,983]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:07:58,691]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:03,950]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:06,372]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:11,815]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 9.49% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 10.07% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:08:13,625]\u001b[0m Trial 396 finished with value: 4.713595617532287 and parameters: {'n_hidden': 4, 'learning_rate': 0.000944539139479728, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18318514272084707, 'dropout_rate_Layer_2': 0.13934727309450484, 'dropout_rate_Layer_3': 0.29984679912429046, 'dropout_rate_Layer_4': 0.02598324025451888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0310558496142313e-05, 'l1_Layer_2': 0.0020067283498565007, 'l1_Layer_3': 9.185438003445901e-05, 'l1_Layer_4': 0.0007700350765403304, 'n_units_Layer_1': 215, 'n_units_Layer_2': 145, 'n_units_Layer_3': 290, 'n_units_Layer_4': 150}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:14,763]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:18,068]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:20,609]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:24,532]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:26,388]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:28,635]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:30,896]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:40,503]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:44,826]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:08:54,558]\u001b[0m Trial 408 finished with value: 4.122034598071704 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012535095005902844, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1932184974016717, 'dropout_rate_Layer_2': 0.2594772467462322, 'dropout_rate_Layer_3': 0.1926340890301424, 'dropout_rate_Layer_4': 0.237302469177898, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0024398614408205252, 'l1_Layer_2': 0.000197032157670913, 'l1_Layer_3': 1.0165405641780394e-05, 'l1_Layer_4': 0.0003993887974183304, 'n_units_Layer_1': 275, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185, 'n_units_Layer_4': 195}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 8.79% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.13 | sMAPE for Test Set is: 8.60% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:08:58,196]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:09:06,817]\u001b[0m Trial 409 finished with value: 3.967184778724968 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014051062700777836, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2563885025361063, 'dropout_rate_Layer_2': 0.12481671581621585, 'dropout_rate_Layer_3': 0.1479812620160565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045751286108065565, 'l1_Layer_2': 0.0009253133804107508, 'l1_Layer_3': 0.000335684466759212, 'n_units_Layer_1': 300, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 8.32% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 9.47% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:09:28,395]\u001b[0m Trial 417 finished with value: 4.795276812348287 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013639538891807997, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2681739125688501, 'dropout_rate_Layer_2': 0.08171249467368336, 'dropout_rate_Layer_3': 0.26596650288230256, 'dropout_rate_Layer_4': 0.021925874979926666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.860537470122549e-05, 'l1_Layer_2': 0.0007656045090506905, 'l1_Layer_3': 2.647268784064289e-05, 'l1_Layer_4': 0.000363808314568695, 'n_units_Layer_1': 215, 'n_units_Layer_2': 135, 'n_units_Layer_3': 295, 'n_units_Layer_4': 175}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 9.65% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 10.30% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:09:36,335]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:09:36,709]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:09:44,127]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:09:49,679]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:09:54,155]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:09:58,934]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:02,927]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:06,821]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:11,622]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:17,514]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:22,371]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:27,674]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:29,855]\u001b[0m Trial 421 finished with value: 4.80696076986288 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013606933125389973, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3177523093163548, 'dropout_rate_Layer_2': 0.07809536694133976, 'dropout_rate_Layer_3': 0.28344829843104685, 'dropout_rate_Layer_4': 0.027151000599739884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.4241738648953506e-05, 'l1_Layer_2': 0.0008116563800291534, 'l1_Layer_3': 3.0260906997373875e-05, 'l1_Layer_4': 0.0006907639377593182, 'n_units_Layer_1': 215, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280, 'n_units_Layer_4': 175}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 9.67% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 10.49% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:10:39,685]\u001b[0m Trial 420 finished with value: 4.142857063709024 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014719211653019038, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.247787303554922, 'dropout_rate_Layer_2': 0.2240100308840508, 'dropout_rate_Layer_3': 0.1459937521377019, 'dropout_rate_Layer_4': 0.3801168275815544, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011883905621333194, 'l1_Layer_2': 0.0007242551374470853, 'l1_Layer_3': 0.0002515251854709805, 'l1_Layer_4': 0.001644387918534097, 'n_units_Layer_1': 300, 'n_units_Layer_2': 195, 'n_units_Layer_3': 70, 'n_units_Layer_4': 50}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 8.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 10.66% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:10:42,257]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:48,149]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:51,509]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:55,403]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:58,895]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:58,970]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:07,264]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:07,785]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:14,482]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:16,797]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:20,471]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:20,949]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:21,581]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:27,620]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:29,901]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:34,882]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:41,687]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:46,347]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:50,737]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:52,643]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:56,114]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:57,971]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:12:01,292]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:12:16,437]\u001b[0m Trial 446 finished with value: 4.709795697206004 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005743983594857418, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24544379794593302, 'dropout_rate_Layer_2': 0.12191839240257894, 'dropout_rate_Layer_3': 0.32223085567432985, 'dropout_rate_Layer_4': 0.3340938583631811, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.213136677039809e-05, 'l1_Layer_2': 0.0004071247053037392, 'l1_Layer_3': 3.9039563780602786e-05, 'l1_Layer_4': 0.00023161731743950054, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 300, 'n_units_Layer_4': 225}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 9.51% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 9.77% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:12:22,430]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:12:30,217]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:12:33,561]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:12:35,646]\u001b[0m Trial 454 finished with value: 4.603564004498488 and parameters: {'n_hidden': 4, 'learning_rate': 0.001306632622757135, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0074983722776554886, 'dropout_rate_Layer_2': 0.16232114410981857, 'dropout_rate_Layer_3': 0.19635094239566198, 'dropout_rate_Layer_4': 0.38170557332950655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0798713013135923, 'l1_Layer_2': 3.653796162736272e-05, 'l1_Layer_3': 0.07024705239130413, 'l1_Layer_4': 0.00031826058935305546, 'n_units_Layer_1': 105, 'n_units_Layer_2': 300, 'n_units_Layer_3': 285, 'n_units_Layer_4': 295}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 9.71% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 9.82% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:12:39,852]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:12:39,976]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:12:45,288]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:12:48,325]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:12:57,236]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:13:01,306]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:13:26,068]\u001b[0m Trial 463 finished with value: 4.728487350110458 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009362924397430944, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2514531039949103, 'dropout_rate_Layer_2': 0.12018598726432811, 'dropout_rate_Layer_3': 0.27125458508140377, 'dropout_rate_Layer_4': 0.31044612924742115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.733505321001784e-05, 'l1_Layer_2': 0.0011121639834238022, 'l1_Layer_3': 3.7395145483667936e-05, 'l1_Layer_4': 0.00018563957545227795, 'n_units_Layer_1': 200, 'n_units_Layer_2': 180, 'n_units_Layer_3': 300, 'n_units_Layer_4': 225}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 9.58% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 10.22% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:13:29,990]\u001b[0m Trial 460 finished with value: 4.774845660119084 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009446911620547724, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26984950422084114, 'dropout_rate_Layer_2': 0.1362080617718566, 'dropout_rate_Layer_3': 0.3392015419886559, 'dropout_rate_Layer_4': 0.0002135761191056143, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.542612148520424e-05, 'l1_Layer_2': 0.0010169955675495637, 'l1_Layer_3': 3.523484453140277e-05, 'l1_Layer_4': 0.000172525900523177, 'n_units_Layer_1': 200, 'n_units_Layer_2': 175, 'n_units_Layer_3': 295, 'n_units_Layer_4': 220}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 9.57% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 10.02% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:13:32,134]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:13:34,155]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:13:38,108]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:13:41,689]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:13:43,075]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:13:43,508]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:13:50,137]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:13:50,650]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:13:57,365]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:13:57,567]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:05,898]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:09,234]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:11,046]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:13,946]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:14,270]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:19,460]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:19,694]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:25,061]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:27,174]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:29,991]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:30,916]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:33,391]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:35,260]\u001b[0m Trial 465 finished with value: 4.870929341538215 and parameters: {'n_hidden': 3, 'learning_rate': 0.004673659514783962, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1669121581459877, 'dropout_rate_Layer_2': 0.06123530408712536, 'dropout_rate_Layer_3': 0.2591257819078788, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027692654541477344, 'l1_Layer_2': 0.0004213520001067779, 'l1_Layer_3': 0.012959158240413207, 'n_units_Layer_1': 250, 'n_units_Layer_2': 85, 'n_units_Layer_3': 50}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 9.83% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.97 | sMAPE for Test Set is: 10.01% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:14:36,139]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:43,262]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:46,423]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:46,652]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:54,232]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:55,172]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:56,098]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:14:59,880]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:01,957]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:04,006]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:07,994]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:10,676]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:14,012]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:17,272]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:18,152]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:25,800]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:28,257]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:38,684]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:42,395]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:44,254]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:44,851]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:48,282]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:52,693]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:57,045]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:57,252]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:59,557]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:05,720]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:05,828]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:09,977]\u001b[0m Trial 493 finished with value: 4.61052498130159 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005724673363710207, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2758529844148037, 'dropout_rate_Layer_2': 0.11959869324702621, 'dropout_rate_Layer_3': 0.30909515346852084, 'dropout_rate_Layer_4': 0.3310065949338521, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012195987492477987, 'l1_Layer_2': 0.001115373069924786, 'l1_Layer_3': 3.601299860341746e-05, 'l1_Layer_4': 0.00025152323159334414, 'n_units_Layer_1': 190, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290, 'n_units_Layer_4': 205}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 9.24% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 10.03% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:16:12,227]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:12,505]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:15,723]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:19,279]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:20,134]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:24,534]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:27,239]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:32,061]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:35,347]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:39,294]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:41,248]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:44,319]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:46,025]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:47,476]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:52,884]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:16:53,153]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:00,114]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:02,398]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:06,781]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:07,405]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:12,771]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:13,463]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:18,334]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:22,181]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:27,550]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:30,429]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:31,281]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:33,792]\u001b[0m Trial 529 finished with value: 4.795245568543617 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008297019950236643, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2965929045786786, 'dropout_rate_Layer_2': 0.1382548952686853, 'dropout_rate_Layer_3': 0.32327223879769396, 'dropout_rate_Layer_4': 0.02458743358442801, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00020761259433883108, 'l1_Layer_2': 0.0005198050363422636, 'l1_Layer_3': 2.501991853077071e-05, 'l1_Layer_4': 0.00017580348050731694, 'n_units_Layer_1': 165, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290, 'n_units_Layer_4': 230}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 9.63% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 10.15% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:17:35,257]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:38,619]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:43,154]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:45,522]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:49,162]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:49,301]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:54,438]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:17:54,633]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:00,369]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:13,035]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:21,656]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:25,967]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:28,900]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:32,539]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:37,095]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:39,467]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:40,044]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:49,013]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:51,811]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:57,322]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:57,707]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:58,620]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:04,794]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:06,549]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:12,191]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:16,635]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:22,788]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:26,648]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:29,308]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:33,861]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:37,423]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:40,823]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:48,310]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:52,334]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:10,005]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:13,306]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:13,576]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:19,840]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:24,712]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:25,181]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:30,678]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:31,147]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:35,237]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:38,098]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:38,948]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:45,478]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:20:49,554]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:21:36,561]\u001b[0m Trial 566 finished with value: 4.116788210584687 and parameters: {'n_hidden': 3, 'learning_rate': 0.004701543620577546, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2074855247200501, 'dropout_rate_Layer_2': 0.02612813213615594, 'dropout_rate_Layer_3': 0.22547278804876802, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0004321720302007443, 'l1_Layer_2': 0.0010013916907730754, 'l1_Layer_3': 0.02695225819884358, 'n_units_Layer_1': 265, 'n_units_Layer_2': 170, 'n_units_Layer_3': 70}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 8.54% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 8.97% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:21:41,430]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:21:45,558]\u001b[0m Trial 594 finished with value: 4.32072447713749 and parameters: {'n_hidden': 4, 'learning_rate': 0.000547705868294786, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25526646447995316, 'dropout_rate_Layer_2': 0.13297600379894994, 'dropout_rate_Layer_3': 0.26090373804231404, 'dropout_rate_Layer_4': 0.006487367722918015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008779300916523531, 'l1_Layer_2': 2.0673470006119748e-05, 'l1_Layer_3': 3.0378728784511258e-05, 'l1_Layer_4': 0.00017801442167587954, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 300, 'n_units_Layer_4': 180}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 8.70% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 9.65% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:21:48,952]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:21:52,927]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:21:55,634]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:22:01,227]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:22:06,822]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:22:09,916]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:22:28,773]\u001b[0m Trial 600 finished with value: 5.2247785130559405 and parameters: {'n_hidden': 4, 'learning_rate': 0.002562761138419387, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2537661545407052, 'dropout_rate_Layer_2': 0.28405367686251126, 'dropout_rate_Layer_3': 0.2794706718902016, 'dropout_rate_Layer_4': 0.3921387112470413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012646307749823046, 'l1_Layer_2': 4.792933159795197e-05, 'l1_Layer_3': 0.0001082081954083771, 'l1_Layer_4': 0.00031655229446400017, 'n_units_Layer_1': 230, 'n_units_Layer_2': 185, 'n_units_Layer_3': 295, 'n_units_Layer_4': 180}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 10.56% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 11.55% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:22:48,136]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:22:52,242]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:23:28,120]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:23:33,522]\u001b[0m Trial 598 finished with value: 4.352319533367619 and parameters: {'n_hidden': 3, 'learning_rate': 0.004158262034771568, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23419776899116415, 'dropout_rate_Layer_2': 0.07089991354373247, 'dropout_rate_Layer_3': 0.22767855143466875, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0004341101767204682, 'l1_Layer_2': 0.0005429940134538968, 'l1_Layer_3': 0.02539976690183063, 'n_units_Layer_1': 265, 'n_units_Layer_2': 85, 'n_units_Layer_3': 65}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:23:33,693]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 8.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 9.91% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:23:39,895]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:23:42,702]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:23:46,268]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:23:50,881]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:23:54,824]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:23:54,915]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:01,685]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:04,330]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:09,598]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:20,663]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:21,556]\u001b[0m Trial 605 finished with value: 4.683673887812226 and parameters: {'n_hidden': 3, 'learning_rate': 0.009169821465935979, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21204653103449408, 'dropout_rate_Layer_2': 0.013112218394999455, 'dropout_rate_Layer_3': 0.1946954969131878, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008013793113402448, 'l1_Layer_2': 0.00159115356813374, 'l1_Layer_3': 0.025494324385023803, 'n_units_Layer_1': 270, 'n_units_Layer_2': 175, 'n_units_Layer_3': 90}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 9.48% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 9.84% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:24:24,489]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:28,753]\u001b[0m Trial 610 finished with value: 4.541051832781602 and parameters: {'n_hidden': 3, 'learning_rate': 0.007956547960515087, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2116640648328179, 'dropout_rate_Layer_2': 0.010960166435672986, 'dropout_rate_Layer_3': 0.2208280470139844, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001885812879201081, 'l1_Layer_2': 0.0009513660359570069, 'l1_Layer_3': 0.026495704514015356, 'n_units_Layer_1': 275, 'n_units_Layer_2': 155, 'n_units_Layer_3': 90}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 9.23% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.73 | sMAPE for Test Set is: 9.70% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:24:31,481]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:36,308]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:37,842]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:43,065]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:47,777]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:50,859]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:54,906]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:07,465]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:10,547]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:11,449]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:15,378]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:16,184]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:20,477]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:24,171]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:28,532]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:33,071]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:34,274]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:36,851]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:41,611]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:25:51,299]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:08,982]\u001b[0m Trial 645 finished with value: 4.518255713607568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029398303810930317, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11725552318614874, 'dropout_rate_Layer_2': 0.2655241939112338, 'dropout_rate_Layer_3': 0.19520025684443806, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020293526440063296, 'l1_Layer_2': 0.0003988775426813364, 'l1_Layer_3': 0.00036255638057693253, 'n_units_Layer_1': 225, 'n_units_Layer_2': 150, 'n_units_Layer_3': 110}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 9.29% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 10.00% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:26:13,002]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:16,268]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:20,198]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:26,886]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:29,431]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:30,526]\u001b[0m Trial 646 finished with value: 3.96759826540281 and parameters: {'n_hidden': 4, 'learning_rate': 0.002852133824062872, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.046108704896940446, 'dropout_rate_Layer_2': 0.16182701492325052, 'dropout_rate_Layer_3': 0.02276657736884394, 'dropout_rate_Layer_4': 0.22469876317054008, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07376181259727646, 'l1_Layer_2': 2.429413468145648e-05, 'l1_Layer_3': 1.024540151000054e-05, 'l1_Layer_4': 0.00028975680654007947, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290, 'n_units_Layer_4': 190}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 8.41% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 8.62% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:26:31,855]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:37,389]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:37,637]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:43,356]\u001b[0m Trial 642 finished with value: 4.654006437749171 and parameters: {'n_hidden': 3, 'learning_rate': 0.012090080527229506, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24099340620391557, 'dropout_rate_Layer_2': 0.03298925769999271, 'dropout_rate_Layer_3': 0.22602918744100628, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00043323378627695575, 'l1_Layer_2': 0.0006106426923881377, 'l1_Layer_3': 0.02145376561572647, 'n_units_Layer_1': 275, 'n_units_Layer_2': 150, 'n_units_Layer_3': 85}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 9.35% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 10.18% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:26:44,124]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:46,037]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:48,617]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:54,496]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:55,367]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:26:59,171]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:01,082]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:01,153]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:03,180]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:08,302]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:12,547]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:13,507]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:17,842]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:18,209]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:26,545]\u001b[0m Trial 652 finished with value: 4.1042815047624615 and parameters: {'n_hidden': 4, 'learning_rate': 0.001951238051723914, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008870776845325032, 'dropout_rate_Layer_2': 0.2047461220967223, 'dropout_rate_Layer_3': 0.21650610788980848, 'dropout_rate_Layer_4': 0.3595666958434251, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08308514308347432, 'l1_Layer_2': 6.22871623165369e-05, 'l1_Layer_3': 1.2119473848896316e-05, 'l1_Layer_4': 0.0006272788577982287, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290, 'n_units_Layer_4': 195}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 8.61% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.15 | sMAPE for Test Set is: 8.59% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:27:30,777]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:36,832]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:39,755]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:27:57,549]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:28:01,005]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:28:08,146]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:28:12,356]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:28:24,684]\u001b[0m Trial 675 finished with value: 4.080609661955629 and parameters: {'n_hidden': 4, 'learning_rate': 0.002150910778269848, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010413186180559069, 'dropout_rate_Layer_2': 0.2183398317416128, 'dropout_rate_Layer_3': 0.0014147602644411124, 'dropout_rate_Layer_4': 0.3725182469658678, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08007580977985125, 'l1_Layer_2': 6.635672031337562e-05, 'l1_Layer_3': 1.0309082333172173e-05, 'l1_Layer_4': 0.0007645275121758088, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280, 'n_units_Layer_4': 205}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 8.64% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 8.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:28:29,131]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:28:34,791]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:28:39,748]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:28:44,394]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:28:48,512]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:28:52,111]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:28:58,288]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:05,694]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:09,517]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:13,508]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:15,781]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:19,014]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:21,832]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:22,069]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:35,953]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:43,479]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:45,257]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:47,515]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:51,013]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:53,876]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:57,044]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:29:59,157]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:01,410]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:03,342]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:10,901]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:20,586]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:25,731]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:27,847]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:30,044]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:30,377]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:32,852]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:36,023]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:37,393]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:43,108]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:55,604]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:30:59,724]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:31:04,114]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:31:08,335]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:31:12,978]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:31:54,585]\u001b[0m Trial 694 finished with value: 4.37511520314705 and parameters: {'n_hidden': 3, 'learning_rate': 0.006806292930959891, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.245667345150756, 'dropout_rate_Layer_2': 0.029039145777191758, 'dropout_rate_Layer_3': 0.17626730159897486, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008323408571462832, 'l1_Layer_2': 0.0007766311950685731, 'l1_Layer_3': 0.07978902831616973, 'n_units_Layer_1': 260, 'n_units_Layer_2': 160, 'n_units_Layer_3': 65}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 8.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 9.84% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:31:56,727]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:01,226]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:05,528]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:09,463]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:17,212]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:21,364]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:21,872]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:27,279]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:28,017]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:31,610]\u001b[0m Trial 718 finished with value: 4.4781745470125145 and parameters: {'n_hidden': 3, 'learning_rate': 0.005705932563567212, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19321420839681733, 'dropout_rate_Layer_2': 0.07131449951776621, 'dropout_rate_Layer_3': 0.2300274146438271, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00028133214941991673, 'l1_Layer_2': 0.0005365494468652776, 'l1_Layer_3': 0.020670818238122453, 'n_units_Layer_1': 245, 'n_units_Layer_2': 135, 'n_units_Layer_3': 75}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 9.06% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 10.25% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:32:34,926]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:35,597]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:41,693]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:45,337]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:48,795]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:50,997]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:54,966]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:58,053]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:32:58,186]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:04,451]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:08,212]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:08,765]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:13,803]\u001b[0m Trial 719 finished with value: 4.250150030516157 and parameters: {'n_hidden': 3, 'learning_rate': 0.005931121949192415, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2274902330822828, 'dropout_rate_Layer_2': 0.07050998607451794, 'dropout_rate_Layer_3': 0.23140870194476615, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0002715361829372903, 'l1_Layer_2': 0.0005340813049507991, 'l1_Layer_3': 0.0306238501758816, 'n_units_Layer_1': 235, 'n_units_Layer_2': 135, 'n_units_Layer_3': 75}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 8.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.37 | sMAPE for Test Set is: 8.94% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:33:14,080]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:15,441]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:23,204]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:44,745]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:48,430]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:55,046]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:34:02,865]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:34:04,721]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:34:08,023]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:34:16,672]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:34:31,460]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:34:49,435]\u001b[0m Trial 738 finished with value: 4.049733092434136 and parameters: {'n_hidden': 3, 'learning_rate': 0.019310230594353536, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.397616152023039, 'dropout_rate_Layer_2': 0.12144212079637845, 'dropout_rate_Layer_3': 0.18298534461054877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002361144712478079, 'l1_Layer_2': 0.00027659504298071673, 'l1_Layer_3': 1.6969198051461847e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 8.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 9.36% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:34:57,142]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:34:57,907]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:03,561]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:07,512]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:11,239]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:14,531]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:14,782]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:19,822]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:21,573]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:26,033]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:26,334]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:33,643]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:40,135]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:40,327]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:43,177]\u001b[0m Trial 756 finished with value: 4.008820922947463 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009310503569193348, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008518145576472924, 'dropout_rate_Layer_2': 0.1605504438757769, 'dropout_rate_Layer_3': 0.2579693535539908, 'dropout_rate_Layer_4': 0.26662271931407966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05538873942465153, 'l1_Layer_2': 7.336251126725109e-05, 'l1_Layer_3': 1.414633614238121e-05, 'l1_Layer_4': 2.6781136921893345e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 295, 'n_units_Layer_3': 150, 'n_units_Layer_4': 210}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 8.57% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 8.84% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:35:48,337]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:52,420]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:35:55,830]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:00,152]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:03,623]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:03,901]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:11,122]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:15,412]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:16,945]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:20,161]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:23,274]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:23,599]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:24,418]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:31,113]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:36,640]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:36,854]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:39,696]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:42,643]\u001b[0m Trial 783 finished with value: 5.569275805457345 and parameters: {'n_hidden': 3, 'learning_rate': 0.03174172460737518, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012245251232704979, 'dropout_rate_Layer_2': 0.05287113869277048, 'dropout_rate_Layer_3': 0.006905736447295155, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011649407979824817, 'l1_Layer_2': 0.0015526477008421294, 'l1_Layer_3': 3.951878099283436e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 135, 'n_units_Layer_3': 105}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 11.37% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 11.58% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:36:46,623]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:46,774]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:49,872]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:55,598]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:55,711]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:56,204]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:36:56,353]\u001b[0m Trial 787 finished with value: 7.797457106286589 and parameters: {'n_hidden': 3, 'learning_rate': 0.026392672901110054, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34862869141160285, 'dropout_rate_Layer_2': 0.05328018890547133, 'dropout_rate_Layer_3': 0.11562495031461295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003321125750670414, 'l1_Layer_2': 0.0001903019808108627, 'l1_Layer_3': 7.881937641500518e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 85, 'n_units_Layer_3': 90}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.80 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 10.42 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:37:07,920]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:37:08,256]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:37:12,991]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:37:17,049]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:37:18,043]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:37:22,788]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:37:25,237]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:37:29,638]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:37:38,138]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:38:04,503]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:38:11,466]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:38:21,884]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:38:25,802]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:38:30,452]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:38:36,061]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:38:40,856]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:38:48,895]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:38:55,166]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:38:55,311]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:38:55,646]\u001b[0m Trial 803 finished with value: 4.319690063741176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0047531792111263835, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19506832501064117, 'dropout_rate_Layer_2': 0.018225207575609463, 'dropout_rate_Layer_3': 0.17765197633098087, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00031919657143028064, 'l1_Layer_2': 0.0002405403781613661, 'l1_Layer_3': 0.016411546453912153, 'n_units_Layer_1': 235, 'n_units_Layer_2': 160, 'n_units_Layer_3': 55}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 8.71% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 9.63% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:39:01,701]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:02,903]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:03,346]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:10,598]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:10,841]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:16,523]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:16,817]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:21,725]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:25,283]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:25,503]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:28,099]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:35,532]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:36,017]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:36,104]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:44,091]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:49,190]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:52,584]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:39:53,238]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:40:06,725]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:40:09,093]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:40:10,024]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:40:14,416]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:40:19,729]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:40:22,356]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:40:46,343]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:40:52,954]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:40:58,700]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:02,811]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:06,436]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:10,369]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:14,052]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:17,229]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:27,819]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:32,024]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:34,909]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:38,676]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:43,861]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:44,395]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:44,706]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:54,038]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:54,144]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:42:01,321]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:42:01,468]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:42:07,418]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:42:13,962]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:42:18,089]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:42:23,002]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:42:23,299]\u001b[0m Trial 832 finished with value: 4.070182592100715 and parameters: {'n_hidden': 3, 'learning_rate': 0.003657886696976754, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19916244296247285, 'dropout_rate_Layer_2': 0.035934844360134555, 'dropout_rate_Layer_3': 0.17927485904145338, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0006325226941754079, 'l1_Layer_2': 0.0015017639358020313, 'l1_Layer_3': 0.02517042833096287, 'n_units_Layer_1': 235, 'n_units_Layer_2': 165, 'n_units_Layer_3': 80}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 8.44% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 9.32% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:42:31,988]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:42:34,988]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:42:46,339]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:42:48,787]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:42:52,511]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:43:10,445]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:43:14,734]\u001b[0m Trial 861 finished with value: 4.7721742405394165 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006769675848722193, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24132064521687174, 'dropout_rate_Layer_2': 0.06982619056096692, 'dropout_rate_Layer_3': 0.25046431337777847, 'dropout_rate_Layer_4': 0.02449259722635555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.1292140374632652e-05, 'l1_Layer_2': 9.169027140419815e-05, 'l1_Layer_3': 4.3355583670391296e-05, 'l1_Layer_4': 0.00015686099190339897, 'n_units_Layer_1': 230, 'n_units_Layer_2': 125, 'n_units_Layer_3': 290, 'n_units_Layer_4': 300}. Best is trial 272 with value: 3.8964186563038967.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 9.63% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 10.30% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:43:19,096]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:43:23,640]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:43:25,814]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:43:32,156]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:43:37,331]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:43:41,180]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:43:42,818]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:43:53,118]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:43:57,078]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:44:00,599]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:44:19,390]\u001b[0m Trial 877 finished with value: 3.6957522657374873 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007572254349446478, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32836286458228464, 'dropout_rate_Layer_2': 0.061278745537592896, 'dropout_rate_Layer_3': 0.23438445019579768, 'dropout_rate_Layer_4': 0.31609823081931165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00019191064817391786, 'l1_Layer_2': 7.169467256142786e-05, 'l1_Layer_3': 0.00014055553373654357, 'l1_Layer_4': 0.00019453715788900268, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 295, 'n_units_Layer_4': 300}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.85% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 8.29% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:44:31,332]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:44:34,362]\u001b[0m Trial 870 finished with value: 4.155062010532429 and parameters: {'n_hidden': 3, 'learning_rate': 0.005134323223763816, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19786441922152043, 'dropout_rate_Layer_2': 0.0057576902261518535, 'dropout_rate_Layer_3': 0.21277634069330287, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0007104695112768139, 'l1_Layer_2': 0.0023549631424374905, 'l1_Layer_3': 0.015989856292299202, 'n_units_Layer_1': 265, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.16 | sMAPE for Validation Set is: 8.51% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 8.97% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:44:35,135]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:44:39,926]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:44:43,500]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:44:53,924]\u001b[0m Trial 873 finished with value: 4.4771290735425895 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006089379857926548, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22306270729076505, 'dropout_rate_Layer_2': 0.23246087325624376, 'dropout_rate_Layer_3': 0.24586083984250623, 'dropout_rate_Layer_4': 0.029633667365262135, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.0808845017347634e-05, 'l1_Layer_2': 0.0011401144907059884, 'l1_Layer_3': 7.292244014540278e-05, 'l1_Layer_4': 0.0001230994391339849, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 300, 'n_units_Layer_4': 300}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 9.11% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 9.51% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:44:54,146]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:45:00,544]\u001b[0m Trial 880 finished with value: 5.00295000327588 and parameters: {'n_hidden': 3, 'learning_rate': 0.04034997129425265, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3478569582774989, 'dropout_rate_Layer_2': 0.03237189897154809, 'dropout_rate_Layer_3': 0.19379204938185082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016375628223394168, 'l1_Layer_2': 0.0013442226381730456, 'l1_Layer_3': 2.232432016680009e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 50, 'n_units_Layer_3': 120}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 10.28% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 4.94 | sMAPE for Test Set is: 10.18% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:45:04,331]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:45:09,151]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:45:14,651]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:45:20,246]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:45:33,132]\u001b[0m Trial 887 finished with value: 4.209927230627177 and parameters: {'n_hidden': 3, 'learning_rate': 0.025384071460013948, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3492944033762877, 'dropout_rate_Layer_2': 0.029919243537875652, 'dropout_rate_Layer_3': 0.07885962581601749, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011110653178947793, 'l1_Layer_2': 0.005120808200006196, 'l1_Layer_3': 0.0016326786991487765, 'n_units_Layer_1': 300, 'n_units_Layer_2': 50, 'n_units_Layer_3': 260}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 8.69% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 8.92% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:45:37,233]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:45:40,705]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:45:44,779]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:45:49,607]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:45:52,265]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:45:54,288]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:45:59,646]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:04,641]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:08,744]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:13,106]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:17,012]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:20,408]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:24,223]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:28,621]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:28,890]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:31,894]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:34,850]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:38,059]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:40,015]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:45,513]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:49,266]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:50,489]\u001b[0m Trial 885 finished with value: 4.152491492346012 and parameters: {'n_hidden': 3, 'learning_rate': 0.005296097128614587, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21511189301309058, 'dropout_rate_Layer_2': 0.006678797101800818, 'dropout_rate_Layer_3': 0.21247540231903775, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0003830986475665163, 'l1_Layer_2': 0.001422179268123674, 'l1_Layer_3': 0.014942095212354277, 'n_units_Layer_1': 300, 'n_units_Layer_2': 205, 'n_units_Layer_3': 60}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 8.49% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 8.74% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:46:54,000]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:46:55,083]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:00,775]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:02,635]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:06,381]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:08,209]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:11,231]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:13,639]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:15,331]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:19,993]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:30,109]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:30,715]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:34,269]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:34,975]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:35,817]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:39,863]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:43,569]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:45,906]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:49,906]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:50,768]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:56,149]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:47:59,167]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:01,910]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:02,767]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:06,705]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:08,600]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:10,931]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:14,335]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:17,126]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:17,925]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:23,093]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:24,932]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:29,274]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:32,504]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:34,960]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:36,027]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:40,923]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:44,370]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:48,516]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:48:59,056]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:49:03,460]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:49:06,142]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:49:10,280]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:49:14,359]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:49:17,939]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:49:34,320]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:49:52,561]\u001b[0m Trial 961 finished with value: 3.9985568236061533 and parameters: {'n_hidden': 4, 'learning_rate': 0.00165014991787838, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12538591863384663, 'dropout_rate_Layer_2': 0.2656585241820351, 'dropout_rate_Layer_3': 0.21088136234595756, 'dropout_rate_Layer_4': 0.2587729675367281, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.05769229848978879, 'l1_Layer_2': 1.5805341084090183e-05, 'l1_Layer_3': 3.463084203404604e-05, 'l1_Layer_4': 1.4242967766110034e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 270, 'n_units_Layer_3': 170, 'n_units_Layer_4': 270}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 8.43% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 8.42% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:49:56,982]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:05,918]\u001b[0m Trial 925 finished with value: 4.1990654809958885 and parameters: {'n_hidden': 3, 'learning_rate': 0.002235112741612678, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25998328025324435, 'dropout_rate_Layer_2': 0.017025669820101053, 'dropout_rate_Layer_3': 0.197763335993974, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00033222429611882406, 'l1_Layer_2': 0.0023076937150012, 'l1_Layer_3': 0.010822274638558631, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 65}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 8.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 8.95% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:50:09,948]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:14,232]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:20,914]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:28,085]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:31,745]\u001b[0m Trial 962 finished with value: 3.960997009819002 and parameters: {'n_hidden': 3, 'learning_rate': 0.03246012341045407, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3800788773096806, 'dropout_rate_Layer_2': 0.14787050016887202, 'dropout_rate_Layer_3': 0.21092795601429717, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0062485954270904e-05, 'l1_Layer_2': 0.00038368677025361257, 'l1_Layer_3': 0.0002469668945069875, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 145}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 8.32% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 9.11% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:50:35,714]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:36,639]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:43,012]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:47,118]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:50,448]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:55,602]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:59,428]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:04,015]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:05,984]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:19,252]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:26,691]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:30,395]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:34,230]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:38,727]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:43,070]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:46,131]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:49,449]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:50,077]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:55,374]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:51:56,496]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:52:01,854]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:52:05,453]\u001b[0m Trial 978 finished with value: 4.183132903686893 and parameters: {'n_hidden': 3, 'learning_rate': 0.03290615014593772, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3975571178392177, 'dropout_rate_Layer_2': 0.15010111761948736, 'dropout_rate_Layer_3': 0.2163855313722045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.588870341710516e-05, 'l1_Layer_2': 0.00037813806459323254, 'l1_Layer_3': 0.0006101554025278483, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 140}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 8.82% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 8.79% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:52:09,265]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:52:12,728]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:52:12,809]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:52:19,239]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:52:21,496]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:52:29,073]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:52:57,769]\u001b[0m Trial 997 finished with value: 3.9530235724253813 and parameters: {'n_hidden': 3, 'learning_rate': 0.020931880257090602, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37646624416662544, 'dropout_rate_Layer_2': 0.16313474442787995, 'dropout_rate_Layer_3': 0.12322671524210763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0697958418739204e-05, 'l1_Layer_2': 0.0007396861796373265, 'l1_Layer_3': 0.0002400508643480077, 'n_units_Layer_1': 95, 'n_units_Layer_2': 155, 'n_units_Layer_3': 150}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.95 | sMAPE for Validation Set is: 8.27% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 8.89% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:52:58,602]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:04,174]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:09,701]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:17,170]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:21,186]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:23,536]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:27,768]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:27,945]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:34,211]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:37,828]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:41,037]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:42,386]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 7.91% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.08 | sMAPE for Test Set is: 8.51% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:53:43,746]\u001b[0m Trial 1000 finished with value: 3.7561309481910268 and parameters: {'n_hidden': 3, 'learning_rate': 0.009055482617639206, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3156648861583539, 'dropout_rate_Layer_2': 0.1644548927067138, 'dropout_rate_Layer_3': 0.08918154952275174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0605098086450165e-05, 'l1_Layer_2': 0.0007074670274815304, 'l1_Layer_3': 0.00023811906783612413, 'n_units_Layer_1': 85, 'n_units_Layer_2': 160, 'n_units_Layer_3': 170}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:51,364]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:55,054]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:53:55,441]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:00,799]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:01,345]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:02,051]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:02,940]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:13,270]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:13,679]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:18,321]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:21,769]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:22,647]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:22,746]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:29,897]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:31,962]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:36,203]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:39,562]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:43,081]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:47,953]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:49,835]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:58,902]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:02,696]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:09,688]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:15,050]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:18,719]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 9.08% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.40 | sMAPE for Test Set is: 9.00% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:55:21,368]\u001b[0m Trial 1021 finished with value: 4.4554405901196725 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009654153587110684, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32788150939439864, 'dropout_rate_Layer_2': 0.1461031234679493, 'dropout_rate_Layer_3': 0.34165302330473324, 'dropout_rate_Layer_4': 0.30366967531013767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0014654299371199952, 'l1_Layer_2': 0.004863642111686045, 'l1_Layer_3': 0.00014500439077786838, 'l1_Layer_4': 1.2553794307998324e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290, 'n_units_Layer_4': 280}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:36,278]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:39,369]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:43,291]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:45,671]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:53,851]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:56,509]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:58,765]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:56:02,122]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:56:06,817]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:56:17,428]\u001b[0m Trial 1032 finished with value: 4.293763831616336 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007840950414273582, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3329146687453338, 'dropout_rate_Layer_2': 0.1242625000955809, 'dropout_rate_Layer_3': 0.20030373280837244, 'dropout_rate_Layer_4': 0.036827878995465045, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0015025475049672788, 'l1_Layer_2': 0.005014745751145302, 'l1_Layer_3': 3.383945957421475e-05, 'l1_Layer_4': 1.1715805862039426e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 160, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 8.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 8.86% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:56:21,096]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:56:24,369]\u001b[0m Trial 1042 finished with value: 4.727492924136157 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010436168925914812, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2996195043960883, 'dropout_rate_Layer_2': 0.1294952020948729, 'dropout_rate_Layer_3': 0.32872595802996807, 'dropout_rate_Layer_4': 0.21336436627645217, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0018605177577063253, 'l1_Layer_2': 0.0040944850097590245, 'l1_Layer_3': 0.00018926109026241102, 'l1_Layer_4': 1.91233233819764e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280, 'n_units_Layer_4': 260}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 9.76% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.85 | sMAPE for Test Set is: 9.95% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:56:28,284]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:56:32,481]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:56:50,585]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:56:57,402]\u001b[0m Trial 1046 finished with value: 3.70772021120487 and parameters: {'n_hidden': 3, 'learning_rate': 0.011555046425776977, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28610673150301935, 'dropout_rate_Layer_2': 0.011902472034866728, 'dropout_rate_Layer_3': 0.07003608286763517, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.765091729153337e-05, 'l1_Layer_2': 0.0011499458065721401, 'l1_Layer_3': 0.00027756941841019383, 'n_units_Layer_1': 75, 'n_units_Layer_2': 190, 'n_units_Layer_3': 140}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.76% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.78 | sMAPE for Test Set is: 7.89% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:57:09,047]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:57:17,979]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:57:27,381]\u001b[0m Trial 1047 finished with value: 4.603953068651523 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008365813492168441, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3368114050183613, 'dropout_rate_Layer_2': 0.14506250598162948, 'dropout_rate_Layer_3': 0.3569307608251721, 'dropout_rate_Layer_4': 0.28410565980506747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015941082397137583, 'l1_Layer_2': 0.0036474066114629577, 'l1_Layer_3': 0.00012040356563667703, 'l1_Layer_4': 1.3926856315305865e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280, 'n_units_Layer_4': 280}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 9.34% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 9.19% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:57:33,913]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:57:39,309]\u001b[0m Trial 1054 finished with value: 3.7721895591284755 and parameters: {'n_hidden': 3, 'learning_rate': 0.011414425265953522, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27941731282903015, 'dropout_rate_Layer_2': 0.007009466951145208, 'dropout_rate_Layer_3': 0.062149266791953345, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.705714678164625e-05, 'l1_Layer_2': 0.0012119445350659082, 'l1_Layer_3': 0.00026420783962911897, 'n_units_Layer_1': 75, 'n_units_Layer_2': 200, 'n_units_Layer_3': 135}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 7.92% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.82 | sMAPE for Test Set is: 7.93% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:57:43,520]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:57:45,847]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:57:48,662]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:57:50,552]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:57:53,681]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:57:58,906]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:01,681]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:05,235]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:05,864]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:10,206]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:13,737]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:13,961]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:14,891]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:26,140]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:26,304]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:33,366]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:38,317]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:44,175]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:49,403]\u001b[0m Trial 1072 finished with value: 3.972610462515492 and parameters: {'n_hidden': 3, 'learning_rate': 0.04689795036878873, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27666796255124176, 'dropout_rate_Layer_2': 0.007971129827829642, 'dropout_rate_Layer_3': 0.06999278961343028, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9799732149139622e-05, 'l1_Layer_2': 0.0012124904719477854, 'l1_Layer_3': 0.0002949294195931728, 'n_units_Layer_1': 55, 'n_units_Layer_2': 190, 'n_units_Layer_3': 135}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 8.35% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.36 | sMAPE for Test Set is: 9.21% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:58:50,663]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:58:59,544]\u001b[0m Trial 1074 finished with value: 3.790080187103158 and parameters: {'n_hidden': 3, 'learning_rate': 0.03622332622152265, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27733276564831155, 'dropout_rate_Layer_2': 0.018704842720625982, 'dropout_rate_Layer_3': 0.06344360507597138, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7985221475922815e-05, 'l1_Layer_2': 0.0011055712256897578, 'l1_Layer_3': 0.00028022099617872824, 'n_units_Layer_1': 60, 'n_units_Layer_2': 190, 'n_units_Layer_3': 135}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.75 | sMAPE for Test Set is: 8.14% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:59:04,955]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:06,034]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:12,489]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:16,054]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:17,352]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:22,673]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:24,462]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:26,649]\u001b[0m Trial 1078 finished with value: 3.802648134049535 and parameters: {'n_hidden': 3, 'learning_rate': 0.03586021903210665, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24859573218738773, 'dropout_rate_Layer_2': 0.012306706237195188, 'dropout_rate_Layer_3': 0.06152451861780495, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.617032590500522e-05, 'l1_Layer_2': 0.001877824586511373, 'l1_Layer_3': 0.0005917826243775786, 'n_units_Layer_1': 75, 'n_units_Layer_2': 185, 'n_units_Layer_3': 140}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 7.93% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 9.02% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:59:32,559]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:34,072]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:38,432]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:39,155]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:41,214]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:44,854]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:47,748]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:51,651]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:55,551]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:59,254]\u001b[0m Trial 1081 finished with value: 4.610219149141116 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014302898703392655, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3410584985978904, 'dropout_rate_Layer_2': 0.16084727011736014, 'dropout_rate_Layer_3': 0.3141784370874995, 'dropout_rate_Layer_4': 0.2688173812115361, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0013385452234116056, 'l1_Layer_2': 0.004669091160634151, 'l1_Layer_3': 9.599871312610228e-05, 'l1_Layer_4': 2.4637280100065495e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295, 'n_units_Layer_4': 285}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 9.40% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.64 | sMAPE for Test Set is: 9.40% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:59:59,452]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:07,112]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:11,097]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:15,847]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:16,027]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:22,534]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:23,081]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:23,215]\u001b[0m Trial 1093 finished with value: 3.9136699479829447 and parameters: {'n_hidden': 3, 'learning_rate': 0.04757144426083255, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2408342582311482, 'dropout_rate_Layer_2': 0.01603731017016611, 'dropout_rate_Layer_3': 0.040785822427736526, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.7441531151997496e-05, 'l1_Layer_2': 0.00313352476834997, 'l1_Layer_3': 0.0005979670080037266, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 8.14% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.08% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:00:32,090]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:35,800]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:36,179]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:41,916]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:45,245]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:48,560]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:51,192]\u001b[0m Trial 1100 finished with value: 4.518479715956434 and parameters: {'n_hidden': 4, 'learning_rate': 0.001601876317717238, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3370117810302913, 'dropout_rate_Layer_2': 0.1588214020952163, 'dropout_rate_Layer_3': 0.30593343212139706, 'dropout_rate_Layer_4': 0.27290898819798715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009965178160814194, 'l1_Layer_2': 0.003983140442277433, 'l1_Layer_3': 9.050715298197308e-05, 'l1_Layer_4': 1.878317775520348e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 110, 'n_units_Layer_3': 290, 'n_units_Layer_4': 275}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 9.18% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 9.22% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:00:54,888]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:57,647]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:01:00,052]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:01:08,130]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:01:21,271]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:01:24,890]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:01:33,623]\u001b[0m Trial 1115 finished with value: 4.665619957327176 and parameters: {'n_hidden': 4, 'learning_rate': 0.001668452743004513, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3405468272684227, 'dropout_rate_Layer_2': 0.1602828021503692, 'dropout_rate_Layer_3': 0.3103029348723172, 'dropout_rate_Layer_4': 0.270488425376486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009908454483177627, 'l1_Layer_2': 0.003830835725427791, 'l1_Layer_3': 8.81170881550452e-05, 'l1_Layer_4': 2.5391952691705518e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 115, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 9.41% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 9.27% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:01:35,775]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:01:41,348]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:01:45,787]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:01:50,747]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:01:55,041]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:01:59,622]\u001b[0m Trial 1114 finished with value: 3.8338333274443506 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022305847690950995, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03590024284708507, 'dropout_rate_Layer_2': 0.1838894107242728, 'dropout_rate_Layer_3': 0.22460440161671072, 'dropout_rate_Layer_4': 0.2611433555951591, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003912470475586125, 'l1_Layer_2': 2.2409355114473697e-05, 'l1_Layer_3': 0.002001477388592236, 'l1_Layer_4': 0.0005198404979319092, 'n_units_Layer_1': 95, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285, 'n_units_Layer_4': 230}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 8.07% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 8.69% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:02:04,240]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:02:09,297]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:02:10,378]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:02:10,625]\u001b[0m Trial 1111 finished with value: 4.248505198453836 and parameters: {'n_hidden': 3, 'learning_rate': 0.007459401595823306, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2229211524119406, 'dropout_rate_Layer_2': 0.06691893616194093, 'dropout_rate_Layer_3': 0.1936275286756094, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00012758043940117042, 'l1_Layer_2': 0.0012093339461143964, 'l1_Layer_3': 0.017143261142160464, 'n_units_Layer_1': 255, 'n_units_Layer_2': 160, 'n_units_Layer_3': 65}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 8.69% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.55 | sMAPE for Test Set is: 9.20% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:02:19,395]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:02:26,202]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:02:28,690]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:02:32,237]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:02:36,245]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:02:41,001]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:02:46,349]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:03:02,945]\u001b[0m Trial 1129 finished with value: 4.415201385203242 and parameters: {'n_hidden': 4, 'learning_rate': 0.001288871007693485, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3513961125226847, 'dropout_rate_Layer_2': 0.16000933335346756, 'dropout_rate_Layer_3': 0.3120296717556799, 'dropout_rate_Layer_4': 0.26690411606178155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007636642630392614, 'l1_Layer_2': 0.003957890157286124, 'l1_Layer_3': 8.713825582227259e-05, 'l1_Layer_4': 3.0591017629107435e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 110, 'n_units_Layer_3': 290, 'n_units_Layer_4': 280}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 9.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 9.00% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:03:26,645]\u001b[0m Trial 1120 finished with value: 4.483027105890839 and parameters: {'n_hidden': 3, 'learning_rate': 0.006336447547023434, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17385483686089198, 'dropout_rate_Layer_2': 0.03103492263005439, 'dropout_rate_Layer_3': 0.2138090653916203, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0007815036501104093, 'l1_Layer_2': 0.0020543577107376525, 'l1_Layer_3': 0.017587213268428332, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 60}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 9.16% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 9.58% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:03:31,742]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:03:40,222]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:03:44,920]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:03:53,602]\u001b[0m Trial 1138 finished with value: 3.825289482679669 and parameters: {'n_hidden': 3, 'learning_rate': 0.026034338120474204, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2783867388745516, 'dropout_rate_Layer_2': 0.027465298731365176, 'dropout_rate_Layer_3': 0.05412173271533968, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.290988124461597e-05, 'l1_Layer_2': 0.0012188845020204772, 'l1_Layer_3': 0.0015261822596327197, 'n_units_Layer_1': 85, 'n_units_Layer_2': 190, 'n_units_Layer_3': 145}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 7.99% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.93 | sMAPE for Test Set is: 8.26% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:03:55,687]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:04:04,015]\u001b[0m Trial 1133 finished with value: 4.1703984406718115 and parameters: {'n_hidden': 3, 'learning_rate': 0.005399829080496531, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22788087492589162, 'dropout_rate_Layer_2': 0.08151331663490424, 'dropout_rate_Layer_3': 0.18645592465666855, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010517196504672859, 'l1_Layer_2': 0.001971696590629792, 'l1_Layer_3': 0.022722412196664453, 'n_units_Layer_1': 260, 'n_units_Layer_2': 165, 'n_units_Layer_3': 50}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 8.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 9.16% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:04:11,048]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:04:14,931]\u001b[0m Trial 1141 finished with value: 3.7821142636109113 and parameters: {'n_hidden': 3, 'learning_rate': 0.029158963172336825, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2743165994923491, 'dropout_rate_Layer_2': 0.027090609325963647, 'dropout_rate_Layer_3': 0.05672286259832063, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2613225128792132e-05, 'l1_Layer_2': 0.002609846816091946, 'l1_Layer_3': 0.0002593320795668414, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 150}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 7.92% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.14 | sMAPE for Test Set is: 8.60% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:04:19,310]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:04:19,688]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:04:25,871]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:04:34,251]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:04:43,564]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:04:49,169]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:04:53,446]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:04:57,823]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:05:01,685]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:05:13,397]\u001b[0m Trial 1151 finished with value: 3.798592343614532 and parameters: {'n_hidden': 3, 'learning_rate': 0.029161836394895776, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27261670625688694, 'dropout_rate_Layer_2': 0.010208780044387814, 'dropout_rate_Layer_3': 0.04988092807408011, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.133353547136333e-05, 'l1_Layer_2': 0.002874207943906083, 'l1_Layer_3': 0.0015662732561660306, 'n_units_Layer_1': 50, 'n_units_Layer_2': 190, 'n_units_Layer_3': 150}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 7.98% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.09 | sMAPE for Test Set is: 8.55% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:05:15,874]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:05:16,328]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:05:21,812]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:05:26,686]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:05:26,995]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:05:27,536]\u001b[0m Trial 1156 finished with value: 3.8710220794171595 and parameters: {'n_hidden': 3, 'learning_rate': 0.028516083903964227, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23569585972349882, 'dropout_rate_Layer_2': 0.027856550307063972, 'dropout_rate_Layer_3': 0.058346713374491946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1867425391350728e-05, 'l1_Layer_2': 0.001163099593730608, 'l1_Layer_3': 0.0019391628389669887, 'n_units_Layer_1': 85, 'n_units_Layer_2': 190, 'n_units_Layer_3': 150}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 8.21% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.17 | sMAPE for Test Set is: 8.86% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:05:37,589]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:05:51,245]\u001b[0m Trial 1159 finished with value: 4.675926776687083 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016950135929193466, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.373577980731896, 'dropout_rate_Layer_2': 0.14993010320764039, 'dropout_rate_Layer_3': 0.3259508148273082, 'dropout_rate_Layer_4': 0.27768244459242264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006776399759242257, 'l1_Layer_2': 0.004490626359489509, 'l1_Layer_3': 8.71425355754397e-05, 'l1_Layer_4': 2.4730681419445066e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 105, 'n_units_Layer_3': 295, 'n_units_Layer_4': 280}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 9.48% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 9.71% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:06:02,487]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:02,502]\u001b[0m Trial 1164 finished with value: 3.922073723102194 and parameters: {'n_hidden': 3, 'learning_rate': 0.06360750592678585, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21071150286477303, 'dropout_rate_Layer_2': 0.029328495179271163, 'dropout_rate_Layer_3': 0.06002497165357499, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.31231746177936e-05, 'l1_Layer_2': 0.003008467128447983, 'l1_Layer_3': 0.004786684876311081, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 140}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 8.13% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.27 | sMAPE for Test Set is: 8.78% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:06:04,639]\u001b[0m Trial 1161 finished with value: 4.54037965855341 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011715961357706612, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3683913114216526, 'dropout_rate_Layer_2': 0.16340817934819665, 'dropout_rate_Layer_3': 0.3258589225989298, 'dropout_rate_Layer_4': 0.2688698662990057, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0010958056459171696, 'l1_Layer_2': 0.003465096562960871, 'l1_Layer_3': 8.928026871297239e-05, 'l1_Layer_4': 2.3708348184562268e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 110, 'n_units_Layer_3': 65, 'n_units_Layer_4': 280}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 9.24% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 9.26% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:06:14,168]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:14,999]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:23,271]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:23,452]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:29,184]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:29,856]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:30,235]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:38,841]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:41,077]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:43,878]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:43,926]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:48,939]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:51,318]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:54,957]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:02,930]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:09,093]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:11,387]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:14,353]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:19,271]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:23,253]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:24,019]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 9.16% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 9.37% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:07:26,599]\u001b[0m Trial 1180 finished with value: 4.491517873303184 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016156382219481699, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3399716409741769, 'dropout_rate_Layer_2': 0.1571170880562663, 'dropout_rate_Layer_3': 0.32561993196651456, 'dropout_rate_Layer_4': 0.25209796505056664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007251296582376299, 'l1_Layer_2': 0.004232345310455979, 'l1_Layer_3': 9.311594977604766e-05, 'l1_Layer_4': 2.560361682348201e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 105, 'n_units_Layer_3': 300, 'n_units_Layer_4': 285}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:26,719]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:35,451]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:37,632]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:40,802]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:44,701]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:46,223]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:50,156]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:54,032]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:58,198]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:07:59,779]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:08:01,854]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:08:07,557]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:08:10,111]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:08:15,515]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:08:31,564]\u001b[0m Trial 1198 finished with value: 3.888157473525078 and parameters: {'n_hidden': 3, 'learning_rate': 0.0298855994166397, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27064095789593096, 'dropout_rate_Layer_2': 0.011205347791774206, 'dropout_rate_Layer_3': 0.029691422209250036, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.981261953249473e-05, 'l1_Layer_2': 0.0025682495075428934, 'l1_Layer_3': 0.0019005420819514975, 'n_units_Layer_1': 80, 'n_units_Layer_2': 200, 'n_units_Layer_3': 155}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 7.99% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 8.59% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:08:36,279]\u001b[0m Trial 1202 finished with value: 3.847096473491392 and parameters: {'n_hidden': 3, 'learning_rate': 0.02454111305839238, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28271306284946796, 'dropout_rate_Layer_2': 0.0013187110336284448, 'dropout_rate_Layer_3': 0.06035313962358135, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.8144454314980598e-05, 'l1_Layer_2': 0.004471973342871395, 'l1_Layer_3': 0.0012686821380039597, 'n_units_Layer_1': 60, 'n_units_Layer_2': 215, 'n_units_Layer_3': 140}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 8.03% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 8.60% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:08:39,872]\u001b[0m Trial 1200 finished with value: 3.826503555841286 and parameters: {'n_hidden': 3, 'learning_rate': 0.02739753264107874, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2837442491241944, 'dropout_rate_Layer_2': 0.0016623173400215387, 'dropout_rate_Layer_3': 0.06141816421743928, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.670012870097035e-05, 'l1_Layer_2': 0.004618847753059026, 'l1_Layer_3': 0.0012425306452028828, 'n_units_Layer_1': 60, 'n_units_Layer_2': 215, 'n_units_Layer_3': 140}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 8.02% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.00 | sMAPE for Test Set is: 8.31% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:08:43,286]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:08:43,773]\u001b[0m Trial 1204 finished with value: 3.8403610818923304 and parameters: {'n_hidden': 3, 'learning_rate': 0.028119837356956442, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27949660109857777, 'dropout_rate_Layer_2': 0.010665167201809427, 'dropout_rate_Layer_3': 0.00918733729070012, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.587719186696199e-05, 'l1_Layer_2': 0.004926471780480575, 'l1_Layer_3': 0.001087547790765156, 'n_units_Layer_1': 65, 'n_units_Layer_2': 180, 'n_units_Layer_3': 140}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 7.98% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 8.65% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:08:43,949]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:08:51,843]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:08:54,685]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:08:59,833]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:09:04,188]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:09:08,089]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:09:13,590]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:09:18,795]\u001b[0m Trial 1205 finished with value: 3.7941156769597995 and parameters: {'n_hidden': 3, 'learning_rate': 0.027599389988185622, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28155785797321653, 'dropout_rate_Layer_2': 0.002683503376713369, 'dropout_rate_Layer_3': 0.06240085126774966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.66559433609382e-05, 'l1_Layer_2': 0.0047983354533118775, 'l1_Layer_3': 0.001034885600070819, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 150}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 7.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 8.76% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:09:23,607]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:09:31,933]\u001b[0m Trial 1211 finished with value: 4.515454585609934 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010786649233518015, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35412090048891814, 'dropout_rate_Layer_2': 0.14863578272187417, 'dropout_rate_Layer_3': 0.31923769725633333, 'dropout_rate_Layer_4': 0.23311747854911724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015642037304950543, 'l1_Layer_2': 0.005889792802533058, 'l1_Layer_3': 7.985967152778921e-05, 'l1_Layer_4': 2.131898986781602e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 90, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 9.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 9.08% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:09:35,688]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:09:40,504]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:09:44,585]\u001b[0m Trial 1217 finished with value: 3.7534791284344493 and parameters: {'n_hidden': 3, 'learning_rate': 0.036534639174464895, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25355812458725047, 'dropout_rate_Layer_2': 0.04261867683304327, 'dropout_rate_Layer_3': 0.011655642438932433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3676211490456008e-05, 'l1_Layer_2': 0.005878095085005624, 'l1_Layer_3': 0.0010339589924985722, 'n_units_Layer_1': 50, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.87% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.85 | sMAPE for Test Set is: 8.02% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:09:49,993]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:09:51,286]\u001b[0m Trial 1210 finished with value: 3.9914373788220927 and parameters: {'n_hidden': 4, 'learning_rate': 0.000615387745532747, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37092001375816075, 'dropout_rate_Layer_2': 0.17532333840361558, 'dropout_rate_Layer_3': 0.319542270954346, 'dropout_rate_Layer_4': 0.26877315017590886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015407717268409035, 'l1_Layer_2': 0.004490927795476161, 'l1_Layer_3': 5.626401491772879e-05, 'l1_Layer_4': 3.0666695426581807e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 115, 'n_units_Layer_3': 290, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 8.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 9.06% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:09:56,139]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:10:00,910]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:10:04,475]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:10:13,389]\u001b[0m Trial 1218 finished with value: 4.312383669057595 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013138018690295064, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3526589329896004, 'dropout_rate_Layer_2': 0.14886992858157333, 'dropout_rate_Layer_3': 0.1999901439771718, 'dropout_rate_Layer_4': 0.25246764034494007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0013043126901944022, 'l1_Layer_2': 0.0022314660797893983, 'l1_Layer_3': 8.358569552416214e-05, 'l1_Layer_4': 2.110381751494732e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 105, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 8.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 10.06% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:10:17,702]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:10:21,688]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:10:26,678]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:10:32,201]\u001b[0m Trial 1221 finished with value: 4.184539112409844 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013366904395046772, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35525799801941926, 'dropout_rate_Layer_2': 0.1489388376621394, 'dropout_rate_Layer_3': 0.31995396713550683, 'dropout_rate_Layer_4': 0.23249837246631844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0014996365995366713, 'l1_Layer_2': 0.008213918775345552, 'l1_Layer_3': 8.93705393816412e-05, 'l1_Layer_4': 2.2084191841471295e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 90, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 8.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.64 | sMAPE for Test Set is: 9.53% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:10:36,076]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:10:42,172]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:10:58,732]\u001b[0m Trial 1231 finished with value: 3.9402438301214295 and parameters: {'n_hidden': 3, 'learning_rate': 0.03581564284726512, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25511415177794744, 'dropout_rate_Layer_2': 0.04020988190021613, 'dropout_rate_Layer_3': 0.08428752428834707, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3727219358696208e-05, 'l1_Layer_2': 0.007350672638030959, 'l1_Layer_3': 0.000721215808243353, 'n_units_Layer_1': 50, 'n_units_Layer_2': 170, 'n_units_Layer_3': 145}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 8.16% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 8.88% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:11:09,036]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:11:18,080]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:11:23,192]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:11:30,258]\u001b[0m Trial 1227 finished with value: 3.933278461332872 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005678512079372354, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35447450160474164, 'dropout_rate_Layer_2': 0.18195794112950664, 'dropout_rate_Layer_3': 0.3216225247817094, 'dropout_rate_Layer_4': 0.24099891293549466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0017181083671973139, 'l1_Layer_2': 0.004681629378469562, 'l1_Layer_3': 8.960729119501526e-05, 'l1_Layer_4': 3.0344995991997664e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 95, 'n_units_Layer_3': 295, 'n_units_Layer_4': 290}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 8.15% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.23 | sMAPE for Test Set is: 8.71% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:11:38,626]\u001b[0m Trial 1234 finished with value: 4.27496232662787 and parameters: {'n_hidden': 4, 'learning_rate': 0.001289321429359868, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35610398693122297, 'dropout_rate_Layer_2': 0.18189402437408914, 'dropout_rate_Layer_3': 0.20691535686049214, 'dropout_rate_Layer_4': 0.24888916129047467, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0013248322407233347, 'l1_Layer_2': 0.007957103203176105, 'l1_Layer_3': 9.314458681102793e-05, 'l1_Layer_4': 1.6250570135837492e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 95, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 8.73% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 9.59% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:11:44,130]\u001b[0m Trial 1226 finished with value: 4.321998863770754 and parameters: {'n_hidden': 3, 'learning_rate': 0.007130482097537155, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23273916965416983, 'dropout_rate_Layer_2': 0.013579805636074306, 'dropout_rate_Layer_3': 0.19488283299794984, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00044819762510865625, 'l1_Layer_2': 0.0021458954850068403, 'l1_Layer_3': 0.023860253898141465, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 70}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 8.82% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 9.63% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:11:53,265]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:12:09,721]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:12:14,250]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:12:17,578]\u001b[0m Trial 1238 finished with value: 4.410906878236952 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016551775188011356, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3530373820311484, 'dropout_rate_Layer_2': 0.14657888835556218, 'dropout_rate_Layer_3': 0.20048936168721507, 'dropout_rate_Layer_4': 0.2650934151648587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015896006346458726, 'l1_Layer_2': 0.009935543330601478, 'l1_Layer_3': 9.976357461879889e-05, 'l1_Layer_4': 2.5490711512091373e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 85, 'n_units_Layer_3': 295, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 8.97% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 9.75% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:12:21,581]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:12:27,604]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:12:53,633]\u001b[0m Trial 1242 finished with value: 4.3453595413486825 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013222184416694423, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3419612218924605, 'dropout_rate_Layer_2': 0.18160756481558427, 'dropout_rate_Layer_3': 0.18889964926563432, 'dropout_rate_Layer_4': 0.23281195203360613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0017083692969937121, 'l1_Layer_2': 0.00824454781908489, 'l1_Layer_3': 7.076906232561572e-05, 'l1_Layer_4': 1.2331742278992735e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 8.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 9.88% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:12:58,122]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:13:06,565]\u001b[0m Trial 1239 finished with value: 3.978271463467866 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005691271107305059, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3532886775672349, 'dropout_rate_Layer_2': 0.18964700203601437, 'dropout_rate_Layer_3': 0.20134716932364025, 'dropout_rate_Layer_4': 0.22461257257032732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0016446429907481794, 'l1_Layer_2': 0.006003385253526367, 'l1_Layer_3': 6.888094489659763e-05, 'l1_Layer_4': 2.5255097406698885e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295, 'n_units_Layer_4': 290}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 8.30% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.27 | sMAPE for Test Set is: 8.81% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:13:10,321]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:13:16,034]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:13:22,589]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:13:27,431]\u001b[0m Trial 1247 finished with value: 4.30787123321377 and parameters: {'n_hidden': 4, 'learning_rate': 0.001340064053593172, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.342467596806696, 'dropout_rate_Layer_2': 0.1824382547251821, 'dropout_rate_Layer_3': 0.1942325584305899, 'dropout_rate_Layer_4': 0.2398674093207013, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012888815262197858, 'l1_Layer_2': 0.00727643539743438, 'l1_Layer_3': 0.00012822401900564214, 'l1_Layer_4': 1.3412106366771884e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 300, 'n_units_Layer_4': 300}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 8.81% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 9.18% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:13:31,135]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:13:35,768]\u001b[0m Trial 1245 finished with value: 4.387387099816591 and parameters: {'n_hidden': 4, 'learning_rate': 0.00141107730794556, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3429687638255787, 'dropout_rate_Layer_2': 0.17263480838532033, 'dropout_rate_Layer_3': 0.19785393189516395, 'dropout_rate_Layer_4': 0.2534551147106388, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012814789162947102, 'l1_Layer_2': 0.010489415046521029, 'l1_Layer_3': 0.0001280463795360861, 'l1_Layer_4': 1.2140115655003677e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 8.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 9.29% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:13:39,969]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:13:42,170]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:13:46,244]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:13:46,671]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:13:55,636]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:13:59,111]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:14:03,229]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:14:08,822]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:14:13,067]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:14:13,828]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:14:20,169]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:14:27,282]\u001b[0m Trial 1259 finished with value: 3.803384841571751 and parameters: {'n_hidden': 3, 'learning_rate': 0.017328397068196697, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30565580997846636, 'dropout_rate_Layer_2': 0.0034280418310475074, 'dropout_rate_Layer_3': 0.09094730189644887, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.52171100168944e-05, 'l1_Layer_2': 0.0037733161124345912, 'l1_Layer_3': 0.000953013802300621, 'n_units_Layer_1': 60, 'n_units_Layer_2': 195, 'n_units_Layer_3': 130}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 7.94% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.85 | sMAPE for Test Set is: 8.34% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:14:31,551]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:14:31,619]\u001b[0m Trial 1254 finished with value: 4.297434571903733 and parameters: {'n_hidden': 4, 'learning_rate': 0.001274671903789207, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34710237414272027, 'dropout_rate_Layer_2': 0.18601763877101216, 'dropout_rate_Layer_3': 0.17792398002637014, 'dropout_rate_Layer_4': 0.24124547852895395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001339916437449785, 'l1_Layer_2': 0.010628140126703213, 'l1_Layer_3': 0.0001306308298066706, 'l1_Layer_4': 1.4482343773647559e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 8.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.85 | sMAPE for Test Set is: 9.76% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:14:48,099]\u001b[0m Trial 1267 finished with value: 3.919420916052948 and parameters: {'n_hidden': 3, 'learning_rate': 0.024113879486054188, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2655399844158401, 'dropout_rate_Layer_2': 0.04472208844283148, 'dropout_rate_Layer_3': 0.09284340565980037, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6211862924496288e-05, 'l1_Layer_2': 0.010582965845219176, 'l1_Layer_3': 0.0013894796304817518, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 135}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 8.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.00 | sMAPE for Test Set is: 8.29% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:15:04,002]\u001b[0m Trial 1269 finished with value: 3.7623668397072314 and parameters: {'n_hidden': 3, 'learning_rate': 0.017630278647959085, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3055437816725359, 'dropout_rate_Layer_2': 0.05756619497183119, 'dropout_rate_Layer_3': 0.09143447622701545, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.913945741229191e-05, 'l1_Layer_2': 0.0016405975200772377, 'l1_Layer_3': 0.0008997166263257397, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 7.90% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 8.69% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:15:13,951]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:15:20,882]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:15:26,684]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:15:30,359]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:15:34,318]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:15:47,591]\u001b[0m Trial 1271 finished with value: 4.274624673676446 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012986415385491802, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3502600658401972, 'dropout_rate_Layer_2': 0.17497149635325018, 'dropout_rate_Layer_3': 0.17552251993235082, 'dropout_rate_Layer_4': 0.2377276143093941, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0021090642079582334, 'l1_Layer_2': 0.0117244394440007, 'l1_Layer_3': 0.00012717358931503076, 'l1_Layer_4': 1.6003043020075714e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 65, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 8.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 9.24% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:15:50,879]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:15:58,088]\u001b[0m Trial 1272 finished with value: 4.331132820411768 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012109140442752055, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3515210114234572, 'dropout_rate_Layer_2': 0.18398698712904976, 'dropout_rate_Layer_3': 0.18120694546208269, 'dropout_rate_Layer_4': 0.23704338497852936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002075556569427305, 'l1_Layer_2': 0.012466873969718567, 'l1_Layer_3': 0.00012840664698822207, 'l1_Layer_4': 1.6293678683845686e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 9.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.60 | sMAPE for Test Set is: 9.44% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:16:04,382]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:16:07,909]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:16:20,189]\u001b[0m Trial 1278 finished with value: 3.855061491268307 and parameters: {'n_hidden': 3, 'learning_rate': 0.017416877398167076, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32213247825082625, 'dropout_rate_Layer_2': 0.28227132319430176, 'dropout_rate_Layer_3': 0.07586742459258712, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.00777456350878e-05, 'l1_Layer_2': 0.0017278311649113153, 'l1_Layer_3': 0.0008773891037570763, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 8.09% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.11 | sMAPE for Test Set is: 8.58% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:16:27,625]\u001b[0m Trial 1265 finished with value: 4.314587655564704 and parameters: {'n_hidden': 3, 'learning_rate': 0.00471074323422595, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23581716989984064, 'dropout_rate_Layer_2': 0.04678253536351086, 'dropout_rate_Layer_3': 0.20479173326626748, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.000441297316846011, 'l1_Layer_2': 0.0022271485590528227, 'l1_Layer_3': 0.030376851773748385, 'n_units_Layer_1': 300, 'n_units_Layer_2': 165, 'n_units_Layer_3': 65}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 8.80% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 9.48% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:16:32,200]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:16:37,941]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:16:44,471]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:16:52,453]\u001b[0m Trial 1279 finished with value: 4.29625997442995 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013004283979969054, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34933969091641276, 'dropout_rate_Layer_2': 0.18601356073184536, 'dropout_rate_Layer_3': 0.17244116097595985, 'dropout_rate_Layer_4': 0.23587938522318483, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0020832908338487438, 'l1_Layer_2': 0.010699307435162488, 'l1_Layer_3': 0.00013326466668431712, 'l1_Layer_4': 1.2302308767896195e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 8.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.10% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:16:56,844]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:16:59,768]\u001b[0m Trial 1282 finished with value: 4.2269603383563314 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012512415217956008, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3520999528275422, 'dropout_rate_Layer_2': 0.18322619832548692, 'dropout_rate_Layer_3': 0.17534468625102617, 'dropout_rate_Layer_4': 0.2366443238949468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0022315827049247503, 'l1_Layer_2': 0.012438654241461518, 'l1_Layer_3': 0.00013817765363126463, 'l1_Layer_4': 1.1239063404504756e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 8.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 9.18% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:17:03,222]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:04,552]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:11,645]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:11,861]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:11,991]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:20,922]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:22,200]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:22,433]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:25,536]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:26,770]\u001b[0m Trial 1283 finished with value: 4.275331445113242 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012862861656501275, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3457410437144645, 'dropout_rate_Layer_2': 0.183425302753684, 'dropout_rate_Layer_3': 0.17806914152808834, 'dropout_rate_Layer_4': 0.23922593423087943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002246801359801598, 'l1_Layer_2': 0.011048286041253916, 'l1_Layer_3': 0.0001313882419767318, 'l1_Layer_4': 1.0119631229393317e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 65, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 8.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 9.63% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:17:36,702]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:38,778]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:39,237]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:47,850]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:51,142]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:17:55,037]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:18:04,752]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:18:09,079]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:18:09,300]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:18:18,270]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:18:22,264]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:18:28,787]\u001b[0m Trial 1302 finished with value: 4.360777249132011 and parameters: {'n_hidden': 4, 'learning_rate': 0.001373734700572603, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.350103969485157, 'dropout_rate_Layer_2': 0.18211193818103721, 'dropout_rate_Layer_3': 0.16061961133216968, 'dropout_rate_Layer_4': 0.22787652926744617, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002062397425007727, 'l1_Layer_2': 0.010498874762305826, 'l1_Layer_3': 0.00017399370642718858, 'l1_Layer_4': 1.1132566848929562e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 295, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 8.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 10.05% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:18:31,850]\u001b[0m Trial 1301 finished with value: 4.269910283568185 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012726061906913294, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3461175928405103, 'dropout_rate_Layer_2': 0.18352454570359503, 'dropout_rate_Layer_3': 0.16828956443983278, 'dropout_rate_Layer_4': 0.22139612574723944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001975307214511391, 'l1_Layer_2': 0.012651329689086322, 'l1_Layer_3': 0.00016829285845690393, 'l1_Layer_4': 1.0236499597123276e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 295, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 8.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.09% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:18:32,886]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:18:35,165]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:18:38,748]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:19:03,654]\u001b[0m Trial 1314 finished with value: 4.3472897598596925 and parameters: {'n_hidden': 4, 'learning_rate': 0.001297320934124359, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3511626310578706, 'dropout_rate_Layer_2': 0.1888281417161247, 'dropout_rate_Layer_3': 0.16205300315486987, 'dropout_rate_Layer_4': 0.2405550628003254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0019794785083464637, 'l1_Layer_2': 0.0116717522582944, 'l1_Layer_3': 0.00017743172455484383, 'l1_Layer_4': 1.0064166867257055e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 65, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 8.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.49 | sMAPE for Test Set is: 9.29% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:19:04,561]\u001b[0m Trial 1311 finished with value: 4.246707212014794 and parameters: {'n_hidden': 4, 'learning_rate': 0.001269951409972746, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34666356118576763, 'dropout_rate_Layer_2': 0.1905980875335883, 'dropout_rate_Layer_3': 0.17952218377131274, 'dropout_rate_Layer_4': 0.22478733224806177, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0026685647684594914, 'l1_Layer_2': 0.011412599399269434, 'l1_Layer_3': 0.00012988573656786613, 'l1_Layer_4': 1.1996645538232752e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300, 'n_units_Layer_4': 290}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 8.74% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.34 | sMAPE for Test Set is: 8.92% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:19:10,868]\u001b[0m Trial 1316 finished with value: 4.26270608360763 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012616168897339457, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3572464452803067, 'dropout_rate_Layer_2': 0.1897747175926779, 'dropout_rate_Layer_3': 0.16392009269155725, 'dropout_rate_Layer_4': 0.2413489484556507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0027006167919662117, 'l1_Layer_2': 0.011042571365483657, 'l1_Layer_3': 0.00017092599018675499, 'l1_Layer_4': 1.041304679029891e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 8.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.33 | sMAPE for Test Set is: 8.97% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:19:17,949]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:19:19,038]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:19:23,730]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:19:25,272]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:19:30,026]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:19:35,644]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:19:39,892]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:19:54,545]\u001b[0m Trial 1323 finished with value: 3.7745939971659213 and parameters: {'n_hidden': 3, 'learning_rate': 0.011695946067747773, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29412234654520064, 'dropout_rate_Layer_2': 0.06003538987629586, 'dropout_rate_Layer_3': 0.04640683207037968, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.01860373543173e-05, 'l1_Layer_2': 0.001400728154371746, 'l1_Layer_3': 0.0007301302699797865, 'n_units_Layer_1': 55, 'n_units_Layer_2': 180, 'n_units_Layer_3': 110}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 7.97% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 8.14% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:19:57,024]\u001b[0m Trial 1317 finished with value: 4.362906016242349 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012930632943697678, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3564419465990146, 'dropout_rate_Layer_2': 0.19033327461732022, 'dropout_rate_Layer_3': 0.16188056317339594, 'dropout_rate_Layer_4': 0.24032441426561685, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002475517526148138, 'l1_Layer_2': 0.014034172233950572, 'l1_Layer_3': 0.00017276058480695874, 'l1_Layer_4': 1.0518255294110889e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 9.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 9.35% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:19:59,189]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:20:04,051]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:20:07,865]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:20:13,226]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:20:16,769]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:20:20,633]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:20:24,399]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:20:42,573]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:20:48,626]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:20:53,547]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:20:58,184]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:21:28,451]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:21:31,958]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:21:33,013]\u001b[0m Trial 1337 finished with value: 4.277809482300082 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011458709461957886, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3441710329442645, 'dropout_rate_Layer_2': 0.19377945832416718, 'dropout_rate_Layer_3': 0.15271959139965108, 'dropout_rate_Layer_4': 0.23502893980550016, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0020138478672891533, 'l1_Layer_2': 0.014116873395738198, 'l1_Layer_3': 0.00017639006695764782, 'l1_Layer_4': 1.4929589417101729e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 300, 'n_units_Layer_4': 290}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 8.84% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 9.29% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:22:23,248]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:22:29,869]\u001b[0m Trial 1340 finished with value: 3.759042993843888 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007632830236935123, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08529082990884776, 'dropout_rate_Layer_2': 0.16181479288714035, 'dropout_rate_Layer_3': 0.16240485301612875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.095747904733934e-05, 'l1_Layer_2': 6.549007900465029e-05, 'l1_Layer_3': 0.003494552486895702, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295}. Best is trial 877 with value: 3.6957522657374873.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 8.01% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.81 | sMAPE for Test Set is: 8.05% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:22:36,239]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:22:46,524]\u001b[0m Trial 1341 finished with value: 3.691912178389409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007974340357211899, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09365934892844943, 'dropout_rate_Layer_2': 0.15203510570798748, 'dropout_rate_Layer_3': 0.3569755416099918, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.390291353262361e-05, 'l1_Layer_2': 6.902257582718225e-05, 'l1_Layer_3': 0.0033113742839737986, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.83% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.91 | sMAPE for Test Set is: 8.14% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:23:17,457]\u001b[0m Trial 1345 finished with value: 3.9682324188070806 and parameters: {'n_hidden': 3, 'learning_rate': 0.00068071403092726, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09458450095687483, 'dropout_rate_Layer_2': 0.15234076809986247, 'dropout_rate_Layer_3': 0.39512073267341224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.376243585447644e-05, 'l1_Layer_2': 7.013249708167324e-05, 'l1_Layer_3': 0.003537588714694107, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 8.47% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.01 | sMAPE for Test Set is: 8.46% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:23:26,739]\u001b[0m Trial 1344 finished with value: 3.855511423950977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007718944623705786, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09547045544783392, 'dropout_rate_Layer_2': 0.1505603058905587, 'dropout_rate_Layer_3': 0.1592829086191831, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.183102901706636e-05, 'l1_Layer_2': 7.141293636552799e-05, 'l1_Layer_3': 0.0032306862504289427, 'n_units_Layer_1': 160, 'n_units_Layer_2': 220, 'n_units_Layer_3': 300}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 8.25% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.16 | sMAPE for Test Set is: 8.61% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:23:33,695]\u001b[0m Trial 1346 finished with value: 3.7643848571475433 and parameters: {'n_hidden': 3, 'learning_rate': 0.000688289735074987, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0831726694757478, 'dropout_rate_Layer_2': 0.14782153159411002, 'dropout_rate_Layer_3': 0.39222703002499415, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.351302835150184e-05, 'l1_Layer_2': 6.904925028857053e-05, 'l1_Layer_3': 0.0035056669736284406, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 8.00% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 8.72% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:23:56,553]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:24:22,754]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:24:26,420]\u001b[0m Trial 1349 finished with value: 4.2869859459147115 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011243781050471948, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3683309726606337, 'dropout_rate_Layer_2': 0.18704227448519417, 'dropout_rate_Layer_3': 0.15775941849387373, 'dropout_rate_Layer_4': 0.23753346301105538, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0019702376855978525, 'l1_Layer_2': 0.012721465376372358, 'l1_Layer_3': 0.00016550937092418052, 'l1_Layer_4': 1.4926960698255249e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300, 'n_units_Layer_4': 290}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 8.91% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 9.70% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:24:30,453]\u001b[0m Trial 1328 finished with value: 4.340374057590407 and parameters: {'n_hidden': 3, 'learning_rate': 0.006013030523819082, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19425516080692906, 'dropout_rate_Layer_2': 0.059718589288086064, 'dropout_rate_Layer_3': 0.19002969558864669, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00032013316256683576, 'l1_Layer_2': 0.0035805414987311983, 'l1_Layer_3': 0.03802211260359584, 'n_units_Layer_1': 240, 'n_units_Layer_2': 175, 'n_units_Layer_3': 50}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 8.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 9.34% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:24:39,615]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:24:44,690]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:24:58,810]\u001b[0m Trial 1350 finished with value: 3.825291165026872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005343580227704419, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0877363256569733, 'dropout_rate_Layer_2': 0.1461138230521064, 'dropout_rate_Layer_3': 0.39234513770478907, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.385273891681976e-05, 'l1_Layer_2': 7.370086048229438e-05, 'l1_Layer_3': 0.00352604787280711, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 8.11% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 8.30% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:25:03,578]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:25:04,019]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:25:16,017]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:25:26,569]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:25:30,016]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:25:41,221]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:25:45,357]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:25:50,226]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:25:59,511]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:26:04,752]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:26:06,837]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:26:18,213]\u001b[0m Trial 1361 finished with value: 4.3711439477797995 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014378923214582267, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33520192546612415, 'dropout_rate_Layer_2': 0.19277307997491785, 'dropout_rate_Layer_3': 0.19224822477770276, 'dropout_rate_Layer_4': 0.21617121789455104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0031730402339584783, 'l1_Layer_2': 0.012067530115460757, 'l1_Layer_3': 0.0001555587996441645, 'l1_Layer_4': 1.2658281363835954e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 8.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 9.22% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:26:42,420]\u001b[0m Trial 1362 finished with value: 3.7449151484659935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005667274412219595, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09606600688447393, 'dropout_rate_Layer_2': 0.13428378047411976, 'dropout_rate_Layer_3': 0.3936493826239808, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.0093691164009925e-05, 'l1_Layer_2': 7.623658025876514e-05, 'l1_Layer_3': 0.0041577667632014936, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.85 | sMAPE for Test Set is: 8.02% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:26:52,194]\u001b[0m Trial 1367 finished with value: 3.7513251137422667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006668599431245913, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0987776565945429, 'dropout_rate_Layer_2': 0.13103130208828548, 'dropout_rate_Layer_3': 0.3876299226630435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010307581657951547, 'l1_Layer_2': 8.437039320936524e-05, 'l1_Layer_3': 0.004678066546403669, 'n_units_Layer_1': 165, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.97% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.89 | sMAPE for Test Set is: 8.14% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:26:58,308]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:27:02,877]\u001b[0m Trial 1366 finished with value: 4.335945615004783 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013234714309434434, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36063485270144563, 'dropout_rate_Layer_2': 0.20411210198543683, 'dropout_rate_Layer_3': 0.1935564396663241, 'dropout_rate_Layer_4': 0.23441521627884762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0024374229707799914, 'l1_Layer_2': 0.011776701984333247, 'l1_Layer_3': 0.00023357702026168418, 'l1_Layer_4': 1.257666304072548e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 75, 'n_units_Layer_3': 295, 'n_units_Layer_4': 300}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 8.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 9.98% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:27:12,189]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:27:14,953]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:27:20,947]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:27:24,793]\u001b[0m Trial 1368 finished with value: 4.057887887399734 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010700130031041182, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3598174485098772, 'dropout_rate_Layer_2': 0.1848580726582026, 'dropout_rate_Layer_3': 0.14131875965693844, 'dropout_rate_Layer_4': 0.2341939580551956, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0017916130332395943, 'l1_Layer_2': 0.009227345119515892, 'l1_Layer_3': 0.0002341833049851229, 'l1_Layer_4': 1.2217488241823929e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 295, 'n_units_Layer_4': 300}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 8.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 9.06% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:27:31,405]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:27:34,689]\u001b[0m Trial 1371 finished with value: 3.857736554070336 and parameters: {'n_hidden': 3, 'learning_rate': 0.015642223010821577, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3073498802109289, 'dropout_rate_Layer_2': 0.06060815604660876, 'dropout_rate_Layer_3': 0.03468442607095009, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.582486554796209e-05, 'l1_Layer_2': 0.0014892259485349952, 'l1_Layer_3': 0.0006854373995939491, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 110}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 8.06% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 8.81% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:28:04,251]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:28:04,438]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 8.08% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.06 | sMAPE for Test Set is: 8.43% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:28:09,329]\u001b[0m Trial 1374 finished with value: 3.793264813165646 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006350951140254609, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08159460004237357, 'dropout_rate_Layer_2': 0.11822217474293988, 'dropout_rate_Layer_3': 0.37463009649283424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.2568385441601544e-05, 'l1_Layer_2': 8.599437595337815e-05, 'l1_Layer_3': 0.004940563400621129, 'n_units_Layer_1': 170, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:28:15,455]\u001b[0m Trial 1375 finished with value: 3.7996964889487295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006358697567210187, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10483562148389772, 'dropout_rate_Layer_2': 0.13454983917258673, 'dropout_rate_Layer_3': 0.39024977624181556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010241339357972805, 'l1_Layer_2': 9.014915305097788e-05, 'l1_Layer_3': 0.005937951077367807, 'n_units_Layer_1': 165, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 8.02% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.91 | sMAPE for Test Set is: 8.13% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:28:22,452]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:28:29,266]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:28:50,588]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:12,926]\u001b[0m Trial 1383 finished with value: 4.746755281569128 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010393668270918855, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3689183960966375, 'dropout_rate_Layer_2': 0.17445653964901683, 'dropout_rate_Layer_3': 0.14902468867915497, 'dropout_rate_Layer_4': 0.25070909155714816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002628025810440423, 'l1_Layer_2': 0.014516045580855124, 'l1_Layer_3': 0.0001169648398122196, 'l1_Layer_4': 1.7818792646610245e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 9.78% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 9.62% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:29:25,326]\u001b[0m Trial 1382 finished with value: 4.294973563863801 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010799373801004032, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3680469972510956, 'dropout_rate_Layer_2': 0.1759224936674223, 'dropout_rate_Layer_3': 0.1916033808193142, 'dropout_rate_Layer_4': 0.22485841029077647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0026869207996736985, 'l1_Layer_2': 0.009359085177711121, 'l1_Layer_3': 0.00014402082305445558, 'l1_Layer_4': 1.8657128657739665e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 90, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 8.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 8.96% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:29:28,709]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:30,850]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:34,219]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:39,952]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:52,145]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:55,028]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:30:07,538]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:30:23,113]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:30:24,965]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:30:42,137]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:30:48,429]\u001b[0m Trial 1391 finished with value: 4.226242301224331 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010098599355081285, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3617364690355842, 'dropout_rate_Layer_2': 0.1971771835712285, 'dropout_rate_Layer_3': 0.1785568958532328, 'dropout_rate_Layer_4': 0.22358832194397507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0037932530470777192, 'l1_Layer_2': 0.007323027843195316, 'l1_Layer_3': 0.00014143716436029963, 'l1_Layer_4': 2.0245692203626744e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 290, 'n_units_Layer_4': 300}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 8.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 9.11% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:30:49,160]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:30:50,344]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:30:58,745]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:31:05,105]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:31:10,035]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:31:39,504]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:31:42,990]\u001b[0m Trial 1401 finished with value: 4.077416895732311 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010132384418345029, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34405956760209355, 'dropout_rate_Layer_2': 0.18582121516115757, 'dropout_rate_Layer_3': 0.17112364877150152, 'dropout_rate_Layer_4': 0.22947565521707539, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0013400735420574772, 'l1_Layer_2': 0.009527695208757018, 'l1_Layer_3': 0.0001164374684319773, 'l1_Layer_4': 1.953412666720233e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 60, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 8.46% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.27 | sMAPE for Test Set is: 8.74% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:31:44,063]\u001b[0m Trial 1403 finished with value: 3.7446156319559623 and parameters: {'n_hidden': 3, 'learning_rate': 0.009550726307583003, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3230606072079421, 'dropout_rate_Layer_2': 0.07525969446594738, 'dropout_rate_Layer_3': 0.08990647384726848, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.275055710762114e-05, 'l1_Layer_2': 0.0020633889642625684, 'l1_Layer_3': 0.00029187437793780574, 'n_units_Layer_1': 55, 'n_units_Layer_2': 185, 'n_units_Layer_3': 125}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.86% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 8.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:31:44,508]\u001b[0m Trial 1398 finished with value: 3.7972360048524934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006134571417660354, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0782289666728851, 'dropout_rate_Layer_2': 0.12884960044422164, 'dropout_rate_Layer_3': 0.39202657877378616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.650149442662105e-05, 'l1_Layer_2': 7.764616958366571e-05, 'l1_Layer_3': 0.004081816588585433, 'n_units_Layer_1': 175, 'n_units_Layer_2': 220, 'n_units_Layer_3': 300}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 8.07% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.02 | sMAPE for Test Set is: 8.31% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:31:59,920]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:32:15,135]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:32:28,326]\u001b[0m Trial 1405 finished with value: 4.114685263682566 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009809846309541022, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3426339690016604, 'dropout_rate_Layer_2': 0.19235578068915268, 'dropout_rate_Layer_3': 0.17006562965724503, 'dropout_rate_Layer_4': 0.19791574598163653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0036112753408434886, 'l1_Layer_2': 0.0071503027785303885, 'l1_Layer_3': 0.00012504686596701643, 'l1_Layer_4': 1.9328683640693255e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 285, 'n_units_Layer_4': 290}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 8.56% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 8.72% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:32:46,846]\u001b[0m Trial 1404 finished with value: 3.6981708536556526 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007216832224279851, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10070422008871502, 'dropout_rate_Layer_2': 0.128212693533151, 'dropout_rate_Layer_3': 0.39068262640334217, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011251691450206536, 'l1_Layer_2': 9.742189262920954e-05, 'l1_Layer_3': 0.003000752069563774, 'n_units_Layer_1': 165, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 1341 with value: 3.691912178389409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.89% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.91 | sMAPE for Test Set is: 8.16% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:32:58,902]\u001b[0m Trial 1406 finished with value: 3.685969537960528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007044810775594498, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0984512598902291, 'dropout_rate_Layer_2': 0.12827100974311365, 'dropout_rate_Layer_3': 0.3896624135764022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001256321738839545, 'l1_Layer_2': 6.73299133725512e-05, 'l1_Layer_3': 0.0030868582855432974, 'n_units_Layer_1': 170, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 1406 with value: 3.685969537960528.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.82% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.68 | sMAPE for Test Set is: 7.73% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:33:31,347]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:33:37,996]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.89% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.82 | sMAPE for Test Set is: 7.97% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:33:40,041]\u001b[0m Trial 1410 finished with value: 3.717089459882768 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007382267270203588, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09732981574764529, 'dropout_rate_Layer_2': 0.11752821158023077, 'dropout_rate_Layer_3': 0.3994535267674243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.287646476932101e-05, 'l1_Layer_2': 6.87478590247347e-05, 'l1_Layer_3': 0.0032617627190138893, 'n_units_Layer_1': 160, 'n_units_Layer_2': 230, 'n_units_Layer_3': 300}. Best is trial 1406 with value: 3.685969537960528.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:33:58,585]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:34:02,141]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:34:11,062]\u001b[0m Trial 1411 finished with value: 3.67390991071527 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007167556340011003, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09619642191780232, 'dropout_rate_Layer_2': 0.10585308681878454, 'dropout_rate_Layer_3': 0.3712072350678022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001427359820231888, 'l1_Layer_2': 6.770917809690358e-05, 'l1_Layer_3': 0.0029819610617667367, 'n_units_Layer_1': 165, 'n_units_Layer_2': 215, 'n_units_Layer_3': 300}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 7.78% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.69 | sMAPE for Test Set is: 7.74% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:34:18,147]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:34:28,005]\u001b[0m Trial 1409 finished with value: 4.336290412206668 and parameters: {'n_hidden': 3, 'learning_rate': 0.005441145257051808, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22438688395500866, 'dropout_rate_Layer_2': 0.0637946297192192, 'dropout_rate_Layer_3': 0.20842599869337228, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00023433392980776204, 'l1_Layer_2': 0.0014614388660254332, 'l1_Layer_3': 0.017652751773026665, 'n_units_Layer_1': 250, 'n_units_Layer_2': 170, 'n_units_Layer_3': 60}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 8.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 9.62% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:34:38,140]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:34:52,453]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:35:05,042]\u001b[0m Trial 1418 finished with value: 3.7246086847759927 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007373837503720736, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10301412863030969, 'dropout_rate_Layer_2': 0.10048115441973732, 'dropout_rate_Layer_3': 0.37105780285215845, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011882207326020817, 'l1_Layer_2': 6.596203665533982e-05, 'l1_Layer_3': 0.004161661420280013, 'n_units_Layer_1': 165, 'n_units_Layer_2': 215, 'n_units_Layer_3': 300}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.91% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.80 | sMAPE for Test Set is: 7.97% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:35:10,531]\u001b[0m Trial 1419 finished with value: 3.9579232049920705 and parameters: {'n_hidden': 3, 'learning_rate': 0.01345290840060134, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2729553893118257, 'dropout_rate_Layer_2': 0.06839769485527405, 'dropout_rate_Layer_3': 0.022869788544436692, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3527122125629037e-05, 'l1_Layer_2': 0.0018933870002179492, 'l1_Layer_3': 0.0004147726824659108, 'n_units_Layer_1': 70, 'n_units_Layer_2': 180, 'n_units_Layer_3': 125}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 8.19% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.47 | sMAPE for Test Set is: 8.98% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:35:15,103]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:35:20,171]\u001b[0m Trial 1420 finished with value: 3.773182810635984 and parameters: {'n_hidden': 3, 'learning_rate': 0.000736934019438599, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10662797320002147, 'dropout_rate_Layer_2': 0.10229348355402428, 'dropout_rate_Layer_3': 0.3707722163941366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011962719041394221, 'l1_Layer_2': 6.610826090269395e-05, 'l1_Layer_3': 0.0040337379196373115, 'n_units_Layer_1': 165, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 8.00% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 8.20% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:35:24,907]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:35:34,011]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:35:38,598]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:35:42,469]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:35:44,241]\u001b[0m Trial 1422 finished with value: 4.223747233767305 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010457316067511025, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34335377820357954, 'dropout_rate_Layer_2': 0.1881781885696556, 'dropout_rate_Layer_3': 0.15529759800610515, 'dropout_rate_Layer_4': 0.22516894361347695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003613441638778014, 'l1_Layer_2': 0.00887413244230917, 'l1_Layer_3': 0.0001188939008539718, 'l1_Layer_4': 2.0164766081130754e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 60, 'n_units_Layer_3': 285, 'n_units_Layer_4': 290}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 8.69% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 9.19% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:35:55,553]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:36:01,116]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:36:10,093]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:36:22,116]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:36:32,646]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:36:33,681]\u001b[0m Trial 1428 finished with value: 4.1354917915617735 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010232923871955643, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.333895855428354, 'dropout_rate_Layer_2': 0.17248402485609338, 'dropout_rate_Layer_3': 0.15471146795323665, 'dropout_rate_Layer_4': 0.23061125112732933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0035915452958670433, 'l1_Layer_2': 0.007101726509968026, 'l1_Layer_3': 0.00014176852281845757, 'l1_Layer_4': 2.0180747199482297e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 60, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 8.47% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.31 | sMAPE for Test Set is: 8.86% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:36:43,946]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:36:50,191]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:36:53,992]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:37:03,039]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:37:05,842]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:37:08,449]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:37:24,940]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:37:31,381]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:37:35,168]\u001b[0m Trial 1441 finished with value: 3.7707619088011306 and parameters: {'n_hidden': 3, 'learning_rate': 0.04134596964986437, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30150229928777805, 'dropout_rate_Layer_2': 0.0003031060094423263, 'dropout_rate_Layer_3': 0.08764696650522803, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.7605833120244805e-05, 'l1_Layer_2': 0.005962390671703954, 'l1_Layer_3': 0.0010611860582344656, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 125}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 7.88% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 8.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:37:36,303]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:37:43,707]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:37:51,159]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:37:59,825]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:38:23,431]\u001b[0m Trial 1446 finished with value: 4.186635953159084 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009301582751869229, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33462467902682214, 'dropout_rate_Layer_2': 0.17031195179793648, 'dropout_rate_Layer_3': 0.1753414473595153, 'dropout_rate_Layer_4': 0.230966492195051, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0034784887507246605, 'l1_Layer_2': 0.007584211372384061, 'l1_Layer_3': 0.00013861896488068373, 'l1_Layer_4': 1.4194535484596236e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 65, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 8.65% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 9.22% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:38:38,930]\u001b[0m Trial 1448 finished with value: 3.7777809120911683 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006828746333765581, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09838680381388422, 'dropout_rate_Layer_2': 0.11086765580425262, 'dropout_rate_Layer_3': 0.39844926622659854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.640992041995902e-05, 'l1_Layer_2': 8.896526194523983e-05, 'l1_Layer_3': 0.004700540685597303, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 8.00% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.86 | sMAPE for Test Set is: 8.04% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:38:43,813]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:38:57,579]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:38:57,616]\u001b[0m Trial 1450 finished with value: 3.762569735924847 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007109574099092399, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09817762566163397, 'dropout_rate_Layer_2': 0.1024922128808581, 'dropout_rate_Layer_3': 0.3992681249645248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010476571607207122, 'l1_Layer_2': 9.028974410881637e-05, 'l1_Layer_3': 0.00457033150302844, 'n_units_Layer_1': 165, 'n_units_Layer_2': 230, 'n_units_Layer_3': 300}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 7.99% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 8.29% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:39:06,922]\u001b[0m Trial 1449 finished with value: 3.753369593540383 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007062539625836386, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09555880689910601, 'dropout_rate_Layer_2': 0.11261020568054808, 'dropout_rate_Layer_3': 0.3982904084967619, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.821951635807563e-05, 'l1_Layer_2': 8.840147932012332e-05, 'l1_Layer_3': 0.005717834222922015, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.86 | sMAPE for Test Set is: 8.04% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:39:12,271]\u001b[0m Trial 1453 finished with value: 4.64098519360775 and parameters: {'n_hidden': 4, 'learning_rate': 0.001000110942748841, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3310165083626677, 'dropout_rate_Layer_2': 0.19476162950249487, 'dropout_rate_Layer_3': 0.1677174303672706, 'dropout_rate_Layer_4': 0.21660824553932126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0031181761917905395, 'l1_Layer_2': 0.015617064995693401, 'l1_Layer_3': 0.00014792940218641748, 'l1_Layer_4': 1.0019143533504408e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 65, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 9.63% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 9.34% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:39:17,219]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:39:17,726]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:39:26,136]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:39:30,511]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:39:30,980]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:40:09,143]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:40:23,448]\u001b[0m Trial 1456 finished with value: 4.504080277155231 and parameters: {'n_hidden': 3, 'learning_rate': 0.006987495756965, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2070761250067192, 'dropout_rate_Layer_2': 0.0553172169536382, 'dropout_rate_Layer_3': 0.1986842103211733, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005710155655320472, 'l1_Layer_2': 0.0010468334565354007, 'l1_Layer_3': 0.01794994153939625, 'n_units_Layer_1': 300, 'n_units_Layer_2': 155, 'n_units_Layer_3': 60}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 9.08% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.84 | sMAPE for Test Set is: 9.80% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:40:31,930]\u001b[0m Trial 1460 finished with value: 4.224320302866469 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009585854483105617, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34760729316187816, 'dropout_rate_Layer_2': 0.17557744158024918, 'dropout_rate_Layer_3': 0.15376012575006698, 'dropout_rate_Layer_4': 0.20427563450380923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0028850231886081022, 'l1_Layer_2': 0.006371450662685494, 'l1_Layer_3': 0.00014150175631603377, 'l1_Layer_4': 1.3910944150948211e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 55, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 8.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 9.31% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:40:32,821]\u001b[0m Trial 1461 finished with value: 4.185508001698684 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009676270852608117, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3224777727397467, 'dropout_rate_Layer_2': 0.20568741578096272, 'dropout_rate_Layer_3': 0.15097003267440398, 'dropout_rate_Layer_4': 0.21850589823028935, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0028763923801266265, 'l1_Layer_2': 0.006552454104781966, 'l1_Layer_3': 0.00014299993528958506, 'l1_Layer_4': 1.3971599569811174e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 55, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 8.60% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.96 | sMAPE for Test Set is: 9.94% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:40:52,121]\u001b[0m Trial 1463 finished with value: 4.146576811223945 and parameters: {'n_hidden': 4, 'learning_rate': 0.000938879629267114, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32221941046017033, 'dropout_rate_Layer_2': 0.20251051021346642, 'dropout_rate_Layer_3': 0.1463434768577835, 'dropout_rate_Layer_4': 0.22210304461290906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003030331399929863, 'l1_Layer_2': 0.006518694378812099, 'l1_Layer_3': 0.00014357821534584155, 'l1_Layer_4': 1.4552070848775376e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 8.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 9.04% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:40:56,923]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:41:01,946]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:41:05,685]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:41:08,998]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:41:14,933]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:41:22,284]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:41:31,544]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:41:36,070]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:41:45,581]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:41:48,941]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:42:05,668]\u001b[0m Trial 1471 finished with value: 4.177186570629284 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009279653882392059, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32120022103747486, 'dropout_rate_Layer_2': 0.21393077886143694, 'dropout_rate_Layer_3': 0.14504368653240343, 'dropout_rate_Layer_4': 0.20080675579707402, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003286999491563336, 'l1_Layer_2': 0.0066902407808645745, 'l1_Layer_3': 0.0001871357102632997, 'l1_Layer_4': 1.473374033865449e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275, 'n_units_Layer_4': 295}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 8.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.58 | sMAPE for Test Set is: 9.38% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:42:12,645]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:42:15,971]\u001b[0m Trial 1477 finished with value: 3.936146139867701 and parameters: {'n_hidden': 3, 'learning_rate': 0.051851972058676574, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2860424241773171, 'dropout_rate_Layer_2': 0.020263941323344033, 'dropout_rate_Layer_3': 0.08938262952498385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.074690413679777e-05, 'l1_Layer_2': 0.006648453505282228, 'l1_Layer_3': 0.0007440627336460875, 'n_units_Layer_1': 75, 'n_units_Layer_2': 170, 'n_units_Layer_3': 125}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 8.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 9.67% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:42:24,548]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:42:27,793]\u001b[0m Trial 1474 finished with value: 3.777871293027085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007609173814349862, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07736671532606643, 'dropout_rate_Layer_2': 0.0856146861186726, 'dropout_rate_Layer_3': 0.39903556620906794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.45157410852494e-05, 'l1_Layer_2': 7.989011935843005e-05, 'l1_Layer_3': 0.005900958114119629, 'n_units_Layer_1': 165, 'n_units_Layer_2': 230, 'n_units_Layer_3': 295}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 7.99% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.89 | sMAPE for Test Set is: 8.09% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:42:28,947]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:42:32,845]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:42:47,369]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:42:51,737]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:43:01,200]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:43:04,594]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:43:08,256]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:43:08,798]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:43:09,624]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:43:19,093]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:43:22,652]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:43:29,345]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:43:29,806]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:44:07,354]\u001b[0m Trial 1491 finished with value: 4.166146971153814 and parameters: {'n_hidden': 4, 'learning_rate': 0.000951832749935104, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31366542919623636, 'dropout_rate_Layer_2': 0.20203293880129128, 'dropout_rate_Layer_3': 0.15541868527095334, 'dropout_rate_Layer_4': 0.20193909773407895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003027386985431492, 'l1_Layer_2': 0.007870092906252747, 'l1_Layer_3': 0.0001608167832323174, 'l1_Layer_4': 3.863083549868147e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 55, 'n_units_Layer_3': 275, 'n_units_Layer_4': 300}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 8.64% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.37 | sMAPE for Test Set is: 9.09% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:44:13,539]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:44:25,584]\u001b[0m Trial 1495 finished with value: 4.258935769376809 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009062194648365894, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3409290130850576, 'dropout_rate_Layer_2': 0.19884085103614169, 'dropout_rate_Layer_3': 0.1384772927244287, 'dropout_rate_Layer_4': 0.20809684568684378, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00533629213924253, 'l1_Layer_2': 0.008331487701933768, 'l1_Layer_3': 0.0002324559773159814, 'l1_Layer_4': 2.1874348757940737e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 60, 'n_units_Layer_3': 280, 'n_units_Layer_4': 300}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 8.77% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 9.20% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:44:29,210]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:44:33,900]\u001b[0m Trial 1494 finished with value: 4.129707146312494 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008814515864409843, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34012172973649596, 'dropout_rate_Layer_2': 0.20486485437343244, 'dropout_rate_Layer_3': 0.1577062448809135, 'dropout_rate_Layer_4': 0.19713284620315027, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004165051891133237, 'l1_Layer_2': 0.007671688871032213, 'l1_Layer_3': 0.00010963179331748101, 'l1_Layer_4': 2.9705760142590915e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 60, 'n_units_Layer_3': 280, 'n_units_Layer_4': 300}. Best is trial 1411 with value: 3.67390991071527.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 8.52% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.48 | sMAPE for Test Set is: 9.20% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:44:34,322]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:44:39,536]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:44:48,044]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-01-01, MAE is:6.13 & sMAPE is:77.65% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 77.65% & 0.15\n",
      "for 2018-01-02, MAE is:14.07 & sMAPE is:44.75% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 61.20% & 0.66\n",
      "for 2018-01-03, MAE is:9.80 & sMAPE is:45.57% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 55.99% & 0.94\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018C2FEB7430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:6.89 & sMAPE is:32.54% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 50.13% & 0.87\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018D07C423A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:12.51 & sMAPE is:40.23% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :9.88 & 48.15% & 0.95\n",
      "for 2018-01-06, MAE is:5.36 & sMAPE is:11.83% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :9.13 & 42.10% & 0.87\n",
      "for 2018-01-07, MAE is:12.34 & sMAPE is:30.62% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.59 & 40.46% & 0.81\n",
      "for 2018-01-08, MAE is:11.45 & sMAPE is:19.51% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 37.84% & 0.73\n",
      "for 2018-01-09, MAE is:4.57 & sMAPE is:7.44% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.24 & 34.46% & 0.67\n",
      "for 2018-01-10, MAE is:12.66 & sMAPE is:21.42% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 33.16% & 0.68\n",
      "for 2018-01-11, MAE is:4.12 & sMAPE is:9.12% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.08 & 30.97% & 0.64\n",
      "for 2018-01-12, MAE is:3.97 & sMAPE is:7.85% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 29.04% & 0.61\n",
      "for 2018-01-13, MAE is:1.61 & sMAPE is:2.99% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 27.04% & 0.58\n",
      "for 2018-01-14, MAE is:3.90 & sMAPE is:7.64% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 25.65% & 0.56\n",
      "for 2018-01-15, MAE is:4.46 & sMAPE is:7.43% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 24.44% & 0.56\n",
      "for 2018-01-16, MAE is:3.08 & sMAPE is:6.42% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 23.31% & 0.56\n",
      "for 2018-01-17, MAE is:2.73 & sMAPE is:5.51% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 22.27% & 0.54\n",
      "for 2018-01-18, MAE is:5.44 & sMAPE is:8.95% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 21.53% & 0.56\n",
      "for 2018-01-19, MAE is:3.30 & sMAPE is:5.85% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 20.70% & 0.56\n",
      "for 2018-01-20, MAE is:4.99 & sMAPE is:10.20% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 20.18% & 0.56\n",
      "for 2018-01-21, MAE is:4.51 & sMAPE is:10.46% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 19.71% & 0.56\n",
      "for 2018-01-22, MAE is:4.20 & sMAPE is:7.61% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 19.16% & 0.57\n",
      "for 2018-01-23, MAE is:3.10 & sMAPE is:6.00% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 18.59% & 0.57\n",
      "for 2018-01-24, MAE is:5.35 & sMAPE is:9.11% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 18.20% & 0.58\n",
      "for 2018-01-25, MAE is:4.16 & sMAPE is:7.72% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 17.78% & 0.59\n",
      "for 2018-01-26, MAE is:3.42 & sMAPE is:7.03% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 17.36% & 0.59\n",
      "for 2018-01-27, MAE is:3.48 & sMAPE is:7.10% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 16.98% & 0.60\n",
      "for 2018-01-28, MAE is:3.11 & sMAPE is:6.41% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 16.61% & 0.59\n",
      "for 2018-01-29, MAE is:5.50 & sMAPE is:10.00% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 16.38% & 0.64\n",
      "for 2018-01-30, MAE is:2.18 & sMAPE is:4.28% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 15.97% & 0.64\n",
      "for 2018-01-31, MAE is:3.66 & sMAPE is:6.98% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 15.68% & 0.67\n",
      "for 2018-02-01, MAE is:4.65 & sMAPE is:8.83% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 15.47% & 0.69\n",
      "for 2018-02-02, MAE is:3.67 & sMAPE is:7.56% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 15.23% & 0.71\n",
      "for 2018-02-03, MAE is:4.48 & sMAPE is:9.27% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 15.06% & 0.72\n",
      "for 2018-02-04, MAE is:6.51 & sMAPE is:13.46% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 15.01% & 0.73\n",
      "for 2018-02-05, MAE is:2.81 & sMAPE is:5.12% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 14.73% & 0.75\n",
      "for 2018-02-06, MAE is:3.10 & sMAPE is:5.77% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 14.49% & 0.76\n",
      "for 2018-02-07, MAE is:4.68 & sMAPE is:8.78% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 14.34% & 0.76\n",
      "for 2018-02-08, MAE is:5.53 & sMAPE is:9.43% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 14.22% & 0.76\n",
      "for 2018-02-09, MAE is:3.28 & sMAPE is:5.40% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 14.00% & 0.75\n",
      "for 2018-02-10, MAE is:4.70 & sMAPE is:9.04% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 13.87% & 0.76\n",
      "for 2018-02-11, MAE is:4.90 & sMAPE is:9.59% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 13.77% & 0.77\n",
      "for 2018-02-12, MAE is:4.37 & sMAPE is:7.70% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 13.63% & 0.78\n",
      "for 2018-02-13, MAE is:6.52 & sMAPE is:12.17% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 13.60% & 0.80\n",
      "for 2018-02-14, MAE is:4.23 & sMAPE is:8.64% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 13.49% & 0.80\n",
      "for 2018-02-15, MAE is:7.13 & sMAPE is:13.75% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 13.49% & 0.80\n",
      "for 2018-02-16, MAE is:2.41 & sMAPE is:4.16% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 13.30% & 0.80\n",
      "for 2018-02-17, MAE is:5.76 & sMAPE is:11.16% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 13.25% & 0.81\n",
      "for 2018-02-18, MAE is:3.65 & sMAPE is:7.27% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 13.13% & 0.83\n",
      "for 2018-02-19, MAE is:3.44 & sMAPE is:6.02% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 12.99% & 0.83\n",
      "for 2018-02-20, MAE is:3.92 & sMAPE is:7.62% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 12.88% & 0.84\n",
      "for 2018-02-21, MAE is:5.23 & sMAPE is:10.40% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 12.83% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-22, MAE is:3.41 & sMAPE is:6.70% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 12.72% & 0.86\n",
      "for 2018-02-23, MAE is:2.99 & sMAPE is:5.34% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 12.58% & 0.86\n",
      "for 2018-02-24, MAE is:3.73 & sMAPE is:6.52% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 12.47% & 0.86\n",
      "for 2018-02-25, MAE is:3.71 & sMAPE is:6.60% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 12.37% & 0.85\n",
      "for 2018-02-26, MAE is:2.78 & sMAPE is:4.93% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 12.24% & 0.85\n",
      "for 2018-02-27, MAE is:5.74 & sMAPE is:9.38% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 12.19% & 0.84\n",
      "for 2018-02-28, MAE is:5.52 & sMAPE is:9.06% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 12.13% & 0.84\n",
      "for 2018-03-01, MAE is:5.97 & sMAPE is:11.44% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.12% & 0.85\n",
      "for 2018-03-02, MAE is:7.68 & sMAPE is:15.59% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 12.18% & 0.85\n",
      "for 2018-03-03, MAE is:5.53 & sMAPE is:13.18% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 12.20% & 0.84\n",
      "for 2018-03-04, MAE is:3.27 & sMAPE is:7.33% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 12.12% & 0.83\n",
      "for 2018-03-05, MAE is:8.52 & sMAPE is:18.59% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 12.22% & 0.84\n",
      "for 2018-03-06, MAE is:3.85 & sMAPE is:7.75% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 12.15% & 0.83\n",
      "for 2018-03-07, MAE is:4.29 & sMAPE is:8.52% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 12.10% & 0.83\n",
      "for 2018-03-08, MAE is:4.71 & sMAPE is:9.67% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 12.06% & 0.83\n",
      "for 2018-03-09, MAE is:4.64 & sMAPE is:9.95% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 12.03% & 0.82\n",
      "for 2018-03-10, MAE is:3.63 & sMAPE is:10.39% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 12.00% & 0.82\n",
      "for 2018-03-11, MAE is:23.51 & sMAPE is:126.57% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 13.64% & 0.81\n",
      "for 2018-03-12, MAE is:13.21 & sMAPE is:38.60% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 13.99% & 0.82\n",
      "for 2018-03-13, MAE is:3.87 & sMAPE is:7.89% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 13.91% & 0.82\n",
      "for 2018-03-14, MAE is:8.41 & sMAPE is:23.77% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 14.04% & 0.82\n",
      "for 2018-03-15, MAE is:8.43 & sMAPE is:34.91% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 14.33% & 0.82\n",
      "for 2018-03-16, MAE is:8.17 & sMAPE is:20.23% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 14.40% & 0.84\n",
      "for 2018-03-17, MAE is:8.48 & sMAPE is:20.36% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 14.48% & 0.83\n",
      "for 2018-03-18, MAE is:3.60 & sMAPE is:9.98% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 14.42% & 0.82\n",
      "for 2018-03-19, MAE is:6.52 & sMAPE is:14.54% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 14.43% & 0.82\n",
      "for 2018-03-20, MAE is:7.62 & sMAPE is:18.21% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 14.47% & 0.82\n",
      "for 2018-03-21, MAE is:3.28 & sMAPE is:7.93% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 14.39% & 0.81\n",
      "for 2018-03-22, MAE is:7.08 & sMAPE is:15.02% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 14.40% & 0.81\n",
      "for 2018-03-23, MAE is:4.35 & sMAPE is:9.51% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 14.34% & 0.81\n",
      "for 2018-03-24, MAE is:14.27 & sMAPE is:55.17% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 14.83% & 0.81\n",
      "for 2018-03-25, MAE is:8.31 & sMAPE is:21.55% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 14.91% & 0.83\n",
      "for 2018-03-26, MAE is:4.14 & sMAPE is:8.27% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 14.83% & 0.83\n",
      "for 2018-03-27, MAE is:5.07 & sMAPE is:10.72% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 14.79% & 0.82\n",
      "for 2018-03-28, MAE is:4.32 & sMAPE is:9.84% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 14.73% & 0.82\n",
      "for 2018-03-29, MAE is:12.26 & sMAPE is:40.35% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 15.02% & 0.82\n",
      "for 2018-03-30, MAE is:17.11 & sMAPE is:132.40% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 16.34% & 0.82\n",
      "for 2018-03-31, MAE is:7.32 & sMAPE is:61.38% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 16.84% & 0.81\n",
      "for 2018-04-01, MAE is:4.81 & sMAPE is:18.86% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 16.86% & 0.81\n",
      "for 2018-04-02, MAE is:3.74 & sMAPE is:14.15% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 16.83% & 0.80\n",
      "for 2018-04-03, MAE is:5.05 & sMAPE is:18.21% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 16.85% & 0.80\n",
      "for 2018-04-04, MAE is:4.79 & sMAPE is:15.68% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 16.83% & 0.79\n",
      "for 2018-04-05, MAE is:11.44 & sMAPE is:27.28% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 16.94% & 0.79\n",
      "for 2018-04-06, MAE is:6.57 & sMAPE is:17.65% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 16.95% & 0.78\n",
      "for 2018-04-07, MAE is:7.83 & sMAPE is:19.57% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 16.98% & 0.78\n",
      "for 2018-04-08, MAE is:7.22 & sMAPE is:20.85% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 17.02% & 0.78\n",
      "for 2018-04-09, MAE is:10.44 & sMAPE is:23.53% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 17.08% & 0.78\n",
      "for 2018-04-10, MAE is:3.51 & sMAPE is:8.35% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 17.00% & 0.77\n",
      "for 2018-04-11, MAE is:6.30 & sMAPE is:14.99% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 16.98% & 0.77\n",
      "for 2018-04-12, MAE is:7.89 & sMAPE is:16.75% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 16.97% & 0.77\n",
      "for 2018-04-13, MAE is:10.84 & sMAPE is:20.22% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 17.01% & 0.77\n",
      "for 2018-04-14, MAE is:3.43 & sMAPE is:7.01% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 16.91% & 0.76\n",
      "for 2018-04-15, MAE is:4.26 & sMAPE is:10.76% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 16.85% & 0.76\n",
      "for 2018-04-16, MAE is:4.31 & sMAPE is:9.30% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 16.78% & 0.77\n",
      "for 2018-04-17, MAE is:2.85 & sMAPE is:5.56% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 16.68% & 0.77\n",
      "for 2018-04-18, MAE is:3.96 & sMAPE is:7.87% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 16.59% & 0.76\n",
      "for 2018-04-19, MAE is:4.15 & sMAPE is:8.91% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 16.52% & 0.76\n",
      "for 2018-04-20, MAE is:7.02 & sMAPE is:16.17% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 16.52% & 0.76\n",
      "for 2018-04-21, MAE is:2.00 & sMAPE is:5.22% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 16.42% & 0.75\n",
      "for 2018-04-22, MAE is:2.46 & sMAPE is:6.02% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 16.33% & 0.75\n",
      "for 2018-04-23, MAE is:4.50 & sMAPE is:9.77% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 16.27% & 0.75\n",
      "for 2018-04-24, MAE is:2.65 & sMAPE is:5.82% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 16.18% & 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-25, MAE is:4.68 & sMAPE is:10.30% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 16.12% & 0.75\n",
      "for 2018-04-26, MAE is:7.89 & sMAPE is:18.02% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 16.14% & 0.75\n",
      "for 2018-04-27, MAE is:2.84 & sMAPE is:5.85% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 16.05% & 0.75\n",
      "for 2018-04-28, MAE is:4.70 & sMAPE is:11.16% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 16.01% & 0.75\n",
      "for 2018-04-29, MAE is:14.23 & sMAPE is:52.21% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 16.32% & 0.75\n",
      "for 2018-04-30, MAE is:7.65 & sMAPE is:19.57% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 16.34% & 0.75\n",
      "for 2018-05-01, MAE is:3.64 & sMAPE is:9.10% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 16.28% & 0.75\n",
      "for 2018-05-02, MAE is:5.03 & sMAPE is:11.55% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 16.24% & 0.75\n",
      "for 2018-05-03, MAE is:3.18 & sMAPE is:7.33% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 16.17% & 0.75\n",
      "for 2018-05-04, MAE is:2.75 & sMAPE is:6.59% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 16.09% & 0.75\n",
      "for 2018-05-05, MAE is:4.42 & sMAPE is:9.97% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 16.05% & 0.75\n",
      "for 2018-05-06, MAE is:5.80 & sMAPE is:13.10% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 16.02% & 0.74\n",
      "for 2018-05-07, MAE is:4.52 & sMAPE is:8.70% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 15.96% & 0.74\n",
      "for 2018-05-08, MAE is:4.73 & sMAPE is:8.79% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 15.91% & 0.74\n",
      "for 2018-05-09, MAE is:4.60 & sMAPE is:8.78% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 15.85% & 0.73\n",
      "for 2018-05-10, MAE is:4.39 & sMAPE is:8.46% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 15.80% & 0.73\n",
      "for 2018-05-11, MAE is:2.99 & sMAPE is:5.20% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 15.72% & 0.73\n",
      "for 2018-05-12, MAE is:12.08 & sMAPE is:26.90% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 15.80% & 0.73\n",
      "for 2018-05-13, MAE is:6.38 & sMAPE is:19.76% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 15.83% & 0.73\n",
      "for 2018-05-14, MAE is:2.26 & sMAPE is:4.37% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 15.74% & 0.73\n",
      "for 2018-05-15, MAE is:3.24 & sMAPE is:6.77% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 15.68% & 0.72\n",
      "for 2018-05-16, MAE is:5.69 & sMAPE is:11.30% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 15.65% & 0.73\n",
      "for 2018-05-17, MAE is:3.64 & sMAPE is:7.11% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 15.58% & 0.73\n",
      "for 2018-05-18, MAE is:5.11 & sMAPE is:9.38% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 15.54% & 0.74\n",
      "for 2018-05-19, MAE is:7.53 & sMAPE is:13.38% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 15.52% & 0.74\n",
      "for 2018-05-20, MAE is:4.03 & sMAPE is:7.19% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 15.46% & 0.73\n",
      "for 2018-05-21, MAE is:2.99 & sMAPE is:5.05% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 15.39% & 0.73\n",
      "for 2018-05-22, MAE is:2.90 & sMAPE is:4.54% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 15.31% & 0.73\n",
      "for 2018-05-23, MAE is:3.30 & sMAPE is:5.37% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 15.24% & 0.72\n",
      "for 2018-05-24, MAE is:2.74 & sMAPE is:4.37% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 15.17% & 0.72\n",
      "for 2018-05-25, MAE is:5.04 & sMAPE is:8.34% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 15.12% & 0.72\n",
      "for 2018-05-26, MAE is:3.43 & sMAPE is:5.63% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 15.06% & 0.72\n",
      "for 2018-05-27, MAE is:4.04 & sMAPE is:6.90% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 15.00% & 0.73\n",
      "for 2018-05-28, MAE is:3.95 & sMAPE is:6.52% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 14.94% & 0.73\n",
      "for 2018-05-29, MAE is:4.40 & sMAPE is:7.12% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 14.89% & 0.74\n",
      "for 2018-05-30, MAE is:3.26 & sMAPE is:5.20% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 14.83% & 0.75\n",
      "for 2018-05-31, MAE is:2.35 & sMAPE is:3.85% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 14.75% & 0.75\n",
      "for 2018-06-01, MAE is:3.28 & sMAPE is:5.28% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 14.69% & 0.76\n",
      "for 2018-06-02, MAE is:2.94 & sMAPE is:4.94% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 14.63% & 0.77\n",
      "for 2018-06-03, MAE is:5.83 & sMAPE is:10.53% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 14.60% & 0.77\n",
      "for 2018-06-04, MAE is:2.78 & sMAPE is:4.78% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 14.54% & 0.77\n",
      "for 2018-06-05, MAE is:2.35 & sMAPE is:4.10% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 14.47% & 0.76\n",
      "for 2018-06-06, MAE is:4.85 & sMAPE is:8.24% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 14.43% & 0.77\n",
      "for 2018-06-07, MAE is:4.42 & sMAPE is:7.40% & rMAE is:2.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 14.39% & 0.78\n",
      "for 2018-06-08, MAE is:2.24 & sMAPE is:3.78% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 14.32% & 0.79\n",
      "for 2018-06-09, MAE is:4.26 & sMAPE is:7.57% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 14.28% & 0.79\n",
      "for 2018-06-10, MAE is:1.76 & sMAPE is:3.14% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 14.21% & 0.79\n",
      "for 2018-06-11, MAE is:1.86 & sMAPE is:3.30% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 14.14% & 0.79\n",
      "for 2018-06-12, MAE is:4.63 & sMAPE is:8.32% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 14.10% & 0.79\n",
      "for 2018-06-13, MAE is:2.63 & sMAPE is:5.41% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 14.05% & 0.79\n",
      "for 2018-06-14, MAE is:4.79 & sMAPE is:8.96% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 14.02% & 0.79\n",
      "for 2018-06-15, MAE is:2.68 & sMAPE is:4.78% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 13.97% & 0.79\n",
      "for 2018-06-16, MAE is:1.74 & sMAPE is:3.26% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 13.90% & 0.78\n",
      "for 2018-06-17, MAE is:4.76 & sMAPE is:10.09% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 13.88% & 0.78\n",
      "for 2018-06-18, MAE is:5.04 & sMAPE is:10.13% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 13.86% & 0.78\n",
      "for 2018-06-19, MAE is:3.04 & sMAPE is:5.68% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 13.81% & 0.78\n",
      "for 2018-06-20, MAE is:3.95 & sMAPE is:6.81% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 13.77% & 0.78\n",
      "for 2018-06-21, MAE is:2.45 & sMAPE is:4.07% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 13.71% & 0.78\n",
      "for 2018-06-22, MAE is:3.17 & sMAPE is:5.60% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 13.66% & 0.78\n",
      "for 2018-06-23, MAE is:2.82 & sMAPE is:4.99% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 13.61% & 0.78\n",
      "for 2018-06-24, MAE is:3.35 & sMAPE is:5.91% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 13.57% & 0.78\n",
      "for 2018-06-25, MAE is:1.36 & sMAPE is:2.26% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 13.51% & 0.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-26, MAE is:2.34 & sMAPE is:3.73% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 13.45% & 0.77\n",
      "for 2018-06-27, MAE is:2.10 & sMAPE is:3.44% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 13.39% & 0.78\n",
      "for 2018-06-28, MAE is:1.68 & sMAPE is:2.69% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 13.33% & 0.78\n",
      "for 2018-06-29, MAE is:2.15 & sMAPE is:3.62% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 13.28% & 0.78\n",
      "for 2018-06-30, MAE is:2.58 & sMAPE is:4.43% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 13.23% & 0.78\n",
      "for 2018-07-01, MAE is:3.78 & sMAPE is:6.67% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 13.20% & 0.78\n",
      "for 2018-07-02, MAE is:1.63 & sMAPE is:2.77% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 13.14% & 0.79\n",
      "for 2018-07-03, MAE is:1.52 & sMAPE is:2.49% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 13.08% & 0.79\n",
      "for 2018-07-04, MAE is:2.34 & sMAPE is:3.91% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 13.03% & 0.79\n",
      "for 2018-07-05, MAE is:2.35 & sMAPE is:4.12% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.98% & 0.79\n",
      "for 2018-07-06, MAE is:1.53 & sMAPE is:2.58% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 12.93% & 0.79\n",
      "for 2018-07-07, MAE is:4.76 & sMAPE is:8.28% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 12.90% & 0.80\n",
      "for 2018-07-08, MAE is:2.21 & sMAPE is:3.86% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 12.86% & 0.80\n",
      "for 2018-07-09, MAE is:1.48 & sMAPE is:2.47% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 12.80% & 0.80\n",
      "for 2018-07-10, MAE is:1.37 & sMAPE is:2.29% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 12.75% & 0.80\n",
      "for 2018-07-11, MAE is:2.88 & sMAPE is:4.81% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.70% & 0.80\n",
      "for 2018-07-12, MAE is:3.86 & sMAPE is:6.24% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.67% & 0.80\n",
      "for 2018-07-13, MAE is:3.33 & sMAPE is:5.45% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 12.63% & 0.81\n",
      "for 2018-07-14, MAE is:1.86 & sMAPE is:3.08% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 12.58% & 0.81\n",
      "for 2018-07-15, MAE is:2.94 & sMAPE is:4.97% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 12.55% & 0.81\n",
      "for 2018-07-16, MAE is:3.15 & sMAPE is:5.34% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 12.51% & 0.81\n",
      "for 2018-07-17, MAE is:1.34 & sMAPE is:2.15% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 12.46% & 0.81\n",
      "for 2018-07-18, MAE is:3.94 & sMAPE is:6.42% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 12.43% & 0.81\n",
      "for 2018-07-19, MAE is:1.33 & sMAPE is:2.11% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 12.37% & 0.81\n",
      "for 2018-07-20, MAE is:1.79 & sMAPE is:2.96% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 12.33% & 0.82\n",
      "for 2018-07-21, MAE is:3.68 & sMAPE is:6.23% & rMAE is:2.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 12.30% & 0.82\n",
      "for 2018-07-22, MAE is:1.57 & sMAPE is:2.66% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 12.25% & 0.82\n",
      "for 2018-07-23, MAE is:1.22 & sMAPE is:2.03% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 12.20% & 0.82\n",
      "for 2018-07-24, MAE is:1.57 & sMAPE is:2.45% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 12.15% & 0.82\n",
      "for 2018-07-25, MAE is:2.63 & sMAPE is:4.15% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 12.11% & 0.82\n",
      "for 2018-07-26, MAE is:2.26 & sMAPE is:3.55% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 12.07% & 0.83\n",
      "for 2018-07-27, MAE is:2.38 & sMAPE is:3.79% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 12.03% & 0.83\n",
      "for 2018-07-28, MAE is:5.65 & sMAPE is:9.39% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 12.02% & 0.84\n",
      "for 2018-07-29, MAE is:3.07 & sMAPE is:5.15% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 11.99% & 0.84\n",
      "for 2018-07-30, MAE is:2.27 & sMAPE is:3.72% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 11.95% & 0.84\n",
      "for 2018-07-31, MAE is:1.62 & sMAPE is:2.53% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 11.90% & 0.85\n",
      "for 2018-08-01, MAE is:2.94 & sMAPE is:4.70% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 11.87% & 0.85\n",
      "for 2018-08-02, MAE is:2.61 & sMAPE is:4.08% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 11.83% & 0.85\n",
      "for 2018-08-03, MAE is:3.32 & sMAPE is:5.06% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 11.80% & 0.85\n",
      "for 2018-08-04, MAE is:3.07 & sMAPE is:4.82% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 11.77% & 0.85\n",
      "for 2018-08-05, MAE is:3.62 & sMAPE is:5.74% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 11.74% & 0.85\n",
      "for 2018-08-06, MAE is:2.14 & sMAPE is:3.12% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 11.70% & 0.85\n",
      "for 2018-08-07, MAE is:4.59 & sMAPE is:7.11% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 11.68% & 0.85\n",
      "for 2018-08-08, MAE is:1.38 & sMAPE is:2.24% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 11.64% & 0.85\n",
      "for 2018-08-09, MAE is:1.13 & sMAPE is:1.87% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 11.59% & 0.85\n",
      "for 2018-08-10, MAE is:2.43 & sMAPE is:3.92% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 11.56% & 0.85\n",
      "for 2018-08-11, MAE is:3.31 & sMAPE is:5.45% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 11.53% & 0.85\n",
      "for 2018-08-12, MAE is:3.51 & sMAPE is:5.93% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 11.51% & 0.85\n",
      "for 2018-08-13, MAE is:2.05 & sMAPE is:3.23% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 11.47% & 0.85\n",
      "for 2018-08-14, MAE is:1.55 & sMAPE is:2.60% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 11.43% & 0.84\n",
      "for 2018-08-15, MAE is:4.32 & sMAPE is:7.28% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 11.41% & 0.84\n",
      "for 2018-08-16, MAE is:2.20 & sMAPE is:3.50% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 11.38% & 0.84\n",
      "for 2018-08-17, MAE is:2.26 & sMAPE is:3.83% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 11.35% & 0.84\n",
      "for 2018-08-18, MAE is:3.80 & sMAPE is:6.55% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 11.32% & 0.84\n",
      "for 2018-08-19, MAE is:3.02 & sMAPE is:5.32% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 11.30% & 0.84\n",
      "for 2018-08-20, MAE is:2.08 & sMAPE is:3.37% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 11.26% & 0.84\n",
      "for 2018-08-21, MAE is:3.13 & sMAPE is:4.84% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 11.24% & 0.84\n",
      "for 2018-08-22, MAE is:3.31 & sMAPE is:4.94% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 11.21% & 0.84\n",
      "for 2018-08-23, MAE is:2.27 & sMAPE is:3.39% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 11.18% & 0.84\n",
      "for 2018-08-24, MAE is:1.31 & sMAPE is:2.06% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 11.14% & 0.83\n",
      "for 2018-08-25, MAE is:2.36 & sMAPE is:3.84% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 11.11% & 0.83\n",
      "for 2018-08-26, MAE is:3.89 & sMAPE is:6.38% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 11.09% & 0.83\n",
      "for 2018-08-27, MAE is:2.89 & sMAPE is:4.34% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 11.06% & 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-28, MAE is:2.00 & sMAPE is:2.99% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 11.03% & 0.83\n",
      "for 2018-08-29, MAE is:1.74 & sMAPE is:2.46% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 10.99% & 0.83\n",
      "for 2018-08-30, MAE is:3.36 & sMAPE is:4.89% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 10.96% & 0.83\n",
      "for 2018-08-31, MAE is:3.21 & sMAPE is:4.72% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 10.94% & 0.83\n",
      "for 2018-09-01, MAE is:1.99 & sMAPE is:3.15% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 10.91% & 0.83\n",
      "for 2018-09-02, MAE is:2.19 & sMAPE is:3.38% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 10.88% & 0.84\n",
      "for 2018-09-03, MAE is:1.65 & sMAPE is:2.38% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 10.84% & 0.83\n",
      "for 2018-09-04, MAE is:1.96 & sMAPE is:2.89% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 10.81% & 0.83\n",
      "for 2018-09-05, MAE is:4.78 & sMAPE is:6.77% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 10.79% & 0.83\n",
      "for 2018-09-06, MAE is:2.63 & sMAPE is:3.67% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 10.76% & 0.84\n",
      "for 2018-09-07, MAE is:2.34 & sMAPE is:3.56% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 10.74% & 0.84\n",
      "for 2018-09-08, MAE is:4.99 & sMAPE is:7.53% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 10.72% & 0.84\n",
      "for 2018-09-09, MAE is:4.86 & sMAPE is:7.24% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 10.71% & 0.84\n",
      "for 2018-09-10, MAE is:2.71 & sMAPE is:3.84% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 10.68% & 0.84\n",
      "for 2018-09-11, MAE is:3.70 & sMAPE is:5.35% & rMAE is:3.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 10.66% & 0.85\n",
      "for 2018-09-12, MAE is:3.19 & sMAPE is:4.47% & rMAE is:3.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 10.64% & 0.86\n",
      "for 2018-09-13, MAE is:2.45 & sMAPE is:3.38% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 10.61% & 0.86\n",
      "for 2018-09-14, MAE is:2.99 & sMAPE is:4.22% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 10.58% & 0.86\n",
      "for 2018-09-15, MAE is:4.26 & sMAPE is:6.37% & rMAE is:2.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 10.57% & 0.87\n",
      "for 2018-09-16, MAE is:3.78 & sMAPE is:5.63% & rMAE is:3.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 10.55% & 0.88\n",
      "for 2018-09-17, MAE is:3.17 & sMAPE is:4.34% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 10.52% & 0.88\n",
      "for 2018-09-18, MAE is:2.52 & sMAPE is:3.47% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 10.50% & 0.88\n",
      "for 2018-09-19, MAE is:2.37 & sMAPE is:3.18% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 10.47% & 0.88\n",
      "for 2018-09-20, MAE is:3.38 & sMAPE is:4.60% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 10.45% & 0.88\n",
      "for 2018-09-21, MAE is:3.27 & sMAPE is:4.76% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.43% & 0.89\n",
      "for 2018-09-22, MAE is:3.33 & sMAPE is:4.74% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.40% & 0.89\n",
      "for 2018-09-23, MAE is:3.33 & sMAPE is:4.85% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.38% & 0.89\n",
      "for 2018-09-24, MAE is:3.66 & sMAPE is:6.09% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 10.37% & 0.89\n",
      "for 2018-09-25, MAE is:4.22 & sMAPE is:6.53% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 10.35% & 0.89\n",
      "for 2018-09-26, MAE is:2.87 & sMAPE is:4.18% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 10.33% & 0.88\n",
      "for 2018-09-27, MAE is:3.04 & sMAPE is:4.28% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 10.31% & 0.89\n",
      "for 2018-09-28, MAE is:3.50 & sMAPE is:4.80% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 10.29% & 0.89\n",
      "for 2018-09-29, MAE is:2.30 & sMAPE is:3.30% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.26% & 0.89\n",
      "for 2018-09-30, MAE is:3.39 & sMAPE is:4.97% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.24% & 0.89\n",
      "for 2018-10-01, MAE is:5.40 & sMAPE is:8.50% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.24% & 0.89\n",
      "for 2018-10-02, MAE is:4.21 & sMAPE is:6.41% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.22% & 0.89\n",
      "for 2018-10-03, MAE is:4.65 & sMAPE is:6.61% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.21% & 0.89\n",
      "for 2018-10-04, MAE is:4.16 & sMAPE is:5.73% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.19% & 0.90\n",
      "for 2018-10-05, MAE is:3.35 & sMAPE is:4.59% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.17% & 0.90\n",
      "for 2018-10-06, MAE is:5.68 & sMAPE is:8.50% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.17% & 0.90\n",
      "for 2018-10-07, MAE is:5.47 & sMAPE is:9.45% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 10.16% & 0.89\n",
      "for 2018-10-08, MAE is:3.60 & sMAPE is:5.65% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.15% & 0.89\n",
      "for 2018-10-09, MAE is:3.62 & sMAPE is:5.20% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.13% & 0.89\n",
      "for 2018-10-10, MAE is:5.11 & sMAPE is:7.69% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.12% & 0.89\n",
      "for 2018-10-11, MAE is:4.79 & sMAPE is:7.34% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 10.11% & 0.89\n",
      "for 2018-10-12, MAE is:4.88 & sMAPE is:7.99% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 10.10% & 0.89\n",
      "for 2018-10-13, MAE is:4.12 & sMAPE is:6.67% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 10.09% & 0.89\n",
      "for 2018-10-14, MAE is:8.14 & sMAPE is:15.27% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 10.11% & 0.89\n",
      "for 2018-10-15, MAE is:6.15 & sMAPE is:11.40% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.11% & 0.89\n",
      "for 2018-10-16, MAE is:4.79 & sMAPE is:7.06% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.10% & 0.89\n",
      "for 2018-10-17, MAE is:5.92 & sMAPE is:8.66% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.10% & 0.89\n",
      "for 2018-10-18, MAE is:3.19 & sMAPE is:4.90% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.08% & 0.89\n",
      "for 2018-10-19, MAE is:4.03 & sMAPE is:6.62% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.07% & 0.90\n",
      "for 2018-10-20, MAE is:4.33 & sMAPE is:7.38% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.06% & 0.90\n",
      "for 2018-10-21, MAE is:5.47 & sMAPE is:9.46% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.06% & 0.90\n",
      "for 2018-10-22, MAE is:5.86 & sMAPE is:9.07% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.05% & 0.90\n",
      "for 2018-10-23, MAE is:4.67 & sMAPE is:7.81% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 10.05% & 0.90\n",
      "for 2018-10-24, MAE is:2.47 & sMAPE is:3.81% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.03% & 0.89\n",
      "for 2018-10-25, MAE is:4.67 & sMAPE is:7.10% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.02% & 0.89\n",
      "for 2018-10-26, MAE is:4.87 & sMAPE is:7.23% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.01% & 0.89\n",
      "for 2018-10-27, MAE is:4.75 & sMAPE is:8.03% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 10.00% & 0.89\n",
      "for 2018-10-28, MAE is:4.32 & sMAPE is:7.81% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.99% & 0.89\n",
      "for 2018-10-29, MAE is:7.32 & sMAPE is:12.26% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 10.00% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-30, MAE is:3.56 & sMAPE is:6.16% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.99% & 0.89\n",
      "for 2018-10-31, MAE is:2.89 & sMAPE is:4.39% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.97% & 0.89\n",
      "for 2018-11-01, MAE is:4.09 & sMAPE is:6.49% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.96% & 0.89\n",
      "for 2018-11-02, MAE is:4.16 & sMAPE is:6.76% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.95% & 0.89\n",
      "for 2018-11-03, MAE is:4.53 & sMAPE is:7.29% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.94% & 0.89\n",
      "for 2018-11-04, MAE is:4.46 & sMAPE is:7.28% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.93% & 0.89\n",
      "for 2018-11-05, MAE is:4.07 & sMAPE is:7.03% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.92% & 0.89\n",
      "for 2018-11-06, MAE is:4.72 & sMAPE is:8.11% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.92% & 0.89\n",
      "for 2018-11-07, MAE is:5.39 & sMAPE is:9.26% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.91% & 0.89\n",
      "for 2018-11-08, MAE is:3.15 & sMAPE is:5.07% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.90% & 0.89\n",
      "for 2018-11-09, MAE is:4.69 & sMAPE is:8.17% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.89% & 0.89\n",
      "for 2018-11-10, MAE is:4.22 & sMAPE is:7.86% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.89% & 0.89\n",
      "for 2018-11-11, MAE is:4.94 & sMAPE is:9.34% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.88% & 0.89\n",
      "for 2018-11-12, MAE is:5.03 & sMAPE is:8.12% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.88% & 0.89\n",
      "for 2018-11-13, MAE is:4.38 & sMAPE is:7.13% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.87% & 0.89\n",
      "for 2018-11-14, MAE is:3.84 & sMAPE is:6.39% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.86% & 0.89\n",
      "for 2018-11-15, MAE is:5.07 & sMAPE is:8.77% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.86% & 0.89\n",
      "for 2018-11-16, MAE is:3.51 & sMAPE is:5.61% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.84% & 0.89\n",
      "for 2018-11-17, MAE is:6.70 & sMAPE is:11.76% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.85% & 0.89\n",
      "for 2018-11-18, MAE is:4.07 & sMAPE is:7.22% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.84% & 0.89\n",
      "for 2018-11-19, MAE is:5.25 & sMAPE is:8.73% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.84% & 0.89\n",
      "for 2018-11-20, MAE is:5.29 & sMAPE is:7.94% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 9.83% & 0.89\n",
      "for 2018-11-21, MAE is:3.27 & sMAPE is:5.71% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.82% & 0.89\n",
      "for 2018-11-22, MAE is:2.90 & sMAPE is:4.55% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.80% & 0.89\n",
      "for 2018-11-23, MAE is:3.84 & sMAPE is:6.08% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.79% & 0.89\n",
      "for 2018-11-24, MAE is:3.74 & sMAPE is:6.18% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.78% & 0.89\n",
      "for 2018-11-25, MAE is:4.97 & sMAPE is:8.87% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.78% & 0.90\n",
      "for 2018-11-26, MAE is:4.78 & sMAPE is:7.82% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.77% & 0.90\n",
      "for 2018-11-27, MAE is:4.56 & sMAPE is:7.54% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.76% & 0.90\n",
      "for 2018-11-28, MAE is:3.22 & sMAPE is:5.28% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.75% & 0.90\n",
      "for 2018-11-29, MAE is:3.53 & sMAPE is:5.83% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.74% & 0.90\n",
      "for 2018-11-30, MAE is:2.13 & sMAPE is:3.37% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 9.72% & 0.90\n",
      "for 2018-12-01, MAE is:2.95 & sMAPE is:4.92% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 9.71% & 0.90\n",
      "for 2018-12-02, MAE is:3.21 & sMAPE is:5.98% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 9.69% & 0.90\n",
      "for 2018-12-03, MAE is:4.00 & sMAPE is:6.61% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 9.69% & 0.90\n",
      "for 2018-12-04, MAE is:2.82 & sMAPE is:4.38% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.67% & 0.90\n",
      "for 2018-12-05, MAE is:2.46 & sMAPE is:3.90% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.65% & 0.90\n",
      "for 2018-12-06, MAE is:5.47 & sMAPE is:9.14% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.65% & 0.91\n",
      "for 2018-12-07, MAE is:4.41 & sMAPE is:6.98% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.64% & 0.91\n",
      "for 2018-12-08, MAE is:4.99 & sMAPE is:8.55% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.64% & 0.91\n",
      "for 2018-12-09, MAE is:2.48 & sMAPE is:4.29% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.62% & 0.91\n",
      "for 2018-12-10, MAE is:2.88 & sMAPE is:4.62% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 9.61% & 0.91\n",
      "for 2018-12-11, MAE is:2.92 & sMAPE is:4.51% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 9.59% & 0.91\n",
      "for 2018-12-12, MAE is:3.48 & sMAPE is:5.66% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 9.58% & 0.91\n",
      "for 2018-12-13, MAE is:1.71 & sMAPE is:3.13% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 9.56% & 0.91\n",
      "for 2018-12-14, MAE is:3.51 & sMAPE is:6.37% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 9.56% & 0.91\n",
      "for 2018-12-15, MAE is:2.61 & sMAPE is:4.30% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 9.54% & 0.91\n",
      "for 2018-12-16, MAE is:2.97 & sMAPE is:5.20% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 9.53% & 0.91\n",
      "for 2018-12-17, MAE is:4.81 & sMAPE is:7.88% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 9.52% & 0.91\n",
      "for 2018-12-18, MAE is:2.98 & sMAPE is:5.00% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 9.51% & 0.91\n",
      "for 2018-12-19, MAE is:3.29 & sMAPE is:5.48% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 9.50% & 0.91\n",
      "for 2018-12-20, MAE is:3.40 & sMAPE is:5.62% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 9.49% & 0.91\n",
      "for 2018-12-21, MAE is:2.15 & sMAPE is:3.68% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 9.47% & 0.91\n",
      "for 2018-12-22, MAE is:5.99 & sMAPE is:10.06% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 9.47% & 0.91\n",
      "for 2018-12-23, MAE is:1.64 & sMAPE is:2.64% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 9.45% & 0.91\n",
      "for 2018-12-24, MAE is:2.73 & sMAPE is:4.52% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 9.44% & 0.91\n",
      "for 2018-12-25, MAE is:2.49 & sMAPE is:4.05% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 9.43% & 0.91\n",
      "for 2018-12-26, MAE is:2.49 & sMAPE is:3.94% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 9.41% & 0.91\n",
      "for 2018-12-27, MAE is:4.22 & sMAPE is:6.76% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 9.40% & 0.91\n",
      "for 2018-12-28, MAE is:3.32 & sMAPE is:5.03% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 9.39% & 0.91\n",
      "for 2018-12-29, MAE is:2.26 & sMAPE is:3.94% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 9.38% & 0.91\n",
      "for 2018-12-30, MAE is:2.48 & sMAPE is:4.25% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 9.36% & 0.91\n",
      "for 2018-12-31, MAE is:1.95 & sMAPE is:3.21% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 9.34% & 0.91\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:44:25,103]\u001b[0m A new study created in RDB with name: ES_2019\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:44:46,457]\u001b[0m Trial 3 finished with value: 7.909831861996788 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017954203308444686, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09009753321067292, 'dropout_rate_Layer_2': 0.31912657410374606, 'dropout_rate_Layer_3': 0.38256943683275935, 'dropout_rate_Layer_4': 0.34883747918642705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0034095805754495207, 'l1_Layer_2': 0.002811537799410382, 'l1_Layer_3': 0.0022111798284716244, 'l1_Layer_4': 0.08190377416932082, 'n_units_Layer_1': 290, 'n_units_Layer_2': 60, 'n_units_Layer_3': 95, 'n_units_Layer_4': 225}. Best is trial 3 with value: 7.909831861996788.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.91 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 10.23 | sMAPE for Test Set is: 22.07% | rMAE for Test Set is: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:44:54,952]\u001b[0m Trial 2 finished with value: 4.593587649725449 and parameters: {'n_hidden': 3, 'learning_rate': 0.007110137262923117, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15634891001405138, 'dropout_rate_Layer_2': 0.05741291132022273, 'dropout_rate_Layer_3': 0.12515619328021207, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015420608330719074, 'l1_Layer_2': 0.0005704038535722466, 'l1_Layer_3': 0.00738387853016322, 'n_units_Layer_1': 220, 'n_units_Layer_2': 230, 'n_units_Layer_3': 235}. Best is trial 2 with value: 4.593587649725449.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 9.55% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.52 | sMAPE for Test Set is: 11.40% | rMAE for Test Set is: 0.66\n",
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 9.48% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.45 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:44:58,371]\u001b[0m Trial 0 finished with value: 4.555010491673953 and parameters: {'n_hidden': 4, 'learning_rate': 0.0039332731764761646, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041616827601533006, 'dropout_rate_Layer_2': 0.13605568468546478, 'dropout_rate_Layer_3': 0.3036589653115307, 'dropout_rate_Layer_4': 0.3613170024584228, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.016348513803796313, 'l1_Layer_2': 4.626595384967649e-05, 'l1_Layer_3': 0.011583339332285614, 'l1_Layer_4': 0.004349697695682162, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 135, 'n_units_Layer_4': 300}. Best is trial 0 with value: 4.555010491673953.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:45:01,207]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:45:07,822]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:45:11,937]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:45:12,507]\u001b[0m Trial 1 finished with value: 5.550217813042512 and parameters: {'n_hidden': 4, 'learning_rate': 0.021902026783781236, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28704279723916376, 'dropout_rate_Layer_2': 0.0760155330479449, 'dropout_rate_Layer_3': 0.27051060803140164, 'dropout_rate_Layer_4': 0.06641673848745255, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.017328244871457458, 'l1_Layer_2': 0.005468441014654909, 'l1_Layer_3': 0.00816461104682106, 'l1_Layer_4': 1.1233485630478961e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 80, 'n_units_Layer_3': 165, 'n_units_Layer_4': 175}. Best is trial 0 with value: 4.555010491673953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 11.16% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 13.06% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:45:18,136]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:45:19,556]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:45:32,116]\u001b[0m Trial 6 finished with value: 5.194229204148557 and parameters: {'n_hidden': 3, 'learning_rate': 0.002914393446175323, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26061279670424015, 'dropout_rate_Layer_2': 0.13408546365690213, 'dropout_rate_Layer_3': 0.33042923142449765, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.265452132201282e-05, 'l1_Layer_2': 5.575461607682252e-05, 'l1_Layer_3': 0.01274571039142429, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 210}. Best is trial 0 with value: 4.555010491673953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 10.64% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 4.65 | sMAPE for Test Set is: 11.88% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:45:35,862]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:45:39,923]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:45:57,502]\u001b[0m Trial 4 finished with value: 4.805048303972634 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006496090611051502, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08520475565111624, 'dropout_rate_Layer_2': 0.211384139272991, 'dropout_rate_Layer_3': 0.1777031910763252, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00025817602783909094, 'l1_Layer_2': 0.00030703792509433124, 'l1_Layer_3': 0.0027680075834700967, 'n_units_Layer_1': 65, 'n_units_Layer_2': 140, 'n_units_Layer_3': 90}. Best is trial 0 with value: 4.555010491673953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 9.80% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.44 | sMAPE for Test Set is: 11.30% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:46:10,223]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:14,177]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:18,345]\u001b[0m Trial 12 finished with value: 5.228228789214985 and parameters: {'n_hidden': 3, 'learning_rate': 0.006983163126298156, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3028407566278932, 'dropout_rate_Layer_2': 0.3793514728562637, 'dropout_rate_Layer_3': 0.06749742271069313, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 6.823858687340617e-05, 'l1_Layer_2': 0.03588677166085613, 'l1_Layer_3': 5.937561981012022e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 0 with value: 4.555010491673953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 12.51% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:46:22,013]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:22,054]\u001b[0m Trial 11 finished with value: 6.567303790513367 and parameters: {'n_hidden': 3, 'learning_rate': 0.059053108800749356, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36300349608271487, 'dropout_rate_Layer_2': 0.2620661369599479, 'dropout_rate_Layer_3': 0.2362270805625876, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.523414466525156e-05, 'l1_Layer_2': 0.002657616994815158, 'l1_Layer_3': 0.00019418636310389298, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 0 with value: 4.555010491673953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 12.84% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 9.25 | sMAPE for Test Set is: 20.31% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:46:27,510]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:27,847]\u001b[0m Trial 15 finished with value: 6.051252588515401 and parameters: {'n_hidden': 4, 'learning_rate': 0.008160228255511407, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3652237994763864, 'dropout_rate_Layer_2': 0.2803595460536138, 'dropout_rate_Layer_3': 0.17997002597445141, 'dropout_rate_Layer_4': 0.02298873626463145, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.037622031714744056, 'l1_Layer_2': 0.056556897694681835, 'l1_Layer_3': 0.010707758596394761, 'l1_Layer_4': 0.011397907845659623, 'n_units_Layer_1': 135, 'n_units_Layer_2': 275, 'n_units_Layer_3': 245, 'n_units_Layer_4': 270}. Best is trial 0 with value: 4.555010491673953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 11.98% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:46:31,557]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:34,168]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:36,721]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:40,269]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:43,088]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:47,310]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:50,873]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:53,729]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:54,157]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:58,003]\u001b[0m Trial 29 finished with value: 7.61542978093167 and parameters: {'n_hidden': 4, 'learning_rate': 0.07055412689858061, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29213666871177524, 'dropout_rate_Layer_2': 0.29406868650422946, 'dropout_rate_Layer_3': 0.13457294727026614, 'dropout_rate_Layer_4': 0.3299750479032119, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004683861594646949, 'l1_Layer_2': 0.0006684146024886317, 'l1_Layer_3': 7.907201733203521e-05, 'l1_Layer_4': 9.063195970033699e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 265, 'n_units_Layer_3': 75, 'n_units_Layer_4': 185}. Best is trial 0 with value: 4.555010491673953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.62 | sMAPE for Validation Set is: 14.75% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 17.59% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:47:00,641]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:01,367]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:07,575]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:18,476]\u001b[0m Trial 23 finished with value: 4.962356145923589 and parameters: {'n_hidden': 3, 'learning_rate': 0.019538482445712293, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29264032804502177, 'dropout_rate_Layer_2': 0.2946497958165806, 'dropout_rate_Layer_3': 0.3285276294288686, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 7.822402576567745e-05, 'l1_Layer_2': 0.028914233879862476, 'l1_Layer_3': 0.02532070445820083, 'n_units_Layer_1': 210, 'n_units_Layer_2': 240, 'n_units_Layer_3': 250}. Best is trial 0 with value: 4.555010491673953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 10.30% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 4.63 | sMAPE for Test Set is: 11.91% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:47:23,234]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:24,187]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:29,404]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:31,903]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:36,041]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:38,487]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:41,999]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:44,878]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:45,280]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:55,036]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:47:59,092]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:48:02,324]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:48:04,490]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:48:08,740]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:48:28,112]\u001b[0m Trial 34 finished with value: 4.492268073827417 and parameters: {'n_hidden': 4, 'learning_rate': 0.000773202221645681, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34370553193460185, 'dropout_rate_Layer_2': 0.3501438083779707, 'dropout_rate_Layer_3': 0.1811071586084545, 'dropout_rate_Layer_4': 0.30877005048614553, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.5679479462423482e-05, 'l1_Layer_2': 1.2487074782499196e-05, 'l1_Layer_3': 0.0025003627039628354, 'l1_Layer_4': 0.00013533899990588252, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 185, 'n_units_Layer_4': 220}. Best is trial 34 with value: 4.492268073827417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 9.31% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.34 | sMAPE for Test Set is: 11.23% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:48:45,325]\u001b[0m Trial 49 finished with value: 4.008528007555275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009202018200380589, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.333230527682852, 'dropout_rate_Layer_2': 0.24977134862606382, 'dropout_rate_Layer_3': 0.35722241199705257, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2624136327918175e-05, 'l1_Layer_2': 0.0006506474587906091, 'l1_Layer_3': 0.00012587105317694438, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 220}. Best is trial 49 with value: 4.008528007555275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 8.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.88 | sMAPE for Test Set is: 10.12% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:48:48,565]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:48:53,367]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:00,622]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:05,207]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:09,365]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:13,754]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:15,799]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:19,397]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:23,462]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:24,669]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:25,840]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:31,644]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:31,848]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:37,333]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:37,481]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:42,823]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:44,033]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:48,947]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:51,272]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:55,067]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:49:57,997]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:03,113]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:21,006]\u001b[0m Trial 73 finished with value: 6.33464441450393 and parameters: {'n_hidden': 3, 'learning_rate': 0.04404252245291581, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3867212985426045, 'dropout_rate_Layer_2': 0.1459262594630742, 'dropout_rate_Layer_3': 0.10935793104702252, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016804731598413418, 'l1_Layer_2': 8.50022548686661e-05, 'l1_Layer_3': 0.00014481044297816196, 'n_units_Layer_1': 210, 'n_units_Layer_2': 110, 'n_units_Layer_3': 170}. Best is trial 49 with value: 4.008528007555275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 13.99% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:50:22,301]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:27,891]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:31,932]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:34,711]\u001b[0m Trial 36 finished with value: 4.496807561384678 and parameters: {'n_hidden': 3, 'learning_rate': 0.003814770371854608, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10161921620035488, 'dropout_rate_Layer_2': 0.1123279152477048, 'dropout_rate_Layer_3': 0.29998053950684683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001641430165394609, 'l1_Layer_2': 0.00010273046168735408, 'l1_Layer_3': 0.09189488151766993, 'n_units_Layer_1': 210, 'n_units_Layer_2': 210, 'n_units_Layer_3': 215}. Best is trial 49 with value: 4.008528007555275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 9.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 10.90% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:50:35,709]\u001b[0m Trial 77 finished with value: 7.29062065835772 and parameters: {'n_hidden': 4, 'learning_rate': 0.06290627737199878, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04347520602188229, 'dropout_rate_Layer_2': 0.15612613376620046, 'dropout_rate_Layer_3': 0.24572802312030842, 'dropout_rate_Layer_4': 0.38581906487971857, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00034248492081270164, 'l1_Layer_2': 2.068569498446533e-05, 'l1_Layer_3': 0.0053314943060209265, 'l1_Layer_4': 0.013981742270411856, 'n_units_Layer_1': 175, 'n_units_Layer_2': 155, 'n_units_Layer_3': 105, 'n_units_Layer_4': 290}. Best is trial 49 with value: 4.008528007555275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 7.62 | sMAPE for Test Set is: 17.26% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:50:37,503]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:40,443]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:45,246]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:51,752]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:55,347]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:55,737]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:55,974]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:02,571]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:06,419]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:06,455]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:09,388]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:14,082]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:17,702]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:24,915]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:30,142]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:34,877]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:36,572]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:38,649]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:40,203]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:44,380]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:48,110]\u001b[0m Trial 68 finished with value: 3.828927565034986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017208275294291063, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06954688938122597, 'dropout_rate_Layer_2': 0.23465795794076905, 'dropout_rate_Layer_3': 0.33654131798709686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000747020131280547, 'l1_Layer_2': 0.00012907474869399901, 'l1_Layer_3': 0.017289981906333438, 'n_units_Layer_1': 215, 'n_units_Layer_2': 125, 'n_units_Layer_3': 295}. Best is trial 68 with value: 3.828927565034986.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 8.09% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.85 | sMAPE for Test Set is: 9.92% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:51:53,428]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:57,309]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:57,481]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:04,370]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:06,514]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:12,740]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:17,365]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:22,620]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:27,364]\u001b[0m Trial 104 finished with value: 4.641992867787681 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027665682436372823, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39886128556058537, 'dropout_rate_Layer_2': 0.3251189010338285, 'dropout_rate_Layer_3': 0.33314120509506373, 'dropout_rate_Layer_4': 0.24629196293254926, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0024868643037664743, 'l1_Layer_2': 0.003505609375736337, 'l1_Layer_3': 0.007153708949199523, 'l1_Layer_4': 0.00012486245916520344, 'n_units_Layer_1': 175, 'n_units_Layer_2': 60, 'n_units_Layer_3': 245, 'n_units_Layer_4': 100}. Best is trial 68 with value: 3.828927565034986.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 9.67% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 11.26% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:52:31,047]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:35,431]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:40,310]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:44,142]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:49,043]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:54,188]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:59,650]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:53:11,101]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 8.24% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 10.24% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:53:12,912]\u001b[0m Trial 102 finished with value: 3.891340399476625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017526313373739842, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08218326333721951, 'dropout_rate_Layer_2': 0.22622773177566202, 'dropout_rate_Layer_3': 0.3616755736912815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012553688246608715, 'l1_Layer_2': 0.0001867915559650898, 'l1_Layer_3': 0.025531711980829, 'n_units_Layer_1': 220, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255}. Best is trial 68 with value: 3.828927565034986.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:53:17,383]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:53:23,731]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:53:32,361]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:53:37,301]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:53:39,054]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:53:44,737]\u001b[0m Trial 109 finished with value: 3.548136214490709 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019395886516042446, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0772814868836546, 'dropout_rate_Layer_2': 0.24786220305354906, 'dropout_rate_Layer_3': 0.27568030440172475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003983755265387222, 'l1_Layer_2': 0.0007515499916633314, 'l1_Layer_3': 0.0022960298503361324, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 109 with value: 3.548136214490709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 7.58% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.71 | sMAPE for Test Set is: 9.66% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:53:46,255]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:53:50,364]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:53:50,718]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:53:56,874]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:53:58,244]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:04,802]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:05,233]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:06,416]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:14,441]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:18,145]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:22,899]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:25,622]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:29,942]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:31,259]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:35,810]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:39,845]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:40,568]\u001b[0m Trial 135 finished with value: 4.588836666210183 and parameters: {'n_hidden': 3, 'learning_rate': 0.003186991731888073, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3228364707893827, 'dropout_rate_Layer_2': 0.2544799030889192, 'dropout_rate_Layer_3': 0.061175860402195956, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 7.114339179825812e-05, 'l1_Layer_2': 0.00019162268761090462, 'l1_Layer_3': 8.525454599176552e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 95, 'n_units_Layer_3': 235}. Best is trial 109 with value: 3.548136214490709.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 9.44% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 10.93% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:54:42,936]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:48,123]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:49,111]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:54:55,416]\u001b[0m Trial 110 finished with value: 3.4864508422881753 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005685545802511058, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0790935662815565, 'dropout_rate_Layer_2': 0.25145631525747014, 'dropout_rate_Layer_3': 0.35790178696412456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00030646535815478774, 'l1_Layer_2': 0.0006843122068319752, 'l1_Layer_3': 0.0027645306153184, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245}. Best is trial 110 with value: 3.4864508422881753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 7.46% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.68 | sMAPE for Test Set is: 9.59% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:55:02,234]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:07,023]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:11,918]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:15,081]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:19,089]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:22,993]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:25,892]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:29,094]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:34,013]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:39,052]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:42,355]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:47,733]\u001b[0m Trial 146 finished with value: 4.738245757105632 and parameters: {'n_hidden': 3, 'learning_rate': 0.003502215132744406, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2501390896368027, 'dropout_rate_Layer_2': 0.19434061801720046, 'dropout_rate_Layer_3': 0.06275831369050222, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.239617264153188e-05, 'l1_Layer_2': 0.00016130669732789004, 'l1_Layer_3': 1.0249924231410818e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 100, 'n_units_Layer_3': 140}. Best is trial 110 with value: 3.4864508422881753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 9.87% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.56 | sMAPE for Test Set is: 11.65% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:55:57,018]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:56:01,013]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:56:05,135]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:56:08,640]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:56:12,240]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:56:20,998]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:56:25,620]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:56:30,295]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:56:41,765]\u001b[0m Trial 151 finished with value: 3.4676542749551427 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014777275919803288, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024216008947501595, 'dropout_rate_Layer_2': 0.2323850802063147, 'dropout_rate_Layer_3': 0.3396143900303229, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003939091715422669, 'l1_Layer_2': 0.0016292956898984895, 'l1_Layer_3': 0.0005968200757498264, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 7.38% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.94 | sMAPE for Test Set is: 10.18% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:56:44,271]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:56:47,560]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:57:03,560]\u001b[0m Trial 164 finished with value: 3.6816863252108774 and parameters: {'n_hidden': 3, 'learning_rate': 0.002401632912088705, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07626924355111145, 'dropout_rate_Layer_2': 0.05916387141918325, 'dropout_rate_Layer_3': 0.1983599500880241, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005539637274713765, 'l1_Layer_2': 2.8635288658928655e-05, 'l1_Layer_3': 0.0005450147955775191, 'n_units_Layer_1': 90, 'n_units_Layer_2': 255, 'n_units_Layer_3': 225}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.80% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.81 | sMAPE for Test Set is: 9.99% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:57:04,261]\u001b[0m Trial 170 finished with value: 4.760191407314672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034347372649257985, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39759261119220357, 'dropout_rate_Layer_2': 0.2286017894704804, 'dropout_rate_Layer_3': 0.04292703091522221, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.567468911757941e-05, 'l1_Layer_2': 0.00016086785839320363, 'l1_Layer_3': 1.0984275263344689e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 9.73% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 11.86% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:57:09,732]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:57:13,589]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:57:18,778]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:57:26,404]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 7.91% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.78 | sMAPE for Test Set is: 9.90% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:57:28,106]\u001b[0m Trial 168 finished with value: 3.7193909906608433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024116375361609523, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08001680450030912, 'dropout_rate_Layer_2': 0.06089694666592094, 'dropout_rate_Layer_3': 0.15209148773510814, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00600613235986228, 'l1_Layer_2': 0.0006581845253832711, 'l1_Layer_3': 0.0004907747186782704, 'n_units_Layer_1': 135, 'n_units_Layer_2': 270, 'n_units_Layer_3': 255}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:57:32,188]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:57:38,335]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:57:42,498]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:57:46,451]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:57:51,589]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:57:52,319]\u001b[0m Trial 159 finished with value: 4.360803939470366 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012643506329599167, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22621877433400778, 'dropout_rate_Layer_2': 0.2112833154778044, 'dropout_rate_Layer_3': 0.014989493239397439, 'dropout_rate_Layer_4': 0.21469039182261038, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.533216947099635e-05, 'l1_Layer_2': 7.864691682346492e-05, 'l1_Layer_3': 4.4501302942108485e-05, 'l1_Layer_4': 0.00034663293202578835, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215, 'n_units_Layer_4': 190}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 8.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.01 | sMAPE for Test Set is: 10.27% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:57:56,392]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:57:56,796]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:58:02,262]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:58:06,588]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:58:16,129]\u001b[0m Trial 174 finished with value: 3.9620234635200364 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011782320771911224, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10215481048134106, 'dropout_rate_Layer_2': 0.3403010464463861, 'dropout_rate_Layer_3': 0.39677528600413303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00034462448907664965, 'l1_Layer_2': 0.0004582384256521447, 'l1_Layer_3': 0.0014480650363193693, 'n_units_Layer_1': 230, 'n_units_Layer_2': 100, 'n_units_Layer_3': 165}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 8.26% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 10.96% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:58:22,813]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:58:30,121]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:58:34,760]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:58:45,797]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:58:53,113]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:59:00,416]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:59:17,483]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:59:24,172]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:59:31,459]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:59:37,868]\u001b[0m Trial 183 finished with value: 3.878678079990036 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013081534431067007, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09059696646308762, 'dropout_rate_Layer_2': 0.1635911585482452, 'dropout_rate_Layer_3': 0.39559375172326083, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004092420029979196, 'l1_Layer_2': 0.0003780586371252278, 'l1_Layer_3': 1.075163088591827e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 255, 'n_units_Layer_3': 275}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 8.14% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.98 | sMAPE for Test Set is: 10.18% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:59:38,217]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:59:42,318]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:59:46,161]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:59:49,275]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:59:50,396]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:59:56,506]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:59:57,843]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:05,283]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:05,724]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:12,283]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:15,497]\u001b[0m Trial 185 finished with value: 3.843029525216732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015497606056835555, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06495549824158361, 'dropout_rate_Layer_2': 0.1717767148231245, 'dropout_rate_Layer_3': 0.3823698730795813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005436817038653155, 'l1_Layer_2': 0.00038098306343746296, 'l1_Layer_3': 1.66622509336478e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 8.25% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.83 | sMAPE for Test Set is: 9.91% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:00:18,034]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:19,747]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:22,329]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:25,703]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:28,030]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:32,992]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:40,834]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:45,929]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:50,521]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:54,615]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:00:57,713]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:01:03,940]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 9.31% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 11.43% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:01:05,806]\u001b[0m Trial 205 finished with value: 4.571243396713304 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015348229772647614, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35632173788462546, 'dropout_rate_Layer_2': 0.2544086267460739, 'dropout_rate_Layer_3': 0.09609123496075135, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00011548549896865983, 'l1_Layer_2': 5.183622896127936e-05, 'l1_Layer_3': 3.612616775845368e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 150, 'n_units_Layer_3': 190}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:01:08,978]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:01:15,963]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:01:23,537]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:01:27,743]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:01:31,239]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:01:35,313]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:01:42,444]\u001b[0m Trial 223 finished with value: 3.9109882028178906 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027141277092674115, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0160546808116402, 'dropout_rate_Layer_2': 0.08118761502415028, 'dropout_rate_Layer_3': 0.27974957205517953, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004475378983321503, 'l1_Layer_2': 0.013345207436772049, 'l1_Layer_3': 3.2485552568195754e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 255, 'n_units_Layer_3': 275}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 8.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.91 | sMAPE for Test Set is: 10.15% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:01:47,237]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:01:50,350]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:01:53,767]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:05,845]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 9.56% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.47 | sMAPE for Test Set is: 11.56% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:02:07,206]\u001b[0m Trial 212 finished with value: 4.641487428819002 and parameters: {'n_hidden': 3, 'learning_rate': 0.007624022523952586, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26508278271016245, 'dropout_rate_Layer_2': 0.37090856345494644, 'dropout_rate_Layer_3': 0.06056036592012372, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00011607601688115814, 'l1_Layer_2': 0.00026644666704286706, 'l1_Layer_3': 5.0092406086492253e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 135, 'n_units_Layer_3': 135}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:11,571]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:14,881]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:14,938]\u001b[0m Trial 221 finished with value: 3.7523226588997765 and parameters: {'n_hidden': 3, 'learning_rate': 0.001123539173174573, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11535909002825091, 'dropout_rate_Layer_2': 0.07188957758779531, 'dropout_rate_Layer_3': 0.24607532419186515, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0101279017165691, 'l1_Layer_2': 3.888015888511622e-05, 'l1_Layer_3': 0.0001281785152337725, 'n_units_Layer_1': 70, 'n_units_Layer_2': 260, 'n_units_Layer_3': 295}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.97% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 10.11% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:02:20,184]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:26,886]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:31,389]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:37,883]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:41,230]\u001b[0m Trial 228 finished with value: 4.33360506635416 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009837629761001187, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3654932067984978, 'dropout_rate_Layer_2': 0.3135462300619457, 'dropout_rate_Layer_3': 0.04563367641827613, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00012750396439108148, 'l1_Layer_2': 6.624602503872439e-05, 'l1_Layer_3': 4.119882074118862e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 100, 'n_units_Layer_3': 220}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 9.08% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.38 | sMAPE for Test Set is: 11.42% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:02:46,491]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:46,759]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:49,842]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:55,263]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:59,078]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:59,497]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:59,835]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:06,064]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:10,228]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:10,933]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:18,177]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:20,667]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:27,169]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:30,864]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:34,703]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:44,577]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:48,341]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:51,914]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:56,423]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:00,234]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:03,707]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:06,638]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:06,794]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:12,516]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:13,652]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:18,661]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:23,190]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:28,523]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:32,935]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:33,186]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:37,679]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:41,454]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:45,230]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:49,369]\u001b[0m Trial 247 finished with value: 3.652290202372567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008695822606507297, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04716718876349209, 'dropout_rate_Layer_2': 0.03135614231943495, 'dropout_rate_Layer_3': 0.2224893189602322, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010753465134321339, 'l1_Layer_2': 2.4921619442745288e-05, 'l1_Layer_3': 0.0001836745670740984, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.72 | sMAPE for Test Set is: 9.72% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:04:51,259]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:55,050]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:55,282]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:00,552]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:00,700]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:05,044]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:20,131]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:27,494]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:33,050]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:35,818]\u001b[0m Trial 281 finished with value: 3.6264225443981224 and parameters: {'n_hidden': 3, 'learning_rate': 0.002662842398187171, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011885792215759562, 'dropout_rate_Layer_2': 0.04041529742939509, 'dropout_rate_Layer_3': 0.27259474202748785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006339418863166524, 'l1_Layer_2': 0.0018206331423816363, 'l1_Layer_3': 2.461754150573195e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 250, 'n_units_Layer_3': 270}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 7.74% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.75 | sMAPE for Test Set is: 9.77% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:05:39,166]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:43,077]\u001b[0m Trial 277 finished with value: 4.500250648089184 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013492598864362887, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3675293063193704, 'dropout_rate_Layer_2': 0.3113168782171413, 'dropout_rate_Layer_3': 0.054899763340435837, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0004922004350020452, 'l1_Layer_2': 0.0013160221783547507, 'l1_Layer_3': 0.00017877482633827497, 'n_units_Layer_1': 225, 'n_units_Layer_2': 190, 'n_units_Layer_3': 265}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 9.25% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.43 | sMAPE for Test Set is: 11.20% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:05:45,467]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:46,795]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:54,531]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:57,377]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:59,278]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:01,790]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 9.44% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 11.19% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:06:04,180]\u001b[0m Trial 254 finished with value: 4.582648403906513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009827088749819694, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32195667482795837, 'dropout_rate_Layer_2': 0.30819250851741065, 'dropout_rate_Layer_3': 0.09145692453023165, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00012177413398708886, 'l1_Layer_2': 2.953175125689986e-05, 'l1_Layer_3': 0.00015293712582793148, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 265}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:11,579]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:11,874]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:16,676]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:21,155]\u001b[0m Trial 288 finished with value: 3.9635411305947557 and parameters: {'n_hidden': 3, 'learning_rate': 0.00451738171278492, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05673924644845015, 'dropout_rate_Layer_2': 0.0058876599895771875, 'dropout_rate_Layer_3': 0.3635518353004111, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017203734232905363, 'l1_Layer_2': 0.0015422409269360254, 'l1_Layer_3': 1.2505019846586807e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 220, 'n_units_Layer_3': 260}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 8.32% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 10.12% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:06:24,455]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:26,763]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:29,966]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:32,149]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:32,576]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:33,550]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:38,752]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:44,363]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:06:46,075]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:00,732]\u001b[0m Trial 304 finished with value: 3.614715368130298 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020119130455432724, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1372328264409719, 'dropout_rate_Layer_2': 0.1139450220041668, 'dropout_rate_Layer_3': 0.32016721822192795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013219215925786734, 'l1_Layer_2': 0.0002434107501493878, 'l1_Layer_3': 0.0003156320150171437, 'n_units_Layer_1': 265, 'n_units_Layer_2': 280, 'n_units_Layer_3': 230}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.63% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.77 | sMAPE for Test Set is: 9.80% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:07:01,577]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:04,849]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:08,928]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:11,837]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:11,926]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:18,705]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:19,997]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:23,234]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:26,091]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:26,568]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:30,681]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:35,332]\u001b[0m Trial 319 finished with value: 8.771007574710103 and parameters: {'n_hidden': 3, 'learning_rate': 0.014234327673061955, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041899473290213686, 'dropout_rate_Layer_2': 0.042340499399450796, 'dropout_rate_Layer_3': 0.24329913820468732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0013046928350798994, 'l1_Layer_2': 0.0034365118405154807, 'l1_Layer_3': 7.349896339069531e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 295}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.77 | sMAPE for Validation Set is: 16.66% | rMAE for Validation Set is: 1.29\n",
      "MAE for Test Set is: 10.67 | sMAPE for Test Set is: 22.78% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:07:37,074]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.22 | sMAPE for Validation Set is: 19.56% | rMAE for Validation Set is: 1.51\n",
      "MAE for Test Set is: 8.87 | sMAPE for Test Set is: 19.72% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:07:39,561]\u001b[0m Trial 320 finished with value: 10.219122139861469 and parameters: {'n_hidden': 3, 'learning_rate': 0.011054655488352575, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1990758784913006, 'dropout_rate_Layer_2': 0.055377430594008986, 'dropout_rate_Layer_3': 0.24078022853053738, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0018752235800328326, 'l1_Layer_2': 0.0043813400307131855, 'l1_Layer_3': 9.150142601558096e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 165, 'n_units_Layer_3': 285}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:42,700]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:45,796]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:48,065]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:50,704]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:52,112]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:55,986]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:57,231]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:08:01,748]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:08:04,283]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:08:04,739]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:08:09,563]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:08:09,776]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:08:29,579]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:08:42,591]\u001b[0m Trial 335 finished with value: 4.656604904999726 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016400723721254906, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3798844253668953, 'dropout_rate_Layer_2': 0.34171201549667746, 'dropout_rate_Layer_3': 0.049954281785072434, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00023284182739607192, 'l1_Layer_2': 0.00041080622095160656, 'l1_Layer_3': 2.6658958770679868e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 70, 'n_units_Layer_3': 240}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 9.47% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.73 | sMAPE for Test Set is: 11.82% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:09:05,050]\u001b[0m Trial 336 finished with value: 4.447246611739892 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015248500400431239, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.367076505199238, 'dropout_rate_Layer_2': 0.34180822430987323, 'dropout_rate_Layer_3': 0.048710783677410704, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0002919351603059867, 'l1_Layer_2': 1.0224375443964677e-05, 'l1_Layer_3': 0.00022280085722095773, 'n_units_Layer_1': 250, 'n_units_Layer_2': 70, 'n_units_Layer_3': 235}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 9.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.46 | sMAPE for Test Set is: 11.51% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:09:10,232]\u001b[0m Trial 337 finished with value: 4.328188920149813 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023102722977043945, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3171344080387242, 'dropout_rate_Layer_2': 0.292953153053905, 'dropout_rate_Layer_3': 0.11348929857341827, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00035543505260182527, 'l1_Layer_2': 1.0754617433368517e-05, 'l1_Layer_3': 0.0002552502609916319, 'n_units_Layer_1': 285, 'n_units_Layer_2': 50, 'n_units_Layer_3': 260}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 8.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 11.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:09:14,097]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:09:18,100]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:09:39,299]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:09:42,926]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:09:56,414]\u001b[0m Trial 308 finished with value: 4.014510817434535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005110602622380579, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36548549829289145, 'dropout_rate_Layer_2': 0.30904617066898926, 'dropout_rate_Layer_3': 0.15208786721731254, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00040170229216063746, 'l1_Layer_2': 1.0689839270069986e-05, 'l1_Layer_3': 0.0012887298366070588, 'n_units_Layer_1': 225, 'n_units_Layer_2': 195, 'n_units_Layer_3': 300}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 8.39% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 10.53% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:10:02,316]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:10:05,579]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:10:26,807]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:10:30,415]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:10:30,563]\u001b[0m Trial 334 finished with value: 3.6019058792662135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008149458370721452, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09545859386404247, 'dropout_rate_Layer_2': 0.20915845095048102, 'dropout_rate_Layer_3': 0.33290483519882585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007668646711560358, 'l1_Layer_2': 0.0001931391166109309, 'l1_Layer_3': 0.00686781534704215, 'n_units_Layer_1': 235, 'n_units_Layer_2': 145, 'n_units_Layer_3': 255}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 7.72% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.79 | sMAPE for Test Set is: 9.90% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:10:35,805]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:10:41,679]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:10:45,736]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:10:48,570]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:10:52,691]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:10:56,450]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:10:59,030]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:01,456]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:05,146]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:09,014]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:10,722]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:15,054]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:19,288]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:27,191]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:35,533]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:38,891]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:42,747]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:43,337]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:48,964]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:52,277]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:52,741]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:56,700]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:00,498]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:06,302]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:16,894]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:21,004]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:24,824]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:25,515]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:30,259]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:33,240]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:35,957]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:39,702]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:43,233]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:44,363]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:48,644]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:52,953]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:53,335]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:58,087]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:58,214]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:58,443]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:06,234]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:08,940]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:12,852]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:13,147]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:13,531]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:21,141]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:22,019]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:22,323]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:24,424]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:33,189]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:33,362]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:40,140]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:40,307]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:45,902]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:50,242]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:50,588]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:54,058]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:02,999]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:23,391]\u001b[0m Trial 395 finished with value: 4.4790300448699485 and parameters: {'n_hidden': 3, 'learning_rate': 0.002300266954036247, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06335403164723138, 'dropout_rate_Layer_2': 0.29262304246555154, 'dropout_rate_Layer_3': 0.1123356031269168, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002563149304198337, 'l1_Layer_2': 1.822018174212901e-05, 'l1_Layer_3': 0.00024210135936369344, 'n_units_Layer_1': 220, 'n_units_Layer_2': 225, 'n_units_Layer_3': 260}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 9.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.66 | sMAPE for Test Set is: 12.45% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:14:29,629]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:34,036]\u001b[0m Trial 407 finished with value: 3.9861068628220586 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012506474960154545, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09145434152451154, 'dropout_rate_Layer_2': 0.0350931084954895, 'dropout_rate_Layer_3': 0.20907149692576213, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012568947963646823, 'l1_Layer_2': 2.125069947112941e-05, 'l1_Layer_3': 0.0004525507332951549, 'n_units_Layer_1': 60, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 8.41% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.39 | sMAPE for Test Set is: 11.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:14:34,570]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:39,813]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:40,419]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:44,006]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:45,493]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:47,341]\u001b[0m Trial 404 finished with value: 4.474551045084356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011149589598645764, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28450075655298335, 'dropout_rate_Layer_2': 0.28500975108658755, 'dropout_rate_Layer_3': 0.11258738170353483, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019061083464213197, 'l1_Layer_2': 1.967069854497467e-05, 'l1_Layer_3': 0.00351183073554218, 'n_units_Layer_1': 220, 'n_units_Layer_2': 235, 'n_units_Layer_3': 260}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.47 | sMAPE for Validation Set is: 9.24% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 10.99% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:14:52,995]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:53,492]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:59,684]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:01,589]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:05,198]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:07,016]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:07,624]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:14,669]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:18,674]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:18,838]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:19,009]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:19,127]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:28,993]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:29,156]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:29,281]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:38,729]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:40,296]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:44,152]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:46,300]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:48,595]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:49,569]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:53,192]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:55,627]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:57,666]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:59,731]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:59,931]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:03,443]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:03,937]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:06,359]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:09,932]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:10,651]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:14,147]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:15,315]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:16,663]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:21,840]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:23,240]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:24,328]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:32,433]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:36,126]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:39,628]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:43,797]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:47,184]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:54,550]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:57,722]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:17:01,325]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:17:02,001]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:17:06,845]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:17:08,773]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:17:12,907]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:17:17,153]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:17:21,325]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:17:25,518]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:17:29,680]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:17:36,309]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:17:56,416]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:00,845]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:04,926]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:12,837]\u001b[0m Trial 460 finished with value: 3.528244505358559 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008985540778432415, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029210604701127588, 'dropout_rate_Layer_2': 0.19352170074302108, 'dropout_rate_Layer_3': 0.2618156009867334, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027793271452461457, 'l1_Layer_2': 0.0006229101287309292, 'l1_Layer_3': 0.00012617384733811055, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 230}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.53 | sMAPE for Validation Set is: 7.57% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.55 | sMAPE for Test Set is: 9.27% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:18:15,761]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.74 | sMAPE for Test Set is: 9.59% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:18:17,053]\u001b[0m Trial 463 finished with value: 3.5195472954942026 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010424846466438901, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029927749892830743, 'dropout_rate_Layer_2': 0.24303369049217316, 'dropout_rate_Layer_3': 0.15305806137468675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002511993226537402, 'l1_Layer_2': 0.0005774731508909661, 'l1_Layer_3': 0.00011061594317450076, 'n_units_Layer_1': 265, 'n_units_Layer_2': 235, 'n_units_Layer_3': 230}. Best is trial 151 with value: 3.4676542749551427.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:22,105]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:22,667]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:23,171]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:27,908]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:31,161]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:31,813]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:42,332]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:45,133]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:48,859]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:51,300]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:53,742]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:54,562]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:59,177]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:59,774]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:04,290]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:08,478]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:12,595]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:17,021]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:17,385]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:22,407]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:24,407]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:29,341]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:32,909]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:37,266]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:41,510]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:47,686]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:52,520]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:00,549]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:08,543]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:18,095]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:25,252]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:27,105]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:29,451]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:35,955]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:36,173]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:38,449]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:41,726]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:42,762]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:52,685]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:00,423]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:06,506]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:10,161]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:10,857]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:15,077]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:20,002]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:23,640]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:27,515]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:29,973]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:31,829]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:32,692]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:38,747]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:39,339]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:47,480]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:47,872]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:51,401]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:54,952]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:55,256]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:55,432]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:56,906]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:01,319]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:02,035]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:02,954]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:02,970]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:10,369]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:10,813]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:14,164]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:16,074]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:17,332]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:24,681]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:28,645]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:36,316]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:41,614]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:46,522]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:46,757]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:50,877]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:51,925]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:56,633]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:57,279]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:03,229]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:03,359]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:07,433]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:11,262]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:14,505]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:23:19,733]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:21,656]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:25,309]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:25,794]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:28,751]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:33,027]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:33,138]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:38,041]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:40,027]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:42,358]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:44,623]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:52,982]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:55,911]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:56,695]\u001b[0m Trial 560 finished with value: 3.42286095762608 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012005532959860677, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07384438478709804, 'dropout_rate_Layer_2': 0.11710022996809326, 'dropout_rate_Layer_3': 0.33398603835233265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006394441688035394, 'l1_Layer_2': 9.08368293777693e-05, 'l1_Layer_3': 4.925807742240062e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 100, 'n_units_Layer_3': 275}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 7.30% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.59 | sMAPE for Test Set is: 9.39% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:23:57,344]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:00,568]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:10,964]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:13,003]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:15,058]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:15,339]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:17,743]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:20,393]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:24,358]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:29,820]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:34,851]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:35,072]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:40,956]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:44,290]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:47,495]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:48,164]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:48,436]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:00,456]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:02,145]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:05,753]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:09,931]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:09,995]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:15,134]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:15,575]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:19,691]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:21,127]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:25,346]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:28,672]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:32,283]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:34,540]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:35,468]\u001b[0m Trial 588 finished with value: 3.756563688987239 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014757183169544004, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04249541128065896, 'dropout_rate_Layer_2': 0.04613402935542056, 'dropout_rate_Layer_3': 0.21475448966140875, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005413593309432734, 'l1_Layer_2': 3.416935309020731e-05, 'l1_Layer_3': 0.0004938104215220759, 'n_units_Layer_1': 115, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.75 | sMAPE for Test Set is: 9.78% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:25:37,995]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:42,584]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:44,019]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:48,479]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:50,882]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:53,002]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:55,546]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:56,188]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:57,618]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:03,379]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:04,203]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:04,644]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:07,341]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:12,221]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:12,720]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:13,989]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:21,737]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:21,887]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:27,084]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:27,587]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:28,413]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:30,139]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:32,671]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:39,361]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:39,858]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:40,249]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:40,339]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:50,777]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:55,002]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:55,320]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:56,585]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:58,124]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:01,743]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:02,197]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:05,488]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:08,102]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:13,027]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:14,657]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:18,045]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:21,589]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:48,548]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:52,763]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:55,267]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:27:58,177]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:01,124]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:04,418]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:08,698]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:11,651]\u001b[0m Trial 637 finished with value: 4.866478256255777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013235894144019722, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3835049671686205, 'dropout_rate_Layer_2': 0.3103277717837393, 'dropout_rate_Layer_3': 0.09366518116312506, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00013841783791282466, 'l1_Layer_2': 3.0659460382723446e-05, 'l1_Layer_3': 0.00014256634599768656, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 265}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 10.28% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 12.66% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:28:16,709]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:26,424]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:29,596]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:33,167]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:35,099]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:37,328]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:38,549]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:39,580]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:41,170]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:45,558]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:49,337]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:49,780]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:50,517]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:56,775]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:00,791]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:01,132]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:06,324]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:06,732]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:10,071]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:13,306]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:21,768]\u001b[0m Trial 647 finished with value: 3.7072305309031592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011825401599333551, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09460896488502384, 'dropout_rate_Layer_2': 0.20761091269930443, 'dropout_rate_Layer_3': 0.3309842823014876, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001097811027026798, 'l1_Layer_2': 0.0026206472436344935, 'l1_Layer_3': 0.0006391982109881192, 'n_units_Layer_1': 195, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.86% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.71 | sMAPE for Test Set is: 9.56% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:29:27,815]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:33,598]\u001b[0m Trial 670 finished with value: 3.510078780697711 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014776178555043695, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10189352895598695, 'dropout_rate_Layer_2': 0.24584819798646818, 'dropout_rate_Layer_3': 0.29292561200284467, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003030873495577754, 'l1_Layer_2': 0.00048234654570430225, 'l1_Layer_3': 0.0003432928503045682, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 280}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.51 | sMAPE for Validation Set is: 7.47% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.59 | sMAPE for Test Set is: 9.40% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:29:37,914]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:42,473]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:42,785]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:49,818]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:53,065]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:56,488]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:29:57,739]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:03,499]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:03,684]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:09,296]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:12,435]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:14,334]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:16,619]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:20,501]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:24,083]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:25,016]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:29,644]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:30,021]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:35,376]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:35,919]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:40,471]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:43,545]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:54,741]\u001b[0m Trial 683 finished with value: 3.7511414469775772 and parameters: {'n_hidden': 3, 'learning_rate': 0.002454349006928014, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09487088618793173, 'dropout_rate_Layer_2': 0.20110650188797602, 'dropout_rate_Layer_3': 0.29674193704140356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.090812089230339e-05, 'l1_Layer_2': 0.0030835411903297133, 'l1_Layer_3': 0.0005910633162895907, 'n_units_Layer_1': 185, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.81% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.85 | sMAPE for Test Set is: 9.95% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:30:59,798]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:03,254]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:06,427]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:10,123]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:14,162]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:18,316]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:21,830]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:25,339]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:26,368]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:33,092]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:36,827]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:40,318]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:40,495]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:46,382]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:11,746]\u001b[0m Trial 706 finished with value: 3.679278961036015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013170459179328614, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06962038451645378, 'dropout_rate_Layer_2': 0.2362848407083035, 'dropout_rate_Layer_3': 0.0937438153795526, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005519665183538992, 'l1_Layer_2': 3.644002405776603e-05, 'l1_Layer_3': 0.00035814884160481424, 'n_units_Layer_1': 75, 'n_units_Layer_2': 245, 'n_units_Layer_3': 180}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.83% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.75 | sMAPE for Test Set is: 9.78% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:32:14,083]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:31,419]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:32,023]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:41,414]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:44,439]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:44,927]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:47,943]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:53,842]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:57,688]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:01,125]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:01,306]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 8.43% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.02 | sMAPE for Test Set is: 10.37% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:33:06,226]\u001b[0m Trial 686 finished with value: 4.040721405245073 and parameters: {'n_hidden': 3, 'learning_rate': 0.001946197022781335, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0690903532600441, 'dropout_rate_Layer_2': 0.27774802655399505, 'dropout_rate_Layer_3': 0.11644616537161809, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008632098019163099, 'l1_Layer_2': 8.973315362686232e-05, 'l1_Layer_3': 0.005143826645986932, 'n_units_Layer_1': 220, 'n_units_Layer_2': 90, 'n_units_Layer_3': 225}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:08,271]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:09,701]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:16,201]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:19,085]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:22,646]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:24,247]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:28,060]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:29,757]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:31,210]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:33,952]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:37,597]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:42,498]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:43,338]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:55,227]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:58,633]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:33:59,347]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:03,395]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:07,413]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:13,318]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:15,224]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:15,659]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:18,535]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:22,671]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:26,745]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:27,406]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:32,468]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:34,865]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:35,401]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:39,478]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:41,160]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:41,940]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:43,257]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:49,349]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:51,753]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:55,366]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:59,413]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:02,654]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:05,693]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:08,675]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:14,585]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:17,436]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:20,902]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:26,015]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:29,467]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:31,793]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:38,549]\u001b[0m Trial 751 finished with value: 3.706089947240313 and parameters: {'n_hidden': 3, 'learning_rate': 0.001613518231211853, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.075460275561198, 'dropout_rate_Layer_2': 0.21777758161562563, 'dropout_rate_Layer_3': 0.25235884081084897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001432871593246772, 'l1_Layer_2': 0.004029509908003562, 'l1_Layer_3': 0.0005506969715107414, 'n_units_Layer_1': 160, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.82% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.79 | sMAPE for Test Set is: 9.80% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:35:43,577]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:46,793]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:47,031]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:49,660]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:53,954]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:06,279]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:10,585]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:31,810]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:35,458]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:44,575]\u001b[0m Trial 775 finished with value: 3.655355310404545 and parameters: {'n_hidden': 3, 'learning_rate': 0.002343717681216076, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11425190760727147, 'dropout_rate_Layer_2': 0.24670294107202265, 'dropout_rate_Layer_3': 0.22973709480076895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.745139076309023e-05, 'l1_Layer_2': 0.008291724040388962, 'l1_Layer_3': 0.0009068418157190496, 'n_units_Layer_1': 165, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.77 | sMAPE for Test Set is: 9.79% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:36:48,573]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:48,916]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:55,889]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:57,159]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:00,653]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:04,315]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:06,762]\u001b[0m Trial 770 finished with value: 4.608707194918806 and parameters: {'n_hidden': 3, 'learning_rate': 0.001215673565801764, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060518451801754414, 'dropout_rate_Layer_2': 0.3348408952756261, 'dropout_rate_Layer_3': 0.08355366515289012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000436635549057421, 'l1_Layer_2': 3.5626507064126074e-05, 'l1_Layer_3': 0.00119789068677429, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 240}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 9.40% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.35 | sMAPE for Test Set is: 11.06% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:37:08,203]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:08,954]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:09,906]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:15,187]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:17,502]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:18,877]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:30,878]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:34,309]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:34,459]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:34,884]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:43,341]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:46,462]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:50,503]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:53,048]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:37:58,520]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:38:03,122]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:38:06,770]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:38:20,240]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:38:26,534]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:38:31,079]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:38:37,319]\u001b[0m Trial 797 finished with value: 3.504364868972999 and parameters: {'n_hidden': 3, 'learning_rate': 0.002053855200980568, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19300820962296228, 'dropout_rate_Layer_2': 0.24316739224207543, 'dropout_rate_Layer_3': 0.23309669749887135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.7830686268076113e-05, 'l1_Layer_2': 0.024520267111119435, 'l1_Layer_3': 9.711482234946621e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 245, 'n_units_Layer_3': 215}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 7.49% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.73 | sMAPE for Test Set is: 9.67% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:38:41,264]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:38:41,598]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:38:46,774]\u001b[0m Trial 801 finished with value: 4.876940250023786 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017775877377692849, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.348376006295078, 'dropout_rate_Layer_2': 0.2644302143668863, 'dropout_rate_Layer_3': 0.04811279831559023, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0003336731416756366, 'l1_Layer_2': 0.00014256336335084535, 'l1_Layer_3': 0.002742637295746598, 'n_units_Layer_1': 265, 'n_units_Layer_2': 195, 'n_units_Layer_3': 275}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 10.08% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 12.27% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:38:49,104]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:38:55,107]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:38:55,931]\u001b[0m Trial 773 finished with value: 3.4484591260569055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005657437097689923, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11763917396102379, 'dropout_rate_Layer_2': 0.19569466841980834, 'dropout_rate_Layer_3': 0.3878380994594098, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006955331106460856, 'l1_Layer_2': 0.00026925251056755903, 'l1_Layer_3': 0.004862998231360778, 'n_units_Layer_1': 210, 'n_units_Layer_2': 95, 'n_units_Layer_3': 275}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 7.42% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.71 | sMAPE for Test Set is: 9.66% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:39:00,529]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:03,535]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:05,434]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:08,459]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:11,713]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:13,907]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:16,528]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:19,036]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:19,235]\u001b[0m Trial 813 finished with value: 4.339178115833184 and parameters: {'n_hidden': 3, 'learning_rate': 0.004099338998521742, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20085221095118497, 'dropout_rate_Layer_2': 0.06812868232888475, 'dropout_rate_Layer_3': 0.2111639739207345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014007983855327281, 'l1_Layer_2': 0.021877501729347805, 'l1_Layer_3': 0.00011390114823932033, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 215}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 9.17% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 11.04% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:39:20,467]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:26,275]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:30,322]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:33,737]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:38,527]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:46,491]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:48,438]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:56,256]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:40:00,188]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:40:05,430]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:40:08,593]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:40:11,891]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:40:21,516]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:40:21,916]\u001b[0m Trial 816 finished with value: 3.6199786665730413 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005213143702046555, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13404325963711367, 'dropout_rate_Layer_2': 0.1851139445459604, 'dropout_rate_Layer_3': 0.3893678745040472, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007877115753465313, 'l1_Layer_2': 0.0002373825845196418, 'l1_Layer_3': 0.002202586957327566, 'n_units_Layer_1': 210, 'n_units_Layer_2': 95, 'n_units_Layer_3': 280}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.67% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.80 | sMAPE for Test Set is: 9.81% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:40:30,706]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:40:34,017]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:40:55,419]\u001b[0m Trial 831 finished with value: 3.9210150445163863 and parameters: {'n_hidden': 3, 'learning_rate': 0.002691679823524129, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2756874034775514, 'dropout_rate_Layer_2': 0.3034420841830442, 'dropout_rate_Layer_3': 0.12590745552896881, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010947747116428067, 'l1_Layer_2': 0.0016248187213826573, 'l1_Layer_3': 0.00012671037423025324, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 295}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 8.27% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 10.56% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:40:59,388]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:41:12,655]\u001b[0m Trial 838 finished with value: 4.339109785696788 and parameters: {'n_hidden': 3, 'learning_rate': 0.0043625176827176, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0026880661610211853, 'dropout_rate_Layer_2': 0.3028977237166876, 'dropout_rate_Layer_3': 0.12830920260925505, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.546176643651939e-05, 'l1_Layer_2': 9.773089127266346e-05, 'l1_Layer_3': 0.00013785217593385634, 'n_units_Layer_1': 240, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 8.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.20 | sMAPE for Test Set is: 10.76% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:41:13,484]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:41:18,791]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:41:28,452]\u001b[0m Trial 837 finished with value: 4.063603418764677 and parameters: {'n_hidden': 3, 'learning_rate': 0.002505755751205799, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24060207963208674, 'dropout_rate_Layer_2': 0.3135333153083849, 'dropout_rate_Layer_3': 0.13746189733279657, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011232693644152355, 'l1_Layer_2': 0.0001107511158222709, 'l1_Layer_3': 0.00017982947987170143, 'n_units_Layer_1': 240, 'n_units_Layer_2': 130, 'n_units_Layer_3': 295}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 8.51% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 11.58% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:41:28,889]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:41:33,708]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:41:39,528]\u001b[0m Trial 840 finished with value: 3.779444931923122 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010434257170034002, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37052070051001734, 'dropout_rate_Layer_2': 0.23768470836083874, 'dropout_rate_Layer_3': 0.021308258262612536, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00103240075371433, 'l1_Layer_2': 0.0016680146887008414, 'l1_Layer_3': 0.00012626371839059158, 'n_units_Layer_1': 235, 'n_units_Layer_2': 55, 'n_units_Layer_3': 265}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 7.97% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.84 | sMAPE for Test Set is: 10.02% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:41:42,882]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:41:43,290]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:41:47,744]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:41:50,921]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:41:59,239]\u001b[0m Trial 843 finished with value: 3.700612183576189 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012524224428974112, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.051467693630508696, 'dropout_rate_Layer_2': 0.09023978559935622, 'dropout_rate_Layer_3': 0.21222413466706158, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008556580373433898, 'l1_Layer_2': 1.896462063306495e-05, 'l1_Layer_3': 0.00024884618357658004, 'n_units_Layer_1': 55, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.88% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.84 | sMAPE for Test Set is: 9.94% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:42:03,703]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:42:12,646]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:42:17,212]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:42:21,352]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:42:25,606]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:42:32,448]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:42:36,111]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:42:39,979]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:42:58,226]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:43:14,459]\u001b[0m Trial 859 finished with value: 4.603694673858765 and parameters: {'n_hidden': 3, 'learning_rate': 0.00618835283551035, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0035894958935949136, 'dropout_rate_Layer_2': 0.35039529930635005, 'dropout_rate_Layer_3': 0.0007339884204786012, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012006093424683146, 'l1_Layer_2': 0.0017006562329805073, 'l1_Layer_3': 0.00014057224612720954, 'n_units_Layer_1': 240, 'n_units_Layer_2': 135, 'n_units_Layer_3': 295}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 9.41% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.26 | sMAPE for Test Set is: 10.98% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:43:24,050]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:43:27,862]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:43:30,247]\u001b[0m Trial 850 finished with value: 4.039023919527312 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039018698022834967, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23918240072986333, 'dropout_rate_Layer_2': 0.2840896669215766, 'dropout_rate_Layer_3': 5.166156472142386e-05, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026739563050073114, 'l1_Layer_2': 0.0016961116983987398, 'l1_Layer_3': 0.00012740764670105694, 'n_units_Layer_1': 240, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 8.62% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 11.92% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:43:32,339]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:43:38,067]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:43:43,253]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:43:55,503]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:43:59,667]\u001b[0m Trial 862 finished with value: 4.143547518391517 and parameters: {'n_hidden': 3, 'learning_rate': 0.003803216095817874, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23933832975593589, 'dropout_rate_Layer_2': 0.3488522566844706, 'dropout_rate_Layer_3': 0.1378868000632025, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001261154062352887, 'l1_Layer_2': 0.0016804695938437502, 'l1_Layer_3': 0.00024689895927815, 'n_units_Layer_1': 250, 'n_units_Layer_2': 135, 'n_units_Layer_3': 285}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.14 | sMAPE for Validation Set is: 8.85% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.70 | sMAPE for Test Set is: 12.19% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:44:06,342]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:11,409]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:14,958]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:18,513]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:21,888]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:26,110]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:27,032]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:33,552]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:37,263]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:39,294]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:42,090]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:46,067]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:49,812]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:56,047]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:04,976]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:12,376]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:15,588]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:16,051]\u001b[0m Trial 870 finished with value: 4.004532245766074 and parameters: {'n_hidden': 3, 'learning_rate': 0.004710290776108482, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22079809164779216, 'dropout_rate_Layer_2': 0.2855972460372237, 'dropout_rate_Layer_3': 0.16618360623982487, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019738542528209145, 'l1_Layer_2': 0.00027106515103438614, 'l1_Layer_3': 0.000388568103949529, 'n_units_Layer_1': 245, 'n_units_Layer_2': 235, 'n_units_Layer_3': 285}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 8.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.22 | sMAPE for Test Set is: 10.65% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:45:28,273]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:30,713]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:33,726]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:34,402]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:42,178]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:45,713]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:46,114]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:51,673]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:00,149]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:05,416]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:09,225]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:13,441]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:13,931]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:14,067]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:21,949]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:26,056]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:28,851]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:31,105]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:33,625]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:43,154]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:45,303]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:48,109]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:48,657]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:51,133]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:55,453]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:46:56,616]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:00,435]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:04,871]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:09,003]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:09,426]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:09,948]\u001b[0m Trial 896 finished with value: 3.454209338548685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012514892050748947, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13779739195309573, 'dropout_rate_Layer_2': 0.22265783107302337, 'dropout_rate_Layer_3': 0.242246636220704, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010806500158556052, 'l1_Layer_2': 0.0018693292952030565, 'l1_Layer_3': 9.359917474277247e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 250, 'n_units_Layer_3': 270}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 7.37% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.46 | sMAPE for Test Set is: 8.95% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:47:16,868]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:17,236]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:19,792]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:25,276]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:26,492]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:28,597]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:30,731]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:31,277]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:33,690]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:40,586]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:41,248]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:46,129]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:46,723]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:47,178]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:52,332]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:55,492]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:55,659]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:00,780]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:01,790]\u001b[0m Trial 927 finished with value: 3.675045772847516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029798576952525394, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14054303021021938, 'dropout_rate_Layer_2': 0.2299969332420891, 'dropout_rate_Layer_3': 0.17901339029023558, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6514611905336674e-05, 'l1_Layer_2': 0.008622887503514197, 'l1_Layer_3': 8.518695360645584e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 235, 'n_units_Layer_3': 265}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.77% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.76 | sMAPE for Test Set is: 9.80% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:48:04,830]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:07,124]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:13,118]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:17,112]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:19,495]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:20,272]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:25,175]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:25,920]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:26,228]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:33,164]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:33,477]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:39,007]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:39,675]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:44,736]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:46,725]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:50,492]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:52,504]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:56,797]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:48:59,218]\u001b[0m Trial 942 finished with value: 4.025865762835331 and parameters: {'n_hidden': 3, 'learning_rate': 0.00528870556691998, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26077298432657386, 'dropout_rate_Layer_2': 0.2838360720397842, 'dropout_rate_Layer_3': 0.13772138273664347, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020175067248094764, 'l1_Layer_2': 0.0018729663121255342, 'l1_Layer_3': 0.00012066196971141424, 'n_units_Layer_1': 235, 'n_units_Layer_2': 230, 'n_units_Layer_3': 280}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 8.34% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 10.20% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:49:02,636]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:49:11,549]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:49:16,472]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:49:20,412]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:49:24,248]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:49:28,335]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:49:33,139]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:49:47,197]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:49:52,455]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:49:59,284]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:00,763]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:05,149]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:09,878]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:12,995]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:13,634]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:17,669]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:19,169]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:24,125]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:27,506]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:31,771]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:38,992]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:50:53,407]\u001b[0m Trial 956 finished with value: 3.491843810286824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005192282995660475, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14944217400969736, 'dropout_rate_Layer_2': 0.17441859855837552, 'dropout_rate_Layer_3': 0.20900822102109118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010124091380013102, 'l1_Layer_2': 0.0002002516196453166, 'l1_Layer_3': 2.5385379356282537e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 275}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 7.45% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.59 | sMAPE for Test Set is: 9.45% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:50:56,151]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:51:08,332]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:51:23,337]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:51:26,940]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:51:29,917]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:51:35,006]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:51:42,067]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:51:46,290]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:51:46,506]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:51:52,860]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:51:54,195]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:52:02,308]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:52:10,038]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:52:16,695]\u001b[0m Trial 967 finished with value: 3.447260873267771 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007061080264163667, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1569365227745985, 'dropout_rate_Layer_2': 0.19334914758448324, 'dropout_rate_Layer_3': 0.3348201222070058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009685599122313178, 'l1_Layer_2': 0.00029028520945973405, 'l1_Layer_3': 0.0015979529182766573, 'n_units_Layer_1': 175, 'n_units_Layer_2': 145, 'n_units_Layer_3': 260}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 7.34% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.63 | sMAPE for Test Set is: 9.49% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:52:38,187]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:52:44,449]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:52:56,736]\u001b[0m Trial 976 finished with value: 3.433078489102687 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005898778483915726, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15764140518273478, 'dropout_rate_Layer_2': 0.16391625988277309, 'dropout_rate_Layer_3': 0.3342726531879164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035751830043887167, 'l1_Layer_2': 0.0003063994113634793, 'l1_Layer_3': 0.0013346720704472766, 'n_units_Layer_1': 160, 'n_units_Layer_2': 140, 'n_units_Layer_3': 265}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 7.31% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.60 | sMAPE for Test Set is: 9.40% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:53:00,635]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:53:01,450]\u001b[0m Trial 991 finished with value: 4.035925841622291 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032622832496645524, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23525460739438112, 'dropout_rate_Layer_2': 0.3024645071599328, 'dropout_rate_Layer_3': 0.15253970035171743, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015165234021465564, 'l1_Layer_2': 0.00048787490468687995, 'l1_Layer_3': 0.00019179995040431277, 'n_units_Layer_1': 240, 'n_units_Layer_2': 55, 'n_units_Layer_3': 290}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 8.46% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.32 | sMAPE for Test Set is: 11.03% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:53:06,873]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:53:07,182]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:53:15,868]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:53:21,922]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:53:24,518]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:53:28,503]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:53:36,924]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:53:47,485]\u001b[0m Trial 995 finished with value: 4.110787106772375 and parameters: {'n_hidden': 3, 'learning_rate': 0.003420795764004555, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18886637811681412, 'dropout_rate_Layer_2': 0.3034786588643448, 'dropout_rate_Layer_3': 0.1539116688799312, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013698133114322115, 'l1_Layer_2': 0.00010754443767259284, 'l1_Layer_3': 0.00017545943384167953, 'n_units_Layer_1': 240, 'n_units_Layer_2': 55, 'n_units_Layer_3': 290}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 8.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.07 | sMAPE for Test Set is: 10.58% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:53:54,831]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:53:59,560]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:05,311]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:07,748]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:10,626]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:14,310]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:15,078]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:21,447]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:21,524]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:27,501]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:27,617]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:35,617]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:36,348]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:41,658]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:45,804]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:46,357]\u001b[0m Trial 997 finished with value: 4.226280035791395 and parameters: {'n_hidden': 3, 'learning_rate': 0.004034075827508199, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23104344540949265, 'dropout_rate_Layer_2': 0.3028907682034229, 'dropout_rate_Layer_3': 0.1667030615376982, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014128364459705626, 'l1_Layer_2': 0.0005978064429610059, 'l1_Layer_3': 0.00019318349871309028, 'n_units_Layer_1': 260, 'n_units_Layer_2': 255, 'n_units_Layer_3': 290}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 9.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.34 | sMAPE for Test Set is: 11.52% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:54:50,200]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:54,726]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:55,299]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:58,213]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:03,863]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:04,315]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:04,469]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:04,922]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:14,232]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:14,745]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:14,998]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:15,649]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:27,990]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:28,991]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:29,161]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:29,443]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:35,046]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:42,073]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:44,145]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:46,327]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:47,468]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:53,473]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:53,605]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:53,824]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:01,412]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:01,483]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:05,250]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:05,596]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:11,715]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:15,858]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:16,272]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:21,034]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:21,930]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:22,799]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:27,710]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:33,082]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:36,339]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:36,702]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:42,804]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:43,413]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:43,737]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:44,545]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:51,762]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:55,537]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:56,928]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:56:58,039]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:04,102]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:05,382]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:07,833]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:07,896]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:14,695]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:14,747]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:20,674]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:22,943]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:25,437]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:28,712]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:29,361]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:31,962]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:35,304]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:39,219]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:44,505]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:48,513]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:48,858]\u001b[0m Trial 1072 finished with value: 4.113726636395554 and parameters: {'n_hidden': 3, 'learning_rate': 0.002112665561395601, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15700704148272443, 'dropout_rate_Layer_2': 0.25797248315999766, 'dropout_rate_Layer_3': 0.2397569301716822, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.443417779726583e-05, 'l1_Layer_2': 0.0008365114930334938, 'l1_Layer_3': 0.00025109247699080597, 'n_units_Layer_1': 175, 'n_units_Layer_2': 260, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 8.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 3.87 | sMAPE for Test Set is: 10.09% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:57:48,997]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:57,876]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:02,928]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:03,610]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:08,760]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:14,595]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:19,223]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:23,790]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:29,332]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:35,739]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:36,018]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:37,731]\u001b[0m Trial 1081 finished with value: 3.5892943414096723 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019603471940713643, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05428597493288624, 'dropout_rate_Layer_2': 0.016478305787643813, 'dropout_rate_Layer_3': 0.23788628105415102, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.695009593846628e-05, 'l1_Layer_2': 0.0007942454728912665, 'l1_Layer_3': 0.0002365969461949798, 'n_units_Layer_1': 175, 'n_units_Layer_2': 260, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 7.69% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.61 | sMAPE for Test Set is: 9.32% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:58:42,238]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:44,773]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:46,779]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:50,405]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:53,546]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:53,666]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:54,214]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:56,022]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:01,338]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:02,320]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:09,504]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:13,628]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:20,389]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:22,514]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:26,976]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:31,374]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:35,000]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:36,713]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:41,995]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:45,854]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:51,277]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:55,242]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:59,345]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:59,665]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:05,134]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:09,955]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:13,109]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:16,969]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:17,702]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:22,959]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:26,412]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:31,827]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:35,127]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:39,231]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:43,157]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:48,156]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:59,768]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:04,529]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:08,399]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:13,060]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:16,345]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:19,904]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:22,340]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:26,810]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:29,800]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:36,654]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:37,214]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:49,615]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:52,411]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:59,457]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:13,505]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:18,037]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:21,964]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:25,899]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:26,332]\u001b[0m Trial 1148 finished with value: 3.6513090925221117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010660299760658892, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038811991692774765, 'dropout_rate_Layer_2': 0.04194099754650022, 'dropout_rate_Layer_3': 0.21802153346858152, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023421841604915152, 'l1_Layer_2': 2.279997315920027e-05, 'l1_Layer_3': 0.00013419812227295546, 'n_units_Layer_1': 235, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.72% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.66 | sMAPE for Test Set is: 9.50% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:02:32,938]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:37,288]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:45,063]\u001b[0m Trial 1112 finished with value: 3.4701756255275935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005105800026692423, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09080693243394104, 'dropout_rate_Layer_2': 0.20464484065370295, 'dropout_rate_Layer_3': 0.33258782893800964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009536647973988906, 'l1_Layer_2': 0.00029782392419707435, 'l1_Layer_3': 0.0031625348113828644, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 255}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 7.42% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.75 | sMAPE for Test Set is: 9.70% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:02:51,784]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:54,692]\u001b[0m Trial 1125 finished with value: 3.42700735500183 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005048420504938304, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02385492576741048, 'dropout_rate_Layer_2': 0.19215933053188966, 'dropout_rate_Layer_3': 0.33198791661074034, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.660435109949302e-05, 'l1_Layer_2': 0.0003005775717609939, 'l1_Layer_3': 0.0019785887914749818, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 7.32% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.68 | sMAPE for Test Set is: 9.60% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:02:57,370]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:03:00,589]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:03:03,638]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:03:08,085]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:03:08,499]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:03:14,858]\u001b[0m Trial 1156 finished with value: 3.6903148864478816 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018341553149667199, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0806335822545988, 'dropout_rate_Layer_2': 0.0003783677216104321, 'dropout_rate_Layer_3': 0.2801056362989197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.280585499545593e-05, 'l1_Layer_2': 0.001037485792470717, 'l1_Layer_3': 0.00023162681514268593, 'n_units_Layer_1': 155, 'n_units_Layer_2': 245, 'n_units_Layer_3': 265}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.81% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.73 | sMAPE for Test Set is: 9.69% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:03:19,264]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:03:19,966]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:03:27,057]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:03:33,205]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:03:33,906]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:03:34,259]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:03:36,772]\u001b[0m Trial 1154 finished with value: 3.685811567861497 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010721718644576522, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01870236102882394, 'dropout_rate_Layer_2': 0.23207425955927458, 'dropout_rate_Layer_3': 0.39230225448483186, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011038018074797001, 'l1_Layer_2': 0.00010019904843811372, 'l1_Layer_3': 0.00085028992688517, 'n_units_Layer_1': 170, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 7.84% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 10.34% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:03:45,714]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:00,556]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:04,913]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:07,481]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:11,536]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:22,535]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:26,086]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:26,425]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:31,915]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:32,462]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:40,971]\u001b[0m Trial 1172 finished with value: 4.461424460797338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037245137888298877, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22975326909845292, 'dropout_rate_Layer_2': 0.30387462830988454, 'dropout_rate_Layer_3': 0.1273556995159444, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.659635245973976e-05, 'l1_Layer_2': 0.0019936786215315142, 'l1_Layer_3': 0.0002085163524214263, 'n_units_Layer_1': 220, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 9.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 4.28 | sMAPE for Test Set is: 10.89% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:04:51,080]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:55,372]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:59,156]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:05:15,052]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:05:15,593]\u001b[0m Trial 1169 finished with value: 4.115080723909028 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035406552886641817, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22852480679563897, 'dropout_rate_Layer_2': 0.2829306255684178, 'dropout_rate_Layer_3': 0.12557067279348555, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9816322203188912e-05, 'l1_Layer_2': 0.0026489680721288314, 'l1_Layer_3': 0.00020657017228235594, 'n_units_Layer_1': 220, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 8.63% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 10.71% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:05:23,478]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:05:24,223]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:05:35,216]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:05:44,617]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:05:54,286]\u001b[0m Trial 1181 finished with value: 3.979778466661577 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024770918383311678, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23379045932591141, 'dropout_rate_Layer_2': 0.3101523023687445, 'dropout_rate_Layer_3': 0.12405985886463677, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007457194627050938, 'l1_Layer_2': 0.00046571888693870944, 'l1_Layer_3': 0.0005189333212440498, 'n_units_Layer_1': 260, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 8.40% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.17 | sMAPE for Test Set is: 11.05% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:05:59,716]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:06:03,414]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:06:07,701]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:06:21,672]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:06:40,236]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:06:45,910]\u001b[0m Trial 1189 finished with value: 4.021579694955765 and parameters: {'n_hidden': 3, 'learning_rate': 0.002521031071424037, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20587531970331785, 'dropout_rate_Layer_2': 0.2178545399372928, 'dropout_rate_Layer_3': 0.1707244857193427, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6464571959144403e-05, 'l1_Layer_2': 0.0007053622063433393, 'l1_Layer_3': 0.0003649663816877141, 'n_units_Layer_1': 215, 'n_units_Layer_2': 115, 'n_units_Layer_3': 295}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 8.42% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.97 | sMAPE for Test Set is: 10.36% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:06:54,353]\u001b[0m Trial 1192 finished with value: 3.599174938854558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009767663454280707, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05367335469083313, 'dropout_rate_Layer_2': 0.011703945569747604, 'dropout_rate_Layer_3': 0.07910480855331348, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003994957105232098, 'l1_Layer_2': 1.9812588742663493e-05, 'l1_Layer_3': 0.0006060154223954523, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 7.61% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.57 | sMAPE for Test Set is: 9.47% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:07:02,926]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:07:12,539]\u001b[0m Trial 1197 finished with value: 3.651465305548362 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007894647143084224, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03483015202102855, 'dropout_rate_Layer_2': 0.04339876337984254, 'dropout_rate_Layer_3': 0.08651544961276379, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018866751445762108, 'l1_Layer_2': 3.855968192526301e-05, 'l1_Layer_3': 0.0010723823811214788, 'n_units_Layer_1': 205, 'n_units_Layer_2': 265, 'n_units_Layer_3': 235}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.70% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.58 | sMAPE for Test Set is: 9.32% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:07:14,821]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:07:21,720]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:07:22,032]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:07:31,402]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:07:31,903]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:07:38,783]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:07:39,763]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:07:45,937]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:07:47,740]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:07:59,772]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:08:05,365]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:08:17,432]\u001b[0m Trial 1199 finished with value: 3.5878090886408174 and parameters: {'n_hidden': 3, 'learning_rate': 0.000798866052506258, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012957711583696681, 'dropout_rate_Layer_2': 0.042795947725603536, 'dropout_rate_Layer_3': 0.07339316978496577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016589300251299386, 'l1_Layer_2': 4.04116315924123e-05, 'l1_Layer_3': 0.0017012757004701625, 'n_units_Layer_1': 205, 'n_units_Layer_2': 260, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 7.58% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.68 | sMAPE for Test Set is: 9.63% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:08:22,669]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:08:27,622]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:08:32,452]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:08:35,751]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:08:36,746]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:08:42,005]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:08:43,272]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 7.37% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.60 | sMAPE for Test Set is: 9.27% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:08:46,130]\u001b[0m Trial 1207 finished with value: 3.4843869849306905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008363729840257348, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03823472395296883, 'dropout_rate_Layer_2': 0.04600676807243767, 'dropout_rate_Layer_3': 0.07875210135019538, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020418941187800616, 'l1_Layer_2': 3.904505913990521e-05, 'l1_Layer_3': 1.9221050543576602e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 255, 'n_units_Layer_3': 235}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:08:53,606]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:09:03,721]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:09:09,160]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:09:17,672]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:09:31,990]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:09:39,323]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:09:39,487]\u001b[0m Trial 1226 finished with value: 3.7148101728435887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013613437688633377, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13227214113932614, 'dropout_rate_Layer_2': 0.032699358566886605, 'dropout_rate_Layer_3': 0.2897637178122115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.629088301873268e-05, 'l1_Layer_2': 0.0003617586090025734, 'l1_Layer_3': 6.007099749618424e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 295}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.88% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.75 | sMAPE for Test Set is: 9.65% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:09:53,250]\u001b[0m Trial 1217 finished with value: 3.556859632528056 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006960804417628455, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012663249376727869, 'dropout_rate_Layer_2': 0.01950850674041896, 'dropout_rate_Layer_3': 0.07712099608908754, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019511137566931343, 'l1_Layer_2': 4.216095574968825e-05, 'l1_Layer_3': 0.001899314075343085, 'n_units_Layer_1': 210, 'n_units_Layer_2': 265, 'n_units_Layer_3': 240}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 7.60% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.70 | sMAPE for Test Set is: 9.66% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:09:59,911]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:10:07,262]\u001b[0m Trial 1222 finished with value: 3.605727786520839 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007315662076194767, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003935504409339052, 'dropout_rate_Layer_2': 0.04844768307444714, 'dropout_rate_Layer_3': 0.07310656674651764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011374443021381865, 'l1_Layer_2': 4.572686419374978e-05, 'l1_Layer_3': 0.0011578976526379634, 'n_units_Layer_1': 210, 'n_units_Layer_2': 250, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.64% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.73 | sMAPE for Test Set is: 9.53% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:10:12,142]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:10:23,845]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:10:35,495]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:10:40,779]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:10:45,023]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:10:58,217]\u001b[0m Trial 1229 finished with value: 3.522577681172937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007064291470449657, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01388048227724192, 'dropout_rate_Layer_2': 0.02134427263995585, 'dropout_rate_Layer_3': 0.08226566097924956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020492561541655906, 'l1_Layer_2': 5.379375340063376e-05, 'l1_Layer_3': 0.002149805670143517, 'n_units_Layer_1': 190, 'n_units_Layer_2': 255, 'n_units_Layer_3': 220}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 7.46% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.64 | sMAPE for Test Set is: 9.37% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:10:59,455]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:03,472]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:06,911]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:12,171]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:16,654]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:21,007]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:23,999]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:26,887]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:27,301]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:35,438]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:35,613]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:42,401]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:45,358]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:57,464]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:00,982]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:04,502]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:06,702]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:11,118]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:11,843]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:15,051]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:20,858]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:24,577]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:31,027]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:33,670]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:40,049]\u001b[0m Trial 1231 finished with value: 3.546820621499497 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005127047994301633, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.001409120991062886, 'dropout_rate_Layer_2': 0.005059858678495736, 'dropout_rate_Layer_3': 0.06605091814501435, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016611380259550098, 'l1_Layer_2': 7.220067328744762e-05, 'l1_Layer_3': 0.003124193000183477, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 7.57% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.63 | sMAPE for Test Set is: 9.42% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:12:40,909]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:53,615]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:58,341]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:00,785]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:05,407]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:08,037]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:08,093]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:19,244]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:24,577]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:29,311]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:31,788]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:37,389]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:40,696]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:46,349]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:51,354]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:57,127]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:01,141]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:14,908]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:16,775]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:19,188]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:32,734]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:35,425]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:36,068]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:52,805]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:15:10,810]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:15:22,568]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:15:30,571]\u001b[0m Trial 1286 finished with value: 3.565883926061057 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007092009409808088, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07144199919119099, 'dropout_rate_Layer_2': 0.016547091975363852, 'dropout_rate_Layer_3': 0.3050849531655006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8742004506057993e-05, 'l1_Layer_2': 0.00013493380147333524, 'l1_Layer_3': 2.4015544576741296e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 280, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 7.60% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.62 | sMAPE for Test Set is: 9.47% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:15:50,857]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:15:58,585]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:16:03,562]\u001b[0m Trial 1285 finished with value: 3.672852396790971 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005109954435166899, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013553391092033098, 'dropout_rate_Layer_2': 0.01950791714854573, 'dropout_rate_Layer_3': 0.03648521479312855, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008509289238082062, 'l1_Layer_2': 0.00010889248067446163, 'l1_Layer_3': 1.1283588688110903e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 230, 'n_units_Layer_3': 225}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 8.05% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.70 | sMAPE for Test Set is: 9.67% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:16:08,819]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:16:18,143]\u001b[0m Trial 1284 finished with value: 3.7120752485189414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006222696565862068, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012471581793552112, 'dropout_rate_Layer_2': 0.020674726642004274, 'dropout_rate_Layer_3': 0.06588233034457275, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006989299033689929, 'l1_Layer_2': 6.973611157421882e-05, 'l1_Layer_3': 0.0022285641528530945, 'n_units_Layer_1': 220, 'n_units_Layer_2': 240, 'n_units_Layer_3': 215}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 7.87% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.72 | sMAPE for Test Set is: 9.72% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:16:23,125]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:16:24,156]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:16:31,096]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:16:47,975]\u001b[0m Trial 1294 finished with value: 3.654743122965361 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007303391316105326, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.033428431641518624, 'dropout_rate_Layer_2': 0.27732732276822014, 'dropout_rate_Layer_3': 0.3237546545287032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3430611198939511e-05, 'l1_Layer_2': 8.60872048873183e-05, 'l1_Layer_3': 7.992731455779991e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 250, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.77% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.80 | sMAPE for Test Set is: 9.98% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:16:54,922]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:04,370]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:25,668]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:30,316]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:32,318]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:35,811]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:39,773]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:40,510]\u001b[0m Trial 1299 finished with value: 3.6140290353617863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006013861702032379, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0008144150418182353, 'dropout_rate_Layer_2': 0.01660762684507276, 'dropout_rate_Layer_3': 0.03499831608051163, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004541578004532584, 'l1_Layer_2': 7.251902384738441e-05, 'l1_Layer_3': 1.076242756105596e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 235, 'n_units_Layer_3': 215}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.73% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.71 | sMAPE for Test Set is: 9.75% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:17:45,839]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:48,264]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:54,075]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:58,060]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:04,110]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:12,621]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:25,594]\u001b[0m Trial 1303 finished with value: 3.6412250295964035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007213815931573463, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.032239231704424554, 'dropout_rate_Layer_2': 0.330357623837476, 'dropout_rate_Layer_3': 0.34012849953935437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8407433306995182e-05, 'l1_Layer_2': 8.491309385171774e-05, 'l1_Layer_3': 3.0394159385893346e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 280, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.71% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.96 | sMAPE for Test Set is: 10.17% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:18:32,679]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:57,716]\u001b[0m Trial 1308 finished with value: 3.857603912135964 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029724245722660583, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22102076803871765, 'dropout_rate_Layer_2': 0.2871024466467786, 'dropout_rate_Layer_3': 0.1614257540597601, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00183860202332722, 'l1_Layer_2': 0.0013710702017361576, 'l1_Layer_3': 0.00023976343437454007, 'n_units_Layer_1': 255, 'n_units_Layer_2': 150, 'n_units_Layer_3': 295}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 8.01% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 4.02 | sMAPE for Test Set is: 10.33% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:19:03,669]\u001b[0m Trial 1314 finished with value: 4.1692648673113055 and parameters: {'n_hidden': 3, 'learning_rate': 0.004042775948307865, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22663580934905136, 'dropout_rate_Layer_2': 0.28461100605681444, 'dropout_rate_Layer_3': 0.13759236557233406, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015953770736354719, 'l1_Layer_2': 0.0008534929853604866, 'l1_Layer_3': 0.0001612158472970805, 'n_units_Layer_1': 245, 'n_units_Layer_2': 165, 'n_units_Layer_3': 270}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 8.57% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 10.41% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:19:22,411]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:19:42,753]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:19:47,158]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:20:02,748]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:20:09,086]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:20:17,072]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:20:18,603]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:20:25,910]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:20:25,985]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:20:54,277]\u001b[0m Trial 1315 finished with value: 3.697630031951313 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005478728495113607, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012360638074117535, 'dropout_rate_Layer_2': 0.015200415368483098, 'dropout_rate_Layer_3': 0.03985386050453003, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012785174565976317, 'l1_Layer_2': 9.092449813836792e-05, 'l1_Layer_3': 2.0582547400232493e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 235, 'n_units_Layer_3': 210}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.80% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.59 | sMAPE for Test Set is: 9.21% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:21:04,781]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:21:10,822]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:21:16,083]\u001b[0m Trial 1327 finished with value: 3.8366510949306387 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005846168994766879, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031382814974299976, 'dropout_rate_Layer_2': 0.3276933813526541, 'dropout_rate_Layer_3': 0.35295372799185004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2459682039516743e-05, 'l1_Layer_2': 6.675856161175787e-05, 'l1_Layer_3': 1.3987489055554775e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 285, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 8.08% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.89 | sMAPE for Test Set is: 9.99% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:21:19,844]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:21:28,209]\u001b[0m Trial 1320 finished with value: 3.6239712083994564 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005826046852301517, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030122910829248457, 'dropout_rate_Layer_2': 0.3204476180030484, 'dropout_rate_Layer_3': 0.34272475055966795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031484344498923732, 'l1_Layer_2': 7.631888059830609e-05, 'l1_Layer_3': 1.3779256380020754e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 280, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.66% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.79 | sMAPE for Test Set is: 9.87% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:21:44,257]\u001b[0m Trial 1326 finished with value: 3.523704399932697 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005638588232189664, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024037811201466988, 'dropout_rate_Layer_2': 0.3345641046630231, 'dropout_rate_Layer_3': 0.35882851808482535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023299422865835344, 'l1_Layer_2': 6.741541123442746e-05, 'l1_Layer_3': 1.583549851834974e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 7.48% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.65 | sMAPE for Test Set is: 9.53% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:21:47,675]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:21:48,268]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:21:50,864]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:21:58,092]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:22:07,121]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:22:09,031]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:22:10,074]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:22:20,827]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:22:56,641]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:13,773]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:18,275]\u001b[0m Trial 1339 finished with value: 3.6374016130791915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005917540637832648, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009973137312230752, 'dropout_rate_Layer_2': 0.02400696976069626, 'dropout_rate_Layer_3': 0.05433361475049463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009132841216590885, 'l1_Layer_2': 6.709586531993614e-05, 'l1_Layer_3': 1.4986853640779464e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 235, 'n_units_Layer_3': 205}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.71% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.73 | sMAPE for Test Set is: 9.64% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:23:26,392]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:26,625]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:53,143]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:58,828]\u001b[0m Trial 1341 finished with value: 3.5595580910404294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005814580310551585, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010838757143836045, 'dropout_rate_Layer_2': 0.025942868074155207, 'dropout_rate_Layer_3': 0.021043498698906267, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013779999046434892, 'l1_Layer_2': 6.808075062043949e-05, 'l1_Layer_3': 1.700996777549001e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 225, 'n_units_Layer_3': 215}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 7.56% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.55 | sMAPE for Test Set is: 9.28% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:24:06,798]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:24:11,642]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:24:14,996]\u001b[0m Trial 1345 finished with value: 3.736080139591263 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005566131565935215, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00932067597163283, 'dropout_rate_Layer_2': 0.02813894929554478, 'dropout_rate_Layer_3': 0.05427101559499601, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026843304678321895, 'l1_Layer_2': 8.008113912695404e-05, 'l1_Layer_3': 1.5650001486972035e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 235, 'n_units_Layer_3': 215}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.81 | sMAPE for Test Set is: 9.79% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:24:26,042]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:24:44,722]\u001b[0m Trial 1342 finished with value: 3.585838986721056 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005056826477096373, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011102034020725236, 'dropout_rate_Layer_2': 0.02100214371345261, 'dropout_rate_Layer_3': 0.011400793636882057, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015115502947965, 'l1_Layer_2': 7.580133602519217e-05, 'l1_Layer_3': 1.4419986609739172e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 225, 'n_units_Layer_3': 215}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 7.66% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.74 | sMAPE for Test Set is: 9.78% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:24:47,199]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:24:52,613]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:24:58,517]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:04,227]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:17,908]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:23,166]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:32,611]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:45,664]\u001b[0m Trial 1354 finished with value: 3.679300776588518 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005089573801439158, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007798767448365434, 'dropout_rate_Layer_2': 0.031815276229981204, 'dropout_rate_Layer_3': 0.011479571273080108, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002509177710356156, 'l1_Layer_2': 0.00011688460585117637, 'l1_Layer_3': 1.9386865579032858e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 220, 'n_units_Layer_3': 205}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.85% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.82 | sMAPE for Test Set is: 9.81% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:25:49,473]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:53,455]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:57,961]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:26:24,635]\u001b[0m Trial 1359 finished with value: 3.6099816818846118 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005714005629618935, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0005361820669711921, 'dropout_rate_Layer_2': 0.03194284655524131, 'dropout_rate_Layer_3': 0.00014282918727011144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00039704033250615177, 'l1_Layer_2': 9.668955582737014e-05, 'l1_Layer_3': 2.5594459419154045e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 230, 'n_units_Layer_3': 210}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.73% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.67 | sMAPE for Test Set is: 9.86% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:26:47,021]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:26:54,701]\u001b[0m Trial 1363 finished with value: 3.6518358531991084 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005003291055613933, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01587971630112136, 'dropout_rate_Layer_2': 0.018476113559351748, 'dropout_rate_Layer_3': 0.011699050778200767, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003182849423971199, 'l1_Layer_2': 0.00016114287809467325, 'l1_Layer_3': 1.6898891470229674e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 215, 'n_units_Layer_3': 200}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.78% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.66 | sMAPE for Test Set is: 9.56% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:26:59,337]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:27:03,488]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:27:44,288]\u001b[0m Trial 1366 finished with value: 3.780418937075293 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028775553582925293, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23744996529907766, 'dropout_rate_Layer_2': 0.282053176886915, 'dropout_rate_Layer_3': 0.1773663356452504, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018898379654860332, 'l1_Layer_2': 0.00043184031673966993, 'l1_Layer_3': 0.00011820225770948288, 'n_units_Layer_1': 240, 'n_units_Layer_2': 130, 'n_units_Layer_3': 300}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 7.97% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 4.50 | sMAPE for Test Set is: 11.13% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:27:44,633]\u001b[0m Trial 1362 finished with value: 3.6209200945548594 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005000919635442515, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018970992031797532, 'dropout_rate_Layer_2': 0.019343137039916504, 'dropout_rate_Layer_3': 0.012666697715935772, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011801413540613594, 'l1_Layer_2': 0.00011397936629602642, 'l1_Layer_3': 2.6263906140527503e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 210}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.74% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.73 | sMAPE for Test Set is: 9.71% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:27:57,128]\u001b[0m Trial 1368 finished with value: 3.616787339915805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005853516288706756, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0001088737314155451, 'dropout_rate_Layer_2': 0.01809465002215599, 'dropout_rate_Layer_3': 0.00993750222645544, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004041076390820273, 'l1_Layer_2': 0.00011010620363001685, 'l1_Layer_3': 1.6459403779564915e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 210, 'n_units_Layer_3': 200}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.74% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.77 | sMAPE for Test Set is: 9.90% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:27:58,910]\u001b[0m Trial 1369 finished with value: 3.7666686561859084 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005844665958731982, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0007136494224331385, 'dropout_rate_Layer_2': 0.01924514942941604, 'dropout_rate_Layer_3': 0.0032107224819414443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024134942277137522, 'l1_Layer_2': 0.0001224429484565759, 'l1_Layer_3': 1.604569488600002e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 225, 'n_units_Layer_3': 195}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 8.02% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.85 | sMAPE for Test Set is: 9.99% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:28:10,140]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:28:22,269]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:28:31,535]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:28:34,612]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:28:42,112]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:28:45,554]\u001b[0m Trial 1370 finished with value: 3.6819501080398673 and parameters: {'n_hidden': 3, 'learning_rate': 0.000561054095930201, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01718657630536525, 'dropout_rate_Layer_2': 0.01696736910222645, 'dropout_rate_Layer_3': 0.012554090336123572, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035319635813273924, 'l1_Layer_2': 9.645208935518791e-05, 'l1_Layer_3': 2.7579292156152974e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 215, 'n_units_Layer_3': 200}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 7.87% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 10.53% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:28:48,651]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:28:57,077]\u001b[0m Trial 1372 finished with value: 3.6744347828959625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005817710219018727, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008680707254989643, 'dropout_rate_Layer_2': 0.015160756785233744, 'dropout_rate_Layer_3': 0.00039666201728100203, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037059411726995907, 'l1_Layer_2': 0.0001392285572165499, 'l1_Layer_3': 3.171641049749015e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 205, 'n_units_Layer_3': 200}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 7.85% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 10.06% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:28:59,771]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:29:01,127]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:29:07,690]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:29:11,426]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:29:15,978]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:29:30,685]\u001b[0m Trial 1381 finished with value: 4.147977154722207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008744409459373348, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0111363497521335, 'dropout_rate_Layer_2': 0.3583587691780285, 'dropout_rate_Layer_3': 0.3615917637251006, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024342153229488692, 'l1_Layer_2': 5.377146003461761e-05, 'l1_Layer_3': 2.895684121560258e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 220}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.15 | sMAPE for Validation Set is: 8.60% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.08 | sMAPE for Test Set is: 10.50% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:29:33,386]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:29:45,796]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:29:55,474]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:30:01,498]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:30:11,813]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:30:17,644]\u001b[0m Trial 1387 finished with value: 3.983980416627792 and parameters: {'n_hidden': 3, 'learning_rate': 0.002755088104598302, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21442858000323983, 'dropout_rate_Layer_2': 0.2685291897216163, 'dropout_rate_Layer_3': 0.17850422138626984, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007922790991190552, 'l1_Layer_2': 0.0002773137258328726, 'l1_Layer_3': 0.00010197184589323587, 'n_units_Layer_1': 240, 'n_units_Layer_2': 130, 'n_units_Layer_3': 100}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.98 | sMAPE for Validation Set is: 8.39% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.02 | sMAPE for Test Set is: 10.42% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:30:20,907]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:30:25,757]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:30:45,718]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:31:00,016]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:31:14,608]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:31:25,390]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:31:31,382]\u001b[0m Trial 1396 finished with value: 3.7846659946092025 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005029364077075592, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0241823181384037, 'dropout_rate_Layer_2': 0.01842000092099135, 'dropout_rate_Layer_3': 0.02735908409804142, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023442327361453664, 'l1_Layer_2': 0.00011078212048610111, 'l1_Layer_3': 3.185643088117581e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 215, 'n_units_Layer_3': 200}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 8.01% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.84 | sMAPE for Test Set is: 9.94% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:31:33,667]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:31:40,744]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:31:46,553]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:31:52,063]\u001b[0m Trial 1398 finished with value: 3.7374820692518127 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005036860174991194, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0257451266079938, 'dropout_rate_Layer_2': 0.017409458184636628, 'dropout_rate_Layer_3': 0.02719973769978145, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002636876719367783, 'l1_Layer_2': 0.0001160508646406629, 'l1_Layer_3': 3.062799903805651e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 215, 'n_units_Layer_3': 200}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 7.92% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.89 | sMAPE for Test Set is: 10.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:32:08,893]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:32:20,065]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:32:20,796]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:32:29,922]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:32:30,793]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:32:32,549]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:32:41,183]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:32:42,875]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:32:45,476]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:32:50,129]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:32:51,047]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:32:56,942]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:33:02,355]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:33:05,561]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:33:09,235]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:33:12,204]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:33:24,553]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:33:28,712]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:33:47,397]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:33:51,638]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:34:13,443]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:34:18,586]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:34:43,971]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:34:47,944]\u001b[0m Trial 1423 finished with value: 4.021774264320981 and parameters: {'n_hidden': 3, 'learning_rate': 0.00244975915137224, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21239983790501865, 'dropout_rate_Layer_2': 0.2849401839415278, 'dropout_rate_Layer_3': 0.12641596389188625, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016081276270527125, 'l1_Layer_2': 0.001851045574569665, 'l1_Layer_3': 0.00015474626822585818, 'n_units_Layer_1': 250, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 8.37% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 4.09 | sMAPE for Test Set is: 10.36% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:34:50,976]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:34:55,959]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:35:02,545]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:35:07,066]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:35:14,658]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:35:19,260]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:35:24,092]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:35:30,870]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:35:35,519]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:35:46,906]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:35:51,555]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:36:03,546]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:36:14,784]\u001b[0m Trial 1419 finished with value: 3.6113153716860764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005454846994828735, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09996586537826121, 'dropout_rate_Layer_2': 0.15724227775314087, 'dropout_rate_Layer_3': 0.3855956844332751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047022627067762844, 'l1_Layer_2': 0.00014849390576144653, 'l1_Layer_3': 0.00043846990620425, 'n_units_Layer_1': 210, 'n_units_Layer_2': 135, 'n_units_Layer_3': 285}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 7.65% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.80 | sMAPE for Test Set is: 9.86% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:36:21,084]\u001b[0m Trial 1435 finished with value: 3.648592176973279 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005567124368450875, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00947053624948527, 'dropout_rate_Layer_2': 0.03273999123988498, 'dropout_rate_Layer_3': 0.009625568420614941, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003936547123517001, 'l1_Layer_2': 0.0001106842535603244, 'l1_Layer_3': 2.152997217274026e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 210, 'n_units_Layer_3': 185}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 7.88% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.80 | sMAPE for Test Set is: 10.01% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:36:25,527]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:36:33,715]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:36:38,677]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:37:04,415]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:37:13,263]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:37:20,633]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:37:36,590]\u001b[0m Trial 1444 finished with value: 3.7316369741268844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006611527857584616, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00016585446510200205, 'dropout_rate_Layer_2': 0.03321449156886656, 'dropout_rate_Layer_3': 0.016380971142145102, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003317729295120705, 'l1_Layer_2': 0.00015659223492583933, 'l1_Layer_3': 2.716682310352732e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 210, 'n_units_Layer_3': 190}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 7.94% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.84 | sMAPE for Test Set is: 10.14% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:37:41,506]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:37:46,223]\u001b[0m Trial 1446 finished with value: 3.6551387828261057 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006514081352297009, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006576268954861142, 'dropout_rate_Layer_2': 0.03375398676694964, 'dropout_rate_Layer_3': 0.010150938194943327, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003838000219761077, 'l1_Layer_2': 0.00012113389688892689, 'l1_Layer_3': 2.6770010605917375e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 200, 'n_units_Layer_3': 180}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 7.84% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.85 | sMAPE for Test Set is: 9.95% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:37:47,013]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:37:53,383]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:37:59,592]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:38:00,473]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:38:12,021]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:38:22,799]\u001b[0m Trial 1448 finished with value: 3.642483303828834 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007520379062325006, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03324508180962127, 'dropout_rate_Layer_2': 0.31452690377722803, 'dropout_rate_Layer_3': 0.3259778406249767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.030238375196176e-05, 'l1_Layer_2': 0.00016457731313827435, 'l1_Layer_3': 2.4610868028087946e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 280, 'n_units_Layer_3': 230}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 7.67% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 3.82 | sMAPE for Test Set is: 9.85% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:38:25,766]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:38:29,239]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:38:46,764]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:38:48,166]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:38:53,654]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:38:54,644]\u001b[0m Trial 1449 finished with value: 3.7760298269746735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006057310270143304, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012153001020607955, 'dropout_rate_Layer_2': 0.025201331141418544, 'dropout_rate_Layer_3': 0.012769828230273438, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021913207139294424, 'l1_Layer_2': 0.00012733875061417483, 'l1_Layer_3': 1.2380604546063246e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 200, 'n_units_Layer_3': 180}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 8.00% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.86 | sMAPE for Test Set is: 9.95% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:39:01,742]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:39:41,122]\u001b[0m Trial 1460 finished with value: 3.7005215478029796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007471514182943519, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013026318669253585, 'dropout_rate_Layer_2': 0.025551915307268643, 'dropout_rate_Layer_3': 0.026130766659602317, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002880175066860864, 'l1_Layer_2': 6.798504863717386e-05, 'l1_Layer_3': 1.7943848069644693e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 8.01% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.70 | sMAPE for Test Set is: 9.68% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:40:28,993]\u001b[0m Trial 1462 finished with value: 3.7031876514677236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005564113552357124, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.057369624460444385, 'dropout_rate_Layer_2': 0.2314782302379966, 'dropout_rate_Layer_3': 0.38512236766951813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006811470999220268, 'l1_Layer_2': 0.00010404562565517818, 'l1_Layer_3': 0.0003398551840803881, 'n_units_Layer_1': 205, 'n_units_Layer_2': 145, 'n_units_Layer_3': 280}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 7.89% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 3.98 | sMAPE for Test Set is: 10.28% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:40:32,412]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:40:44,481]\u001b[0m Trial 1464 finished with value: 3.7527834582099877 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005517591729448391, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028428549889591672, 'dropout_rate_Layer_2': 0.03826549950291368, 'dropout_rate_Layer_3': 0.008204106674745392, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005640516029875819, 'l1_Layer_2': 7.68782362411866e-05, 'l1_Layer_3': 2.2056001791130216e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 190, 'n_units_Layer_3': 190}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 7.96% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 4.10 | sMAPE for Test Set is: 10.46% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:40:49,352]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:40:59,741]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:41:10,777]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:41:19,646]\u001b[0m Trial 1463 finished with value: 3.6186087491037235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005525710972215435, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02823907226100945, 'dropout_rate_Layer_2': 0.03749009089813808, 'dropout_rate_Layer_3': 0.006119270882073143, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006169662973294754, 'l1_Layer_2': 7.794144893790091e-05, 'l1_Layer_3': 1.506731368538956e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 190, 'n_units_Layer_3': 190}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 7.75% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 3.71 | sMAPE for Test Set is: 9.76% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:41:21,831]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:41:27,361]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:41:32,456]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:41:47,974]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:41:52,416]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:41:57,090]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:41:57,966]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:42:07,360]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:42:19,952]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:42:27,677]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:42:31,053]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:42:31,315]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:42:38,899]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:42:52,338]\u001b[0m Trial 1478 finished with value: 3.661013536288419 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006568614957961317, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020662271496482712, 'dropout_rate_Layer_2': 0.019686601858443623, 'dropout_rate_Layer_3': 0.02254303735865137, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005007169962235022, 'l1_Layer_2': 7.710673902478583e-05, 'l1_Layer_3': 2.51806298964929e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 210, 'n_units_Layer_3': 205}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 7.81% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 4.01 | sMAPE for Test Set is: 10.14% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:42:55,806]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:42:56,016]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:42:57,471]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:42:58,043]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:43:07,414]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:43:12,049]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:43:12,447]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:43:16,109]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:43:17,926]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:43:38,368]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:43:39,290]\u001b[0m Trial 1494 finished with value: 3.509805942175275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009269425305661195, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017817344243092836, 'dropout_rate_Layer_2': 0.2942018380883049, 'dropout_rate_Layer_3': 0.04154905029090311, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.123236832945543e-05, 'l1_Layer_2': 2.8798652132488416e-05, 'l1_Layer_3': 4.2901645418922444e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 235}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.51 | sMAPE for Validation Set is: 7.44% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.66 | sMAPE for Test Set is: 9.56% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:43:47,757]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:43:51,164]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:44:01,446]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:44:02,564]\u001b[0m Trial 1495 finished with value: 3.8955649069856215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019352461147626712, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23844254422846858, 'dropout_rate_Layer_2': 0.2801775101773812, 'dropout_rate_Layer_3': 0.21553458175571416, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008386682653095923, 'l1_Layer_2': 0.0003702316387479033, 'l1_Layer_3': 0.0001773995175393568, 'n_units_Layer_1': 240, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 8.04% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 10.14% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:44:06,236]\u001b[0m Trial 1492 finished with value: 4.10619235097585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019418867766786314, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24769630794733205, 'dropout_rate_Layer_2': 0.3217902940524765, 'dropout_rate_Layer_3': 0.15100125117861157, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009976153796880747, 'l1_Layer_2': 0.0003741003527791722, 'l1_Layer_3': 0.00018241897960558128, 'n_units_Layer_1': 215, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 560 with value: 3.42286095762608.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 8.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.42 | sMAPE for Test Set is: 11.13% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:44:07,161]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-01-01, MAE is:4.80 & sMAPE is:8.10% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 8.10% & 2.30\n",
      "for 2019-01-02, MAE is:7.59 & sMAPE is:11.89% & rMAE is:3.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 10.00% & 2.66\n",
      "for 2019-01-03, MAE is:2.23 & sMAPE is:3.50% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 7.83% & 1.97\n",
      "for 2019-01-04, MAE is:2.07 & sMAPE is:3.15% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 6.66% & 1.63\n",
      "for 2019-01-05, MAE is:4.03 & sMAPE is:6.36% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 6.60% & 1.40\n",
      "for 2019-01-06, MAE is:2.38 & sMAPE is:4.00% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 6.17% & 1.43\n",
      "for 2019-01-07, MAE is:2.45 & sMAPE is:3.99% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 5.86% & 1.35\n",
      "for 2019-01-08, MAE is:3.90 & sMAPE is:6.10% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 5.89% & 1.28\n",
      "for 2019-01-09, MAE is:3.53 & sMAPE is:5.91% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 5.89% & 1.29\n",
      "for 2019-01-10, MAE is:2.86 & sMAPE is:5.03% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 5.80% & 1.31\n",
      "for 2019-01-11, MAE is:3.81 & sMAPE is:5.84% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.61 & 5.81% & 1.30\n",
      "for 2019-01-12, MAE is:2.24 & sMAPE is:3.60% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.49 & 5.62% & 1.23\n",
      "for 2019-01-13, MAE is:3.00 & sMAPE is:5.07% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.45 & 5.58% & 1.23\n",
      "for 2019-01-14, MAE is:4.31 & sMAPE is:6.53% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 5.65% & 1.31\n",
      "for 2019-01-15, MAE is:2.97 & sMAPE is:4.57% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 5.58% & 1.27\n",
      "for 2019-01-16, MAE is:3.15 & sMAPE is:4.81% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 5.53% & 1.21\n",
      "for 2019-01-17, MAE is:3.16 & sMAPE is:4.75% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 5.48% & 1.20\n",
      "for 2019-01-18, MAE is:3.22 & sMAPE is:4.98% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 5.45% & 1.18\n",
      "for 2019-01-19, MAE is:2.34 & sMAPE is:3.66% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 5.36% & 1.15\n",
      "for 2019-01-20, MAE is:3.77 & sMAPE is:6.42% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 5.41% & 1.14\n",
      "for 2019-01-21, MAE is:3.42 & sMAPE is:5.32% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 5.41% & 1.15\n",
      "for 2019-01-22, MAE is:3.51 & sMAPE is:5.47% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 5.41% & 1.14\n",
      "for 2019-01-23, MAE is:2.63 & sMAPE is:4.69% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 5.38% & 1.10\n",
      "for 2019-01-24, MAE is:4.04 & sMAPE is:6.73% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 5.44% & 1.09\n",
      "for 2019-01-25, MAE is:2.48 & sMAPE is:4.08% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 5.38% & 1.07\n",
      "for 2019-01-26, MAE is:3.45 & sMAPE is:5.67% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 5.39% & 1.06\n",
      "for 2019-01-27, MAE is:9.66 & sMAPE is:22.92% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 6.04% & 1.04\n",
      "for 2019-01-28, MAE is:4.35 & sMAPE is:8.01% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.62 & 6.11% & 1.02\n",
      "for 2019-01-29, MAE is:6.07 & sMAPE is:9.74% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 6.24% & 1.03\n",
      "for 2019-01-30, MAE is:5.46 & sMAPE is:10.11% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 6.37% & 1.05\n",
      "for 2019-01-31, MAE is:3.69 & sMAPE is:6.91% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 6.38% & 1.04\n",
      "for 2019-02-01, MAE is:3.53 & sMAPE is:6.71% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 6.39% & 1.02\n",
      "for 2019-02-02, MAE is:14.61 & sMAPE is:33.81% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 7.22% & 1.01\n",
      "for 2019-02-03, MAE is:6.14 & sMAPE is:14.61% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 7.44% & 1.00\n",
      "for 2019-02-04, MAE is:4.24 & sMAPE is:7.43% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 7.44% & 1.01\n",
      "for 2019-02-05, MAE is:3.24 & sMAPE is:5.51% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 7.39% & 1.02\n",
      "for 2019-02-06, MAE is:4.14 & sMAPE is:7.39% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 7.39% & 1.01\n",
      "for 2019-02-07, MAE is:3.53 & sMAPE is:6.15% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 7.36% & 1.01\n",
      "for 2019-02-08, MAE is:5.01 & sMAPE is:8.68% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 7.39% & 1.01\n",
      "for 2019-02-09, MAE is:5.25 & sMAPE is:10.02% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 7.46% & 0.99\n",
      "for 2019-02-10, MAE is:11.49 & sMAPE is:32.62% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 8.07% & 0.99\n",
      "for 2019-02-11, MAE is:3.36 & sMAPE is:6.54% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 8.03% & 0.99\n",
      "for 2019-02-12, MAE is:3.60 & sMAPE is:6.35% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 7.99% & 1.01\n",
      "for 2019-02-13, MAE is:4.02 & sMAPE is:7.11% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 7.97% & 1.03\n",
      "for 2019-02-14, MAE is:3.52 & sMAPE is:6.47% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 7.94% & 1.03\n",
      "for 2019-02-15, MAE is:2.86 & sMAPE is:5.18% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 7.88% & 1.02\n",
      "for 2019-02-16, MAE is:4.08 & sMAPE is:7.85% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 7.88% & 1.02\n",
      "for 2019-02-17, MAE is:2.79 & sMAPE is:5.81% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 7.84% & 1.00\n",
      "for 2019-02-18, MAE is:2.93 & sMAPE is:5.52% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 7.79% & 1.00\n",
      "for 2019-02-19, MAE is:2.50 & sMAPE is:4.51% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 7.72% & 1.00\n",
      "for 2019-02-20, MAE is:3.26 & sMAPE is:5.69% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 7.68% & 1.00\n",
      "for 2019-02-21, MAE is:3.13 & sMAPE is:5.80% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 7.65% & 1.01\n",
      "for 2019-02-22, MAE is:2.76 & sMAPE is:5.17% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 7.60% & 1.01\n",
      "for 2019-02-23, MAE is:2.01 & sMAPE is:3.98% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 7.53% & 1.01\n",
      "for 2019-02-24, MAE is:3.45 & sMAPE is:6.92% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 7.52% & 1.01\n",
      "for 2019-02-25, MAE is:2.23 & sMAPE is:4.07% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 7.46% & 1.01\n",
      "for 2019-02-26, MAE is:4.10 & sMAPE is:7.60% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 7.46% & 1.01\n",
      "for 2019-02-27, MAE is:3.34 & sMAPE is:6.40% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 7.44% & 1.00\n",
      "for 2019-02-28, MAE is:1.72 & sMAPE is:3.28% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 7.37% & 0.99\n",
      "for 2019-03-01, MAE is:2.68 & sMAPE is:5.27% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 7.34% & 0.99\n",
      "for 2019-03-02, MAE is:4.14 & sMAPE is:8.62% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 7.36% & 0.99\n",
      "for 2019-03-03, MAE is:8.15 & sMAPE is:20.30% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 7.57% & 0.99\n",
      "for 2019-03-04, MAE is:7.42 & sMAPE is:29.24% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 7.91% & 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-05, MAE is:6.30 & sMAPE is:12.94% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 7.99% & 1.00\n",
      "for 2019-03-06, MAE is:7.78 & sMAPE is:19.42% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 8.17% & 0.99\n",
      "for 2019-03-07, MAE is:10.40 & sMAPE is:23.73% & rMAE is:2.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 8.40% & 1.02\n",
      "for 2019-03-08, MAE is:1.73 & sMAPE is:3.21% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 8.33% & 1.02\n",
      "for 2019-03-09, MAE is:2.91 & sMAPE is:5.57% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 8.28% & 1.02\n",
      "for 2019-03-10, MAE is:3.99 & sMAPE is:8.40% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 8.29% & 1.01\n",
      "for 2019-03-11, MAE is:3.34 & sMAPE is:6.61% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 8.26% & 1.00\n",
      "for 2019-03-12, MAE is:5.74 & sMAPE is:10.90% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 8.30% & 1.02\n",
      "for 2019-03-13, MAE is:2.84 & sMAPE is:6.11% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 8.27% & 1.01\n",
      "for 2019-03-14, MAE is:4.10 & sMAPE is:8.53% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 8.27% & 1.01\n",
      "for 2019-03-15, MAE is:4.44 & sMAPE is:8.66% & rMAE is:4.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 8.28% & 1.05\n",
      "for 2019-03-16, MAE is:3.38 & sMAPE is:6.76% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 8.26% & 1.05\n",
      "for 2019-03-17, MAE is:10.69 & sMAPE is:32.81% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 8.58% & 1.05\n",
      "for 2019-03-18, MAE is:3.47 & sMAPE is:8.24% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 8.58% & 1.05\n",
      "for 2019-03-19, MAE is:2.40 & sMAPE is:4.81% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 8.53% & 1.04\n",
      "for 2019-03-20, MAE is:2.72 & sMAPE is:5.62% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 8.49% & 1.04\n",
      "for 2019-03-21, MAE is:4.64 & sMAPE is:9.77% & rMAE is:2.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 8.51% & 1.06\n",
      "for 2019-03-22, MAE is:3.73 & sMAPE is:7.09% & rMAE is:2.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 8.49% & 1.09\n",
      "for 2019-03-23, MAE is:2.17 & sMAPE is:4.23% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 8.44% & 1.08\n",
      "for 2019-03-24, MAE is:3.29 & sMAPE is:7.21% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 8.42% & 1.07\n",
      "for 2019-03-25, MAE is:6.22 & sMAPE is:14.13% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 8.49% & 1.07\n",
      "for 2019-03-26, MAE is:3.64 & sMAPE is:9.45% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 8.50% & 1.06\n",
      "for 2019-03-27, MAE is:4.68 & sMAPE is:10.96% & rMAE is:2.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 8.53% & 1.08\n",
      "for 2019-03-28, MAE is:3.83 & sMAPE is:8.19% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 8.53% & 1.10\n",
      "for 2019-03-29, MAE is:3.52 & sMAPE is:7.04% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 8.51% & 1.10\n",
      "for 2019-03-30, MAE is:2.66 & sMAPE is:5.38% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 8.47% & 1.11\n",
      "for 2019-03-31, MAE is:2.38 & sMAPE is:4.70% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 8.43% & 1.10\n",
      "for 2019-04-01, MAE is:4.30 & sMAPE is:7.95% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 8.43% & 1.09\n",
      "for 2019-04-02, MAE is:2.96 & sMAPE is:5.08% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 8.39% & 1.08\n",
      "for 2019-04-03, MAE is:4.58 & sMAPE is:8.93% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 8.40% & 1.08\n",
      "for 2019-04-04, MAE is:2.82 & sMAPE is:5.39% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 8.36% & 1.07\n",
      "for 2019-04-05, MAE is:2.50 & sMAPE is:5.10% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 8.33% & 1.07\n",
      "for 2019-04-06, MAE is:4.29 & sMAPE is:9.50% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 8.34% & 1.07\n",
      "for 2019-04-07, MAE is:3.03 & sMAPE is:6.58% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 8.32% & 1.06\n",
      "for 2019-04-08, MAE is:2.66 & sMAPE is:5.03% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 8.29% & 1.05\n",
      "for 2019-04-09, MAE is:2.85 & sMAPE is:5.70% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 8.26% & 1.05\n",
      "for 2019-04-10, MAE is:2.33 & sMAPE is:4.77% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 8.23% & 1.04\n",
      "for 2019-04-11, MAE is:2.44 & sMAPE is:4.51% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 8.19% & 1.05\n",
      "for 2019-04-12, MAE is:3.50 & sMAPE is:6.50% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 8.18% & 1.04\n",
      "for 2019-04-13, MAE is:4.45 & sMAPE is:8.08% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 8.18% & 1.04\n",
      "for 2019-04-14, MAE is:3.75 & sMAPE is:7.19% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 8.17% & 1.03\n",
      "for 2019-04-15, MAE is:4.74 & sMAPE is:8.89% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 8.17% & 1.03\n",
      "for 2019-04-16, MAE is:3.27 & sMAPE is:6.01% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 8.15% & 1.03\n",
      "for 2019-04-17, MAE is:5.05 & sMAPE is:10.81% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 8.18% & 1.03\n",
      "for 2019-04-18, MAE is:7.47 & sMAPE is:14.54% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 8.24% & 1.04\n",
      "for 2019-04-19, MAE is:12.15 & sMAPE is:29.09% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 8.43% & 1.04\n",
      "for 2019-04-20, MAE is:7.27 & sMAPE is:21.92% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 8.55% & 1.03\n",
      "for 2019-04-21, MAE is:3.82 & sMAPE is:9.32% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 8.56% & 1.02\n",
      "for 2019-04-22, MAE is:8.07 & sMAPE is:16.23% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 8.63% & 1.03\n",
      "for 2019-04-23, MAE is:4.27 & sMAPE is:9.17% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 8.63% & 1.03\n",
      "for 2019-04-24, MAE is:8.86 & sMAPE is:20.97% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 8.74% & 1.03\n",
      "for 2019-04-25, MAE is:12.02 & sMAPE is:42.93% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 9.04% & 1.03\n",
      "for 2019-04-26, MAE is:9.04 & sMAPE is:19.50% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 9.13% & 1.02\n",
      "for 2019-04-27, MAE is:2.39 & sMAPE is:4.25% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 9.08% & 1.01\n",
      "for 2019-04-28, MAE is:3.64 & sMAPE is:7.30% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 9.07% & 1.01\n",
      "for 2019-04-29, MAE is:2.37 & sMAPE is:4.36% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 9.03% & 1.01\n",
      "for 2019-04-30, MAE is:2.70 & sMAPE is:4.67% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 8.99% & 1.00\n",
      "for 2019-05-01, MAE is:5.62 & sMAPE is:11.48% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 9.01% & 1.00\n",
      "for 2019-05-02, MAE is:3.69 & sMAPE is:8.38% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 9.01% & 0.99\n",
      "for 2019-05-03, MAE is:5.10 & sMAPE is:10.56% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 9.02% & 0.99\n",
      "for 2019-05-04, MAE is:6.43 & sMAPE is:14.73% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 9.07% & 0.98\n",
      "for 2019-05-05, MAE is:5.63 & sMAPE is:15.87% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 9.12% & 0.98\n",
      "for 2019-05-06, MAE is:2.48 & sMAPE is:4.94% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 9.09% & 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-07, MAE is:3.63 & sMAPE is:7.02% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 9.07% & 0.97\n",
      "for 2019-05-08, MAE is:8.46 & sMAPE is:19.61% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 9.15% & 0.97\n",
      "for 2019-05-09, MAE is:6.89 & sMAPE is:16.37% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 9.21% & 0.98\n",
      "for 2019-05-10, MAE is:3.93 & sMAPE is:8.42% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.20% & 0.98\n",
      "for 2019-05-11, MAE is:3.42 & sMAPE is:7.03% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 9.19% & 0.98\n",
      "for 2019-05-12, MAE is:7.14 & sMAPE is:19.64% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 9.27% & 0.98\n",
      "for 2019-05-13, MAE is:3.67 & sMAPE is:7.65% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 9.26% & 0.98\n",
      "for 2019-05-14, MAE is:2.43 & sMAPE is:5.09% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.22% & 0.98\n",
      "for 2019-05-15, MAE is:3.15 & sMAPE is:6.28% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 9.20% & 0.97\n",
      "for 2019-05-16, MAE is:6.27 & sMAPE is:12.39% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.23% & 0.97\n",
      "for 2019-05-17, MAE is:3.62 & sMAPE is:8.22% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.22% & 0.97\n",
      "for 2019-05-18, MAE is:4.70 & sMAPE is:10.35% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.23% & 0.97\n",
      "for 2019-05-19, MAE is:4.30 & sMAPE is:9.23% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 9.23% & 0.96\n",
      "for 2019-05-20, MAE is:2.27 & sMAPE is:4.51% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 9.19% & 0.96\n",
      "for 2019-05-21, MAE is:2.74 & sMAPE is:5.07% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 9.16% & 0.96\n",
      "for 2019-05-22, MAE is:2.61 & sMAPE is:4.68% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 9.13% & 0.96\n",
      "for 2019-05-23, MAE is:2.24 & sMAPE is:3.99% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 9.10% & 0.95\n",
      "for 2019-05-24, MAE is:2.81 & sMAPE is:5.67% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 9.07% & 0.95\n",
      "for 2019-05-25, MAE is:3.48 & sMAPE is:7.95% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 9.06% & 0.95\n",
      "for 2019-05-26, MAE is:5.68 & sMAPE is:13.49% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 9.10% & 0.94\n",
      "for 2019-05-27, MAE is:4.47 & sMAPE is:9.16% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 9.10% & 0.95\n",
      "for 2019-05-28, MAE is:3.46 & sMAPE is:7.43% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 9.08% & 0.94\n",
      "for 2019-05-29, MAE is:1.73 & sMAPE is:3.67% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 9.05% & 0.94\n",
      "for 2019-05-30, MAE is:2.08 & sMAPE is:4.09% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 9.01% & 0.93\n",
      "for 2019-05-31, MAE is:2.33 & sMAPE is:4.41% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 8.98% & 0.93\n",
      "for 2019-06-01, MAE is:3.92 & sMAPE is:7.49% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 8.97% & 0.93\n",
      "for 2019-06-02, MAE is:2.48 & sMAPE is:5.17% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 8.95% & 0.92\n",
      "for 2019-06-03, MAE is:2.09 & sMAPE is:3.89% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 8.92% & 0.92\n",
      "for 2019-06-04, MAE is:5.57 & sMAPE is:10.80% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 8.93% & 0.92\n",
      "for 2019-06-05, MAE is:4.77 & sMAPE is:10.14% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 8.94% & 0.93\n",
      "for 2019-06-06, MAE is:8.63 & sMAPE is:18.77% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 9.00% & 0.92\n",
      "for 2019-06-07, MAE is:5.27 & sMAPE is:12.65% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 9.02% & 0.92\n",
      "for 2019-06-08, MAE is:1.85 & sMAPE is:3.95% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 8.99% & 0.92\n",
      "for 2019-06-09, MAE is:3.07 & sMAPE is:7.02% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 8.98% & 0.91\n",
      "for 2019-06-10, MAE is:3.85 & sMAPE is:9.63% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 8.98% & 0.91\n",
      "for 2019-06-11, MAE is:3.19 & sMAPE is:6.79% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 8.97% & 0.91\n",
      "for 2019-06-12, MAE is:2.11 & sMAPE is:4.54% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 8.94% & 0.91\n",
      "for 2019-06-13, MAE is:1.57 & sMAPE is:3.49% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 8.91% & 0.90\n",
      "for 2019-06-14, MAE is:3.27 & sMAPE is:7.25% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 8.90% & 0.90\n",
      "for 2019-06-15, MAE is:5.62 & sMAPE is:13.05% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 8.92% & 0.91\n",
      "for 2019-06-16, MAE is:1.88 & sMAPE is:4.03% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 8.89% & 0.91\n",
      "for 2019-06-17, MAE is:4.66 & sMAPE is:9.06% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 8.89% & 0.91\n",
      "for 2019-06-18, MAE is:4.36 & sMAPE is:9.41% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 8.90% & 0.91\n",
      "for 2019-06-19, MAE is:2.04 & sMAPE is:4.43% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 8.87% & 0.91\n",
      "for 2019-06-20, MAE is:2.33 & sMAPE is:4.93% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 8.85% & 0.91\n",
      "for 2019-06-21, MAE is:1.56 & sMAPE is:3.42% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 8.82% & 0.91\n",
      "for 2019-06-22, MAE is:2.61 & sMAPE is:5.79% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 8.80% & 0.91\n",
      "for 2019-06-23, MAE is:2.36 & sMAPE is:5.37% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 8.78% & 0.91\n",
      "for 2019-06-24, MAE is:1.50 & sMAPE is:3.23% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 8.75% & 0.91\n",
      "for 2019-06-25, MAE is:2.45 & sMAPE is:4.92% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 8.73% & 0.91\n",
      "for 2019-06-26, MAE is:2.88 & sMAPE is:6.03% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 8.71% & 0.91\n",
      "for 2019-06-27, MAE is:3.52 & sMAPE is:7.47% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 8.70% & 0.91\n",
      "for 2019-06-28, MAE is:2.00 & sMAPE is:4.07% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 8.68% & 0.91\n",
      "for 2019-06-29, MAE is:1.57 & sMAPE is:3.22% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 8.65% & 0.91\n",
      "for 2019-06-30, MAE is:1.60 & sMAPE is:3.46% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 8.62% & 0.90\n",
      "for 2019-07-01, MAE is:3.35 & sMAPE is:6.70% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 8.61% & 0.91\n",
      "for 2019-07-02, MAE is:1.43 & sMAPE is:2.97% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 8.58% & 0.90\n",
      "for 2019-07-03, MAE is:2.18 & sMAPE is:4.42% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 8.56% & 0.90\n",
      "for 2019-07-04, MAE is:1.48 & sMAPE is:2.93% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 8.53% & 0.90\n",
      "for 2019-07-05, MAE is:2.74 & sMAPE is:5.09% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 8.51% & 0.90\n",
      "for 2019-07-06, MAE is:3.24 & sMAPE is:6.30% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 8.49% & 0.90\n",
      "for 2019-07-07, MAE is:2.64 & sMAPE is:5.25% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 8.48% & 0.90\n",
      "for 2019-07-08, MAE is:1.87 & sMAPE is:3.81% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.45% & 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-09, MAE is:0.98 & sMAPE is:1.88% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.42% & 0.89\n",
      "for 2019-07-10, MAE is:2.13 & sMAPE is:4.24% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 8.40% & 0.90\n",
      "for 2019-07-11, MAE is:1.40 & sMAPE is:2.68% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 8.37% & 0.90\n",
      "for 2019-07-12, MAE is:4.18 & sMAPE is:7.72% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 8.36% & 0.91\n",
      "for 2019-07-13, MAE is:2.60 & sMAPE is:5.04% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 8.35% & 0.91\n",
      "for 2019-07-14, MAE is:2.24 & sMAPE is:4.62% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 8.33% & 0.91\n",
      "for 2019-07-15, MAE is:2.99 & sMAPE is:5.63% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 8.31% & 0.91\n",
      "for 2019-07-16, MAE is:1.34 & sMAPE is:2.61% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.28% & 0.91\n",
      "for 2019-07-17, MAE is:2.87 & sMAPE is:5.75% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.27% & 0.91\n",
      "for 2019-07-18, MAE is:1.60 & sMAPE is:2.93% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.24% & 0.91\n",
      "for 2019-07-19, MAE is:2.06 & sMAPE is:4.00% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.22% & 0.91\n",
      "for 2019-07-20, MAE is:3.42 & sMAPE is:6.85% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.22% & 0.92\n",
      "for 2019-07-21, MAE is:4.02 & sMAPE is:8.35% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.22% & 0.92\n",
      "for 2019-07-22, MAE is:3.17 & sMAPE is:6.02% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.21% & 0.92\n",
      "for 2019-07-23, MAE is:2.51 & sMAPE is:4.39% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 8.19% & 0.92\n",
      "for 2019-07-24, MAE is:2.43 & sMAPE is:4.27% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 8.17% & 0.92\n",
      "for 2019-07-25, MAE is:2.76 & sMAPE is:5.12% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 8.15% & 0.92\n",
      "for 2019-07-26, MAE is:1.45 & sMAPE is:2.81% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 8.13% & 0.92\n",
      "for 2019-07-27, MAE is:4.01 & sMAPE is:8.64% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 8.13% & 0.92\n",
      "for 2019-07-28, MAE is:3.40 & sMAPE is:7.57% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 8.13% & 0.92\n",
      "for 2019-07-29, MAE is:5.61 & sMAPE is:11.32% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 8.14% & 0.92\n",
      "for 2019-07-30, MAE is:3.17 & sMAPE is:6.64% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 8.14% & 0.92\n",
      "for 2019-07-31, MAE is:2.89 & sMAPE is:5.90% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 8.13% & 0.91\n",
      "for 2019-08-01, MAE is:1.84 & sMAPE is:4.03% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 8.11% & 0.91\n",
      "for 2019-08-02, MAE is:0.98 & sMAPE is:2.07% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 8.08% & 0.91\n",
      "for 2019-08-03, MAE is:2.12 & sMAPE is:4.52% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 8.06% & 0.91\n",
      "for 2019-08-04, MAE is:2.23 & sMAPE is:4.86% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 8.05% & 0.91\n",
      "for 2019-08-05, MAE is:2.52 & sMAPE is:5.25% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 8.03% & 0.91\n",
      "for 2019-08-06, MAE is:2.27 & sMAPE is:4.70% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 8.02% & 0.90\n",
      "for 2019-08-07, MAE is:1.19 & sMAPE is:2.46% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 7.99% & 0.90\n",
      "for 2019-08-08, MAE is:2.89 & sMAPE is:5.87% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 7.98% & 0.90\n",
      "for 2019-08-09, MAE is:4.04 & sMAPE is:8.88% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 7.99% & 0.90\n",
      "for 2019-08-10, MAE is:1.06 & sMAPE is:2.26% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 7.96% & 0.90\n",
      "for 2019-08-11, MAE is:2.24 & sMAPE is:5.25% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 7.95% & 0.90\n",
      "for 2019-08-12, MAE is:2.46 & sMAPE is:5.43% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 7.94% & 0.90\n",
      "for 2019-08-13, MAE is:1.80 & sMAPE is:4.21% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 7.92% & 0.89\n",
      "for 2019-08-14, MAE is:1.52 & sMAPE is:3.35% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 7.90% & 0.89\n",
      "for 2019-08-15, MAE is:3.21 & sMAPE is:7.73% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 7.90% & 0.89\n",
      "for 2019-08-16, MAE is:2.40 & sMAPE is:5.57% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 7.89% & 0.89\n",
      "for 2019-08-17, MAE is:2.65 & sMAPE is:6.36% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.74 & 7.88% & 0.89\n",
      "for 2019-08-18, MAE is:2.21 & sMAPE is:5.77% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.74 & 7.87% & 0.89\n",
      "for 2019-08-19, MAE is:1.86 & sMAPE is:4.44% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 7.86% & 0.89\n",
      "for 2019-08-20, MAE is:2.06 & sMAPE is:5.02% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 7.85% & 0.89\n",
      "for 2019-08-21, MAE is:2.19 & sMAPE is:5.37% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 7.84% & 0.88\n",
      "for 2019-08-22, MAE is:4.08 & sMAPE is:9.78% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 7.85% & 0.89\n",
      "for 2019-08-23, MAE is:1.51 & sMAPE is:3.71% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 7.83% & 0.88\n",
      "for 2019-08-24, MAE is:2.30 & sMAPE is:5.66% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 7.82% & 0.89\n",
      "for 2019-08-25, MAE is:2.87 & sMAPE is:7.35% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 7.82% & 0.89\n",
      "for 2019-08-26, MAE is:2.06 & sMAPE is:4.75% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 7.80% & 0.89\n",
      "for 2019-08-27, MAE is:3.51 & sMAPE is:7.30% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 7.80% & 0.88\n",
      "for 2019-08-28, MAE is:2.12 & sMAPE is:4.12% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 7.79% & 0.88\n",
      "for 2019-08-29, MAE is:1.41 & sMAPE is:2.88% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 7.77% & 0.88\n",
      "for 2019-08-30, MAE is:2.26 & sMAPE is:4.54% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 7.75% & 0.87\n",
      "for 2019-08-31, MAE is:3.01 & sMAPE is:6.82% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.75% & 0.88\n",
      "for 2019-09-01, MAE is:4.67 & sMAPE is:11.45% & rMAE is:3.14 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 7.76% & 0.89\n",
      "for 2019-09-02, MAE is:4.66 & sMAPE is:12.11% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 7.78% & 0.89\n",
      "for 2019-09-03, MAE is:3.38 & sMAPE is:7.91% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 7.78% & 0.88\n",
      "for 2019-09-04, MAE is:5.00 & sMAPE is:11.03% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 7.80% & 0.88\n",
      "for 2019-09-05, MAE is:4.71 & sMAPE is:11.36% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 7.81% & 0.88\n",
      "for 2019-09-06, MAE is:2.58 & sMAPE is:7.05% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 7.81% & 0.88\n",
      "for 2019-09-07, MAE is:3.07 & sMAPE is:8.90% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 7.81% & 0.88\n",
      "for 2019-09-08, MAE is:2.33 & sMAPE is:6.71% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 7.81% & 0.87\n",
      "for 2019-09-09, MAE is:4.08 & sMAPE is:9.76% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 7.81% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-10, MAE is:3.93 & sMAPE is:10.97% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 7.83% & 0.87\n",
      "for 2019-09-11, MAE is:2.06 & sMAPE is:5.86% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 7.82% & 0.87\n",
      "for 2019-09-12, MAE is:2.69 & sMAPE is:7.30% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.82% & 0.87\n",
      "for 2019-09-13, MAE is:3.98 & sMAPE is:10.24% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.83% & 0.87\n",
      "for 2019-09-14, MAE is:3.34 & sMAPE is:8.95% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.83% & 0.87\n",
      "for 2019-09-15, MAE is:2.25 & sMAPE is:5.79% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.82% & 0.87\n",
      "for 2019-09-16, MAE is:3.18 & sMAPE is:6.83% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.82% & 0.87\n",
      "for 2019-09-17, MAE is:2.58 & sMAPE is:5.34% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.81% & 0.86\n",
      "for 2019-09-18, MAE is:2.15 & sMAPE is:4.18% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 7.80% & 0.86\n",
      "for 2019-09-19, MAE is:2.76 & sMAPE is:5.65% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 7.79% & 0.86\n",
      "for 2019-09-20, MAE is:3.91 & sMAPE is:7.75% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 7.79% & 0.86\n",
      "for 2019-09-21, MAE is:4.84 & sMAPE is:11.74% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.80% & 0.86\n",
      "for 2019-09-22, MAE is:3.27 & sMAPE is:8.52% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.80% & 0.86\n",
      "for 2019-09-23, MAE is:5.55 & sMAPE is:11.29% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.82% & 0.87\n",
      "for 2019-09-24, MAE is:3.23 & sMAPE is:7.51% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.82% & 0.86\n",
      "for 2019-09-25, MAE is:1.95 & sMAPE is:4.54% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 7.80% & 0.86\n",
      "for 2019-09-26, MAE is:3.00 & sMAPE is:6.49% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 7.80% & 0.86\n",
      "for 2019-09-27, MAE is:2.12 & sMAPE is:4.48% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 7.79% & 0.87\n",
      "for 2019-09-28, MAE is:3.61 & sMAPE is:8.10% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 7.79% & 0.87\n",
      "for 2019-09-29, MAE is:2.95 & sMAPE is:6.61% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.78% & 0.87\n",
      "for 2019-09-30, MAE is:2.86 & sMAPE is:5.83% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.78% & 0.87\n",
      "for 2019-10-01, MAE is:4.54 & sMAPE is:9.89% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.78% & 0.87\n",
      "for 2019-10-02, MAE is:3.55 & sMAPE is:8.27% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.79% & 0.87\n",
      "for 2019-10-03, MAE is:4.52 & sMAPE is:9.71% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 7.79% & 0.87\n",
      "for 2019-10-04, MAE is:3.88 & sMAPE is:7.83% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 7.79% & 0.88\n",
      "for 2019-10-05, MAE is:2.82 & sMAPE is:5.84% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 7.79% & 0.87\n",
      "for 2019-10-06, MAE is:2.57 & sMAPE is:5.66% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.78% & 0.87\n",
      "for 2019-10-07, MAE is:3.91 & sMAPE is:8.18% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.78% & 0.88\n",
      "for 2019-10-08, MAE is:3.69 & sMAPE is:7.09% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.78% & 0.88\n",
      "for 2019-10-09, MAE is:3.77 & sMAPE is:7.74% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.78% & 0.88\n",
      "for 2019-10-10, MAE is:2.75 & sMAPE is:5.66% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.77% & 0.87\n",
      "for 2019-10-11, MAE is:3.60 & sMAPE is:7.34% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.77% & 0.87\n",
      "for 2019-10-12, MAE is:4.13 & sMAPE is:10.46% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.78% & 0.87\n",
      "for 2019-10-13, MAE is:3.68 & sMAPE is:8.99% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 7.78% & 0.87\n",
      "for 2019-10-14, MAE is:6.44 & sMAPE is:14.70% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 7.81% & 0.87\n",
      "for 2019-10-15, MAE is:5.34 & sMAPE is:13.72% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.83% & 0.87\n",
      "for 2019-10-16, MAE is:4.68 & sMAPE is:10.58% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.84% & 0.87\n",
      "for 2019-10-17, MAE is:3.27 & sMAPE is:7.04% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.83% & 0.87\n",
      "for 2019-10-18, MAE is:2.53 & sMAPE is:5.68% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.83% & 0.87\n",
      "for 2019-10-19, MAE is:4.68 & sMAPE is:11.21% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.84% & 0.87\n",
      "for 2019-10-20, MAE is:3.85 & sMAPE is:9.29% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.84% & 0.87\n",
      "for 2019-10-21, MAE is:4.74 & sMAPE is:9.30% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.85% & 0.87\n",
      "for 2019-10-22, MAE is:3.51 & sMAPE is:7.12% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 7.85% & 0.87\n",
      "for 2019-10-23, MAE is:4.30 & sMAPE is:9.76% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.85% & 0.87\n",
      "for 2019-10-24, MAE is:4.21 & sMAPE is:9.09% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.86% & 0.87\n",
      "for 2019-10-25, MAE is:3.44 & sMAPE is:6.98% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.85% & 0.87\n",
      "for 2019-10-26, MAE is:4.58 & sMAPE is:9.73% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.86% & 0.87\n",
      "for 2019-10-27, MAE is:2.84 & sMAPE is:6.00% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.85% & 0.87\n",
      "for 2019-10-28, MAE is:3.14 & sMAPE is:5.71% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.85% & 0.87\n",
      "for 2019-10-29, MAE is:4.03 & sMAPE is:7.16% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.84% & 0.87\n",
      "for 2019-10-30, MAE is:3.59 & sMAPE is:6.98% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.84% & 0.87\n",
      "for 2019-10-31, MAE is:3.62 & sMAPE is:7.41% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 7.84% & 0.87\n",
      "for 2019-11-01, MAE is:11.32 & sMAPE is:29.40% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 7.91% & 0.87\n",
      "for 2019-11-02, MAE is:6.05 & sMAPE is:18.14% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 7.94% & 0.87\n",
      "for 2019-11-03, MAE is:7.49 & sMAPE is:39.86% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 8.05% & 0.86\n",
      "for 2019-11-04, MAE is:12.29 & sMAPE is:47.25% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 8.17% & 0.86\n",
      "for 2019-11-05, MAE is:8.69 & sMAPE is:32.45% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 8.25% & 0.86\n",
      "for 2019-11-06, MAE is:4.09 & sMAPE is:10.56% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 8.26% & 0.86\n",
      "for 2019-11-07, MAE is:5.72 & sMAPE is:13.60% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 8.28% & 0.86\n",
      "for 2019-11-08, MAE is:3.83 & sMAPE is:9.83% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 8.28% & 0.86\n",
      "for 2019-11-09, MAE is:2.98 & sMAPE is:7.55% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 8.28% & 0.86\n",
      "for 2019-11-10, MAE is:4.68 & sMAPE is:13.29% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 8.30% & 0.85\n",
      "for 2019-11-11, MAE is:10.25 & sMAPE is:19.97% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 8.33% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-12, MAE is:3.02 & sMAPE is:6.15% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 8.33% & 0.85\n",
      "for 2019-11-13, MAE is:3.25 & sMAPE is:6.75% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 8.32% & 0.85\n",
      "for 2019-11-14, MAE is:5.30 & sMAPE is:11.25% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 8.33% & 0.85\n",
      "for 2019-11-15, MAE is:5.89 & sMAPE is:11.36% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 8.34% & 0.85\n",
      "for 2019-11-16, MAE is:8.44 & sMAPE is:17.34% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 8.37% & 0.85\n",
      "for 2019-11-17, MAE is:3.32 & sMAPE is:7.47% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 8.37% & 0.85\n",
      "for 2019-11-18, MAE is:4.23 & sMAPE is:8.43% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 8.37% & 0.85\n",
      "for 2019-11-19, MAE is:3.65 & sMAPE is:6.47% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 8.36% & 0.85\n",
      "for 2019-11-20, MAE is:2.82 & sMAPE is:5.11% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 8.35% & 0.85\n",
      "for 2019-11-21, MAE is:3.97 & sMAPE is:7.47% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 8.35% & 0.85\n",
      "for 2019-11-22, MAE is:6.32 & sMAPE is:13.10% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 8.36% & 0.85\n",
      "for 2019-11-23, MAE is:5.69 & sMAPE is:14.96% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 8.38% & 0.85\n",
      "for 2019-11-24, MAE is:4.37 & sMAPE is:10.47% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 8.39% & 0.85\n",
      "for 2019-11-25, MAE is:3.52 & sMAPE is:7.82% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 8.39% & 0.85\n",
      "for 2019-11-26, MAE is:5.73 & sMAPE is:12.42% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 8.40% & 0.85\n",
      "for 2019-11-27, MAE is:4.00 & sMAPE is:9.45% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 8.40% & 0.85\n",
      "for 2019-11-28, MAE is:7.45 & sMAPE is:20.92% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 8.44% & 0.85\n",
      "for 2019-11-29, MAE is:4.41 & sMAPE is:9.58% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 8.44% & 0.85\n",
      "for 2019-11-30, MAE is:5.90 & sMAPE is:13.48% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 8.46% & 0.85\n",
      "for 2019-12-01, MAE is:4.24 & sMAPE is:10.07% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 8.46% & 0.85\n",
      "for 2019-12-02, MAE is:3.58 & sMAPE is:7.67% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 8.46% & 0.85\n",
      "for 2019-12-03, MAE is:4.99 & sMAPE is:9.99% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 8.47% & 0.85\n",
      "for 2019-12-04, MAE is:3.23 & sMAPE is:5.97% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 8.46% & 0.85\n",
      "for 2019-12-05, MAE is:4.17 & sMAPE is:8.36% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 8.46% & 0.85\n",
      "for 2019-12-06, MAE is:2.84 & sMAPE is:5.98% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 8.45% & 0.85\n",
      "for 2019-12-07, MAE is:2.75 & sMAPE is:5.66% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 8.44% & 0.85\n",
      "for 2019-12-08, MAE is:3.40 & sMAPE is:8.12% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 8.44% & 0.85\n",
      "for 2019-12-09, MAE is:2.52 & sMAPE is:6.25% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 8.44% & 0.84\n",
      "for 2019-12-10, MAE is:2.86 & sMAPE is:6.11% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 8.43% & 0.84\n",
      "for 2019-12-11, MAE is:4.82 & sMAPE is:10.76% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 8.44% & 0.84\n",
      "for 2019-12-12, MAE is:3.88 & sMAPE is:9.63% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 8.44% & 0.84\n",
      "for 2019-12-13, MAE is:14.68 & sMAPE is:49.21% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 8.56% & 0.84\n",
      "for 2019-12-14, MAE is:5.97 & sMAPE is:17.95% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 8.58% & 0.84\n",
      "for 2019-12-15, MAE is:10.20 & sMAPE is:44.74% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 8.69% & 0.84\n",
      "for 2019-12-16, MAE is:6.38 & sMAPE is:14.48% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 8.70% & 0.84\n",
      "for 2019-12-17, MAE is:4.35 & sMAPE is:10.24% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 8.71% & 0.84\n",
      "for 2019-12-18, MAE is:5.52 & sMAPE is:14.02% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.89 & 8.72% & 0.84\n",
      "for 2019-12-19, MAE is:18.05 & sMAPE is:69.37% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.89% & 0.84\n",
      "for 2019-12-20, MAE is:9.31 & sMAPE is:61.98% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 9.04% & 0.84\n",
      "for 2019-12-21, MAE is:14.94 & sMAPE is:147.36% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 9.43% & 0.84\n",
      "for 2019-12-22, MAE is:9.87 & sMAPE is:153.16% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 9.84% & 0.84\n",
      "for 2019-12-23, MAE is:6.46 & sMAPE is:48.95% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 9.95% & 0.84\n",
      "for 2019-12-24, MAE is:8.64 & sMAPE is:56.27% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 10.08% & 0.84\n",
      "for 2019-12-25, MAE is:7.53 & sMAPE is:52.84% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 10.20% & 0.84\n",
      "for 2019-12-26, MAE is:10.78 & sMAPE is:45.88% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 10.29% & 0.84\n",
      "for 2019-12-27, MAE is:3.12 & sMAPE is:10.23% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 10.29% & 0.84\n",
      "for 2019-12-28, MAE is:6.13 & sMAPE is:20.25% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 10.32% & 0.84\n",
      "for 2019-12-29, MAE is:5.67 & sMAPE is:17.86% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 10.34% & 0.84\n",
      "for 2019-12-30, MAE is:5.46 & sMAPE is:15.77% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 10.36% & 0.84\n",
      "for 2019-12-31, MAE is:3.65 & sMAPE is:9.52% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 10.36% & 0.84\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:49:13,195]\u001b[0m A new study created in RDB with name: ES_2020\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:49:32,053]\u001b[0m Trial 0 finished with value: 5.874648338705025 and parameters: {'n_hidden': 4, 'learning_rate': 0.027825839270245133, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06495969637577624, 'dropout_rate_Layer_2': 0.32304274607379246, 'dropout_rate_Layer_3': 0.0893592388052889, 'dropout_rate_Layer_4': 0.2528336419225869, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0018363062355142587, 'l1_Layer_2': 1.5038481309824962e-05, 'l1_Layer_3': 0.018801243971323937, 'l1_Layer_4': 0.003449378991815022, 'n_units_Layer_1': 290, 'n_units_Layer_2': 290, 'n_units_Layer_3': 210, 'n_units_Layer_4': 160}. Best is trial 0 with value: 5.874648338705025.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 14.26% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 12.40 | sMAPE for Test Set is: 35.98% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:49:35,485]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:49:44,419]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:49:49,110]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:02,048]\u001b[0m Trial 3 finished with value: 4.360962784241475 and parameters: {'n_hidden': 4, 'learning_rate': 0.006432805727589748, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27716792909159693, 'dropout_rate_Layer_2': 0.2930162632575307, 'dropout_rate_Layer_3': 0.2844259910941411, 'dropout_rate_Layer_4': 0.04238551594724314, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.8578253714372757e-05, 'l1_Layer_2': 0.005332676346567337, 'l1_Layer_3': 0.003089086689260377, 'l1_Layer_4': 0.00012419905371348344, 'n_units_Layer_1': 200, 'n_units_Layer_2': 70, 'n_units_Layer_3': 145, 'n_units_Layer_4': 165}. Best is trial 3 with value: 4.360962784241475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 11.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.10 | sMAPE for Test Set is: 25.48% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:50:06,433]\u001b[0m Trial 1 finished with value: 3.839741691879277 and parameters: {'n_hidden': 3, 'learning_rate': 0.0045543684654952244, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34040427140568225, 'dropout_rate_Layer_2': 0.15069632109430475, 'dropout_rate_Layer_3': 0.07984938029491812, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01201501060296636, 'l1_Layer_2': 1.7044692166085808e-05, 'l1_Layer_3': 5.385445505724712e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 250}. Best is trial 1 with value: 3.839741691879277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 10.01% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 18.00% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:50:09,451]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:14,159]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:19,130]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:22,274]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:26,154]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:26,526]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:35,038]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:39,146]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:40,152]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:48,006]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:53,762]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:50:58,828]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:51:09,516]\u001b[0m Trial 7 finished with value: 4.8470641581217455 and parameters: {'n_hidden': 4, 'learning_rate': 0.001130608569717018, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011750238703217654, 'dropout_rate_Layer_2': 0.24595329244712924, 'dropout_rate_Layer_3': 0.07928634720516672, 'dropout_rate_Layer_4': 0.26553919691406985, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.028985250490986634, 'l1_Layer_2': 0.0006622419352526349, 'l1_Layer_3': 0.025467806438188263, 'l1_Layer_4': 0.00495822278209918, 'n_units_Layer_1': 85, 'n_units_Layer_2': 220, 'n_units_Layer_3': 205, 'n_units_Layer_4': 90}. Best is trial 1 with value: 3.839741691879277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 12.19% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.16 | sMAPE for Test Set is: 31.23% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:51:12,106]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:51:18,173]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:51:27,359]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:51:33,500]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:51:35,179]\u001b[0m Trial 4 finished with value: 3.8804355204971146 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006954203554559068, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2589381480055936, 'dropout_rate_Layer_2': 0.25600483470379337, 'dropout_rate_Layer_3': 0.08574256748632028, 'dropout_rate_Layer_4': 0.3733516646211214, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0013969001597851972, 'l1_Layer_2': 0.0006761880479753895, 'l1_Layer_3': 8.591337645528315e-05, 'l1_Layer_4': 1.5113820711650823e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 120, 'n_units_Layer_3': 115, 'n_units_Layer_4': 225}. Best is trial 1 with value: 3.839741691879277.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 10.12% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 22.70% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:51:40,167]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:51:43,740]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:51:46,016]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:51:53,154]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:51:54,982]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:00,944]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:01,239]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:03,641]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 9.62% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 19.39% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:52:06,673]\u001b[0m Trial 21 finished with value: 3.693024479703531 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007054296173680221, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04912998594404958, 'dropout_rate_Layer_2': 0.14695719448785788, 'dropout_rate_Layer_3': 0.257377263530895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012652481866146658, 'l1_Layer_2': 0.00470948782121468, 'l1_Layer_3': 1.4078616602211025e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 160, 'n_units_Layer_3': 225}. Best is trial 21 with value: 3.693024479703531.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:08,971]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:12,151]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:15,374]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:18,754]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:19,010]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:20,003]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:22,100]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:27,527]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:29,665]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:32,948]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:33,576]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:38,334]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:44,287]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:48,689]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:50,487]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:53,593]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:55,942]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:52:59,833]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:01,699]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:04,938]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:06,521]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:22,926]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:25,058]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:30,579]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:35,170]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:36,983]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:41,393]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:44,283]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:51,808]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:53:54,153]\u001b[0m Trial 57 finished with value: 3.5622416434563298 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028666795519505526, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0067463792053484295, 'dropout_rate_Layer_2': 0.16221331900726416, 'dropout_rate_Layer_3': 0.29343914112408814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046603300950449173, 'l1_Layer_2': 0.003765776348297392, 'l1_Layer_3': 0.00026145363978260524, 'n_units_Layer_1': 240, 'n_units_Layer_2': 120, 'n_units_Layer_3': 240}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 9.38% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 14.64% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:53:57,687]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:00,640]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:08,369]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:12,556]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:13,425]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:14,854]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:18,160]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:20,185]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:21,016]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:23,053]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:30,165]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:34,774]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:40,852]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:41,077]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:46,509]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:51,806]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:51,911]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:57,643]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:54:57,778]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:05,896]\u001b[0m Trial 74 finished with value: 3.8661844216689496 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020326591487846804, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3983635600756877, 'dropout_rate_Layer_2': 0.03620676907906428, 'dropout_rate_Layer_3': 0.09941309389910848, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026760977762479553, 'l1_Layer_2': 6.500785343313481e-05, 'l1_Layer_3': 0.0014321239639013806, 'n_units_Layer_1': 135, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 10.11% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 22.86% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:55:08,521]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:10,549]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:13,872]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:15,545]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:19,932]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:19,999]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 10.20% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 22.52% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:55:24,438]\u001b[0m Trial 81 finished with value: 3.908607074508454 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019331266759890224, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3686671056081593, 'dropout_rate_Layer_2': 0.03695638825336609, 'dropout_rate_Layer_3': 0.07455920430996446, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00033488137295988973, 'l1_Layer_2': 7.218405082437413e-05, 'l1_Layer_3': 0.00017394820603687633, 'n_units_Layer_1': 140, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:26,812]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:29,536]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:30,059]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:32,057]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:36,233]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:37,498]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:42,086]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:42,543]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:47,702]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:49,986]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:52,729]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:54,431]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:55,329]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:55:58,903]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:03,964]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:04,524]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:07,470]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:11,162]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:17,430]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:21,245]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:21,747]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:29,026]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:29,257]\u001b[0m Trial 98 finished with value: 3.827497170211217 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028939478974493132, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3356066710923162, 'dropout_rate_Layer_2': 0.026884085726440125, 'dropout_rate_Layer_3': 0.04109733942869433, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009818532691808104, 'l1_Layer_2': 5.482852553833062e-05, 'l1_Layer_3': 3.719149355805957e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 240, 'n_units_Layer_3': 265}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 10.05% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 22.86% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:56:37,061]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:43,536]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:46,523]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:52,264]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:52,398]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:59,625]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:56:59,890]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:17,729]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:18,497]\u001b[0m Trial 123 finished with value: 3.774800883598168 and parameters: {'n_hidden': 3, 'learning_rate': 0.004205515608434122, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21123959152237565, 'dropout_rate_Layer_2': 0.2869511035322949, 'dropout_rate_Layer_3': 0.027557830689677015, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008762220813417643, 'l1_Layer_2': 4.416145998226687e-05, 'l1_Layer_3': 1.50933076301434e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 165}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 9.91% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 21.89% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 01:57:25,337]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:28,527]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:32,598]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:35,665]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:37,792]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:37,899]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:42,561]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:50,179]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:50,803]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:53,409]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:57,487]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:57,699]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:57:58,565]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:58:05,724]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:58:08,824]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:58:11,343]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:58:16,014]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:58:20,151]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:58:24,920]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:58:29,761]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:58:50,339]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:58:54,109]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:06,749]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:10,800]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:10,945]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:14,901]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:19,301]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:21,064]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:22,106]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:27,148]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:33,681]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:37,001]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:42,829]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:43,405]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:46,802]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:47,858]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:50,650]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:53,182]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:55,417]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 01:59:57,819]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:00,065]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:05,007]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:06,835]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:11,880]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:13,848]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:18,628]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:20,144]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:26,593]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:33,920]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:35,970]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:40,391]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:40,700]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:47,560]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:53,408]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:00:57,163]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:00,306]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:03,961]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:13,372]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:18,555]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:24,053]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:24,314]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:30,734]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:31,488]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:36,522]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:36,721]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:37,169]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:43,589]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:43,848]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:48,911]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:50,908]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:54,184]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:01:54,916]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:01,992]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:02,155]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:02,575]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:02,835]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:16,031]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:21,045]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:22,508]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:26,695]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:32,609]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:35,228]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:38,464]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:41,605]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:42,819]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:46,588]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:51,079]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:51,238]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:52,233]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:02:58,343]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:00,049]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:02,345]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:07,848]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:03:10,695]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:12,955]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:16,154]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:17,129]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:24,822]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:28,735]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:31,532]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:35,507]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:37,876]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:41,004]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:42,880]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:47,343]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:54,958]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:03:56,543]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:04:12,343]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:04:30,635]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:04:35,713]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:04:41,351]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:04:46,983]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:04:58,211]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:04:58,914]\u001b[0m Trial 233 finished with value: 3.742289660701067 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006251690073688694, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12348803460784483, 'dropout_rate_Layer_2': 0.3485978329261332, 'dropout_rate_Layer_3': 0.2738906835696827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002258544117706862, 'l1_Layer_2': 3.982084291824164e-05, 'l1_Layer_3': 0.0003581991655639113, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 230}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 9.77% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 17.45% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:05:04,007]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:05:09,412]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:05:26,423]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:05:29,734]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:05:34,171]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:05:46,274]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:05:50,399]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:05:54,997]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:06:00,263]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:06:05,270]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:06:05,692]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:06:05,883]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:06:12,903]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:06:13,831]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:06:23,015]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:06:32,345]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:07:07,718]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:07:26,475]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:07:30,131]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:07:47,833]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:07:52,661]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:07:55,413]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:08:05,156]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:08:05,469]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:08:05,565]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:08:14,876]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:08:17,816]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:08:21,868]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:08:23,966]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:08:30,982]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:08:35,983]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:09:06,425]\u001b[0m Trial 270 finished with value: 3.815009334065173 and parameters: {'n_hidden': 3, 'learning_rate': 0.001952954034572293, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07980259553680853, 'dropout_rate_Layer_2': 0.2689719930618555, 'dropout_rate_Layer_3': 0.26624155685779066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6017452480442395e-05, 'l1_Layer_2': 0.008109845870973995, 'l1_Layer_3': 0.00065441866440457, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 9.95% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 17.51% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:09:14,083]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:09:24,781]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:09:45,666]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:10:06,773]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:10:11,275]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:10:17,880]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:10:22,235]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:10:32,230]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:10:37,659]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:10:42,445]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:10:52,900]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:10:57,129]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:11:09,341]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:11:12,178]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:11:15,550]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:11:19,116]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:11:23,260]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:11:30,020]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:11:35,877]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:12:07,620]\u001b[0m Trial 250 finished with value: 4.3165783580943415 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005086413426100726, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21143638847014518, 'dropout_rate_Layer_2': 0.33367235124295086, 'dropout_rate_Layer_3': 0.20127197506899902, 'dropout_rate_Layer_4': 0.25356422979634413, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012123821562608653, 'l1_Layer_2': 3.3111058230538604e-05, 'l1_Layer_3': 4.2058400968030754e-05, 'l1_Layer_4': 0.004065669911416384, 'n_units_Layer_1': 270, 'n_units_Layer_2': 95, 'n_units_Layer_3': 120, 'n_units_Layer_4': 295}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 11.09% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.17 | sMAPE for Test Set is: 23.89% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:12:16,417]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:12:33,463]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:12:36,491]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:12:40,513]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:12:46,800]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:12:51,767]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:12:59,163]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:13:04,456]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:13:09,391]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:13:26,559]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:13:34,729]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:13:38,967]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:13:39,385]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:13:46,066]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:13:50,136]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:13:50,659]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:13:51,082]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:13:59,004]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:00,810]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:03,926]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:09,235]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:10,647]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:11,385]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:18,903]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:19,210]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:23,248]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:31,391]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:33,165]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:36,230]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:40,037]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:43,811]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:48,402]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:52,853]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:54,316]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:58,326]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:14:58,531]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:15:04,079]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:15:07,100]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:15:14,265]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:15:19,634]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:15:23,449]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:15:32,253]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:15:36,242]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:15:48,229]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:15:51,941]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:15:55,433]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:16:00,416]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:16:03,229]\u001b[0m Trial 312 finished with value: 4.269688837661423 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007275570694078894, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25250157269102963, 'dropout_rate_Layer_2': 0.27928068521420896, 'dropout_rate_Layer_3': 0.2579484366071343, 'dropout_rate_Layer_4': 0.2550638803036701, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006522062980473905, 'l1_Layer_2': 8.750232960937276e-05, 'l1_Layer_3': 6.123407558996985e-05, 'l1_Layer_4': 0.0027880091413245347, 'n_units_Layer_1': 300, 'n_units_Layer_2': 100, 'n_units_Layer_3': 105, 'n_units_Layer_4': 70}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 10.97% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 20.22% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:16:06,909]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:16:34,695]\u001b[0m Trial 340 finished with value: 4.005935170139903 and parameters: {'n_hidden': 3, 'learning_rate': 0.002685646197416088, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3695518956081333, 'dropout_rate_Layer_2': 0.3319186362302733, 'dropout_rate_Layer_3': 0.06535335243074725, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001925157933034754, 'l1_Layer_2': 5.3556820971477005e-05, 'l1_Layer_3': 9.114718295970114e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 265, 'n_units_Layer_3': 180}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 10.41% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 22.10% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:16:42,214]\u001b[0m Trial 334 finished with value: 3.6212882404154243 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007819106447305632, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08892397400115624, 'dropout_rate_Layer_2': 0.2518807762460381, 'dropout_rate_Layer_3': 0.24861716791698008, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019134712735362338, 'l1_Layer_2': 0.00031670429191609444, 'l1_Layer_3': 5.1508279380043557e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 125, 'n_units_Layer_3': 240}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 9.48% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 7.62 | sMAPE for Test Set is: 24.84% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:16:43,947]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:16:48,261]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:16:54,770]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:16:54,869]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:16:55,790]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:01,901]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:02,016]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:03,029]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:11,051]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:13,876]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:15,597]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:18,906]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:23,979]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:24,574]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:28,972]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:34,608]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:34,895]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:41,816]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:46,719]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:51,858]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:55,127]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:17:55,660]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:18:01,050]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:18:05,898]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:18:11,330]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:18:11,538]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:18:19,030]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:18:22,780]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:18:32,291]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:18:40,365]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:01,267]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:01,970]\u001b[0m Trial 364 finished with value: 3.616681545991694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007496612295327216, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08333441432643157, 'dropout_rate_Layer_2': 0.24996467378542941, 'dropout_rate_Layer_3': 0.2953060344869594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013138408166927763, 'l1_Layer_2': 0.0003401489925733035, 'l1_Layer_3': 0.0001054621692036093, 'n_units_Layer_1': 150, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 9.50% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 18.83% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:19:08,680]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:09,262]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:14,374]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:17,809]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:20,624]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:26,889]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:32,360]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:33,800]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:43,200]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:53,113]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:19:56,362]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:20:01,191]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:20:06,820]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:20:21,438]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:20:25,231]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:20:29,673]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:20:29,695]\u001b[0m Trial 381 finished with value: 3.648174848384198 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006861441240036993, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10474437631071257, 'dropout_rate_Layer_2': 0.30393079532995443, 'dropout_rate_Layer_3': 0.2552140319166976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005729816565642221, 'l1_Layer_2': 0.0003572944482875265, 'l1_Layer_3': 0.00019572949993517408, 'n_units_Layer_1': 300, 'n_units_Layer_2': 115, 'n_units_Layer_3': 290}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 9.46% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 6.37 | sMAPE for Test Set is: 20.84% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:20:38,519]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:20:41,250]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:20:46,253]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:20:53,098]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:21:02,021]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:21:19,396]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:21:20,116]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:21:21,685]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:21:27,714]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:21:30,770]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:21:35,453]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:21:40,574]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:21:48,421]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:21:52,615]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:21:57,628]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:22:01,704]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:22:11,036]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:22:21,933]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:22:22,541]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:22:28,180]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:22:32,327]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:22:38,793]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:22:49,531]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:22:53,737]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:22:59,255]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:09,327]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:13,511]\u001b[0m Trial 412 finished with value: 3.61752041152486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005379595861574025, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09218365981071373, 'dropout_rate_Layer_2': 0.2504407332262629, 'dropout_rate_Layer_3': 0.25937840158121805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00047052376832311746, 'l1_Layer_2': 0.0003497121668891585, 'l1_Layer_3': 0.00012762776647037312, 'n_units_Layer_1': 285, 'n_units_Layer_2': 85, 'n_units_Layer_3': 290}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 9.47% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:23:19,483]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:19,589]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:26,852]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:33,194]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:36,423]\u001b[0m Trial 413 finished with value: 3.806211653665347 and parameters: {'n_hidden': 3, 'learning_rate': 0.0051233817223500094, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31993154959062087, 'dropout_rate_Layer_2': 0.309260079567715, 'dropout_rate_Layer_3': 0.027354924628019514, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.552525845550588e-05, 'l1_Layer_2': 1.0494676461820187e-05, 'l1_Layer_3': 9.631175701764442e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 250}. Best is trial 57 with value: 3.5622416434563298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 9.79% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 18.27% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:23:41,044]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:41,076]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:42,548]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:48,241]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:51,478]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:52,230]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:53,766]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:23:59,807]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:02,606]\u001b[0m Trial 420 finished with value: 3.4434131312638776 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005793163655998326, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11178018817833851, 'dropout_rate_Layer_2': 0.14339622313829584, 'dropout_rate_Layer_3': 0.22747932056489267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021434615111602057, 'l1_Layer_2': 8.169775789648803e-05, 'l1_Layer_3': 0.00012954526805621395, 'n_units_Layer_1': 280, 'n_units_Layer_2': 90, 'n_units_Layer_3': 260}. Best is trial 420 with value: 3.4434131312638776.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:02,610]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 9.07% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 4.82 | sMAPE for Test Set is: 16.34% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:24:03,984]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:10,430]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:13,577]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:19,773]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:23,261]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:26,041]\u001b[0m Trial 429 finished with value: 3.4975828032808125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005950784619359714, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11486964628514314, 'dropout_rate_Layer_2': 0.14346143958548918, 'dropout_rate_Layer_3': 0.22306805347341038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021305784605129353, 'l1_Layer_2': 0.00010737217154572444, 'l1_Layer_3': 0.00012236572721355642, 'n_units_Layer_1': 280, 'n_units_Layer_2': 120, 'n_units_Layer_3': 255}. Best is trial 420 with value: 3.4434131312638776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 9.23% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 17.84% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:24:29,196]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:32,165]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:35,589]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:46,090]\u001b[0m Trial 434 finished with value: 3.49923133734357 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006704766236093276, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1139890747794179, 'dropout_rate_Layer_2': 0.1469635549059948, 'dropout_rate_Layer_3': 0.22496071781969662, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021489622687633807, 'l1_Layer_2': 3.466320330123912e-05, 'l1_Layer_3': 0.00014078126702123892, 'n_units_Layer_1': 280, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 420 with value: 3.4434131312638776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 9.15% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:24:48,827]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:52,099]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:52,559]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:24:57,604]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.46 | sMAPE for Validation Set is: 9.10% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 17.89% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:24:59,671]\u001b[0m Trial 439 finished with value: 3.461980914059937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005795308016066974, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11591017685122867, 'dropout_rate_Layer_2': 0.1474061142958644, 'dropout_rate_Layer_3': 0.22275598306951958, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020718691261896027, 'l1_Layer_2': 0.00010397928291880382, 'l1_Layer_3': 0.00012921347195068124, 'n_units_Layer_1': 280, 'n_units_Layer_2': 90, 'n_units_Layer_3': 280}. Best is trial 420 with value: 3.4434131312638776.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:25:03,361]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:25:20,180]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:25:25,805]\u001b[0m Trial 448 finished with value: 3.489596646454956 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005688138622653151, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10504151068148447, 'dropout_rate_Layer_2': 0.1453176074036474, 'dropout_rate_Layer_3': 0.2197371979035002, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00032211502035496195, 'l1_Layer_2': 7.762426879141161e-05, 'l1_Layer_3': 0.00013122742649052414, 'n_units_Layer_1': 280, 'n_units_Layer_2': 90, 'n_units_Layer_3': 275}. Best is trial 420 with value: 3.4434131312638776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 9.18% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:25:30,015]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:25:35,432]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:25:38,908]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:25:41,941]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:25:47,445]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:25:48,086]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:25:50,681]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:25:56,613]\u001b[0m Trial 450 finished with value: 3.4417069400207345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005860875010027591, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10906604818148431, 'dropout_rate_Layer_2': 0.14750660227092152, 'dropout_rate_Layer_3': 0.18493022438898765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013964256390893947, 'l1_Layer_2': 7.838718727925511e-05, 'l1_Layer_3': 0.00013561241932396933, 'n_units_Layer_1': 280, 'n_units_Layer_2': 95, 'n_units_Layer_3': 275}. Best is trial 450 with value: 3.4417069400207345.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 9.02% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:25:59,460]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:26:04,920]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:26:07,061]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:26:10,125]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:26:12,881]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:26:18,235]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:26:25,626]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:26:35,464]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:26:37,802]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:26:44,172]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:26:48,137]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:26:52,418]\u001b[0m Trial 463 finished with value: 3.437013760528751 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005474966190445523, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13704510046235843, 'dropout_rate_Layer_2': 0.14595468614412263, 'dropout_rate_Layer_3': 0.1813670360970213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013677911561946313, 'l1_Layer_2': 8.82256916134941e-05, 'l1_Layer_3': 0.00013025182953976054, 'n_units_Layer_1': 255, 'n_units_Layer_2': 85, 'n_units_Layer_3': 275}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 8.99% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 18.13% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:27:11,621]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:27:17,509]\u001b[0m Trial 471 finished with value: 3.5800779879083464 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005012144098115513, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14156154373691246, 'dropout_rate_Layer_2': 0.1296180479220163, 'dropout_rate_Layer_3': 0.17848228074514175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013423985816645, 'l1_Layer_2': 7.468547920527291e-05, 'l1_Layer_3': 9.411592669105816e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 255}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 9.38% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:27:25,597]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:27:26,189]\u001b[0m Trial 470 finished with value: 3.480600572286704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005674409134899424, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15013691555553044, 'dropout_rate_Layer_2': 0.12877788002734655, 'dropout_rate_Layer_3': 0.18021213929450708, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001275803641358428, 'l1_Layer_2': 7.628539662376944e-05, 'l1_Layer_3': 0.00013005346483411107, 'n_units_Layer_1': 255, 'n_units_Layer_2': 85, 'n_units_Layer_3': 275}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 9.10% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 16.70% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:27:33,112]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:27:36,861]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:27:39,472]\u001b[0m Trial 472 finished with value: 3.525061746216839 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005680021557027371, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13704378476203605, 'dropout_rate_Layer_2': 0.14585106679693832, 'dropout_rate_Layer_3': 0.17959128790389375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013829430987877662, 'l1_Layer_2': 8.926369493353184e-05, 'l1_Layer_3': 9.189339768613284e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 275}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.53 | sMAPE for Validation Set is: 9.28% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 17.50% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:27:47,870]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:27:51,902]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:27:53,564]\u001b[0m Trial 473 finished with value: 3.4865230901374225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005027976980844306, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1462913815367724, 'dropout_rate_Layer_2': 0.12961397345183762, 'dropout_rate_Layer_3': 0.1864572993593974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013396153312470507, 'l1_Layer_2': 6.468291401725556e-05, 'l1_Layer_3': 6.419822209932118e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 255}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 9.09% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 4.00 | sMAPE for Test Set is: 13.91% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:27:59,981]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:04,373]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:07,676]\u001b[0m Trial 476 finished with value: 3.529001985220186 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005955560266556106, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15707355856132096, 'dropout_rate_Layer_2': 0.14595049523522433, 'dropout_rate_Layer_3': 0.16664621800701504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010373252766370483, 'l1_Layer_2': 2.138435117248676e-05, 'l1_Layer_3': 6.384518228291486e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 95, 'n_units_Layer_3': 275}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.53 | sMAPE for Validation Set is: 9.23% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 3.69 | sMAPE for Test Set is: 12.90% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:28:11,648]\u001b[0m Trial 477 finished with value: 3.476412628587592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005720424635797428, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1582284623749054, 'dropout_rate_Layer_2': 0.14965608643528058, 'dropout_rate_Layer_3': 0.16113968618143276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010091285658497653, 'l1_Layer_2': 2.1486824693979912e-05, 'l1_Layer_3': 6.483690803002671e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 95, 'n_units_Layer_3': 275}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:11,667]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 9.08% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.83 | sMAPE for Test Set is: 13.24% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:28:13,868]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:19,536]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:19,574]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:24,252]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:26,977]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:31,053]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:31,094]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:37,166]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:37,676]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:42,482]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:46,437]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:50,553]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:53,513]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:54,158]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:28:55,489]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:02,147]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:02,930]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:05,261]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:09,868]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:10,325]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:16,195]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:18,362]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:18,840]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:23,504]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:26,028]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:30,214]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:37,895]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:41,886]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:44,577]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:49,471]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:50,318]\u001b[0m Trial 507 finished with value: 3.509143650406829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005508466963122813, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11698383846382097, 'dropout_rate_Layer_2': 0.1724528360153277, 'dropout_rate_Layer_3': 0.1445069775795924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00031002712993521546, 'l1_Layer_2': 3.627799047285383e-05, 'l1_Layer_3': 0.0001913633726830308, 'n_units_Layer_1': 245, 'n_units_Layer_2': 95, 'n_units_Layer_3': 255}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.51 | sMAPE for Validation Set is: 9.22% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 4.05 | sMAPE for Test Set is: 14.16% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:29:52,378]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:54,961]\u001b[0m Trial 508 finished with value: 3.5339186430667677 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005818670053050222, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12149604467498458, 'dropout_rate_Layer_2': 0.1303571927995383, 'dropout_rate_Layer_3': 0.1885525996106855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00030854353799210994, 'l1_Layer_2': 4.057889436873343e-05, 'l1_Layer_3': 0.00019230191923120683, 'n_units_Layer_1': 245, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.53 | sMAPE for Validation Set is: 9.28% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 14.49% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:29:58,908]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:29:59,757]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:04,137]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:06,026]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:06,248]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:10,825]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:13,181]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:16,753]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:16,949]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:24,113]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:28,100]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:28,313]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:34,254]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:37,951]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:38,186]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:45,171]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:46,232]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:49,122]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:30:50,042]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:01,912]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:02,303]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:09,705]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:12,712]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:20,729]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:24,484]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:28,324]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:28,807]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:30,017]\u001b[0m Trial 536 finished with value: 3.8173315669102266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032383827366844636, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13469012024088542, 'dropout_rate_Layer_2': 0.016852961281143303, 'dropout_rate_Layer_3': 0.04304019722058569, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.066352283123463e-05, 'l1_Layer_2': 0.0004205154040587757, 'l1_Layer_3': 0.0006412156219466375, 'n_units_Layer_1': 260, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 9.97% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 24.09% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:31:40,463]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:44,943]\u001b[0m Trial 540 finished with value: 3.767171003117298 and parameters: {'n_hidden': 3, 'learning_rate': 0.002815891838419866, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12128168453293366, 'dropout_rate_Layer_2': 0.01388457252353378, 'dropout_rate_Layer_3': 0.06964633166757758, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010647433292653145, 'l1_Layer_2': 4.821340264309385e-05, 'l1_Layer_3': 0.0006387781099194698, 'n_units_Layer_1': 190, 'n_units_Layer_2': 295, 'n_units_Layer_3': 200}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 9.78% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 23.04% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:31:49,575]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:49,680]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:31:57,619]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:02,134]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:03,756]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:04,493]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:06,608]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:09,856]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:10,976]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:17,312]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:20,317]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:24,350]\u001b[0m Trial 550 finished with value: 3.7964992901133434 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034493393239651677, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09524391183562203, 'dropout_rate_Layer_2': 0.03187230650401669, 'dropout_rate_Layer_3': 0.0690561081328724, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012620448810102687, 'l1_Layer_2': 0.0007435251843110548, 'l1_Layer_3': 0.0007609790464838633, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 195}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 9.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.44 | sMAPE for Test Set is: 24.38% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:32:27,533]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:33,073]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:35,097]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:36,875]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:41,050]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:44,916]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:49,626]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:50,988]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:32:56,744]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:01,543]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:06,139]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:06,473]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:10,539]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:14,457]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:14,813]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:16,966]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:26,408]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:27,041]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:27,530]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:30,030]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:36,833]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:37,520]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:39,470]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:46,392]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:48,050]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:55,456]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:33:56,326]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:02,351]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:05,381]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:05,663]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:12,248]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:13,901]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:14,854]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:22,217]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:22,468]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:22,689]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:31,146]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:31,565]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:37,958]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:41,300]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:41,436]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:47,346]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:49,740]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:50,106]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:50,179]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:52,901]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:59,022]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:34:59,781]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:02,235]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:04,390]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:06,571]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:11,886]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:12,424]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:15,798]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:20,087]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:20,593]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:21,604]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:24,896]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:29,863]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:33,622]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:36,243]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:39,823]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:42,628]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:47,251]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:49,028]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:56,670]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:35:56,735]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:01,165]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:02,406]\u001b[0m Trial 621 finished with value: 3.5242874364041534 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007090994692363323, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17840239733221944, 'dropout_rate_Layer_2': 0.18178543182383716, 'dropout_rate_Layer_3': 0.19164080658456936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.616454867911474e-05, 'l1_Layer_2': 0.00015085042278425214, 'l1_Layer_3': 0.00010383493229979725, 'n_units_Layer_1': 295, 'n_units_Layer_2': 100, 'n_units_Layer_3': 295}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 9.20% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 17.50% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:36:04,248]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:07,254]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:11,367]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:12,398]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:14,805]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:19,374]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:24,892]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:27,757]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:32,199]\u001b[0m Trial 630 finished with value: 3.571554112610974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008038600233933252, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18139661979935814, 'dropout_rate_Layer_2': 0.182886099541743, 'dropout_rate_Layer_3': 0.20550130300825908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.3028497049686656e-05, 'l1_Layer_2': 8.114948242225159e-05, 'l1_Layer_3': 0.0001663660829248181, 'n_units_Layer_1': 295, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 9.33% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 6.22 | sMAPE for Test Set is: 20.34% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:36:32,376]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:35,068]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:41,712]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:41,848]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:42,398]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:42,606]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:52,820]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:55,561]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:36:55,784]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:03,363]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:08,141]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:09,130]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:10,768]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:17,211]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:18,124]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:21,378]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:24,874]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:40,301]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:48,099]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:48,987]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:37:49,295]\u001b[0m Trial 648 finished with value: 3.8941260927937784 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024237927456254448, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1311122561832096, 'dropout_rate_Layer_2': 0.016671099697208407, 'dropout_rate_Layer_3': 0.07560860393740966, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010936934691065048, 'l1_Layer_2': 0.0013446952216744177, 'l1_Layer_3': 0.000552320241704662, 'n_units_Layer_1': 250, 'n_units_Layer_2': 295, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 10.11% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.93 | sMAPE for Test Set is: 25.44% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:37:58,482]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:06,245]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:10,714]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:14,340]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:19,020]\u001b[0m Trial 661 finished with value: 3.6029146286592693 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006614115105833838, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11086054991711039, 'dropout_rate_Layer_2': 0.10957822062828218, 'dropout_rate_Layer_3': 0.19464781948121979, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018195953588773838, 'l1_Layer_2': 0.00010265740967684211, 'l1_Layer_3': 0.00012466320074956444, 'n_units_Layer_1': 270, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 9.46% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 20.44% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:38:19,743]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:24,757]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:29,087]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:29,659]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:31,673]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:34,647]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:36,706]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:41,291]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:43,504]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:47,004]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:49,080]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:52,955]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:54,659]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:55,315]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:38:56,039]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:03,871]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:05,634]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:06,551]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:10,024]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:15,288]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:16,082]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:18,176]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:26,351]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:30,553]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:34,988]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:39,739]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:39,949]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:42,881]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:48,959]\u001b[0m Trial 678 finished with value: 3.443219886802318 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006518828299792225, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12062879140615054, 'dropout_rate_Layer_2': 0.16675264230227121, 'dropout_rate_Layer_3': 0.174665886682087, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022743849805971454, 'l1_Layer_2': 5.791219364244691e-05, 'l1_Layer_3': 0.00013029348417815774, 'n_units_Layer_1': 255, 'n_units_Layer_2': 105, 'n_units_Layer_3': 285}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.44 | sMAPE for Validation Set is: 8.99% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 4.08 | sMAPE for Test Set is: 14.20% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:39:49,319]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:49,418]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:53,913]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:39:59,839]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:00,083]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:00,211]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:00,798]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:08,322]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:15,627]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:31,513]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:34,691]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:37,555]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:40,450]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:43,786]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:44,383]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:50,087]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:40:50,362]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:00,649]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:05,015]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:10,343]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:10,673]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:18,057]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:21,165]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:25,584]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:27,049]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 10.16% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.67 | sMAPE for Test Set is: 24.96% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:41:27,590]\u001b[0m Trial 707 finished with value: 3.913366803677555 and parameters: {'n_hidden': 3, 'learning_rate': 0.002167649828581875, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03527420493445675, 'dropout_rate_Layer_2': 0.027205987682725336, 'dropout_rate_Layer_3': 0.05138194202176544, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.2951186782412455e-05, 'l1_Layer_2': 0.0007428831477903767, 'l1_Layer_3': 0.0005300716099519355, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 185}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:36,416]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:39,885]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:40,733]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:50,430]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:54,488]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:58,611]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:41:59,383]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:03,507]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:08,722]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:17,762]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:20,984]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:25,720]\u001b[0m Trial 723 finished with value: 3.9092282862003955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027768267423100897, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0570184080915011, 'dropout_rate_Layer_2': 0.04372181023411717, 'dropout_rate_Layer_3': 0.07889865665721484, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.6072305671611696e-05, 'l1_Layer_2': 0.0009720289519353875, 'l1_Layer_3': 0.00030605648397763604, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 190}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 10.18% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 24.69% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:42:28,046]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:35,796]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:36,764]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:42,277]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:44,421]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:46,880]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:48,237]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:48,848]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:55,880]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:57,966]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:42:58,236]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:00,973]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:06,643]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:07,149]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:12,108]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:25,759]\u001b[0m Trial 731 finished with value: 3.9087739369514605 and parameters: {'n_hidden': 3, 'learning_rate': 0.001952213317026892, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003497784260799143, 'dropout_rate_Layer_2': 0.01796745283213043, 'dropout_rate_Layer_3': 0.06933403435688543, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027659227556763716, 'l1_Layer_2': 0.0005900390309890499, 'l1_Layer_3': 0.00031673630471412424, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 185}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 10.14% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.41 | sMAPE for Test Set is: 24.25% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:43:28,445]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:34,415]\u001b[0m Trial 747 finished with value: 3.4880367320363574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005017584762365557, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11240435410349578, 'dropout_rate_Layer_2': 0.114745371735234, 'dropout_rate_Layer_3': 0.19472076000192007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001512510873619273, 'l1_Layer_2': 1.008146876196169e-05, 'l1_Layer_3': 0.0001430040421403938, 'n_units_Layer_1': 270, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 9.16% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 14.03% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:43:36,547]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:40,205]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:42,313]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:45,647]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:50,872]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:51,415]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:56,517]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:43:57,410]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:05,028]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:05,830]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:10,020]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:11,982]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:15,245]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:18,322]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:19,726]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:21,481]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:22,811]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:30,849]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:33,342]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:41,175]\u001b[0m Trial 751 finished with value: 3.873698412255701 and parameters: {'n_hidden': 3, 'learning_rate': 0.002658984887148943, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005364285585743128, 'dropout_rate_Layer_2': 0.034217318323965726, 'dropout_rate_Layer_3': 0.08143005189598515, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1860981751452358e-05, 'l1_Layer_2': 0.0005881480322158798, 'l1_Layer_3': 0.0003340495224640276, 'n_units_Layer_1': 235, 'n_units_Layer_2': 285, 'n_units_Layer_3': 200}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 10.05% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.15 | sMAPE for Test Set is: 25.94% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:44:51,251]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:44:59,836]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:45:08,504]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:45:11,294]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:45:15,596]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:45:20,741]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:45:24,023]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:45:30,212]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:45:33,949]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:45:34,114]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:45:42,196]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:45:44,571]\u001b[0m Trial 772 finished with value: 3.7882519555702334 and parameters: {'n_hidden': 3, 'learning_rate': 0.002384312318700406, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0050108331246341365, 'dropout_rate_Layer_2': 0.12070384737759332, 'dropout_rate_Layer_3': 0.08443334667879536, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5972609351813842e-05, 'l1_Layer_2': 0.0005020360132831275, 'l1_Layer_3': 0.0004784371493838536, 'n_units_Layer_1': 215, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 9.89% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 22.11% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:45:49,555]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:45:54,493]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:02,737]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:07,285]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:07,673]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:14,064]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:15,020]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:25,341]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:35,374]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:44,315]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:47,917]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:49,874]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:54,646]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:57,743]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:46:58,112]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:47:04,614]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:47:05,256]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:47:14,144]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:47:17,666]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:47:24,993]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:47:29,750]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:47:32,996]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:47:34,068]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:47:40,516]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:47:56,054]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:48:00,677]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:48:04,413]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:48:06,782]\u001b[0m Trial 801 finished with value: 3.720144798624671 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019985839572308197, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021323189955425106, 'dropout_rate_Layer_2': 0.06026458818864619, 'dropout_rate_Layer_3': 0.06806799749799433, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.12386732396487e-05, 'l1_Layer_2': 0.0008199920398695344, 'l1_Layer_3': 0.0003400472063052122, 'n_units_Layer_1': 225, 'n_units_Layer_2': 290, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 9.69% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 23.00% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:48:07,120]\u001b[0m Trial 769 finished with value: 3.9103634141477137 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006054025663896878, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22285239714028063, 'dropout_rate_Layer_2': 0.29578338740238136, 'dropout_rate_Layer_3': 0.19414299855735245, 'dropout_rate_Layer_4': 0.26922202724992655, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005924870501384089, 'l1_Layer_2': 5.602447256400574e-05, 'l1_Layer_3': 4.689169839501576e-05, 'l1_Layer_4': 0.0028514227008806727, 'n_units_Layer_1': 285, 'n_units_Layer_2': 265, 'n_units_Layer_3': 100, 'n_units_Layer_4': 235}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 10.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 23.16% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:48:11,172]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:48:13,351]\u001b[0m Trial 804 finished with value: 3.8390240177202775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019803708872945225, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0023940629660433497, 'dropout_rate_Layer_2': 0.05553621735643661, 'dropout_rate_Layer_3': 0.07550542106191423, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0876969938226543e-05, 'l1_Layer_2': 0.0008564021899947703, 'l1_Layer_3': 0.00033435466552912235, 'n_units_Layer_1': 220, 'n_units_Layer_2': 290, 'n_units_Layer_3': 185}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 9.95% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.78 | sMAPE for Test Set is: 25.10% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:48:14,218]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:48:23,464]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:48:27,390]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:48:47,933]\u001b[0m Trial 811 finished with value: 3.7309714791854387 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021062751115261723, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04945915331462655, 'dropout_rate_Layer_2': 0.0630662112745076, 'dropout_rate_Layer_3': 0.0764939296864834, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0151806587228195e-05, 'l1_Layer_2': 0.000604208605203383, 'l1_Layer_3': 0.0003699223177862075, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 9.79% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 23.29% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:48:49,479]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:48:54,759]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:48:58,441]\u001b[0m Trial 815 finished with value: 3.48355978518669 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005948692785847251, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11960531531751013, 'dropout_rate_Layer_2': 0.1355872722956806, 'dropout_rate_Layer_3': 0.18833152777851017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000274418035504472, 'l1_Layer_2': 4.156341790681835e-05, 'l1_Layer_3': 0.00018991813600091194, 'n_units_Layer_1': 245, 'n_units_Layer_2': 65, 'n_units_Layer_3': 275}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 9.17% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 4.47 | sMAPE for Test Set is: 15.68% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:49:00,832]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:49:05,337]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:49:08,176]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:49:08,446]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:49:19,425]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:49:28,736]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:49:32,684]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:49:37,898]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:49:38,949]\u001b[0m Trial 814 finished with value: 3.768051117277901 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005437659960128926, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20800306981911626, 'dropout_rate_Layer_2': 0.29467839190597234, 'dropout_rate_Layer_3': 0.19894281498724992, 'dropout_rate_Layer_4': 0.05779648767391024, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00036200410779526596, 'l1_Layer_2': 7.253983832557643e-05, 'l1_Layer_3': 5.2308787675740816e-05, 'l1_Layer_4': 0.0011401262103575079, 'n_units_Layer_1': 280, 'n_units_Layer_2': 255, 'n_units_Layer_3': 90, 'n_units_Layer_4': 235}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 9.79% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 19.78% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:49:43,768]\u001b[0m Trial 822 finished with value: 3.7491497344155995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018013006764587554, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030690780393708185, 'dropout_rate_Layer_2': 0.06783780689706859, 'dropout_rate_Layer_3': 0.09784251722031073, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0746171795755439e-05, 'l1_Layer_2': 0.00057106226288123, 'l1_Layer_3': 0.0002716669380017354, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 9.82% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 24.00% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:49:47,914]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:49:48,251]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:49:54,874]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:50:05,432]\u001b[0m Trial 824 finished with value: 3.8105816147129574 and parameters: {'n_hidden': 3, 'learning_rate': 0.002316081935828324, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03394815785916505, 'dropout_rate_Layer_2': 0.05374654192725813, 'dropout_rate_Layer_3': 0.08030653123449655, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.061234850954377e-05, 'l1_Layer_2': 0.0009708809477650266, 'l1_Layer_3': 0.00026904407962144797, 'n_units_Layer_1': 220, 'n_units_Layer_2': 275, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 9.97% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.34 | sMAPE for Test Set is: 26.48% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:50:08,694]\u001b[0m Trial 829 finished with value: 3.461000599033118 and parameters: {'n_hidden': 3, 'learning_rate': 0.000555161339787693, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1220582905433909, 'dropout_rate_Layer_2': 0.12277463073916184, 'dropout_rate_Layer_3': 0.17836997878577468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.891057690062895e-05, 'l1_Layer_2': 2.8232857622131657e-05, 'l1_Layer_3': 0.00021216755568225718, 'n_units_Layer_1': 240, 'n_units_Layer_2': 95, 'n_units_Layer_3': 265}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.46 | sMAPE for Validation Set is: 9.09% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 14.03% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:50:13,190]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:50:17,525]\u001b[0m Trial 833 finished with value: 3.4657042668164615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005513590130176209, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12343509842298792, 'dropout_rate_Layer_2': 0.12255046701318029, 'dropout_rate_Layer_3': 0.18792843848589932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013330197173078517, 'l1_Layer_2': 2.2772988349530244e-05, 'l1_Layer_3': 8.272817056182982e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 95, 'n_units_Layer_3': 265}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.47 | sMAPE for Validation Set is: 9.12% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.92 | sMAPE for Test Set is: 13.53% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:50:21,862]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:50:22,025]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:50:31,877]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:50:33,901]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:50:38,188]\u001b[0m Trial 831 finished with value: 3.797175114705354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015505771742185305, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03401319372082663, 'dropout_rate_Layer_2': 0.06055305713989689, 'dropout_rate_Layer_3': 0.10619920159865302, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.255042082543223e-05, 'l1_Layer_2': 0.0006069099582313679, 'l1_Layer_3': 0.00029648873064223765, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 180}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 9.95% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.89 | sMAPE for Test Set is: 25.54% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:50:38,542]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:50:40,546]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:50:42,434]\u001b[0m Trial 834 finished with value: 3.7847234247542327 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019477935413220776, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027327835846131847, 'dropout_rate_Layer_2': 0.06462709978426595, 'dropout_rate_Layer_3': 0.10004624364367459, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0254807631216355e-05, 'l1_Layer_2': 0.0009025962778867858, 'l1_Layer_3': 0.0002446317703938761, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 170}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 9.93% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.43 | sMAPE for Test Set is: 24.27% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:50:51,720]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:50:56,871]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:50:57,367]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:04,641]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:08,114]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:09,978]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:14,896]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:19,653]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:25,318]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:25,347]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:34,750]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:35,035]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:41,610]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:48,012]\u001b[0m Trial 847 finished with value: 3.7474773214141415 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014608089457558225, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03316993510370478, 'dropout_rate_Layer_2': 0.06622848182194119, 'dropout_rate_Layer_3': 0.10817751887826697, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2509393402376239e-05, 'l1_Layer_2': 0.0006285108680989525, 'l1_Layer_3': 0.0002488471532005293, 'n_units_Layer_1': 220, 'n_units_Layer_2': 265, 'n_units_Layer_3': 180}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 9.84% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.91 | sMAPE for Test Set is: 25.54% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:51:51,024]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:53,111]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:51:57,745]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:52:03,234]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:52:08,057]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:52:08,255]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:52:14,481]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:52:18,568]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:52:22,149]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:52:24,436]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:52:29,284]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:52:31,701]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:52:36,739]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:52:41,835]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:07,872]\u001b[0m Trial 868 finished with value: 3.711588248904358 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014779785553363592, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02565321906373578, 'dropout_rate_Layer_2': 0.07416711510734933, 'dropout_rate_Layer_3': 0.0941862368791587, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8555847965154678e-05, 'l1_Layer_2': 0.0005931922233263528, 'l1_Layer_3': 0.00029399181439212287, 'n_units_Layer_1': 200, 'n_units_Layer_2': 265, 'n_units_Layer_3': 160}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 9.75% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.84 | sMAPE for Test Set is: 25.27% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:53:13,362]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:18,444]\u001b[0m Trial 873 finished with value: 3.815981448686351 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014179572543246738, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0254845028195226, 'dropout_rate_Layer_2': 0.07227295102777719, 'dropout_rate_Layer_3': 0.09615592895862861, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2621553924829015e-05, 'l1_Layer_2': 0.0005966003377787022, 'l1_Layer_3': 0.00027249180478434044, 'n_units_Layer_1': 200, 'n_units_Layer_2': 270, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 9.94% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.30 | sMAPE for Test Set is: 24.00% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:53:21,488]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:22,354]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:24,763]\u001b[0m Trial 872 finished with value: 3.7808856238300605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013689601170039534, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02669575509132051, 'dropout_rate_Layer_2': 0.07352295337561345, 'dropout_rate_Layer_3': 0.09488316318918003, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.320433601402243e-05, 'l1_Layer_2': 0.0005884576734536756, 'l1_Layer_3': 0.00030230507569261797, 'n_units_Layer_1': 200, 'n_units_Layer_2': 265, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 9.88% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.49 | sMAPE for Test Set is: 24.49% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:53:28,241]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:30,480]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:35,146]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:35,659]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:41,725]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:42,864]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:48,995]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:52,831]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:55,499]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:53:59,374]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:00,340]\u001b[0m Trial 860 finished with value: 4.294402398152946 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006887708808721303, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22968335324173295, 'dropout_rate_Layer_2': 0.3145705893209348, 'dropout_rate_Layer_3': 0.2648256645340023, 'dropout_rate_Layer_4': 0.042878769393953874, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009739861256496335, 'l1_Layer_2': 6.704040151494147e-05, 'l1_Layer_3': 7.001055256021593e-05, 'l1_Layer_4': 0.0023134017669598577, 'n_units_Layer_1': 280, 'n_units_Layer_2': 105, 'n_units_Layer_3': 110, 'n_units_Layer_4': 85}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 11.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.19 | sMAPE for Test Set is: 23.95% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:54:03,850]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:07,329]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:07,803]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:11,761]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:15,994]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:17,228]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:18,547]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:23,991]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:25,293]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:25,385]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:35,136]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:39,065]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.51 | sMAPE for Validation Set is: 9.25% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 15.69% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:54:40,724]\u001b[0m Trial 893 finished with value: 3.510373415659552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005044756246038582, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1381335353702631, 'dropout_rate_Layer_2': 0.13444904043153283, 'dropout_rate_Layer_3': 0.18065109978074556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017166133223709668, 'l1_Layer_2': 3.5778231921612505e-05, 'l1_Layer_3': 0.00019684822860833556, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 265}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:45,662]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:45,912]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 9.33% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 18.97% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:54:50,955]\u001b[0m Trial 899 finished with value: 3.5730309067217 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007244943326795207, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09888034233296762, 'dropout_rate_Layer_2': 0.15581369627386527, 'dropout_rate_Layer_3': 0.19924390460882663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018652852592877003, 'l1_Layer_2': 1.6958162326715376e-05, 'l1_Layer_3': 8.153043609146617e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 275}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:54,899]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:54:57,206]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:00,615]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:04,019]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:07,509]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:11,475]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:12,254]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:12,555]\u001b[0m Trial 902 finished with value: 3.5541270917312726 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007054473436167017, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12878031795637027, 'dropout_rate_Layer_2': 0.12608546694765865, 'dropout_rate_Layer_3': 0.16995046583153495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011977767200260278, 'l1_Layer_2': 2.4455519327205248e-05, 'l1_Layer_3': 0.00017424161297128674, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 250}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 9.33% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 4.18 | sMAPE for Test Set is: 14.75% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:55:12,856]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:21,223]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:21,498]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:21,921]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:22,771]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:31,321]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:34,565]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:37,576]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:41,459]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:44,979]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:48,548]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:52,784]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:54,323]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:55,032]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:55:57,051]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:04,131]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:04,476]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:04,708]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:12,289]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:16,154]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:16,188]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:17,650]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:27,381]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:31,408]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:31,700]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:38,536]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:38,766]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:41,769]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:47,558]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:48,087]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:53,584]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:54,391]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:56:56,596]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:02,812]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:05,163]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:07,105]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:09,442]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:15,285]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:20,378]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:21,323]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:26,437]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:28,182]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:32,248]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:38,193]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:38,817]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:41,034]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:42,033]\u001b[0m Trial 951 finished with value: 3.5461831218148525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006699301329981078, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11048755503038735, 'dropout_rate_Layer_2': 0.18087230068957477, 'dropout_rate_Layer_3': 0.22172376394726614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.244292731845503e-05, 'l1_Layer_2': 4.5613782790489606e-05, 'l1_Layer_3': 0.00048097969113193573, 'n_units_Layer_1': 260, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 9.32% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 18.31% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 02:57:44,879]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:50,107]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:52,910]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:56,013]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:56,480]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:57:56,913]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:05,987]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:06,222]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:06,444]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:13,008]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:15,103]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:22,658]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:23,193]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:23,409]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:27,243]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:34,364]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:34,764]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:35,091]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:37,041]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:41,056]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:45,395]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:47,236]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:58:56,433]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:59:00,445]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:59:02,656]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:59:06,976]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:59:07,322]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:59:11,578]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:59:14,600]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:59:21,746]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:59:25,444]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:59:28,245]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:59:32,478]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 02:59:36,642]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:00:07,099]\u001b[0m Trial 988 finished with value: 3.763826735710077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017201755916357998, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2699098661708043, 'dropout_rate_Layer_2': 0.054411594728213615, 'dropout_rate_Layer_3': 0.11059008316262554, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6807471311682753e-05, 'l1_Layer_2': 0.0006721828453403179, 'l1_Layer_3': 0.00025843652360563933, 'n_units_Layer_1': 220, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 9.92% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 24.20% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:00:12,768]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:00:18,370]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:00:22,717]\u001b[0m Trial 995 finished with value: 3.7913493153280835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018812738898936333, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2615102256043258, 'dropout_rate_Layer_2': 0.17486198521940685, 'dropout_rate_Layer_3': 0.08457089523117699, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008241795600907783, 'l1_Layer_2': 0.0006007624167687055, 'l1_Layer_3': 1.4419151061421676e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 280}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 9.95% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 21.91% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:00:22,949]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:00:29,135]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:00:29,746]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:00:36,171]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:00:40,067]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:00:41,741]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:00:50,357]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:00:53,562]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:00:56,039]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:00,055]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:03,762]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:03,970]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:05,404]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:11,912]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:15,239]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:17,531]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:18,025]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:25,105]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:25,270]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:32,536]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:32,762]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:33,406]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:40,100]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:46,310]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:48,643]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:49,214]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:49,323]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:56,846]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:01:56,900]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:02,671]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:04,816]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:07,134]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:10,066]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:10,525]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:16,019]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:16,677]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:22,419]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:23,410]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:26,166]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:33,069]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:34,339]\u001b[0m Trial 1031 finished with value: 3.545440373025189 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007675808148804585, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3403839693005811, 'dropout_rate_Layer_2': 0.037753625980486816, 'dropout_rate_Layer_3': 0.1693887079324506, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.961952935459333e-05, 'l1_Layer_2': 9.071782393336308e-05, 'l1_Layer_3': 0.00014998005950909527, 'n_units_Layer_1': 250, 'n_units_Layer_2': 110, 'n_units_Layer_3': 285}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 9.24% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 4.19 | sMAPE for Test Set is: 14.45% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:02:43,644]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:47,211]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:50,079]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:54,754]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:02:57,639]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:00,480]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:02,565]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:06,900]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:06,962]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:07,090]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:14,594]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:18,156]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:18,822]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:20,782]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:31,675]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:40,684]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:43,999]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:48,283]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:50,855]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:55,243]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:58,483]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:03:59,100]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:04,876]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:07,021]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:10,344]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:14,135]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:17,725]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:18,128]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:18,418]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:31,767]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:36,198]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:41,392]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:52,674]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:55,242]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:04:58,582]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:03,407]\u001b[0m Trial 1067 finished with value: 3.4615944480466587 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005469034305837514, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11538141981635482, 'dropout_rate_Layer_2': 0.15012647881846353, 'dropout_rate_Layer_3': 0.2321483749014152, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024715821434359846, 'l1_Layer_2': 1.1479792764141356e-05, 'l1_Layer_3': 8.221064896000401e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 100, 'n_units_Layer_3': 255}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.46 | sMAPE for Validation Set is: 9.07% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 17.38% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:05:04,234]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:05,877]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:07,259]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:12,498]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:13,647]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:14,447]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:20,939]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:23,872]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:24,424]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:31,674]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:31,942]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:32,091]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:40,857]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:43,174]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:43,353]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:50,050]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:54,855]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:05:59,146]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:05,359]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:05,488]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:06,304]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:07,150]\u001b[0m Trial 1089 finished with value: 3.780631577045946 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019456248212019352, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00820292331404672, 'dropout_rate_Layer_2': 0.06273968397611451, 'dropout_rate_Layer_3': 0.09123480703055106, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.729680617957724e-05, 'l1_Layer_2': 1.630739080411342e-05, 'l1_Layer_3': 6.299588338805776e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 280, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 9.85% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.46 | sMAPE for Test Set is: 24.33% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:06:13,509]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:17,587]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:20,152]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:25,333]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:25,533]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:32,379]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:36,642]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:37,214]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 9.84% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.74 | sMAPE for Test Set is: 22.21% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:06:37,239]\u001b[0m Trial 1100 finished with value: 3.760918569470681 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031983812288417326, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012834784712162362, 'dropout_rate_Layer_2': 0.058978435309844465, 'dropout_rate_Layer_3': 0.10573314803905019, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2749369699027794e-05, 'l1_Layer_2': 1.6962270088467356e-05, 'l1_Layer_3': 4.993984389588923e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:37,669]\u001b[0m Trial 1097 finished with value: 3.801495712139337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034349729252950464, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014447099014045853, 'dropout_rate_Layer_2': 0.058906118696215815, 'dropout_rate_Layer_3': 0.09267304092616988, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2958676687800309e-05, 'l1_Layer_2': 1.6417101555213063e-05, 'l1_Layer_3': 6.215523002792007e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 285, 'n_units_Layer_3': 180}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 9.93% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 21.72% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:06:50,605]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:53,465]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:06:55,767]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:01,503]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:05,492]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:06,530]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:07,891]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:10,449]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:11,787]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:16,471]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:20,263]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:21,621]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:24,280]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:25,870]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:27,019]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:28,541]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:37,521]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:37,739]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:42,383]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:44,688]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:49,399]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:49,630]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:07:50,523]\u001b[0m Trial 1123 finished with value: 3.646553358292516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006989894675781328, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10922847467603441, 'dropout_rate_Layer_2': 0.14443657072692231, 'dropout_rate_Layer_3': 0.010583217475158724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016796409363492636, 'l1_Layer_2': 2.3641099590069613e-05, 'l1_Layer_3': 0.00015073554636094071, 'n_units_Layer_1': 265, 'n_units_Layer_2': 85, 'n_units_Layer_3': 280}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 9.54% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 4.12 | sMAPE for Test Set is: 14.34% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:07:58,322]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:00,706]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:05,178]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:05,681]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:06,095]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:14,671]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:18,191]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:19,051]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:20,368]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:23,255]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:26,492]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:27,679]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:31,653]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:37,965]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:38,892]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:41,262]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:46,874]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:47,015]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:48,236]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:08:51,703]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:01,181]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:01,505]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:02,132]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:09,713]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:12,760]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:13,508]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:16,017]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:21,182]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:23,631]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:23,843]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:31,906]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:35,195]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:38,146]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:41,562]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:46,156]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:49,624]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:09:53,597]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:02,462]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:08,219]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:10,736]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:14,586]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:17,583]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:20,698]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:21,837]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:25,726]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:26,081]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:31,259]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:34,012]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:36,397]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:39,623]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:40,433]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:40,829]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:49,782]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:52,376]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:56,332]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:56,499]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:10:57,428]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:06,339]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:06,957]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:12,700]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:14,703]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:18,822]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:18,963]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:23,644]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:27,592]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:31,031]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:34,255]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:37,548]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:39,275]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:40,523]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:43,360]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:55,778]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:56,314]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:11:58,482]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:02,218]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:06,856]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:07,348]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:09,481]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:13,748]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:19,370]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:22,657]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:23,680]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:25,858]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:30,275]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:30,741]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:31,212]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:39,090]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:43,575]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:47,004]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:49,301]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:53,367]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:55,752]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:12:56,446]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:12:59,874]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:02,466]\u001b[0m Trial 1150 finished with value: 4.3100384141213395 and parameters: {'n_hidden': 4, 'learning_rate': 0.000787267972438455, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22447144084146498, 'dropout_rate_Layer_2': 0.16501379241124106, 'dropout_rate_Layer_3': 0.2311654803305108, 'dropout_rate_Layer_4': 0.2831328028467862, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002124375640020549, 'l1_Layer_2': 3.380452161341988e-05, 'l1_Layer_3': 0.0009842473400507885, 'l1_Layer_4': 0.001848206202890366, 'n_units_Layer_1': 95, 'n_units_Layer_2': 110, 'n_units_Layer_3': 125, 'n_units_Layer_4': 75}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 11.16% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 16.79% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:13:04,878]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:04,949]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:08,957]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:12,976]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:15,891]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:19,621]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:24,312]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:28,147]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:28,990]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:31,718]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:36,391]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:37,197]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:38,323]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:39,801]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:45,395]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:47,258]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:48,827]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:54,775]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:55,942]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:13:58,857]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:00,922]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:02,510]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:10,031]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:11,005]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:11,260]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:13,730]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:24,086]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:25,175]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:27,142]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:30,406]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:35,198]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:35,421]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:36,330]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:44,202]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:44,297]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:45,257]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:46,091]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:52,750]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:57,562]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:57,733]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:14:58,536]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:05,006]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:05,703]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:10,547]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:13,925]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:18,314]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:18,525]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:19,406]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:20,184]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:27,278]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:31,147]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:34,074]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:40,581]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:42,292]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:42,539]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:43,874]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:49,533]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:54,007]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:54,106]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:15:55,103]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:02,504]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:03,952]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:09,986]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:10,879]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:13,149]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:19,152]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:21,658]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:22,396]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:23,628]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:30,985]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:34,065]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:38,469]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:40,629]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:44,937]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:51,149]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:16:54,111]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:00,056]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:06,053]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:10,086]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:13,857]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:14,512]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:18,357]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:22,676]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:25,087]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:27,430]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:28,404]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:29,229]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:33,010]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:42,912]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:45,441]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:49,309]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:52,102]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:17:55,209]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:17:58,818]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:00,991]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:05,301]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:07,102]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:12,120]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:14,619]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:20,005]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:21,253]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:23,078]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:24,881]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:30,457]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:32,220]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:35,894]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:36,447]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:40,179]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:41,781]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:44,033]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:49,238]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:51,282]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:52,316]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:18:56,719]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:00,284]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:01,623]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:07,364]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:07,557]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:13,878]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:14,627]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:18,292]\u001b[0m Trial 1340 finished with value: 3.831015673812732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029449444535204453, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025482462532950438, 'dropout_rate_Layer_2': 0.050097007723446135, 'dropout_rate_Layer_3': 0.034439767860722705, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5055996648970929e-05, 'l1_Layer_2': 2.8060671447124272e-05, 'l1_Layer_3': 1.9694645738550106e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 275, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 10.01% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 21.69% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:19:21,576]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:27,190]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:30,945]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:36,260]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:42,259]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:45,196]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:49,479]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:51,100]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:56,995]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:19:59,827]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:00,260]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:07,828]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:10,065]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:10,356]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:17,771]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:18,079]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:22,748]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:30,336]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:36,004]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:42,566]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:48,760]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:20:54,972]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:00,614]\u001b[0m Trial 1363 finished with value: 3.4619540577287506 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005433008005070288, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08433968725512998, 'dropout_rate_Layer_2': 0.15901615232831393, 'dropout_rate_Layer_3': 0.18326206675461776, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023915201286338792, 'l1_Layer_2': 4.795519793591817e-05, 'l1_Layer_3': 0.00011052660764773404, 'n_units_Layer_1': 255, 'n_units_Layer_2': 85, 'n_units_Layer_3': 265}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.46 | sMAPE for Validation Set is: 9.09% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 3.72 | sMAPE for Test Set is: 12.98% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:21:05,548]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:05,728]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:12,200]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:18,354]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:18,727]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:28,172]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:31,632]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:38,260]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:44,048]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:49,634]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:54,198]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:21:57,128]\u001b[0m Trial 1376 finished with value: 3.7948825939017 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024585096150398734, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01370443375044702, 'dropout_rate_Layer_2': 0.06770562568801365, 'dropout_rate_Layer_3': 0.07134424441132682, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4878562480597939e-05, 'l1_Layer_2': 2.3669336686788173e-05, 'l1_Layer_3': 2.3006495394799485e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 240, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 9.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.07 | sMAPE for Test Set is: 26.05% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:22:01,782]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:22:02,347]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:22:13,126]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:22:25,747]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:22:27,342]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:22:33,676]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:22:37,608]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:22:42,663]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:22:46,325]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:22:50,976]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:22:56,145]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:06,718]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:11,250]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:15,517]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:18,483]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:26,330]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:29,374]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:33,527]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:40,162]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:44,672]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:47,256]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:48,471]\u001b[0m Trial 1393 finished with value: 3.760792447133076 and parameters: {'n_hidden': 3, 'learning_rate': 0.002314514826666815, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01794313308796144, 'dropout_rate_Layer_2': 0.0658189822947137, 'dropout_rate_Layer_3': 0.0784760376345312, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1692252039536754e-05, 'l1_Layer_2': 0.0009423736620684932, 'l1_Layer_3': 2.2869591326091727e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 280, 'n_units_Layer_3': 185}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 9.85% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.68 | sMAPE for Test Set is: 24.82% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:23:55,113]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:57,209]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:23:58,089]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:05,192]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:05,230]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:10,536]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:15,184]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:17,782]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:20,900]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:25,798]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:31,239]\u001b[0m Trial 1349 finished with value: 4.400994011694271 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005000996752440821, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21396818175012974, 'dropout_rate_Layer_2': 0.2588214861810456, 'dropout_rate_Layer_3': 0.0910127883634675, 'dropout_rate_Layer_4': 0.2554174627947404, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007847440378151086, 'l1_Layer_2': 6.336736804148008e-05, 'l1_Layer_3': 0.0028238202272179965, 'l1_Layer_4': 0.0030147396250558537, 'n_units_Layer_1': 180, 'n_units_Layer_2': 255, 'n_units_Layer_3': 205, 'n_units_Layer_4': 160}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 11.26% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.40 | sMAPE for Test Set is: 21.74% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:24:31,581]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:36,684]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:43,504]\u001b[0m Trial 1411 finished with value: 3.719532276308597 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024894005242139497, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06618943917279764, 'dropout_rate_Layer_2': 0.07424137026509894, 'dropout_rate_Layer_3': 0.08097747148789734, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6789681730312342e-05, 'l1_Layer_2': 2.0298682750227287e-05, 'l1_Layer_3': 1.5405599855251756e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 280, 'n_units_Layer_3': 175}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 9.75% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.44 | sMAPE for Test Set is: 24.22% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:24:43,751]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:51,477]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:56,722]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:24:57,632]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:25:04,239]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:25:17,652]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:25:22,151]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:25:39,816]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:25:49,231]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:25:53,254]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:26:08,528]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:26:11,663]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:26:13,956]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:26:19,991]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:26:23,861]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:26:24,081]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:26:43,202]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:04,069]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:07,117]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:10,074]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:18,322]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:21,928]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:22,703]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:25,183]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:31,332]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:33,934]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:37,324]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:40,240]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:45,673]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:49,695]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:27:51,015]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:01,092]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:03,808]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:07,077]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:08,766]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:11,842]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:15,900]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:19,825]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:22,263]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:25,739]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:32,908]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:37,256]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:37,639]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:44,770]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:47,752]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:52,400]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:28:53,062]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:00,179]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:07,759]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:11,207]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:12,052]\u001b[0m Trial 1418 finished with value: 4.304359344654687 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005076832481681144, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20499743196895215, 'dropout_rate_Layer_2': 0.26538732017731337, 'dropout_rate_Layer_3': 0.09484300843801312, 'dropout_rate_Layer_4': 0.03699780118344495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007548040528342424, 'l1_Layer_2': 5.2898995477063704e-05, 'l1_Layer_3': 0.0032630302186193194, 'l1_Layer_4': 0.005156710904782153, 'n_units_Layer_1': 255, 'n_units_Layer_2': 290, 'n_units_Layer_3': 210, 'n_units_Layer_4': 155}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 11.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 21.04% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:29:14,155]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:20,124]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:23,019]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:38,282]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:42,457]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:42,721]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:48,156]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:49,722]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:52,387]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:29:53,946]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:30:00,693]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:30:04,118]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:30:04,950]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:30:06,513]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:30:21,193]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:30:27,302]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:30:32,378]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:30:37,993]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:30:44,108]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:00,211]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:02,635]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:09,274]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:13,712]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:18,572]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:23,381]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:27,551]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:32,125]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:36,275]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:43,655]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:46,616]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:49,927]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:31:56,092]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 03:32:40,130]\u001b[0m Trial 1486 finished with value: 4.26546748183959 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006316162581432209, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22209803007861567, 'dropout_rate_Layer_2': 0.2789956124011715, 'dropout_rate_Layer_3': 0.09058221739752274, 'dropout_rate_Layer_4': 0.045791666306904524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005781052405691072, 'l1_Layer_2': 0.00010387711567853554, 'l1_Layer_3': 0.002270680362267521, 'l1_Layer_4': 0.005763736714830709, 'n_units_Layer_1': 265, 'n_units_Layer_2': 295, 'n_units_Layer_3': 200, 'n_units_Layer_4': 165}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.91 | sMAPE for Test Set is: 23.17% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 03:32:59,510]\u001b[0m Trial 1489 finished with value: 4.399691103841118 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007118398583974605, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21858277324336295, 'dropout_rate_Layer_2': 0.2987677964192497, 'dropout_rate_Layer_3': 0.10715920285242808, 'dropout_rate_Layer_4': 0.049254056145962434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015505510450550567, 'l1_Layer_2': 6.110811114011518e-05, 'l1_Layer_3': 0.002302585033295996, 'l1_Layer_4': 0.004232282691411265, 'n_units_Layer_1': 250, 'n_units_Layer_2': 280, 'n_units_Layer_3': 90, 'n_units_Layer_4': 185}. Best is trial 463 with value: 3.437013760528751.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 11.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.30 | sMAPE for Test Set is: 24.46% | rMAE for Test Set is: 1.08\n",
      "for 2020-01-01, MAE is:4.10 & sMAPE is:11.54% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 11.54% & 0.19\n",
      "for 2020-01-02, MAE is:5.12 & sMAPE is:12.78% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 12.16% & 0.27\n",
      "for 2020-01-03, MAE is:2.51 & sMAPE is:6.28% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 10.20% & 0.30\n",
      "for 2020-01-04, MAE is:3.60 & sMAPE is:9.73% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 10.08% & 0.42\n",
      "for 2020-01-05, MAE is:3.95 & sMAPE is:9.85% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 10.04% & 0.46\n",
      "for 2020-01-06, MAE is:5.58 & sMAPE is:13.72% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 10.65% & 0.56\n",
      "for 2020-01-07, MAE is:3.20 & sMAPE is:7.36% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 10.18% & 0.53\n",
      "for 2020-01-08, MAE is:3.87 & sMAPE is:8.41% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 9.96% & 0.51\n",
      "for 2020-01-09, MAE is:4.83 & sMAPE is:10.72% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 10.04% & 0.55\n",
      "for 2020-01-10, MAE is:5.24 & sMAPE is:13.19% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 10.36% & 0.67\n",
      "for 2020-01-11, MAE is:4.87 & sMAPE is:11.03% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 10.42% & 0.68\n",
      "for 2020-01-12, MAE is:5.90 & sMAPE is:13.50% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 10.68% & 0.72\n",
      "for 2020-01-13, MAE is:7.40 & sMAPE is:14.83% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 11.00% & 0.76\n",
      "for 2020-01-14, MAE is:3.91 & sMAPE is:9.71% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 10.90% & 0.74\n",
      "for 2020-01-15, MAE is:3.49 & sMAPE is:10.56% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 10.88% & 0.72\n",
      "for 2020-01-16, MAE is:4.79 & sMAPE is:12.03% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 10.95% & 0.72\n",
      "for 2020-01-17, MAE is:3.12 & sMAPE is:7.69% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 10.76% & 0.76\n",
      "for 2020-01-18, MAE is:4.47 & sMAPE is:11.23% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 10.79% & 0.77\n",
      "for 2020-01-19, MAE is:5.12 & sMAPE is:16.44% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 11.08% & 0.75\n",
      "for 2020-01-20, MAE is:3.50 & sMAPE is:10.98% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 11.08% & 0.72\n",
      "for 2020-01-21, MAE is:3.51 & sMAPE is:8.70% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 10.97% & 0.77\n",
      "for 2020-01-22, MAE is:8.79 & sMAPE is:20.76% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 11.41% & 0.78\n",
      "for 2020-01-23, MAE is:5.03 & sMAPE is:9.90% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 11.35% & 0.76\n",
      "for 2020-01-24, MAE is:5.07 & sMAPE is:9.75% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 11.28% & 0.74\n",
      "for 2020-01-25, MAE is:2.81 & sMAPE is:5.77% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 11.06% & 0.72\n",
      "for 2020-01-26, MAE is:4.22 & sMAPE is:10.27% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 11.03% & 0.71\n",
      "for 2020-01-27, MAE is:3.93 & sMAPE is:10.77% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 11.02% & 0.71\n",
      "for 2020-01-28, MAE is:2.95 & sMAPE is:8.57% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 10.93% & 0.74\n",
      "for 2020-01-29, MAE is:3.83 & sMAPE is:9.09% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 10.87% & 0.73\n",
      "for 2020-01-30, MAE is:3.58 & sMAPE is:8.95% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 10.80% & 0.71\n",
      "for 2020-01-31, MAE is:2.61 & sMAPE is:7.91% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 10.71% & 0.69\n",
      "for 2020-02-01, MAE is:2.25 & sMAPE is:7.58% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 10.61% & 0.68\n",
      "for 2020-02-02, MAE is:4.17 & sMAPE is:15.86% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 10.77% & 0.67\n",
      "for 2020-02-03, MAE is:3.35 & sMAPE is:9.10% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 10.72% & 0.68\n",
      "for 2020-02-04, MAE is:5.69 & sMAPE is:14.10% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 10.82% & 0.69\n",
      "for 2020-02-05, MAE is:4.48 & sMAPE is:12.08% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 10.85% & 0.71\n",
      "for 2020-02-06, MAE is:4.06 & sMAPE is:10.51% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 10.84% & 0.75\n",
      "for 2020-02-07, MAE is:3.54 & sMAPE is:8.78% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 10.79% & 0.76\n",
      "for 2020-02-08, MAE is:2.95 & sMAPE is:7.88% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 10.72% & 0.75\n",
      "for 2020-02-09, MAE is:3.14 & sMAPE is:10.05% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 10.70% & 0.74\n",
      "for 2020-02-10, MAE is:5.21 & sMAPE is:16.30% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 10.84% & 0.74\n",
      "for 2020-02-11, MAE is:4.52 & sMAPE is:11.90% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 10.86% & 0.75\n",
      "for 2020-02-12, MAE is:2.85 & sMAPE is:6.79% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 10.77% & 0.74\n",
      "for 2020-02-13, MAE is:2.84 & sMAPE is:7.23% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 10.69% & 0.75\n",
      "for 2020-02-14, MAE is:4.40 & sMAPE is:11.43% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 10.70% & 0.77\n",
      "for 2020-02-15, MAE is:4.93 & sMAPE is:13.61% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 10.77% & 0.78\n",
      "for 2020-02-16, MAE is:6.27 & sMAPE is:27.35% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 11.12% & 0.78\n",
      "for 2020-02-17, MAE is:3.90 & sMAPE is:11.78% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 11.13% & 0.78\n",
      "for 2020-02-18, MAE is:2.47 & sMAPE is:6.83% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 11.04% & 0.78\n",
      "for 2020-02-19, MAE is:6.52 & sMAPE is:17.16% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 11.17% & 0.81\n",
      "for 2020-02-20, MAE is:2.08 & sMAPE is:4.85% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 11.04% & 0.80\n",
      "for 2020-02-21, MAE is:3.45 & sMAPE is:8.64% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 11.00% & 0.80\n",
      "for 2020-02-22, MAE is:4.23 & sMAPE is:10.23% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 10.98% & 0.81\n",
      "for 2020-02-23, MAE is:4.06 & sMAPE is:10.95% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 10.98% & 0.80\n",
      "for 2020-02-24, MAE is:4.90 & sMAPE is:11.03% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 10.98% & 0.80\n",
      "for 2020-02-25, MAE is:4.95 & sMAPE is:14.22% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 11.04% & 0.80\n",
      "for 2020-02-26, MAE is:4.22 & sMAPE is:12.49% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 11.07% & 0.79\n",
      "for 2020-02-27, MAE is:5.35 & sMAPE is:16.90% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 11.17% & 0.79\n",
      "for 2020-02-28, MAE is:3.47 & sMAPE is:10.69% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 11.16% & 0.78\n",
      "for 2020-02-29, MAE is:9.85 & sMAPE is:46.17% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 11.74% & 0.78\n",
      "for 2020-03-01, MAE is:4.56 & sMAPE is:30.04% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 12.04% & 0.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-02, MAE is:5.75 & sMAPE is:22.79% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 12.22% & 0.76\n",
      "for 2020-03-03, MAE is:5.01 & sMAPE is:17.74% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 12.30% & 0.76\n",
      "for 2020-03-04, MAE is:4.86 & sMAPE is:17.24% & rMAE is:2.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 12.38% & 0.79\n",
      "for 2020-03-05, MAE is:9.42 & sMAPE is:30.53% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 12.66% & 0.80\n",
      "for 2020-03-06, MAE is:6.28 & sMAPE is:27.04% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 12.88% & 0.80\n",
      "for 2020-03-07, MAE is:3.20 & sMAPE is:11.18% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 12.85% & 0.79\n",
      "for 2020-03-08, MAE is:5.80 & sMAPE is:19.85% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 12.96% & 0.78\n",
      "for 2020-03-09, MAE is:2.87 & sMAPE is:9.00% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 12.90% & 0.78\n",
      "for 2020-03-10, MAE is:2.64 & sMAPE is:7.61% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 12.82% & 0.77\n",
      "for 2020-03-11, MAE is:3.49 & sMAPE is:9.14% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 12.77% & 0.77\n",
      "for 2020-03-12, MAE is:1.71 & sMAPE is:4.50% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 12.66% & 0.76\n",
      "for 2020-03-13, MAE is:4.30 & sMAPE is:13.14% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 12.66% & 0.75\n",
      "for 2020-03-14, MAE is:2.29 & sMAPE is:6.56% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 12.58% & 0.75\n",
      "for 2020-03-15, MAE is:9.97 & sMAPE is:33.07% & rMAE is:2.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 12.85% & 0.77\n",
      "for 2020-03-16, MAE is:6.11 & sMAPE is:20.42% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 12.95% & 0.78\n",
      "for 2020-03-17, MAE is:4.38 & sMAPE is:14.46% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 12.97% & 0.78\n",
      "for 2020-03-18, MAE is:4.26 & sMAPE is:13.33% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 12.98% & 0.78\n",
      "for 2020-03-19, MAE is:3.30 & sMAPE is:10.42% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 12.94% & 0.77\n",
      "for 2020-03-20, MAE is:1.98 & sMAPE is:6.98% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 12.87% & 0.76\n",
      "for 2020-03-21, MAE is:3.23 & sMAPE is:12.34% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 12.86% & 0.76\n",
      "for 2020-03-22, MAE is:2.02 & sMAPE is:7.17% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 12.79% & 0.76\n",
      "for 2020-03-23, MAE is:3.53 & sMAPE is:13.67% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 12.80% & 0.76\n",
      "for 2020-03-24, MAE is:3.06 & sMAPE is:12.46% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 12.80% & 0.76\n",
      "for 2020-03-25, MAE is:3.12 & sMAPE is:10.55% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 12.77% & 0.77\n",
      "for 2020-03-26, MAE is:9.04 & sMAPE is:34.20% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 13.02% & 0.77\n",
      "for 2020-03-27, MAE is:3.57 & sMAPE is:13.96% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 13.03% & 0.77\n",
      "for 2020-03-28, MAE is:3.84 & sMAPE is:14.86% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 13.05% & 0.79\n",
      "for 2020-03-29, MAE is:6.99 & sMAPE is:30.44% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 13.25% & 0.79\n",
      "for 2020-03-30, MAE is:6.02 & sMAPE is:28.90% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 13.42% & 0.79\n",
      "for 2020-03-31, MAE is:3.42 & sMAPE is:17.51% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 13.47% & 0.79\n",
      "for 2020-04-01, MAE is:4.54 & sMAPE is:20.07% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 13.54% & 0.79\n",
      "for 2020-04-02, MAE is:4.86 & sMAPE is:18.81% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 13.60% & 0.80\n",
      "for 2020-04-03, MAE is:2.53 & sMAPE is:11.66% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 13.58% & 0.80\n",
      "for 2020-04-04, MAE is:10.60 & sMAPE is:51.68% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 13.98% & 0.80\n",
      "for 2020-04-05, MAE is:7.33 & sMAPE is:71.89% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 14.58% & 0.80\n",
      "for 2020-04-06, MAE is:7.47 & sMAPE is:35.86% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 14.80% & 0.81\n",
      "for 2020-04-07, MAE is:2.62 & sMAPE is:12.33% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 14.78% & 0.80\n",
      "for 2020-04-08, MAE is:2.03 & sMAPE is:8.55% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 14.71% & 0.80\n",
      "for 2020-04-09, MAE is:3.16 & sMAPE is:14.63% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 14.71% & 0.81\n",
      "for 2020-04-10, MAE is:3.51 & sMAPE is:17.49% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.43 & 14.74% & 0.81\n",
      "for 2020-04-11, MAE is:2.27 & sMAPE is:10.23% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 14.69% & 0.80\n",
      "for 2020-04-12, MAE is:2.61 & sMAPE is:13.19% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 14.68% & 0.80\n",
      "for 2020-04-13, MAE is:2.07 & sMAPE is:9.52% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 14.63% & 0.80\n",
      "for 2020-04-14, MAE is:3.41 & sMAPE is:14.96% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 14.63% & 0.80\n",
      "for 2020-04-15, MAE is:2.96 & sMAPE is:16.19% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 14.65% & 0.80\n",
      "for 2020-04-16, MAE is:4.41 & sMAPE is:28.51% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 14.78% & 0.80\n",
      "for 2020-04-17, MAE is:3.55 & sMAPE is:22.47% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.85% & 0.80\n",
      "for 2020-04-18, MAE is:2.87 & sMAPE is:14.07% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 14.84% & 0.80\n",
      "for 2020-04-19, MAE is:8.88 & sMAPE is:50.69% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 15.17% & 0.81\n",
      "for 2020-04-20, MAE is:4.60 & sMAPE is:35.43% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 15.35% & 0.81\n",
      "for 2020-04-21, MAE is:5.49 & sMAPE is:45.35% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 15.62% & 0.81\n",
      "for 2020-04-22, MAE is:3.12 & sMAPE is:37.11% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 15.81% & 0.80\n",
      "for 2020-04-23, MAE is:2.60 & sMAPE is:15.12% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 15.80% & 0.80\n",
      "for 2020-04-24, MAE is:3.28 & sMAPE is:18.49% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 15.83% & 0.80\n",
      "for 2020-04-25, MAE is:2.22 & sMAPE is:12.17% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 15.79% & 0.80\n",
      "for 2020-04-26, MAE is:2.92 & sMAPE is:18.73% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 15.82% & 0.80\n",
      "for 2020-04-27, MAE is:1.61 & sMAPE is:8.14% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 15.75% & 0.79\n",
      "for 2020-04-28, MAE is:2.18 & sMAPE is:11.86% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 15.72% & 0.79\n",
      "for 2020-04-29, MAE is:7.81 & sMAPE is:54.92% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 16.05% & 0.80\n",
      "for 2020-04-30, MAE is:6.47 & sMAPE is:56.14% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 16.38% & 0.79\n",
      "for 2020-05-01, MAE is:5.91 & sMAPE is:88.72% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 16.97% & 0.79\n",
      "for 2020-05-02, MAE is:2.05 & sMAPE is:20.12% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 17.00% & 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-03, MAE is:5.68 & sMAPE is:35.59% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 17.15% & 0.80\n",
      "for 2020-05-04, MAE is:6.17 & sMAPE is:32.46% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 17.27% & 0.81\n",
      "for 2020-05-05, MAE is:2.08 & sMAPE is:11.23% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 17.22% & 0.81\n",
      "for 2020-05-06, MAE is:3.10 & sMAPE is:14.17% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 17.20% & 0.80\n",
      "for 2020-05-07, MAE is:2.73 & sMAPE is:13.02% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 17.17% & 0.80\n",
      "for 2020-05-08, MAE is:2.67 & sMAPE is:13.05% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 17.13% & 0.79\n",
      "for 2020-05-09, MAE is:4.08 & sMAPE is:19.94% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 17.16% & 0.79\n",
      "for 2020-05-10, MAE is:7.00 & sMAPE is:45.81% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 17.37% & 0.81\n",
      "for 2020-05-11, MAE is:1.92 & sMAPE is:11.65% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 17.33% & 0.81\n",
      "for 2020-05-12, MAE is:4.39 & sMAPE is:20.23% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 17.35% & 0.81\n",
      "for 2020-05-13, MAE is:4.29 & sMAPE is:18.69% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 17.36% & 0.81\n",
      "for 2020-05-14, MAE is:2.20 & sMAPE is:8.62% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 17.30% & 0.81\n",
      "for 2020-05-15, MAE is:2.12 & sMAPE is:10.81% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 17.25% & 0.81\n",
      "for 2020-05-16, MAE is:3.00 & sMAPE is:18.15% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 17.26% & 0.81\n",
      "for 2020-05-17, MAE is:3.65 & sMAPE is:23.31% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 17.30% & 0.81\n",
      "for 2020-05-18, MAE is:1.94 & sMAPE is:7.61% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 17.23% & 0.80\n",
      "for 2020-05-19, MAE is:2.04 & sMAPE is:7.46% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 17.16% & 0.80\n",
      "for 2020-05-20, MAE is:2.98 & sMAPE is:10.35% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 17.11% & 0.81\n",
      "for 2020-05-21, MAE is:1.73 & sMAPE is:6.44% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 17.04% & 0.81\n",
      "for 2020-05-22, MAE is:1.52 & sMAPE is:5.30% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 16.96% & 0.81\n",
      "for 2020-05-23, MAE is:9.97 & sMAPE is:47.48% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 17.17% & 0.81\n",
      "for 2020-05-24, MAE is:4.43 & sMAPE is:36.67% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 17.30% & 0.82\n",
      "for 2020-05-25, MAE is:2.32 & sMAPE is:9.90% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 17.25% & 0.82\n",
      "for 2020-05-26, MAE is:2.52 & sMAPE is:11.70% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 17.21% & 0.81\n",
      "for 2020-05-27, MAE is:1.90 & sMAPE is:7.69% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 17.15% & 0.81\n",
      "for 2020-05-28, MAE is:1.63 & sMAPE is:5.74% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 17.07% & 0.82\n",
      "for 2020-05-29, MAE is:1.51 & sMAPE is:4.59% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 16.99% & 0.82\n",
      "for 2020-05-30, MAE is:2.76 & sMAPE is:9.54% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 16.94% & 0.81\n",
      "for 2020-05-31, MAE is:3.73 & sMAPE is:12.97% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 16.91% & 0.81\n",
      "for 2020-06-01, MAE is:1.53 & sMAPE is:4.62% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 16.83% & 0.80\n",
      "for 2020-06-02, MAE is:1.89 & sMAPE is:5.52% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 16.76% & 0.80\n",
      "for 2020-06-03, MAE is:3.47 & sMAPE is:10.44% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 16.72% & 0.80\n",
      "for 2020-06-04, MAE is:5.14 & sMAPE is:20.62% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 16.74% & 0.80\n",
      "for 2020-06-05, MAE is:4.35 & sMAPE is:16.55% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 16.74% & 0.80\n",
      "for 2020-06-06, MAE is:2.78 & sMAPE is:9.98% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 16.70% & 0.80\n",
      "for 2020-06-07, MAE is:7.48 & sMAPE is:33.89% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 16.81% & 0.80\n",
      "for 2020-06-08, MAE is:2.42 & sMAPE is:8.88% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 16.76% & 0.80\n",
      "for 2020-06-09, MAE is:2.07 & sMAPE is:7.34% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 16.70% & 0.80\n",
      "for 2020-06-10, MAE is:2.94 & sMAPE is:9.64% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 16.66% & 0.80\n",
      "for 2020-06-11, MAE is:6.74 & sMAPE is:25.62% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 16.71% & 0.80\n",
      "for 2020-06-12, MAE is:2.37 & sMAPE is:11.52% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 16.68% & 0.80\n",
      "for 2020-06-13, MAE is:3.81 & sMAPE is:17.26% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 16.68% & 0.80\n",
      "for 2020-06-14, MAE is:3.39 & sMAPE is:13.92% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 16.67% & 0.80\n",
      "for 2020-06-15, MAE is:3.12 & sMAPE is:10.37% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 16.63% & 0.80\n",
      "for 2020-06-16, MAE is:3.09 & sMAPE is:10.14% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 16.59% & 0.80\n",
      "for 2020-06-17, MAE is:3.33 & sMAPE is:10.19% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 16.55% & 0.80\n",
      "for 2020-06-18, MAE is:3.18 & sMAPE is:8.78% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 16.51% & 0.79\n",
      "for 2020-06-19, MAE is:2.28 & sMAPE is:6.99% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 16.45% & 0.79\n",
      "for 2020-06-20, MAE is:2.54 & sMAPE is:8.45% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.40% & 0.79\n",
      "for 2020-06-21, MAE is:5.01 & sMAPE is:17.72% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 16.41% & 0.79\n",
      "for 2020-06-22, MAE is:4.51 & sMAPE is:15.04% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 16.40% & 0.80\n",
      "for 2020-06-23, MAE is:3.48 & sMAPE is:10.34% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 16.37% & 0.80\n",
      "for 2020-06-24, MAE is:2.48 & sMAPE is:6.76% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.32% & 0.80\n",
      "for 2020-06-25, MAE is:2.32 & sMAPE is:6.16% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 16.26% & 0.80\n",
      "for 2020-06-26, MAE is:2.68 & sMAPE is:7.14% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 16.21% & 0.80\n",
      "for 2020-06-27, MAE is:5.48 & sMAPE is:17.30% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 16.21% & 0.80\n",
      "for 2020-06-28, MAE is:5.55 & sMAPE is:17.57% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.22% & 0.80\n",
      "for 2020-06-29, MAE is:4.74 & sMAPE is:13.50% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.21% & 0.80\n",
      "for 2020-06-30, MAE is:2.96 & sMAPE is:8.11% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 16.16% & 0.80\n",
      "for 2020-07-01, MAE is:2.39 & sMAPE is:6.66% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 16.11% & 0.81\n",
      "for 2020-07-02, MAE is:5.66 & sMAPE is:16.11% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 16.11% & 0.81\n",
      "for 2020-07-03, MAE is:3.44 & sMAPE is:10.04% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 16.08% & 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-04, MAE is:6.71 & sMAPE is:21.23% & rMAE is:3.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.10% & 0.82\n",
      "for 2020-07-05, MAE is:2.62 & sMAPE is:9.71% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.07% & 0.82\n",
      "for 2020-07-06, MAE is:5.17 & sMAPE is:18.18% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.08% & 0.82\n",
      "for 2020-07-07, MAE is:2.84 & sMAPE is:8.06% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 16.04% & 0.82\n",
      "for 2020-07-08, MAE is:3.05 & sMAPE is:8.28% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 16.00% & 0.82\n",
      "for 2020-07-09, MAE is:4.79 & sMAPE is:12.43% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 15.98% & 0.82\n",
      "for 2020-07-10, MAE is:4.02 & sMAPE is:10.42% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 15.95% & 0.82\n",
      "for 2020-07-11, MAE is:3.70 & sMAPE is:12.41% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 15.93% & 0.83\n",
      "for 2020-07-12, MAE is:5.20 & sMAPE is:17.52% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 15.94% & 0.83\n",
      "for 2020-07-13, MAE is:3.86 & sMAPE is:11.37% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 15.92% & 0.83\n",
      "for 2020-07-14, MAE is:4.16 & sMAPE is:12.70% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 15.90% & 0.84\n",
      "for 2020-07-15, MAE is:2.24 & sMAPE is:7.16% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 15.86% & 0.84\n",
      "for 2020-07-16, MAE is:1.61 & sMAPE is:4.64% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 15.80% & 0.83\n",
      "for 2020-07-17, MAE is:3.23 & sMAPE is:9.85% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 15.77% & 0.83\n",
      "for 2020-07-18, MAE is:4.80 & sMAPE is:15.36% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 15.77% & 0.84\n",
      "for 2020-07-19, MAE is:5.25 & sMAPE is:16.87% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 15.77% & 0.85\n",
      "for 2020-07-20, MAE is:2.78 & sMAPE is:8.19% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 15.74% & 0.85\n",
      "for 2020-07-21, MAE is:4.22 & sMAPE is:12.14% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 15.72% & 0.85\n",
      "for 2020-07-22, MAE is:3.40 & sMAPE is:8.73% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 15.68% & 0.85\n",
      "for 2020-07-23, MAE is:1.56 & sMAPE is:3.76% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 15.62% & 0.85\n",
      "for 2020-07-24, MAE is:5.54 & sMAPE is:14.94% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 15.62% & 0.85\n",
      "for 2020-07-25, MAE is:2.94 & sMAPE is:8.90% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 15.59% & 0.85\n",
      "for 2020-07-26, MAE is:3.48 & sMAPE is:11.27% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 15.57% & 0.85\n",
      "for 2020-07-27, MAE is:1.59 & sMAPE is:4.05% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 15.51% & 0.85\n",
      "for 2020-07-28, MAE is:2.33 & sMAPE is:6.73% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 15.47% & 0.85\n",
      "for 2020-07-29, MAE is:2.73 & sMAPE is:7.50% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 15.43% & 0.85\n",
      "for 2020-07-30, MAE is:2.87 & sMAPE is:7.02% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 15.39% & 0.85\n",
      "for 2020-07-31, MAE is:2.64 & sMAPE is:6.36% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 15.35% & 0.85\n",
      "for 2020-08-01, MAE is:8.72 & sMAPE is:23.26% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 15.39% & 0.86\n",
      "for 2020-08-02, MAE is:2.85 & sMAPE is:9.70% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 15.36% & 0.86\n",
      "for 2020-08-03, MAE is:2.44 & sMAPE is:7.08% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 15.32% & 0.86\n",
      "for 2020-08-04, MAE is:2.47 & sMAPE is:7.01% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 15.29% & 0.86\n",
      "for 2020-08-05, MAE is:3.77 & sMAPE is:10.15% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 15.26% & 0.86\n",
      "for 2020-08-06, MAE is:3.37 & sMAPE is:8.92% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 15.23% & 0.87\n",
      "for 2020-08-07, MAE is:3.81 & sMAPE is:9.82% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 15.21% & 0.87\n",
      "for 2020-08-08, MAE is:3.20 & sMAPE is:8.70% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 15.18% & 0.87\n",
      "for 2020-08-09, MAE is:3.93 & sMAPE is:11.43% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 15.16% & 0.86\n",
      "for 2020-08-10, MAE is:3.70 & sMAPE is:9.85% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 15.14% & 0.87\n",
      "for 2020-08-11, MAE is:2.45 & sMAPE is:6.44% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 15.10% & 0.87\n",
      "for 2020-08-12, MAE is:3.45 & sMAPE is:8.84% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 15.07% & 0.87\n",
      "for 2020-08-13, MAE is:2.63 & sMAPE is:6.41% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 15.03% & 0.87\n",
      "for 2020-08-14, MAE is:4.64 & sMAPE is:12.31% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 15.02% & 0.87\n",
      "for 2020-08-15, MAE is:3.64 & sMAPE is:11.30% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 15.00% & 0.87\n",
      "for 2020-08-16, MAE is:4.68 & sMAPE is:15.72% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 15.01% & 0.87\n",
      "for 2020-08-17, MAE is:2.49 & sMAPE is:7.08% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 14.97% & 0.87\n",
      "for 2020-08-18, MAE is:4.05 & sMAPE is:10.53% & rMAE is:3.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 14.95% & 0.88\n",
      "for 2020-08-19, MAE is:7.14 & sMAPE is:19.37% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 14.97% & 0.89\n",
      "for 2020-08-20, MAE is:6.12 & sMAPE is:17.18% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 14.98% & 0.89\n",
      "for 2020-08-21, MAE is:6.85 & sMAPE is:19.46% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 15.00% & 0.89\n",
      "for 2020-08-22, MAE is:6.29 & sMAPE is:18.68% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 15.02% & 0.89\n",
      "for 2020-08-23, MAE is:4.98 & sMAPE is:16.81% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 15.03% & 0.90\n",
      "for 2020-08-24, MAE is:6.74 & sMAPE is:18.08% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 15.04% & 0.90\n",
      "for 2020-08-25, MAE is:5.68 & sMAPE is:13.72% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 15.03% & 0.91\n",
      "for 2020-08-26, MAE is:6.87 & sMAPE is:17.14% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 15.04% & 0.91\n",
      "for 2020-08-27, MAE is:2.15 & sMAPE is:4.76% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 15.00% & 0.91\n",
      "for 2020-08-28, MAE is:4.56 & sMAPE is:11.53% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 14.98% & 0.90\n",
      "for 2020-08-29, MAE is:5.39 & sMAPE is:17.34% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 14.99% & 0.91\n",
      "for 2020-08-30, MAE is:2.63 & sMAPE is:7.64% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 14.96% & 0.91\n",
      "for 2020-08-31, MAE is:5.54 & sMAPE is:13.61% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 14.96% & 0.91\n",
      "for 2020-09-01, MAE is:6.43 & sMAPE is:14.44% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 14.96% & 0.91\n",
      "for 2020-09-02, MAE is:5.69 & sMAPE is:13.51% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 14.95% & 0.91\n",
      "for 2020-09-03, MAE is:4.33 & sMAPE is:9.48% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 14.93% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-04, MAE is:5.55 & sMAPE is:12.67% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 14.92% & 0.91\n",
      "for 2020-09-05, MAE is:6.61 & sMAPE is:17.59% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 14.93% & 0.91\n",
      "for 2020-09-06, MAE is:3.34 & sMAPE is:10.31% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 14.91% & 0.92\n",
      "for 2020-09-07, MAE is:4.09 & sMAPE is:10.23% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 14.89% & 0.92\n",
      "for 2020-09-08, MAE is:3.45 & sMAPE is:8.41% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 14.87% & 0.92\n",
      "for 2020-09-09, MAE is:3.30 & sMAPE is:7.54% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 14.84% & 0.92\n",
      "for 2020-09-10, MAE is:4.01 & sMAPE is:9.13% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 14.82% & 0.92\n",
      "for 2020-09-11, MAE is:4.39 & sMAPE is:9.63% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 14.79% & 0.92\n",
      "for 2020-09-12, MAE is:4.80 & sMAPE is:11.54% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 14.78% & 0.92\n",
      "for 2020-09-13, MAE is:5.86 & sMAPE is:16.09% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 14.79% & 0.92\n",
      "for 2020-09-14, MAE is:5.33 & sMAPE is:12.48% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 14.78% & 0.92\n",
      "for 2020-09-15, MAE is:3.69 & sMAPE is:7.81% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 14.75% & 0.92\n",
      "for 2020-09-16, MAE is:2.76 & sMAPE is:5.51% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 14.72% & 0.92\n",
      "for 2020-09-17, MAE is:5.91 & sMAPE is:13.01% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 14.71% & 0.93\n",
      "for 2020-09-18, MAE is:3.68 & sMAPE is:8.54% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 14.69% & 0.93\n",
      "for 2020-09-19, MAE is:3.06 & sMAPE is:7.51% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 14.66% & 0.93\n",
      "for 2020-09-20, MAE is:4.69 & sMAPE is:11.68% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 14.65% & 0.93\n",
      "for 2020-09-21, MAE is:3.80 & sMAPE is:7.95% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 14.62% & 0.93\n",
      "for 2020-09-22, MAE is:2.19 & sMAPE is:4.34% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 14.58% & 0.93\n",
      "for 2020-09-23, MAE is:4.34 & sMAPE is:9.64% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 14.56% & 0.93\n",
      "for 2020-09-24, MAE is:6.04 & sMAPE is:15.09% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 14.57% & 0.92\n",
      "for 2020-09-25, MAE is:6.79 & sMAPE is:25.10% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 14.61% & 0.92\n",
      "for 2020-09-26, MAE is:6.86 & sMAPE is:22.29% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 14.63% & 0.92\n",
      "for 2020-09-27, MAE is:6.41 & sMAPE is:26.31% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 14.68% & 0.92\n",
      "for 2020-09-28, MAE is:4.18 & sMAPE is:10.00% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 14.66% & 0.92\n",
      "for 2020-09-29, MAE is:6.65 & sMAPE is:14.13% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 14.66% & 0.92\n",
      "for 2020-09-30, MAE is:4.08 & sMAPE is:8.41% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 14.64% & 0.92\n",
      "for 2020-10-01, MAE is:5.67 & sMAPE is:13.70% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 14.63% & 0.93\n",
      "for 2020-10-02, MAE is:8.67 & sMAPE is:31.40% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 14.69% & 0.93\n",
      "for 2020-10-03, MAE is:6.84 & sMAPE is:34.59% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 14.76% & 0.93\n",
      "for 2020-10-04, MAE is:14.31 & sMAPE is:79.12% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 15.00% & 0.93\n",
      "for 2020-10-05, MAE is:10.81 & sMAPE is:33.09% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 15.06% & 0.93\n",
      "for 2020-10-06, MAE is:4.12 & sMAPE is:9.95% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 15.04% & 0.93\n",
      "for 2020-10-07, MAE is:3.77 & sMAPE is:8.65% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 15.02% & 0.93\n",
      "for 2020-10-08, MAE is:4.51 & sMAPE is:10.14% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 15.00% & 0.93\n",
      "for 2020-10-09, MAE is:4.29 & sMAPE is:9.59% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 14.98% & 0.93\n",
      "for 2020-10-10, MAE is:3.19 & sMAPE is:9.71% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 14.96% & 0.92\n",
      "for 2020-10-11, MAE is:2.81 & sMAPE is:9.99% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 14.95% & 0.92\n",
      "for 2020-10-12, MAE is:7.86 & sMAPE is:22.28% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 14.97% & 0.92\n",
      "for 2020-10-13, MAE is:6.95 & sMAPE is:16.75% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 14.98% & 0.93\n",
      "for 2020-10-14, MAE is:6.05 & sMAPE is:16.35% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.98% & 0.93\n",
      "for 2020-10-15, MAE is:3.78 & sMAPE is:9.48% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 14.97% & 0.92\n",
      "for 2020-10-16, MAE is:4.43 & sMAPE is:10.34% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.95% & 0.92\n",
      "for 2020-10-17, MAE is:4.88 & sMAPE is:11.31% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.94% & 0.92\n",
      "for 2020-10-18, MAE is:3.55 & sMAPE is:8.96% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.92% & 0.92\n",
      "for 2020-10-19, MAE is:6.43 & sMAPE is:18.18% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.93% & 0.92\n",
      "for 2020-10-20, MAE is:3.65 & sMAPE is:10.19% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 14.91% & 0.92\n",
      "for 2020-10-21, MAE is:6.48 & sMAPE is:18.23% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 14.92% & 0.92\n",
      "for 2020-10-22, MAE is:6.23 & sMAPE is:14.11% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 14.92% & 0.92\n",
      "for 2020-10-23, MAE is:3.80 & sMAPE is:8.44% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 14.90% & 0.92\n",
      "for 2020-10-24, MAE is:7.48 & sMAPE is:21.84% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 14.92% & 0.92\n",
      "for 2020-10-25, MAE is:10.92 & sMAPE is:72.37% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 15.11% & 0.92\n",
      "for 2020-10-26, MAE is:8.19 & sMAPE is:26.48% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 15.15% & 0.92\n",
      "for 2020-10-27, MAE is:4.09 & sMAPE is:10.40% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 15.14% & 0.92\n",
      "for 2020-10-28, MAE is:5.80 & sMAPE is:13.56% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 15.13% & 0.92\n",
      "for 2020-10-29, MAE is:2.77 & sMAPE is:6.12% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 15.10% & 0.92\n",
      "for 2020-10-30, MAE is:3.78 & sMAPE is:9.18% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 15.08% & 0.92\n",
      "for 2020-10-31, MAE is:4.09 & sMAPE is:11.33% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 15.07% & 0.92\n",
      "for 2020-11-01, MAE is:8.56 & sMAPE is:30.32% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 15.12% & 0.92\n",
      "for 2020-11-02, MAE is:8.37 & sMAPE is:22.04% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 15.14% & 0.92\n",
      "for 2020-11-03, MAE is:5.81 & sMAPE is:14.35% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 15.14% & 0.92\n",
      "for 2020-11-04, MAE is:7.70 & sMAPE is:22.02% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 15.16% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-05, MAE is:3.99 & sMAPE is:13.36% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 15.15% & 0.92\n",
      "for 2020-11-06, MAE is:2.74 & sMAPE is:7.70% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 15.13% & 0.92\n",
      "for 2020-11-07, MAE is:4.96 & sMAPE is:16.52% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 15.14% & 0.92\n",
      "for 2020-11-08, MAE is:2.72 & sMAPE is:7.67% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 15.11% & 0.92\n",
      "for 2020-11-09, MAE is:5.46 & sMAPE is:12.07% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 15.10% & 0.92\n",
      "for 2020-11-10, MAE is:4.17 & sMAPE is:8.61% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 15.08% & 0.92\n",
      "for 2020-11-11, MAE is:5.67 & sMAPE is:12.45% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 15.07% & 0.92\n",
      "for 2020-11-12, MAE is:5.55 & sMAPE is:13.40% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 15.07% & 0.92\n",
      "for 2020-11-13, MAE is:4.84 & sMAPE is:11.62% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 15.06% & 0.91\n",
      "for 2020-11-14, MAE is:4.62 & sMAPE is:12.47% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 15.05% & 0.91\n",
      "for 2020-11-15, MAE is:8.68 & sMAPE is:38.96% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 15.12% & 0.91\n",
      "for 2020-11-16, MAE is:4.83 & sMAPE is:12.40% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 15.11% & 0.92\n",
      "for 2020-11-17, MAE is:2.70 & sMAPE is:5.93% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 15.09% & 0.91\n",
      "for 2020-11-18, MAE is:3.62 & sMAPE is:8.60% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 15.07% & 0.91\n",
      "for 2020-11-19, MAE is:6.38 & sMAPE is:15.40% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 15.07% & 0.91\n",
      "for 2020-11-20, MAE is:2.72 & sMAPE is:6.82% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 15.04% & 0.91\n",
      "for 2020-11-21, MAE is:4.32 & sMAPE is:10.81% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 15.03% & 0.91\n",
      "for 2020-11-22, MAE is:3.08 & sMAPE is:7.27% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 15.01% & 0.91\n",
      "for 2020-11-23, MAE is:3.33 & sMAPE is:6.49% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 14.98% & 0.91\n",
      "for 2020-11-24, MAE is:4.27 & sMAPE is:9.28% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 14.96% & 0.91\n",
      "for 2020-11-25, MAE is:5.91 & sMAPE is:12.57% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 14.95% & 0.91\n",
      "for 2020-11-26, MAE is:4.77 & sMAPE is:10.97% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 14.94% & 0.91\n",
      "for 2020-11-27, MAE is:6.49 & sMAPE is:12.94% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.94% & 0.91\n",
      "for 2020-11-28, MAE is:3.32 & sMAPE is:6.82% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.91% & 0.91\n",
      "for 2020-11-29, MAE is:4.25 & sMAPE is:9.22% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.90% & 0.91\n",
      "for 2020-11-30, MAE is:3.97 & sMAPE is:7.76% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.87% & 0.91\n",
      "for 2020-12-01, MAE is:3.19 & sMAPE is:6.33% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 14.85% & 0.91\n",
      "for 2020-12-02, MAE is:4.21 & sMAPE is:8.69% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 14.83% & 0.91\n",
      "for 2020-12-03, MAE is:7.81 & sMAPE is:15.08% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.83% & 0.91\n",
      "for 2020-12-04, MAE is:3.16 & sMAPE is:7.82% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.81% & 0.91\n",
      "for 2020-12-05, MAE is:3.10 & sMAPE is:7.19% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.79% & 0.91\n",
      "for 2020-12-06, MAE is:5.13 & sMAPE is:12.32% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.78% & 0.91\n",
      "for 2020-12-07, MAE is:6.69 & sMAPE is:16.05% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 14.78% & 0.91\n",
      "for 2020-12-08, MAE is:9.46 & sMAPE is:54.61% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 14.90% & 0.91\n",
      "for 2020-12-09, MAE is:5.86 & sMAPE is:14.55% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 14.90% & 0.91\n",
      "for 2020-12-10, MAE is:1.89 & sMAPE is:4.55% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 14.87% & 0.91\n",
      "for 2020-12-11, MAE is:6.49 & sMAPE is:17.34% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 14.88% & 0.91\n",
      "for 2020-12-12, MAE is:4.94 & sMAPE is:14.40% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 14.88% & 0.91\n",
      "for 2020-12-13, MAE is:3.38 & sMAPE is:7.75% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 14.85% & 0.91\n",
      "for 2020-12-14, MAE is:4.33 & sMAPE is:10.28% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 14.84% & 0.90\n",
      "for 2020-12-15, MAE is:10.45 & sMAPE is:24.46% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 14.87% & 0.90\n",
      "for 2020-12-16, MAE is:5.37 & sMAPE is:11.04% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 14.86% & 0.90\n",
      "for 2020-12-17, MAE is:5.50 & sMAPE is:9.73% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 14.84% & 0.90\n",
      "for 2020-12-18, MAE is:4.39 & sMAPE is:9.19% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 14.83% & 0.90\n",
      "for 2020-12-19, MAE is:7.04 & sMAPE is:16.21% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 14.83% & 0.90\n",
      "for 2020-12-20, MAE is:4.13 & sMAPE is:9.62% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 14.82% & 0.90\n",
      "for 2020-12-21, MAE is:3.20 & sMAPE is:7.84% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 14.80% & 0.91\n",
      "for 2020-12-22, MAE is:2.50 & sMAPE is:5.42% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 14.77% & 0.90\n",
      "for 2020-12-23, MAE is:2.86 & sMAPE is:6.46% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 14.75% & 0.90\n",
      "for 2020-12-24, MAE is:6.58 & sMAPE is:15.67% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 14.75% & 0.90\n",
      "for 2020-12-25, MAE is:12.18 & sMAPE is:66.34% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 14.89% & 0.90\n",
      "for 2020-12-26, MAE is:5.35 & sMAPE is:16.23% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.41 & 14.90% & 0.90\n",
      "for 2020-12-27, MAE is:15.25 & sMAPE is:46.31% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 14.98% & 0.90\n",
      "for 2020-12-28, MAE is:13.19 & sMAPE is:70.05% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 15.14% & 0.90\n",
      "for 2020-12-29, MAE is:5.80 & sMAPE is:16.77% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 15.14% & 0.90\n",
      "for 2020-12-30, MAE is:5.69 & sMAPE is:12.39% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 15.13% & 0.90\n",
      "for 2020-12-31, MAE is:3.71 & sMAPE is:8.41% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 15.11% & 0.90\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:26:04,706]\u001b[0m A new study created in RDB with name: ES_2021\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:26:28,168]\u001b[0m Trial 2 finished with value: 7.254399223301074 and parameters: {'n_hidden': 4, 'learning_rate': 0.03379642088503727, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3767695560302619, 'dropout_rate_Layer_2': 0.2890903019896071, 'dropout_rate_Layer_3': 0.3220519328049977, 'dropout_rate_Layer_4': 0.026443605002068306, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0006421242308699898, 'l1_Layer_2': 2.090242576171393e-05, 'l1_Layer_3': 1.4803661455462642e-05, 'l1_Layer_4': 0.00468639769117352, 'n_units_Layer_1': 195, 'n_units_Layer_2': 85, 'n_units_Layer_3': 195, 'n_units_Layer_4': 180}. Best is trial 2 with value: 7.254399223301074.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.25 | sMAPE for Validation Set is: 24.17% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 58.04 | sMAPE for Test Set is: 55.40% | rMAE for Test Set is: 2.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:26:29,883]\u001b[0m Trial 1 pruned. Trial was pruned at epoch 7.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:26:33,783]\u001b[0m Trial 3 finished with value: 4.230666098705352 and parameters: {'n_hidden': 4, 'learning_rate': 0.0038393827170707046, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1081740374721111, 'dropout_rate_Layer_2': 0.01831548604111193, 'dropout_rate_Layer_3': 0.11904538187650943, 'dropout_rate_Layer_4': 0.15362453640371365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.06914256941148228, 'l1_Layer_2': 0.0018028420715818058, 'l1_Layer_3': 0.011380132149944811, 'l1_Layer_4': 0.0010635751072230572, 'n_units_Layer_1': 115, 'n_units_Layer_2': 80, 'n_units_Layer_3': 70, 'n_units_Layer_4': 115}. Best is trial 3 with value: 4.230666098705352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 55.12 | sMAPE for Test Set is: 51.64% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:26:37,445]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:26:37,668]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 22.15% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 62.72 | sMAPE for Test Set is: 62.24% | rMAE for Test Set is: 2.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:26:39,654]\u001b[0m Trial 0 finished with value: 6.531691403136612 and parameters: {'n_hidden': 3, 'learning_rate': 0.0064132001759237625, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3120282083846102, 'dropout_rate_Layer_2': 0.3104856106302253, 'dropout_rate_Layer_3': 0.1925687865415994, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01487334741561497, 'l1_Layer_2': 0.002089284044992833, 'l1_Layer_3': 0.0033480243908472966, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 180}. Best is trial 3 with value: 4.230666098705352.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:26:39,683]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:26:48,198]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:26:53,777]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:26:57,039]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:00,399]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:06,306]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:09,035]\u001b[0m Trial 8 finished with value: 5.132702440374297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006734692790989812, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06752651807949164, 'dropout_rate_Layer_2': 0.27999108516361326, 'dropout_rate_Layer_3': 0.015604230257473973, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016722154837212113, 'l1_Layer_2': 5.380697359309934e-05, 'l1_Layer_3': 0.00036236976417474564, 'n_units_Layer_1': 250, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125}. Best is trial 3 with value: 4.230666098705352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 17.96% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 53.93 | sMAPE for Test Set is: 50.20% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:27:16,642]\u001b[0m Trial 12 finished with value: 5.498610850190718 and parameters: {'n_hidden': 3, 'learning_rate': 0.0326479713313349, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31475817833853176, 'dropout_rate_Layer_2': 0.28701718635838697, 'dropout_rate_Layer_3': 0.2540404699916056, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018692886373334217, 'l1_Layer_2': 0.012295365192906492, 'l1_Layer_3': 0.008789082106626628, 'n_units_Layer_1': 100, 'n_units_Layer_2': 145, 'n_units_Layer_3': 100}. Best is trial 3 with value: 4.230666098705352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 57.15 | sMAPE for Test Set is: 54.49% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:27:21,585]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:21,836]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:25,713]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:29,275]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:29,605]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:34,282]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:34,925]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:39,876]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:40,252]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.17 | sMAPE for Validation Set is: 15.20% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.45 | sMAPE for Test Set is: 47.00% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:27:44,747]\u001b[0m Trial 7 finished with value: 4.16712409386036 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034690599817579905, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29011640097770863, 'dropout_rate_Layer_2': 0.007599355881323211, 'dropout_rate_Layer_3': 0.11045763051860012, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001776467093596079, 'l1_Layer_2': 1.8677950609198415e-05, 'l1_Layer_3': 0.0013505208638345788, 'n_units_Layer_1': 160, 'n_units_Layer_2': 165, 'n_units_Layer_3': 80}. Best is trial 7 with value: 4.16712409386036.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:48,281]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:50,051]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:53,673]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:55,923]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:27:59,130]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:02,592]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:06,404]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:10,451]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:22,715]\u001b[0m Trial 20 finished with value: 4.846095520150584 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007527915778587996, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28418686264051507, 'dropout_rate_Layer_2': 0.020227125928197157, 'dropout_rate_Layer_3': 0.07403061273573312, 'dropout_rate_Layer_4': 0.03441100302319327, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.491414327596402e-05, 'l1_Layer_2': 0.03781008398869461, 'l1_Layer_3': 0.052032820454976515, 'l1_Layer_4': 0.00041134548467270727, 'n_units_Layer_1': 155, 'n_units_Layer_2': 155, 'n_units_Layer_3': 95, 'n_units_Layer_4': 70}. Best is trial 7 with value: 4.16712409386036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 50.43 | sMAPE for Test Set is: 46.27% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:28:28,063]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:32,649]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:36,966]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:40,090]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:44,244]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:44,323]\u001b[0m Trial 33 finished with value: 5.221694594773574 and parameters: {'n_hidden': 4, 'learning_rate': 0.011559519245080812, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17821963987866535, 'dropout_rate_Layer_2': 0.10576952946491716, 'dropout_rate_Layer_3': 0.2558595369084397, 'dropout_rate_Layer_4': 0.08059313520616547, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.77732482910442e-05, 'l1_Layer_2': 2.677916408960957e-05, 'l1_Layer_3': 0.00027209171305658526, 'l1_Layer_4': 2.8170440102962015e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 195, 'n_units_Layer_3': 95, 'n_units_Layer_4': 200}. Best is trial 7 with value: 4.16712409386036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 28.60 | sMAPE for Test Set is: 28.65% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:28:47,204]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:47,407]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:51,616]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:51,753]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:52,381]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:52,620]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:56,850]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:28:59,341]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:04,471]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:07,753]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:11,975]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:12,517]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:13,555]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:21,756]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:23,224]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:27,736]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:28,508]\u001b[0m Trial 47 finished with value: 4.892231553873755 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014798391775860122, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2545108852672031, 'dropout_rate_Layer_2': 0.069095911031396, 'dropout_rate_Layer_3': 0.16631275588695238, 'dropout_rate_Layer_4': 0.25547927784591706, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004393821650140979, 'l1_Layer_2': 0.00032504041306184744, 'l1_Layer_3': 0.05574010901522584, 'l1_Layer_4': 0.011123707723393472, 'n_units_Layer_1': 75, 'n_units_Layer_2': 245, 'n_units_Layer_3': 85, 'n_units_Layer_4': 235}. Best is trial 7 with value: 4.16712409386036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 55.71 | sMAPE for Test Set is: 52.52% | rMAE for Test Set is: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:29:33,602]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:37,540]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:42,461]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:47,248]\u001b[0m Trial 59 finished with value: 5.197494545815272 and parameters: {'n_hidden': 3, 'learning_rate': 0.003207558567003179, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03985232298850155, 'dropout_rate_Layer_2': 0.11045419353649577, 'dropout_rate_Layer_3': 0.19221996679051442, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0012031479587439498, 'l1_Layer_2': 2.5409163030510038e-05, 'l1_Layer_3': 0.027930027067474546, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 175}. Best is trial 7 with value: 4.16712409386036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 18.54% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 56.94 | sMAPE for Test Set is: 54.08% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:29:49,092]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:53,798]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:54,181]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:56,544]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:29:58,269]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:02,385]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:06,546]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:08,839]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:11,443]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:16,407]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:19,246]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:19,858]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:24,511]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:26,691]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:27,655]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:30,713]\u001b[0m Trial 69 finished with value: 4.873337349479908 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022422865046893416, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2809443401807619, 'dropout_rate_Layer_2': 0.0017720295795859292, 'dropout_rate_Layer_3': 0.18953879380759855, 'dropout_rate_Layer_4': 0.29174532830791783, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006214108406461683, 'l1_Layer_2': 8.563918626046813e-05, 'l1_Layer_3': 0.03326452976494153, 'l1_Layer_4': 0.0026100095338548427, 'n_units_Layer_1': 80, 'n_units_Layer_2': 195, 'n_units_Layer_3': 70, 'n_units_Layer_4': 265}. Best is trial 7 with value: 4.16712409386036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 17.13% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 57.18 | sMAPE for Test Set is: 54.53% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:30:33,584]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:33,969]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:34,370]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:37,963]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:43,851]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:44,172]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:44,403]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:48,803]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:52,842]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:52,964]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:53,199]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:30:53,548]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:00,634]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:01,460]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:02,730]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:02,874]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:04,017]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:13,766]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:13,909]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:19,386]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:21,616]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:23,306]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:23,861]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:28,227]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:30,811]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:32,992]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:34,897]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:37,729]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:40,062]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:43,019]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:43,391]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:45,661]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:51,455]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:53,895]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:56,407]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:59,751]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:31:59,905]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:00,097]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:05,850]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:06,058]\u001b[0m Trial 111 finished with value: 4.650622195462551 and parameters: {'n_hidden': 3, 'learning_rate': 0.004460326059091483, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034851911646864145, 'dropout_rate_Layer_2': 0.07848450764541641, 'dropout_rate_Layer_3': 0.18216340019436178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04149259207323811, 'l1_Layer_2': 0.0035218567949475885, 'l1_Layer_3': 0.03903362450253061, 'n_units_Layer_1': 195, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300}. Best is trial 7 with value: 4.16712409386036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 16.48% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 16.03 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:32:06,352]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:06,689]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:16,546]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:20,083]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:20,377]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:27,671]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:30,962]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:34,921]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:35,160]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:35,401]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:42,949]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:44,838]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:45,168]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:46,248]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:51,545]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:32:56,411]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:02,464]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:07,926]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:07,969]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:14,980]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:15,393]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:18,790]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:24,179]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:24,607]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:29,236]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:31,656]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:31,787]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:32,094]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:38,842]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:44,728]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:44,995]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:47,541]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:52,511]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:53,208]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:54,956]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:58,134]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:33:59,564]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:01,747]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:02,564]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:09,931]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:10,085]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:16,445]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:16,619]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:23,023]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:23,440]\u001b[0m Trial 155 finished with value: 5.643937292674569 and parameters: {'n_hidden': 3, 'learning_rate': 0.007119123582848273, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006224620910176656, 'dropout_rate_Layer_2': 0.04256861172016553, 'dropout_rate_Layer_3': 0.0676828245824179, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022401582453793558, 'l1_Layer_2': 0.00047172823683958926, 'l1_Layer_3': 0.00920586698914879, 'n_units_Layer_1': 50, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300}. Best is trial 7 with value: 4.16712409386036.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 19.65% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 57.05 | sMAPE for Test Set is: 54.15% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:34:23,982]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:31,278]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:32,604]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:34,289]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:36,209]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.91 | sMAPE for Test Set is: 56.42% | rMAE for Test Set is: 2.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:34:39,332]\u001b[0m Trial 161 finished with value: 4.1202804269564846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0073724004402492445, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1071709733862796, 'dropout_rate_Layer_2': 0.04778455641919065, 'dropout_rate_Layer_3': 0.06853110080675559, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002511600342537816, 'l1_Layer_2': 0.00044109186401424156, 'l1_Layer_3': 0.0025106415917111793, 'n_units_Layer_1': 75, 'n_units_Layer_2': 220, 'n_units_Layer_3': 300}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:40,366]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:42,349]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:47,476]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:50,009]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:52,136]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:52,934]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:34:56,747]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:00,587]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:02,412]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:05,871]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:09,573]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:10,043]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:16,111]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:16,539]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:21,684]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:24,644]\u001b[0m Trial 175 finished with value: 4.368439517773847 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013898201582977574, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25776866983302027, 'dropout_rate_Layer_2': 0.3826074567729614, 'dropout_rate_Layer_3': 0.3238414431120916, 'dropout_rate_Layer_4': 0.15759525127601962, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009696945047696153, 'l1_Layer_2': 2.2142317673543452e-05, 'l1_Layer_3': 0.00020945174063305362, 'l1_Layer_4': 0.09742122015853896, 'n_units_Layer_1': 295, 'n_units_Layer_2': 220, 'n_units_Layer_3': 95, 'n_units_Layer_4': 55}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 15.36% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 56.52 | sMAPE for Test Set is: 53.58% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:35:28,575]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:28,955]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:33,694]\u001b[0m Trial 179 finished with value: 4.209762825997427 and parameters: {'n_hidden': 3, 'learning_rate': 0.010145265045386284, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1031554838787081, 'dropout_rate_Layer_2': 0.008398386449745103, 'dropout_rate_Layer_3': 0.014332918718293328, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012879103230397634, 'l1_Layer_2': 0.00036044496838478357, 'l1_Layer_3': 0.0008591168936324564, 'n_units_Layer_1': 70, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 15.03% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 54.68 | sMAPE for Test Set is: 50.59% | rMAE for Test Set is: 2.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:35:36,966]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:37,566]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:38,223]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:43,819]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:47,728]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:49,194]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:52,364]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:35:55,559]\u001b[0m Trial 183 finished with value: 4.220559500766885 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017693847283001933, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32350744040467033, 'dropout_rate_Layer_2': 0.06634707942602366, 'dropout_rate_Layer_3': 0.08617545747432694, 'dropout_rate_Layer_4': 0.20509885182901463, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00015697315547852594, 'l1_Layer_2': 0.00014771077659754846, 'l1_Layer_3': 0.001125261323940207, 'l1_Layer_4': 0.00014575530170921665, 'n_units_Layer_1': 175, 'n_units_Layer_2': 190, 'n_units_Layer_3': 70, 'n_units_Layer_4': 125}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 48.87 | sMAPE for Test Set is: 44.40% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:35:58,404]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:00,097]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:01,026]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:01,990]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:03,677]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:06,938]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:11,579]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:15,856]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:19,456]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:34,856]\u001b[0m Trial 202 finished with value: 4.277449055902363 and parameters: {'n_hidden': 3, 'learning_rate': 0.004785390985383034, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0007907012988008499, 'dropout_rate_Layer_2': 0.062277716027231214, 'dropout_rate_Layer_3': 0.1465053040447362, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017172184447590763, 'l1_Layer_2': 0.0006653585897560152, 'l1_Layer_3': 0.005787459211843655, 'n_units_Layer_1': 75, 'n_units_Layer_2': 235, 'n_units_Layer_3': 300}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 52.90 | sMAPE for Test Set is: 49.09% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:36:37,947]\u001b[0m Trial 200 finished with value: 4.432010996786665 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013958760837825845, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25849655774797886, 'dropout_rate_Layer_2': 0.38057539396586015, 'dropout_rate_Layer_3': 0.2845289354795302, 'dropout_rate_Layer_4': 0.14722799078934562, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.010133569987941111, 'l1_Layer_2': 2.0699667102547264e-05, 'l1_Layer_3': 0.00021170067450282753, 'l1_Layer_4': 0.07941603221479893, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 95, 'n_units_Layer_4': 50}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 15.82% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 55.94 | sMAPE for Test Set is: 52.98% | rMAE for Test Set is: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:36:40,804]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:41,403]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:45,741]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:48,897]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:51,704]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:53,642]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:36:57,949]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:03,073]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:08,377]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:08,737]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:13,491]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:14,054]\u001b[0m Trial 206 finished with value: 4.339025314117651 and parameters: {'n_hidden': 3, 'learning_rate': 0.002385445932617497, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10571651300085035, 'dropout_rate_Layer_2': 0.04001358304813431, 'dropout_rate_Layer_3': 0.08606441708734534, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020180070101254985, 'l1_Layer_2': 0.0001297479607517812, 'l1_Layer_3': 0.019440805146038603, 'n_units_Layer_1': 105, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 15.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 45.95 | sMAPE for Test Set is: 41.44% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:37:14,320]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:21,619]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:24,871]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:25,138]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:29,179]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:31,005]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:32,519]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:35,848]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:38,690]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:38,887]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:39,796]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:45,559]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:46,028]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:51,143]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:51,358]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:56,483]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:37:56,655]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:02,281]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:02,743]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:07,285]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:09,724]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:10,286]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:14,930]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 15.08% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 47.37 | sMAPE for Test Set is: 42.87% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:38:17,088]\u001b[0m Trial 231 finished with value: 4.286977007506397 and parameters: {'n_hidden': 3, 'learning_rate': 0.005350520964456153, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03790129705004477, 'dropout_rate_Layer_2': 0.03149572798830898, 'dropout_rate_Layer_3': 0.1201981082127652, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.049643036021603845, 'l1_Layer_2': 0.0004539070929235857, 'l1_Layer_3': 0.012468393500751683, 'n_units_Layer_1': 75, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:17,931]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:24,745]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:27,419]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:27,616]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:32,326]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:32,813]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:33,085]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:38,175]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:41,586]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:41,866]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:45,996]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:48,951]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:49,509]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:49,792]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:56,535]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:57,121]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:38:58,846]\u001b[0m Trial 245 finished with value: 4.18253505294148 and parameters: {'n_hidden': 4, 'learning_rate': 0.001348514433690701, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.343278693302823, 'dropout_rate_Layer_2': 0.061083151258204384, 'dropout_rate_Layer_3': 0.044005713850305606, 'dropout_rate_Layer_4': 0.00311851603347853, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00011362785439012049, 'l1_Layer_2': 0.0005124160745486594, 'l1_Layer_3': 1.3878366097064098e-05, 'l1_Layer_4': 3.1322459519461324e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 135, 'n_units_Layer_3': 80, 'n_units_Layer_4': 300}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 48.40 | sMAPE for Test Set is: 43.89% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:39:02,596]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:02,890]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:06,241]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:11,628]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:12,223]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:16,223]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:17,192]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:21,309]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:22,911]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:27,408]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:35,137]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:38,236]\u001b[0m Trial 266 finished with value: 4.975181724845864 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012545710667473697, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31695883619644305, 'dropout_rate_Layer_2': 0.3624626720904102, 'dropout_rate_Layer_3': 0.3599358544808101, 'dropout_rate_Layer_4': 0.10863255120857147, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.044490529198202136, 'l1_Layer_2': 1.0148220458171678e-05, 'l1_Layer_3': 6.76533323478373e-05, 'l1_Layer_4': 0.00939984639806891, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 50, 'n_units_Layer_4': 60}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 17.56% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 50.35 | sMAPE for Test Set is: 46.30% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:39:39,641]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:43,501]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:45,953]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:49,132]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:50,790]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:51,638]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:53,215]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:56,324]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:39:57,984]\u001b[0m Trial 263 finished with value: 5.445763888049147 and parameters: {'n_hidden': 4, 'learning_rate': 0.022692067137537193, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2400976471450934, 'dropout_rate_Layer_2': 0.0516269164335988, 'dropout_rate_Layer_3': 0.1639343907934158, 'dropout_rate_Layer_4': 0.35951658811327425, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0031023645052343785, 'l1_Layer_2': 0.00016209048760042178, 'l1_Layer_3': 0.006263490093293259, 'l1_Layer_4': 0.0001259781084102398, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 75, 'n_units_Layer_4': 230}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 18.92% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 54.31 | sMAPE for Test Set is: 50.71% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:39:58,163]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:02,877]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:04,976]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:05,448]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:07,711]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:09,347]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:14,304]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:16,350]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:16,971]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:17,472]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:19,751]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:24,633]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:25,076]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:25,969]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:30,641]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:32,333]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:35,219]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:35,540]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:41,552]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:44,737]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:48,557]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:51,545]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:54,770]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:40:58,603]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:06,255]\u001b[0m Trial 296 finished with value: 4.37327881016107 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007965376406550775, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28379967720268295, 'dropout_rate_Layer_2': 0.3640636601659787, 'dropout_rate_Layer_3': 0.2811532184697263, 'dropout_rate_Layer_4': 0.03062078010618942, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.016206088307879164, 'l1_Layer_2': 1.9703651031815823e-05, 'l1_Layer_3': 0.0004595308535826094, 'l1_Layer_4': 0.03287258696853186, 'n_units_Layer_1': 270, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145, 'n_units_Layer_4': 85}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.37 | sMAPE for Validation Set is: 15.38% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 50.86 | sMAPE for Test Set is: 46.86% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:41:09,565]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:09,602]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:15,956]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:16,208]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:22,355]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:22,561]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:23,174]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:27,789]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:29,784]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:30,505]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:32,833]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:37,006]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:37,942]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:41,801]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:43,942]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:47,385]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:49,216]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:50,733]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:51,352]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:41:56,608]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:00,054]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:00,932]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:01,782]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:08,333]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:08,529]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:08,692]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:15,844]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:19,242]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:23,594]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:23,745]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:28,653]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:28,878]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:34,336]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:36,988]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:37,747]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:40,062]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:42,793]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:46,351]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:47,293]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:48,606]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:52,289]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:54,913]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:57,162]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:42:57,405]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:03,114]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:03,826]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:06,552]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:09,980]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:10,921]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:13,250]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:16,576]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:16,589]\u001b[0m Trial 346 finished with value: 4.8449124786703255 and parameters: {'n_hidden': 3, 'learning_rate': 0.004779416282442912, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06722244910040759, 'dropout_rate_Layer_2': 0.08334745555735289, 'dropout_rate_Layer_3': 0.09176309616163586, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.812460940980995e-05, 'l1_Layer_2': 0.0009821308097440206, 'l1_Layer_3': 0.04628409581250733, 'n_units_Layer_1': 75, 'n_units_Layer_2': 170, 'n_units_Layer_3': 65}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 16.88% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 59.80 | sMAPE for Test Set is: 57.72% | rMAE for Test Set is: 2.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:43:18,156]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:20,605]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:21,789]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:23,294]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:23,980]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:28,709]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:31,619]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:33,831]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:35,189]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:40,991]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:43,142]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:45,494]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:46,414]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:46,858]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:49,270]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:54,336]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:56,099]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:43:59,909]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:02,802]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:04,734]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:10,955]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:11,522]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:16,068]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:17,756]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:21,409]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:30,988]\u001b[0m Trial 371 finished with value: 4.681203737818984 and parameters: {'n_hidden': 4, 'learning_rate': 0.00983215910066867, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24152697178028537, 'dropout_rate_Layer_2': 0.00040917584563714485, 'dropout_rate_Layer_3': 0.2314489366958103, 'dropout_rate_Layer_4': 0.11388283485757528, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012078869062632865, 'l1_Layer_2': 5.9678325056246385e-05, 'l1_Layer_3': 0.0007581441718581046, 'l1_Layer_4': 0.000846782201417023, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 80, 'n_units_Layer_4': 220}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 80.05 | sMAPE for Test Set is: 90.67% | rMAE for Test Set is: 3.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:44:35,833]\u001b[0m Trial 383 finished with value: 4.345941591487787 and parameters: {'n_hidden': 3, 'learning_rate': 0.006847867259731608, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08590729843283175, 'dropout_rate_Layer_2': 0.040420463777428875, 'dropout_rate_Layer_3': 0.08726313683134641, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.6254804173381154e-05, 'l1_Layer_2': 0.000776520483810842, 'l1_Layer_3': 0.004913370222194598, 'n_units_Layer_1': 85, 'n_units_Layer_2': 165, 'n_units_Layer_3': 50}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 16.06% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 57.77 | sMAPE for Test Set is: 54.92% | rMAE for Test Set is: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:44:36,407]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:40,922]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:43,224]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:46,822]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:46,866]\u001b[0m Trial 382 finished with value: 5.1520120859677405 and parameters: {'n_hidden': 4, 'learning_rate': 0.010458866023232385, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23193908313793538, 'dropout_rate_Layer_2': 0.05022750024269339, 'dropout_rate_Layer_3': 0.22538609444346983, 'dropout_rate_Layer_4': 0.11486327051213559, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001211699614756605, 'l1_Layer_2': 0.000258603246845951, 'l1_Layer_3': 0.000655306128712658, 'l1_Layer_4': 0.0005846227464624028, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 80, 'n_units_Layer_4': 215}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 54.35 | sMAPE for Test Set is: 50.63% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:44:47,324]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:54,080]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:56,234]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:44:59,682]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:02,992]\u001b[0m Trial 384 finished with value: 4.381841577451984 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021103562887257463, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39370691374595124, 'dropout_rate_Layer_2': 0.039166095172483525, 'dropout_rate_Layer_3': 0.1493487013791816, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001599748191792182, 'l1_Layer_2': 8.723466148176422e-05, 'l1_Layer_3': 0.016886423594036627, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85}. Best is trial 161 with value: 4.1202804269564846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 15.63% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 53.15 | sMAPE for Test Set is: 49.37% | rMAE for Test Set is: 2.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:45:05,495]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:11,005]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:13,497]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:16,061]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:16,200]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:22,717]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:22,844]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:29,530]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:34,566]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:34,582]\u001b[0m Trial 399 finished with value: 3.7690314564930696 and parameters: {'n_hidden': 3, 'learning_rate': 0.007699876525080005, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06029075577209461, 'dropout_rate_Layer_2': 0.011162864907541703, 'dropout_rate_Layer_3': 0.10026402416073726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.6268701932432125e-05, 'l1_Layer_2': 0.0018546772830761945, 'l1_Layer_3': 0.0029264459259759545, 'n_units_Layer_1': 190, 'n_units_Layer_2': 170, 'n_units_Layer_3': 50}. Best is trial 399 with value: 3.7690314564930696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 13.08% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 15.48 | sMAPE for Test Set is: 19.67% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:45:34,850]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:41,492]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:41,706]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:48,104]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:48,592]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:54,281]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:45:57,003]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:46:02,630]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:46:14,658]\u001b[0m Trial 413 finished with value: 3.745433585575696 and parameters: {'n_hidden': 3, 'learning_rate': 0.004182968339150945, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05925300850143495, 'dropout_rate_Layer_2': 0.026109105623013187, 'dropout_rate_Layer_3': 0.0745446299302513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7896249759417902e-05, 'l1_Layer_2': 0.0010082221073875422, 'l1_Layer_3': 0.003929948193511062, 'n_units_Layer_1': 275, 'n_units_Layer_2': 165, 'n_units_Layer_3': 70}. Best is trial 413 with value: 3.745433585575696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 13.05% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.34 | sMAPE for Test Set is: 18.60% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:46:20,954]\u001b[0m Trial 394 finished with value: 5.085610672787261 and parameters: {'n_hidden': 4, 'learning_rate': 0.008434781600482388, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15979338133491236, 'dropout_rate_Layer_2': 0.013023065504033426, 'dropout_rate_Layer_3': 0.23764443605896035, 'dropout_rate_Layer_4': 0.08318718620564003, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.513688663294953e-05, 'l1_Layer_2': 4.425487701410658e-05, 'l1_Layer_3': 0.0005604042324096791, 'l1_Layer_4': 0.0013488912219524194, 'n_units_Layer_1': 80, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150, 'n_units_Layer_4': 190}. Best is trial 413 with value: 3.745433585575696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 19.55% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 52.72 | sMAPE for Test Set is: 50.34% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:46:32,806]\u001b[0m Trial 414 finished with value: 3.673414942031672 and parameters: {'n_hidden': 3, 'learning_rate': 0.004095372093465475, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.057343343627772596, 'dropout_rate_Layer_2': 0.025258067057613395, 'dropout_rate_Layer_3': 0.09431881241267587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.606855890863076e-05, 'l1_Layer_2': 0.0028687682082460956, 'l1_Layer_3': 0.0017839163733099413, 'n_units_Layer_1': 190, 'n_units_Layer_2': 165, 'n_units_Layer_3': 60}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 15.60 | sMAPE for Test Set is: 19.61% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:46:39,034]\u001b[0m Trial 415 finished with value: 4.011473535738726 and parameters: {'n_hidden': 3, 'learning_rate': 0.001621527693157058, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3667748606690939, 'dropout_rate_Layer_2': 0.0601031729208555, 'dropout_rate_Layer_3': 0.16261032214734658, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015252218667840287, 'l1_Layer_2': 3.8155842527297864e-05, 'l1_Layer_3': 0.001105832367861633, 'n_units_Layer_1': 200, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 48.62 | sMAPE for Test Set is: 44.17% | rMAE for Test Set is: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:46:42,292]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:46:45,177]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:46:50,323]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:46:57,356]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:46:59,365]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:47:03,376]\u001b[0m Trial 419 finished with value: 3.7890167712822147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041365900411200595, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0599941395152946, 'dropout_rate_Layer_2': 0.027799425787340376, 'dropout_rate_Layer_3': 0.09295715330715176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.494897572880928e-05, 'l1_Layer_2': 0.004358346290157844, 'l1_Layer_3': 0.0015590813341026537, 'n_units_Layer_1': 260, 'n_units_Layer_2': 150, 'n_units_Layer_3': 60}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 13.12% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.84 | sMAPE for Test Set is: 19.13% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:47:08,626]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:47:09,736]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:47:13,808]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:47:16,426]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:47:18,499]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:47:19,169]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:47:26,899]\u001b[0m Trial 422 finished with value: 4.206273847874824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017153721656197381, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.372686797009227, 'dropout_rate_Layer_2': 0.05813398811121025, 'dropout_rate_Layer_3': 0.16580751335950397, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012025528680103372, 'l1_Layer_2': 3.865814377864368e-05, 'l1_Layer_3': 0.00981674614219778, 'n_units_Layer_1': 210, 'n_units_Layer_2': 195, 'n_units_Layer_3': 70}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.21 | sMAPE for Validation Set is: 15.01% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.71 | sMAPE for Test Set is: 47.56% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:47:30,727]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:47:34,289]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:47:38,076]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:47:42,099]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:47:54,323]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:01,982]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:02,206]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:04,360]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:06,907]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:09,559]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:13,485]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:14,218]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:14,504]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:20,335]\u001b[0m Trial 436 finished with value: 4.123006848976804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015791062883678743, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3762881046368112, 'dropout_rate_Layer_2': 0.07197897423345782, 'dropout_rate_Layer_3': 0.16641671384671253, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011519480173203369, 'l1_Layer_2': 2.7716696142700604e-05, 'l1_Layer_3': 0.009552890715503843, 'n_units_Layer_1': 205, 'n_units_Layer_2': 190, 'n_units_Layer_3': 90}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 14.79% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.22 | sMAPE for Test Set is: 48.19% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:48:21,073]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:22,101]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:23,718]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:26,888]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:28,682]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:30,526]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:37,301]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:38,017]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:42,455]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:42,575]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:43,068]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:49,024]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:51,052]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:52,504]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:54,878]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:48:57,443]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:01,652]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:04,997]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:05,176]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:05,835]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:13,618]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:13,830]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:14,170]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:19,438]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:23,750]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:26,582]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:26,674]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:27,692]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:33,992]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:36,194]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:41,888]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:44,568]\u001b[0m Trial 466 finished with value: 4.540270863115068 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017007899100488812, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37129240594418667, 'dropout_rate_Layer_2': 0.0018434772748451489, 'dropout_rate_Layer_3': 0.16857749603428474, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.301504082338737e-05, 'l1_Layer_2': 5.944995684653981e-05, 'l1_Layer_3': 0.011907084352694091, 'n_units_Layer_1': 190, 'n_units_Layer_2': 180, 'n_units_Layer_3': 65}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 16.16% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 53.97 | sMAPE for Test Set is: 50.35% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:49:46,586]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 59.55 | sMAPE for Test Set is: 57.66% | rMAE for Test Set is: 2.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:49:49,228]\u001b[0m Trial 471 finished with value: 5.191105222321265 and parameters: {'n_hidden': 4, 'learning_rate': 0.005103994995357121, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21330437168666455, 'dropout_rate_Layer_2': 0.15005687687276442, 'dropout_rate_Layer_3': 0.18992900908405766, 'dropout_rate_Layer_4': 0.1577929633164769, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.636405631692796e-05, 'l1_Layer_2': 2.7144167429674295e-05, 'l1_Layer_3': 0.0016323447764730245, 'l1_Layer_4': 0.0003254503722896099, 'n_units_Layer_1': 130, 'n_units_Layer_2': 220, 'n_units_Layer_3': 145, 'n_units_Layer_4': 255}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:51,167]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:54,827]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:58,131]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:49:58,593]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:00,193]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:03,019]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:04,096]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:06,174]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:09,564]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:10,130]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:13,079]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:13,845]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:19,532]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:20,037]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:20,320]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:26,229]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:26,960]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:27,017]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:33,478]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:38,598]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:40,843]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:42,753]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:47,056]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:50,253]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:52,561]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:55,634]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:50:55,765]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:01,000]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:01,195]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:07,294]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:09,845]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:14,734]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:16,440]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:20,100]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:20,458]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:25,585]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:28,770]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:33,814]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:37,655]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:40,834]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:44,187]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:48,558]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:51,588]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:55,039]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:51:58,321]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:01,590]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:05,905]\u001b[0m Trial 521 finished with value: 4.432179778658247 and parameters: {'n_hidden': 3, 'learning_rate': 0.013668804834601428, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07087191266606385, 'dropout_rate_Layer_2': 0.037364155903409316, 'dropout_rate_Layer_3': 0.0943627056357256, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014234126971756406, 'l1_Layer_2': 0.0004596137188073383, 'l1_Layer_3': 0.0026445111120673623, 'n_units_Layer_1': 125, 'n_units_Layer_2': 60, 'n_units_Layer_3': 55}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 56.00 | sMAPE for Test Set is: 52.34% | rMAE for Test Set is: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:52:06,455]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:06,590]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:13,635]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:14,120]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:19,824]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:29,110]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:29,921]\u001b[0m Trial 529 finished with value: 4.408970650167738 and parameters: {'n_hidden': 3, 'learning_rate': 0.014198907353148951, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0838782776222469, 'dropout_rate_Layer_2': 0.020670396050117567, 'dropout_rate_Layer_3': 0.0994426739449134, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009487309412829859, 'l1_Layer_2': 0.0004381874050142494, 'l1_Layer_3': 0.00510207512537174, 'n_units_Layer_1': 115, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.41 | sMAPE for Validation Set is: 15.49% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 57.92 | sMAPE for Test Set is: 54.83% | rMAE for Test Set is: 2.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:52:35,555]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:37,648]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:40,825]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:41,648]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:45,707]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:45,969]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:51,763]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:56,260]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:52:59,617]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:00,723]\u001b[0m Trial 530 finished with value: 4.610103183213272 and parameters: {'n_hidden': 4, 'learning_rate': 0.013550540412458144, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17786616697675417, 'dropout_rate_Layer_2': 0.0368963270965446, 'dropout_rate_Layer_3': 0.22668464976613967, 'dropout_rate_Layer_4': 0.10944415874931211, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014497020269965398, 'l1_Layer_2': 7.70777686669384e-05, 'l1_Layer_3': 0.0006719872362655646, 'l1_Layer_4': 0.0008220758216805903, 'n_units_Layer_1': 95, 'n_units_Layer_2': 155, 'n_units_Layer_3': 70, 'n_units_Layer_4': 215}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 16.15% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 67.53 | sMAPE for Test Set is: 68.43% | rMAE for Test Set is: 2.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:53:04,380]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:05,798]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:16,203]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:18,255]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:21,723]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:22,578]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:23,427]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:25,691]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:31,328]\u001b[0m Trial 540 finished with value: 4.50473202035509 and parameters: {'n_hidden': 4, 'learning_rate': 0.010802206775466977, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2569138067591327, 'dropout_rate_Layer_2': 0.033371759747916965, 'dropout_rate_Layer_3': 0.21756554553678062, 'dropout_rate_Layer_4': 0.11016825032027044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014743369235535922, 'l1_Layer_2': 7.5569090635543e-05, 'l1_Layer_3': 0.0007092359164201849, 'l1_Layer_4': 0.0005718296591101677, 'n_units_Layer_1': 90, 'n_units_Layer_2': 165, 'n_units_Layer_3': 65, 'n_units_Layer_4': 210}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 15.95% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 68.43 | sMAPE for Test Set is: 69.48% | rMAE for Test Set is: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:53:31,980]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:37,158]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:37,582]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:43,297]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:47,652]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:50,757]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:53,912]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:54,479]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:53:54,845]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:00,317]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:06,158]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:10,282]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:10,685]\u001b[0m Trial 553 finished with value: 6.502349577109462 and parameters: {'n_hidden': 4, 'learning_rate': 0.04743093339235491, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2661497845895705, 'dropout_rate_Layer_2': 0.027189097694067937, 'dropout_rate_Layer_3': 0.2790071589051867, 'dropout_rate_Layer_4': 0.12330214028857084, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00017279023980643578, 'l1_Layer_2': 7.643511005517782e-05, 'l1_Layer_3': 0.0003352873521328865, 'l1_Layer_4': 0.00025565474887534234, 'n_units_Layer_1': 165, 'n_units_Layer_2': 140, 'n_units_Layer_3': 65, 'n_units_Layer_4': 240}. Best is trial 414 with value: 3.673414942031672.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 21.98% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 57.57 | sMAPE for Test Set is: 55.06% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:54:13,461]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:18,930]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:21,479]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:24,485]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:25,163]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:28,240]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:29,504]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:29,716]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:36,031]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:37,910]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:38,774]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:41,539]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:47,142]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:47,592]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:47,840]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:54,195]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:55,878]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:54:58,174]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:01,258]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:06,334]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:08,310]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:11,510]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:14,113]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:16,360]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:17,073]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:22,151]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:22,483]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:24,968]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:29,621]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:30,040]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:30,249]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:37,473]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:37,565]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:37,677]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:37,782]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:47,242]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:47,676]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:50,238]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:52,529]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:53,836]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:55,726]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:56,233]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:55:58,866]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:03,238]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:05,313]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:06,182]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:08,502]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:16,576]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:16,644]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:18,294]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:22,753]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:25,030]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:27,764]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:31,266]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:31,595]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:35,964]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:39,026]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:39,750]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:44,654]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:47,774]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:48,581]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:48,656]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:53,954]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:56,378]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:57,475]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:56:58,653]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:05,874]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:06,815]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:10,721]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:12,315]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:15,040]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:17,820]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:21,186]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:21,306]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:26,886]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:32,588]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:36,193]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:39,514]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:42,541]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:42,931]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:47,813]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:49,954]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:54,326]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:55,857]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:57:57,539]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:00,675]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:04,391]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:04,560]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:10,007]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:12,246]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:13,527]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:16,187]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:19,910]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:58:22,489]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:23,498]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:24,546]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:29,858]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:32,446]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:34,349]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:37,690]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:39,842]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:43,926]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:47,277]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:47,879]\u001b[0m Trial 649 finished with value: 3.670767905049115 and parameters: {'n_hidden': 3, 'learning_rate': 0.004575226985151477, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08878545278895494, 'dropout_rate_Layer_2': 0.038135208228330476, 'dropout_rate_Layer_3': 0.09361435041941281, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.3682435712188924e-05, 'l1_Layer_2': 0.0019671326903007527, 'l1_Layer_3': 0.004575743724800305, 'n_units_Layer_1': 290, 'n_units_Layer_2': 165, 'n_units_Layer_3': 60}. Best is trial 649 with value: 3.670767905049115.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.34 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:58:48,005]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:54,853]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:58:55,096]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:59:00,668]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:59:04,038]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:59:09,769]\u001b[0m Trial 672 finished with value: 4.446327116518189 and parameters: {'n_hidden': 3, 'learning_rate': 0.005720796719834756, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2250460698693562, 'dropout_rate_Layer_2': 0.2246944005082561, 'dropout_rate_Layer_3': 0.13571314658475706, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08958088031719108, 'l1_Layer_2': 0.00047397529045642255, 'l1_Layer_3': 0.0009819378959644385, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 85}. Best is trial 649 with value: 3.670767905049115.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 15.82% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.13 | sMAPE for Test Set is: 41.92% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:59:12,502]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 18.91% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 64.19 | sMAPE for Test Set is: 64.15% | rMAE for Test Set is: 2.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:59:14,208]\u001b[0m Trial 666 finished with value: 5.195638164774399 and parameters: {'n_hidden': 4, 'learning_rate': 0.0060530801634530035, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0580911845043718, 'dropout_rate_Layer_2': 0.0028825556741309093, 'dropout_rate_Layer_3': 0.17429216849483664, 'dropout_rate_Layer_4': 0.043047428251282396, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.485013622739701e-05, 'l1_Layer_2': 6.212074069769276e-05, 'l1_Layer_3': 0.00010841049564444503, 'l1_Layer_4': 0.016318371376841175, 'n_units_Layer_1': 120, 'n_units_Layer_2': 175, 'n_units_Layer_3': 90, 'n_units_Layer_4': 200}. Best is trial 649 with value: 3.670767905049115.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:59:19,197]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:59:26,427]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:59:31,934]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:59:36,260]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:59:36,298]\u001b[0m Trial 674 finished with value: 5.154615081332852 and parameters: {'n_hidden': 4, 'learning_rate': 0.011634340400043084, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040356286145050824, 'dropout_rate_Layer_2': 0.0035773749657194154, 'dropout_rate_Layer_3': 0.17437524660605663, 'dropout_rate_Layer_4': 0.04303972601880078, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.545144162497905e-05, 'l1_Layer_2': 8.355039166703661e-05, 'l1_Layer_3': 0.00010557016357304586, 'l1_Layer_4': 0.0004747750420925604, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 60, 'n_units_Layer_4': 200}. Best is trial 649 with value: 3.670767905049115.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 17.96% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 63.84 | sMAPE for Test Set is: 62.54% | rMAE for Test Set is: 2.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:59:37,387]\u001b[0m Trial 675 finished with value: 3.669122592900346 and parameters: {'n_hidden': 3, 'learning_rate': 0.003489716276136975, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10154133463338244, 'dropout_rate_Layer_2': 0.04067156075323492, 'dropout_rate_Layer_3': 0.08957622711693815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9793415670387495e-05, 'l1_Layer_2': 0.003155976250080296, 'l1_Layer_3': 0.005006099391178373, 'n_units_Layer_1': 280, 'n_units_Layer_2': 165, 'n_units_Layer_3': 65}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 12.84% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.10 | sMAPE for Test Set is: 18.58% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:59:45,534]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:59:48,882]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:59:53,157]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 04:59:54,189]\u001b[0m Trial 680 finished with value: 3.8350793245022445 and parameters: {'n_hidden': 3, 'learning_rate': 0.006136616302271887, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1022980598406052, 'dropout_rate_Layer_2': 0.04125483721553623, 'dropout_rate_Layer_3': 0.08985954748720056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8123538714531106e-05, 'l1_Layer_2': 0.002749825629647158, 'l1_Layer_3': 0.004731984596250492, 'n_units_Layer_1': 295, 'n_units_Layer_2': 165, 'n_units_Layer_3': 60}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 13.25% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 14.69 | sMAPE for Test Set is: 18.94% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 04:59:58,449]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:01,112]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:05,334]\u001b[0m Trial 681 finished with value: 4.276320808834794 and parameters: {'n_hidden': 3, 'learning_rate': 0.004332126689786452, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20608959924228298, 'dropout_rate_Layer_2': 0.1592954512035805, 'dropout_rate_Layer_3': 0.18852412446339298, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02765848827063384, 'l1_Layer_2': 1.3001966043211275e-05, 'l1_Layer_3': 0.0010070922720129603, 'n_units_Layer_1': 180, 'n_units_Layer_2': 275, 'n_units_Layer_3': 70}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:05,405]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 15.21% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 49.35 | sMAPE for Test Set is: 45.12% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:00:05,642]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:06,407]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:12,039]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:15,835]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:17,187]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:19,008]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:27,147]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:27,337]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:33,557]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:36,899]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:39,343]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:42,059]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:44,487]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:48,211]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:50,915]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:52,878]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:00:56,120]\u001b[0m Trial 698 finished with value: 4.427210314090094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0049313952911742955, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2086010047864901, 'dropout_rate_Layer_2': 0.17391108660074722, 'dropout_rate_Layer_3': 0.20460944656178748, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025157948527279893, 'l1_Layer_2': 1.2059489059956013e-05, 'l1_Layer_3': 0.0010884907028383478, 'n_units_Layer_1': 140, 'n_units_Layer_2': 260, 'n_units_Layer_3': 65}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 15.55% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.11 | sMAPE for Test Set is: 44.86% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:00:59,730]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:10,868]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:13,363]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:15,869]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:19,473]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:22,314]\u001b[0m Trial 695 finished with value: 4.219083285882944 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023942971567344823, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0707866509822257, 'dropout_rate_Layer_2': 0.001877442291633326, 'dropout_rate_Layer_3': 0.08494433418645084, 'dropout_rate_Layer_4': 0.35011855834802696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005605944174680912, 'l1_Layer_2': 0.0037693823300390863, 'l1_Layer_3': 0.003368480488787801, 'l1_Layer_4': 0.0038260599653773797, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 55, 'n_units_Layer_4': 155}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 15.96 | sMAPE for Test Set is: 20.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:01:24,600]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:25,343]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:30,052]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:32,149]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:34,497]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:36,543]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:38,003]\u001b[0m Trial 709 finished with value: 3.9427177212718685 and parameters: {'n_hidden': 4, 'learning_rate': 0.012692728213711178, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16835114973726986, 'dropout_rate_Layer_2': 0.08734605103122457, 'dropout_rate_Layer_3': 0.23589929826629635, 'dropout_rate_Layer_4': 0.07568558581626314, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002498190656071319, 'l1_Layer_2': 0.00010901554632276544, 'l1_Layer_3': 0.0015388390394181202, 'l1_Layer_4': 0.00023807034919664778, 'n_units_Layer_1': 50, 'n_units_Layer_2': 150, 'n_units_Layer_3': 125, 'n_units_Layer_4': 50}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 13.79% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 16.70 | sMAPE for Test Set is: 20.00% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:01:44,278]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:48,475]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:48,878]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:49,454]\u001b[0m Trial 714 finished with value: 4.382199999177025 and parameters: {'n_hidden': 3, 'learning_rate': 0.0040123984544579655, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1850479844808864, 'dropout_rate_Layer_2': 0.17268647804014053, 'dropout_rate_Layer_3': 0.1800486753894619, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.030135224394619065, 'l1_Layer_2': 1.2996500901176466e-05, 'l1_Layer_3': 0.001216266623395415, 'n_units_Layer_1': 130, 'n_units_Layer_2': 270, 'n_units_Layer_3': 65}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 15.51% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.89 | sMAPE for Test Set is: 44.64% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:01:57,739]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:01:58,938]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:03,611]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:06,077]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:10,828]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:12,541]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:17,294]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:22,962]\u001b[0m Trial 725 finished with value: 4.342769585333163 and parameters: {'n_hidden': 3, 'learning_rate': 0.00435845147681581, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18445118856152456, 'dropout_rate_Layer_2': 0.18660501397378648, 'dropout_rate_Layer_3': 0.19861048840901657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02754554377927253, 'l1_Layer_2': 1.1657237764038645e-05, 'l1_Layer_3': 0.0013116011177235604, 'n_units_Layer_1': 140, 'n_units_Layer_2': 255, 'n_units_Layer_3': 65}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 15.35% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 49.89 | sMAPE for Test Set is: 45.71% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:02:28,608]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:28,899]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.30 | sMAPE for Validation Set is: 15.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 50.06 | sMAPE for Test Set is: 45.86% | rMAE for Test Set is: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:02:32,623]\u001b[0m Trial 731 finished with value: 4.301309615452198 and parameters: {'n_hidden': 3, 'learning_rate': 0.004912770166347019, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22046278353833873, 'dropout_rate_Layer_2': 0.17592653623766838, 'dropout_rate_Layer_3': 0.18053311177746165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028393188112999644, 'l1_Layer_2': 1.1924855292460124e-05, 'l1_Layer_3': 0.0012051604830829003, 'n_units_Layer_1': 140, 'n_units_Layer_2': 260, 'n_units_Layer_3': 65}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:38,135]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:39,626]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:43,875]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:44,122]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:50,296]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:53,895]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:02:59,453]\u001b[0m Trial 720 finished with value: 4.224371598827251 and parameters: {'n_hidden': 4, 'learning_rate': 0.002755082929279821, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06094854903761612, 'dropout_rate_Layer_2': 0.009116765623535136, 'dropout_rate_Layer_3': 0.0965884808713718, 'dropout_rate_Layer_4': 0.3570496952787896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008993898255901604, 'l1_Layer_2': 0.006805595282764377, 'l1_Layer_3': 0.00406599969707386, 'l1_Layer_4': 0.01870188073736484, 'n_units_Layer_1': 285, 'n_units_Layer_2': 160, 'n_units_Layer_3': 65, 'n_units_Layer_4': 185}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 15.68 | sMAPE for Test Set is: 19.90% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:03:02,365]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:05,921]\u001b[0m Trial 740 finished with value: 4.31604264718023 and parameters: {'n_hidden': 3, 'learning_rate': 0.004700882983249231, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18613686212608557, 'dropout_rate_Layer_2': 0.16579963687541785, 'dropout_rate_Layer_3': 0.17739403736028425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.026137059614833143, 'l1_Layer_2': 1.3176987526792962e-05, 'l1_Layer_3': 0.0014402751344390929, 'n_units_Layer_1': 140, 'n_units_Layer_2': 260, 'n_units_Layer_3': 65}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 15.34% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 52.23 | sMAPE for Test Set is: 48.36% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:03:07,401]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:11,824]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:12,033]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:13,648]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:20,289]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:22,900]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:23,409]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:29,121]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:32,507]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:33,742]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:37,551]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:42,790]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:44,334]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:48,358]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:53,515]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:54,050]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:03:59,406]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:02,914]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:05,727]\u001b[0m Trial 735 finished with value: 4.20090315706772 and parameters: {'n_hidden': 4, 'learning_rate': 0.002749276393985217, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05765630899166107, 'dropout_rate_Layer_2': 0.018711657920647835, 'dropout_rate_Layer_3': 0.10627888749910298, 'dropout_rate_Layer_4': 0.3582300227495919, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007695589423530849, 'l1_Layer_2': 0.002038048871936511, 'l1_Layer_3': 0.003951107533334749, 'l1_Layer_4': 0.012155978866990828, 'n_units_Layer_1': 300, 'n_units_Layer_2': 165, 'n_units_Layer_3': 50, 'n_units_Layer_4': 140}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.20 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 16.93 | sMAPE for Test Set is: 20.53% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:04:12,145]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:17,022]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:20,155]\u001b[0m Trial 760 finished with value: 4.350848159622488 and parameters: {'n_hidden': 4, 'learning_rate': 0.006165615948848481, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22124957289384656, 'dropout_rate_Layer_2': 0.021255371565741987, 'dropout_rate_Layer_3': 0.21068156301647795, 'dropout_rate_Layer_4': 0.07752721465589206, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.458602339805453e-05, 'l1_Layer_2': 5.423286779957356e-05, 'l1_Layer_3': 0.001424279398640766, 'l1_Layer_4': 0.00125001682053233, 'n_units_Layer_1': 85, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150, 'n_units_Layer_4': 115}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 15.70% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 17.90 | sMAPE for Test Set is: 20.65% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:04:23,055]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:25,120]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:25,989]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:27,267]\u001b[0m Trial 764 finished with value: 4.292715293615088 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037980287359961435, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18511616823965543, 'dropout_rate_Layer_2': 0.18676976310893065, 'dropout_rate_Layer_3': 0.19576300554095338, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025712178004360514, 'l1_Layer_2': 1.1403074689429586e-05, 'l1_Layer_3': 0.0014239909465549841, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 60}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 15.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 48.35 | sMAPE for Test Set is: 44.05% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:04:34,226]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:38,122]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:38,381]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:38,495]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:46,427]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:47,160]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:51,855]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:55,430]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:55,773]\u001b[0m Trial 773 finished with value: 4.322095816124338 and parameters: {'n_hidden': 3, 'learning_rate': 0.004679222428233676, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18768587370154324, 'dropout_rate_Layer_2': 0.1944132510519878, 'dropout_rate_Layer_3': 0.18618945180166036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028759830093365205, 'l1_Layer_2': 1.2014776013365936e-05, 'l1_Layer_3': 0.0018445859774426862, 'n_units_Layer_1': 130, 'n_units_Layer_2': 275, 'n_units_Layer_3': 55}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.32 | sMAPE for Validation Set is: 15.32% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 50.54 | sMAPE for Test Set is: 46.58% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:04:56,048]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:04:56,509]\u001b[0m Trial 770 finished with value: 4.183779115235241 and parameters: {'n_hidden': 4, 'learning_rate': 0.006124439461963554, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32829581466448615, 'dropout_rate_Layer_2': 0.04592322871992732, 'dropout_rate_Layer_3': 0.2665855211666845, 'dropout_rate_Layer_4': 0.022676697407304706, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.312539101036839e-05, 'l1_Layer_2': 9.68410656032053e-05, 'l1_Layer_3': 0.004141995692589994, 'l1_Layer_4': 0.0004977645381186834, 'n_units_Layer_1': 50, 'n_units_Layer_2': 130, 'n_units_Layer_3': 85, 'n_units_Layer_4': 80}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.18 | sMAPE for Validation Set is: 14.85% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 17.62 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:05:04,586]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:06,744]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:07,654]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:12,717]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:17,743]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:18,576]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:28,514]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:29,149]\u001b[0m Trial 785 finished with value: 4.305196645456879 and parameters: {'n_hidden': 3, 'learning_rate': 0.005056780011530164, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18829957661640845, 'dropout_rate_Layer_2': 0.1946137952395126, 'dropout_rate_Layer_3': 0.1805690259334721, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03205260355951688, 'l1_Layer_2': 1.191335403825197e-05, 'l1_Layer_3': 0.0020800512155221508, 'n_units_Layer_1': 125, 'n_units_Layer_2': 295, 'n_units_Layer_3': 55}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 15.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 51.02 | sMAPE for Test Set is: 47.00% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:05:35,302]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:36,860]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:42,061]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:43,247]\u001b[0m Trial 786 finished with value: 3.9456272555695375 and parameters: {'n_hidden': 4, 'learning_rate': 0.005828696066971166, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3328925457702023, 'dropout_rate_Layer_2': 0.057430198221168474, 'dropout_rate_Layer_3': 0.2858623618536117, 'dropout_rate_Layer_4': 0.10602812442677806, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010160688483762822, 'l1_Layer_2': 6.276953259102844e-05, 'l1_Layer_3': 0.00403966759769913, 'l1_Layer_4': 0.0006822757791395881, 'n_units_Layer_1': 50, 'n_units_Layer_2': 130, 'n_units_Layer_3': 130, 'n_units_Layer_4': 75}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:43,281]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.95 | sMAPE for Validation Set is: 13.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 21.69 | sMAPE for Test Set is: 23.87% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:05:43,591]\u001b[0m Trial 787 finished with value: 4.103634001980695 and parameters: {'n_hidden': 3, 'learning_rate': 0.002604015041710376, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29516019954717665, 'dropout_rate_Layer_2': 0.08414477922606958, 'dropout_rate_Layer_3': 0.16863295007656526, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010902269716529644, 'l1_Layer_2': 0.0007044928570453565, 'l1_Layer_3': 0.013047460899293798, 'n_units_Layer_1': 250, 'n_units_Layer_2': 100, 'n_units_Layer_3': 60}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 14.72% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 54.32 | sMAPE for Test Set is: 50.64% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:05:51,459]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:52,277]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:52,445]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:56,094]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:05:59,088]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:01,035]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:03,897]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:08,571]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:08,966]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:09,364]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:15,916]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:19,233]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:22,082]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:25,408]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:25,989]\u001b[0m Trial 798 finished with value: 3.9701219085286414 and parameters: {'n_hidden': 4, 'learning_rate': 0.004531425335224555, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36659792662019175, 'dropout_rate_Layer_2': 0.0728529994658804, 'dropout_rate_Layer_3': 0.27909200551743557, 'dropout_rate_Layer_4': 0.024759247081863944, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.16742338409263e-05, 'l1_Layer_2': 0.00010652861395781455, 'l1_Layer_3': 0.0014516505170729648, 'l1_Layer_4': 8.239108098224964e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 165, 'n_units_Layer_3': 170, 'n_units_Layer_4': 110}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 13.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 16.69 | sMAPE for Test Set is: 20.13% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:06:32,694]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:33,033]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:38,725]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:43,111]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:47,672]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:47,916]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:53,014]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:53,349]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:06:58,253]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:07:07,271]\u001b[0m Trial 812 finished with value: 4.25261590342225 and parameters: {'n_hidden': 4, 'learning_rate': 0.0043131554155903876, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.367602422075013, 'dropout_rate_Layer_2': 0.06554777011057009, 'dropout_rate_Layer_3': 0.27145119749731966, 'dropout_rate_Layer_4': 0.019386379819281086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.0250896820915804e-05, 'l1_Layer_2': 0.00010024918644026872, 'l1_Layer_3': 0.008661013624273748, 'l1_Layer_4': 4.4766993680929706e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 170, 'n_units_Layer_4': 105}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 14.78% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 15.82 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:07:14,017]\u001b[0m Trial 819 finished with value: 4.284309688723796 and parameters: {'n_hidden': 4, 'learning_rate': 0.0044095094774061925, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3718309701278636, 'dropout_rate_Layer_2': 0.06294691938828759, 'dropout_rate_Layer_3': 0.30189615400716807, 'dropout_rate_Layer_4': 0.024210315566707257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.223129744556811e-05, 'l1_Layer_2': 0.00020598484931428309, 'l1_Layer_3': 0.008647047983326259, 'l1_Layer_4': 8.523345747573689e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 105, 'n_units_Layer_3': 170, 'n_units_Layer_4': 110}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 14.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 15.83 | sMAPE for Test Set is: 19.77% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:07:18,210]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:07:22,247]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:07:27,690]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:07:27,888]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:07:29,250]\u001b[0m Trial 821 finished with value: 3.9162387247153916 and parameters: {'n_hidden': 4, 'learning_rate': 0.004330032120840757, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3737042487174643, 'dropout_rate_Layer_2': 0.07186927224508675, 'dropout_rate_Layer_3': 0.2702111281966901, 'dropout_rate_Layer_4': 0.02358589868956288, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.872685435641337e-05, 'l1_Layer_2': 0.0001106946116352555, 'l1_Layer_3': 0.008146117789622724, 'l1_Layer_4': 1.0710154202313601e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 75, 'n_units_Layer_3': 170, 'n_units_Layer_4': 115}. Best is trial 675 with value: 3.669122592900346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 13.67% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 15.97 | sMAPE for Test Set is: 20.57% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:07:34,483]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:07:38,062]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:07:41,685]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:07:45,527]\u001b[0m Trial 816 finished with value: 3.5164071083472845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010543949552658139, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006636069937958983, 'dropout_rate_Layer_2': 0.19469956984910092, 'dropout_rate_Layer_3': 0.17118635834456192, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010252395641498818, 'l1_Layer_2': 0.0004788681706119808, 'l1_Layer_3': 0.020629327841348126, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.57 | sMAPE for Test Set is: 18.96% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:07:49,738]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:07:59,665]\u001b[0m Trial 830 finished with value: 3.750268317692349 and parameters: {'n_hidden': 3, 'learning_rate': 0.004513581944634653, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06699890743441295, 'dropout_rate_Layer_2': 0.04769583301387517, 'dropout_rate_Layer_3': 0.12678608568953406, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027237056043410163, 'l1_Layer_2': 0.000827857691630089, 'l1_Layer_3': 0.005408673484463753, 'n_units_Layer_1': 115, 'n_units_Layer_2': 240, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 13.17% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.72 | sMAPE for Test Set is: 19.13% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:08:05,926]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:08:25,850]\u001b[0m Trial 827 finished with value: 3.7447007853628413 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009417077389860115, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.312527813034935, 'dropout_rate_Layer_2': 0.3260440121994016, 'dropout_rate_Layer_3': 0.1787585081511683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.833946072539671e-05, 'l1_Layer_2': 0.0007454696934230741, 'l1_Layer_3': 0.02546117792468819, 'n_units_Layer_1': 245, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.36 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:08:29,822]\u001b[0m Trial 826 finished with value: 3.8043712779826993 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010101384134250612, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32044507382117504, 'dropout_rate_Layer_2': 0.2721366684027188, 'dropout_rate_Layer_3': 0.18511993496787627, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011789863607326822, 'l1_Layer_2': 0.0013134434502510791, 'l1_Layer_3': 0.024405680212312375, 'n_units_Layer_1': 250, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 13.26% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 14.04 | sMAPE for Test Set is: 18.62% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:08:33,355]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:08:33,730]\u001b[0m Trial 833 finished with value: 3.6069501161918436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011726135374897613, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31253911686151004, 'dropout_rate_Layer_2': 0.19795191787558158, 'dropout_rate_Layer_3': 0.17904363040487048, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010604439584326957, 'l1_Layer_2': 0.0005175092509400825, 'l1_Layer_3': 0.020897745747072472, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 12.56% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 13.99 | sMAPE for Test Set is: 18.57% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:08:39,764]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:08:40,347]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:08:44,782]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:08:45,392]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:08:50,880]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:08:55,714]\u001b[0m Trial 834 finished with value: 3.681444039085781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012132033219215315, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01494902331225473, 'dropout_rate_Layer_2': 0.37911907114943166, 'dropout_rate_Layer_3': 0.181384035014117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010244320680766577, 'l1_Layer_2': 0.00046502860400963043, 'l1_Layer_3': 0.016896656555974, 'n_units_Layer_1': 255, 'n_units_Layer_2': 215, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 12.89% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 15.13 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:09:03,922]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:06,685]\u001b[0m Trial 842 finished with value: 4.5256284667566735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029852079276333943, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3711608187420746, 'dropout_rate_Layer_2': 0.1300983587028386, 'dropout_rate_Layer_3': 0.32758137571485363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 7.45265619795148e-05, 'l1_Layer_2': 0.0006086836505139575, 'l1_Layer_3': 0.0170970968505499, 'n_units_Layer_1': 60, 'n_units_Layer_2': 65, 'n_units_Layer_3': 205}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 16.03% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 49.73 | sMAPE for Test Set is: 45.44% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:09:10,778]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:14,054]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:19,076]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:21,000]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:27,200]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:30,838]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:34,021]\u001b[0m Trial 849 finished with value: 4.538777559527447 and parameters: {'n_hidden': 3, 'learning_rate': 0.006760370931605169, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15276424565811178, 'dropout_rate_Layer_2': 0.20174841229738297, 'dropout_rate_Layer_3': 0.15834385448114432, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04816876536487898, 'l1_Layer_2': 1.0081305588490052e-05, 'l1_Layer_3': 0.0006475909675868544, 'n_units_Layer_1': 160, 'n_units_Layer_2': 245, 'n_units_Layer_3': 75}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 16.13% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 48.28 | sMAPE for Test Set is: 44.04% | rMAE for Test Set is: 1.94\n",
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 13.28% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.28 | sMAPE for Test Set is: 18.92% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:09:34,149]\u001b[0m Trial 835 finished with value: 3.7501148064408234 and parameters: {'n_hidden': 3, 'learning_rate': 0.001041550331318961, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3128683509624943, 'dropout_rate_Layer_2': 0.19529465022798564, 'dropout_rate_Layer_3': 0.18725407776958256, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.81948157065747e-05, 'l1_Layer_2': 0.0012563149936390705, 'l1_Layer_3': 0.0266038804260956, 'n_units_Layer_1': 250, 'n_units_Layer_2': 220, 'n_units_Layer_3': 50}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:38,517]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:41,864]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:44,477]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:48,919]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:52,415]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:09:58,539]\u001b[0m Trial 855 finished with value: 4.445477693902196 and parameters: {'n_hidden': 3, 'learning_rate': 0.005075167922858334, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21583792091738177, 'dropout_rate_Layer_2': 0.17513743196910472, 'dropout_rate_Layer_3': 0.20084053440856353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02808023226623068, 'l1_Layer_2': 1.2913533688757117e-05, 'l1_Layer_3': 0.0023662643431412627, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 15.74% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 53.63 | sMAPE for Test Set is: 49.93% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:10:01,659]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:02,113]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:07,782]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:08,316]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:13,057]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:13,685]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:19,600]\u001b[0m Trial 859 finished with value: 3.961093851524918 and parameters: {'n_hidden': 4, 'learning_rate': 0.004664129511042188, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3618205692772616, 'dropout_rate_Layer_2': 0.06586181091215074, 'dropout_rate_Layer_3': 0.3028180033380361, 'dropout_rate_Layer_4': 0.022969571764729368, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.267033451365303e-05, 'l1_Layer_2': 0.0001179431425753562, 'l1_Layer_3': 0.008494220371026453, 'l1_Layer_4': 1.6898627196523548e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 170, 'n_units_Layer_4': 75}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 14.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 16.50 | sMAPE for Test Set is: 20.23% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:10:20,284]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:25,345]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:25,852]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:30,488]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:32,378]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:36,368]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:38,811]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:43,253]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:46,481]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:50,905]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:54,194]\u001b[0m Trial 853 finished with value: 3.6127069514541574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008708656841394222, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11884591055645392, 'dropout_rate_Layer_2': 0.18890824942785173, 'dropout_rate_Layer_3': 0.18258005150378012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.688791338287781e-05, 'l1_Layer_2': 0.001853538007432067, 'l1_Layer_3': 0.03436427139121233, 'n_units_Layer_1': 255, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 12.65% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.27 | sMAPE for Test Set is: 18.77% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:10:55,033]\u001b[0m Trial 865 finished with value: 3.8817051508499723 and parameters: {'n_hidden': 3, 'learning_rate': 0.00103271144849971, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31700283158416287, 'dropout_rate_Layer_2': 0.35503680051735986, 'dropout_rate_Layer_3': 0.21253979044513455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001049902728298689, 'l1_Layer_2': 0.000556541489163109, 'l1_Layer_3': 0.017674345246950624, 'n_units_Layer_1': 240, 'n_units_Layer_2': 230, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:10:55,128]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 13.60% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 14.62 | sMAPE for Test Set is: 19.00% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:11:01,237]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:03,695]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:06,378]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:10,625]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:11,265]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:11,893]\u001b[0m Trial 880 finished with value: 4.508280986380332 and parameters: {'n_hidden': 3, 'learning_rate': 0.005564970047437904, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2100351700171721, 'dropout_rate_Layer_2': 0.16735859005825365, 'dropout_rate_Layer_3': 0.20294859036031934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02241729410236111, 'l1_Layer_2': 1.535648612796855e-05, 'l1_Layer_3': 0.0008083037055871047, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 50}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 50.25 | sMAPE for Test Set is: 46.24% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:11:12,213]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:16,374]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:16,582]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:22,445]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:23,384]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:28,096]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:28,635]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:28,746]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:32,708]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:37,058]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:37,339]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:38,375]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:44,274]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:47,564]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:11:50,012]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:02,609]\u001b[0m Trial 897 finished with value: 3.871473534839398 and parameters: {'n_hidden': 4, 'learning_rate': 0.0038377693701285194, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32271851130565316, 'dropout_rate_Layer_2': 0.09496167496375064, 'dropout_rate_Layer_3': 0.2887579461945336, 'dropout_rate_Layer_4': 0.014657334239745353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.6466743497450863e-05, 'l1_Layer_2': 0.0001234609162842857, 'l1_Layer_3': 0.006206574366664869, 'l1_Layer_4': 1.1294053934905894e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 85, 'n_units_Layer_3': 165, 'n_units_Layer_4': 75}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 13.87% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 15.77 | sMAPE for Test Set is: 19.99% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:12:06,002]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:08,098]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:12,633]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:17,142]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:24,020]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:27,073]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:31,401]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:35,072]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:41,016]\u001b[0m Trial 888 finished with value: 3.885808220429894 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007970282302742202, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01701146665418786, 'dropout_rate_Layer_2': 0.18036375498607052, 'dropout_rate_Layer_3': 0.28158379773311143, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.252039749516627e-05, 'l1_Layer_2': 0.0012407882615995869, 'l1_Layer_3': 0.018812792005069266, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 13.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 14.74 | sMAPE for Test Set is: 18.97% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:12:46,120]\u001b[0m Trial 900 finished with value: 3.5856457869599225 and parameters: {'n_hidden': 3, 'learning_rate': 0.001162519834158591, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03449618517080622, 'dropout_rate_Layer_2': 0.1996037637769499, 'dropout_rate_Layer_3': 0.17540537714188906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010918887666541165, 'l1_Layer_2': 0.0006786706338491696, 'l1_Layer_3': 0.0296027467058661, 'n_units_Layer_1': 250, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 12.57% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 13.87 | sMAPE for Test Set is: 18.44% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:12:50,089]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:55,458]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:59,720]\u001b[0m Trial 911 finished with value: 4.458255329109943 and parameters: {'n_hidden': 3, 'learning_rate': 0.005153829059714968, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21979298075960554, 'dropout_rate_Layer_2': 0.17659805029316294, 'dropout_rate_Layer_3': 0.20914223182384895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05813317391584767, 'l1_Layer_2': 1.9342592788864713e-05, 'l1_Layer_3': 0.0010610643624485371, 'n_units_Layer_1': 160, 'n_units_Layer_2': 280, 'n_units_Layer_3': 70}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:12:59,754]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 15.82% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.21 | sMAPE for Test Set is: 43.88% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:13:01,121]\u001b[0m Trial 903 finished with value: 3.5823312636006173 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008037242196921423, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31713103641872753, 'dropout_rate_Layer_2': 0.19534526354490378, 'dropout_rate_Layer_3': 0.1763511226957439, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010620223563482414, 'l1_Layer_2': 0.0006191657381920578, 'l1_Layer_3': 0.020728773893205387, 'n_units_Layer_1': 250, 'n_units_Layer_2': 225, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 12.52% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.60 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:13:07,974]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:11,612]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:15,790]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:21,228]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:24,579]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:25,693]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:30,492]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:31,695]\u001b[0m Trial 916 finished with value: 3.9648600707318677 and parameters: {'n_hidden': 4, 'learning_rate': 0.003781503553974337, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32910269935332037, 'dropout_rate_Layer_2': 0.10086936439591185, 'dropout_rate_Layer_3': 0.36161898606664233, 'dropout_rate_Layer_4': 0.03278520583395294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.75176825758717e-05, 'l1_Layer_2': 0.00015617087832605185, 'l1_Layer_3': 0.006551428272373276, 'l1_Layer_4': 1.362980746885487e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 125, 'n_units_Layer_3': 195, 'n_units_Layer_4': 75}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 13.74% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 15.86 | sMAPE for Test Set is: 19.71% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:13:38,926]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:43,092]\u001b[0m Trial 910 finished with value: 3.618652772049496 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008301817176091821, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3123048393107614, 'dropout_rate_Layer_2': 0.19978233323758213, 'dropout_rate_Layer_3': 0.17494903226195507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001106610455078244, 'l1_Layer_2': 0.0006025560205778077, 'l1_Layer_3': 0.031408061669624614, 'n_units_Layer_1': 255, 'n_units_Layer_2': 210, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 12.68% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.22 | sMAPE for Test Set is: 18.73% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:13:43,518]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:47,198]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:50,003]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:50,160]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:57,201]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:13:59,521]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:07,402]\u001b[0m Trial 929 finished with value: 4.380961717585225 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035793786328919674, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39957544893361663, 'dropout_rate_Layer_2': 0.1371703556719248, 'dropout_rate_Layer_3': 0.31518046132981425, 'dropout_rate_Layer_4': 0.010656549016509715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.257533063433086e-05, 'l1_Layer_2': 0.0003039768778318241, 'l1_Layer_3': 0.02249359358635417, 'l1_Layer_4': 1.9818972314298342e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 80, 'n_units_Layer_3': 160, 'n_units_Layer_4': 70}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 16.21% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 18.83 | sMAPE for Test Set is: 22.28% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:14:08,625]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:14,577]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:15,144]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:20,497]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:21,079]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:24,865]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:26,233]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:30,108]\u001b[0m Trial 923 finished with value: 3.909255799050672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007919099298518681, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0372772803673849, 'dropout_rate_Layer_2': 0.2175483504691237, 'dropout_rate_Layer_3': 0.3016125511557067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.795970225500754e-05, 'l1_Layer_2': 0.0007002574429187238, 'l1_Layer_3': 0.03565055103139365, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 15.67 | sMAPE for Test Set is: 19.74% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:14:33,456]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:33,768]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:39,147]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:39,580]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:39,784]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:46,811]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:47,316]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:51,983]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:52,470]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:53,131]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:14:59,587]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:00,731]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:02,497]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:03,515]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:05,968]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:13,912]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:14,027]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:15,117]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:22,064]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:22,832]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:28,077]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:28,623]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:33,045]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:35,147]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:36,496]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:38,933]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:41,905]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:47,048]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:47,215]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:53,109]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:53,380]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:59,335]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:59,441]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:15:59,827]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:08,410]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:08,438]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:08,853]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:08,950]\u001b[0m Trial 967 finished with value: 3.9299648396384406 and parameters: {'n_hidden': 4, 'learning_rate': 0.004939794399890543, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3258082379557097, 'dropout_rate_Layer_2': 0.1615199219289631, 'dropout_rate_Layer_3': 0.355836046636347, 'dropout_rate_Layer_4': 0.03777100208479112, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.685165958240764e-05, 'l1_Layer_2': 0.00013015491168561345, 'l1_Layer_3': 0.0030908079124591565, 'l1_Layer_4': 1.9625082593883365e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220, 'n_units_Layer_4': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 13.52% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 15.14 | sMAPE for Test Set is: 19.46% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:16:17,671]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:19,716]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:20,094]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:21,289]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:21,718]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:30,986]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:34,236]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:34,754]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:40,229]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:41,506]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:46,029]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:46,185]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:52,074]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:16:55,979]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:00,818]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:04,990]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:06,500]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:10,859]\u001b[0m Trial 985 finished with value: 4.328780942242126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020829259528595033, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16068977369331222, 'dropout_rate_Layer_2': 0.1431592558121198, 'dropout_rate_Layer_3': 0.22089809029440235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04953816649288804, 'l1_Layer_2': 2.9657543168360168e-05, 'l1_Layer_3': 0.0015080928733244166, 'n_units_Layer_1': 140, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 15.29% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 48.82 | sMAPE for Test Set is: 44.52% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:17:11,088]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:16,803]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:18,475]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:19,670]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:21,825]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:25,268]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:26,016]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:31,783]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:33,191]\u001b[0m Trial 987 finished with value: 3.564861862308993 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010453825894875459, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00912590341733009, 'dropout_rate_Layer_2': 0.17404917632607025, 'dropout_rate_Layer_3': 0.19387575313936123, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001072582275587997, 'l1_Layer_2': 0.0007254532773439731, 'l1_Layer_3': 0.016951620529983908, 'n_units_Layer_1': 265, 'n_units_Layer_2': 220, 'n_units_Layer_3': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 12.61% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.25 | sMAPE for Test Set is: 18.75% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:17:38,633]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:39,015]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:39,739]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:39,810]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:50,825]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:17:58,277]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:18:05,183]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:18:09,058]\u001b[0m Trial 1010 finished with value: 3.8395224789944424 and parameters: {'n_hidden': 4, 'learning_rate': 0.002535043310108346, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3587173341894648, 'dropout_rate_Layer_2': 0.11448202155719475, 'dropout_rate_Layer_3': 0.3737883903353889, 'dropout_rate_Layer_4': 0.03863310522772412, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.7959432537232202e-05, 'l1_Layer_2': 3.3614661302128374e-05, 'l1_Layer_3': 0.0064661378961282075, 'l1_Layer_4': 1.097048045771748e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 55, 'n_units_Layer_3': 255, 'n_units_Layer_4': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 13.66% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 17.85 | sMAPE for Test Set is: 20.63% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:18:12,827]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:18:17,562]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:18:18,524]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:18:25,129]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:18:32,268]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:18:36,724]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:18:52,587]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:18:53,821]\u001b[0m Trial 1011 finished with value: 3.6010664415868647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010683137045623132, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01868133224241702, 'dropout_rate_Layer_2': 0.1884889322672586, 'dropout_rate_Layer_3': 0.1996364904421699, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011151010076154262, 'l1_Layer_2': 0.0007815791086887125, 'l1_Layer_3': 0.01817590126734054, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 12.68% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.33 | sMAPE for Test Set is: 18.71% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:18:59,207]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:19:01,682]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:19:09,869]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:19:23,309]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:19:25,994]\u001b[0m Trial 1014 finished with value: 3.5677067692984603 and parameters: {'n_hidden': 3, 'learning_rate': 0.00057140336875982, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02017330795888746, 'dropout_rate_Layer_2': 0.15194422484523368, 'dropout_rate_Layer_3': 0.18712698124546867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.5637587221607036e-05, 'l1_Layer_2': 0.0008262208850892682, 'l1_Layer_3': 0.020602841319981417, 'n_units_Layer_1': 250, 'n_units_Layer_2': 225, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.05 | sMAPE for Test Set is: 18.50% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:19:31,116]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:19:34,100]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:19:38,114]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:19:43,504]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:19:43,680]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:19:50,588]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:19:51,121]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:19:56,818]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:20:01,759]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:20:05,190]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:20:14,363]\u001b[0m Trial 1021 finished with value: 3.538217463365781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005758889384973633, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019975559537804485, 'dropout_rate_Layer_2': 0.2008715492416767, 'dropout_rate_Layer_3': 0.1895270587174352, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001468317857042526, 'l1_Layer_2': 0.0004692122134579164, 'l1_Layer_3': 0.01881000012814619, 'n_units_Layer_1': 245, 'n_units_Layer_2': 215, 'n_units_Layer_3': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 12.50% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.09 | sMAPE for Test Set is: 18.70% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:20:21,730]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:20:29,066]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:20:33,849]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:20:40,447]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:20:40,887]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:20:46,685]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:20:49,525]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:20:52,718]\u001b[0m Trial 1031 finished with value: 3.5469769933772723 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006664460229268594, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015029351935948456, 'dropout_rate_Layer_2': 0.16877150872413868, 'dropout_rate_Layer_3': 0.19397048476009487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.402882668349101e-05, 'l1_Layer_2': 0.0008786175807393072, 'l1_Layer_3': 0.019714982050820704, 'n_units_Layer_1': 245, 'n_units_Layer_2': 225, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 12.42% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 13.98 | sMAPE for Test Set is: 18.54% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:20:54,673]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:20:59,325]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:21:03,943]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:21:10,164]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:21:16,998]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:21:17,506]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:21:29,783]\u001b[0m Trial 1053 finished with value: 4.33661342917932 and parameters: {'n_hidden': 3, 'learning_rate': 0.004184276090510586, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15868371428378453, 'dropout_rate_Layer_2': 0.17536912656902795, 'dropout_rate_Layer_3': 0.22278621005483407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.024529329204112715, 'l1_Layer_2': 3.205592004334078e-05, 'l1_Layer_3': 0.001353619584935168, 'n_units_Layer_1': 140, 'n_units_Layer_2': 270, 'n_units_Layer_3': 50}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 15.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 47.61 | sMAPE for Test Set is: 43.19% | rMAE for Test Set is: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:21:30,476]\u001b[0m Trial 1034 finished with value: 3.631413174341869 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006177411817170114, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038684912682296, 'dropout_rate_Layer_2': 0.19757055358864645, 'dropout_rate_Layer_3': 0.1871275433960133, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.94208742694829e-05, 'l1_Layer_2': 0.0013567064910784174, 'l1_Layer_3': 0.024696382709770988, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.69 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:21:34,963]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:21:38,971]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:22:03,668]\u001b[0m Trial 1057 finished with value: 3.8310391016336314 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018972536168728957, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3272155902632101, 'dropout_rate_Layer_2': 0.09081333049436925, 'dropout_rate_Layer_3': 0.3571760422509864, 'dropout_rate_Layer_4': 0.03813909038782595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5392727978834126e-05, 'l1_Layer_2': 0.00012085741078197929, 'l1_Layer_3': 0.006514810004534313, 'l1_Layer_4': 1.4810880012695328e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 60, 'n_units_Layer_3': 270, 'n_units_Layer_4': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 13.63% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.51 | sMAPE for Test Set is: 19.15% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:22:08,041]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:22:11,382]\u001b[0m Trial 1055 finished with value: 3.81351429625806 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018859857256416548, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32076152441807737, 'dropout_rate_Layer_2': 0.21334551800784654, 'dropout_rate_Layer_3': 0.36457841998017043, 'dropout_rate_Layer_4': 0.03677655535769009, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.7740534684389984e-05, 'l1_Layer_2': 0.0001232073326236853, 'l1_Layer_3': 0.006317333113461854, 'l1_Layer_4': 1.4204579527857379e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275, 'n_units_Layer_4': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 13.60% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.06 | sMAPE for Test Set is: 19.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:22:13,517]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:22:15,435]\u001b[0m Trial 1052 finished with value: 3.736983806254582 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006519453550496043, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01514759819340895, 'dropout_rate_Layer_2': 0.14936439552501782, 'dropout_rate_Layer_3': 0.20496902183905646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.405121114485015e-05, 'l1_Layer_2': 0.0006060195320175307, 'l1_Layer_3': 0.029396993984429905, 'n_units_Layer_1': 235, 'n_units_Layer_2': 225, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 13.05% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 15.26 | sMAPE for Test Set is: 19.38% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:22:21,510]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:22:24,526]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:22:31,724]\u001b[0m Trial 1045 finished with value: 3.622113298276783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005775919157151626, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01711408883962556, 'dropout_rate_Layer_2': 0.20922002389154154, 'dropout_rate_Layer_3': 0.22782553090805757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.725937736319295e-05, 'l1_Layer_2': 0.0012322831023662527, 'l1_Layer_3': 0.015260752633706794, 'n_units_Layer_1': 280, 'n_units_Layer_2': 215, 'n_units_Layer_3': 50}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 12.61% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.02 | sMAPE for Test Set is: 18.69% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:22:33,923]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:22:39,623]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:22:51,741]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:22:55,467]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:22:57,591]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:23:02,035]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:23:11,752]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:23:14,921]\u001b[0m Trial 1069 finished with value: 4.3944274392566305 and parameters: {'n_hidden': 3, 'learning_rate': 0.004084463055830871, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15913045003208606, 'dropout_rate_Layer_2': 0.173752875967721, 'dropout_rate_Layer_3': 0.21807731601740413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02195514765410141, 'l1_Layer_2': 2.638058762949024e-05, 'l1_Layer_3': 0.0015408215135273642, 'n_units_Layer_1': 125, 'n_units_Layer_2': 280, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 15.40% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.88 | sMAPE for Test Set is: 44.57% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:23:19,444]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:23:22,718]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:23:29,783]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:23:33,798]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:23:41,195]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:23:49,612]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:23:50,300]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:23:54,947]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:23:57,293]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:01,413]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:04,022]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:15,805]\u001b[0m Trial 1067 finished with value: 3.613392953863826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006105519237024315, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021843132054915372, 'dropout_rate_Layer_2': 0.20886365931912296, 'dropout_rate_Layer_3': 0.2202778109524172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.247434830794492e-05, 'l1_Layer_2': 0.0014103241599996502, 'l1_Layer_3': 0.020910847204624775, 'n_units_Layer_1': 280, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 12.63% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.25 | sMAPE for Test Set is: 18.69% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:24:17,265]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.57 | sMAPE for Test Set is: 18.94% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:24:18,429]\u001b[0m Trial 1074 finished with value: 3.6911707892147825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006482178939114312, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015373661705768111, 'dropout_rate_Layer_2': 0.2308984033378829, 'dropout_rate_Layer_3': 0.2112583428969294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.931759252232657e-05, 'l1_Layer_2': 0.0010831431906328233, 'l1_Layer_3': 0.021050860247268148, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:29,369]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:29,461]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:39,158]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:39,534]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:39,948]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:48,107]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:50,098]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:51,365]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:24:58,732]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:01,997]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:09,080]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:09,229]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:09,341]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:18,466]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:22,534]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:26,576]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:30,216]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:34,760]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:39,449]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:43,292]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:46,735]\u001b[0m Trial 1101 finished with value: 4.403884425756548 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038630171744301793, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15297691423161625, 'dropout_rate_Layer_2': 0.17356057626130098, 'dropout_rate_Layer_3': 0.22188201517440734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028036527569547064, 'l1_Layer_2': 6.110738659254782e-05, 'l1_Layer_3': 0.001673472932375069, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 15.52% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 49.29 | sMAPE for Test Set is: 45.07% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:25:51,159]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:25:54,845]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:26:01,127]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:26:04,908]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:26:09,361]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:26:13,906]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:26:39,877]\u001b[0m Trial 1110 finished with value: 3.863027990561674 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012002500018687774, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2938256531659061, 'dropout_rate_Layer_2': 0.1670078841737903, 'dropout_rate_Layer_3': 0.38532081826343956, 'dropout_rate_Layer_4': 0.06708182561738903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0893456680925603e-05, 'l1_Layer_2': 2.0072181828709225e-05, 'l1_Layer_3': 0.005373918484058192, 'l1_Layer_4': 1.1910479393981243e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 50, 'n_units_Layer_3': 255, 'n_units_Layer_4': 50}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 13.86% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 14.88 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:26:44,485]\u001b[0m Trial 1102 finished with value: 3.6899600342306247 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007204335832626667, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029795165883876443, 'dropout_rate_Layer_2': 0.17208834314973248, 'dropout_rate_Layer_3': 0.21968352957818535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.835685897346273e-05, 'l1_Layer_2': 0.0018310592956788919, 'l1_Layer_3': 0.01565746088490273, 'n_units_Layer_1': 250, 'n_units_Layer_2': 215, 'n_units_Layer_3': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 12.80% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.50 | sMAPE for Test Set is: 18.96% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:26:58,258]\u001b[0m Trial 1106 finished with value: 3.671299438790911 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007217998884863923, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022486593588809382, 'dropout_rate_Layer_2': 0.17113129386939116, 'dropout_rate_Layer_3': 0.21716325546200907, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.631504585386326e-05, 'l1_Layer_2': 0.0019750131611255234, 'l1_Layer_3': 0.015158767819460559, 'n_units_Layer_1': 250, 'n_units_Layer_2': 215, 'n_units_Layer_3': 50}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.28 | sMAPE for Test Set is: 18.69% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:27:03,564]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:27:18,655]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:27:33,946]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:27:36,954]\u001b[0m Trial 1114 finished with value: 3.5549799066837338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005818908165510405, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021078536809563092, 'dropout_rate_Layer_2': 0.1754194681677507, 'dropout_rate_Layer_3': 0.18881063189945527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001038394633758008, 'l1_Layer_2': 0.0008157227703441049, 'l1_Layer_3': 0.043214522473467055, 'n_units_Layer_1': 265, 'n_units_Layer_2': 225, 'n_units_Layer_3': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 12.44% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.66 | sMAPE for Test Set is: 19.13% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:27:41,714]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:27:41,934]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:27:48,151]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:27:53,758]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:27:54,718]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:06,363]\u001b[0m Trial 1117 finished with value: 3.712699500031236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005988662074400324, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03357989963707979, 'dropout_rate_Layer_2': 0.17249434410912778, 'dropout_rate_Layer_3': 0.22272796394485603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.51398144291419e-05, 'l1_Layer_2': 0.002133174745849686, 'l1_Layer_3': 0.015058954176767305, 'n_units_Layer_1': 245, 'n_units_Layer_2': 210, 'n_units_Layer_3': 50}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 13.12% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.73 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:28:11,652]\u001b[0m Trial 1115 finished with value: 3.552602625039294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005725132532911938, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007014206268135642, 'dropout_rate_Layer_2': 0.17434407267884533, 'dropout_rate_Layer_3': 0.19273805362594007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010533223759074002, 'l1_Layer_2': 0.001761699393927921, 'l1_Layer_3': 0.014757654977630884, 'n_units_Layer_1': 265, 'n_units_Layer_2': 225, 'n_units_Layer_3': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 12.49% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.39 | sMAPE for Test Set is: 18.67% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:28:14,941]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:17,469]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:20,805]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:24,432]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:32,031]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:36,919]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:42,019]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:44,961]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:47,063]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:47,870]\u001b[0m Trial 1130 finished with value: 4.249188619142566 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012927477206532265, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3014556452669357, 'dropout_rate_Layer_2': 0.2373774016577275, 'dropout_rate_Layer_3': 0.3472124618819768, 'dropout_rate_Layer_4': 0.282852963877681, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0131506815888316e-05, 'l1_Layer_2': 0.00029409292819856817, 'l1_Layer_3': 0.010533004931469452, 'l1_Layer_4': 1.0508968260644884e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 255, 'n_units_Layer_4': 50}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.25 | sMAPE for Validation Set is: 15.07% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 16.35 | sMAPE for Test Set is: 20.11% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:28:52,086]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:54,983]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:28:55,521]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:29:03,740]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:29:04,649]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:29:11,259]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:29:14,493]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:29:14,576]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:29:21,301]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:29:36,242]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:29:36,638]\u001b[0m Trial 1146 finished with value: 4.527636993850063 and parameters: {'n_hidden': 4, 'learning_rate': 0.001469822632021939, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38486051432796187, 'dropout_rate_Layer_2': 0.16012847257558632, 'dropout_rate_Layer_3': 0.3837407696047816, 'dropout_rate_Layer_4': 0.0632302910854877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5158575846556443e-05, 'l1_Layer_2': 1.4804172174378081e-05, 'l1_Layer_3': 0.001998814937561506, 'l1_Layer_4': 1.622926858892989e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 75, 'n_units_Layer_3': 275, 'n_units_Layer_4': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 16.18% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 16.80 | sMAPE for Test Set is: 21.10% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:29:45,884]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:29:53,601]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:29:54,770]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:29:57,385]\u001b[0m Trial 1125 finished with value: 3.5204913996189084 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006168256715289239, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007857060686555308, 'dropout_rate_Layer_2': 0.16130371320221454, 'dropout_rate_Layer_3': 0.21345811958501362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.9408952945942554e-05, 'l1_Layer_2': 0.0016746043055892242, 'l1_Layer_3': 0.014487905886696403, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 12.31% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.50 | sMAPE for Test Set is: 18.83% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:30:02,163]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:30:04,028]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:30:07,698]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:30:11,295]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:30:15,483]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:30:22,604]\u001b[0m Trial 1157 finished with value: 4.332851694703876 and parameters: {'n_hidden': 3, 'learning_rate': 0.005176725329222815, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18669562821727714, 'dropout_rate_Layer_2': 0.17400792530522213, 'dropout_rate_Layer_3': 0.18897725136403296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.039940730803594074, 'l1_Layer_2': 1.183303834777487e-05, 'l1_Layer_3': 0.0006850107609031472, 'n_units_Layer_1': 125, 'n_units_Layer_2': 265, 'n_units_Layer_3': 70}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.33 | sMAPE for Validation Set is: 15.36% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 47.05 | sMAPE for Test Set is: 42.65% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:30:23,512]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:30:33,090]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:30:37,066]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:30:42,541]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:30:49,644]\u001b[0m Trial 1149 finished with value: 3.564352503978995 and parameters: {'n_hidden': 3, 'learning_rate': 0.000676082980929228, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0004208009350004059, 'dropout_rate_Layer_2': 0.1637798374931566, 'dropout_rate_Layer_3': 0.18914154767200508, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.316492413734248e-05, 'l1_Layer_2': 0.001897333071575872, 'l1_Layer_3': 0.016533010416948997, 'n_units_Layer_1': 245, 'n_units_Layer_2': 220, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.56 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 18.91% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:30:54,325]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:30:58,831]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:01,193]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:05,176]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:05,242]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:18,400]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:21,692]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:22,050]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:29,219]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:29,253]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:34,540]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:34,723]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:43,614]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:48,953]\u001b[0m Trial 1151 finished with value: 3.5969397980611184 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006971093773341392, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0007715281347162525, 'dropout_rate_Layer_2': 0.15104153973334786, 'dropout_rate_Layer_3': 0.22308189775807288, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.629189175617653e-05, 'l1_Layer_2': 0.002723479689620989, 'l1_Layer_3': 0.02284732967338881, 'n_units_Layer_1': 255, 'n_units_Layer_2': 230, 'n_units_Layer_3': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 12.57% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.03 | sMAPE for Test Set is: 18.60% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:31:53,105]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:56,157]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:31:57,999]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:01,142]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:08,997]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:12,864]\u001b[0m Trial 1181 finished with value: 4.389779539497892 and parameters: {'n_hidden': 3, 'learning_rate': 0.005407292562232929, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1817293282754052, 'dropout_rate_Layer_2': 0.19513475630644564, 'dropout_rate_Layer_3': 0.18012642888456457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04243419711936626, 'l1_Layer_2': 1.1989074682713567e-05, 'l1_Layer_3': 0.0007709712320867004, 'n_units_Layer_1': 135, 'n_units_Layer_2': 290, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 15.44% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 45.95 | sMAPE for Test Set is: 41.51% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:32:17,018]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:17,224]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:22,339]\u001b[0m Trial 1177 finished with value: 4.067510333199576 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017303456346149106, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2950512808355155, 'dropout_rate_Layer_2': 0.21930781885576775, 'dropout_rate_Layer_3': 0.3464133952203929, 'dropout_rate_Layer_4': 0.07193855561417994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.024493126614253e-05, 'l1_Layer_2': 1.066193867190415e-05, 'l1_Layer_3': 0.0029300902674334016, 'l1_Layer_4': 1.3779910215347746e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285, 'n_units_Layer_4': 85}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.07 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.27 | sMAPE for Test Set is: 22.63% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:32:28,168]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:28,341]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:28,504]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:29,012]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:43,543]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:43,747]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:54,778]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:32:58,215]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:33:07,839]\u001b[0m Trial 1190 finished with value: 3.937407980334902 and parameters: {'n_hidden': 4, 'learning_rate': 0.002365501538711452, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34283218290029965, 'dropout_rate_Layer_2': 0.13980452136295246, 'dropout_rate_Layer_3': 0.39162111384399906, 'dropout_rate_Layer_4': 0.055544409865678525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.9554047417504136e-05, 'l1_Layer_2': 1.8682927404699343e-05, 'l1_Layer_3': 0.0044402694120370175, 'l1_Layer_4': 3.504900008588683e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220, 'n_units_Layer_4': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 15.62 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:33:11,248]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:33:20,117]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:33:31,447]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:33:36,818]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:33:41,962]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:33:45,932]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:33:51,066]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:33:55,900]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:33:59,862]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:04,342]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:04,865]\u001b[0m Trial 1200 finished with value: 4.019531900747683 and parameters: {'n_hidden': 4, 'learning_rate': 0.002546218190685937, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35429640439249854, 'dropout_rate_Layer_2': 0.1711892895639935, 'dropout_rate_Layer_3': 0.358048436037932, 'dropout_rate_Layer_4': 0.050311030772511894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.84012035813305e-05, 'l1_Layer_2': 1.9780675416202266e-05, 'l1_Layer_3': 0.010904417555442737, 'l1_Layer_4': 3.479235853805213e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220, 'n_units_Layer_4': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 14.27% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.68 | sMAPE for Test Set is: 19.53% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:34:11,269]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:15,990]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:19,591]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:24,285]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:24,834]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:31,122]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:35,176]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:35,341]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.20 | sMAPE for Test Set is: 18.65% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:34:39,518]\u001b[0m Trial 1197 finished with value: 3.586012656993631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005657725226648583, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011027763900885236, 'dropout_rate_Layer_2': 0.16336486398664662, 'dropout_rate_Layer_3': 0.19403188643998076, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.585299592962156e-05, 'l1_Layer_2': 0.002709920477640814, 'l1_Layer_3': 0.011563015873916704, 'n_units_Layer_1': 235, 'n_units_Layer_2': 230, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:43,697]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:44,525]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:44,561]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:53,008]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:54,994]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:59,141]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:34:59,816]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:35:00,434]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:35:06,357]\u001b[0m Trial 1199 finished with value: 3.6391355314825895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005579807792028323, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022049711199123443, 'dropout_rate_Layer_2': 0.1616526261703034, 'dropout_rate_Layer_3': 0.1966210779862353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.832898562692784e-05, 'l1_Layer_2': 0.0014201258297583176, 'l1_Layer_3': 0.024056535562255038, 'n_units_Layer_1': 235, 'n_units_Layer_2': 210, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.75 | sMAPE for Test Set is: 19.03% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:35:09,959]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:35:16,249]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:35:20,594]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:35:42,101]\u001b[0m Trial 1224 finished with value: 3.8258822685319616 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019692569836040133, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27272890954893103, 'dropout_rate_Layer_2': 0.19242578863132703, 'dropout_rate_Layer_3': 0.39166049907151945, 'dropout_rate_Layer_4': 0.01268524901903274, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.382741288592964e-05, 'l1_Layer_2': 1.693241542207501e-05, 'l1_Layer_3': 0.0071037093943480695, 'l1_Layer_4': 5.3482756252788007e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240, 'n_units_Layer_4': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 13.69% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 18.59 | sMAPE for Test Set is: 21.06% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:35:47,009]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:35:51,348]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:35:53,558]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:02,033]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:02,195]\u001b[0m Trial 1222 finished with value: 3.585680797404455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008208398461572036, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12830190597707097, 'dropout_rate_Layer_2': 0.15989695264844936, 'dropout_rate_Layer_3': 0.17896043207842544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.117589393416428e-05, 'l1_Layer_2': 0.002189117944554781, 'l1_Layer_3': 0.0179278032528807, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 70}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.93 | sMAPE for Test Set is: 19.17% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:36:07,997]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:08,045]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:08,881]\u001b[0m Trial 1226 finished with value: 3.6513893816121326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005512934568129874, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1654660515352159, 'dropout_rate_Layer_2': 0.16084092016205626, 'dropout_rate_Layer_3': 0.19428613102368075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.276021005475169e-05, 'l1_Layer_2': 0.001288589705253977, 'l1_Layer_3': 0.0211009942148816, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 15.24 | sMAPE for Test Set is: 19.39% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:36:09,919]\u001b[0m Trial 1231 finished with value: 4.488529539037437 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029484091805314166, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21054230078581276, 'dropout_rate_Layer_2': 0.20897889117629417, 'dropout_rate_Layer_3': 0.2375313409121667, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04904288352288131, 'l1_Layer_2': 1.3740800423211998e-05, 'l1_Layer_3': 0.001989546575323755, 'n_units_Layer_1': 115, 'n_units_Layer_2': 250, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.49 | sMAPE for Validation Set is: 15.69% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 49.87 | sMAPE for Test Set is: 45.90% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:36:18,908]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:19,238]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:25,287]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:25,877]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:26,036]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:31,942]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:35,538]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:37,392]\u001b[0m Trial 1237 finished with value: 4.387607045275477 and parameters: {'n_hidden': 4, 'learning_rate': 0.00203271478456644, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2702317807149266, 'dropout_rate_Layer_2': 0.1873515317388539, 'dropout_rate_Layer_3': 0.38473766011450045, 'dropout_rate_Layer_4': 0.011167125300320711, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3434921025607339e-05, 'l1_Layer_2': 1.3313608205970963e-05, 'l1_Layer_3': 0.004899036536771552, 'l1_Layer_4': 2.3512292548654607e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 270, 'n_units_Layer_4': 70}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.39 | sMAPE for Validation Set is: 15.47% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 15.62 | sMAPE for Test Set is: 20.01% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:36:40,935]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:45,452]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:45,686]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:46,122]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:48,720]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:56,400]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:36:59,519]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:01,966]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:04,431]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:06,820]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:14,051]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:14,260]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:20,437]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:21,518]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:23,622]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:25,610]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:31,175]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:35,278]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:39,579]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:40,581]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:44,126]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:49,389]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:50,146]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:56,214]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:37:57,672]\u001b[0m Trial 1249 finished with value: 3.6761219906895497 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005844757481672004, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15698279030597587, 'dropout_rate_Layer_2': 0.16436208345949171, 'dropout_rate_Layer_3': 0.19542176964453103, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.101972444258216e-05, 'l1_Layer_2': 0.000978568313768245, 'l1_Layer_3': 0.035265070192984554, 'n_units_Layer_1': 270, 'n_units_Layer_2': 225, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 12.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.18 | sMAPE for Test Set is: 18.75% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:37:59,458]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:03,382]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:06,864]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:10,117]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:20,947]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:25,354]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:26,217]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:32,157]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:33,023]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:38,363]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:39,055]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:45,010]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:50,860]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:55,336]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:59,296]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:38:59,940]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:05,465]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:06,310]\u001b[0m Trial 1269 finished with value: 3.5858488847087013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005635131551233264, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1274464754893751, 'dropout_rate_Layer_2': 0.16068437966702145, 'dropout_rate_Layer_3': 0.19137261405922149, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.220646849775693e-05, 'l1_Layer_2': 0.0011599009767954257, 'l1_Layer_3': 0.01758671734352955, 'n_units_Layer_1': 260, 'n_units_Layer_2': 225, 'n_units_Layer_3': 75}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.21 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:39:09,589]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:14,661]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:15,971]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:21,300]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:25,616]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:27,995]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:32,802]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:37,034]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:40,380]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:40,613]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:41,468]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:51,255]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:54,944]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:39:55,127]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:01,099]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:01,163]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:04,240]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:10,039]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:14,560]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:16,845]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:17,006]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:22,425]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:26,062]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:27,294]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:27,490]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:30,889]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:36,748]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:37,058]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:45,026]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:46,044]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:51,315]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:51,509]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:40:53,044]\u001b[0m Trial 1316 finished with value: 4.311562921821572 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032355410332702474, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22619641914405758, 'dropout_rate_Layer_2': 0.17583129455064012, 'dropout_rate_Layer_3': 0.22805494334832138, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.038293468106147185, 'l1_Layer_2': 1.185714336329272e-05, 'l1_Layer_3': 0.0010188570803333972, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.31 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 46.82 | sMAPE for Test Set is: 42.50% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:41:00,364]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:01,332]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:01,493]\u001b[0m Trial 1312 finished with value: 3.8990548724804968 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031800819697917365, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3213347196981769, 'dropout_rate_Layer_2': 0.12320080377797789, 'dropout_rate_Layer_3': 0.36292915237780454, 'dropout_rate_Layer_4': 0.06838899974145668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.3996315119437653e-05, 'l1_Layer_2': 1.6887790004158082e-05, 'l1_Layer_3': 0.004922594296689102, 'l1_Layer_4': 0.00013843514190378162, 'n_units_Layer_1': 55, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235, 'n_units_Layer_4': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 13.86% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 14.83 | sMAPE for Test Set is: 18.91% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:41:07,444]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:11,964]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:12,807]\u001b[0m Trial 1320 finished with value: 4.418592435270963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033089255304804242, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22639039748559808, 'dropout_rate_Layer_2': 0.1779819301360584, 'dropout_rate_Layer_3': 0.19867140038140851, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04026183917464311, 'l1_Layer_2': 2.669614758740154e-05, 'l1_Layer_3': 0.000769692458005863, 'n_units_Layer_1': 165, 'n_units_Layer_2': 270, 'n_units_Layer_3': 55}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.42 | sMAPE for Validation Set is: 15.74% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 45.75 | sMAPE for Test Set is: 41.33% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:41:14,977]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:22,529]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:25,299]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:29,996]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:33,078]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:33,234]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:34,595]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:35,086]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:41,828]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:43,401]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:45,854]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:48,067]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:50,039]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:56,054]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:57,252]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:41:57,652]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:06,966]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:07,158]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:08,157]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:15,807]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:16,394]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:21,667]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:21,853]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:22,130]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:23,493]\u001b[0m Trial 1341 finished with value: 4.279940508777827 and parameters: {'n_hidden': 3, 'learning_rate': 0.004413926208762906, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16479720952007101, 'dropout_rate_Layer_2': 0.15404894521966278, 'dropout_rate_Layer_3': 0.18516645328958303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.029089306955545804, 'l1_Layer_2': 1.823712613438212e-05, 'l1_Layer_3': 0.0012881645236287218, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 50.76 | sMAPE for Test Set is: 46.63% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:42:31,656]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:34,109]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:35,968]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:39,215]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:40,390]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:41,553]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:46,364]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:49,271]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:51,674]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:42:55,602]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:00,762]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:00,849]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:01,708]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:10,243]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:14,445]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:17,501]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:20,658]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:24,320]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:27,694]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:31,219]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:35,604]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:39,332]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:43,332]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:48,937]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:53,198]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:43:56,367]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:02,507]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:05,068]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:18,734]\u001b[0m Trial 1361 finished with value: 3.5872866306508584 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005571407721925901, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 4.369041034986551e-06, 'dropout_rate_Layer_2': 0.16486496275555781, 'dropout_rate_Layer_3': 0.16672320859194067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.170883041623852e-05, 'l1_Layer_2': 0.0009876985344882698, 'l1_Layer_3': 0.03007073134767581, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.35 | sMAPE for Test Set is: 18.77% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:44:22,857]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:26,551]\u001b[0m Trial 1380 finished with value: 4.223492275169854 and parameters: {'n_hidden': 3, 'learning_rate': 0.004150836470213925, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18304537335292762, 'dropout_rate_Layer_2': 0.21751273622138442, 'dropout_rate_Layer_3': 0.1845272772838437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015326619825594618, 'l1_Layer_2': 2.1844243510336037e-05, 'l1_Layer_3': 0.001884566618964326, 'n_units_Layer_1': 135, 'n_units_Layer_2': 275, 'n_units_Layer_3': 70}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.22 | sMAPE for Validation Set is: 14.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.51 | sMAPE for Test Set is: 48.61% | rMAE for Test Set is: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:44:28,776]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:32,514]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:35,033]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:37,313]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:42,240]\u001b[0m Trial 1381 finished with value: 3.8363199868657127 and parameters: {'n_hidden': 4, 'learning_rate': 0.002702957972709402, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29095793856611873, 'dropout_rate_Layer_2': 0.15336217296211258, 'dropout_rate_Layer_3': 0.3674075466731691, 'dropout_rate_Layer_4': 0.041321083028477396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1898106663767794e-05, 'l1_Layer_2': 1.2648594719133193e-05, 'l1_Layer_3': 0.007081817660593596, 'l1_Layer_4': 1.2265973377674561e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 250, 'n_units_Layer_4': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 14.46 | sMAPE for Test Set is: 18.63% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:44:43,339]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:45,903]\u001b[0m Trial 1370 finished with value: 3.523070336251537 and parameters: {'n_hidden': 3, 'learning_rate': 0.000825997590123096, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014176043989085174, 'dropout_rate_Layer_2': 0.16870405094124763, 'dropout_rate_Layer_3': 0.20181190387614445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.556653103582612e-05, 'l1_Layer_2': 0.0015449709578468933, 'l1_Layer_3': 0.019284828573242502, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 270}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 12.31% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.30 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:44:48,552]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:53,503]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:54,892]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:58,787]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:44:59,518]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:02,064]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:04,298]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:11,772]\u001b[0m Trial 1387 finished with value: 4.04939003676093 and parameters: {'n_hidden': 4, 'learning_rate': 0.002729303798441307, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2834147543365521, 'dropout_rate_Layer_2': 0.11884637667675599, 'dropout_rate_Layer_3': 0.33141942254725015, 'dropout_rate_Layer_4': 0.04207664957575971, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007063849054597714, 'l1_Layer_2': 2.874746403439225e-05, 'l1_Layer_3': 0.016130592800513183, 'l1_Layer_4': 1.2726111607166644e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 250, 'n_units_Layer_4': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.05 | sMAPE for Validation Set is: 14.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.36 | sMAPE for Test Set is: 19.81% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:45:12,136]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:18,353]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:21,154]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:24,590]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:25,503]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:27,578]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:28,013]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:35,046]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:35,757]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:36,171]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:36,758]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:45,756]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:47,470]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:47,869]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:51,478]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:45:57,415]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:00,773]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:03,790]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:06,239]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:06,475]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:08,126]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:14,627]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:15,385]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:15,557]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:19,259]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:24,569]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:25,418]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:31,599]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:31,802]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:34,873]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:39,279]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:41,810]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:44,539]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:49,743]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:49,897]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.28 | sMAPE for Validation Set is: 15.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 45.03 | sMAPE for Test Set is: 40.65% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:46:54,252]\u001b[0m Trial 1425 finished with value: 4.278945669255659 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018843589867162539, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1736253214457873, 'dropout_rate_Layer_2': 0.15552763355421773, 'dropout_rate_Layer_3': 0.19588878828195908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014907646600689661, 'l1_Layer_2': 1.0207714265391703e-05, 'l1_Layer_3': 0.0004694683408631574, 'n_units_Layer_1': 130, 'n_units_Layer_2': 285, 'n_units_Layer_3': 50}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:58,748]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:58,795]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:46:59,342]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:00,114]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:04,982]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:10,380]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:18,353]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:20,961]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:23,830]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:28,242]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:32,929]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:37,303]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:38,012]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:39,342]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:47,367]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:51,782]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:55,657]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:47:56,875]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:02,946]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:03,232]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:04,607]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:11,409]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:12,339]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:13,042]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:20,219]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:23,131]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:25,679]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:26,453]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:31,947]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:31,976]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:38,632]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:38,751]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:48,828]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:52,158]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:48:59,356]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:05,872]\u001b[0m Trial 1466 finished with value: 3.619899645447731 and parameters: {'n_hidden': 3, 'learning_rate': 0.005435948430889903, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012603984822041225, 'dropout_rate_Layer_2': 0.03867319534539916, 'dropout_rate_Layer_3': 0.11420842297492646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8075115445012058e-05, 'l1_Layer_2': 0.0001433758437211885, 'l1_Layer_3': 0.005085359776500089, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 65}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 13.85 | sMAPE for Test Set is: 18.35% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:49:06,965]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:09,255]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:10,836]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:18,072]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:18,724]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:25,918]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:26,096]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:27,379]\u001b[0m Trial 1470 finished with value: 4.268023912572374 and parameters: {'n_hidden': 3, 'learning_rate': 0.00195086279157382, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2355028183760159, 'dropout_rate_Layer_2': 0.16495542756742398, 'dropout_rate_Layer_3': 0.21180178882266265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014330439862643882, 'l1_Layer_2': 1.2533736628957701e-05, 'l1_Layer_3': 0.0007081730510883008, 'n_units_Layer_1': 150, 'n_units_Layer_2': 285, 'n_units_Layer_3': 60}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 15.11% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 46.82 | sMAPE for Test Set is: 42.47% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:49:37,339]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:37,513]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:45,731]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:49,158]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:54,942]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:49:58,246]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:04,202]\u001b[0m Trial 1483 finished with value: 4.6377500896002255 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021956016564937245, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.301447911320055, 'dropout_rate_Layer_2': 0.15074346430541766, 'dropout_rate_Layer_3': 0.3888671973764347, 'dropout_rate_Layer_4': 0.3947788007626058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.7889925632854565e-05, 'l1_Layer_2': 1.6472287852027236e-05, 'l1_Layer_3': 0.005241430060791272, 'l1_Layer_4': 2.227441183318537e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230, 'n_units_Layer_4': 80}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 16.21% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.22 | sMAPE for Test Set is: 22.28% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:50:11,590]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:15,756]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:16,970]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:21,690]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:22,527]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:28,238]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:30,732]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:32,067]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 12.56% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:50:33,825]\u001b[0m Trial 1472 finished with value: 3.5878153775445596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006175425285600136, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007509965021401729, 'dropout_rate_Layer_2': 0.21263877298793302, 'dropout_rate_Layer_3': 0.16131239757030738, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.0586774816848885e-05, 'l1_Layer_2': 0.0005285192216758126, 'l1_Layer_3': 0.01916482879739951, 'n_units_Layer_1': 250, 'n_units_Layer_2': 230, 'n_units_Layer_3': 70}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:36,331]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:42,102]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:42,317]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:48,086]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:50,845]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:52,070]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 05:50:54,353]\u001b[0m Trial 1480 finished with value: 3.6315865332867774 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005458013525717152, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005234377961240709, 'dropout_rate_Layer_2': 0.19292934779942997, 'dropout_rate_Layer_3': 0.1977173383973358, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5204747338160076e-05, 'l1_Layer_2': 0.000973246140388409, 'l1_Layer_3': 0.014286959993849012, 'n_units_Layer_1': 270, 'n_units_Layer_2': 210, 'n_units_Layer_3': 190}. Best is trial 816 with value: 3.5164071083472845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 12.70% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 14.20 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 05:51:04,431]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-01-01, MAE is:4.46 & sMAPE is:10.35% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 10.35% & 0.17\n",
      "for 2021-01-02, MAE is:2.46 & sMAPE is:4.85% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 7.60% & 0.16\n",
      "for 2021-01-03, MAE is:3.71 & sMAPE is:7.82% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 7.67% & 0.17\n",
      "for 2021-01-04, MAE is:7.73 & sMAPE is:13.22% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 9.06% & 0.17\n",
      "for 2021-01-05, MAE is:11.47 & sMAPE is:17.99% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 10.85% & 0.22\n",
      "for 2021-01-06, MAE is:9.15 & sMAPE is:13.18% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 11.24% & 0.25\n",
      "for 2021-01-07, MAE is:16.36 & sMAPE is:18.85% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 12.32% & 0.28\n",
      "for 2021-01-08, MAE is:13.73 & sMAPE is:14.89% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 12.64% & 0.27\n",
      "for 2021-01-09, MAE is:17.48 & sMAPE is:21.94% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 13.68% & 0.30\n",
      "for 2021-01-10, MAE is:28.83 & sMAPE is:38.80% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :11.54 & 16.19% & 0.42\n",
      "for 2021-01-11, MAE is:13.28 & sMAPE is:16.92% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.70 & 16.26% & 0.44\n",
      "for 2021-01-12, MAE is:10.80 & sMAPE is:13.62% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :11.62 & 16.04% & 0.46\n",
      "for 2021-01-13, MAE is:10.87 & sMAPE is:12.12% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :11.56 & 15.73% & 0.46\n",
      "for 2021-01-14, MAE is:7.33 & sMAPE is:9.04% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 15.26% & 0.52\n",
      "for 2021-01-15, MAE is:15.78 & sMAPE is:19.47% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :11.56 & 15.54% & 0.55\n",
      "for 2021-01-16, MAE is:10.84 & sMAPE is:15.60% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :11.52 & 15.54% & 0.57\n",
      "for 2021-01-17, MAE is:7.81 & sMAPE is:11.69% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 15.32% & 0.59\n",
      "for 2021-01-18, MAE is:9.18 & sMAPE is:11.47% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 15.10% & 0.60\n",
      "for 2021-01-19, MAE is:6.78 & sMAPE is:9.04% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :10.95 & 14.78% & 0.60\n",
      "for 2021-01-20, MAE is:15.89 & sMAPE is:27.37% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 15.41% & 0.59\n",
      "for 2021-01-21, MAE is:9.56 & sMAPE is:32.43% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :11.12 & 16.22% & 0.57\n",
      "for 2021-01-22, MAE is:3.55 & sMAPE is:8.66% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.78 & 15.88% & 0.55\n",
      "for 2021-01-23, MAE is:15.63 & sMAPE is:49.93% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 17.36% & 0.54\n",
      "for 2021-01-24, MAE is:10.98 & sMAPE is:51.88% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 18.80% & 0.53\n",
      "for 2021-01-25, MAE is:14.05 & sMAPE is:25.79% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 19.08% & 0.54\n",
      "for 2021-01-26, MAE is:6.56 & sMAPE is:10.32% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :10.93 & 18.74% & 0.54\n",
      "for 2021-01-27, MAE is:5.03 & sMAPE is:8.80% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.72 & 18.37% & 0.54\n",
      "for 2021-01-28, MAE is:4.61 & sMAPE is:8.38% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 18.02% & 0.54\n",
      "for 2021-01-29, MAE is:5.21 & sMAPE is:11.24% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.31 & 17.78% & 0.54\n",
      "for 2021-01-30, MAE is:34.32 & sMAPE is:164.02% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 22.66% & 0.57\n",
      "for 2021-01-31, MAE is:9.14 & sMAPE is:155.83% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.05 & 26.95% & 0.57\n",
      "for 2021-02-01, MAE is:7.67 & sMAPE is:100.42% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.95 & 29.25% & 0.55\n",
      "for 2021-02-02, MAE is:7.19 & sMAPE is:31.38% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.83 & 29.31% & 0.54\n",
      "for 2021-02-03, MAE is:10.96 & sMAPE is:34.32% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.84 & 29.46% & 0.54\n",
      "for 2021-02-04, MAE is:13.84 & sMAPE is:29.35% & rMAE is:2.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 29.46% & 0.60\n",
      "for 2021-02-05, MAE is:5.16 & sMAPE is:10.42% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :10.76 & 28.93% & 0.62\n",
      "for 2021-02-06, MAE is:3.97 & sMAPE is:10.67% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :10.58 & 28.43% & 0.60\n",
      "for 2021-02-07, MAE is:14.66 & sMAPE is:91.48% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :10.69 & 30.09% & 0.62\n",
      "for 2021-02-08, MAE is:6.42 & sMAPE is:75.27% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :10.58 & 31.25% & 0.64\n",
      "for 2021-02-09, MAE is:4.77 & sMAPE is:82.20% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 32.53% & 0.63\n",
      "for 2021-02-10, MAE is:19.88 & sMAPE is:127.34% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.66 & 34.84% & 0.65\n",
      "for 2021-02-11, MAE is:11.52 & sMAPE is:33.36% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :10.68 & 34.80% & 0.66\n",
      "for 2021-02-12, MAE is:14.17 & sMAPE is:42.38% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :10.76 & 34.98% & 0.67\n",
      "for 2021-02-13, MAE is:9.67 & sMAPE is:31.19% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :10.74 & 34.89% & 0.67\n",
      "for 2021-02-14, MAE is:28.07 & sMAPE is:108.50% & rMAE is:3.36 ||| daily mean of MAE & sMAPE & rMAE till now are :11.12 & 36.53% & 0.73\n",
      "for 2021-02-15, MAE is:9.58 & sMAPE is:88.75% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :11.09 & 37.66% & 0.74\n",
      "for 2021-02-16, MAE is:14.54 & sMAPE is:80.00% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 38.57% & 0.74\n",
      "for 2021-02-17, MAE is:10.89 & sMAPE is:28.08% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 38.35% & 0.74\n",
      "for 2021-02-18, MAE is:9.76 & sMAPE is:38.46% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 38.35% & 0.74\n",
      "for 2021-02-19, MAE is:18.07 & sMAPE is:63.38% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 38.85% & 0.75\n",
      "for 2021-02-20, MAE is:18.31 & sMAPE is:170.20% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :11.41 & 41.43% & 0.74\n",
      "for 2021-02-21, MAE is:4.07 & sMAPE is:107.97% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 42.70% & 0.74\n",
      "for 2021-02-22, MAE is:29.73 & sMAPE is:129.86% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :11.61 & 44.35% & 0.75\n",
      "for 2021-02-23, MAE is:6.28 & sMAPE is:14.31% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.51 & 43.79% & 0.74\n",
      "for 2021-02-24, MAE is:12.87 & sMAPE is:54.95% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :11.54 & 44.00% & 0.74\n",
      "for 2021-02-25, MAE is:11.36 & sMAPE is:28.14% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :11.54 & 43.71% & 0.74\n",
      "for 2021-02-26, MAE is:6.98 & sMAPE is:15.44% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :11.46 & 43.22% & 0.73\n",
      "for 2021-02-27, MAE is:7.45 & sMAPE is:23.65% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :11.39 & 42.88% & 0.73\n",
      "for 2021-02-28, MAE is:8.74 & sMAPE is:42.70% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :11.34 & 42.88% & 0.73\n",
      "for 2021-03-01, MAE is:15.86 & sMAPE is:47.50% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :11.42 & 42.95% & 0.76\n",
      "for 2021-03-02, MAE is:9.15 & sMAPE is:18.53% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 42.55% & 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-03, MAE is:6.48 & sMAPE is:12.10% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 42.06% & 0.75\n",
      "for 2021-03-04, MAE is:5.63 & sMAPE is:10.30% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.21 & 41.56% & 0.75\n",
      "for 2021-03-05, MAE is:5.07 & sMAPE is:9.57% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 41.06% & 0.75\n",
      "for 2021-03-06, MAE is:4.74 & sMAPE is:10.71% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :11.02 & 40.59% & 0.75\n",
      "for 2021-03-07, MAE is:4.89 & sMAPE is:10.63% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 40.14% & 0.74\n",
      "for 2021-03-08, MAE is:6.19 & sMAPE is:11.85% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.85 & 39.71% & 0.73\n",
      "for 2021-03-09, MAE is:6.89 & sMAPE is:12.48% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.79 & 39.31% & 0.74\n",
      "for 2021-03-10, MAE is:4.45 & sMAPE is:7.89% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 38.86% & 0.75\n",
      "for 2021-03-11, MAE is:9.44 & sMAPE is:23.78% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :10.68 & 38.64% & 0.75\n",
      "for 2021-03-12, MAE is:8.10 & sMAPE is:20.76% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.65 & 38.39% & 0.75\n",
      "for 2021-03-13, MAE is:13.16 & sMAPE is:44.28% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.68 & 38.47% & 0.75\n",
      "for 2021-03-14, MAE is:11.87 & sMAPE is:48.05% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 38.60% & 0.74\n",
      "for 2021-03-15, MAE is:7.41 & sMAPE is:16.95% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :10.65 & 38.31% & 0.75\n",
      "for 2021-03-16, MAE is:10.96 & sMAPE is:28.80% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.66 & 38.18% & 0.74\n",
      "for 2021-03-17, MAE is:18.27 & sMAPE is:70.00% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.76 & 38.60% & 0.74\n",
      "for 2021-03-18, MAE is:14.94 & sMAPE is:62.72% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :10.81 & 38.92% & 0.75\n",
      "for 2021-03-19, MAE is:5.77 & sMAPE is:19.05% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.75 & 38.66% & 0.75\n",
      "for 2021-03-20, MAE is:8.85 & sMAPE is:36.23% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.72 & 38.63% & 0.75\n",
      "for 2021-03-21, MAE is:9.24 & sMAPE is:30.05% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.71 & 38.52% & 0.76\n",
      "for 2021-03-22, MAE is:13.94 & sMAPE is:28.78% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :10.75 & 38.40% & 0.77\n",
      "for 2021-03-23, MAE is:10.40 & sMAPE is:17.00% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.74 & 38.14% & 0.77\n",
      "for 2021-03-24, MAE is:5.35 & sMAPE is:8.20% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.68 & 37.78% & 0.76\n",
      "for 2021-03-25, MAE is:9.55 & sMAPE is:15.10% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.66 & 37.51% & 0.75\n",
      "for 2021-03-26, MAE is:4.41 & sMAPE is:7.44% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.59 & 37.16% & 0.75\n",
      "for 2021-03-27, MAE is:11.19 & sMAPE is:26.30% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :10.60 & 37.03% & 0.75\n",
      "for 2021-03-28, MAE is:8.68 & sMAPE is:22.27% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 36.86% & 0.75\n",
      "for 2021-03-29, MAE is:10.52 & sMAPE is:23.98% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 36.72% & 0.75\n",
      "for 2021-03-30, MAE is:9.80 & sMAPE is:19.03% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 36.52% & 0.75\n",
      "for 2021-03-31, MAE is:7.44 & sMAPE is:13.74% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 36.26% & 0.75\n",
      "for 2021-04-01, MAE is:6.13 & sMAPE is:11.82% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.48 & 36.00% & 0.75\n",
      "for 2021-04-02, MAE is:6.71 & sMAPE is:13.42% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 35.75% & 0.75\n",
      "for 2021-04-03, MAE is:11.05 & sMAPE is:35.72% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 35.75% & 0.75\n",
      "for 2021-04-04, MAE is:9.70 & sMAPE is:44.23% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 35.84% & 0.75\n",
      "for 2021-04-05, MAE is:8.71 & sMAPE is:20.61% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 35.68% & 0.75\n",
      "for 2021-04-06, MAE is:9.51 & sMAPE is:17.97% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 35.50% & 0.76\n",
      "for 2021-04-07, MAE is:14.47 & sMAPE is:24.52% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 35.38% & 0.77\n",
      "for 2021-04-08, MAE is:7.19 & sMAPE is:10.55% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 35.13% & 0.77\n",
      "for 2021-04-09, MAE is:6.58 & sMAPE is:9.26% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 34.87% & 0.76\n",
      "for 2021-04-10, MAE is:5.16 & sMAPE is:8.14% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 34.60% & 0.75\n",
      "for 2021-04-11, MAE is:5.18 & sMAPE is:10.44% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 34.36% & 0.75\n",
      "for 2021-04-12, MAE is:11.07 & sMAPE is:18.77% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :10.29 & 34.21% & 0.75\n",
      "for 2021-04-13, MAE is:9.81 & sMAPE is:13.57% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 34.01% & 0.75\n",
      "for 2021-04-14, MAE is:5.61 & sMAPE is:7.58% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 33.75% & 0.74\n",
      "for 2021-04-15, MAE is:3.97 & sMAPE is:5.87% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 33.49% & 0.75\n",
      "for 2021-04-16, MAE is:8.15 & sMAPE is:12.37% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 33.29% & 0.76\n",
      "for 2021-04-17, MAE is:6.00 & sMAPE is:9.45% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :10.12 & 33.07% & 0.77\n",
      "for 2021-04-18, MAE is:6.22 & sMAPE is:9.52% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 32.85% & 0.77\n",
      "for 2021-04-19, MAE is:5.91 & sMAPE is:7.62% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.05 & 32.62% & 0.76\n",
      "for 2021-04-20, MAE is:7.38 & sMAPE is:9.38% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 32.41% & 0.77\n",
      "for 2021-04-21, MAE is:6.99 & sMAPE is:8.97% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.99 & 32.19% & 0.78\n",
      "for 2021-04-22, MAE is:6.31 & sMAPE is:8.56% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :9.96 & 31.98% & 0.78\n",
      "for 2021-04-23, MAE is:10.16 & sMAPE is:14.85% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :9.96 & 31.83% & 0.79\n",
      "for 2021-04-24, MAE is:7.89 & sMAPE is:14.04% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 31.68% & 0.79\n",
      "for 2021-04-25, MAE is:7.38 & sMAPE is:11.64% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.92 & 31.50% & 0.80\n",
      "for 2021-04-26, MAE is:4.76 & sMAPE is:6.42% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.88 & 31.28% & 0.81\n",
      "for 2021-04-27, MAE is:5.82 & sMAPE is:7.70% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 31.08% & 0.81\n",
      "for 2021-04-28, MAE is:4.88 & sMAPE is:6.70% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :9.80 & 30.88% & 0.81\n",
      "for 2021-04-29, MAE is:5.81 & sMAPE is:7.81% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.77 & 30.68% & 0.82\n",
      "for 2021-04-30, MAE is:8.00 & sMAPE is:10.48% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 30.51% & 0.82\n",
      "for 2021-05-01, MAE is:8.41 & sMAPE is:13.85% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 30.38% & 0.84\n",
      "for 2021-05-02, MAE is:6.25 & sMAPE is:9.92% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 30.21% & 0.84\n",
      "for 2021-05-03, MAE is:9.35 & sMAPE is:13.08% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 30.07% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-04, MAE is:6.34 & sMAPE is:8.07% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 29.89% & 0.85\n",
      "for 2021-05-05, MAE is:5.49 & sMAPE is:7.30% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :9.65 & 29.71% & 0.86\n",
      "for 2021-05-06, MAE is:5.74 & sMAPE is:7.83% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 29.54% & 0.87\n",
      "for 2021-05-07, MAE is:7.91 & sMAPE is:10.88% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 29.39% & 0.87\n",
      "for 2021-05-08, MAE is:26.09 & sMAPE is:59.02% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.73 & 29.62% & 0.87\n",
      "for 2021-05-09, MAE is:36.17 & sMAPE is:151.75% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 30.57% & 0.87\n",
      "for 2021-05-10, MAE is:21.81 & sMAPE is:44.33% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.03 & 30.68% & 0.87\n",
      "for 2021-05-11, MAE is:14.04 & sMAPE is:26.82% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 30.65% & 0.87\n",
      "for 2021-05-12, MAE is:16.17 & sMAPE is:34.93% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.11 & 30.68% & 0.87\n",
      "for 2021-05-13, MAE is:9.82 & sMAPE is:17.50% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 30.58% & 0.87\n",
      "for 2021-05-14, MAE is:7.53 & sMAPE is:10.64% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 30.43% & 0.88\n",
      "for 2021-05-15, MAE is:21.90 & sMAPE is:58.73% & rMAE is:2.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.17 & 30.64% & 0.89\n",
      "for 2021-05-16, MAE is:25.97 & sMAPE is:84.87% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.29 & 31.04% & 0.90\n",
      "for 2021-05-17, MAE is:21.73 & sMAPE is:32.34% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.37 & 31.05% & 0.90\n",
      "for 2021-05-18, MAE is:7.67 & sMAPE is:10.12% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 30.90% & 0.90\n",
      "for 2021-05-19, MAE is:9.00 & sMAPE is:11.75% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 30.76% & 0.89\n",
      "for 2021-05-20, MAE is:7.69 & sMAPE is:9.81% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 30.61% & 0.89\n",
      "for 2021-05-21, MAE is:12.59 & sMAPE is:19.39% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 30.53% & 0.89\n",
      "for 2021-05-22, MAE is:12.15 & sMAPE is:19.10% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 30.45% & 0.89\n",
      "for 2021-05-23, MAE is:8.70 & sMAPE is:12.83% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 30.33% & 0.88\n",
      "for 2021-05-24, MAE is:8.28 & sMAPE is:12.11% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 30.20% & 0.88\n",
      "for 2021-05-25, MAE is:6.14 & sMAPE is:8.35% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 30.05% & 0.89\n",
      "for 2021-05-26, MAE is:7.59 & sMAPE is:9.83% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 29.91% & 0.89\n",
      "for 2021-05-27, MAE is:10.07 & sMAPE is:12.45% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 29.79% & 0.89\n",
      "for 2021-05-28, MAE is:6.43 & sMAPE is:7.49% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 29.64% & 0.89\n",
      "for 2021-05-29, MAE is:7.09 & sMAPE is:9.04% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 29.50% & 0.88\n",
      "for 2021-05-30, MAE is:7.58 & sMAPE is:10.27% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 29.37% & 0.88\n",
      "for 2021-05-31, MAE is:5.83 & sMAPE is:6.89% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 29.23% & 0.88\n",
      "for 2021-06-01, MAE is:5.18 & sMAPE is:6.14% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :10.15 & 29.07% & 0.88\n",
      "for 2021-06-02, MAE is:5.09 & sMAPE is:5.95% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :10.12 & 28.92% & 0.88\n",
      "for 2021-06-03, MAE is:5.95 & sMAPE is:7.68% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 28.78% & 0.88\n",
      "for 2021-06-04, MAE is:4.51 & sMAPE is:5.66% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 28.64% & 0.88\n",
      "for 2021-06-05, MAE is:4.58 & sMAPE is:6.03% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 28.49% & 0.87\n",
      "for 2021-06-06, MAE is:7.23 & sMAPE is:10.88% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 28.38% & 0.88\n",
      "for 2021-06-07, MAE is:4.70 & sMAPE is:6.01% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :9.97 & 28.24% & 0.88\n",
      "for 2021-06-08, MAE is:5.11 & sMAPE is:6.29% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 28.10% & 0.88\n",
      "for 2021-06-09, MAE is:4.04 & sMAPE is:5.04% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :9.90 & 27.95% & 0.88\n",
      "for 2021-06-10, MAE is:6.69 & sMAPE is:8.29% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :9.88 & 27.83% & 0.88\n",
      "for 2021-06-11, MAE is:3.71 & sMAPE is:4.51% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 27.69% & 0.88\n",
      "for 2021-06-12, MAE is:5.39 & sMAPE is:6.89% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 27.56% & 0.88\n",
      "for 2021-06-13, MAE is:5.55 & sMAPE is:6.98% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.79 & 27.44% & 0.88\n",
      "for 2021-06-14, MAE is:4.14 & sMAPE is:4.77% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.76 & 27.30% & 0.87\n",
      "for 2021-06-15, MAE is:6.56 & sMAPE is:7.45% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 27.18% & 0.87\n",
      "for 2021-06-16, MAE is:6.19 & sMAPE is:6.70% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.72 & 27.06% & 0.87\n",
      "for 2021-06-17, MAE is:5.30 & sMAPE is:5.79% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 26.93% & 0.87\n",
      "for 2021-06-18, MAE is:3.42 & sMAPE is:3.71% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.65 & 26.79% & 0.87\n",
      "for 2021-06-19, MAE is:6.12 & sMAPE is:7.32% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.63 & 26.68% & 0.86\n",
      "for 2021-06-20, MAE is:26.72 & sMAPE is:49.68% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :9.73 & 26.81% & 0.87\n",
      "for 2021-06-21, MAE is:12.30 & sMAPE is:15.51% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 26.75% & 0.87\n",
      "for 2021-06-22, MAE is:3.83 & sMAPE is:4.37% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 26.62% & 0.87\n",
      "for 2021-06-23, MAE is:4.07 & sMAPE is:4.65% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 26.49% & 0.87\n",
      "for 2021-06-24, MAE is:4.85 & sMAPE is:5.78% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.65 & 26.37% & 0.87\n",
      "for 2021-06-25, MAE is:5.58 & sMAPE is:6.45% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.63 & 26.26% & 0.87\n",
      "for 2021-06-26, MAE is:8.52 & sMAPE is:10.44% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 26.17% & 0.88\n",
      "for 2021-06-27, MAE is:18.10 & sMAPE is:33.11% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.67 & 26.21% & 0.88\n",
      "for 2021-06-28, MAE is:10.36 & sMAPE is:12.43% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.67 & 26.13% & 0.89\n",
      "for 2021-06-29, MAE is:4.15 & sMAPE is:4.52% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :9.64 & 26.01% & 0.89\n",
      "for 2021-06-30, MAE is:5.10 & sMAPE is:5.56% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 25.90% & 0.89\n",
      "for 2021-07-01, MAE is:4.09 & sMAPE is:4.46% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.59 & 25.78% & 0.89\n",
      "for 2021-07-02, MAE is:10.93 & sMAPE is:11.51% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 25.70% & 0.89\n",
      "for 2021-07-03, MAE is:6.20 & sMAPE is:6.77% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 25.60% & 0.89\n",
      "for 2021-07-04, MAE is:11.12 & sMAPE is:13.78% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.59 & 25.54% & 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-05, MAE is:6.43 & sMAPE is:7.00% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 25.44% & 0.88\n",
      "for 2021-07-06, MAE is:5.66 & sMAPE is:6.22% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 25.33% & 0.89\n",
      "for 2021-07-07, MAE is:3.65 & sMAPE is:3.70% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 25.22% & 0.88\n",
      "for 2021-07-08, MAE is:4.00 & sMAPE is:4.42% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :9.49 & 25.11% & 0.88\n",
      "for 2021-07-09, MAE is:4.23 & sMAPE is:4.62% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.46 & 25.00% & 0.88\n",
      "for 2021-07-10, MAE is:6.91 & sMAPE is:7.81% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 24.91% & 0.89\n",
      "for 2021-07-11, MAE is:9.92 & sMAPE is:11.30% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 24.84% & 0.89\n",
      "for 2021-07-12, MAE is:10.48 & sMAPE is:12.08% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 24.77% & 0.89\n",
      "for 2021-07-13, MAE is:6.93 & sMAPE is:7.58% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 24.68% & 0.89\n",
      "for 2021-07-14, MAE is:8.83 & sMAPE is:10.22% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 24.61% & 0.89\n",
      "for 2021-07-15, MAE is:7.28 & sMAPE is:8.30% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 24.53% & 0.89\n",
      "for 2021-07-16, MAE is:5.04 & sMAPE is:5.91% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 24.43% & 0.89\n",
      "for 2021-07-17, MAE is:8.56 & sMAPE is:9.85% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 24.36% & 0.89\n",
      "for 2021-07-18, MAE is:15.74 & sMAPE is:24.84% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 24.36% & 0.89\n",
      "for 2021-07-19, MAE is:12.23 & sMAPE is:13.26% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 24.31% & 0.89\n",
      "for 2021-07-20, MAE is:4.25 & sMAPE is:4.25% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 24.21% & 0.89\n",
      "for 2021-07-21, MAE is:7.70 & sMAPE is:7.54% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 24.12% & 0.89\n",
      "for 2021-07-22, MAE is:4.37 & sMAPE is:4.29% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 24.03% & 0.88\n",
      "for 2021-07-23, MAE is:8.64 & sMAPE is:9.22% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 23.95% & 0.88\n",
      "for 2021-07-24, MAE is:5.61 & sMAPE is:6.21% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 23.87% & 0.88\n",
      "for 2021-07-25, MAE is:6.90 & sMAPE is:7.46% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 23.79% & 0.88\n",
      "for 2021-07-26, MAE is:3.54 & sMAPE is:3.59% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 23.69% & 0.88\n",
      "for 2021-07-27, MAE is:4.95 & sMAPE is:4.97% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 23.60% & 0.88\n",
      "for 2021-07-28, MAE is:7.29 & sMAPE is:7.90% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 23.52% & 0.88\n",
      "for 2021-07-29, MAE is:8.48 & sMAPE is:9.02% & rMAE is:2.86 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 23.46% & 0.89\n",
      "for 2021-07-30, MAE is:7.66 & sMAPE is:8.44% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 23.38% & 0.89\n",
      "for 2021-07-31, MAE is:25.22 & sMAPE is:40.48% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 23.47% & 0.89\n",
      "for 2021-08-01, MAE is:12.93 & sMAPE is:16.99% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 23.43% & 0.89\n",
      "for 2021-08-02, MAE is:7.93 & sMAPE is:8.14% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 23.36% & 0.89\n",
      "for 2021-08-03, MAE is:8.42 & sMAPE is:8.31% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 23.29% & 0.90\n",
      "for 2021-08-04, MAE is:5.17 & sMAPE is:5.00% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 23.21% & 0.89\n",
      "for 2021-08-05, MAE is:9.21 & sMAPE is:9.37% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 23.14% & 0.90\n",
      "for 2021-08-06, MAE is:8.45 & sMAPE is:9.10% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 23.08% & 0.90\n",
      "for 2021-08-07, MAE is:25.19 & sMAPE is:47.42% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 23.19% & 0.91\n",
      "for 2021-08-08, MAE is:12.97 & sMAPE is:15.52% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 23.16% & 0.91\n",
      "for 2021-08-09, MAE is:7.40 & sMAPE is:7.24% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 23.08% & 0.91\n",
      "for 2021-08-10, MAE is:6.69 & sMAPE is:6.16% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 23.01% & 0.91\n",
      "for 2021-08-11, MAE is:5.86 & sMAPE is:5.21% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 22.93% & 0.91\n",
      "for 2021-08-12, MAE is:5.87 & sMAPE is:5.04% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 22.85% & 0.91\n",
      "for 2021-08-13, MAE is:7.16 & sMAPE is:6.21% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 22.77% & 0.91\n",
      "for 2021-08-14, MAE is:11.97 & sMAPE is:10.79% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 22.72% & 0.90\n",
      "for 2021-08-15, MAE is:10.33 & sMAPE is:9.74% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 22.66% & 0.90\n",
      "for 2021-08-16, MAE is:19.41 & sMAPE is:19.82% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 22.65% & 0.90\n",
      "for 2021-08-17, MAE is:6.07 & sMAPE is:6.52% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 22.58% & 0.90\n",
      "for 2021-08-18, MAE is:12.35 & sMAPE is:11.79% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 22.53% & 0.90\n",
      "for 2021-08-19, MAE is:9.10 & sMAPE is:8.29% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 22.47% & 0.90\n",
      "for 2021-08-20, MAE is:6.33 & sMAPE is:5.48% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 22.40% & 0.90\n",
      "for 2021-08-21, MAE is:6.78 & sMAPE is:6.24% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 22.33% & 0.91\n",
      "for 2021-08-22, MAE is:9.03 & sMAPE is:8.90% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 22.27% & 0.90\n",
      "for 2021-08-23, MAE is:7.03 & sMAPE is:7.00% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 22.21% & 0.90\n",
      "for 2021-08-24, MAE is:10.41 & sMAPE is:10.13% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 22.16% & 0.90\n",
      "for 2021-08-25, MAE is:10.31 & sMAPE is:9.32% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 22.10% & 0.90\n",
      "for 2021-08-26, MAE is:5.76 & sMAPE is:4.89% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 22.03% & 0.90\n",
      "for 2021-08-27, MAE is:6.26 & sMAPE is:5.33% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 21.96% & 0.91\n",
      "for 2021-08-28, MAE is:12.95 & sMAPE is:12.01% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 21.92% & 0.91\n",
      "for 2021-08-29, MAE is:9.57 & sMAPE is:9.15% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 21.87% & 0.91\n",
      "for 2021-08-30, MAE is:13.27 & sMAPE is:11.39% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 21.82% & 0.91\n",
      "for 2021-08-31, MAE is:8.04 & sMAPE is:6.42% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 21.76% & 0.90\n",
      "for 2021-09-01, MAE is:7.96 & sMAPE is:6.17% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 21.70% & 0.90\n",
      "for 2021-09-02, MAE is:5.64 & sMAPE is:4.16% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 21.62% & 0.90\n",
      "for 2021-09-03, MAE is:8.52 & sMAPE is:6.21% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 21.56% & 0.90\n",
      "for 2021-09-04, MAE is:15.14 & sMAPE is:11.57% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 21.52% & 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-05, MAE is:15.45 & sMAPE is:12.24% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 21.48% & 0.90\n",
      "for 2021-09-06, MAE is:12.75 & sMAPE is:9.57% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 21.44% & 0.90\n",
      "for 2021-09-07, MAE is:14.14 & sMAPE is:11.16% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 21.39% & 0.90\n",
      "for 2021-09-08, MAE is:8.18 & sMAPE is:6.15% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 21.33% & 0.90\n",
      "for 2021-09-09, MAE is:5.04 & sMAPE is:3.60% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 21.26% & 0.90\n",
      "for 2021-09-10, MAE is:10.70 & sMAPE is:7.35% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 21.21% & 0.90\n",
      "for 2021-09-11, MAE is:9.90 & sMAPE is:6.80% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 21.15% & 0.90\n",
      "for 2021-09-12, MAE is:17.11 & sMAPE is:12.31% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.46 & 21.12% & 0.90\n",
      "for 2021-09-13, MAE is:6.92 & sMAPE is:4.57% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 21.05% & 0.89\n",
      "for 2021-09-14, MAE is:12.53 & sMAPE is:8.59% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.46 & 21.00% & 0.89\n",
      "for 2021-09-15, MAE is:19.07 & sMAPE is:11.73% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 20.97% & 0.89\n",
      "for 2021-09-16, MAE is:21.81 & sMAPE is:12.37% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 20.93% & 0.89\n",
      "for 2021-09-17, MAE is:23.29 & sMAPE is:13.35% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 20.91% & 0.89\n",
      "for 2021-09-18, MAE is:17.00 & sMAPE is:10.90% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :9.63 & 20.87% & 0.89\n",
      "for 2021-09-19, MAE is:24.79 & sMAPE is:17.38% & rMAE is:3.29 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 20.85% & 0.90\n",
      "for 2021-09-20, MAE is:17.37 & sMAPE is:10.86% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.72 & 20.82% & 0.91\n",
      "for 2021-09-21, MAE is:19.36 & sMAPE is:12.74% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 20.79% & 0.91\n",
      "for 2021-09-22, MAE is:23.55 & sMAPE is:14.15% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.80 & 20.76% & 0.91\n",
      "for 2021-09-23, MAE is:14.49 & sMAPE is:9.06% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 20.72% & 0.91\n",
      "for 2021-09-24, MAE is:7.73 & sMAPE is:4.56% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 20.66% & 0.91\n",
      "for 2021-09-25, MAE is:15.97 & sMAPE is:10.02% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 20.62% & 0.91\n",
      "for 2021-09-26, MAE is:18.73 & sMAPE is:11.95% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 20.58% & 0.91\n",
      "for 2021-09-27, MAE is:10.54 & sMAPE is:6.30% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 20.53% & 0.91\n",
      "for 2021-09-28, MAE is:13.95 & sMAPE is:7.96% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 20.48% & 0.91\n",
      "for 2021-09-29, MAE is:18.12 & sMAPE is:9.99% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :9.92 & 20.45% & 0.91\n",
      "for 2021-09-30, MAE is:17.43 & sMAPE is:9.46% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.95 & 20.41% & 0.91\n",
      "for 2021-10-01, MAE is:19.10 & sMAPE is:9.26% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :9.98 & 20.37% & 0.91\n",
      "for 2021-10-02, MAE is:48.17 & sMAPE is:29.45% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.12 & 20.40% & 0.91\n",
      "for 2021-10-03, MAE is:54.71 & sMAPE is:48.31% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 20.50% & 0.91\n",
      "for 2021-10-04, MAE is:38.44 & sMAPE is:21.70% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 20.50% & 0.91\n",
      "for 2021-10-05, MAE is:22.41 & sMAPE is:10.88% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 20.47% & 0.91\n",
      "for 2021-10-06, MAE is:23.77 & sMAPE is:10.75% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 20.43% & 0.91\n",
      "for 2021-10-07, MAE is:58.94 & sMAPE is:22.73% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :10.65 & 20.44% & 0.91\n",
      "for 2021-10-08, MAE is:46.94 & sMAPE is:19.33% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.77 & 20.44% & 0.92\n",
      "for 2021-10-09, MAE is:17.50 & sMAPE is:7.85% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.80 & 20.39% & 0.91\n",
      "for 2021-10-10, MAE is:38.86 & sMAPE is:21.12% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.90 & 20.40% & 0.91\n",
      "for 2021-10-11, MAE is:33.17 & sMAPE is:18.15% & rMAE is:3.04 ||| daily mean of MAE & sMAPE & rMAE till now are :10.98 & 20.39% & 0.92\n",
      "for 2021-10-12, MAE is:16.04 & sMAPE is:8.65% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 20.35% & 0.92\n",
      "for 2021-10-13, MAE is:25.27 & sMAPE is:13.70% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 20.32% & 0.92\n",
      "for 2021-10-14, MAE is:20.24 & sMAPE is:9.63% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 20.29% & 0.92\n",
      "for 2021-10-15, MAE is:17.41 & sMAPE is:7.60% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 20.24% & 0.92\n",
      "for 2021-10-16, MAE is:15.66 & sMAPE is:6.92% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 20.20% & 0.92\n",
      "for 2021-10-17, MAE is:25.11 & sMAPE is:11.61% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 20.17% & 0.92\n",
      "for 2021-10-18, MAE is:20.03 & sMAPE is:8.74% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 20.13% & 0.92\n",
      "for 2021-10-19, MAE is:30.58 & sMAPE is:14.36% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 20.11% & 0.92\n",
      "for 2021-10-20, MAE is:27.29 & sMAPE is:13.54% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :11.31 & 20.09% & 0.92\n",
      "for 2021-10-21, MAE is:19.78 & sMAPE is:9.43% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :11.34 & 20.05% & 0.93\n",
      "for 2021-10-22, MAE is:19.62 & sMAPE is:9.54% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :11.37 & 20.01% & 0.93\n",
      "for 2021-10-23, MAE is:18.46 & sMAPE is:8.63% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :11.39 & 19.98% & 0.93\n",
      "for 2021-10-24, MAE is:18.55 & sMAPE is:8.61% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :11.42 & 19.94% & 0.93\n",
      "for 2021-10-25, MAE is:15.08 & sMAPE is:6.58% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.43 & 19.89% & 0.93\n",
      "for 2021-10-26, MAE is:23.37 & sMAPE is:10.80% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :11.47 & 19.86% & 0.93\n",
      "for 2021-10-27, MAE is:21.62 & sMAPE is:9.78% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :11.50 & 19.83% & 0.93\n",
      "for 2021-10-28, MAE is:26.49 & sMAPE is:12.71% & rMAE is:3.02 ||| daily mean of MAE & sMAPE & rMAE till now are :11.55 & 19.80% & 0.94\n",
      "for 2021-10-29, MAE is:26.36 & sMAPE is:14.94% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :11.60 & 19.79% & 0.94\n",
      "for 2021-10-30, MAE is:46.44 & sMAPE is:35.94% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :11.72 & 19.84% & 0.94\n",
      "for 2021-10-31, MAE is:58.63 & sMAPE is:58.02% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :11.87 & 19.97% & 0.94\n",
      "for 2021-11-01, MAE is:40.61 & sMAPE is:46.33% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :11.97 & 20.05% & 0.94\n",
      "for 2021-11-02, MAE is:32.29 & sMAPE is:22.29% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :12.03 & 20.06% & 0.93\n",
      "for 2021-11-03, MAE is:23.05 & sMAPE is:14.86% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.07 & 20.04% & 0.93\n",
      "for 2021-11-04, MAE is:14.43 & sMAPE is:8.50% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :12.08 & 20.01% & 0.93\n",
      "for 2021-11-05, MAE is:16.24 & sMAPE is:9.54% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 19.97% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-06, MAE is:18.95 & sMAPE is:11.83% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :12.11 & 19.95% & 0.93\n",
      "for 2021-11-07, MAE is:33.15 & sMAPE is:25.82% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :12.18 & 19.97% & 0.93\n",
      "for 2021-11-08, MAE is:25.73 & sMAPE is:15.94% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :12.22 & 19.95% & 0.93\n",
      "for 2021-11-09, MAE is:17.82 & sMAPE is:10.06% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :12.24 & 19.92% & 0.92\n",
      "for 2021-11-10, MAE is:17.51 & sMAPE is:8.95% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :12.26 & 19.89% & 0.92\n",
      "for 2021-11-11, MAE is:22.93 & sMAPE is:12.19% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :12.29 & 19.86% & 0.93\n",
      "for 2021-11-12, MAE is:12.26 & sMAPE is:6.66% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :12.29 & 19.82% & 0.92\n",
      "for 2021-11-13, MAE is:15.85 & sMAPE is:8.80% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :12.30 & 19.78% & 0.92\n",
      "for 2021-11-14, MAE is:11.24 & sMAPE is:6.39% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :12.30 & 19.74% & 0.92\n",
      "for 2021-11-15, MAE is:23.17 & sMAPE is:12.75% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :12.33 & 19.72% & 0.92\n",
      "for 2021-11-16, MAE is:19.35 & sMAPE is:9.83% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :12.36 & 19.69% & 0.92\n",
      "for 2021-11-17, MAE is:22.49 & sMAPE is:11.44% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :12.39 & 19.66% & 0.93\n",
      "for 2021-11-18, MAE is:29.55 & sMAPE is:13.48% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :12.44 & 19.64% & 0.93\n",
      "for 2021-11-19, MAE is:13.91 & sMAPE is:6.05% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.44 & 19.60% & 0.92\n",
      "for 2021-11-20, MAE is:15.48 & sMAPE is:7.00% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :12.45 & 19.56% & 0.92\n",
      "for 2021-11-21, MAE is:18.33 & sMAPE is:8.07% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.47 & 19.53% & 0.92\n",
      "for 2021-11-22, MAE is:23.03 & sMAPE is:9.99% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :12.50 & 19.50% & 0.92\n",
      "for 2021-11-23, MAE is:16.59 & sMAPE is:7.27% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :12.52 & 19.46% & 0.92\n",
      "for 2021-11-24, MAE is:17.96 & sMAPE is:7.89% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :12.53 & 19.43% & 0.92\n",
      "for 2021-11-25, MAE is:18.89 & sMAPE is:8.57% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.55 & 19.39% & 0.92\n",
      "for 2021-11-26, MAE is:14.72 & sMAPE is:6.58% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :12.56 & 19.35% & 0.92\n",
      "for 2021-11-27, MAE is:22.11 & sMAPE is:10.73% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :12.59 & 19.33% & 0.92\n",
      "for 2021-11-28, MAE is:16.13 & sMAPE is:7.80% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :12.60 & 19.29% & 0.92\n",
      "for 2021-11-29, MAE is:28.81 & sMAPE is:15.21% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :12.65 & 19.28% & 0.92\n",
      "for 2021-11-30, MAE is:43.20 & sMAPE is:16.80% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :12.74 & 19.27% & 0.92\n",
      "for 2021-12-01, MAE is:24.26 & sMAPE is:9.66% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :12.77 & 19.25% & 0.92\n",
      "for 2021-12-02, MAE is:27.41 & sMAPE is:12.51% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :12.82 & 19.23% & 0.92\n",
      "for 2021-12-03, MAE is:21.31 & sMAPE is:9.29% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :12.84 & 19.20% & 0.92\n",
      "for 2021-12-04, MAE is:13.43 & sMAPE is:6.13% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :12.84 & 19.16% & 0.92\n",
      "for 2021-12-05, MAE is:117.37 & sMAPE is:97.24% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :13.15 & 19.39% & 0.92\n",
      "for 2021-12-06, MAE is:44.63 & sMAPE is:23.14% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :13.25 & 19.40% & 0.93\n",
      "for 2021-12-07, MAE is:19.92 & sMAPE is:9.16% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :13.26 & 19.37% & 0.92\n",
      "for 2021-12-08, MAE is:96.63 & sMAPE is:79.56% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :13.51 & 19.54% & 0.92\n",
      "for 2021-12-09, MAE is:49.99 & sMAPE is:25.63% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :13.61 & 19.56% & 0.93\n",
      "for 2021-12-10, MAE is:33.17 & sMAPE is:17.69% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :13.67 & 19.56% & 0.93\n",
      "for 2021-12-11, MAE is:31.31 & sMAPE is:13.27% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :13.72 & 19.54% & 0.93\n",
      "for 2021-12-12, MAE is:21.44 & sMAPE is:8.48% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :13.75 & 19.51% & 0.93\n",
      "for 2021-12-13, MAE is:23.69 & sMAPE is:8.92% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :13.77 & 19.48% & 0.93\n",
      "for 2021-12-14, MAE is:27.26 & sMAPE is:9.89% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :13.81 & 19.45% & 0.92\n",
      "for 2021-12-15, MAE is:33.09 & sMAPE is:12.03% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :13.87 & 19.43% & 0.92\n",
      "for 2021-12-16, MAE is:31.50 & sMAPE is:10.73% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :13.92 & 19.40% & 0.92\n",
      "for 2021-12-17, MAE is:29.74 & sMAPE is:9.87% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :13.96 & 19.38% & 0.92\n",
      "for 2021-12-18, MAE is:19.92 & sMAPE is:6.66% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :13.98 & 19.34% & 0.92\n",
      "for 2021-12-19, MAE is:24.82 & sMAPE is:8.04% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :14.01 & 19.31% & 0.92\n",
      "for 2021-12-20, MAE is:34.38 & sMAPE is:10.44% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :14.07 & 19.28% & 0.91\n",
      "for 2021-12-21, MAE is:20.11 & sMAPE is:6.23% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :14.09 & 19.25% & 0.91\n",
      "for 2021-12-22, MAE is:48.29 & sMAPE is:14.48% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :14.18 & 19.23% & 0.91\n",
      "for 2021-12-23, MAE is:50.80 & sMAPE is:14.03% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :14.28 & 19.22% & 0.91\n",
      "for 2021-12-24, MAE is:43.70 & sMAPE is:13.41% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :14.37 & 19.20% & 0.92\n",
      "for 2021-12-25, MAE is:60.34 & sMAPE is:25.86% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 19.22% & 0.92\n",
      "for 2021-12-26, MAE is:69.06 & sMAPE is:31.81% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :14.65 & 19.25% & 0.91\n",
      "for 2021-12-27, MAE is:109.12 & sMAPE is:88.51% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :14.91 & 19.45% & 0.91\n",
      "for 2021-12-28, MAE is:32.91 & sMAPE is:41.98% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.96 & 19.51% & 0.91\n",
      "for 2021-12-29, MAE is:54.77 & sMAPE is:32.95% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :15.07 & 19.55% & 0.91\n",
      "for 2021-12-30, MAE is:26.12 & sMAPE is:12.59% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :15.10 & 19.53% & 0.91\n",
      "for 2021-12-31, MAE is:68.58 & sMAPE is:40.22% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :15.24 & 19.58% & 0.91\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:32:07,670]\u001b[0m A new study created in RDB with name: ES_2022\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:32:28,048]\u001b[0m Trial 2 finished with value: 46.74879714550252 and parameters: {'n_hidden': 4, 'learning_rate': 0.02788636396905152, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35793693301766993, 'dropout_rate_Layer_2': 0.1692735189676935, 'dropout_rate_Layer_3': 0.3012901612964606, 'dropout_rate_Layer_4': 0.07628875601846286, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.450935357960458e-05, 'l1_Layer_2': 2.456885844464377e-05, 'l1_Layer_3': 1.3229108619107549e-05, 'l1_Layer_4': 9.221780834186701e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 130, 'n_units_Layer_4': 265}. Best is trial 2 with value: 46.74879714550252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.75 | sMAPE for Validation Set is: 44.51% | rMAE for Validation Set is: 1.88\n",
      "MAE for Test Set is: 78.98 | sMAPE for Test Set is: 56.62% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:32:32,095]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:32:36,552]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:32:40,478]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:32:43,120]\u001b[0m Trial 3 finished with value: 17.51517359940089 and parameters: {'n_hidden': 3, 'learning_rate': 0.06397276441161125, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21871939670121063, 'dropout_rate_Layer_2': 0.3390050136142196, 'dropout_rate_Layer_3': 0.3007108815147704, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003756663547847597, 'l1_Layer_2': 0.007597762591223351, 'l1_Layer_3': 0.04296499431104198, 'n_units_Layer_1': 120, 'n_units_Layer_2': 50, 'n_units_Layer_3': 265}. Best is trial 3 with value: 17.51517359940089.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.52 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 34.43 | sMAPE for Test Set is: 23.09% | rMAE for Test Set is: 0.87\n",
      "MAE for Validation Set is: 63.12 | sMAPE for Validation Set is: 62.40% | rMAE for Validation Set is: 2.54\n",
      "MAE for Test Set is: 112.10 | sMAPE for Test Set is: 93.08% | rMAE for Test Set is: 2.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:32:45,524]\u001b[0m Trial 0 finished with value: 63.11579757565671 and parameters: {'n_hidden': 3, 'learning_rate': 0.009533776889093975, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20082792746501377, 'dropout_rate_Layer_2': 0.34615835513508664, 'dropout_rate_Layer_3': 0.23981496743662212, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.011018225957900972, 'l1_Layer_2': 5.182332546249609e-05, 'l1_Layer_3': 0.0009800280545350785, 'n_units_Layer_1': 160, 'n_units_Layer_2': 215, 'n_units_Layer_3': 155}. Best is trial 3 with value: 17.51517359940089.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:32:48,797]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:32:49,196]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:32:51,200]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:32:56,680]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:32:58,310]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:00,979]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:06,741]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:07,035]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:13,707]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:16,598]\u001b[0m Trial 1 finished with value: 58.760272814760214 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026607536033817557, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1957405234163582, 'dropout_rate_Layer_2': 0.3507739017174085, 'dropout_rate_Layer_3': 0.17407008295161952, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037883617741646495, 'l1_Layer_2': 0.00031589098602355473, 'l1_Layer_3': 1.861087608312337e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 50, 'n_units_Layer_3': 105}. Best is trial 3 with value: 17.51517359940089.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.76 | sMAPE for Validation Set is: 56.08% | rMAE for Validation Set is: 2.36\n",
      "MAE for Test Set is: 106.45 | sMAPE for Test Set is: 85.79% | rMAE for Test Set is: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:33:17,038]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:25,055]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:31,586]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:31,599]\u001b[0m Trial 15 finished with value: 53.125688019499215 and parameters: {'n_hidden': 3, 'learning_rate': 0.026938694055232987, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24919200010920672, 'dropout_rate_Layer_2': 0.1029359206221371, 'dropout_rate_Layer_3': 0.2493524574297999, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.047078707201158e-05, 'l1_Layer_2': 7.194402055766699e-05, 'l1_Layer_3': 0.0006268931413504022, 'n_units_Layer_1': 95, 'n_units_Layer_2': 230, 'n_units_Layer_3': 230}. Best is trial 3 with value: 17.51517359940089.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.13 | sMAPE for Validation Set is: 48.98% | rMAE for Validation Set is: 2.13\n",
      "MAE for Test Set is: 98.03 | sMAPE for Test Set is: 75.68% | rMAE for Test Set is: 2.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:33:31,902]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:41,302]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:44,889]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:48,952]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:50,788]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:53,983]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:57,285]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:33:59,399]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:03,175]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:07,170]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:17,043]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:22,958]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:26,673]\u001b[0m Trial 31 finished with value: 13.541439784831285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034707652950742105, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2431770515708242, 'dropout_rate_Layer_2': 0.3803370615152813, 'dropout_rate_Layer_3': 0.28984499537167624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012872934247765594, 'l1_Layer_2': 0.00016791127275876536, 'l1_Layer_3': 0.00015766870128737306, 'n_units_Layer_1': 200, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.54 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 28.33 | sMAPE for Test Set is: 20.17% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:34:27,730]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:28,199]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:33,932]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:37,344]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:37,498]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:39,229]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:44,013]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:44,472]\u001b[0m Trial 32 finished with value: 13.698569892350742 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037232982304225377, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26875065771887585, 'dropout_rate_Layer_2': 0.1137656412259244, 'dropout_rate_Layer_3': 0.2852390430649944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013361645648507733, 'l1_Layer_2': 0.0001497609753238888, 'l1_Layer_3': 0.0001423205886915795, 'n_units_Layer_1': 300, 'n_units_Layer_2': 265, 'n_units_Layer_3': 140}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.70 | sMAPE for Validation Set is: 18.09% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 26.87 | sMAPE for Test Set is: 19.34% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:34:46,713]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:47,173]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:52,735]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:34:57,308]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:00,015]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:00,351]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:00,538]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:07,532]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:08,708]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:11,355]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:14,074]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:15,203]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:17,775]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:22,575]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:26,139]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:30,493]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:36,954]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:41,353]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:44,641]\u001b[0m Trial 59 finished with value: 17.27637319399658 and parameters: {'n_hidden': 3, 'learning_rate': 0.007005372639322963, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007152330352149861, 'dropout_rate_Layer_2': 0.10449410694567987, 'dropout_rate_Layer_3': 0.13237453935198432, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017322093816146931, 'l1_Layer_2': 0.0022578050776704667, 'l1_Layer_3': 0.017224777578197757, 'n_units_Layer_1': 50, 'n_units_Layer_2': 90, 'n_units_Layer_3': 200}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.28 | sMAPE for Validation Set is: 21.53% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 29.87 | sMAPE for Test Set is: 21.33% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:35:45,868]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:50,770]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:54,787]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:55,882]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.57 | sMAPE for Validation Set is: 17.94% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 28.08 | sMAPE for Test Set is: 20.08% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:35:59,211]\u001b[0m Trial 58 finished with value: 13.566570236096558 and parameters: {'n_hidden': 3, 'learning_rate': 0.001514132988427481, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3832362629846747, 'dropout_rate_Layer_2': 0.11509579806801735, 'dropout_rate_Layer_3': 0.38157010556227744, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.500233467693158e-05, 'l1_Layer_2': 0.0030822847670919696, 'l1_Layer_3': 8.388946589213544e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 180}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:35:59,877]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:36:05,538]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:36:11,931]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:36:18,145]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:36:20,929]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:36:23,929]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:36:24,122]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:36:30,626]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:36:34,305]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:36:43,051]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:36:53,656]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:36:54,016]\u001b[0m Trial 74 finished with value: 57.524760594678774 and parameters: {'n_hidden': 4, 'learning_rate': 0.05537481343894483, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2798613519719804, 'dropout_rate_Layer_2': 0.23385864341791712, 'dropout_rate_Layer_3': 0.23250338419983937, 'dropout_rate_Layer_4': 0.03654533427562469, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004233394544339406, 'l1_Layer_2': 0.009790374069529834, 'l1_Layer_3': 2.9189031666118896e-05, 'l1_Layer_4': 1.640690102891e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300, 'n_units_Layer_4': 285}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.52 | sMAPE for Validation Set is: 55.53% | rMAE for Validation Set is: 2.31\n",
      "MAE for Test Set is: 102.65 | sMAPE for Test Set is: 81.19% | rMAE for Test Set is: 2.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:36:59,476]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:37:07,818]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:37:14,178]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:37:23,145]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:37:26,197]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:37:26,890]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:37:33,342]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:37:38,650]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:37:43,787]\u001b[0m Trial 79 finished with value: 18.222042537843826 and parameters: {'n_hidden': 4, 'learning_rate': 0.05705143452515446, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3001063948872198, 'dropout_rate_Layer_2': 0.2103125647212176, 'dropout_rate_Layer_3': 0.1576458867403897, 'dropout_rate_Layer_4': 0.12828018154198093, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.05709231638474139, 'l1_Layer_2': 1.0207942005015767e-05, 'l1_Layer_3': 1.0756761201717283e-05, 'l1_Layer_4': 1.8596376478435835e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 105, 'n_units_Layer_3': 90, 'n_units_Layer_4': 295}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.22 | sMAPE for Validation Set is: 21.56% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 31.81 | sMAPE for Test Set is: 22.31% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:37:48,526]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:37:53,758]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:37:54,205]\u001b[0m Trial 88 finished with value: 48.70777482762683 and parameters: {'n_hidden': 3, 'learning_rate': 0.04385012707910891, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24504907447934943, 'dropout_rate_Layer_2': 0.3700513173815833, 'dropout_rate_Layer_3': 0.3287333589383285, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010127035604710476, 'l1_Layer_2': 0.00021437465693472643, 'l1_Layer_3': 0.005837854382118875, 'n_units_Layer_1': 105, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.71 | sMAPE for Validation Set is: 44.92% | rMAE for Validation Set is: 1.96\n",
      "MAE for Test Set is: 88.09 | sMAPE for Test Set is: 65.37% | rMAE for Test Set is: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:37:59,898]\u001b[0m Trial 87 finished with value: 51.29392754552972 and parameters: {'n_hidden': 3, 'learning_rate': 0.04484960824701349, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24966436167801032, 'dropout_rate_Layer_2': 0.33595304376215307, 'dropout_rate_Layer_3': 0.3291692250746085, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010092098944353207, 'l1_Layer_2': 9.394908747877175e-05, 'l1_Layer_3': 0.0003220597692429022, 'n_units_Layer_1': 105, 'n_units_Layer_2': 205, 'n_units_Layer_3': 265}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.29 | sMAPE for Validation Set is: 48.29% | rMAE for Validation Set is: 2.06\n",
      "MAE for Test Set is: 89.91 | sMAPE for Test Set is: 67.29% | rMAE for Test Set is: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:38:07,141]\u001b[0m Trial 73 finished with value: 15.979752442206307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0841787742671434, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26904424558461054, 'dropout_rate_Layer_2': 0.2935908622332548, 'dropout_rate_Layer_3': 0.013544796400073736, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00876030054774796, 'l1_Layer_2': 0.015621130640008524, 'l1_Layer_3': 0.007994566940044941, 'n_units_Layer_1': 195, 'n_units_Layer_2': 70, 'n_units_Layer_3': 75}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.98 | sMAPE for Validation Set is: 20.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 30.11 | sMAPE for Test Set is: 21.02% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:38:10,549]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:38:15,165]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:38:19,199]\u001b[0m Trial 91 finished with value: 13.664890225885827 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009477739649865998, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11381503206595955, 'dropout_rate_Layer_2': 0.15358901523043095, 'dropout_rate_Layer_3': 0.36703421991213037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035766105022513287, 'l1_Layer_2': 3.832566237902992e-05, 'l1_Layer_3': 5.288761083145264e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.66 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.96 | sMAPE for Test Set is: 20.00% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:38:24,506]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:38:27,840]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:38:31,454]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:38:34,550]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:38:40,628]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:38:41,804]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:38:46,890]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:38:47,185]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:38:53,792]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:38:59,062]\u001b[0m Trial 94 finished with value: 15.67722559243829 and parameters: {'n_hidden': 3, 'learning_rate': 0.008899070063279649, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1880260159216679, 'dropout_rate_Layer_2': 0.3740393883756062, 'dropout_rate_Layer_3': 0.06596911770226285, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002451489139248268, 'l1_Layer_2': 0.004056552759954477, 'l1_Layer_3': 0.0274540832288536, 'n_units_Layer_1': 240, 'n_units_Layer_2': 50, 'n_units_Layer_3': 165}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.68 | sMAPE for Validation Set is: 19.75% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 30.79 | sMAPE for Test Set is: 21.59% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:39:12,370]\u001b[0m Trial 104 finished with value: 44.4210203231688 and parameters: {'n_hidden': 3, 'learning_rate': 0.04852630860394625, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25858160033659944, 'dropout_rate_Layer_2': 0.3338392444935641, 'dropout_rate_Layer_3': 0.2859992070222471, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.380230117912924e-05, 'l1_Layer_2': 0.0013071222867260112, 'l1_Layer_3': 3.637418520268627e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 155, 'n_units_Layer_3': 220}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.42 | sMAPE for Validation Set is: 41.30% | rMAE for Validation Set is: 1.78\n",
      "MAE for Test Set is: 80.49 | sMAPE for Test Set is: 57.85% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:39:24,877]\u001b[0m Trial 106 finished with value: 16.247406527638656 and parameters: {'n_hidden': 3, 'learning_rate': 0.0051146620104032545, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16720396406683644, 'dropout_rate_Layer_2': 0.3736272681670708, 'dropout_rate_Layer_3': 0.05774626954568444, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0028668776229150675, 'l1_Layer_2': 0.06564540372538423, 'l1_Layer_3': 0.002857628210486843, 'n_units_Layer_1': 295, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.25 | sMAPE for Validation Set is: 19.91% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 30.66 | sMAPE for Test Set is: 21.58% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:39:28,789]\u001b[0m Trial 107 finished with value: 13.785450245652562 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015004085686158377, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18250392353542166, 'dropout_rate_Layer_2': 0.21478647881906618, 'dropout_rate_Layer_3': 0.3523749746765051, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005032421759941668, 'l1_Layer_2': 0.0014736763190566176, 'l1_Layer_3': 2.377485677757622e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 110}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.79 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 26.82 | sMAPE for Test Set is: 19.35% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:39:33,415]\u001b[0m Trial 108 finished with value: 42.55045495893285 and parameters: {'n_hidden': 3, 'learning_rate': 0.021122983562660597, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27797976645096534, 'dropout_rate_Layer_2': 0.3612332082416523, 'dropout_rate_Layer_3': 0.2793794903419015, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.671546126406029e-05, 'l1_Layer_2': 0.0009434911991453704, 'l1_Layer_3': 1.5822219191588998e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 155, 'n_units_Layer_3': 245}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.55 | sMAPE for Validation Set is: 43.09% | rMAE for Validation Set is: 1.71\n",
      "MAE for Test Set is: 59.77 | sMAPE for Test Set is: 39.82% | rMAE for Test Set is: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:39:37,663]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:39:40,900]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:39:40,970]\u001b[0m Trial 93 finished with value: 15.09467966896168 and parameters: {'n_hidden': 3, 'learning_rate': 0.006642398441255828, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3079515140363445, 'dropout_rate_Layer_2': 0.2734932025406696, 'dropout_rate_Layer_3': 0.07685608371443771, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002700212708323388, 'l1_Layer_2': 0.0036670409650441005, 'l1_Layer_3': 0.00021703120712628562, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 220}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.09 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 30.58 | sMAPE for Test Set is: 21.36% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:39:41,839]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:39:56,543]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:39:57,223]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:04,039]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:07,615]\u001b[0m Trial 113 finished with value: 36.720354797844 and parameters: {'n_hidden': 3, 'learning_rate': 0.02115923681679892, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2819907806261383, 'dropout_rate_Layer_2': 0.3359037397358128, 'dropout_rate_Layer_3': 0.08882489023741588, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.15733860947848e-05, 'l1_Layer_2': 0.001017967797750986, 'l1_Layer_3': 1.6915075756374467e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 160, 'n_units_Layer_3': 245}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.72 | sMAPE for Validation Set is: 45.83% | rMAE for Validation Set is: 1.48\n",
      "MAE for Test Set is: 42.64 | sMAPE for Test Set is: 28.26% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:40:11,698]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:16,773]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:19,926]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:21,275]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:25,000]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:28,552]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:32,642]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:37,265]\u001b[0m Trial 112 finished with value: 15.67918930785394 and parameters: {'n_hidden': 3, 'learning_rate': 0.014125915139814706, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1721085990706778, 'dropout_rate_Layer_2': 0.39686912937371205, 'dropout_rate_Layer_3': 0.05648132838906669, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0041526972889215545, 'l1_Layer_2': 0.07412877476234894, 'l1_Layer_3': 0.002921124608694065, 'n_units_Layer_1': 300, 'n_units_Layer_2': 65, 'n_units_Layer_3': 220}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.68 | sMAPE for Validation Set is: 19.88% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 30.92 | sMAPE for Test Set is: 21.52% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:40:39,261]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:42,548]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:45,754]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:49,941]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:53,474]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:40:57,731]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:02,947]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:03,461]\u001b[0m Trial 117 finished with value: 16.324017846322366 and parameters: {'n_hidden': 3, 'learning_rate': 0.015016103765643963, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3368743886569036, 'dropout_rate_Layer_2': 0.390581930698766, 'dropout_rate_Layer_3': 0.03764012122736993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005105314331609701, 'l1_Layer_2': 0.0036422579662834104, 'l1_Layer_3': 0.000199486881521619, 'n_units_Layer_1': 210, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.32 | sMAPE for Validation Set is: 20.51% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 31.90 | sMAPE for Test Set is: 22.09% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:41:06,619]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:17,417]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:18,801]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:22,637]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:27,168]\u001b[0m Trial 134 finished with value: 41.13684591225489 and parameters: {'n_hidden': 3, 'learning_rate': 0.04086429185477224, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21577420545753312, 'dropout_rate_Layer_2': 0.017202835836523683, 'dropout_rate_Layer_3': 0.06707218880652673, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002858971158593738, 'l1_Layer_2': 0.0024752739955652896, 'l1_Layer_3': 3.309683923902388e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 90, 'n_units_Layer_3': 210}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.14 | sMAPE for Validation Set is: 39.51% | rMAE for Validation Set is: 1.65\n",
      "MAE for Test Set is: 66.50 | sMAPE for Test Set is: 45.32% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:41:29,772]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:32,217]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:37,251]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:37,423]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:43,566]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:47,967]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:48,411]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.03 | sMAPE for Validation Set is: 42.09% | rMAE for Validation Set is: 1.69\n",
      "MAE for Test Set is: 57.16 | sMAPE for Test Set is: 37.88% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:41:52,399]\u001b[0m Trial 142 finished with value: 42.03026300924977 and parameters: {'n_hidden': 3, 'learning_rate': 0.05047643484445971, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2744773797622819, 'dropout_rate_Layer_2': 0.34375822432165265, 'dropout_rate_Layer_3': 0.07845427941304209, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002805021725209995, 'l1_Layer_2': 0.0008321575197994966, 'l1_Layer_3': 1.937618826260637e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 245}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:54,825]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:55,320]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:41:57,853]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:03,077]\u001b[0m Trial 133 finished with value: 16.111921907597857 and parameters: {'n_hidden': 3, 'learning_rate': 0.014855235212084742, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21469138998143927, 'dropout_rate_Layer_2': 0.38042722707693477, 'dropout_rate_Layer_3': 0.04948804201178439, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004160767679113697, 'l1_Layer_2': 0.004862693295971334, 'l1_Layer_3': 0.00019660566008911396, 'n_units_Layer_1': 290, 'n_units_Layer_2': 135, 'n_units_Layer_3': 265}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.11 | sMAPE for Validation Set is: 20.05% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 30.39 | sMAPE for Test Set is: 21.30% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:42:06,188]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:06,431]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:07,149]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:13,545]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:16,186]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:18,545]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:18,880]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:21,861]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:24,262]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:29,208]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:32,843]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:33,060]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:38,045]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:38,905]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:46,526]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:49,902]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:54,250]\u001b[0m Trial 163 finished with value: 44.916170323978655 and parameters: {'n_hidden': 3, 'learning_rate': 0.044236933170839, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2560539357293506, 'dropout_rate_Layer_2': 0.35216163944751444, 'dropout_rate_Layer_3': 0.11910814426976174, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002010740917796444, 'l1_Layer_2': 0.0012014918165408732, 'l1_Layer_3': 3.067984220062497e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 225}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.92 | sMAPE for Validation Set is: 42.11% | rMAE for Validation Set is: 1.80\n",
      "MAE for Test Set is: 72.37 | sMAPE for Test Set is: 49.94% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:42:56,574]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:42:58,551]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:05,318]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:05,730]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.66 | sMAPE for Validation Set is: 19.73% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 31.42 | sMAPE for Test Set is: 21.80% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:43:09,104]\u001b[0m Trial 164 finished with value: 15.658888296013217 and parameters: {'n_hidden': 3, 'learning_rate': 0.010985863879125349, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12365514537224903, 'dropout_rate_Layer_2': 0.25970839703874266, 'dropout_rate_Layer_3': 0.19707270236919786, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021785188175403153, 'l1_Layer_2': 0.03359836475025261, 'l1_Layer_3': 0.03678264939751713, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 170}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:10,267]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:13,835]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:19,615]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:22,539]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:23,506]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:25,973]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:29,391]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:30,339]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:32,748]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:36,826]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:37,064]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:43,528]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:47,535]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:51,974]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:54,570]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:43:54,848]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:00,365]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:03,455]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:03,611]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:03,704]\u001b[0m Trial 183 finished with value: 15.197179305877546 and parameters: {'n_hidden': 3, 'learning_rate': 0.009746175265465302, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06559516930133488, 'dropout_rate_Layer_2': 0.31706463169001875, 'dropout_rate_Layer_3': 0.19365873304977427, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018330227553665535, 'l1_Layer_2': 0.028888647990059916, 'l1_Layer_3': 0.04704506316842785, 'n_units_Layer_1': 165, 'n_units_Layer_2': 195, 'n_units_Layer_3': 150}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.20 | sMAPE for Validation Set is: 19.52% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 30.36 | sMAPE for Test Set is: 21.39% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:44:10,932]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:11,301]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:17,767]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:20,984]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:24,750]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:25,611]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:33,746]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:37,736]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:38,331]\u001b[0m Trial 194 finished with value: 15.317523940626245 and parameters: {'n_hidden': 3, 'learning_rate': 0.005656735014030609, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08603213078588402, 'dropout_rate_Layer_2': 0.24851379826702702, 'dropout_rate_Layer_3': 0.18699511634590965, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007182723931172384, 'l1_Layer_2': 0.002178309982224434, 'l1_Layer_3': 0.05188223727509194, 'n_units_Layer_1': 180, 'n_units_Layer_2': 210, 'n_units_Layer_3': 150}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.32 | sMAPE for Validation Set is: 19.55% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.79 | sMAPE for Test Set is: 21.09% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:44:45,438]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:46,104]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:51,841]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:52,707]\u001b[0m Trial 200 finished with value: 41.096576329290976 and parameters: {'n_hidden': 3, 'learning_rate': 0.018924584190208055, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2758027636579352, 'dropout_rate_Layer_2': 0.3338969185437392, 'dropout_rate_Layer_3': 0.03040987441648829, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011300279134062965, 'l1_Layer_2': 0.000804358646468081, 'l1_Layer_3': 1.0000712392560416e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 155, 'n_units_Layer_3': 195}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.10 | sMAPE for Validation Set is: 40.63% | rMAE for Validation Set is: 1.65\n",
      "MAE for Test Set is: 63.61 | sMAPE for Test Set is: 42.70% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:44:54,350]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:44:57,937]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:02,267]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:06,313]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:09,612]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:12,967]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:13,028]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:18,004]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:20,162]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:20,821]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:27,730]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:33,147]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:33,293]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:38,347]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:43,271]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:46,960]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:50,350]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:52,928]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:56,554]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:45:59,605]\u001b[0m Trial 191 finished with value: 16.006168534786784 and parameters: {'n_hidden': 3, 'learning_rate': 0.006176755728566645, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19067075657718488, 'dropout_rate_Layer_2': 0.35693767255976927, 'dropout_rate_Layer_3': 0.1893769310461217, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0026717777831952233, 'l1_Layer_2': 0.05878474654598962, 'l1_Layer_3': 0.004982099713559247, 'n_units_Layer_1': 230, 'n_units_Layer_2': 200, 'n_units_Layer_3': 210}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.01 | sMAPE for Validation Set is: 20.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 29.96 | sMAPE for Test Set is: 21.21% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:46:00,345]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:02,758]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:08,581]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:09,182]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:10,631]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:14,705]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:18,307]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:18,335]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:18,816]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:25,421]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:27,448]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:31,508]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:38,211]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:38,905]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:39,245]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:44,326]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:49,247]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:49,721]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:55,381]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:46:57,401]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:02,283]\u001b[0m Trial 241 finished with value: 15.748774315578311 and parameters: {'n_hidden': 3, 'learning_rate': 0.02153042377274636, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09031553070212778, 'dropout_rate_Layer_2': 0.23506012106500435, 'dropout_rate_Layer_3': 0.25441664928528945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008636956450571834, 'l1_Layer_2': 0.008823305560343773, 'l1_Layer_3': 0.09162428261253443, 'n_units_Layer_1': 155, 'n_units_Layer_2': 170, 'n_units_Layer_3': 120}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:02,377]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.75 | sMAPE for Validation Set is: 20.28% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 30.68 | sMAPE for Test Set is: 21.58% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:47:06,171]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:12,074]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:12,242]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:14,463]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:22,341]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:23,669]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:25,108]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:25,222]\u001b[0m Trial 235 finished with value: 13.596376674508386 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009715074868374799, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17253511702638807, 'dropout_rate_Layer_2': 0.2483614710830042, 'dropout_rate_Layer_3': 0.3203957289939335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005967490125566995, 'l1_Layer_2': 0.002560206168257292, 'l1_Layer_3': 3.67631206175104e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 230, 'n_units_Layer_3': 120}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.60 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.20 | sMAPE for Test Set is: 19.60% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:47:34,208]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:37,160]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:39,873]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:40,252]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:43,294]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:44,814]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:49,539]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:53,985]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:56,122]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:47:56,680]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:02,698]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:03,033]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:06,565]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:11,650]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:15,588]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:15,769]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:23,482]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:25,997]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:28,540]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:31,626]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:33,556]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:36,980]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:43,123]\u001b[0m Trial 260 finished with value: 13.547134855770727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010102390521868078, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14876662617078465, 'dropout_rate_Layer_2': 0.21997042968842456, 'dropout_rate_Layer_3': 0.1842021738766895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004044404918632048, 'l1_Layer_2': 0.004214633870789985, 'l1_Layer_3': 5.438412656774944e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 225, 'n_units_Layer_3': 120}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.55 | sMAPE for Validation Set is: 18.14% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 26.64 | sMAPE for Test Set is: 19.28% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:48:47,733]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:53,175]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:48:53,920]\u001b[0m Trial 278 finished with value: 46.447109071938684 and parameters: {'n_hidden': 3, 'learning_rate': 0.04350106507791371, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24228824491322795, 'dropout_rate_Layer_2': 0.34158369760384355, 'dropout_rate_Layer_3': 0.10371338479854378, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.563387008218859e-05, 'l1_Layer_2': 0.0014596696657196938, 'l1_Layer_3': 2.9162918023864138e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 115, 'n_units_Layer_3': 225}. Best is trial 31 with value: 13.541439784831285.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.45 | sMAPE for Validation Set is: 44.14% | rMAE for Validation Set is: 1.87\n",
      "MAE for Test Set is: 79.93 | sMAPE for Test Set is: 56.95% | rMAE for Test Set is: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:48:55,806]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:00,191]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:03,539]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:03,624]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:07,263]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:16,280]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:17,657]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:22,935]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:28,365]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:28,895]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:34,980]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:39,760]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:42,744]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:45,853]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:45,924]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:51,773]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:49:58,740]\u001b[0m Trial 286 finished with value: 13.342638082846138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012563082870978778, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13429124799878922, 'dropout_rate_Layer_2': 0.3738662806241758, 'dropout_rate_Layer_3': 0.1819351418652644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3190496042497197e-05, 'l1_Layer_2': 0.0022504369474544827, 'l1_Layer_3': 3.500128247468884e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.34 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 26.06 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:50:05,893]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:50:09,005]\u001b[0m Trial 297 finished with value: 15.52180799334631 and parameters: {'n_hidden': 3, 'learning_rate': 0.004995461751206176, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23434936558776354, 'dropout_rate_Layer_2': 0.39938497899374836, 'dropout_rate_Layer_3': 0.027224801700767652, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003762971705455758, 'l1_Layer_2': 0.046513470175370025, 'l1_Layer_3': 0.0013575653426378587, 'n_units_Layer_1': 280, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.52 | sMAPE for Validation Set is: 19.79% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 30.96 | sMAPE for Test Set is: 21.58% | rMAE for Test Set is: 0.78\n",
      "MAE for Validation Set is: 16.11 | sMAPE for Validation Set is: 20.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 29.28 | sMAPE for Test Set is: 20.91% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:50:10,470]\u001b[0m Trial 296 finished with value: 16.110488668043075 and parameters: {'n_hidden': 3, 'learning_rate': 0.00567455265036378, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2350334389857962, 'dropout_rate_Layer_2': 0.3983492387617096, 'dropout_rate_Layer_3': 0.06772746580843483, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034130845767698786, 'l1_Layer_2': 0.049094795852763974, 'l1_Layer_3': 0.0049596933938859875, 'n_units_Layer_1': 260, 'n_units_Layer_2': 65, 'n_units_Layer_3': 235}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:50:18,941]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:50:27,383]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:50:29,042]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:50:30,767]\u001b[0m Trial 303 finished with value: 43.00322795094641 and parameters: {'n_hidden': 3, 'learning_rate': 0.02229783013502836, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2356628306703683, 'dropout_rate_Layer_2': 0.3838978704616508, 'dropout_rate_Layer_3': 0.08225509533978245, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010531985613506636, 'l1_Layer_2': 0.0003267094198651952, 'l1_Layer_3': 0.00010482803824892525, 'n_units_Layer_1': 175, 'n_units_Layer_2': 60, 'n_units_Layer_3': 235}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.00 | sMAPE for Validation Set is: 45.03% | rMAE for Validation Set is: 1.73\n",
      "MAE for Test Set is: 67.14 | sMAPE for Test Set is: 45.75% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:50:35,425]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:50:40,807]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:50:40,900]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:50:48,684]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:50:48,934]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:50:56,915]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:03,438]\u001b[0m Trial 301 finished with value: 15.775256102473321 and parameters: {'n_hidden': 3, 'learning_rate': 0.005264920336229596, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23982456887691891, 'dropout_rate_Layer_2': 0.37266172418714155, 'dropout_rate_Layer_3': 0.02997743532502123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004252141959855813, 'l1_Layer_2': 0.049704284987298376, 'l1_Layer_3': 0.00508794232336489, 'n_units_Layer_1': 260, 'n_units_Layer_2': 60, 'n_units_Layer_3': 235}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.78 | sMAPE for Validation Set is: 19.75% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 31.76 | sMAPE for Test Set is: 21.95% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:51:11,305]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:14,226]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:14,469]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:15,342]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:15,798]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:25,480]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:30,849]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:31,367]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:38,025]\u001b[0m Trial 316 finished with value: 44.486016917264216 and parameters: {'n_hidden': 3, 'learning_rate': 0.054870591953189184, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2594467104964943, 'dropout_rate_Layer_2': 0.3716718820764358, 'dropout_rate_Layer_3': 0.057903912691797225, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.109298730891314e-05, 'l1_Layer_2': 0.00010315302322017559, 'l1_Layer_3': 1.0040782832429807e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.49 | sMAPE for Validation Set is: 43.69% | rMAE for Validation Set is: 1.79\n",
      "MAE for Test Set is: 69.55 | sMAPE for Test Set is: 47.73% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:51:42,664]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:43,332]\u001b[0m Trial 319 finished with value: 46.5619511519256 and parameters: {'n_hidden': 3, 'learning_rate': 0.03505287562334803, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24279808587613272, 'dropout_rate_Layer_2': 0.3601362249472984, 'dropout_rate_Layer_3': 0.08446394850869238, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.663589899382997e-05, 'l1_Layer_2': 0.0010449319523335144, 'l1_Layer_3': 1.0440271740750648e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.56 | sMAPE for Validation Set is: 43.33% | rMAE for Validation Set is: 1.87\n",
      "MAE for Test Set is: 84.07 | sMAPE for Test Set is: 60.77% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:51:45,354]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:46,746]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:51:57,273]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:52:05,295]\u001b[0m Trial 324 finished with value: 43.80291619918838 and parameters: {'n_hidden': 3, 'learning_rate': 0.0222729015862008, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24255286166656845, 'dropout_rate_Layer_2': 0.38091521988221994, 'dropout_rate_Layer_3': 0.05760080118172527, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.659891360724937e-05, 'l1_Layer_2': 0.00010749496815952363, 'l1_Layer_3': 1.0144989334199494e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 75, 'n_units_Layer_3': 230}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.80 | sMAPE for Validation Set is: 42.64% | rMAE for Validation Set is: 1.76\n",
      "MAE for Test Set is: 69.26 | sMAPE for Test Set is: 47.35% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:52:08,875]\u001b[0m Trial 325 finished with value: 44.364352090902884 and parameters: {'n_hidden': 3, 'learning_rate': 0.024001190894215513, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23885986373777043, 'dropout_rate_Layer_2': 0.38284167489075643, 'dropout_rate_Layer_3': 0.06160483293435089, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001076361792724831, 'l1_Layer_2': 0.00012713357914475115, 'l1_Layer_3': 1.09592016335599e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 75, 'n_units_Layer_3': 230}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.36 | sMAPE for Validation Set is: 46.60% | rMAE for Validation Set is: 1.78\n",
      "MAE for Test Set is: 49.30 | sMAPE for Test Set is: 32.26% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:52:12,199]\u001b[0m Trial 326 finished with value: 43.0904633128113 and parameters: {'n_hidden': 3, 'learning_rate': 0.035401943259947284, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22397077595632273, 'dropout_rate_Layer_2': 0.38031855129561665, 'dropout_rate_Layer_3': 0.07076672631753586, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.289653201660548e-05, 'l1_Layer_2': 0.00011488176816019585, 'l1_Layer_3': 1.2964104859647859e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.09 | sMAPE for Validation Set is: 44.57% | rMAE for Validation Set is: 1.73\n",
      "MAE for Test Set is: 67.07 | sMAPE for Test Set is: 45.62% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:52:14,581]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:52:18,778]\u001b[0m Trial 328 finished with value: 41.21645800951223 and parameters: {'n_hidden': 3, 'learning_rate': 0.03456496618903667, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23527105708280155, 'dropout_rate_Layer_2': 0.38153242956925215, 'dropout_rate_Layer_3': 0.03714077364116279, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.878727411000634e-05, 'l1_Layer_2': 7.560218060234296e-05, 'l1_Layer_3': 1.3076322330997707e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 75, 'n_units_Layer_3': 140}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.22 | sMAPE for Validation Set is: 40.16% | rMAE for Validation Set is: 1.66\n",
      "MAE for Test Set is: 60.37 | sMAPE for Test Set is: 40.49% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:52:21,797]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:52:24,433]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:52:26,257]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:52:31,762]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:52:34,204]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:52:37,203]\u001b[0m Trial 332 finished with value: 35.556680241464676 and parameters: {'n_hidden': 3, 'learning_rate': 0.025618308845407205, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22725865185146465, 'dropout_rate_Layer_2': 0.37563168028218713, 'dropout_rate_Layer_3': 0.07099278536545017, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.486841139004096e-05, 'l1_Layer_2': 9.994201199498725e-05, 'l1_Layer_3': 0.00043687025416606456, 'n_units_Layer_1': 120, 'n_units_Layer_2': 75, 'n_units_Layer_3': 225}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.56 | sMAPE for Validation Set is: 43.79% | rMAE for Validation Set is: 1.43\n",
      "MAE for Test Set is: 48.72 | sMAPE for Test Set is: 33.30% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:52:42,528]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:52:43,270]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:52:51,302]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:52:51,435]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:52:58,010]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:01,049]\u001b[0m Trial 340 finished with value: 42.54130551565209 and parameters: {'n_hidden': 3, 'learning_rate': 0.021880977737068992, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21619146732020358, 'dropout_rate_Layer_2': 0.3837834997233713, 'dropout_rate_Layer_3': 0.0707722903379144, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.44034033384906e-05, 'l1_Layer_2': 0.00011199800161810323, 'l1_Layer_3': 1.3027832666026348e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 75, 'n_units_Layer_3': 110}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.54 | sMAPE for Validation Set is: 44.10% | rMAE for Validation Set is: 1.71\n",
      "MAE for Test Set is: 47.08 | sMAPE for Test Set is: 30.80% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:53:03,363]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:07,772]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:10,172]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:13,532]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:14,112]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:16,328]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:16,829]\u001b[0m Trial 343 finished with value: 45.32552366901058 and parameters: {'n_hidden': 3, 'learning_rate': 0.023139860821638717, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22584405576301703, 'dropout_rate_Layer_2': 0.39103131942330466, 'dropout_rate_Layer_3': 0.056067448761949586, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.429135521714022e-05, 'l1_Layer_2': 0.00010207596848111142, 'l1_Layer_3': 1.2205387912008007e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 75, 'n_units_Layer_3': 230}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.33 | sMAPE for Validation Set is: 46.51% | rMAE for Validation Set is: 1.82\n",
      "MAE for Test Set is: 63.62 | sMAPE for Test Set is: 42.83% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:53:20,937]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:25,407]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:30,900]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:30,938]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:33,522]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:39,189]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:39,420]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:47,794]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:51,378]\u001b[0m Trial 353 finished with value: 38.374305074138626 and parameters: {'n_hidden': 3, 'learning_rate': 0.02578066007284186, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19399508198845083, 'dropout_rate_Layer_2': 0.3939753096980799, 'dropout_rate_Layer_3': 0.037469591246610645, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8589309664812114e-05, 'l1_Layer_2': 7.588315812437932e-05, 'l1_Layer_3': 1.7513307516911542e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 80, 'n_units_Layer_3': 240}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.37 | sMAPE for Validation Set is: 42.03% | rMAE for Validation Set is: 1.54\n",
      "MAE for Test Set is: 50.84 | sMAPE for Test Set is: 33.36% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:53:55,988]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:53:59,978]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:03,838]\u001b[0m Trial 358 finished with value: 39.41160412421495 and parameters: {'n_hidden': 3, 'learning_rate': 0.017876131382631638, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2279730760091163, 'dropout_rate_Layer_2': 0.3703595743407103, 'dropout_rate_Layer_3': 0.03827588119053931, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.6805986284614496e-05, 'l1_Layer_2': 7.75383026246533e-05, 'l1_Layer_3': 1.4435563682232626e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 90, 'n_units_Layer_3': 220}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.41 | sMAPE for Validation Set is: 38.55% | rMAE for Validation Set is: 1.58\n",
      "MAE for Test Set is: 63.98 | sMAPE for Test Set is: 42.88% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:54:04,460]\u001b[0m Trial 359 finished with value: 40.2189280654132 and parameters: {'n_hidden': 3, 'learning_rate': 0.0336951758342588, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2258874491467848, 'dropout_rate_Layer_2': 0.3735374829954697, 'dropout_rate_Layer_3': 0.03791299154791315, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9438874096469564e-05, 'l1_Layer_2': 7.989178025210701e-05, 'l1_Layer_3': 1.3777849100148376e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 90, 'n_units_Layer_3': 220}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.22 | sMAPE for Validation Set is: 41.11% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 62.78 | sMAPE for Test Set is: 42.19% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:54:10,660]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:14,726]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:15,340]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:17,423]\u001b[0m Trial 362 finished with value: 42.84965968681087 and parameters: {'n_hidden': 3, 'learning_rate': 0.01566530737394483, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21388411445521238, 'dropout_rate_Layer_2': 0.37795795939604765, 'dropout_rate_Layer_3': 0.044456099406395985, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5170800258337774e-05, 'l1_Layer_2': 8.907613431544906e-05, 'l1_Layer_3': 2.1174980455862787e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 65, 'n_units_Layer_3': 75}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.85 | sMAPE for Validation Set is: 43.08% | rMAE for Validation Set is: 1.72\n",
      "MAE for Test Set is: 67.47 | sMAPE for Test Set is: 46.03% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:54:23,813]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:30,481]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:35,807]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:44,451]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:48,227]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:49,496]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:53,502]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:55,984]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:54:58,016]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:01,383]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:07,034]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:11,137]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:13,393]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.66 | sMAPE for Validation Set is: 29.44% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 47.77 | sMAPE for Test Set is: 31.32% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:55:15,830]\u001b[0m Trial 368 finished with value: 29.663315154049872 and parameters: {'n_hidden': 3, 'learning_rate': 0.021526699182663648, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1830312574618299, 'dropout_rate_Layer_2': 0.3714280222400581, 'dropout_rate_Layer_3': 0.044352917904986106, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.948042722785888e-05, 'l1_Layer_2': 8.512386395904896e-05, 'l1_Layer_3': 1.5021505640926684e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 70, 'n_units_Layer_3': 85}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:17,418]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:21,034]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:25,523]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:25,755]\u001b[0m Trial 377 finished with value: 41.36408292333396 and parameters: {'n_hidden': 3, 'learning_rate': 0.01504378225063041, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2112733355322806, 'dropout_rate_Layer_2': 0.3719219826908861, 'dropout_rate_Layer_3': 0.04927345064845558, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4507705947690913e-05, 'l1_Layer_2': 0.00013097293103792046, 'l1_Layer_3': 2.025602512871805e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 90, 'n_units_Layer_3': 60}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.36 | sMAPE for Validation Set is: 39.28% | rMAE for Validation Set is: 1.66\n",
      "MAE for Test Set is: 68.60 | sMAPE for Test Set is: 46.62% | rMAE for Test Set is: 1.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:55:28,316]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:32,760]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:36,962]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:37,235]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:41,007]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:46,522]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:49,039]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:56,484]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:55:56,983]\u001b[0m Trial 388 finished with value: 38.37184250688614 and parameters: {'n_hidden': 3, 'learning_rate': 0.017735779394720964, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2051458536922358, 'dropout_rate_Layer_2': 0.3644048424347591, 'dropout_rate_Layer_3': 0.04096070985560396, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.624521848877161e-05, 'l1_Layer_2': 0.00011535737281433603, 'l1_Layer_3': 1.62366639578412e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 95, 'n_units_Layer_3': 55}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.37 | sMAPE for Validation Set is: 38.46% | rMAE for Validation Set is: 1.54\n",
      "MAE for Test Set is: 58.68 | sMAPE for Test Set is: 39.10% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:56:02,811]\u001b[0m Trial 390 finished with value: 37.22882107676518 and parameters: {'n_hidden': 3, 'learning_rate': 0.014510368687919883, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20318307226548013, 'dropout_rate_Layer_2': 0.37666661425369324, 'dropout_rate_Layer_3': 0.06160071488194527, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1005501793079723e-05, 'l1_Layer_2': 0.00010985406911240934, 'l1_Layer_3': 1.5909680635092066e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 95, 'n_units_Layer_3': 70}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.23 | sMAPE for Validation Set is: 36.72% | rMAE for Validation Set is: 1.50\n",
      "MAE for Test Set is: 60.83 | sMAPE for Test Set is: 41.08% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:56:05,195]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:56:08,458]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:56:12,452]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:56:14,823]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:56:21,940]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:56:26,267]\u001b[0m Trial 397 finished with value: 41.683143985651334 and parameters: {'n_hidden': 3, 'learning_rate': 0.013555507668695078, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18908001621712373, 'dropout_rate_Layer_2': 0.39940773376552974, 'dropout_rate_Layer_3': 0.03931320653252385, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3645049585267794e-05, 'l1_Layer_2': 8.553598371219757e-05, 'l1_Layer_3': 1.6684880365284875e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 100, 'n_units_Layer_3': 75}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.68 | sMAPE for Validation Set is: 43.64% | rMAE for Validation Set is: 1.67\n",
      "MAE for Test Set is: 50.65 | sMAPE for Test Set is: 32.93% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:56:32,140]\u001b[0m Trial 400 finished with value: 41.328621645293424 and parameters: {'n_hidden': 3, 'learning_rate': 0.012892066710586255, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19048041308632013, 'dropout_rate_Layer_2': 0.3615213647575531, 'dropout_rate_Layer_3': 0.07222982983641307, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2525381813404645e-05, 'l1_Layer_2': 8.869587404469764e-05, 'l1_Layer_3': 2.0684432946972673e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 50, 'n_units_Layer_3': 65}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.33 | sMAPE for Validation Set is: 39.47% | rMAE for Validation Set is: 1.66\n",
      "MAE for Test Set is: 64.24 | sMAPE for Test Set is: 43.26% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:56:38,891]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:56:41,779]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:56:44,592]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:56:45,321]\u001b[0m Trial 403 finished with value: 39.52212172641629 and parameters: {'n_hidden': 3, 'learning_rate': 0.01716294263608798, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18342541995504133, 'dropout_rate_Layer_2': 0.39871772312822285, 'dropout_rate_Layer_3': 0.07249332271925057, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2702657197192904e-05, 'l1_Layer_2': 0.000127284147264498, 'l1_Layer_3': 1.3808526782087316e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 65, 'n_units_Layer_3': 80}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.52 | sMAPE for Validation Set is: 43.23% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 57.21 | sMAPE for Test Set is: 38.29% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:56:52,476]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:56:57,230]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:56:57,537]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:56:58,064]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:02,953]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:08,181]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:10,578]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:13,090]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:15,361]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:16,456]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:16,830]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:18,924]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:23,086]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:25,556]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:28,157]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:28,654]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:36,820]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:39,993]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:43,226]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:47,007]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:48,428]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:52,276]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:57,062]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:57,448]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:57:59,648]\u001b[0m Trial 424 finished with value: 37.94519156984472 and parameters: {'n_hidden': 3, 'learning_rate': 0.02075760820797599, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16613711634442363, 'dropout_rate_Layer_2': 0.3663220377980856, 'dropout_rate_Layer_3': 0.0685984365182905, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4927656929549774e-05, 'l1_Layer_2': 0.00012696680202932292, 'l1_Layer_3': 1.730576190612687e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 65}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.95 | sMAPE for Validation Set is: 43.06% | rMAE for Validation Set is: 1.52\n",
      "MAE for Test Set is: 52.24 | sMAPE for Test Set is: 34.61% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:58:05,046]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:05,093]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:05,600]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:14,965]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:16,372]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:19,133]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:19,787]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:20,579]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:21,314]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:30,408]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:34,117]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:34,446]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:38,069]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:43,053]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:43,479]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:43,528]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:52,145]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:52,484]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:58,833]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:58:59,226]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:01,465]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:03,569]\u001b[0m Trial 446 finished with value: 14.330736434499643 and parameters: {'n_hidden': 3, 'learning_rate': 0.003621719444254228, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07885799496343592, 'dropout_rate_Layer_2': 0.380976478145915, 'dropout_rate_Layer_3': 0.07532336172428114, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020770848510126224, 'l1_Layer_2': 0.004981725646616246, 'l1_Layer_3': 0.0007605507958546412, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 200}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.33 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.75 | sMAPE for Test Set is: 20.46% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:59:08,550]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:13,506]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:15,971]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:16,306]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:20,883]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:22,391]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:24,929]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:25,603]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:28,957]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:35,994]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:36,496]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:41,596]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:45,977]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:50,125]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 07:59:53,714]\u001b[0m Trial 465 finished with value: 14.469072812620267 and parameters: {'n_hidden': 3, 'learning_rate': 0.00620982889479891, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05073105268873454, 'dropout_rate_Layer_2': 0.34585051944571826, 'dropout_rate_Layer_3': 0.046205611320512555, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.035378980692350674, 'l1_Layer_2': 0.0017197653549153387, 'l1_Layer_3': 0.0002203917382820548, 'n_units_Layer_1': 165, 'n_units_Layer_2': 70, 'n_units_Layer_3': 200}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.47 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 29.65 | sMAPE for Test Set is: 20.87% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 07:59:56,416]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:03,040]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:03,512]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:03,918]\u001b[0m Trial 466 finished with value: 15.08673008790007 and parameters: {'n_hidden': 3, 'learning_rate': 0.003983211778044111, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17583645053831437, 'dropout_rate_Layer_2': 0.37717570002939144, 'dropout_rate_Layer_3': 0.07661169321475803, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03522039029083039, 'l1_Layer_2': 0.06778357952853802, 'l1_Layer_3': 0.00024198417436248237, 'n_units_Layer_1': 125, 'n_units_Layer_2': 220, 'n_units_Layer_3': 200}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.09 | sMAPE for Validation Set is: 19.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.72 | sMAPE for Test Set is: 21.01% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:00:13,377]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:14,783]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:15,838]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:20,368]\u001b[0m Trial 470 finished with value: 41.852243120561546 and parameters: {'n_hidden': 3, 'learning_rate': 0.02167029476380511, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23749194948315178, 'dropout_rate_Layer_2': 0.3928791558016871, 'dropout_rate_Layer_3': 0.033935349941526895, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1257051597083363e-05, 'l1_Layer_2': 0.0001003011250071118, 'l1_Layer_3': 1.9714265863874998e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 90, 'n_units_Layer_3': 225}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.85 | sMAPE for Validation Set is: 40.79% | rMAE for Validation Set is: 1.68\n",
      "MAE for Test Set is: 74.88 | sMAPE for Test Set is: 52.48% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:00:22,325]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:22,936]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:26,948]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:30,820]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:34,403]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:38,659]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:39,463]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:41,683]\u001b[0m Trial 477 finished with value: 37.748194726353695 and parameters: {'n_hidden': 3, 'learning_rate': 0.014376751085564361, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22440377237970335, 'dropout_rate_Layer_2': 0.36604594531179396, 'dropout_rate_Layer_3': 0.04467128284825379, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.41875655957753e-05, 'l1_Layer_2': 0.000115772668672074, 'l1_Layer_3': 1.6982116979566453e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 85}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.75 | sMAPE for Validation Set is: 37.92% | rMAE for Validation Set is: 1.52\n",
      "MAE for Test Set is: 57.95 | sMAPE for Test Set is: 38.66% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:00:48,347]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:48,905]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:50,553]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:00:54,966]\u001b[0m Trial 481 finished with value: 14.481386916566384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026630047619114945, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04995046255671167, 'dropout_rate_Layer_2': 0.34631755784352497, 'dropout_rate_Layer_3': 0.07745614427254358, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.040370559293973735, 'l1_Layer_2': 0.0026456439162073596, 'l1_Layer_3': 0.0002271773619373237, 'n_units_Layer_1': 125, 'n_units_Layer_2': 215, 'n_units_Layer_3': 210}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.48 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.96 | sMAPE for Test Set is: 20.55% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:00:58,848]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:01,392]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:05,332]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:06,524]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:08,449]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:13,413]\u001b[0m Trial 488 finished with value: 14.398736499248272 and parameters: {'n_hidden': 3, 'learning_rate': 0.002520163883311855, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048705933026724706, 'dropout_rate_Layer_2': 0.32546362464586137, 'dropout_rate_Layer_3': 0.07978506201234178, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.046000429537691914, 'l1_Layer_2': 0.001627906087588586, 'l1_Layer_3': 0.0002486235300424309, 'n_units_Layer_1': 125, 'n_units_Layer_2': 220, 'n_units_Layer_3': 200}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.40 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 29.10 | sMAPE for Test Set is: 20.68% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:01:15,913]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:19,631]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:21,805]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:26,410]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:30,397]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:34,869]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:34,894]\u001b[0m Trial 495 finished with value: 14.961027356978898 and parameters: {'n_hidden': 3, 'learning_rate': 0.006017183465561781, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07963840903764721, 'dropout_rate_Layer_2': 0.3673098861928917, 'dropout_rate_Layer_3': 0.12460465099299109, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07506838179930059, 'l1_Layer_2': 0.0018348976780847971, 'l1_Layer_3': 0.0004263918364192734, 'n_units_Layer_1': 135, 'n_units_Layer_2': 205, 'n_units_Layer_3': 215}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.96 | sMAPE for Validation Set is: 19.52% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.60 | sMAPE for Test Set is: 20.90% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:01:41,978]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:44,525]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:49,352]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:01:53,935]\u001b[0m Trial 501 finished with value: 40.82130383533694 and parameters: {'n_hidden': 3, 'learning_rate': 0.01641396256343732, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2170803589592195, 'dropout_rate_Layer_2': 0.39852016395449125, 'dropout_rate_Layer_3': 0.04212877374111392, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0826814471389546e-05, 'l1_Layer_2': 6.177628788606373e-05, 'l1_Layer_3': 1.4391802971772686e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 80}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.82 | sMAPE for Validation Set is: 40.75% | rMAE for Validation Set is: 1.64\n",
      "MAE for Test Set is: 63.62 | sMAPE for Test Set is: 42.73% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:01:57,567]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:00,465]\u001b[0m Trial 493 finished with value: 27.155421378947732 and parameters: {'n_hidden': 3, 'learning_rate': 0.012745098141161376, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20552033037832734, 'dropout_rate_Layer_2': 0.11496142336566594, 'dropout_rate_Layer_3': 0.03076637519377526, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6096722646654484e-05, 'l1_Layer_2': 5.957044692227833e-05, 'l1_Layer_3': 1.6742440423386722e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 80, 'n_units_Layer_3': 95}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.16 | sMAPE for Validation Set is: 26.46% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 47.69 | sMAPE for Test Set is: 31.34% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:02:04,447]\u001b[0m Trial 504 finished with value: 42.553147235274366 and parameters: {'n_hidden': 3, 'learning_rate': 0.01605195284335095, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22645948816266034, 'dropout_rate_Layer_2': 0.11000434629931631, 'dropout_rate_Layer_3': 0.015474016245426676, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.630537744431854e-05, 'l1_Layer_2': 5.774394695740352e-05, 'l1_Layer_3': 0.0031283005397364245, 'n_units_Layer_1': 200, 'n_units_Layer_2': 50, 'n_units_Layer_3': 70}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.55 | sMAPE for Validation Set is: 40.19% | rMAE for Validation Set is: 1.71\n",
      "MAE for Test Set is: 73.21 | sMAPE for Test Set is: 50.62% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:02:06,435]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:08,127]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:13,631]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:14,119]\u001b[0m Trial 506 finished with value: 40.22876734583516 and parameters: {'n_hidden': 3, 'learning_rate': 0.01596509150778942, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18694311777658457, 'dropout_rate_Layer_2': 0.3866451676988512, 'dropout_rate_Layer_3': 0.39177087487336065, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3810355803717828e-05, 'l1_Layer_2': 0.00020968924670081453, 'l1_Layer_3': 1.3513531527515877e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 250}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.23 | sMAPE for Validation Set is: 39.82% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 61.02 | sMAPE for Test Set is: 40.64% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:02:21,296]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:25,216]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:26,256]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:31,510]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:35,477]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:35,830]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:35,940]\u001b[0m Trial 513 finished with value: 36.77815001513663 and parameters: {'n_hidden': 3, 'learning_rate': 0.010325151918791515, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18683133784476458, 'dropout_rate_Layer_2': 0.03337085949511478, 'dropout_rate_Layer_3': 0.2590517949207158, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3248062586642074e-05, 'l1_Layer_2': 4.6283291348514843e-05, 'l1_Layer_3': 1.4199778039495602e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 255}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.78 | sMAPE for Validation Set is: 37.14% | rMAE for Validation Set is: 1.48\n",
      "MAE for Test Set is: 56.47 | sMAPE for Test Set is: 37.73% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:02:45,033]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:46,523]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:47,536]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:51,783]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:55,275]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:55,759]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.81 | sMAPE for Validation Set is: 25.43% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 38.77 | sMAPE for Test Set is: 25.84% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:02:56,068]\u001b[0m Trial 512 finished with value: 23.805806446149532 and parameters: {'n_hidden': 3, 'learning_rate': 0.013558658289834253, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20816883027149058, 'dropout_rate_Layer_2': 0.13755665820563173, 'dropout_rate_Layer_3': 0.017789012165698493, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9071246676484317e-05, 'l1_Layer_2': 5.848526112283167e-05, 'l1_Layer_3': 0.0020194471643035236, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 80}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:02:57,298]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:04,861]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:07,181]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:08,712]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:11,875]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:15,980]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:18,035]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:27,316]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:32,559]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:37,334]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:42,091]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:48,059]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:48,341]\u001b[0m Trial 528 finished with value: 28.706382879724725 and parameters: {'n_hidden': 3, 'learning_rate': 0.012865055521729165, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19383288055764938, 'dropout_rate_Layer_2': 0.004138077994580129, 'dropout_rate_Layer_3': 0.19145186310429974, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.882427775537557e-05, 'l1_Layer_2': 4.2870011127411846e-05, 'l1_Layer_3': 1.793871535980098e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 85, 'n_units_Layer_3': 80}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.71 | sMAPE for Validation Set is: 28.52% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 47.38 | sMAPE for Test Set is: 30.96% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:03:48,847]\u001b[0m Trial 534 finished with value: 25.334859666073736 and parameters: {'n_hidden': 3, 'learning_rate': 0.013590273413343238, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20403281340986495, 'dropout_rate_Layer_2': 0.1736540614702182, 'dropout_rate_Layer_3': 0.020362398134867805, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4544509616564463e-05, 'l1_Layer_2': 3.764626765559308e-05, 'l1_Layer_3': 1.7244679271594223e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 55, 'n_units_Layer_3': 255}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.33 | sMAPE for Validation Set is: 25.82% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 41.55 | sMAPE for Test Set is: 27.32% | rMAE for Test Set is: 1.05\n",
      "MAE for Validation Set is: 21.45 | sMAPE for Validation Set is: 23.94% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 39.63 | sMAPE for Test Set is: 26.55% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:03:54,853]\u001b[0m Trial 533 finished with value: 21.45245713802689 and parameters: {'n_hidden': 3, 'learning_rate': 0.013836931624025403, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20593323765527113, 'dropout_rate_Layer_2': 0.011234916220384361, 'dropout_rate_Layer_3': 0.2547134285948318, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3280626930052919e-05, 'l1_Layer_2': 2.4802302573854735e-05, 'l1_Layer_3': 1.8140809509323797e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 100, 'n_units_Layer_3': 260}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:55,557]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:03:58,988]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:00,927]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:05,648]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:09,756]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:10,860]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:15,600]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:16,933]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:17,074]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:22,521]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:26,873]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:28,741]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:32,784]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:37,771]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:39,530]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:43,270]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:43,891]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:47,832]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:51,506]\u001b[0m Trial 551 finished with value: 41.596525860591136 and parameters: {'n_hidden': 3, 'learning_rate': 0.015034242323701444, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19633880336692008, 'dropout_rate_Layer_2': 0.18135812918971767, 'dropout_rate_Layer_3': 0.2042481771344747, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.189078508498391e-05, 'l1_Layer_2': 3.619455216309835e-05, 'l1_Layer_3': 1.7317782073296183e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 80, 'n_units_Layer_3': 255}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.60 | sMAPE for Validation Set is: 39.24% | rMAE for Validation Set is: 1.67\n",
      "MAE for Test Set is: 66.93 | sMAPE for Test Set is: 45.52% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:04:53,250]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:53,865]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:54,792]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:04:55,994]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:00,965]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:02,496]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:05,798]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:10,744]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:14,053]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:16,991]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:20,591]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:22,614]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:26,699]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:29,266]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:32,979]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:34,135]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:35,812]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:39,771]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:47,192]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:47,237]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:54,445]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:05:56,009]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:09,421]\u001b[0m Trial 583 finished with value: 14.442881905677375 and parameters: {'n_hidden': 3, 'learning_rate': 0.005231353101166649, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09686907442351406, 'dropout_rate_Layer_2': 0.35243966233223556, 'dropout_rate_Layer_3': 0.08895961614368787, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008949854127917507, 'l1_Layer_2': 9.391074635112079e-05, 'l1_Layer_3': 0.0014872820069161817, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 205}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.44 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.49 | sMAPE for Test Set is: 20.31% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:06:14,405]\u001b[0m Trial 584 finished with value: 14.557301386317283 and parameters: {'n_hidden': 3, 'learning_rate': 0.004908591867912724, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03165682616710204, 'dropout_rate_Layer_2': 0.014828195509238112, 'dropout_rate_Layer_3': 0.08539539120443425, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06219607294856939, 'l1_Layer_2': 0.00010729507343858579, 'l1_Layer_3': 0.0003344350773853571, 'n_units_Layer_1': 130, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.56 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.53 | sMAPE for Test Set is: 20.38% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:06:15,120]\u001b[0m Trial 568 finished with value: 31.200556729489758 and parameters: {'n_hidden': 3, 'learning_rate': 0.01704415873286579, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18138655017048713, 'dropout_rate_Layer_2': 0.04441357964845856, 'dropout_rate_Layer_3': 0.028490199778581665, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1717138600196182e-05, 'l1_Layer_2': 6.362465518020657e-05, 'l1_Layer_3': 2.1869012962326515e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 85, 'n_units_Layer_3': 85}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.20 | sMAPE for Validation Set is: 29.79% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 52.41 | sMAPE for Test Set is: 34.45% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:06:20,440]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:21,929]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:23,516]\u001b[0m Trial 580 finished with value: 24.66583081277445 and parameters: {'n_hidden': 3, 'learning_rate': 0.017800101318392127, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2021861073284153, 'dropout_rate_Layer_2': 0.04355647735319904, 'dropout_rate_Layer_3': 0.3496041998466556, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8473941190650974e-05, 'l1_Layer_2': 5.83629918112765e-05, 'l1_Layer_3': 1.2807608305683477e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 55, 'n_units_Layer_3': 75}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.67 | sMAPE for Validation Set is: 25.64% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 41.73 | sMAPE for Test Set is: 27.37% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:06:24,065]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:28,041]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:33,556]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:33,925]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:34,110]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:42,608]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:44,704]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:45,964]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:48,768]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:06:54,369]\u001b[0m Trial 589 finished with value: 15.023653481201004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013482704585222965, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09920764133986792, 'dropout_rate_Layer_2': 0.02144069067056679, 'dropout_rate_Layer_3': 0.10251949917811949, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010163326187899212, 'l1_Layer_2': 7.524561626953721e-05, 'l1_Layer_3': 0.0001709811158312177, 'n_units_Layer_1': 135, 'n_units_Layer_2': 125, 'n_units_Layer_3': 215}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.02 | sMAPE for Validation Set is: 18.70% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.78 | sMAPE for Test Set is: 20.55% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:06:57,225]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:00,976]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:07,155]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:11,001]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:16,823]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:19,949]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:20,347]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:26,317]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:26,931]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:28,745]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:33,958]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:38,512]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:44,879]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:46,907]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:50,919]\u001b[0m Trial 609 finished with value: 14.903672004426992 and parameters: {'n_hidden': 3, 'learning_rate': 0.000898992128934321, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09626671006427365, 'dropout_rate_Layer_2': 0.007060708586330195, 'dropout_rate_Layer_3': 0.07170270706083046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03569530923777771, 'l1_Layer_2': 7.148556737714869e-05, 'l1_Layer_3': 0.00019363216736163516, 'n_units_Layer_1': 155, 'n_units_Layer_2': 120, 'n_units_Layer_3': 200}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.90 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 30.46 | sMAPE for Test Set is: 21.27% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:07:52,848]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:57,221]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:07:59,077]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:03,186]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:07,602]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:11,600]\u001b[0m Trial 613 finished with value: 14.608155851217623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013458152579257374, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05449584338224593, 'dropout_rate_Layer_2': 0.02145634208932618, 'dropout_rate_Layer_3': 0.12246767391485758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06014091839605279, 'l1_Layer_2': 0.00018379665370207033, 'l1_Layer_3': 0.0005567370793046635, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 215}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.61 | sMAPE for Validation Set is: 18.87% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.66 | sMAPE for Test Set is: 20.45% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:08:15,136]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:19,755]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:26,581]\u001b[0m Trial 618 finished with value: 14.759700082666148 and parameters: {'n_hidden': 3, 'learning_rate': 0.001095677241492616, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09725015590697714, 'dropout_rate_Layer_2': 0.024327950697987866, 'dropout_rate_Layer_3': 0.11600214053992729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06072621779102982, 'l1_Layer_2': 2.3675254774890353e-05, 'l1_Layer_3': 0.00016926313102354958, 'n_units_Layer_1': 145, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 286 with value: 13.342638082846138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.76 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.35 | sMAPE for Test Set is: 20.74% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:08:27,862]\u001b[0m Trial 599 finished with value: 13.036916172602796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006159680770569392, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12514427302625003, 'dropout_rate_Layer_2': 0.22210527261398413, 'dropout_rate_Layer_3': 0.21825931537906285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010888016228696089, 'l1_Layer_2': 0.0013322209300513203, 'l1_Layer_3': 5.176627994030642e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.04 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 26.09 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:08:29,966]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.87 | sMAPE for Validation Set is: 18.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.40 | sMAPE for Test Set is: 20.77% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:08:32,524]\u001b[0m Trial 621 finished with value: 14.871598441507563 and parameters: {'n_hidden': 3, 'learning_rate': 0.001046334185979029, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09745848100702383, 'dropout_rate_Layer_2': 1.4699530790172194e-05, 'dropout_rate_Layer_3': 0.12190523361885924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06388966576869658, 'l1_Layer_2': 0.00014022544624480804, 'l1_Layer_3': 0.0001819651631835821, 'n_units_Layer_1': 145, 'n_units_Layer_2': 105, 'n_units_Layer_3': 215}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:32,797]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:38,322]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:43,933]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:46,619]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:46,756]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:47,134]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:59,069]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:08:59,223]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:06,742]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:09,100]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:10,452]\u001b[0m Trial 630 finished with value: 14.674414698091965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010122027746953496, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05060798484322503, 'dropout_rate_Layer_2': 0.002783678491730844, 'dropout_rate_Layer_3': 0.11417091738452914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09605033372740714, 'l1_Layer_2': 1.6373948491221813e-05, 'l1_Layer_3': 0.0005299183670575671, 'n_units_Layer_1': 155, 'n_units_Layer_2': 150, 'n_units_Layer_3': 225}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.67 | sMAPE for Validation Set is: 19.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.28 | sMAPE for Test Set is: 20.62% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:09:15,753]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:18,564]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:19,156]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:19,421]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:21,085]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:30,443]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:30,892]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:31,132]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:31,917]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:43,048]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:44,071]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:47,925]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:50,051]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:50,984]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:09:55,760]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:10:02,543]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:10:07,216]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:10:15,741]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:10:20,429]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:10:25,361]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:10:26,197]\u001b[0m Trial 651 finished with value: 14.689112727961728 and parameters: {'n_hidden': 3, 'learning_rate': 0.00124093948037707, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03585046333177973, 'dropout_rate_Layer_2': 0.009538424312991423, 'dropout_rate_Layer_3': 0.11470642343411046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.045607491575783, 'l1_Layer_2': 1.704241811823217e-05, 'l1_Layer_3': 0.0019002932961298053, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 205}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.69 | sMAPE for Validation Set is: 19.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.57 | sMAPE for Test Set is: 20.78% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:10:34,015]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.80 | sMAPE for Validation Set is: 19.37% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.41 | sMAPE for Test Set is: 20.73% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:10:36,662]\u001b[0m Trial 653 finished with value: 14.80023388911892 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011283351232284908, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.038854405860186764, 'dropout_rate_Layer_2': 0.00648601111977831, 'dropout_rate_Layer_3': 0.11091900567522034, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.060941953115243544, 'l1_Layer_2': 1.8324971539699235e-05, 'l1_Layer_3': 0.001765840691914831, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 195}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:10:39,438]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:10:40,699]\u001b[0m Trial 650 finished with value: 21.856144238003083 and parameters: {'n_hidden': 3, 'learning_rate': 0.012750399014857389, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19181678395800125, 'dropout_rate_Layer_2': 0.09991560407812722, 'dropout_rate_Layer_3': 0.27066521311545516, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.313705984819314e-05, 'l1_Layer_2': 7.375210166703354e-05, 'l1_Layer_3': 1.3713519199180626e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 50, 'n_units_Layer_3': 255}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.86 | sMAPE for Validation Set is: 25.45% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 35.55 | sMAPE for Test Set is: 24.09% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:10:45,755]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:10:51,980]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:10:53,747]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:10:54,624]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:01,627]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:01,833]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:09,149]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:13,925]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:17,969]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:18,889]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:21,992]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:25,930]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:28,263]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:35,865]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:39,089]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:39,664]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:42,538]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:44,321]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:53,263]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:54,016]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:11:57,188]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:02,298]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:06,297]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:06,936]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:12,956]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:17,453]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:18,072]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.21 | sMAPE for Validation Set is: 43.29% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 58.68 | sMAPE for Test Set is: 39.06% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:12:24,202]\u001b[0m Trial 685 finished with value: 40.21244499206238 and parameters: {'n_hidden': 3, 'learning_rate': 0.013787106006167157, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15651726844953717, 'dropout_rate_Layer_2': 0.3442411732907773, 'dropout_rate_Layer_3': 0.2515934445414548, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1840475576137536e-05, 'l1_Layer_2': 6.296174439195729e-05, 'l1_Layer_3': 2.6938286636852578e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 90, 'n_units_Layer_3': 220}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:29,000]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:29,180]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:29,905]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:30,535]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:37,190]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:38,279]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:39,582]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:39,772]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:46,846]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:49,292]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:52,541]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:54,981]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:56,160]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:12:58,322]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:02,343]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:06,602]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:07,240]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:10,531]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:11,069]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:13,486]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:15,841]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:20,280]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:20,985]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:27,015]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:31,047]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:34,858]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:35,821]\u001b[0m Trial 711 finished with value: 42.811025163792976 and parameters: {'n_hidden': 3, 'learning_rate': 0.018779546338920546, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1432948754099537, 'dropout_rate_Layer_2': 0.3549700867931314, 'dropout_rate_Layer_3': 0.3943647989999562, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0279580162424317e-05, 'l1_Layer_2': 8.909281427842432e-05, 'l1_Layer_3': 1.8566337422006363e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 80, 'n_units_Layer_3': 100}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.81 | sMAPE for Validation Set is: 42.44% | rMAE for Validation Set is: 1.72\n",
      "MAE for Test Set is: 60.08 | sMAPE for Test Set is: 40.15% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:13:36,419]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:36,616]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:47,733]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:52,003]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:52,827]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:13:59,957]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:00,637]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:04,966]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:06,157]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:10,925]\u001b[0m Trial 721 finished with value: 37.82945203340447 and parameters: {'n_hidden': 3, 'learning_rate': 0.01447919357395964, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1732639844803961, 'dropout_rate_Layer_2': 0.39059474518243315, 'dropout_rate_Layer_3': 0.24524816610756986, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.926426306829246e-05, 'l1_Layer_2': 7.66139805410463e-05, 'l1_Layer_3': 2.3270028612047565e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 225}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.83 | sMAPE for Validation Set is: 42.88% | rMAE for Validation Set is: 1.52\n",
      "MAE for Test Set is: 45.32 | sMAPE for Test Set is: 29.99% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:14:11,567]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:13,692]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:16,759]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:21,342]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:28,216]\u001b[0m Trial 725 finished with value: 40.272563769130294 and parameters: {'n_hidden': 3, 'learning_rate': 0.009690090777150644, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16872419883416148, 'dropout_rate_Layer_2': 0.3423666454642508, 'dropout_rate_Layer_3': 0.01373281155441769, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.207920613976466e-05, 'l1_Layer_2': 4.353086431022442e-05, 'l1_Layer_3': 2.295190983201061e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 85, 'n_units_Layer_3': 90}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.27 | sMAPE for Validation Set is: 40.38% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 60.06 | sMAPE for Test Set is: 40.23% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:14:32,662]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:35,303]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:38,593]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:47,338]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:47,779]\u001b[0m Trial 731 finished with value: 14.919647456491353 and parameters: {'n_hidden': 3, 'learning_rate': 0.000983768768757674, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13180316565412462, 'dropout_rate_Layer_2': 0.010096715655207672, 'dropout_rate_Layer_3': 0.0657259563095729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.054624212630165855, 'l1_Layer_2': 1.3310239809553325e-05, 'l1_Layer_3': 0.0003545322498815475, 'n_units_Layer_1': 155, 'n_units_Layer_2': 120, 'n_units_Layer_3': 210}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.92 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.90 | sMAPE for Test Set is: 20.56% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:14:48,684]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:56,682]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:14:57,506]\u001b[0m Trial 730 finished with value: 25.285199706003322 and parameters: {'n_hidden': 3, 'learning_rate': 0.011650923556688125, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15960342976909195, 'dropout_rate_Layer_2': 0.3996351253115419, 'dropout_rate_Layer_3': 0.26456703482901855, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.816725298023406e-05, 'l1_Layer_2': 4.4088719398362254e-05, 'l1_Layer_3': 3.253156860755687e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 220}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.29 | sMAPE for Validation Set is: 25.46% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 43.20 | sMAPE for Test Set is: 28.64% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:14:58,219]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:01,205]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:10,146]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:10,534]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:10,775]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:11,054]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:18,236]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:20,626]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:22,170]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:25,982]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:26,673]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:31,532]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:36,050]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:37,672]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:38,125]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:38,701]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:46,215]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:49,467]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:49,689]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:50,522]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:52,691]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:55,889]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:15:58,147]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:00,880]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:01,611]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:08,059]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:08,772]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:12,445]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:15,523]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:19,992]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:24,054]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:24,142]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:24,173]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:31,858]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:32,546]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:32,842]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:40,271]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:41,078]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:49,013]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:53,963]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:16:59,998]\u001b[0m Trial 779 finished with value: 38.040409088388806 and parameters: {'n_hidden': 3, 'learning_rate': 0.01822592325392356, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20342822919115078, 'dropout_rate_Layer_2': 0.1694105084523343, 'dropout_rate_Layer_3': 0.08644642668637503, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.391364395333893e-05, 'l1_Layer_2': 9.487572784144335e-05, 'l1_Layer_3': 0.0005284718196754317, 'n_units_Layer_1': 185, 'n_units_Layer_2': 55, 'n_units_Layer_3': 260}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 38.04 | sMAPE for Validation Set is: 38.96% | rMAE for Validation Set is: 1.53\n",
      "MAE for Test Set is: 51.77 | sMAPE for Test Set is: 33.88% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:17:00,220]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:01,074]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:09,775]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:10,402]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:12,956]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:17,195]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:21,699]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:21,974]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:23,017]\u001b[0m Trial 768 finished with value: 13.555698396426171 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008847293899745841, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10946870049979204, 'dropout_rate_Layer_2': 0.18975325130401258, 'dropout_rate_Layer_3': 0.2305924580019826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005948626243203598, 'l1_Layer_2': 0.009311667056694626, 'l1_Layer_3': 2.2415843330065708e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 120}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.56 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 27.90 | sMAPE for Test Set is: 19.80% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:17:28,755]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:31,893]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:32,506]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:38,478]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:41,527]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:42,232]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:47,475]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:50,893]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:17:56,256]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:18:00,641]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:18:06,445]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:18:43,601]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:18:50,661]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:18:56,845]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:18:57,000]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:02,853]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:03,180]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:06,864]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:11,867]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:13,908]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:16,813]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:19,857]\u001b[0m Trial 802 finished with value: 27.914987347059412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0785429770254393, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20266526420751177, 'dropout_rate_Layer_2': 0.08547128172518202, 'dropout_rate_Layer_3': 0.09904089283127208, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6568974864045525e-05, 'l1_Layer_2': 7.436620015683718e-05, 'l1_Layer_3': 0.00042858704857112994, 'n_units_Layer_1': 130, 'n_units_Layer_2': 55, 'n_units_Layer_3': 255}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.91 | sMAPE for Validation Set is: 28.89% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 50.32 | sMAPE for Test Set is: 34.35% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:19:24,587]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:27,737]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:28,445]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:28,476]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:33,839]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:39,897]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:40,731]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:45,073]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:48,200]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:55,970]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:19:58,621]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:06,823]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:09,138]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:11,773]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:11,910]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:18,336]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:20,387]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:23,356]\u001b[0m Trial 819 finished with value: 14.891296646144914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008829394084120611, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0900766636596339, 'dropout_rate_Layer_2': 0.029337130201844495, 'dropout_rate_Layer_3': 0.05951297770499757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0811071766690522, 'l1_Layer_2': 0.00014520815942697837, 'l1_Layer_3': 0.0008624448175128931, 'n_units_Layer_1': 135, 'n_units_Layer_2': 125, 'n_units_Layer_3': 215}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.89 | sMAPE for Validation Set is: 19.29% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.94 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:20:24,029]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:29,759]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:32,562]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:37,413]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:39,347]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:45,132]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:48,740]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:51,303]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:51,604]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:20:53,379]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:01,085]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:01,155]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:02,823]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:02,892]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:08,313]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:10,842]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:17,818]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:18,070]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:19,692]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:26,842]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:27,362]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:32,472]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:37,756]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:38,091]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:38,991]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:40,909]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:47,795]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:48,406]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:49,424]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:55,479]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:57,175]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:58,202]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:21:58,436]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:02,420]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:05,998]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:09,955]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:16,688]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:20,441]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:21,298]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:24,033]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:27,430]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:29,658]\u001b[0m Trial 865 finished with value: 39.86427786088523 and parameters: {'n_hidden': 3, 'learning_rate': 0.09723946136150378, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18870039157084578, 'dropout_rate_Layer_2': 0.3574444145574167, 'dropout_rate_Layer_3': 0.028015231808126196, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5280053218711318e-05, 'l1_Layer_2': 2.066054577441839e-05, 'l1_Layer_3': 0.002008833300245043, 'n_units_Layer_1': 120, 'n_units_Layer_2': 55, 'n_units_Layer_3': 70}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.86 | sMAPE for Validation Set is: 38.82% | rMAE for Validation Set is: 1.60\n",
      "MAE for Test Set is: 67.48 | sMAPE for Test Set is: 45.93% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:22:30,237]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:36,600]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:37,140]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:38,315]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:44,618]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:47,125]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:48,111]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:49,149]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:22:50,272]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:00,439]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:02,122]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:02,734]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:03,817]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:13,591]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:14,252]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:14,371]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:17,512]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:22,248]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:25,993]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:28,890]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:29,362]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:29,938]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:34,054]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:37,346]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:38,830]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:39,743]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:40,718]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:48,234]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:48,787]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:50,649]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:23:52,016]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:00,398]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:00,480]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:01,029]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:01,846]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:10,503]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:16,226]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:19,119]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:23,027]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:28,490]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:29,198]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:35,259]\u001b[0m Trial 907 finished with value: 36.55596303208997 and parameters: {'n_hidden': 3, 'learning_rate': 0.021259393724856218, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17009203447029336, 'dropout_rate_Layer_2': 0.37895512687879235, 'dropout_rate_Layer_3': 0.3313769134327585, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3265467354940681e-05, 'l1_Layer_2': 0.00020014407477283303, 'l1_Layer_3': 1.9059673330970432e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 265}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.56 | sMAPE for Validation Set is: 48.54% | rMAE for Validation Set is: 1.47\n",
      "MAE for Test Set is: 45.82 | sMAPE for Test Set is: 30.34% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:24:38,062]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:41,268]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:41,861]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:42,703]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:46,824]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:49,044]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:52,768]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:52,868]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:54,745]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:24:55,679]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:05,436]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:05,635]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:05,846]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:14,637]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:17,104]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:20,517]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:23,753]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:27,045]\u001b[0m Trial 926 finished with value: 14.769809857857737 and parameters: {'n_hidden': 3, 'learning_rate': 0.005738671494325278, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04254655545699371, 'dropout_rate_Layer_2': 0.3397308187186144, 'dropout_rate_Layer_3': 0.0884882975653511, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04806562487438164, 'l1_Layer_2': 0.0014831136435768557, 'l1_Layer_3': 0.00020683533850960925, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 200}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.77 | sMAPE for Validation Set is: 19.48% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.78 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:25:27,746]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:28,595]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:34,608]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:36,481]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:38,982]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:44,692]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:46,949]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:50,754]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:53,358]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:53,550]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:25:54,112]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:03,559]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:03,858]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:04,578]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:12,468]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:14,234]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:14,807]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:19,773]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:21,819]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:29,268]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:34,176]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:38,271]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:39,071]\u001b[0m Trial 924 finished with value: 13.390331593822944 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006099979920030252, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16751223888742256, 'dropout_rate_Layer_2': 0.15897031877010012, 'dropout_rate_Layer_3': 0.23599971511243098, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011538348605457194, 'l1_Layer_2': 0.004422227991767822, 'l1_Layer_3': 3.754265942618672e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 235, 'n_units_Layer_3': 215}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.39 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 28.22 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:26:45,277]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:45,474]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:26:56,863]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:27:01,911]\u001b[0m Trial 950 finished with value: 14.736280261023415 and parameters: {'n_hidden': 3, 'learning_rate': 0.014010738928168105, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17858056721905008, 'dropout_rate_Layer_2': 0.01962039522385609, 'dropout_rate_Layer_3': 0.07577030629266789, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3054258620101073e-05, 'l1_Layer_2': 0.0004253167717754046, 'l1_Layer_3': 1.2064811650698352e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 285, 'n_units_Layer_3': 265}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.74 | sMAPE for Validation Set is: 18.48% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.09 | sMAPE for Test Set is: 19.43% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:27:06,883]\u001b[0m Trial 956 finished with value: 14.688424190379942 and parameters: {'n_hidden': 3, 'learning_rate': 0.013783838964134229, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23301073043949272, 'dropout_rate_Layer_2': 0.02664477501403721, 'dropout_rate_Layer_3': 0.06608141291292596, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3158155646670724e-05, 'l1_Layer_2': 7.00200063075265e-05, 'l1_Layer_3': 1.327906521730878e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.69 | sMAPE for Validation Set is: 19.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.88 | sMAPE for Test Set is: 19.85% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:27:07,450]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:27:07,775]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:27:17,703]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:27:22,276]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:27:39,308]\u001b[0m Trial 963 finished with value: 14.481199305651353 and parameters: {'n_hidden': 3, 'learning_rate': 0.011355540958387275, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2313468397784431, 'dropout_rate_Layer_2': 0.02044799928789687, 'dropout_rate_Layer_3': 0.07697467937699798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.743981494076222e-05, 'l1_Layer_2': 0.00026680751709639715, 'l1_Layer_3': 1.1332287160292555e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.48 | sMAPE for Validation Set is: 19.46% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.29 | sMAPE for Test Set is: 19.58% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:27:40,367]\u001b[0m Trial 964 finished with value: 16.0830466870897 and parameters: {'n_hidden': 3, 'learning_rate': 0.011725479083986136, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15917022119272667, 'dropout_rate_Layer_2': 0.021455606184659352, 'dropout_rate_Layer_3': 0.07640498708983465, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3638345100628897e-05, 'l1_Layer_2': 4.028553862723329e-05, 'l1_Layer_3': 1.135213591030318e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.08 | sMAPE for Validation Set is: 20.66% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 33.20 | sMAPE for Test Set is: 22.37% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:27:47,629]\u001b[0m Trial 961 finished with value: 14.130006361840712 and parameters: {'n_hidden': 3, 'learning_rate': 0.011449882880700165, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15978797467397593, 'dropout_rate_Layer_2': 0.016805957585603704, 'dropout_rate_Layer_3': 0.0776453682629383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6624175794596183e-05, 'l1_Layer_2': 0.0004894048390709555, 'l1_Layer_3': 1.0091365128370092e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 200, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.13 | sMAPE for Validation Set is: 19.41% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.60 | sMAPE for Test Set is: 19.67% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:28:00,137]\u001b[0m Trial 965 finished with value: 15.0897266086714 and parameters: {'n_hidden': 3, 'learning_rate': 0.01131680842132921, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16167032847684956, 'dropout_rate_Layer_2': 0.01700949981388768, 'dropout_rate_Layer_3': 0.0751262765911507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6286282749152354e-05, 'l1_Layer_2': 0.00020839419992695684, 'l1_Layer_3': 1.0921742824177173e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 290, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.09 | sMAPE for Validation Set is: 19.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 32.70 | sMAPE for Test Set is: 22.16% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:28:10,820]\u001b[0m Trial 966 finished with value: 14.513698391017803 and parameters: {'n_hidden': 3, 'learning_rate': 0.009507408086719247, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24357328837779044, 'dropout_rate_Layer_2': 0.021173726101647992, 'dropout_rate_Layer_3': 0.0793372075258355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015482921462583793, 'l1_Layer_2': 0.00023138950380781304, 'l1_Layer_3': 1.038865482580605e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.51 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.63 | sMAPE for Test Set is: 20.28% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:28:11,229]\u001b[0m Trial 967 finished with value: 14.804577382549892 and parameters: {'n_hidden': 3, 'learning_rate': 0.009433475469337012, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23916070069114148, 'dropout_rate_Layer_2': 0.023410573926539564, 'dropout_rate_Layer_3': 0.08177832345262956, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.651909534764384e-05, 'l1_Layer_2': 0.00023860034673940084, 'l1_Layer_3': 1.0113373816603595e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.80 | sMAPE for Validation Set is: 19.41% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.78 | sMAPE for Test Set is: 20.83% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:28:19,460]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:28:25,324]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:28:36,156]\u001b[0m Trial 968 finished with value: 14.642775093894763 and parameters: {'n_hidden': 3, 'learning_rate': 0.009330042434570751, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15863498273883248, 'dropout_rate_Layer_2': 0.01972941534995204, 'dropout_rate_Layer_3': 0.07152281770023713, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.519157363924366e-05, 'l1_Layer_2': 0.0004381875100139462, 'l1_Layer_3': 1.0657968232795758e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 285, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.64 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.98 | sMAPE for Test Set is: 20.45% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:28:46,302]\u001b[0m Trial 970 finished with value: 15.025416210762728 and parameters: {'n_hidden': 3, 'learning_rate': 0.01012874956117748, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24744313871071544, 'dropout_rate_Layer_2': 0.018058533453664122, 'dropout_rate_Layer_3': 0.07775148623450329, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.73344601669953e-05, 'l1_Layer_2': 0.00029745615161343224, 'l1_Layer_3': 1.0160331939087556e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 290, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.03 | sMAPE for Validation Set is: 19.57% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.89 | sMAPE for Test Set is: 20.45% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:28:50,644]\u001b[0m Trial 969 finished with value: 13.955769954975311 and parameters: {'n_hidden': 3, 'learning_rate': 0.011673195438506864, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15942431811223115, 'dropout_rate_Layer_2': 0.01993830747170519, 'dropout_rate_Layer_3': 0.07767941293938233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.830393576762939e-05, 'l1_Layer_2': 0.00046485997410813305, 'l1_Layer_3': 1.007862873518519e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 215, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.96 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.78 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:28:51,561]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:28:56,934]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:29:04,630]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:29:11,023]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:29:19,324]\u001b[0m Trial 974 finished with value: 13.900234862893987 and parameters: {'n_hidden': 3, 'learning_rate': 0.007600754526654709, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2416494668830827, 'dropout_rate_Layer_2': 0.02083539712396606, 'dropout_rate_Layer_3': 0.07999736010361222, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4104917003858096e-05, 'l1_Layer_2': 0.000406316020370253, 'l1_Layer_3': 1.0049833791994581e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 280, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.90 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 29.22 | sMAPE for Test Set is: 20.41% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:29:22,676]\u001b[0m Trial 973 finished with value: 14.691261400575963 and parameters: {'n_hidden': 3, 'learning_rate': 0.009420777343464297, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22997014927792722, 'dropout_rate_Layer_2': 0.023070761730085716, 'dropout_rate_Layer_3': 0.0853567292671764, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001212358676424252, 'l1_Layer_2': 0.0004035769809538563, 'l1_Layer_3': 1.076628267931547e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.69 | sMAPE for Validation Set is: 19.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.98 | sMAPE for Test Set is: 20.50% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:29:29,471]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:29:33,744]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:29:35,039]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:29:40,191]\u001b[0m Trial 978 finished with value: 14.526314986681138 and parameters: {'n_hidden': 3, 'learning_rate': 0.007796341648344751, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2466227616848043, 'dropout_rate_Layer_2': 0.02210321191478802, 'dropout_rate_Layer_3': 0.08081721850520088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019084131180463174, 'l1_Layer_2': 0.000432343230559613, 'l1_Layer_3': 1.0207985809682208e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 285, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.53 | sMAPE for Validation Set is: 19.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 30.81 | sMAPE for Test Set is: 21.40% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:29:54,343]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:29:56,785]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:30:01,833]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:30:02,176]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:30:11,288]\u001b[0m Trial 982 finished with value: 13.919242910869295 and parameters: {'n_hidden': 3, 'learning_rate': 0.007295708498042743, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2502487729973712, 'dropout_rate_Layer_2': 0.018445351861149494, 'dropout_rate_Layer_3': 0.08258658729533502, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001647448507309576, 'l1_Layer_2': 0.00046520534707361605, 'l1_Layer_3': 1.0103638099522778e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 285, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.92 | sMAPE for Validation Set is: 18.69% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.50 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:30:11,880]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:30:17,916]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:30:34,431]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:30:38,335]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:30:42,141]\u001b[0m Trial 993 finished with value: 15.253164173309834 and parameters: {'n_hidden': 3, 'learning_rate': 0.0070855611927127604, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25241436521145943, 'dropout_rate_Layer_2': 0.022960605655980855, 'dropout_rate_Layer_3': 0.09552169712031221, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001576591131725514, 'l1_Layer_2': 0.00048092834609193683, 'l1_Layer_3': 1.0607971672119336e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.25 | sMAPE for Validation Set is: 20.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.19 | sMAPE for Test Set is: 19.53% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:30:47,790]\u001b[0m Trial 988 finished with value: 14.457390800440885 and parameters: {'n_hidden': 3, 'learning_rate': 0.007399293297956648, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24587453236724974, 'dropout_rate_Layer_2': 0.01929395700483984, 'dropout_rate_Layer_3': 0.09322190605404339, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001074337770390185, 'l1_Layer_2': 0.00043645626253430495, 'l1_Layer_3': 1.028160997693273e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.46 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.78 | sMAPE for Test Set is: 19.30% | rMAE for Test Set is: 0.67\n",
      "MAE for Validation Set is: 14.47 | sMAPE for Validation Set is: 18.79% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.68 | sMAPE for Test Set is: 20.38% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:30:49,908]\u001b[0m Trial 990 finished with value: 14.47436586992201 and parameters: {'n_hidden': 3, 'learning_rate': 0.006474700121847063, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2544201004818536, 'dropout_rate_Layer_2': 0.018491354947452947, 'dropout_rate_Layer_3': 0.09345338187595455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014099528690515021, 'l1_Layer_2': 0.00047001242965485386, 'l1_Layer_3': 1.0082575353684678e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 290, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:31:01,476]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:31:06,153]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:31:13,910]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:31:21,281]\u001b[0m Trial 997 finished with value: 14.52639706346742 and parameters: {'n_hidden': 3, 'learning_rate': 0.006241458075653106, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.253840652514507, 'dropout_rate_Layer_2': 0.023460999143344763, 'dropout_rate_Layer_3': 0.0845821691694742, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011271610738491772, 'l1_Layer_2': 0.0004530779976680573, 'l1_Layer_3': 1.0051557059809087e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 285, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.53 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 29.88 | sMAPE for Test Set is: 20.86% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:31:25,210]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:31:29,190]\u001b[0m Trial 1001 finished with value: 14.70839186086335 and parameters: {'n_hidden': 3, 'learning_rate': 0.00679101346615328, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08555783324612506, 'dropout_rate_Layer_2': 0.37167676935737487, 'dropout_rate_Layer_3': 0.12306231302098936, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.050453154327069205, 'l1_Layer_2': 0.0014609464198281677, 'l1_Layer_3': 0.0004591600449586879, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 220}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.71 | sMAPE for Validation Set is: 19.39% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.93 | sMAPE for Test Set is: 20.60% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:31:39,502]\u001b[0m Trial 1000 finished with value: 14.309836081334943 and parameters: {'n_hidden': 3, 'learning_rate': 0.006500431172056858, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25045576441773976, 'dropout_rate_Layer_2': 0.02485423424028822, 'dropout_rate_Layer_3': 0.10366476916436898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010815335928326495, 'l1_Layer_2': 0.00051491769656958, 'l1_Layer_3': 1.0502340925611484e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.31 | sMAPE for Validation Set is: 18.65% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.67 | sMAPE for Test Set is: 19.69% | rMAE for Test Set is: 0.70\n",
      "MAE for Validation Set is: 14.37 | sMAPE for Validation Set is: 18.94% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 29.35 | sMAPE for Test Set is: 20.57% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:31:39,559]\u001b[0m Trial 999 finished with value: 14.37079832640773 and parameters: {'n_hidden': 3, 'learning_rate': 0.006797757832457922, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2508397760071515, 'dropout_rate_Layer_2': 0.02542877073355339, 'dropout_rate_Layer_3': 0.08313129389256772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011278794537622917, 'l1_Layer_2': 0.0005725834340743405, 'l1_Layer_3': 1.0047462358318497e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:31:47,048]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:31:50,361]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:31:55,580]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:32:11,022]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:32:16,145]\u001b[0m Trial 1007 finished with value: 14.324522085739801 and parameters: {'n_hidden': 3, 'learning_rate': 0.004891253603676185, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24808376874497196, 'dropout_rate_Layer_2': 0.01413431191400989, 'dropout_rate_Layer_3': 0.08154842882416151, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009833057767371625, 'l1_Layer_2': 0.00035005414599287825, 'l1_Layer_3': 1.0358979123871436e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.32 | sMAPE for Validation Set is: 18.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.10 | sMAPE for Test Set is: 19.56% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:32:19,463]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:32:22,791]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:32:26,020]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:32:30,357]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:32:40,614]\u001b[0m Trial 1006 finished with value: 14.197404668538013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005525757820869618, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23625551177113382, 'dropout_rate_Layer_2': 0.15313762267794426, 'dropout_rate_Layer_3': 0.37920255898949, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032795719065907957, 'l1_Layer_2': 0.0052520658757008115, 'l1_Layer_3': 4.5986998693392345e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 235, 'n_units_Layer_3': 245}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.20 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.39 | sMAPE for Test Set is: 20.08% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:32:45,226]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:32:49,540]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:32:51,927]\u001b[0m Trial 1010 finished with value: 15.151579887067806 and parameters: {'n_hidden': 3, 'learning_rate': 0.006911530512550405, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2515977096586316, 'dropout_rate_Layer_2': 0.012737931981237318, 'dropout_rate_Layer_3': 0.10322187892430112, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009795351243859177, 'l1_Layer_2': 0.00036401067673630686, 'l1_Layer_3': 1.0067106150061834e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.15 | sMAPE for Validation Set is: 19.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 30.07 | sMAPE for Test Set is: 20.79% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:32:55,850]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:32:58,105]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:33:02,347]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:33:07,522]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:33:07,785]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:33:14,883]\u001b[0m Trial 1021 finished with value: 14.746035650038408 and parameters: {'n_hidden': 3, 'learning_rate': 0.00657152138121944, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06847609080332329, 'dropout_rate_Layer_2': 0.025323052611858434, 'dropout_rate_Layer_3': 0.13561234057157145, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06368001167602429, 'l1_Layer_2': 0.0013178961620013928, 'l1_Layer_3': 0.00044810570310626035, 'n_units_Layer_1': 150, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.75 | sMAPE for Validation Set is: 19.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.35 | sMAPE for Test Set is: 20.71% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:33:19,279]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:33:28,702]\u001b[0m Trial 1020 finished with value: 14.388473084462836 and parameters: {'n_hidden': 3, 'learning_rate': 0.004750736424456274, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24571262580632508, 'dropout_rate_Layer_2': 0.010435808203291779, 'dropout_rate_Layer_3': 0.10622520259950549, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009567303645029946, 'l1_Layer_2': 0.0005413892520739743, 'l1_Layer_3': 1.012885676966831e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 280, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.39 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.98 | sMAPE for Test Set is: 19.70% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:33:32,252]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:33:35,318]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:33:40,625]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:33:42,852]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:33:44,711]\u001b[0m Trial 1025 finished with value: 14.143397866172274 and parameters: {'n_hidden': 3, 'learning_rate': 0.0074478331102125995, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2409644457040942, 'dropout_rate_Layer_2': 0.013425677553626642, 'dropout_rate_Layer_3': 0.08308536639850961, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021650726136474134, 'l1_Layer_2': 0.00030418741612000047, 'l1_Layer_3': 1.0274191353878625e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 295, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.14 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.80 | sMAPE for Test Set is: 19.93% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:33:50,595]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:34:06,699]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:34:10,492]\u001b[0m Trial 1031 finished with value: 14.44502886228957 and parameters: {'n_hidden': 3, 'learning_rate': 0.00439850865826586, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24032141134829513, 'dropout_rate_Layer_2': 0.03286154263042645, 'dropout_rate_Layer_3': 0.11373197948924814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001696397551747287, 'l1_Layer_2': 0.00030267150838744186, 'l1_Layer_3': 1.1459775091904476e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.45 | sMAPE for Validation Set is: 19.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 30.20 | sMAPE for Test Set is: 21.07% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:34:12,479]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.76 | sMAPE for Validation Set is: 18.36% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 28.20 | sMAPE for Test Set is: 19.88% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:34:14,126]\u001b[0m Trial 1026 finished with value: 13.75896917954781 and parameters: {'n_hidden': 3, 'learning_rate': 0.007301593270833612, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2630295792678885, 'dropout_rate_Layer_2': 0.014476391644357363, 'dropout_rate_Layer_3': 0.11511208993254855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021884789075186603, 'l1_Layer_2': 0.00031342233987380526, 'l1_Layer_3': 1.1508076843029217e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 295, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:34:33,285]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:34:37,428]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:34:41,224]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:34:47,565]\u001b[0m Trial 1034 finished with value: 14.780492125412716 and parameters: {'n_hidden': 3, 'learning_rate': 0.004554215991442368, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2436586433159849, 'dropout_rate_Layer_2': 0.01613657606728261, 'dropout_rate_Layer_3': 0.11953249040257267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002196493321842161, 'l1_Layer_2': 0.00029162444726506395, 'l1_Layer_3': 1.0052428290784234e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 295, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.78 | sMAPE for Validation Set is: 19.10% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.68 | sMAPE for Test Set is: 20.25% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:34:51,385]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:34:55,842]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.34 | sMAPE for Validation Set is: 19.82% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.70 | sMAPE for Test Set is: 20.45% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:35:00,090]\u001b[0m Trial 1038 finished with value: 15.344350008466444 and parameters: {'n_hidden': 3, 'learning_rate': 0.006570896186935099, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2663615131729712, 'dropout_rate_Layer_2': 0.008858650093433812, 'dropout_rate_Layer_3': 0.11871175050467912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012628709675798749, 'l1_Layer_2': 0.00034565237962324034, 'l1_Layer_3': 1.159893733867457e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:04,029]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:08,555]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:10,864]\u001b[0m Trial 1036 finished with value: 14.430509171447605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0045986054366448995, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23968419511882627, 'dropout_rate_Layer_2': 0.011012110665428907, 'dropout_rate_Layer_3': 0.10928241308504781, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002233935718808555, 'l1_Layer_2': 0.00028589099705847063, 'l1_Layer_3': 1.011412831606008e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 285, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.43 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.32 | sMAPE for Test Set is: 19.05% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:35:15,107]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:17,503]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:21,356]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:22,286]\u001b[0m Trial 1040 finished with value: 14.206644644872654 and parameters: {'n_hidden': 3, 'learning_rate': 0.004131872054092297, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2660049340561716, 'dropout_rate_Layer_2': 0.009528119186255284, 'dropout_rate_Layer_3': 0.10531654752931335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020564137427668354, 'l1_Layer_2': 0.0003715400651942889, 'l1_Layer_3': 1.007687150135965e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 295, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 29.03 | sMAPE for Test Set is: 20.43% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:35:24,955]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:30,102]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:32,322]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:33,159]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:38,603]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:41,210]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:45,072]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:45,685]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:52,653]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:53,802]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:57,630]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:35:59,411]\u001b[0m Trial 1054 finished with value: 14.152611542844681 and parameters: {'n_hidden': 3, 'learning_rate': 0.003757392984210616, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019791271166642976, 'dropout_rate_Layer_2': 0.06211745153787637, 'dropout_rate_Layer_3': 0.13912478661903174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04589789720139719, 'l1_Layer_2': 0.00011174665436266096, 'l1_Layer_3': 0.0003888236558646926, 'n_units_Layer_1': 140, 'n_units_Layer_2': 130, 'n_units_Layer_3': 240}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.15 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.31 | sMAPE for Test Set is: 19.72% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:36:05,897]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:36:18,885]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:36:21,255]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:36:27,388]\u001b[0m Trial 1062 finished with value: 14.746447126592058 and parameters: {'n_hidden': 3, 'learning_rate': 0.005378709215994565, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26914877475757143, 'dropout_rate_Layer_2': 0.00010471584727883218, 'dropout_rate_Layer_3': 0.10768208315952545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033835115293610564, 'l1_Layer_2': 0.0003979186658558388, 'l1_Layer_3': 1.1883628114898846e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.75 | sMAPE for Validation Set is: 19.99% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.84 | sMAPE for Test Set is: 20.44% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:36:31,513]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:36:33,034]\u001b[0m Trial 1064 finished with value: 14.512652086253992 and parameters: {'n_hidden': 3, 'learning_rate': 0.005441532868187375, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27075650747027036, 'dropout_rate_Layer_2': 0.013044480002340843, 'dropout_rate_Layer_3': 0.10693878078003699, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031830814210304847, 'l1_Layer_2': 0.00036381458447807565, 'l1_Layer_3': 1.215591218290802e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.51 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.11 | sMAPE for Test Set is: 19.94% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:36:43,130]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:36:48,078]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:36:51,535]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:36:56,080]\u001b[0m Trial 1068 finished with value: 14.942349721570002 and parameters: {'n_hidden': 3, 'learning_rate': 0.005319749348414172, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26970258990217894, 'dropout_rate_Layer_2': 0.013124074373633672, 'dropout_rate_Layer_3': 0.11522343770337501, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003563717923616356, 'l1_Layer_2': 0.00041213685662316857, 'l1_Layer_3': 1.0015606953055772e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 285, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.94 | sMAPE for Validation Set is: 19.30% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.16 | sMAPE for Test Set is: 20.08% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:37:05,071]\u001b[0m Trial 1065 finished with value: 13.674770191125504 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006590051652935954, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23552421482338765, 'dropout_rate_Layer_2': 0.13097331804444243, 'dropout_rate_Layer_3': 0.38002398925512554, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023163614979652193, 'l1_Layer_2': 0.0034315933366342523, 'l1_Layer_3': 3.683825121435774e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 255, 'n_units_Layer_3': 235}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.67 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 26.85 | sMAPE for Test Set is: 19.29% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:37:11,964]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:14,301]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:19,345]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:21,746]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:25,423]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:27,396]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:31,932]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:32,520]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:32,909]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:40,629]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:43,840]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:47,247]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:51,268]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:37:56,067]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:38:04,758]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:38:08,859]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:38:21,610]\u001b[0m Trial 1087 finished with value: 14.715638088711591 and parameters: {'n_hidden': 3, 'learning_rate': 0.007399166061233491, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25957417856676984, 'dropout_rate_Layer_2': 0.01057982710728041, 'dropout_rate_Layer_3': 0.0952655123450616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001039959353551334, 'l1_Layer_2': 0.0002655167131104291, 'l1_Layer_3': 1.2317362350208423e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.72 | sMAPE for Validation Set is: 20.33% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.60 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:38:22,473]\u001b[0m Trial 1088 finished with value: 14.49739068118304 and parameters: {'n_hidden': 3, 'learning_rate': 0.007401167873940326, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24973811113096733, 'dropout_rate_Layer_2': 0.01165472872191226, 'dropout_rate_Layer_3': 0.08382873500456588, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001103891415455604, 'l1_Layer_2': 0.00043210738552091775, 'l1_Layer_3': 1.1973904557974199e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.50 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.72 | sMAPE for Test Set is: 19.69% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:38:29,446]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:38:32,168]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:38:36,668]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:38:41,121]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.44 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.93 | sMAPE for Test Set is: 19.42% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:38:43,170]\u001b[0m Trial 1089 finished with value: 14.444021457379032 and parameters: {'n_hidden': 3, 'learning_rate': 0.0048689609197063635, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2500296438194287, 'dropout_rate_Layer_2': 0.009427812086829726, 'dropout_rate_Layer_3': 0.13968282943519908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010446040936585171, 'l1_Layer_2': 0.0002647916834782499, 'l1_Layer_3': 1.2191796918258843e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:38:51,311]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:38:59,804]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:00,051]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:07,076]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:07,997]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:08,230]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:13,050]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:18,821]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:23,120]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:30,947]\u001b[0m Trial 1096 finished with value: 13.907753787342061 and parameters: {'n_hidden': 3, 'learning_rate': 0.007127147604993248, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25710290317376844, 'dropout_rate_Layer_2': 0.012213532830609138, 'dropout_rate_Layer_3': 0.09599406529583246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015858178474876855, 'l1_Layer_2': 0.0007234085090155235, 'l1_Layer_3': 1.0001198304134169e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 270, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.91 | sMAPE for Validation Set is: 18.47% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.71 | sMAPE for Test Set is: 19.77% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:39:35,313]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:36,505]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:37,745]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:46,903]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:49,230]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:50,009]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:39:56,303]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:40:05,008]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:40:12,373]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:40:15,755]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:40:22,372]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:40:27,776]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:40:28,633]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:40:34,498]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:40:38,432]\u001b[0m Trial 1117 finished with value: 14.471956361931795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009761504061585629, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05984005805162665, 'dropout_rate_Layer_2': 0.3673194091988062, 'dropout_rate_Layer_3': 0.08128866865088118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03271156096688138, 'l1_Layer_2': 0.0016514787589755986, 'l1_Layer_3': 0.0001808091073630312, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 235}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.47 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.21 | sMAPE for Test Set is: 20.23% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:40:52,824]\u001b[0m Trial 1114 finished with value: 14.20870467385655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0057290023695514905, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2556666968000338, 'dropout_rate_Layer_2': 0.007928899990466864, 'dropout_rate_Layer_3': 0.09443440845780901, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023644816428775293, 'l1_Layer_2': 0.0007874309570568243, 'l1_Layer_3': 1.0018072950090897e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 280, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.62 | sMAPE for Test Set is: 19.18% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:40:56,439]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:40:58,525]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:41:07,753]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:41:14,010]\u001b[0m Trial 1124 finished with value: 14.170137212396332 and parameters: {'n_hidden': 3, 'learning_rate': 0.005820580143423283, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05953730659791291, 'dropout_rate_Layer_2': 0.384033704293647, 'dropout_rate_Layer_3': 0.09581010174870853, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02243795607323819, 'l1_Layer_2': 0.0012132529442055193, 'l1_Layer_3': 0.000159409385402316, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.22 | sMAPE for Test Set is: 20.19% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:41:20,821]\u001b[0m Trial 1119 finished with value: 13.652127611246135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005880922820122928, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2186166211781259, 'dropout_rate_Layer_2': 0.1573388930753976, 'dropout_rate_Layer_3': 0.37274847231803787, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021389231442049276, 'l1_Layer_2': 0.002513561967357362, 'l1_Layer_3': 4.0162351277145866e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.65 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.89 | sMAPE for Test Set is: 19.84% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:41:21,374]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:41:27,669]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:41:32,908]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:41:38,863]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:41:39,099]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:41:47,097]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:41:47,512]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:41:53,597]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:42:05,454]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:42:10,035]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:42:13,643]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:42:18,120]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:42:21,237]\u001b[0m Trial 1131 finished with value: 14.38302233326646 and parameters: {'n_hidden': 3, 'learning_rate': 0.007084722638925505, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2484246809349567, 'dropout_rate_Layer_2': 0.018429281752579487, 'dropout_rate_Layer_3': 0.1115908777188079, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00123070000307122, 'l1_Layer_2': 0.00023607969850961954, 'l1_Layer_3': 1.004825577056047e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.38 | sMAPE for Validation Set is: 18.89% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.12 | sMAPE for Test Set is: 18.93% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:42:35,988]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:42:43,776]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:42:51,388]\u001b[0m Trial 1141 finished with value: 14.242610675970324 and parameters: {'n_hidden': 3, 'learning_rate': 0.006359926066001264, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2414291934587439, 'dropout_rate_Layer_2': 0.00046854766960321113, 'dropout_rate_Layer_3': 0.10332689200011996, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010705933233679877, 'l1_Layer_2': 0.0002912094315724698, 'l1_Layer_3': 1.3829046926226887e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 300, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.24 | sMAPE for Validation Set is: 18.72% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.17 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:43:09,749]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:43:14,733]\u001b[0m Trial 1139 finished with value: 13.823271803328112 and parameters: {'n_hidden': 3, 'learning_rate': 0.005385087736248364, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24013690297712834, 'dropout_rate_Layer_2': 0.036149681876340094, 'dropout_rate_Layer_3': 0.11580728606445084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025366246126540077, 'l1_Layer_2': 0.0006164884634934026, 'l1_Layer_3': 1.3351450444084216e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 300, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.82 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.49 | sMAPE for Test Set is: 19.63% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:43:15,542]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:43:21,348]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:43:25,021]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:43:26,288]\u001b[0m Trial 1144 finished with value: 14.735492972622259 and parameters: {'n_hidden': 3, 'learning_rate': 0.005377975377787702, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23865341149900954, 'dropout_rate_Layer_2': 0.0018129450358345817, 'dropout_rate_Layer_3': 0.10672566142430433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026192628344832163, 'l1_Layer_2': 0.0002906237055393918, 'l1_Layer_3': 1.3702007059375766e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 300, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.74 | sMAPE for Validation Set is: 20.05% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 30.58 | sMAPE for Test Set is: 21.35% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:43:33,866]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:43:39,999]\u001b[0m Trial 1142 finished with value: 14.12875864308584 and parameters: {'n_hidden': 3, 'learning_rate': 0.005480367132159597, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23968926083231662, 'dropout_rate_Layer_2': 0.008999883566445072, 'dropout_rate_Layer_3': 0.10347418785810933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026281659694832207, 'l1_Layer_2': 0.0003068036378290647, 'l1_Layer_3': 1.3929834189692842e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 300, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.13 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 29.43 | sMAPE for Test Set is: 20.56% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:43:45,765]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:43:50,048]\u001b[0m Trial 1148 finished with value: 14.827479911510949 and parameters: {'n_hidden': 3, 'learning_rate': 0.00544779588850801, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10609390986949713, 'dropout_rate_Layer_2': 0.006464570932984713, 'dropout_rate_Layer_3': 0.12078139870779858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006397107158528297, 'l1_Layer_2': 0.0008040608855365952, 'l1_Layer_3': 1.3722598590325297e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 300, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.83 | sMAPE for Validation Set is: 19.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.08 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:43:53,360]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:43:56,681]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:44:04,093]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:44:07,970]\u001b[0m Trial 1153 finished with value: 15.170405729549557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0053191018663219115, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.052966053566776014, 'dropout_rate_Layer_2': 0.38252960838119776, 'dropout_rate_Layer_3': 0.09616357855808409, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03206331032786891, 'l1_Layer_2': 0.0015380990193709506, 'l1_Layer_3': 0.0001805219459199922, 'n_units_Layer_1': 135, 'n_units_Layer_2': 140, 'n_units_Layer_3': 245}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.17 | sMAPE for Validation Set is: 19.62% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 31.75 | sMAPE for Test Set is: 21.86% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:44:08,515]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:44:08,965]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:44:09,963]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:44:20,769]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:44:28,256]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:44:30,769]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:44:35,909]\u001b[0m Trial 1158 finished with value: 15.229777038541362 and parameters: {'n_hidden': 3, 'learning_rate': 0.006735344830844141, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04198561334394832, 'dropout_rate_Layer_2': 0.3540314969963719, 'dropout_rate_Layer_3': 0.12170893038160623, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09838484139149266, 'l1_Layer_2': 0.003070857888946389, 'l1_Layer_3': 0.0002695927145962269, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.23 | sMAPE for Validation Set is: 19.77% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.78 | sMAPE for Test Set is: 20.98% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:44:39,580]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:44:46,180]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:44:56,886]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:45:03,417]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:45:03,645]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:45:11,394]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:45:18,118]\u001b[0m Trial 1162 finished with value: 13.962039586906103 and parameters: {'n_hidden': 3, 'learning_rate': 0.006546055557297375, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2587371176664323, 'dropout_rate_Layer_2': 0.013452351667078899, 'dropout_rate_Layer_3': 0.10258533374317994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022051666353059564, 'l1_Layer_2': 0.00027767631574101355, 'l1_Layer_3': 1.231682424815079e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.96 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.09 | sMAPE for Test Set is: 19.49% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:45:23,895]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:45:27,665]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:45:32,105]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:45:34,082]\u001b[0m Trial 1171 finished with value: 14.714116709462091 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009000262545041045, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09801405279796861, 'dropout_rate_Layer_2': 0.01267696081249027, 'dropout_rate_Layer_3': 0.0673550689196269, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05400351328180363, 'l1_Layer_2': 0.00015325856762772076, 'l1_Layer_3': 0.00033409906535339156, 'n_units_Layer_1': 150, 'n_units_Layer_2': 130, 'n_units_Layer_3': 210}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.71 | sMAPE for Validation Set is: 18.69% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.33 | sMAPE for Test Set is: 20.72% | rMAE for Test Set is: 0.74\n",
      "MAE for Validation Set is: 14.91 | sMAPE for Validation Set is: 19.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.46 | sMAPE for Test Set is: 20.88% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:45:36,024]\u001b[0m Trial 1169 finished with value: 14.914569952249858 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009342957236759006, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09689088884475631, 'dropout_rate_Layer_2': 0.01222527540362054, 'dropout_rate_Layer_3': 0.06581173489965923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05622903231254057, 'l1_Layer_2': 0.00015821172811896189, 'l1_Layer_3': 0.0003604672631003498, 'n_units_Layer_1': 150, 'n_units_Layer_2': 130, 'n_units_Layer_3': 210}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:45:36,087]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:45:37,854]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:45:47,369]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:45:59,836]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:46:09,842]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:46:12,653]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:46:13,565]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:46:22,130]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:46:26,754]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:46:33,475]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:46:51,024]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:46:58,471]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:02,031]\u001b[0m Trial 1183 finished with value: 15.324583393568709 and parameters: {'n_hidden': 3, 'learning_rate': 0.007345273224511166, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23533084833995982, 'dropout_rate_Layer_2': 0.015089408055213525, 'dropout_rate_Layer_3': 0.09794466852013602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017880387313715276, 'l1_Layer_2': 0.00022873561346614988, 'l1_Layer_3': 1.1893684703105963e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.32 | sMAPE for Validation Set is: 19.76% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.70 | sMAPE for Test Set is: 20.95% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:47:05,899]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:09,900]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:10,098]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:18,408]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:18,464]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:28,344]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:33,619]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:34,743]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:37,115]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:42,444]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:43,365]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:49,616]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:47:53,067]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:48:00,609]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:48:08,012]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.29 | sMAPE for Validation Set is: 19.23% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.60 | sMAPE for Test Set is: 20.23% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:48:10,141]\u001b[0m Trial 1187 finished with value: 14.288389315784142 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025170902299357606, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2499813149821559, 'dropout_rate_Layer_2': 0.029585144926938783, 'dropout_rate_Layer_3': 0.09661576070788849, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001670189207126844, 'l1_Layer_2': 0.0006500847644353696, 'l1_Layer_3': 1.1602706375897824e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 280, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:48:17,524]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:48:20,280]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:48:26,577]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:48:36,474]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:48:50,379]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:48:57,792]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:02,090]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:05,133]\u001b[0m Trial 1210 finished with value: 14.708383980092611 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011871718492736244, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06913564410520374, 'dropout_rate_Layer_2': 0.34714745264718827, 'dropout_rate_Layer_3': 0.08861512369717447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06299462365318967, 'l1_Layer_2': 0.00039515182347750255, 'l1_Layer_3': 0.00015679550566375918, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 215}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.71 | sMAPE for Validation Set is: 19.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.76 | sMAPE for Test Set is: 20.83% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:49:06,287]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:12,499]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:15,871]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:18,900]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:20,014]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:27,977]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:31,180]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:36,206]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:39,971]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:48,941]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:53,309]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:53,992]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:49:59,316]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:50:00,110]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.97 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 28.42 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:50:03,616]\u001b[0m Trial 1211 finished with value: 13.965747072904803 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024261303595280834, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2544218414512984, 'dropout_rate_Layer_2': 0.03323419250162796, 'dropout_rate_Layer_3': 0.13288853657150881, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00193683088911952, 'l1_Layer_2': 0.000878233114867592, 'l1_Layer_3': 1.1972760276161015e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 270, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:50:09,401]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:50:13,621]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:50:17,596]\u001b[0m Trial 1219 finished with value: 13.980111158985496 and parameters: {'n_hidden': 3, 'learning_rate': 0.002586775171431423, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2414205970254966, 'dropout_rate_Layer_2': 0.00919888403972108, 'dropout_rate_Layer_3': 0.09876168134995611, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018954107211226975, 'l1_Layer_2': 0.00027076411304377584, 'l1_Layer_3': 1.219621672325061e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 295, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.98 | sMAPE for Validation Set is: 19.27% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.07 | sMAPE for Test Set is: 19.07% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:50:22,884]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:50:25,953]\u001b[0m Trial 1228 finished with value: 14.603376273953492 and parameters: {'n_hidden': 3, 'learning_rate': 0.001475105760537172, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05230072798751381, 'dropout_rate_Layer_2': 0.37640500830396395, 'dropout_rate_Layer_3': 0.13116466085655626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04445209787996653, 'l1_Layer_2': 8.381462089426108e-05, 'l1_Layer_3': 0.0002706048941724445, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 70}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.60 | sMAPE for Validation Set is: 19.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.28 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:50:29,987]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:50:34,578]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:50:38,673]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:50:49,800]\u001b[0m Trial 1227 finished with value: 13.882854577238277 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023287024632877994, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24085230692819284, 'dropout_rate_Layer_2': 0.015982107326219082, 'dropout_rate_Layer_3': 0.09483872295266821, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012603566832492317, 'l1_Layer_2': 0.0002612315412851153, 'l1_Layer_3': 1.2019289025153787e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 295, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.88 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 28.17 | sMAPE for Test Set is: 19.89% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:50:52,687]\u001b[0m Trial 1233 finished with value: 14.549854569355203 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010488448387923537, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0489923764225483, 'dropout_rate_Layer_2': 0.34897374813261084, 'dropout_rate_Layer_3': 0.11416518323384672, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08099255177471129, 'l1_Layer_2': 0.0012379047846794683, 'l1_Layer_3': 0.0004797014956835923, 'n_units_Layer_1': 140, 'n_units_Layer_2': 135, 'n_units_Layer_3': 210}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.55 | sMAPE for Validation Set is: 19.29% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.43 | sMAPE for Test Set is: 20.30% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:50:56,692]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:50:59,097]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:51:00,478]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:51:06,658]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:51:10,799]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:51:16,623]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:51:19,431]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:51:25,447]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:51:28,395]\u001b[0m Trial 1237 finished with value: 14.648765116363927 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024604998651369995, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24262103266039894, 'dropout_rate_Layer_2': 0.009347104185134136, 'dropout_rate_Layer_3': 0.15072168641771563, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001905103680664446, 'l1_Layer_2': 0.0010790589283850539, 'l1_Layer_3': 1.4912327402721972e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 265, 'n_units_Layer_3': 65}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.65 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.47 | sMAPE for Test Set is: 19.64% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:51:29,832]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:51:37,627]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:51:42,590]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:51:47,707]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:52:02,583]\u001b[0m Trial 1252 finished with value: 13.744851651420916 and parameters: {'n_hidden': 3, 'learning_rate': 0.001983499011184328, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26501092233937046, 'dropout_rate_Layer_2': 0.015793205869713254, 'dropout_rate_Layer_3': 0.1322904953015685, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012423441743237352, 'l1_Layer_2': 0.0003144162134659089, 'l1_Layer_3': 1.2573416121428715e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 270, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.74 | sMAPE for Validation Set is: 18.20% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.62 | sMAPE for Test Set is: 19.71% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:52:05,125]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:52:16,379]\u001b[0m Trial 1250 finished with value: 14.086943997692046 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026121432942839895, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2552783558190822, 'dropout_rate_Layer_2': 0.0334520195745397, 'dropout_rate_Layer_3': 0.13255361899468163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00232417640864638, 'l1_Layer_2': 0.000202762644106809, 'l1_Layer_3': 1.3040271859941193e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.09 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.31 | sMAPE for Test Set is: 20.04% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:52:20,421]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:52:25,568]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:52:30,891]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:52:35,626]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:52:40,407]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:52:50,330]\u001b[0m Trial 1254 finished with value: 13.291252065195772 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006142224878863619, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10104900028175068, 'dropout_rate_Layer_2': 0.13328030977157107, 'dropout_rate_Layer_3': 0.3329582080291266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013780392784422375, 'l1_Layer_2': 0.000272672861843817, 'l1_Layer_3': 1.5088026412714625e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 225, 'n_units_Layer_3': 100}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.29 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 26.45 | sMAPE for Test Set is: 19.06% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:52:54,684]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:52:55,427]\u001b[0m Trial 1253 finished with value: 13.463862896050486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015726641985363817, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26721329941746075, 'dropout_rate_Layer_2': 0.015246915049902873, 'dropout_rate_Layer_3': 0.13156616857565287, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012206309642364623, 'l1_Layer_2': 0.0008240934344597011, 'l1_Layer_3': 1.468635887645685e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 275, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.46 | sMAPE for Validation Set is: 18.36% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 28.97 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:53:00,570]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:53:06,438]\u001b[0m Trial 1260 finished with value: 14.093808205314465 and parameters: {'n_hidden': 3, 'learning_rate': 0.001774788612198506, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2681611539580238, 'dropout_rate_Layer_2': 0.0196050177264687, 'dropout_rate_Layer_3': 0.1296933154872782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031022759608943197, 'l1_Layer_2': 0.0008092982550140841, 'l1_Layer_3': 1.0011219270203368e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 250, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.09 | sMAPE for Validation Set is: 18.66% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.95 | sMAPE for Test Set is: 19.36% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:53:07,001]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:53:07,274]\u001b[0m Trial 1248 finished with value: 14.275564682456476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023180252425841477, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2745453249900164, 'dropout_rate_Layer_2': 0.032110680051655405, 'dropout_rate_Layer_3': 0.11419619640253639, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002249952484791518, 'l1_Layer_2': 0.0002580158253555031, 'l1_Layer_3': 1.2392915447431758e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 260, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.28 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.51 | sMAPE for Test Set is: 19.17% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:53:10,451]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:53:13,512]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:53:15,753]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:53:23,870]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:53:28,774]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:53:36,225]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:53:44,226]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:53:48,728]\u001b[0m Trial 1272 finished with value: 13.799209412561533 and parameters: {'n_hidden': 3, 'learning_rate': 0.001836438585461308, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27837233249471416, 'dropout_rate_Layer_2': 0.04703973529192885, 'dropout_rate_Layer_3': 0.1283840998005498, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032930508442436087, 'l1_Layer_2': 0.0008046129449995479, 'l1_Layer_3': 1.5009405874679326e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 260, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.80 | sMAPE for Validation Set is: 18.22% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.77 | sMAPE for Test Set is: 19.78% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:53:53,390]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:53:55,903]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:53:58,675]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:54:02,208]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:54:05,052]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:54:05,415]\u001b[0m Trial 1268 finished with value: 13.268272062874152 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005904469270614418, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2473923003247513, 'dropout_rate_Layer_2': 0.1673804701923164, 'dropout_rate_Layer_3': 0.34527573897492325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012458487931433732, 'l1_Layer_2': 0.00027931158490112924, 'l1_Layer_3': 3.586933600763854e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 225, 'n_units_Layer_3': 175}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.27 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 26.01 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:54:07,909]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:54:15,887]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:54:24,412]\u001b[0m Trial 1269 finished with value: 14.486135031716893 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023368423263124996, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2889719073708784, 'dropout_rate_Layer_2': 0.045232333286144184, 'dropout_rate_Layer_3': 0.13302994450627356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002843285913642725, 'l1_Layer_2': 0.0008199455237690871, 'l1_Layer_3': 1.4772443192509183e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 260, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.49 | sMAPE for Validation Set is: 18.97% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.00 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:54:28,606]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.41 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.82 | sMAPE for Test Set is: 20.37% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:54:30,849]\u001b[0m Trial 1281 finished with value: 14.409881994446783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012508020096062256, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05063067756572652, 'dropout_rate_Layer_2': 0.31767179687856056, 'dropout_rate_Layer_3': 0.09587363989769504, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012377664173661415, 'l1_Layer_2': 0.002269292510853429, 'l1_Layer_3': 0.0014791840538132708, 'n_units_Layer_1': 180, 'n_units_Layer_2': 135, 'n_units_Layer_3': 70}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:54:34,108]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:54:35,960]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.04 | sMAPE for Validation Set is: 18.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 28.35 | sMAPE for Test Set is: 20.12% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:54:39,532]\u001b[0m Trial 1283 finished with value: 14.044761168677326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016655012655198266, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2727888691932471, 'dropout_rate_Layer_2': 0.037137528923427074, 'dropout_rate_Layer_3': 0.1326776920217253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032051430208979693, 'l1_Layer_2': 0.0008712557938259748, 'l1_Layer_3': 1.572585160598023e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 260, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:54:40,000]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:54:48,419]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:54:54,361]\u001b[0m Trial 1287 finished with value: 14.354601937812133 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015855367501917555, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041717994592265016, 'dropout_rate_Layer_2': 0.31506518406231965, 'dropout_rate_Layer_3': 0.09617439928031649, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015047920573768536, 'l1_Layer_2': 0.0021802066324825126, 'l1_Layer_3': 0.0011497464115100998, 'n_units_Layer_1': 190, 'n_units_Layer_2': 135, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.35 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.14 | sMAPE for Test Set is: 20.09% | rMAE for Test Set is: 0.71\n",
      "MAE for Validation Set is: 14.15 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 29.73 | sMAPE for Test Set is: 20.72% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:54:57,490]\u001b[0m Trial 1288 finished with value: 14.147182847228825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020319685942227373, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27355277655181287, 'dropout_rate_Layer_2': 0.019971698205055066, 'dropout_rate_Layer_3': 0.12418818568693787, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025375607484424854, 'l1_Layer_2': 0.0007199533334137421, 'l1_Layer_3': 1.3793855816459275e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:55:05,615]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:55:11,138]\u001b[0m Trial 1292 finished with value: 13.798050803141928 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017919019831122074, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27908180138597694, 'dropout_rate_Layer_2': 0.053176849575112886, 'dropout_rate_Layer_3': 0.12830055286597905, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002691126295691954, 'l1_Layer_2': 0.0007704496942281548, 'l1_Layer_3': 1.5862210054202895e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 260, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.80 | sMAPE for Validation Set is: 18.12% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.42 | sMAPE for Test Set is: 19.60% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:55:12,466]\u001b[0m Trial 1290 finished with value: 13.576759996373811 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017952993061890832, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.275702887765116, 'dropout_rate_Layer_2': 0.03758015225010027, 'dropout_rate_Layer_3': 0.12959010620799194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025827628443546983, 'l1_Layer_2': 0.0007930971654243014, 'l1_Layer_3': 1.5857117334295282e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 265, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.58 | sMAPE for Validation Set is: 17.93% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.38 | sMAPE for Test Set is: 19.68% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:55:15,704]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:55:19,733]\u001b[0m Trial 1291 finished with value: 13.826609390156145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019746296405926105, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27772217645531166, 'dropout_rate_Layer_2': 0.04551660905091129, 'dropout_rate_Layer_3': 0.12695826768079513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025354556653230035, 'l1_Layer_2': 0.0011833912550402996, 'l1_Layer_3': 1.613366725427481e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.83 | sMAPE for Validation Set is: 18.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.82 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:55:19,943]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:55:21,113]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:55:28,508]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:55:28,659]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:55:38,448]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:55:41,278]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:55:45,423]\u001b[0m Trial 1300 finished with value: 14.176592779694682 and parameters: {'n_hidden': 3, 'learning_rate': 0.001807943508225627, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2809575319652947, 'dropout_rate_Layer_2': 0.05693700030477783, 'dropout_rate_Layer_3': 0.13954290166148192, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033922416213728913, 'l1_Layer_2': 0.0010545698684900266, 'l1_Layer_3': 1.719456638667361e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 265, 'n_units_Layer_3': 65}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 18.71% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.87 | sMAPE for Test Set is: 19.78% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:55:45,669]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:55:45,878]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:55:59,485]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:07,441]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:07,667]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:08,065]\u001b[0m Trial 1302 finished with value: 13.09937021384706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008069366114336902, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26206303744043624, 'dropout_rate_Layer_2': 0.17353817424446025, 'dropout_rate_Layer_3': 0.30126474613143583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000611908723254235, 'l1_Layer_2': 0.00034015610314336027, 'l1_Layer_3': 7.171503833071583e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 225, 'n_units_Layer_3': 175}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.10 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 27.28 | sMAPE for Test Set is: 19.54% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:56:15,828]\u001b[0m Trial 1306 finished with value: 13.775889660763786 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017487282451081698, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2778277477353619, 'dropout_rate_Layer_2': 0.053080839920178674, 'dropout_rate_Layer_3': 0.15346758492806628, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0044964766477101695, 'l1_Layer_2': 0.0009275496277831285, 'l1_Layer_3': 1.8400175626181573e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 265, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.78 | sMAPE for Validation Set is: 18.32% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.43 | sMAPE for Test Set is: 19.61% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:56:15,980]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:21,679]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:24,341]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:24,953]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:25,114]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:33,251]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:33,886]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:42,032]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:52,155]\u001b[0m Trial 1317 finished with value: 13.928327978708724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018009807665171132, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3035975030353449, 'dropout_rate_Layer_2': 0.06150872633123031, 'dropout_rate_Layer_3': 0.1371602609021567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004879316905727586, 'l1_Layer_2': 0.0009688821670983915, 'l1_Layer_3': 1.7771219426939245e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 260, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.93 | sMAPE for Validation Set is: 18.39% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.39 | sMAPE for Test Set is: 19.54% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:56:53,310]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:56:58,473]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:00,986]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:06,461]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:06,832]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:07,549]\u001b[0m Trial 1320 finished with value: 13.54000678356241 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008951591034183386, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24999717767946683, 'dropout_rate_Layer_2': 0.10856894149543772, 'dropout_rate_Layer_3': 0.3209729317277777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007752869652827913, 'l1_Layer_2': 0.0002401438638128998, 'l1_Layer_3': 5.731350427167401e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 220, 'n_units_Layer_3': 175}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.54 | sMAPE for Validation Set is: 17.65% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 27.61 | sMAPE for Test Set is: 19.80% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:57:08,523]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:15,894]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:19,134]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:22,255]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:23,090]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:27,417]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:32,027]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:32,304]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:34,792]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:36,686]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:41,185]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:47,547]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:52,239]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:57:59,939]\u001b[0m Trial 1334 finished with value: 13.90312678784458 and parameters: {'n_hidden': 3, 'learning_rate': 0.002053705822791361, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2887410831649959, 'dropout_rate_Layer_2': 0.039789191420572405, 'dropout_rate_Layer_3': 0.13474379064371902, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004046611788751273, 'l1_Layer_2': 0.0006536973764600361, 'l1_Layer_3': 1.4177571452915771e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 265, 'n_units_Layer_3': 65}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.90 | sMAPE for Validation Set is: 18.33% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 28.32 | sMAPE for Test Set is: 20.05% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:58:00,734]\u001b[0m Trial 1337 finished with value: 14.331354565515115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021676996592769724, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2871205963062618, 'dropout_rate_Layer_2': 0.0550998968981201, 'dropout_rate_Layer_3': 0.13392131203607427, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004060719088073629, 'l1_Layer_2': 0.0014750812089327659, 'l1_Layer_3': 1.4343010269246675e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 245, 'n_units_Layer_3': 65}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.33 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.87 | sMAPE for Test Set is: 20.35% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:58:06,384]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:10,700]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:11,570]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:16,601]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:20,130]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:20,809]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:21,225]\u001b[0m Trial 1340 finished with value: 14.479891506858598 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009447977418902454, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03946513646687027, 'dropout_rate_Layer_2': 0.3845317841700519, 'dropout_rate_Layer_3': 0.0787763909753439, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05302579253547678, 'l1_Layer_2': 1.8033959976398092e-05, 'l1_Layer_3': 0.0010409135696920842, 'n_units_Layer_1': 140, 'n_units_Layer_2': 125, 'n_units_Layer_3': 70}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.48 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 29.07 | sMAPE for Test Set is: 20.54% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:58:27,946]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:33,932]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:37,277]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:43,047]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:46,395]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:55,270]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:55,619]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:58:56,437]\u001b[0m Trial 1349 finished with value: 13.822675230232255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016426000421816318, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29626230034922696, 'dropout_rate_Layer_2': 0.03607912444149907, 'dropout_rate_Layer_3': 0.1365131347562505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003575118032557762, 'l1_Layer_2': 0.0006764159936198216, 'l1_Layer_3': 1.3415025839102968e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 260, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.82 | sMAPE for Validation Set is: 18.11% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.43 | sMAPE for Test Set is: 19.62% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:59:04,361]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:05,572]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:06,201]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:11,243]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:16,628]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:19,561]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:23,465]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:26,608]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.03 | sMAPE for Validation Set is: 18.40% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 28.79 | sMAPE for Test Set is: 20.28% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:59:29,688]\u001b[0m Trial 1354 finished with value: 14.031693509711817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017589160084888072, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29339201429367073, 'dropout_rate_Layer_2': 0.06139769073758396, 'dropout_rate_Layer_3': 0.1373213720940638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009323193473451449, 'l1_Layer_2': 0.0008567251597893414, 'l1_Layer_3': 1.3587965443980099e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 250, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:35,850]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:38,931]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:42,396]\u001b[0m Trial 1359 finished with value: 14.018793837833712 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013970896024910503, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2972464074966909, 'dropout_rate_Layer_2': 0.05207389170733629, 'dropout_rate_Layer_3': 0.14811220014260548, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005118778815153669, 'l1_Layer_2': 0.0008230579797259254, 'l1_Layer_3': 1.675711113113697e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 250, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.02 | sMAPE for Validation Set is: 18.21% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 28.45 | sMAPE for Test Set is: 20.14% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 08:59:43,169]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:49,197]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 08:59:55,158]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:01,044]\u001b[0m Trial 1364 finished with value: 14.162537552120938 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017641500495635325, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28473792044697144, 'dropout_rate_Layer_2': 0.034022905308589445, 'dropout_rate_Layer_3': 0.12268368078205655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005467167206093496, 'l1_Layer_2': 0.001127577008440475, 'l1_Layer_3': 1.592114720988178e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 205, 'n_units_Layer_3': 65}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.16 | sMAPE for Validation Set is: 18.51% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.25 | sMAPE for Test Set is: 19.98% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:00:02,688]\u001b[0m Trial 1367 finished with value: 13.90609014900266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016776630063528016, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30595142201273273, 'dropout_rate_Layer_2': 0.054346691860098315, 'dropout_rate_Layer_3': 0.12313515374551415, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024319364280419842, 'l1_Layer_2': 0.001120379257258564, 'l1_Layer_3': 1.664733433738551e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 250, 'n_units_Layer_3': 70}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.91 | sMAPE for Validation Set is: 18.33% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 28.55 | sMAPE for Test Set is: 20.22% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:00:07,318]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:08,240]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:09,823]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:12,159]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:14,597]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:15,768]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:21,191]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:22,412]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:24,658]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:26,304]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:35,211]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:36,436]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:41,821]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:44,889]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:49,270]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:49,421]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:49,885]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:59,399]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:00:59,489]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:00,924]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:09,494]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:13,713]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:14,398]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:25,166]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:30,522]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:32,563]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:36,354]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:37,633]\u001b[0m Trial 1391 finished with value: 13.832516280469557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017726559767532951, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28590049228277703, 'dropout_rate_Layer_2': 0.05372442209619041, 'dropout_rate_Layer_3': 0.12169330948582445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003633947858828417, 'l1_Layer_2': 0.001039609428437245, 'l1_Layer_3': 2.0846545702892426e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 275, 'n_units_Layer_3': 65}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.83 | sMAPE for Validation Set is: 18.28% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.66 | sMAPE for Test Set is: 19.74% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:01:37,852]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:45,281]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:45,415]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:48,091]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:55,321]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:01:58,630]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:02,186]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:03,209]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:10,700]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:14,636]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:16,107]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:21,302]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:22,891]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:26,911]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:29,475]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:30,793]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:32,649]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:36,878]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:38,508]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:39,930]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:39,973]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:43,545]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:45,342]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:50,567]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:56,474]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:57,059]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:02:57,159]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:05,959]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:07,304]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:12,561]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:19,938]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:22,504]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:27,417]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:27,907]\u001b[0m Trial 1427 finished with value: 14.680901506846176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010320460112788108, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02943921410463775, 'dropout_rate_Layer_2': 0.3238901576716009, 'dropout_rate_Layer_3': 0.10281503082940568, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.043743520658386284, 'l1_Layer_2': 2.8390544656069263e-05, 'l1_Layer_3': 0.0005861985766299296, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 210}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.68 | sMAPE for Validation Set is: 19.22% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.42 | sMAPE for Test Set is: 20.67% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:03:28,565]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:37,377]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:38,934]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:46,482]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:52,307]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:03:52,956]\u001b[0m Trial 1435 finished with value: 13.687115939793971 and parameters: {'n_hidden': 3, 'learning_rate': 0.002378311716902128, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31481108989432066, 'dropout_rate_Layer_2': 0.060908414640501285, 'dropout_rate_Layer_3': 0.1579045389393347, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001475725011405408, 'l1_Layer_2': 0.0008633559527276639, 'l1_Layer_3': 2.5561458939856104e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 265, 'n_units_Layer_3': 50}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.69 | sMAPE for Validation Set is: 18.21% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 28.36 | sMAPE for Test Set is: 20.04% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:03:59,629]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:00,279]\u001b[0m Trial 1438 finished with value: 13.663925029491415 and parameters: {'n_hidden': 3, 'learning_rate': 0.002350279504185995, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3125283533723291, 'dropout_rate_Layer_2': 0.07289396279276557, 'dropout_rate_Layer_3': 0.1465790891060462, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001469692212672963, 'l1_Layer_2': 0.0013713916742852637, 'l1_Layer_3': 1.3264413732908158e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 275, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.66 | sMAPE for Validation Set is: 17.88% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 28.63 | sMAPE for Test Set is: 20.14% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:04:00,692]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:03,705]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:10,291]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:14,703]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:18,468]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:18,741]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:20,663]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:28,374]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:28,620]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:29,942]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:36,726]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:38,151]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:39,420]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:47,147]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:47,482]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:55,021]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:04:59,619]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:02,436]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:07,715]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:08,185]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:14,959]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:15,155]\u001b[0m Trial 1459 finished with value: 13.93775464143375 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021324859339274587, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3170522637913018, 'dropout_rate_Layer_2': 0.04835029710892464, 'dropout_rate_Layer_3': 0.15236149924406814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002047680870359908, 'l1_Layer_2': 0.0006664170647982726, 'l1_Layer_3': 1.8923671382671766e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 265, 'n_units_Layer_3': 65}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.94 | sMAPE for Validation Set is: 18.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.79 | sMAPE for Test Set is: 19.29% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:05:17,743]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:24,127]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:24,157]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:31,504]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:32,004]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:39,376]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:40,478]\u001b[0m Trial 1465 finished with value: 13.870121781196259 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031225939499494168, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3062172486215735, 'dropout_rate_Layer_2': 0.028230848433339038, 'dropout_rate_Layer_3': 0.15372528385733605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016867056397281872, 'l1_Layer_2': 0.0005501210325963659, 'l1_Layer_3': 2.2873173122856758e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.87 | sMAPE for Validation Set is: 18.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.80 | sMAPE for Test Set is: 19.84% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:05:45,834]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:45,916]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:46,491]\u001b[0m Trial 1467 finished with value: 13.45094540475786 and parameters: {'n_hidden': 3, 'learning_rate': 0.002711070209721813, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31188528387910186, 'dropout_rate_Layer_2': 0.026380129444821356, 'dropout_rate_Layer_3': 0.18636873887619113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017014939190496561, 'l1_Layer_2': 0.000585810059328894, 'l1_Layer_3': 2.2201648572636582e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 55}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.45 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 28.73 | sMAPE for Test Set is: 20.18% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:05:46,647]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:05:56,933]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:01,314]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:04,138]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:08,291]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:14,603]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:15,424]\u001b[0m Trial 1477 finished with value: 13.855255703547869 and parameters: {'n_hidden': 3, 'learning_rate': 0.003265978732941307, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34123823053074415, 'dropout_rate_Layer_2': 0.06446427712183797, 'dropout_rate_Layer_3': 0.15372224449315153, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012850348895407956, 'l1_Layer_2': 0.0004744763145820424, 'l1_Layer_3': 3.919287293013592e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 65}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.86 | sMAPE for Validation Set is: 18.28% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.97 | sMAPE for Test Set is: 19.84% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:06:18,423]\u001b[0m Trial 1480 finished with value: 13.810150545967579 and parameters: {'n_hidden': 3, 'learning_rate': 0.003268893838860047, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.319983209583561, 'dropout_rate_Layer_2': 0.02798185815352275, 'dropout_rate_Layer_3': 0.16430833704414688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00241485890894074, 'l1_Layer_2': 0.0006459771793785529, 'l1_Layer_3': 3.1353941191237214e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 60}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.81 | sMAPE for Validation Set is: 18.16% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 28.55 | sMAPE for Test Set is: 20.15% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:06:20,461]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:20,942]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:23,734]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:29,816]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:29,895]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:32,654]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:34,236]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:42,887]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:49,474]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:50,148]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:57,580]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:06:58,196]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.69 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 28.88 | sMAPE for Test Set is: 20.34% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 09:07:03,768]\u001b[0m Trial 1489 finished with value: 13.689096357972815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032902836972708684, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33184146752317695, 'dropout_rate_Layer_2': 0.06020332943767414, 'dropout_rate_Layer_3': 0.16725492367251518, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011628224588082765, 'l1_Layer_2': 0.0010696876524721546, 'l1_Layer_3': 4.311244985700079e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 70}. Best is trial 599 with value: 13.036916172602796.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:07:04,387]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:07:11,440]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:07:12,386]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:07:15,632]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:07:15,866]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 09:07:27,422]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-01-01, MAE is:34.98 & sMAPE is:28.20% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :34.98 & 28.20% & 0.34\n",
      "for 2022-01-02, MAE is:29.65 & sMAPE is:21.01% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :32.31 & 24.61% & 0.44\n",
      "for 2022-01-03, MAE is:20.43 & sMAPE is:13.95% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :28.35 & 21.05% & 0.40\n",
      "for 2022-01-04, MAE is:32.02 & sMAPE is:21.95% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :29.27 & 21.28% & 0.46\n",
      "for 2022-01-05, MAE is:58.25 & sMAPE is:36.22% & rMAE is:5.35 ||| daily mean of MAE & sMAPE & rMAE till now are :35.06 & 24.27% & 1.43\n",
      "for 2022-01-06, MAE is:36.28 & sMAPE is:18.15% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :35.27 & 23.25% & 1.61\n",
      "for 2022-01-07, MAE is:36.59 & sMAPE is:17.70% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :35.46 & 22.46% & 1.45\n",
      "for 2022-01-08, MAE is:24.00 & sMAPE is:12.05% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :34.03 & 21.16% & 1.30\n",
      "for 2022-01-09, MAE is:64.76 & sMAPE is:54.16% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :37.44 & 24.82% & 1.37\n",
      "for 2022-01-10, MAE is:61.38 & sMAPE is:31.66% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :39.83 & 25.51% & 1.33\n",
      "for 2022-01-11, MAE is:22.29 & sMAPE is:10.29% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :38.24 & 24.12% & 1.23\n",
      "for 2022-01-12, MAE is:16.46 & sMAPE is:7.78% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :36.42 & 22.76% & 1.18\n",
      "for 2022-01-13, MAE is:17.13 & sMAPE is:7.96% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :34.94 & 21.62% & 1.23\n",
      "for 2022-01-14, MAE is:16.58 & sMAPE is:8.10% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :33.63 & 20.66% & 1.19\n",
      "for 2022-01-15, MAE is:22.53 & sMAPE is:10.71% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :32.89 & 19.99% & 1.17\n",
      "for 2022-01-16, MAE is:18.48 & sMAPE is:8.75% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :31.99 & 19.29% & 1.11\n",
      "for 2022-01-17, MAE is:31.54 & sMAPE is:13.68% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :31.96 & 18.96% & 1.10\n",
      "for 2022-01-18, MAE is:18.98 & sMAPE is:8.26% & rMAE is:3.00 ||| daily mean of MAE & sMAPE & rMAE till now are :31.24 & 18.37% & 1.21\n",
      "for 2022-01-19, MAE is:16.43 & sMAPE is:7.69% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :30.46 & 17.80% & 1.20\n",
      "for 2022-01-20, MAE is:17.81 & sMAPE is:9.22% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :29.83 & 17.37% & 1.18\n",
      "for 2022-01-21, MAE is:12.59 & sMAPE is:6.96% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :29.01 & 16.88% & 1.15\n",
      "for 2022-01-22, MAE is:16.35 & sMAPE is:8.71% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :28.43 & 16.51% & 1.12\n",
      "for 2022-01-23, MAE is:15.87 & sMAPE is:7.88% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :27.88 & 16.13% & 1.13\n",
      "for 2022-01-24, MAE is:29.57 & sMAPE is:13.35% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :27.96 & 16.02% & 1.15\n",
      "for 2022-01-25, MAE is:13.15 & sMAPE is:5.99% & rMAE is:2.57 ||| daily mean of MAE & sMAPE & rMAE till now are :27.36 & 15.62% & 1.21\n",
      "for 2022-01-26, MAE is:31.76 & sMAPE is:14.63% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :27.53 & 15.58% & 1.21\n",
      "for 2022-01-27, MAE is:24.77 & sMAPE is:11.31% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :27.43 & 15.42% & 1.19\n",
      "for 2022-01-28, MAE is:20.88 & sMAPE is:9.60% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :27.20 & 15.21% & 1.16\n",
      "for 2022-01-29, MAE is:21.27 & sMAPE is:9.73% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :26.99 & 15.02% & 1.14\n",
      "for 2022-01-30, MAE is:19.76 & sMAPE is:8.86% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :26.75 & 14.82% & 1.13\n",
      "for 2022-01-31, MAE is:19.01 & sMAPE is:8.76% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :26.50 & 14.62% & 1.12\n",
      "for 2022-02-01, MAE is:19.19 & sMAPE is:9.26% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :26.27 & 14.45% & 1.12\n",
      "for 2022-02-02, MAE is:22.08 & sMAPE is:10.28% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :26.15 & 14.33% & 1.10\n",
      "for 2022-02-03, MAE is:17.43 & sMAPE is:8.29% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :25.89 & 14.15% & 1.09\n",
      "for 2022-02-04, MAE is:13.46 & sMAPE is:6.73% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :25.53 & 13.94% & 1.07\n",
      "for 2022-02-05, MAE is:12.42 & sMAPE is:6.23% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :25.17 & 13.72% & 1.06\n",
      "for 2022-02-06, MAE is:14.87 & sMAPE is:7.53% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :24.89 & 13.56% & 1.04\n",
      "for 2022-02-07, MAE is:18.59 & sMAPE is:8.90% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :24.73 & 13.43% & 1.04\n",
      "for 2022-02-08, MAE is:19.91 & sMAPE is:9.67% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :24.60 & 13.34% & 1.08\n",
      "for 2022-02-09, MAE is:19.66 & sMAPE is:9.26% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :24.48 & 13.24% & 1.09\n",
      "for 2022-02-10, MAE is:17.40 & sMAPE is:8.42% & rMAE is:3.58 ||| daily mean of MAE & sMAPE & rMAE till now are :24.31 & 13.12% & 1.15\n",
      "for 2022-02-11, MAE is:16.41 & sMAPE is:8.30% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :24.12 & 13.00% & 1.19\n",
      "for 2022-02-12, MAE is:20.03 & sMAPE is:10.43% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :24.02 & 12.94% & 1.21\n",
      "for 2022-02-13, MAE is:28.58 & sMAPE is:18.51% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :24.13 & 13.07% & 1.20\n",
      "for 2022-02-14, MAE is:26.55 & sMAPE is:14.91% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :24.18 & 13.11% & 1.20\n",
      "for 2022-02-15, MAE is:24.26 & sMAPE is:12.11% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :24.18 & 13.09% & 1.22\n",
      "for 2022-02-16, MAE is:22.31 & sMAPE is:12.37% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :24.14 & 13.07% & 1.21\n",
      "for 2022-02-17, MAE is:30.68 & sMAPE is:19.23% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :24.28 & 13.20% & 1.19\n",
      "for 2022-02-18, MAE is:23.43 & sMAPE is:13.08% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :24.26 & 13.20% & 1.19\n",
      "for 2022-02-19, MAE is:30.51 & sMAPE is:22.38% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :24.39 & 13.38% & 1.18\n",
      "for 2022-02-20, MAE is:25.19 & sMAPE is:15.12% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :24.40 & 13.42% & 1.17\n",
      "for 2022-02-21, MAE is:25.28 & sMAPE is:13.78% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :24.42 & 13.42% & 1.18\n",
      "for 2022-02-22, MAE is:16.09 & sMAPE is:9.01% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :24.26 & 13.34% & 1.17\n",
      "for 2022-02-23, MAE is:26.13 & sMAPE is:13.77% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :24.30 & 13.35% & 1.18\n",
      "for 2022-02-24, MAE is:32.92 & sMAPE is:17.36% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :24.45 & 13.42% & 1.16\n",
      "for 2022-02-25, MAE is:70.44 & sMAPE is:32.84% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :25.27 & 13.77% & 1.16\n",
      "for 2022-02-26, MAE is:54.33 & sMAPE is:23.11% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :25.78 & 13.93% & 1.15\n",
      "for 2022-02-27, MAE is:29.50 & sMAPE is:11.44% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :25.85 & 13.89% & 1.14\n",
      "for 2022-02-28, MAE is:40.63 & sMAPE is:15.28% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :26.10 & 13.91% & 1.13\n",
      "for 2022-03-01, MAE is:24.41 & sMAPE is:9.39% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :26.07 & 13.84% & 1.11\n",
      "for 2022-03-02, MAE is:24.72 & sMAPE is:9.88% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :26.05 & 13.77% & 1.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-03, MAE is:116.56 & sMAPE is:40.91% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :27.51 & 14.21% & 1.10\n",
      "for 2022-03-04, MAE is:65.96 & sMAPE is:20.50% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :28.12 & 14.31% & 1.09\n",
      "for 2022-03-05, MAE is:66.28 & sMAPE is:19.86% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :28.71 & 14.40% & 1.08\n",
      "for 2022-03-06, MAE is:50.07 & sMAPE is:13.63% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :29.04 & 14.39% & 1.07\n",
      "for 2022-03-07, MAE is:87.07 & sMAPE is:21.67% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :29.92 & 14.50% & 1.06\n",
      "for 2022-03-08, MAE is:170.21 & sMAPE is:35.72% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :32.02 & 14.81% & 1.06\n",
      "for 2022-03-09, MAE is:62.21 & sMAPE is:13.27% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :32.46 & 14.79% & 1.05\n",
      "for 2022-03-10, MAE is:65.74 & sMAPE is:16.93% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :32.94 & 14.82% & 1.06\n",
      "for 2022-03-11, MAE is:63.17 & sMAPE is:21.83% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :33.37 & 14.92% & 1.06\n",
      "for 2022-03-12, MAE is:66.08 & sMAPE is:24.35% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :33.84 & 15.05% & 1.05\n",
      "for 2022-03-13, MAE is:44.86 & sMAPE is:17.58% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :33.99 & 15.09% & 1.04\n",
      "for 2022-03-14, MAE is:39.32 & sMAPE is:15.00% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :34.06 & 15.09% & 1.03\n",
      "for 2022-03-15, MAE is:32.59 & sMAPE is:12.64% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :34.04 & 15.05% & 1.02\n",
      "for 2022-03-16, MAE is:26.77 & sMAPE is:9.89% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :33.94 & 14.99% & 1.01\n",
      "for 2022-03-17, MAE is:42.44 & sMAPE is:18.33% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :34.06 & 15.03% & 1.00\n",
      "for 2022-03-18, MAE is:22.85 & sMAPE is:9.72% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :33.91 & 14.96% & 0.99\n",
      "for 2022-03-19, MAE is:19.61 & sMAPE is:8.82% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :33.73 & 14.88% & 0.99\n",
      "for 2022-03-20, MAE is:12.44 & sMAPE is:5.88% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :33.46 & 14.77% & 0.98\n",
      "for 2022-03-21, MAE is:23.53 & sMAPE is:10.46% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :33.33 & 14.71% & 0.98\n",
      "for 2022-03-22, MAE is:18.46 & sMAPE is:8.18% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :33.15 & 14.63% & 0.97\n",
      "for 2022-03-23, MAE is:19.10 & sMAPE is:8.95% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :32.98 & 14.56% & 0.97\n",
      "for 2022-03-24, MAE is:20.93 & sMAPE is:9.52% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :32.83 & 14.50% & 0.97\n",
      "for 2022-03-25, MAE is:47.82 & sMAPE is:19.87% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :33.01 & 14.57% & 0.98\n",
      "for 2022-03-26, MAE is:21.11 & sMAPE is:8.88% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :32.87 & 14.50% & 0.98\n",
      "for 2022-03-27, MAE is:21.99 & sMAPE is:10.00% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :32.75 & 14.45% & 0.98\n",
      "for 2022-03-28, MAE is:15.69 & sMAPE is:6.73% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :32.55 & 14.36% & 0.99\n",
      "for 2022-03-29, MAE is:21.08 & sMAPE is:8.70% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :32.42 & 14.30% & 0.99\n",
      "for 2022-03-30, MAE is:18.84 & sMAPE is:7.63% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :32.27 & 14.22% & 0.98\n",
      "for 2022-03-31, MAE is:28.79 & sMAPE is:12.41% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :32.23 & 14.20% & 0.98\n",
      "for 2022-04-01, MAE is:34.27 & sMAPE is:15.16% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :32.25 & 14.21% & 0.98\n",
      "for 2022-04-02, MAE is:49.69 & sMAPE is:24.11% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :32.44 & 14.32% & 0.98\n",
      "for 2022-04-03, MAE is:42.72 & sMAPE is:19.62% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :32.55 & 14.38% & 0.98\n",
      "for 2022-04-04, MAE is:40.22 & sMAPE is:16.83% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :32.63 & 14.40% & 0.98\n",
      "for 2022-04-05, MAE is:20.14 & sMAPE is:7.89% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :32.50 & 14.33% & 0.98\n",
      "for 2022-04-06, MAE is:24.70 & sMAPE is:9.87% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :32.42 & 14.29% & 0.98\n",
      "for 2022-04-07, MAE is:30.10 & sMAPE is:14.18% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :32.40 & 14.29% & 0.99\n",
      "for 2022-04-08, MAE is:70.73 & sMAPE is:51.37% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :32.79 & 14.66% & 0.99\n",
      "for 2022-04-09, MAE is:49.63 & sMAPE is:22.56% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :32.96 & 14.74% & 0.99\n",
      "for 2022-04-10, MAE is:97.04 & sMAPE is:71.91% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :33.60 & 15.32% & 0.99\n",
      "for 2022-04-11, MAE is:59.06 & sMAPE is:38.37% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :33.85 & 15.54% & 0.99\n",
      "for 2022-04-12, MAE is:30.60 & sMAPE is:13.41% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :33.82 & 15.52% & 0.99\n",
      "for 2022-04-13, MAE is:19.85 & sMAPE is:8.56% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :33.68 & 15.45% & 0.99\n",
      "for 2022-04-14, MAE is:16.98 & sMAPE is:7.68% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :33.52 & 15.38% & 0.99\n",
      "for 2022-04-15, MAE is:16.59 & sMAPE is:8.56% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :33.36 & 15.32% & 0.98\n",
      "for 2022-04-16, MAE is:47.34 & sMAPE is:32.69% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :33.49 & 15.48% & 0.97\n",
      "for 2022-04-17, MAE is:54.83 & sMAPE is:53.45% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :33.69 & 15.83% & 0.97\n",
      "for 2022-04-18, MAE is:55.21 & sMAPE is:47.24% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :33.89 & 16.12% & 0.97\n",
      "for 2022-04-19, MAE is:43.54 & sMAPE is:36.35% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :33.98 & 16.31% & 0.97\n",
      "for 2022-04-20, MAE is:50.24 & sMAPE is:57.50% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :34.13 & 16.68% & 0.96\n",
      "for 2022-04-21, MAE is:49.33 & sMAPE is:34.04% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :34.26 & 16.84% & 0.96\n",
      "for 2022-04-22, MAE is:35.32 & sMAPE is:18.52% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :34.27 & 16.86% & 0.96\n",
      "for 2022-04-23, MAE is:92.85 & sMAPE is:92.25% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :34.79 & 17.52% & 0.97\n",
      "for 2022-04-24, MAE is:32.79 & sMAPE is:20.70% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :34.77 & 17.55% & 0.97\n",
      "for 2022-04-25, MAE is:46.85 & sMAPE is:22.05% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :34.88 & 17.59% & 0.96\n",
      "for 2022-04-26, MAE is:32.15 & sMAPE is:14.66% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :34.86 & 17.56% & 0.95\n",
      "for 2022-04-27, MAE is:18.87 & sMAPE is:8.60% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :34.72 & 17.49% & 0.95\n",
      "for 2022-04-28, MAE is:19.88 & sMAPE is:8.89% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :34.59 & 17.42% & 0.94\n",
      "for 2022-04-29, MAE is:13.46 & sMAPE is:6.31% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :34.42 & 17.32% & 0.94\n",
      "for 2022-04-30, MAE is:12.50 & sMAPE is:6.67% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :34.23 & 17.23% & 0.93\n",
      "for 2022-05-01, MAE is:21.12 & sMAPE is:12.64% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :34.13 & 17.20% & 0.93\n",
      "for 2022-05-02, MAE is:14.49 & sMAPE is:7.79% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :33.96 & 17.12% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-03, MAE is:13.98 & sMAPE is:7.61% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :33.80 & 17.04% & 0.92\n",
      "for 2022-05-04, MAE is:15.89 & sMAPE is:8.29% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :33.66 & 16.97% & 0.92\n",
      "for 2022-05-05, MAE is:12.43 & sMAPE is:6.73% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :33.49 & 16.89% & 0.91\n",
      "for 2022-05-06, MAE is:20.60 & sMAPE is:10.77% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :33.39 & 16.84% & 0.92\n",
      "for 2022-05-07, MAE is:20.45 & sMAPE is:11.33% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :33.28 & 16.80% & 0.92\n",
      "for 2022-05-08, MAE is:27.02 & sMAPE is:16.84% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :33.23 & 16.80% & 0.92\n",
      "for 2022-05-09, MAE is:23.95 & sMAPE is:12.16% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :33.16 & 16.76% & 0.93\n",
      "for 2022-05-10, MAE is:16.23 & sMAPE is:7.98% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :33.03 & 16.69% & 0.93\n",
      "for 2022-05-11, MAE is:15.47 & sMAPE is:8.23% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :32.90 & 16.63% & 0.93\n",
      "for 2022-05-12, MAE is:24.36 & sMAPE is:13.44% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :32.83 & 16.60% & 0.93\n",
      "for 2022-05-13, MAE is:20.10 & sMAPE is:10.06% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :32.74 & 16.56% & 0.94\n",
      "for 2022-05-14, MAE is:27.21 & sMAPE is:14.53% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :32.70 & 16.54% & 0.95\n",
      "for 2022-05-15, MAE is:58.77 & sMAPE is:58.62% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :32.89 & 16.85% & 0.95\n",
      "for 2022-05-16, MAE is:35.49 & sMAPE is:19.11% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :32.91 & 16.87% & 0.96\n",
      "for 2022-05-17, MAE is:19.95 & sMAPE is:10.04% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :32.81 & 16.82% & 0.96\n",
      "for 2022-05-18, MAE is:17.27 & sMAPE is:8.89% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :32.70 & 16.76% & 0.96\n",
      "for 2022-05-19, MAE is:18.39 & sMAPE is:9.51% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :32.60 & 16.71% & 0.97\n",
      "for 2022-05-20, MAE is:27.28 & sMAPE is:14.32% & rMAE is:3.20 ||| daily mean of MAE & sMAPE & rMAE till now are :32.56 & 16.69% & 0.98\n",
      "for 2022-05-21, MAE is:9.28 & sMAPE is:5.02% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :32.40 & 16.61% & 0.98\n",
      "for 2022-05-22, MAE is:16.87 & sMAPE is:10.31% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :32.29 & 16.56% & 0.97\n",
      "for 2022-05-23, MAE is:14.83 & sMAPE is:7.75% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :32.16 & 16.50% & 0.97\n",
      "for 2022-05-24, MAE is:10.77 & sMAPE is:5.93% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :32.02 & 16.43% & 0.97\n",
      "for 2022-05-25, MAE is:13.71 & sMAPE is:7.27% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :31.89 & 16.37% & 0.97\n",
      "for 2022-05-26, MAE is:31.10 & sMAPE is:16.68% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :31.88 & 16.37% & 0.98\n",
      "for 2022-05-27, MAE is:40.81 & sMAPE is:21.92% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :31.94 & 16.41% & 0.98\n",
      "for 2022-05-28, MAE is:13.87 & sMAPE is:8.33% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :31.82 & 16.35% & 0.98\n",
      "for 2022-05-29, MAE is:18.69 & sMAPE is:11.44% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :31.73 & 16.32% & 0.98\n",
      "for 2022-05-30, MAE is:23.37 & sMAPE is:11.73% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :31.68 & 16.29% & 0.98\n",
      "for 2022-05-31, MAE is:82.06 & sMAPE is:47.86% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :32.01 & 16.50% & 0.99\n",
      "for 2022-06-01, MAE is:12.88 & sMAPE is:6.07% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :31.89 & 16.43% & 0.99\n",
      "for 2022-06-02, MAE is:24.23 & sMAPE is:11.47% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :31.84 & 16.40% & 0.99\n",
      "for 2022-06-03, MAE is:13.47 & sMAPE is:6.41% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :31.72 & 16.33% & 0.98\n",
      "for 2022-06-04, MAE is:15.77 & sMAPE is:7.70% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :31.61 & 16.28% & 0.98\n",
      "for 2022-06-05, MAE is:19.55 & sMAPE is:10.11% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :31.54 & 16.24% & 0.98\n",
      "for 2022-06-06, MAE is:13.50 & sMAPE is:6.89% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :31.42 & 16.18% & 0.98\n",
      "for 2022-06-07, MAE is:9.35 & sMAPE is:4.85% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :31.28 & 16.11% & 0.97\n",
      "for 2022-06-08, MAE is:11.46 & sMAPE is:6.16% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :31.16 & 16.04% & 0.97\n",
      "for 2022-06-09, MAE is:6.67 & sMAPE is:3.61% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :31.00 & 15.96% & 0.96\n",
      "for 2022-06-10, MAE is:17.49 & sMAPE is:9.40% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :30.92 & 15.92% & 0.96\n",
      "for 2022-06-11, MAE is:14.76 & sMAPE is:7.83% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :30.82 & 15.87% & 0.96\n",
      "for 2022-06-12, MAE is:20.45 & sMAPE is:13.43% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :30.76 & 15.86% & 0.96\n",
      "for 2022-06-13, MAE is:21.38 & sMAPE is:11.07% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :30.70 & 15.83% & 0.96\n",
      "for 2022-06-14, MAE is:12.18 & sMAPE is:5.94% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :30.59 & 15.77% & 0.96\n",
      "for 2022-06-15, MAE is:43.57 & sMAPE is:23.32% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :30.67 & 15.82% & 0.97\n",
      "for 2022-06-16, MAE is:11.93 & sMAPE is:6.85% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :30.55 & 15.76% & 0.97\n",
      "for 2022-06-17, MAE is:8.28 & sMAPE is:4.52% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :30.42 & 15.69% & 0.96\n",
      "for 2022-06-18, MAE is:36.44 & sMAPE is:24.30% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :30.46 & 15.75% & 0.96\n",
      "for 2022-06-19, MAE is:42.63 & sMAPE is:34.92% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :30.53 & 15.86% & 0.96\n",
      "for 2022-06-20, MAE is:24.38 & sMAPE is:15.59% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :30.49 & 15.86% & 0.96\n",
      "for 2022-06-21, MAE is:20.59 & sMAPE is:13.27% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :30.44 & 15.84% & 0.95\n",
      "for 2022-06-22, MAE is:8.51 & sMAPE is:5.38% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :30.31 & 15.78% & 0.95\n",
      "for 2022-06-23, MAE is:13.20 & sMAPE is:8.78% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :30.21 & 15.74% & 0.95\n",
      "for 2022-06-24, MAE is:13.46 & sMAPE is:9.54% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :30.11 & 15.71% & 0.95\n",
      "for 2022-06-25, MAE is:25.83 & sMAPE is:21.39% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :30.09 & 15.74% & 0.95\n",
      "for 2022-06-26, MAE is:14.76 & sMAPE is:13.14% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :30.00 & 15.72% & 0.95\n",
      "for 2022-06-27, MAE is:20.10 & sMAPE is:14.74% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :29.95 & 15.72% & 0.95\n",
      "for 2022-06-28, MAE is:8.15 & sMAPE is:5.64% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :29.83 & 15.66% & 0.95\n",
      "for 2022-06-29, MAE is:20.56 & sMAPE is:15.58% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :29.77 & 15.66% & 0.95\n",
      "for 2022-06-30, MAE is:20.56 & sMAPE is:16.33% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :29.72 & 15.66% & 0.95\n",
      "for 2022-07-01, MAE is:22.06 & sMAPE is:16.62% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :29.68 & 15.67% & 0.95\n",
      "for 2022-07-02, MAE is:19.64 & sMAPE is:14.03% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :29.63 & 15.66% & 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-03, MAE is:18.31 & sMAPE is:13.83% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :29.57 & 15.65% & 0.95\n",
      "for 2022-07-04, MAE is:11.89 & sMAPE is:7.82% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :29.47 & 15.61% & 0.95\n",
      "for 2022-07-05, MAE is:7.69 & sMAPE is:5.62% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :29.35 & 15.56% & 0.95\n",
      "for 2022-07-06, MAE is:17.84 & sMAPE is:12.64% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :29.29 & 15.54% & 0.94\n",
      "for 2022-07-07, MAE is:14.99 & sMAPE is:11.73% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :29.21 & 15.52% & 0.94\n",
      "for 2022-07-08, MAE is:20.94 & sMAPE is:15.20% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :29.17 & 15.52% & 0.95\n",
      "for 2022-07-09, MAE is:19.89 & sMAPE is:14.23% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :29.12 & 15.51% & 0.96\n",
      "for 2022-07-10, MAE is:13.52 & sMAPE is:9.81% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :29.04 & 15.48% & 0.96\n",
      "for 2022-07-11, MAE is:9.23 & sMAPE is:5.94% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :28.94 & 15.43% & 0.96\n",
      "for 2022-07-12, MAE is:12.94 & sMAPE is:8.17% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :28.85 & 15.39% & 0.96\n",
      "for 2022-07-13, MAE is:8.23 & sMAPE is:5.07% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :28.75 & 15.34% & 0.96\n",
      "for 2022-07-14, MAE is:17.74 & sMAPE is:11.31% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :28.69 & 15.32% & 0.95\n",
      "for 2022-07-15, MAE is:10.76 & sMAPE is:7.46% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :28.60 & 15.28% & 0.95\n",
      "for 2022-07-16, MAE is:14.02 & sMAPE is:10.12% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :28.53 & 15.25% & 0.95\n",
      "for 2022-07-17, MAE is:36.44 & sMAPE is:32.80% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :28.57 & 15.34% & 0.95\n",
      "for 2022-07-18, MAE is:22.87 & sMAPE is:18.57% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :28.54 & 15.36% & 0.95\n",
      "for 2022-07-19, MAE is:28.83 & sMAPE is:22.08% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :28.54 & 15.39% & 0.96\n",
      "for 2022-07-20, MAE is:9.59 & sMAPE is:6.57% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :28.44 & 15.35% & 0.96\n",
      "for 2022-07-21, MAE is:12.00 & sMAPE is:9.03% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :28.36 & 15.32% & 0.95\n",
      "for 2022-07-22, MAE is:12.10 & sMAPE is:9.14% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :28.28 & 15.29% & 0.95\n",
      "for 2022-07-23, MAE is:43.72 & sMAPE is:32.04% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :28.36 & 15.37% & 0.96\n",
      "for 2022-07-24, MAE is:22.16 & sMAPE is:16.63% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :28.33 & 15.37% & 0.96\n",
      "for 2022-07-25, MAE is:24.72 & sMAPE is:16.71% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :28.31 & 15.38% & 0.95\n",
      "for 2022-07-26, MAE is:9.65 & sMAPE is:6.69% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :28.22 & 15.34% & 0.95\n",
      "for 2022-07-27, MAE is:13.56 & sMAPE is:9.55% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :28.15 & 15.31% & 0.96\n",
      "for 2022-07-28, MAE is:25.72 & sMAPE is:16.46% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :28.14 & 15.32% & 0.96\n",
      "for 2022-07-29, MAE is:9.81 & sMAPE is:6.78% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :28.05 & 15.28% & 0.96\n",
      "for 2022-07-30, MAE is:9.87 & sMAPE is:7.51% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :27.97 & 15.24% & 0.95\n",
      "for 2022-07-31, MAE is:18.72 & sMAPE is:16.05% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :27.92 & 15.24% & 0.95\n",
      "for 2022-08-01, MAE is:21.46 & sMAPE is:15.72% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :27.89 & 15.25% & 0.95\n",
      "for 2022-08-02, MAE is:15.57 & sMAPE is:10.75% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :27.83 & 15.22% & 0.95\n",
      "for 2022-08-03, MAE is:11.40 & sMAPE is:7.85% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :27.76 & 15.19% & 0.95\n",
      "for 2022-08-04, MAE is:8.68 & sMAPE is:5.99% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :27.67 & 15.15% & 0.95\n",
      "for 2022-08-05, MAE is:7.69 & sMAPE is:5.57% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :27.58 & 15.10% & 0.95\n",
      "for 2022-08-06, MAE is:13.55 & sMAPE is:9.93% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :27.51 & 15.08% & 0.95\n",
      "for 2022-08-07, MAE is:25.58 & sMAPE is:21.82% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :27.50 & 15.11% & 0.95\n",
      "for 2022-08-08, MAE is:9.30 & sMAPE is:6.43% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :27.42 & 15.07% & 0.95\n",
      "for 2022-08-09, MAE is:6.87 & sMAPE is:4.83% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :27.33 & 15.02% & 0.95\n",
      "for 2022-08-10, MAE is:8.47 & sMAPE is:6.02% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :27.24 & 14.98% & 0.95\n",
      "for 2022-08-11, MAE is:9.04 & sMAPE is:6.16% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :27.16 & 14.94% & 0.95\n",
      "for 2022-08-12, MAE is:12.44 & sMAPE is:7.99% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :27.10 & 14.91% & 0.95\n",
      "for 2022-08-13, MAE is:12.34 & sMAPE is:8.43% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :27.03 & 14.88% & 0.95\n",
      "for 2022-08-14, MAE is:33.83 & sMAPE is:23.60% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :27.06 & 14.92% & 0.95\n",
      "for 2022-08-15, MAE is:16.98 & sMAPE is:11.76% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :27.02 & 14.91% & 0.95\n",
      "for 2022-08-16, MAE is:21.07 & sMAPE is:15.11% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :26.99 & 14.91% & 0.95\n",
      "for 2022-08-17, MAE is:23.55 & sMAPE is:17.26% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :26.97 & 14.92% & 0.95\n",
      "for 2022-08-18, MAE is:20.44 & sMAPE is:15.42% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :26.95 & 14.92% & 0.95\n",
      "for 2022-08-19, MAE is:26.12 & sMAPE is:19.49% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :26.94 & 14.94% & 0.95\n",
      "for 2022-08-20, MAE is:17.89 & sMAPE is:10.73% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :26.90 & 14.92% & 0.95\n",
      "for 2022-08-21, MAE is:40.01 & sMAPE is:32.46% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :26.96 & 15.00% & 0.96\n",
      "for 2022-08-22, MAE is:38.18 & sMAPE is:22.72% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :27.01 & 15.03% & 0.96\n",
      "for 2022-08-23, MAE is:16.55 & sMAPE is:8.92% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :26.96 & 15.01% & 0.96\n",
      "for 2022-08-24, MAE is:22.06 & sMAPE is:12.36% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :26.94 & 15.00% & 0.95\n",
      "for 2022-08-25, MAE is:27.65 & sMAPE is:16.51% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :26.95 & 15.00% & 0.95\n",
      "for 2022-08-26, MAE is:32.15 & sMAPE is:18.77% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :26.97 & 15.02% & 0.95\n",
      "for 2022-08-27, MAE is:32.77 & sMAPE is:19.95% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :26.99 & 15.04% & 0.96\n",
      "for 2022-08-28, MAE is:49.98 & sMAPE is:38.50% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :27.09 & 15.14% & 0.96\n",
      "for 2022-08-29, MAE is:25.49 & sMAPE is:13.76% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :27.08 & 15.13% & 0.96\n",
      "for 2022-08-30, MAE is:19.50 & sMAPE is:9.90% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :27.05 & 15.11% & 0.96\n",
      "for 2022-08-31, MAE is:17.21 & sMAPE is:9.20% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :27.01 & 15.08% & 0.96\n",
      "for 2022-09-01, MAE is:16.11 & sMAPE is:8.24% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :26.96 & 15.06% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-02, MAE is:40.70 & sMAPE is:24.50% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :27.02 & 15.09% & 0.96\n",
      "for 2022-09-03, MAE is:34.98 & sMAPE is:33.14% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :27.05 & 15.17% & 0.96\n",
      "for 2022-09-04, MAE is:59.65 & sMAPE is:48.52% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :27.18 & 15.30% & 0.96\n",
      "for 2022-09-05, MAE is:31.96 & sMAPE is:17.69% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :27.20 & 15.31% & 0.97\n",
      "for 2022-09-06, MAE is:40.17 & sMAPE is:23.34% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :27.26 & 15.35% & 0.97\n",
      "for 2022-09-07, MAE is:90.04 & sMAPE is:63.89% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :27.51 & 15.54% & 0.97\n",
      "for 2022-09-08, MAE is:27.47 & sMAPE is:18.29% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :27.51 & 15.55% & 0.97\n",
      "for 2022-09-09, MAE is:26.97 & sMAPE is:16.86% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :27.50 & 15.56% & 0.97\n",
      "for 2022-09-10, MAE is:24.04 & sMAPE is:12.96% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :27.49 & 15.55% & 0.97\n",
      "for 2022-09-11, MAE is:33.18 & sMAPE is:21.74% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :27.51 & 15.57% & 0.97\n",
      "for 2022-09-12, MAE is:18.01 & sMAPE is:10.23% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :27.48 & 15.55% & 0.97\n",
      "for 2022-09-13, MAE is:50.17 & sMAPE is:34.80% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :27.57 & 15.62% & 0.97\n",
      "for 2022-09-14, MAE is:28.33 & sMAPE is:20.72% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :27.57 & 15.64% & 0.97\n",
      "for 2022-09-15, MAE is:27.97 & sMAPE is:17.19% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :27.57 & 15.65% & 0.97\n",
      "for 2022-09-16, MAE is:17.84 & sMAPE is:10.60% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :27.53 & 15.63% & 0.97\n",
      "for 2022-09-17, MAE is:85.65 & sMAPE is:90.34% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :27.76 & 15.92% & 0.97\n",
      "for 2022-09-18, MAE is:42.81 & sMAPE is:35.58% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :27.81 & 15.99% & 0.97\n",
      "for 2022-09-19, MAE is:43.38 & sMAPE is:24.90% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :27.87 & 16.03% & 0.97\n",
      "for 2022-09-20, MAE is:39.17 & sMAPE is:23.92% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :27.92 & 16.06% & 0.97\n",
      "for 2022-09-21, MAE is:17.50 & sMAPE is:12.69% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :27.88 & 16.04% & 0.97\n",
      "for 2022-09-22, MAE is:40.55 & sMAPE is:25.43% & rMAE is:3.08 ||| daily mean of MAE & sMAPE & rMAE till now are :27.92 & 16.08% & 0.98\n",
      "for 2022-09-23, MAE is:37.56 & sMAPE is:27.49% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :27.96 & 16.12% & 0.98\n",
      "for 2022-09-24, MAE is:21.29 & sMAPE is:21.92% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :27.94 & 16.14% & 0.98\n",
      "for 2022-09-25, MAE is:40.78 & sMAPE is:69.59% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :27.98 & 16.34% & 0.98\n",
      "for 2022-09-26, MAE is:21.15 & sMAPE is:17.08% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :27.96 & 16.35% & 0.98\n",
      "for 2022-09-27, MAE is:38.82 & sMAPE is:42.34% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :28.00 & 16.44% & 0.98\n",
      "for 2022-09-28, MAE is:26.13 & sMAPE is:26.97% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :27.99 & 16.48% & 0.98\n",
      "for 2022-09-29, MAE is:16.96 & sMAPE is:14.19% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :27.95 & 16.47% & 0.97\n",
      "for 2022-09-30, MAE is:29.77 & sMAPE is:24.74% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :27.96 & 16.50% & 0.97\n",
      "for 2022-10-01, MAE is:30.68 & sMAPE is:26.24% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :27.97 & 16.54% & 0.97\n",
      "for 2022-10-02, MAE is:30.38 & sMAPE is:21.24% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :27.98 & 16.56% & 0.97\n",
      "for 2022-10-03, MAE is:41.31 & sMAPE is:22.66% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :28.02 & 16.58% & 0.97\n",
      "for 2022-10-04, MAE is:33.01 & sMAPE is:17.47% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :28.04 & 16.58% & 0.97\n",
      "for 2022-10-05, MAE is:40.70 & sMAPE is:23.52% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :28.09 & 16.61% & 0.97\n",
      "for 2022-10-06, MAE is:53.25 & sMAPE is:42.14% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :28.18 & 16.70% & 0.97\n",
      "for 2022-10-07, MAE is:24.02 & sMAPE is:15.15% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :28.16 & 16.69% & 0.97\n",
      "for 2022-10-08, MAE is:27.12 & sMAPE is:22.49% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :28.16 & 16.71% & 0.97\n",
      "for 2022-10-09, MAE is:33.54 & sMAPE is:28.86% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :28.18 & 16.76% & 0.97\n",
      "for 2022-10-10, MAE is:36.32 & sMAPE is:22.56% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :28.21 & 16.78% & 0.97\n",
      "for 2022-10-11, MAE is:17.59 & sMAPE is:10.21% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :28.17 & 16.75% & 0.97\n",
      "for 2022-10-12, MAE is:28.55 & sMAPE is:20.23% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :28.17 & 16.77% & 0.97\n",
      "for 2022-10-13, MAE is:21.77 & sMAPE is:14.35% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :28.15 & 16.76% & 0.97\n",
      "for 2022-10-14, MAE is:25.08 & sMAPE is:19.20% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :28.14 & 16.77% & 0.97\n",
      "for 2022-10-15, MAE is:22.55 & sMAPE is:21.21% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :28.12 & 16.78% & 0.97\n",
      "for 2022-10-16, MAE is:14.90 & sMAPE is:15.67% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :28.07 & 16.78% & 0.97\n",
      "for 2022-10-17, MAE is:21.98 & sMAPE is:15.23% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :28.05 & 16.77% & 0.97\n",
      "for 2022-10-18, MAE is:42.31 & sMAPE is:37.83% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :28.10 & 16.84% & 0.97\n",
      "for 2022-10-19, MAE is:29.65 & sMAPE is:35.23% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :28.11 & 16.91% & 0.97\n",
      "for 2022-10-20, MAE is:10.39 & sMAPE is:11.79% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :28.05 & 16.89% & 0.97\n",
      "for 2022-10-21, MAE is:24.94 & sMAPE is:25.32% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :28.04 & 16.92% & 0.97\n",
      "for 2022-10-22, MAE is:17.66 & sMAPE is:18.14% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :28.00 & 16.92% & 0.97\n",
      "for 2022-10-23, MAE is:26.94 & sMAPE is:41.93% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :28.00 & 17.01% & 0.97\n",
      "for 2022-10-24, MAE is:15.97 & sMAPE is:14.09% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :27.96 & 17.00% & 0.96\n",
      "for 2022-10-25, MAE is:13.80 & sMAPE is:13.14% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :27.91 & 16.98% & 0.96\n",
      "for 2022-10-26, MAE is:13.65 & sMAPE is:12.06% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :27.86 & 16.97% & 0.96\n",
      "for 2022-10-27, MAE is:22.03 & sMAPE is:20.12% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :27.84 & 16.98% & 0.96\n",
      "for 2022-10-28, MAE is:13.28 & sMAPE is:12.00% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :27.79 & 16.96% & 0.96\n",
      "for 2022-10-29, MAE is:9.68 & sMAPE is:9.65% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :27.73 & 16.94% & 0.96\n",
      "for 2022-10-30, MAE is:29.13 & sMAPE is:21.46% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :27.74 & 16.95% & 0.96\n",
      "for 2022-10-31, MAE is:22.73 & sMAPE is:13.62% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :27.72 & 16.94% & 0.96\n",
      "for 2022-11-01, MAE is:54.32 & sMAPE is:41.54% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :27.81 & 17.02% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-02, MAE is:18.38 & sMAPE is:13.87% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :27.78 & 17.01% & 0.96\n",
      "for 2022-11-03, MAE is:14.45 & sMAPE is:11.79% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :27.73 & 16.99% & 0.96\n",
      "for 2022-11-04, MAE is:30.16 & sMAPE is:21.23% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :27.74 & 17.01% & 0.96\n",
      "for 2022-11-05, MAE is:31.79 & sMAPE is:23.30% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :27.76 & 17.03% & 0.96\n",
      "for 2022-11-06, MAE is:13.66 & sMAPE is:12.20% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :27.71 & 17.01% & 0.96\n",
      "for 2022-11-07, MAE is:20.32 & sMAPE is:16.38% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :27.69 & 17.01% & 0.96\n",
      "for 2022-11-08, MAE is:19.05 & sMAPE is:16.81% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :27.66 & 17.01% & 0.96\n",
      "for 2022-11-09, MAE is:17.33 & sMAPE is:13.04% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :27.63 & 17.00% & 0.96\n",
      "for 2022-11-10, MAE is:17.25 & sMAPE is:12.43% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :27.59 & 16.98% & 0.96\n",
      "for 2022-11-11, MAE is:16.16 & sMAPE is:12.94% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :27.56 & 16.97% & 0.96\n",
      "for 2022-11-12, MAE is:18.66 & sMAPE is:16.89% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :27.53 & 16.97% & 0.96\n",
      "for 2022-11-13, MAE is:15.43 & sMAPE is:12.20% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :27.49 & 16.96% & 0.96\n",
      "for 2022-11-14, MAE is:14.91 & sMAPE is:10.82% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :27.45 & 16.94% & 0.96\n",
      "for 2022-11-15, MAE is:19.14 & sMAPE is:17.03% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :27.42 & 16.94% & 0.96\n",
      "for 2022-11-16, MAE is:19.77 & sMAPE is:17.45% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :27.40 & 16.94% & 0.96\n",
      "for 2022-11-17, MAE is:29.73 & sMAPE is:44.90% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :27.41 & 17.03% & 0.96\n",
      "for 2022-11-18, MAE is:21.35 & sMAPE is:17.87% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :27.39 & 17.03% & 0.96\n",
      "for 2022-11-19, MAE is:27.67 & sMAPE is:41.31% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :27.39 & 17.10% & 0.96\n",
      "for 2022-11-20, MAE is:13.04 & sMAPE is:13.51% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :27.35 & 17.09% & 0.96\n",
      "for 2022-11-21, MAE is:22.38 & sMAPE is:26.17% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :27.33 & 17.12% & 0.95\n",
      "for 2022-11-22, MAE is:12.20 & sMAPE is:16.49% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :27.28 & 17.12% & 0.95\n",
      "for 2022-11-23, MAE is:36.12 & sMAPE is:56.54% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :27.31 & 17.24% & 0.95\n",
      "for 2022-11-24, MAE is:23.41 & sMAPE is:17.52% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :27.30 & 17.24% & 0.95\n",
      "for 2022-11-25, MAE is:14.41 & sMAPE is:10.30% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :27.26 & 17.22% & 0.95\n",
      "for 2022-11-26, MAE is:15.86 & sMAPE is:12.20% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :27.22 & 17.20% & 0.95\n",
      "for 2022-11-27, MAE is:18.32 & sMAPE is:15.32% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :27.20 & 17.20% & 0.95\n",
      "for 2022-11-28, MAE is:15.37 & sMAPE is:14.60% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :27.16 & 17.19% & 0.95\n",
      "for 2022-11-29, MAE is:19.13 & sMAPE is:15.19% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :27.14 & 17.18% & 0.94\n",
      "for 2022-11-30, MAE is:16.97 & sMAPE is:11.83% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :27.11 & 17.17% & 0.94\n",
      "for 2022-12-01, MAE is:10.23 & sMAPE is:7.06% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :27.06 & 17.14% & 0.94\n",
      "for 2022-12-02, MAE is:18.82 & sMAPE is:14.65% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :27.03 & 17.13% & 0.94\n",
      "for 2022-12-03, MAE is:15.50 & sMAPE is:12.44% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :27.00 & 17.12% & 0.94\n",
      "for 2022-12-04, MAE is:75.09 & sMAPE is:48.83% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :27.14 & 17.21% & 0.94\n",
      "for 2022-12-05, MAE is:24.87 & sMAPE is:12.30% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :27.13 & 17.20% & 0.94\n",
      "for 2022-12-06, MAE is:39.74 & sMAPE is:22.90% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :27.17 & 17.21% & 0.94\n",
      "for 2022-12-07, MAE is:7.65 & sMAPE is:5.24% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :27.11 & 17.18% & 0.94\n",
      "for 2022-12-08, MAE is:12.88 & sMAPE is:10.59% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :27.07 & 17.16% & 0.94\n",
      "for 2022-12-09, MAE is:24.56 & sMAPE is:17.87% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :27.07 & 17.16% & 0.94\n",
      "for 2022-12-10, MAE is:16.63 & sMAPE is:12.75% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :27.03 & 17.15% & 0.94\n",
      "for 2022-12-11, MAE is:14.15 & sMAPE is:9.73% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :27.00 & 17.13% & 0.94\n",
      "for 2022-12-12, MAE is:26.89 & sMAPE is:21.43% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :27.00 & 17.14% & 0.94\n",
      "for 2022-12-13, MAE is:38.90 & sMAPE is:60.36% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :27.03 & 17.26% & 0.94\n",
      "for 2022-12-14, MAE is:40.37 & sMAPE is:68.71% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :27.07 & 17.41% & 0.93\n",
      "for 2022-12-15, MAE is:33.64 & sMAPE is:27.75% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :27.09 & 17.44% & 0.94\n",
      "for 2022-12-16, MAE is:12.56 & sMAPE is:10.34% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :27.05 & 17.42% & 0.94\n",
      "for 2022-12-17, MAE is:18.34 & sMAPE is:14.62% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :27.02 & 17.41% & 0.94\n",
      "for 2022-12-18, MAE is:17.29 & sMAPE is:16.50% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :26.99 & 17.41% & 0.93\n",
      "for 2022-12-19, MAE is:18.62 & sMAPE is:24.19% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :26.97 & 17.43% & 0.93\n",
      "for 2022-12-20, MAE is:26.19 & sMAPE is:54.76% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :26.97 & 17.53% & 0.93\n",
      "for 2022-12-21, MAE is:12.93 & sMAPE is:19.69% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :26.93 & 17.54% & 0.93\n",
      "for 2022-12-22, MAE is:14.13 & sMAPE is:25.24% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :26.89 & 17.56% & 0.93\n",
      "for 2022-12-23, MAE is:26.95 & sMAPE is:97.32% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :26.89 & 17.78% & 0.93\n",
      "for 2022-12-24, MAE is:13.18 & sMAPE is:33.18% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :26.86 & 17.83% & 0.92\n",
      "for 2022-12-25, MAE is:12.26 & sMAPE is:99.59% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :26.81 & 18.06% & 0.92\n",
      "for 2022-12-26, MAE is:31.45 & sMAPE is:35.42% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :26.83 & 18.10% & 0.92\n",
      "for 2022-12-27, MAE is:22.41 & sMAPE is:20.70% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :26.82 & 18.11% & 0.92\n",
      "for 2022-12-28, MAE is:58.43 & sMAPE is:88.63% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :26.90 & 18.31% & 0.93\n",
      "for 2022-12-29, MAE is:23.03 & sMAPE is:104.64% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :26.89 & 18.54% & 0.93\n",
      "for 2022-12-30, MAE is:8.25 & sMAPE is:92.84% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :26.84 & 18.75% & 0.92\n",
      "for 2022-12-31, MAE is:11.63 & sMAPE is:166.62% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :26.80 & 19.15% & 0.92\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:53:52,318]\u001b[0m A new study created in RDB with name: ES_2023\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:20,814]\u001b[0m Trial 3 finished with value: 28.344402808183784 and parameters: {'n_hidden': 3, 'learning_rate': 0.004798753983782634, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056615063129805736, 'dropout_rate_Layer_2': 0.23660025218482517, 'dropout_rate_Layer_3': 0.1949929517217981, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001032791065788844, 'l1_Layer_2': 0.00033183812332414716, 'l1_Layer_3': 0.0010145249655572094, 'n_units_Layer_1': 300, 'n_units_Layer_2': 105, 'n_units_Layer_3': 65}. Best is trial 3 with value: 28.344402808183784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.34 | sMAPE for Validation Set is: 20.13% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 22.89 | sMAPE for Test Set is: 37.47% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:54:21,301]\u001b[0m Trial 1 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:26,659]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:28,720]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:33,191]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:36,591]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:37,038]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:37,171]\u001b[0m Trial 0 finished with value: 35.50911462814226 and parameters: {'n_hidden': 4, 'learning_rate': 0.015383091314962866, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18856704481285777, 'dropout_rate_Layer_2': 0.21078789636954753, 'dropout_rate_Layer_3': 0.13189218463441854, 'dropout_rate_Layer_4': 0.2872891194754962, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.01795590574537913, 'l1_Layer_2': 0.052709718486821835, 'l1_Layer_3': 0.00012165137424140331, 'l1_Layer_4': 0.007080499610785811, 'n_units_Layer_1': 185, 'n_units_Layer_2': 200, 'n_units_Layer_3': 130, 'n_units_Layer_4': 130}. Best is trial 3 with value: 28.344402808183784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.51 | sMAPE for Validation Set is: 23.99% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 27.73 | sMAPE for Test Set is: 41.56% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:54:43,461]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:45,855]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:46,271]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:52,077]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:53,590]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:59,075]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:55:00,075]\u001b[0m Trial 12 finished with value: 25.33378984313659 and parameters: {'n_hidden': 3, 'learning_rate': 0.03028875482020357, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23589379096037857, 'dropout_rate_Layer_2': 0.06921626222019182, 'dropout_rate_Layer_3': 0.26305566490834187, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004174290343769613, 'l1_Layer_2': 0.01868551043757199, 'l1_Layer_3': 1.38779946797396e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 75, 'n_units_Layer_3': 185}. Best is trial 12 with value: 25.33378984313659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.33 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.63 | sMAPE for Test Set is: 35.92% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:55:03,953]\u001b[0m Trial 2 finished with value: 28.599409291531117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0196080546071709, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.345846708731547, 'dropout_rate_Layer_2': 0.39652982372734424, 'dropout_rate_Layer_3': 0.2619063156389989, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008084476684811425, 'l1_Layer_2': 0.026209238577619736, 'l1_Layer_3': 0.09038470852361981, 'n_units_Layer_1': 195, 'n_units_Layer_2': 185, 'n_units_Layer_3': 170}. Best is trial 12 with value: 25.33378984313659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.60 | sMAPE for Validation Set is: 20.41% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.73 | sMAPE for Test Set is: 38.34% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:55:06,069]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:55:08,536]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:55:13,671]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:55:17,248]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:55:18,238]\u001b[0m Trial 15 finished with value: 29.611971332196635 and parameters: {'n_hidden': 3, 'learning_rate': 0.006730609227779149, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006276452194104865, 'dropout_rate_Layer_2': 0.11073263432480625, 'dropout_rate_Layer_3': 0.0237633529038495, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2101457680906693e-05, 'l1_Layer_2': 4.590570016151113e-05, 'l1_Layer_3': 0.03655250345905744, 'n_units_Layer_1': 160, 'n_units_Layer_2': 150, 'n_units_Layer_3': 85}. Best is trial 12 with value: 25.33378984313659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.61 | sMAPE for Validation Set is: 21.17% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 24.57 | sMAPE for Test Set is: 39.34% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:55:19,773]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:55:24,088]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:55:29,392]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:55:33,871]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:55:40,656]\u001b[0m Trial 19 finished with value: 42.98347558536563 and parameters: {'n_hidden': 4, 'learning_rate': 0.05113534157973176, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18816576583258673, 'dropout_rate_Layer_2': 0.13437655881110905, 'dropout_rate_Layer_3': 0.3347386907907088, 'dropout_rate_Layer_4': 0.25789876808194806, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.003980316997526755, 'l1_Layer_2': 0.049244740285533474, 'l1_Layer_3': 0.015748203659973165, 'l1_Layer_4': 0.007660040114268279, 'n_units_Layer_1': 70, 'n_units_Layer_2': 100, 'n_units_Layer_3': 295, 'n_units_Layer_4': 140}. Best is trial 12 with value: 25.33378984313659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.98 | sMAPE for Validation Set is: 28.13% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 29.93 | sMAPE for Test Set is: 47.21% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:55:50,643]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:55:55,276]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:06,625]\u001b[0m Trial 28 finished with value: 28.994204891673675 and parameters: {'n_hidden': 3, 'learning_rate': 0.012925039957911753, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1930701604767298, 'dropout_rate_Layer_2': 0.2046251727811293, 'dropout_rate_Layer_3': 0.2523875447603423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.02259688892672021, 'l1_Layer_2': 3.717171790671607e-05, 'l1_Layer_3': 0.046709670393666074, 'n_units_Layer_1': 215, 'n_units_Layer_2': 110, 'n_units_Layer_3': 145}. Best is trial 12 with value: 25.33378984313659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.99 | sMAPE for Validation Set is: 20.34% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 22.79 | sMAPE for Test Set is: 36.41% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:56:08,326]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:12,342]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:12,915]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:16,121]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:20,719]\u001b[0m Trial 29 finished with value: 31.788484920736128 and parameters: {'n_hidden': 4, 'learning_rate': 0.00762771410248263, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.298707300778853, 'dropout_rate_Layer_2': 0.3365212451963633, 'dropout_rate_Layer_3': 0.2552493862992337, 'dropout_rate_Layer_4': 0.2884212386117674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04584835990086799, 'l1_Layer_2': 1.2727590862915475e-05, 'l1_Layer_3': 0.0004598659195307272, 'l1_Layer_4': 0.0077552301370851515, 'n_units_Layer_1': 215, 'n_units_Layer_2': 115, 'n_units_Layer_3': 230, 'n_units_Layer_4': 100}. Best is trial 12 with value: 25.33378984313659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.79 | sMAPE for Validation Set is: 21.98% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 24.10 | sMAPE for Test Set is: 38.41% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:56:21,391]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:26,743]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:32,304]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:41,307]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:46,465]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:49,750]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:50,347]\u001b[0m Trial 38 finished with value: 26.988361062009016 and parameters: {'n_hidden': 3, 'learning_rate': 0.00499263607955794, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014459406989741198, 'dropout_rate_Layer_2': 0.2763339366010884, 'dropout_rate_Layer_3': 0.3499704663214771, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006460938326621532, 'l1_Layer_2': 0.011423149355396116, 'l1_Layer_3': 2.5025440608284682e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 270, 'n_units_Layer_3': 240}. Best is trial 12 with value: 25.33378984313659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.99 | sMAPE for Validation Set is: 19.52% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.15 | sMAPE for Test Set is: 36.17% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:56:57,477]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:58,748]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:12,300]\u001b[0m Trial 41 finished with value: 28.84565276237395 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022485746398433226, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.298006896199269, 'dropout_rate_Layer_2': 0.31271842410127826, 'dropout_rate_Layer_3': 0.26206810814537607, 'dropout_rate_Layer_4': 0.25338060458871897, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.122214693331829e-05, 'l1_Layer_2': 0.0015232026719052888, 'l1_Layer_3': 0.037659699015744584, 'l1_Layer_4': 0.00026157126075281663, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 270, 'n_units_Layer_4': 195}. Best is trial 12 with value: 25.33378984313659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.85 | sMAPE for Validation Set is: 20.33% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 23.43 | sMAPE for Test Set is: 37.19% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:57:14,750]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:15,165]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:24,284]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:29,161]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:29,746]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:34,864]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:36,570]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:39,864]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:43,588]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:46,307]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:51,543]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:57,844]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:57:58,339]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:01,380]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:07,220]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:09,206]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:09,361]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:13,510]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:21,759]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:23,811]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:28,464]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:34,546]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:36,936]\u001b[0m Trial 54 finished with value: 26.73360428323515 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014241596803955632, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26224569196738645, 'dropout_rate_Layer_2': 0.3619928593452766, 'dropout_rate_Layer_3': 0.11301897679650304, 'dropout_rate_Layer_4': 0.06679264631051725, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00800737718806271, 'l1_Layer_2': 0.0006117065137664437, 'l1_Layer_3': 0.0018312607532407475, 'l1_Layer_4': 0.00904521726430572, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 85, 'n_units_Layer_4': 210}. Best is trial 12 with value: 25.33378984313659.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.73 | sMAPE for Validation Set is: 19.33% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.51 | sMAPE for Test Set is: 36.45% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:58:45,318]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:48,261]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:48,467]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:54,956]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:56,586]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:01,878]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:03,164]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:04,917]\u001b[0m Trial 65 finished with value: 24.257432918831555 and parameters: {'n_hidden': 3, 'learning_rate': 0.001423387320051848, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1222959217730008, 'dropout_rate_Layer_2': 0.2655411576239734, 'dropout_rate_Layer_3': 0.15923078977623623, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002804628472696629, 'l1_Layer_2': 0.00026743113916753144, 'l1_Layer_3': 0.005463036111670454, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 300}. Best is trial 65 with value: 24.257432918831555.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.26 | sMAPE for Validation Set is: 17.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.77 | sMAPE for Test Set is: 34.70% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:59:05,180]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:09,302]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:13,153]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:19,937]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:20,168]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:29,217]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:32,138]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:32,490]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:38,634]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:38,749]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:41,885]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:42,718]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:47,292]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:47,339]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:49,969]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:51,395]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:54,528]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:57,007]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:00,751]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:03,704]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:07,664]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:19,726]\u001b[0m Trial 97 finished with value: 26.196610156624008 and parameters: {'n_hidden': 3, 'learning_rate': 0.0058081146405671805, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28683013909263166, 'dropout_rate_Layer_2': 0.0444935361818721, 'dropout_rate_Layer_3': 0.16349047141385648, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024225334819679106, 'l1_Layer_2': 0.07767519417041421, 'l1_Layer_3': 0.01291213993210464, 'n_units_Layer_1': 55, 'n_units_Layer_2': 225, 'n_units_Layer_3': 155}. Best is trial 65 with value: 24.257432918831555.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.20 | sMAPE for Validation Set is: 19.37% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.85 | sMAPE for Test Set is: 37.82% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:00:20,243]\u001b[0m Trial 94 finished with value: 26.114976408441635 and parameters: {'n_hidden': 3, 'learning_rate': 0.00589258615435643, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3173599630132534, 'dropout_rate_Layer_2': 0.055743485871995894, 'dropout_rate_Layer_3': 0.13331093044718514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019503442567680456, 'l1_Layer_2': 0.09435349274654704, 'l1_Layer_3': 0.007384523689246087, 'n_units_Layer_1': 50, 'n_units_Layer_2': 210, 'n_units_Layer_3': 155}. Best is trial 65 with value: 24.257432918831555.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.11 | sMAPE for Validation Set is: 19.30% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.22 | sMAPE for Test Set is: 37.25% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:00:21,907]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:33,733]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:36,102]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:39,188]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:39,252]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:39,577]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:49,861]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:52,158]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:56,517]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:02,069]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:02,213]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:02,582]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:02,790]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:14,019]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:14,317]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:20,583]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:21,065]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:27,017]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:27,076]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:33,107]\u001b[0m Trial 111 finished with value: 24.106754936996566 and parameters: {'n_hidden': 3, 'learning_rate': 0.002840537509157005, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002576338041574755, 'dropout_rate_Layer_2': 0.2390060523121168, 'dropout_rate_Layer_3': 0.300270464067533, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010489026069827538, 'l1_Layer_2': 5.834777024941303e-05, 'l1_Layer_3': 0.0012599418401804939, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280}. Best is trial 111 with value: 24.106754936996566.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.11 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.86 | sMAPE for Test Set is: 34.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:01:38,212]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:38,307]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:38,593]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:48,512]\u001b[0m Trial 116 finished with value: 23.498233581412876 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028725068511303883, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03160500593501861, 'dropout_rate_Layer_2': 0.23603037986133507, 'dropout_rate_Layer_3': 0.30186133411100086, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.620013780465719e-05, 'l1_Layer_2': 5.958705300210433e-05, 'l1_Layer_3': 4.4699662114594455e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.50 | sMAPE for Validation Set is: 17.49% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.90 | sMAPE for Test Set is: 34.72% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:01:53,360]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:01:53,865]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:01,137]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:04,643]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:11,161]\u001b[0m Trial 122 finished with value: 30.541832179037545 and parameters: {'n_hidden': 3, 'learning_rate': 0.004002000873581799, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11546291716947704, 'dropout_rate_Layer_2': 0.2844620556930068, 'dropout_rate_Layer_3': 0.1859185704527246, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010801030269142331, 'l1_Layer_2': 1.2652421075534595e-05, 'l1_Layer_3': 0.0001242724343334744, 'n_units_Layer_1': 210, 'n_units_Layer_2': 85, 'n_units_Layer_3': 105}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.54 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 25.26 | sMAPE for Test Set is: 39.50% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:02:13,334]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:17,970]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:19,522]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:23,701]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:29,489]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:29,724]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:32,240]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:40,214]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:43,329]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:45,235]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:47,325]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:02:54,627]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:04,438]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:13,230]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:36,918]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:40,680]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:45,968]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:50,107]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:56,718]\u001b[0m Trial 141 finished with value: 34.60171612135051 and parameters: {'n_hidden': 4, 'learning_rate': 0.006272894459595999, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3321556997700913, 'dropout_rate_Layer_2': 0.25132859017109677, 'dropout_rate_Layer_3': 0.38641239467946925, 'dropout_rate_Layer_4': 0.2673295911662642, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0019633578228140974, 'l1_Layer_2': 3.2982745138225045e-05, 'l1_Layer_3': 0.043830826803150716, 'l1_Layer_4': 3.0394159744570752e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 195, 'n_units_Layer_3': 140, 'n_units_Layer_4': 250}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.60 | sMAPE for Validation Set is: 23.75% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 35.81 | sMAPE for Test Set is: 46.44% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:03:56,901]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:04,150]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:12,671]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.58 | sMAPE for Validation Set is: 18.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 25.18 | sMAPE for Test Set is: 38.87% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:04:14,173]\u001b[0m Trial 139 finished with value: 25.57874976658066 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018967016330583713, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2506416588013817, 'dropout_rate_Layer_2': 0.09997162142754677, 'dropout_rate_Layer_3': 0.3651924335829038, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006290114994764068, 'l1_Layer_2': 0.02391505184297309, 'l1_Layer_3': 0.0005278268860721417, 'n_units_Layer_1': 90, 'n_units_Layer_2': 255, 'n_units_Layer_3': 185}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:19,233]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:34,025]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:37,488]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:38,165]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:41,837]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.79 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.86 | sMAPE for Test Set is: 34.92% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:04:43,920]\u001b[0m Trial 152 finished with value: 23.790729105914323 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014332710642095748, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05061461616937627, 'dropout_rate_Layer_2': 0.22734300511689645, 'dropout_rate_Layer_3': 0.3337352971034095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017717273913858464, 'l1_Layer_2': 5.471885000740641e-05, 'l1_Layer_3': 2.569782940914218e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:46,084]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:46,321]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:50,487]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:51,845]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:54,477]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:57,112]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:58,994]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:03,085]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:03,494]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:04,432]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:06,250]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:12,071]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:16,864]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:22,521]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:26,356]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:26,699]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:30,268]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:35,241]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:38,072]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:38,219]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:40,567]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:45,816]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:47,975]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:48,957]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:56,632]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:01,822]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:16,489]\u001b[0m Trial 185 finished with value: 30.373605640525028 and parameters: {'n_hidden': 4, 'learning_rate': 0.020201407789853035, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3726195014236947, 'dropout_rate_Layer_2': 0.030481718905662758, 'dropout_rate_Layer_3': 0.12803697527581867, 'dropout_rate_Layer_4': 0.006342598374167792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020674280862658144, 'l1_Layer_2': 0.016026225171196735, 'l1_Layer_3': 0.011228697876486008, 'l1_Layer_4': 4.836664264381055e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 150, 'n_units_Layer_3': 155, 'n_units_Layer_4': 50}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.37 | sMAPE for Validation Set is: 21.46% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 25.83 | sMAPE for Test Set is: 40.75% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:06:21,808]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:24,917]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:27,626]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:28,639]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:35,582]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:37,269]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:41,494]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:41,832]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:49,731]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:54,704]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:59,483]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:00,207]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:09,058]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:10,555]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:20,730]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:20,974]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:27,302]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:28,067]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:28,099]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:34,109]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:36,694]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:41,516]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:41,600]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:41,866]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:41,924]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:47,350]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:57,982]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:02,842]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:06,811]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:08,848]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:12,786]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:15,912]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:16,525]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:19,010]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:24,256]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:33,317]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:38,266]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:38,960]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:42,282]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:47,190]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:51,498]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:58,258]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:58,857]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:03,970]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:14,718]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:21,729]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:27,145]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:31,140]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:35,608]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:39,897]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:40,152]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:44,082]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:47,696]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:48,304]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:55,179]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:04,220]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:05,427]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:08,233]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:11,373]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:13,943]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:14,876]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:18,844]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:23,514]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:26,001]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:29,118]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:34,104]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:34,449]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:35,497]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:41,584]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:44,745]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:45,352]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:49,714]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:52,554]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:55,939]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:58,841]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:03,127]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:05,993]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:13,219]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:22,426]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:22,795]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:33,297]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:35,520]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:35,681]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:38,445]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:44,660]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:48,322]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:50,377]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:54,446]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:56,946]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:57,896]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:02,839]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:06,141]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:10,538]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:12:14,811]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:25,190]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:31,216]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:35,353]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:35,455]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:38,842]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:47,332]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:47,504]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:54,128]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:54,269]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:59,888]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:06,949]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:07,240]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:18,638]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:19,299]\u001b[0m Trial 289 finished with value: 25.831814630524406 and parameters: {'n_hidden': 3, 'learning_rate': 0.008437278580952324, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23019877114162018, 'dropout_rate_Layer_2': 0.06946907386275197, 'dropout_rate_Layer_3': 0.12294203590175465, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001583112056257342, 'l1_Layer_2': 0.026020863633645898, 'l1_Layer_3': 0.012901513446490856, 'n_units_Layer_1': 105, 'n_units_Layer_2': 190, 'n_units_Layer_3': 75}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.83 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.13 | sMAPE for Test Set is: 37.12% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:13:21,354]\u001b[0m Trial 277 finished with value: 37.17981767430652 and parameters: {'n_hidden': 4, 'learning_rate': 0.007762273872742669, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3336679384505358, 'dropout_rate_Layer_2': 0.2508943288464233, 'dropout_rate_Layer_3': 0.3485716334085839, 'dropout_rate_Layer_4': 0.17608172985276963, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003937173266638616, 'l1_Layer_2': 0.00023321739897690715, 'l1_Layer_3': 0.0010081952559799162, 'l1_Layer_4': 1.6557199540870586e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 200, 'n_units_Layer_3': 220, 'n_units_Layer_4': 275}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.18 | sMAPE for Validation Set is: 25.19% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 26.53 | sMAPE for Test Set is: 40.99% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:13:26,659]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:29,770]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:34,713]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:37,664]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:41,077]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:44,933]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:48,927]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:52,678]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:57,904]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:06,047]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:08,534]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:11,100]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:11,761]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:19,303]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:23,307]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:27,998]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:32,655]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:37,296]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:43,073]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:48,508]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:54,113]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:15:03,531]\u001b[0m Trial 316 finished with value: 32.08361345544208 and parameters: {'n_hidden': 4, 'learning_rate': 0.0713055719965982, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32464066812365977, 'dropout_rate_Layer_2': 0.053843818543659036, 'dropout_rate_Layer_3': 0.08185739330901724, 'dropout_rate_Layer_4': 0.01486011807710793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00034654321878160285, 'l1_Layer_2': 0.014603542239676049, 'l1_Layer_3': 0.010056623192692012, 'l1_Layer_4': 3.9145996638298134e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135, 'n_units_Layer_4': 70}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.08 | sMAPE for Validation Set is: 22.50% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 27.82 | sMAPE for Test Set is: 43.66% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:15:15,032]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:15:20,519]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:15:25,196]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:15:27,724]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:15:42,912]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:15:45,667]\u001b[0m Trial 321 finished with value: 30.458291551849253 and parameters: {'n_hidden': 4, 'learning_rate': 0.012930856713948566, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39631335616893215, 'dropout_rate_Layer_2': 0.1426327044179911, 'dropout_rate_Layer_3': 0.1448529750057496, 'dropout_rate_Layer_4': 0.08370373245240006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001930760109607048, 'l1_Layer_2': 0.004484792381249309, 'l1_Layer_3': 0.02434245501661767, 'l1_Layer_4': 0.00011349797631700824, 'n_units_Layer_1': 55, 'n_units_Layer_2': 75, 'n_units_Layer_3': 200, 'n_units_Layer_4': 190}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.46 | sMAPE for Validation Set is: 21.24% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 25.57 | sMAPE for Test Set is: 39.35% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:15:52,115]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:15:55,730]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:01,387]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:03,171]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:08,438]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:12,959]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:16,877]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:17,154]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 109.80 | sMAPE for Validation Set is: 89.94% | rMAE for Validation Set is: 2.76\n",
      "MAE for Test Set is: 44.53 | sMAPE for Test Set is: 62.67% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:16:20,413]\u001b[0m Trial 328 finished with value: 109.79577672098823 and parameters: {'n_hidden': 4, 'learning_rate': 0.034015535349841204, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35015982867750717, 'dropout_rate_Layer_2': 0.0867271024524405, 'dropout_rate_Layer_3': 0.20719873724133034, 'dropout_rate_Layer_4': 0.15585494080666107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.007564084313695964, 'l1_Layer_2': 0.016954970227008755, 'l1_Layer_3': 0.00727684743554621, 'l1_Layer_4': 0.0015777395253055943, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 110, 'n_units_Layer_4': 245}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:26,722]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:29,812]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:31,906]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:32,417]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:37,995]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:38,723]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:40,748]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:44,452]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:48,650]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:50,443]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:56,604]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:59,620]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:03,691]\u001b[0m Trial 337 finished with value: 30.66035769411083 and parameters: {'n_hidden': 4, 'learning_rate': 0.005303301112934228, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21225609801077314, 'dropout_rate_Layer_2': 0.18233376985063945, 'dropout_rate_Layer_3': 0.10130455859235057, 'dropout_rate_Layer_4': 0.0425514438538008, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.2580121818700936e-05, 'l1_Layer_2': 0.0004944004647956429, 'l1_Layer_3': 0.00035852489344097516, 'l1_Layer_4': 0.0017530980410145663, 'n_units_Layer_1': 95, 'n_units_Layer_2': 190, 'n_units_Layer_3': 165, 'n_units_Layer_4': 235}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.66 | sMAPE for Validation Set is: 21.55% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 25.04 | sMAPE for Test Set is: 38.89% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:17:04,077]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:04,178]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:12,306]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:20,158]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:20,493]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:23,007]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:30,131]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:34,463]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:36,439]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:36,892]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:43,576]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:49,448]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:52,981]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:53,423]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:02,553]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:04,302]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:05,306]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:10,967]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:12,550]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:18,889]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:24,559]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:27,942]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:34,801]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:36,034]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:43,565]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:44,944]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:56,432]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:19:02,447]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:19:09,709]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:19:14,554]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:19:18,434]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:19:22,601]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:19:25,809]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:19:32,320]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:19:50,984]\u001b[0m Trial 378 finished with value: 29.945870301723478 and parameters: {'n_hidden': 4, 'learning_rate': 0.008725101747373374, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16353098436507488, 'dropout_rate_Layer_2': 0.006418000677153219, 'dropout_rate_Layer_3': 0.049147968927511165, 'dropout_rate_Layer_4': 0.17163448978383256, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003514455402441131, 'l1_Layer_2': 0.0001453377698085789, 'l1_Layer_3': 0.03324084711271116, 'l1_Layer_4': 1.410448683822393e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 240, 'n_units_Layer_3': 85, 'n_units_Layer_4': 280}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.95 | sMAPE for Validation Set is: 20.91% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 23.28 | sMAPE for Test Set is: 36.68% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:20:07,194]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:10,514]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:17,366]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:26,300]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:31,526]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:36,272]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:41,699]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:45,689]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:46,180]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:56,695]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:00,505]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:00,681]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:13,100]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:17,594]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:24,559]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:32,952]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:42,050]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:48,136]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:52,136]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:59,083]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:01,761]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:08,819]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:17,191]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:19,525]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:29,558]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:36,326]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:36,678]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:49,630]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:52,375]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:52,418]\u001b[0m Trial 365 finished with value: 27.21033474860022 and parameters: {'n_hidden': 4, 'learning_rate': 0.007597096301031012, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3163051352097588, 'dropout_rate_Layer_2': 0.38037018454436716, 'dropout_rate_Layer_3': 0.2801088268396256, 'dropout_rate_Layer_4': 0.02603901084631241, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00048297127315167604, 'l1_Layer_2': 0.02390685312671822, 'l1_Layer_3': 0.02291568300656591, 'l1_Layer_4': 1.98519416067243e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 250, 'n_units_Layer_3': 225, 'n_units_Layer_4': 280}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.21 | sMAPE for Validation Set is: 19.89% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.67 | sMAPE for Test Set is: 37.82% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:22:59,289]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:23:05,178]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:23:14,608]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:23:18,995]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:23:25,375]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:23:36,263]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:23:52,873]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:04,448]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:04,883]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:17,190]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:22,458]\u001b[0m Trial 419 finished with value: 46.84625112605107 and parameters: {'n_hidden': 4, 'learning_rate': 0.038760493694707174, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08439956462463855, 'dropout_rate_Layer_2': 0.3186793359320953, 'dropout_rate_Layer_3': 0.052274383463178115, 'dropout_rate_Layer_4': 0.12467507733980206, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004159204116563569, 'l1_Layer_2': 7.67246200711126e-05, 'l1_Layer_3': 3.4828241051761376e-05, 'l1_Layer_4': 1.1140017134471119e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90, 'n_units_Layer_4': 270}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.85 | sMAPE for Validation Set is: 32.80% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 51.02 | sMAPE for Test Set is: 99.44% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:24:27,793]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:33,226]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:35,215]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:40,227]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:42,581]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:48,665]\u001b[0m Trial 411 finished with value: 26.62751505635998 and parameters: {'n_hidden': 4, 'learning_rate': 0.006384689024515142, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32565172675161824, 'dropout_rate_Layer_2': 0.2557382118930584, 'dropout_rate_Layer_3': 0.2822081509894928, 'dropout_rate_Layer_4': 0.032721827619196245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000536158092740319, 'l1_Layer_2': 0.009898660384250463, 'l1_Layer_3': 3.555656775639242e-05, 'l1_Layer_4': 2.010521173385265e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 65, 'n_units_Layer_3': 130, 'n_units_Layer_4': 260}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.63 | sMAPE for Validation Set is: 19.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.94 | sMAPE for Test Set is: 37.35% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:24:50,859]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:55,286]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:00,432]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:04,880]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:08,526]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:29,536]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:37,875]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:52,427]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:56,036]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:26:08,875]\u001b[0m Trial 432 finished with value: 24.354921836376366 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009371231362816975, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052322669961186806, 'dropout_rate_Layer_2': 0.21465304153638978, 'dropout_rate_Layer_3': 0.35853936183061624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036740532640614957, 'l1_Layer_2': 2.5998447184427574e-05, 'l1_Layer_3': 0.001798163072301292, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.35 | sMAPE for Validation Set is: 17.94% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.56 | sMAPE for Test Set is: 34.16% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:26:18,767]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:26:29,155]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:26:31,493]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:26:36,397]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:26:52,783]\u001b[0m Trial 410 finished with value: 24.88380352145495 and parameters: {'n_hidden': 4, 'learning_rate': 0.00686900337848489, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1135834028408266, 'dropout_rate_Layer_2': 0.2533230362921544, 'dropout_rate_Layer_3': 0.28544846876587987, 'dropout_rate_Layer_4': 0.014142957717065053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0015374761805235023, 'l1_Layer_2': 2.0671765420682012e-05, 'l1_Layer_3': 3.591649493227139e-05, 'l1_Layer_4': 2.02663488282091e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130, 'n_units_Layer_4': 245}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.88 | sMAPE for Validation Set is: 18.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.56 | sMAPE for Test Set is: 35.58% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:27:01,419]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:27:10,501]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:27:13,388]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:27:17,426]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:27:32,328]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:27:41,513]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:27:45,865]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:28:16,810]\u001b[0m Trial 433 finished with value: 27.678266775406048 and parameters: {'n_hidden': 4, 'learning_rate': 0.006278064744785005, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06809847491502813, 'dropout_rate_Layer_2': 0.2616396830288864, 'dropout_rate_Layer_3': 0.27339959959496674, 'dropout_rate_Layer_4': 0.028100153078873782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00038024440400084695, 'l1_Layer_2': 0.0003336424431022129, 'l1_Layer_3': 5.01113161676271e-05, 'l1_Layer_4': 3.246733145162431e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 75, 'n_units_Layer_3': 135, 'n_units_Layer_4': 245}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.68 | sMAPE for Validation Set is: 19.90% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.37 | sMAPE for Test Set is: 37.54% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:28:20,606]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:28:30,694]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:28:39,805]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:28:49,320]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:28:55,077]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:03,324]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:10,542]\u001b[0m Trial 444 finished with value: 25.044884507310346 and parameters: {'n_hidden': 4, 'learning_rate': 0.0062621424884407575, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19346122794906387, 'dropout_rate_Layer_2': 0.22693695612184345, 'dropout_rate_Layer_3': 0.29861440639918757, 'dropout_rate_Layer_4': 0.040357450561526724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014663184243531645, 'l1_Layer_2': 2.6077409022193707e-05, 'l1_Layer_3': 1.3521773776376778e-05, 'l1_Layer_4': 1.773666233506512e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 85, 'n_units_Layer_3': 155, 'n_units_Layer_4': 245}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.04 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.24 | sMAPE for Test Set is: 35.53% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:29:13,187]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:14,213]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:19,875]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:21,178]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:29,768]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:37,502]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:52,027]\u001b[0m Trial 442 finished with value: 23.95800240755095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008148944730342807, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05036061788346753, 'dropout_rate_Layer_2': 0.21411671915785244, 'dropout_rate_Layer_3': 0.36392719638300786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003473191565926329, 'l1_Layer_2': 1.400363441115285e-05, 'l1_Layer_3': 0.0012693503227807314, 'n_units_Layer_1': 130, 'n_units_Layer_2': 275, 'n_units_Layer_3': 275}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.96 | sMAPE for Validation Set is: 17.71% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.80 | sMAPE for Test Set is: 33.54% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:30:02,081]\u001b[0m Trial 457 finished with value: 24.056687448200957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009717997627271461, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09286191125241461, 'dropout_rate_Layer_2': 0.24913135017600782, 'dropout_rate_Layer_3': 0.2034091358820057, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001961612344029133, 'l1_Layer_2': 0.0008635303052774429, 'l1_Layer_3': 0.0009416758128903694, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.06 | sMAPE for Validation Set is: 17.73% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.51 | sMAPE for Test Set is: 33.92% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:30:11,742]\u001b[0m Trial 462 finished with value: 24.60182469015126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009169358109616081, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0971828945845635, 'dropout_rate_Layer_2': 0.37917411474213036, 'dropout_rate_Layer_3': 0.20301814418963893, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002347089423941339, 'l1_Layer_2': 0.0009007491816285034, 'l1_Layer_3': 0.0037107320369536875, 'n_units_Layer_1': 125, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.60 | sMAPE for Validation Set is: 18.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.77 | sMAPE for Test Set is: 35.85% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:30:24,961]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:30:30,937]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:31:09,811]\u001b[0m Trial 463 finished with value: 24.123379310025474 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006951202857244544, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09553669351094052, 'dropout_rate_Layer_2': 0.3602409733750117, 'dropout_rate_Layer_3': 0.09885057543779258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002142083645730001, 'l1_Layer_2': 0.00048542596513865475, 'l1_Layer_3': 0.0008682917581550514, 'n_units_Layer_1': 125, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.12 | sMAPE for Validation Set is: 17.81% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.17 | sMAPE for Test Set is: 33.95% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:31:13,074]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:31:27,769]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:31:28,282]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:31:31,369]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:31:37,130]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:31:37,397]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:31:47,020]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:31:51,910]\u001b[0m Trial 473 finished with value: 29.978358689784113 and parameters: {'n_hidden': 4, 'learning_rate': 0.005910772713964414, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2794326732241965, 'dropout_rate_Layer_2': 0.04778968492568125, 'dropout_rate_Layer_3': 0.3713017802384574, 'dropout_rate_Layer_4': 0.0482146434645641, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.494976892731256e-05, 'l1_Layer_2': 0.0002519274947241057, 'l1_Layer_3': 0.0015854534900015835, 'l1_Layer_4': 3.1428009333158444e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260, 'n_units_Layer_4': 125}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.98 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 23.73 | sMAPE for Test Set is: 38.09% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:32:02,851]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:32:08,148]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:32:14,392]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:32:16,677]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:32:23,754]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:32:26,929]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:32:30,836]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:32:39,387]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:32:44,051]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:33:02,035]\u001b[0m Trial 476 finished with value: 24.094873930807307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005692186511199781, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09689607282100446, 'dropout_rate_Layer_2': 0.2010325025648313, 'dropout_rate_Layer_3': 0.3749972635307388, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022180282153568958, 'l1_Layer_2': 0.0006676987706576693, 'l1_Layer_3': 0.001242989719388955, 'n_units_Layer_1': 135, 'n_units_Layer_2': 295, 'n_units_Layer_3': 265}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.09 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.19 | sMAPE for Test Set is: 35.00% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:33:07,822]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:33:09,991]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:33:15,262]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:33:17,798]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:33:31,328]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:33:32,806]\u001b[0m Trial 475 finished with value: 24.260522671435552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009053975088316652, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0940178869837689, 'dropout_rate_Layer_2': 0.3804432592510748, 'dropout_rate_Layer_3': 0.2233341361452014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001825785481881159, 'l1_Layer_2': 0.0006428031778182492, 'l1_Layer_3': 0.004058349747194968, 'n_units_Layer_1': 125, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.26 | sMAPE for Validation Set is: 17.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.27 | sMAPE for Test Set is: 34.20% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:33:34,508]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:33:39,934]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:33:51,267]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:33:53,763]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:33:55,623]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:33:58,725]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:34:04,174]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:34:07,238]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:34:12,832]\u001b[0m Trial 496 finished with value: 30.86934034918495 and parameters: {'n_hidden': 4, 'learning_rate': 0.006102745257332413, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2272120175779912, 'dropout_rate_Layer_2': 0.3624547060999785, 'dropout_rate_Layer_3': 0.3464001309037553, 'dropout_rate_Layer_4': 0.21791087469436338, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001218818359218807, 'l1_Layer_2': 0.0006674611291588677, 'l1_Layer_3': 0.0003363683448429611, 'l1_Layer_4': 0.03490789777190902, 'n_units_Layer_1': 235, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280, 'n_units_Layer_4': 90}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.87 | sMAPE for Validation Set is: 21.35% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 23.17 | sMAPE for Test Set is: 36.94% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:34:13,333]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:34:21,732]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:34:33,377]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:34:48,741]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:34:51,116]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:34:54,055]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:35:03,935]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:35:10,314]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:35:21,490]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:35:30,217]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:35:35,154]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:35:40,009]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:35:49,436]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:35:55,723]\u001b[0m Trial 507 finished with value: 25.14569526860612 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008616055666078765, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3688730784143259, 'dropout_rate_Layer_2': 0.0668698892439264, 'dropout_rate_Layer_3': 0.15546274684796305, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010809653682592928, 'l1_Layer_2': 0.01341051219017692, 'l1_Layer_3': 0.0063579232861320735, 'n_units_Layer_1': 115, 'n_units_Layer_2': 160, 'n_units_Layer_3': 195}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.15 | sMAPE for Validation Set is: 18.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.46 | sMAPE for Test Set is: 35.66% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:36:00,719]\u001b[0m Trial 505 finished with value: 28.859796882776788 and parameters: {'n_hidden': 4, 'learning_rate': 0.006976900710581471, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08933415985910939, 'dropout_rate_Layer_2': 0.23871086550198461, 'dropout_rate_Layer_3': 0.26379574203156886, 'dropout_rate_Layer_4': 0.022308766656440212, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004015917468847484, 'l1_Layer_2': 0.03970017664679369, 'l1_Layer_3': 1.9760211423804998e-05, 'l1_Layer_4': 1.686234124278919e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 60, 'n_units_Layer_3': 160, 'n_units_Layer_4': 260}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.86 | sMAPE for Validation Set is: 20.76% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 23.88 | sMAPE for Test Set is: 38.41% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:36:03,416]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:36:08,907]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:36:12,514]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:36:22,091]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:36:25,701]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:36:30,575]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:36:31,869]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:36:37,533]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:36:42,789]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:36:57,096]\u001b[0m Trial 513 finished with value: 30.086769576632108 and parameters: {'n_hidden': 4, 'learning_rate': 0.009525633374579382, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22840042209042785, 'dropout_rate_Layer_2': 0.228843387184131, 'dropout_rate_Layer_3': 0.23052876814723594, 'dropout_rate_Layer_4': 0.0011847992707305008, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01511591304896624, 'l1_Layer_2': 0.041476002000513434, 'l1_Layer_3': 8.961845226393132e-05, 'l1_Layer_4': 0.0008882682911991892, 'n_units_Layer_1': 110, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170, 'n_units_Layer_4': 60}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.09 | sMAPE for Validation Set is: 20.99% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 24.54 | sMAPE for Test Set is: 39.93% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:37:05,997]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:37:10,114]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:37:14,163]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:37:23,743]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:37:31,074]\u001b[0m Trial 524 finished with value: 24.38303386697001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006685847182240482, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09704442894100729, 'dropout_rate_Layer_2': 0.2502735777570224, 'dropout_rate_Layer_3': 0.32677930946080086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041969419846899327, 'l1_Layer_2': 0.0010245697692754477, 'l1_Layer_3': 0.0003815187313006043, 'n_units_Layer_1': 110, 'n_units_Layer_2': 270, 'n_units_Layer_3': 270}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.38 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.46 | sMAPE for Test Set is: 34.64% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:37:32,433]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:37:39,331]\u001b[0m Trial 523 finished with value: 24.13728084788684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006590241974417479, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02860636782877671, 'dropout_rate_Layer_2': 0.19128408709414604, 'dropout_rate_Layer_3': 0.3264104730266368, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.989510104172191e-05, 'l1_Layer_2': 0.00023673288022651453, 'l1_Layer_3': 0.00042388256998030015, 'n_units_Layer_1': 105, 'n_units_Layer_2': 285, 'n_units_Layer_3': 265}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.14 | sMAPE for Validation Set is: 17.88% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.54 | sMAPE for Test Set is: 34.29% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:37:56,109]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:10,114]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:10,289]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:23,737]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:29,650]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:35,826]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:46,062]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:48,049]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:53,083]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:53,473]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:55,035]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:01,100]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:03,328]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:04,405]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:08,285]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:12,936]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:16,153]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:17,844]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:22,387]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:22,647]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:23,472]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:33,417]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:37,534]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:38,113]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:38,280]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:39:52,070]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:00,410]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:07,725]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:30,352]\u001b[0m Trial 562 finished with value: 24.782446188775747 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005168922719460095, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008123987335446914, 'dropout_rate_Layer_2': 0.18010631646829123, 'dropout_rate_Layer_3': 0.33288961618486945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005576113007226707, 'l1_Layer_2': 0.00045350261809431113, 'l1_Layer_3': 1.3067313026323133e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 275, 'n_units_Layer_3': 270}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.78 | sMAPE for Validation Set is: 18.38% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.06 | sMAPE for Test Set is: 35.23% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:40:36,862]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:37,247]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:39,371]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:46,032]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:50,003]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:50,528]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:56,836]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:00,752]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:10,004]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:17,822]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:27,272]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:33,897]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:34,691]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:35,951]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:46,709]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:47,727]\u001b[0m Trial 574 finished with value: 25.30297836837822 and parameters: {'n_hidden': 4, 'learning_rate': 0.003779103970723529, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2761476893522531, 'dropout_rate_Layer_2': 0.0011838524956758996, 'dropout_rate_Layer_3': 0.29245187709653025, 'dropout_rate_Layer_4': 0.1150520067130273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001075266058604299, 'l1_Layer_2': 0.0018766181177281625, 'l1_Layer_3': 0.0005310691934267446, 'l1_Layer_4': 0.00020701262387731926, 'n_units_Layer_1': 165, 'n_units_Layer_2': 95, 'n_units_Layer_3': 65, 'n_units_Layer_4': 260}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.30 | sMAPE for Validation Set is: 18.70% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.43 | sMAPE for Test Set is: 36.09% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:41:58,798]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:01,577]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:06,031]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:13,038]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:44,941]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:46,527]\u001b[0m Trial 578 finished with value: 23.72904515894994 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006121356203201177, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018469371675616443, 'dropout_rate_Layer_2': 0.1803947369667861, 'dropout_rate_Layer_3': 0.33090705386920666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002210255808405965, 'l1_Layer_2': 0.00032655806674275375, 'l1_Layer_3': 1.3018555426256945e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.73 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 34.14% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:42:59,661]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:01,900]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:06,601]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:07,025]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:16,694]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:25,732]\u001b[0m Trial 589 finished with value: 25.957377695699865 and parameters: {'n_hidden': 4, 'learning_rate': 0.009924162767809809, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2826303538144798, 'dropout_rate_Layer_2': 0.007499704407220032, 'dropout_rate_Layer_3': 0.36656300713562884, 'dropout_rate_Layer_4': 0.16070904741595882, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005336451470515189, 'l1_Layer_2': 2.424287474434593e-05, 'l1_Layer_3': 0.0017790573294900263, 'l1_Layer_4': 2.23732921804018e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 125, 'n_units_Layer_3': 75, 'n_units_Layer_4': 215}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.96 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.78 | sMAPE for Test Set is: 36.55% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:43:31,644]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:35,199]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:39,322]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:41,577]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:43,772]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:44,671]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:46,366]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:54,285]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:57,267]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:44:19,832]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:44:21,787]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:44:27,964]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:44:44,459]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:45:01,237]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:45:17,800]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:45:27,115]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:45:30,006]\u001b[0m Trial 599 finished with value: 27.803045058703287 and parameters: {'n_hidden': 4, 'learning_rate': 0.009270052674439224, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1806127039296354, 'dropout_rate_Layer_2': 0.2463513791638213, 'dropout_rate_Layer_3': 0.29087644228091764, 'dropout_rate_Layer_4': 0.048806262701624456, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.86979819446586e-05, 'l1_Layer_2': 0.012413437200132405, 'l1_Layer_3': 0.00016245834804158162, 'l1_Layer_4': 0.0010528188651442786, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185, 'n_units_Layer_4': 290}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.80 | sMAPE for Validation Set is: 20.35% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 24.51 | sMAPE for Test Set is: 38.81% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:45:34,994]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:45:37,449]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:45:40,078]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:45:50,620]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:45:54,849]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:46:04,055]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:46:32,077]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:47:12,519]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:47:27,819]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:47:33,132]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:47:33,515]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:47:43,461]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:47:43,496]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:47:53,233]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:47:57,213]\u001b[0m Trial 620 finished with value: 26.574829552599834 and parameters: {'n_hidden': 4, 'learning_rate': 0.00975005422409039, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25783604821493344, 'dropout_rate_Layer_2': 0.0016109530269146064, 'dropout_rate_Layer_3': 0.22583926279556613, 'dropout_rate_Layer_4': 0.1729721602153384, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006197348791564098, 'l1_Layer_2': 2.2741740855391383e-05, 'l1_Layer_3': 0.00019997583710429977, 'l1_Layer_4': 0.016259957237552414, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 75, 'n_units_Layer_4': 210}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.57 | sMAPE for Validation Set is: 19.62% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 24.84 | sMAPE for Test Set is: 41.32% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:48:09,159]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:48:14,173]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:48:16,910]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:48:27,956]\u001b[0m Trial 624 finished with value: 25.899406746850115 and parameters: {'n_hidden': 4, 'learning_rate': 0.01091285431109328, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2575114857941098, 'dropout_rate_Layer_2': 0.030856034149773625, 'dropout_rate_Layer_3': 0.23214214276117084, 'dropout_rate_Layer_4': 0.14356634767387164, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006471685813876028, 'l1_Layer_2': 2.087077511995959e-05, 'l1_Layer_3': 0.00019493593267247119, 'l1_Layer_4': 0.02156656055944832, 'n_units_Layer_1': 65, 'n_units_Layer_2': 115, 'n_units_Layer_3': 75, 'n_units_Layer_4': 210}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.90 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.32 | sMAPE for Test Set is: 36.95% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:48:35,313]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:48:43,859]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:48:53,696]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:49:05,772]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:49:12,028]\u001b[0m Trial 610 finished with value: 27.312777875530873 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015793871904404891, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18471124494225383, 'dropout_rate_Layer_2': 0.24367038115226886, 'dropout_rate_Layer_3': 0.18627064288114847, 'dropout_rate_Layer_4': 0.05943651662059464, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011006073034208028, 'l1_Layer_2': 0.012662837784300432, 'l1_Layer_3': 0.00014996084390054643, 'l1_Layer_4': 0.0012152517157961308, 'n_units_Layer_1': 120, 'n_units_Layer_2': 65, 'n_units_Layer_3': 185, 'n_units_Layer_4': 295}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.31 | sMAPE for Validation Set is: 19.88% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.02 | sMAPE for Test Set is: 38.66% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:49:15,968]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:49:17,175]\u001b[0m Trial 628 finished with value: 24.101461688539285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007775169027746601, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04066065406139716, 'dropout_rate_Layer_2': 0.19969057924896816, 'dropout_rate_Layer_3': 0.3367712753882515, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008568666310176786, 'l1_Layer_2': 0.0007405546667628126, 'l1_Layer_3': 1.5959997129374028e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.10 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.87 | sMAPE for Test Set is: 33.84% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:49:24,249]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:49:26,142]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:49:33,482]\u001b[0m Trial 635 finished with value: 27.12855363615842 and parameters: {'n_hidden': 4, 'learning_rate': 0.013730564015167243, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29495445735870934, 'dropout_rate_Layer_2': 0.03410755361007333, 'dropout_rate_Layer_3': 0.22640781765515272, 'dropout_rate_Layer_4': 0.14593002167034713, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002306542499925933, 'l1_Layer_2': 2.120016983699728e-05, 'l1_Layer_3': 0.00021037570096784573, 'l1_Layer_4': 0.018927075641365834, 'n_units_Layer_1': 65, 'n_units_Layer_2': 65, 'n_units_Layer_3': 70, 'n_units_Layer_4': 205}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.13 | sMAPE for Validation Set is: 19.96% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.39 | sMAPE for Test Set is: 38.43% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:49:41,692]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:49:42,153]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:49:52,328]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:50:01,989]\u001b[0m Trial 632 finished with value: 24.654686236137337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036485773248915955, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24091021525804268, 'dropout_rate_Layer_2': 0.0593729547729523, 'dropout_rate_Layer_3': 0.14969223622841257, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010501253430275467, 'l1_Layer_2': 0.00929810520977311, 'l1_Layer_3': 0.006391840530278031, 'n_units_Layer_1': 100, 'n_units_Layer_2': 130, 'n_units_Layer_3': 90}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.65 | sMAPE for Validation Set is: 18.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.97 | sMAPE for Test Set is: 35.12% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:50:11,521]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:50:20,410]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:50:20,911]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:50:26,915]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:50:31,239]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:51:18,588]\u001b[0m Trial 641 finished with value: 28.116693405891922 and parameters: {'n_hidden': 4, 'learning_rate': 0.022912223776906993, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20047065174441164, 'dropout_rate_Layer_2': 0.22262403948029563, 'dropout_rate_Layer_3': 0.28123604430901256, 'dropout_rate_Layer_4': 0.027034326022075544, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.4709482833315393e-05, 'l1_Layer_2': 0.00963752465610013, 'l1_Layer_3': 0.00017588010884729197, 'l1_Layer_4': 1.6553932559441425e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190, 'n_units_Layer_4': 295}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.12 | sMAPE for Validation Set is: 20.41% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 24.14 | sMAPE for Test Set is: 38.55% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:51:20,642]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:51:25,536]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:51:25,819]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:51:33,426]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:51:39,118]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:52:02,031]\u001b[0m Trial 645 finished with value: 25.68774257533377 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009104910590100557, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1918764158376001, 'dropout_rate_Layer_2': 0.21153905113241844, 'dropout_rate_Layer_3': 0.2828901425196275, 'dropout_rate_Layer_4': 0.06239593065237845, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.257476500474432e-05, 'l1_Layer_2': 0.017479440932680675, 'l1_Layer_3': 0.00018942359666038384, 'l1_Layer_4': 0.0009418241531946778, 'n_units_Layer_1': 170, 'n_units_Layer_2': 65, 'n_units_Layer_3': 190, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.69 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.13 | sMAPE for Test Set is: 37.26% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:52:11,060]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:52:14,964]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:52:18,539]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:52:26,829]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:52:33,875]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:52:38,403]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:52:46,251]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:52:51,952]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:52:52,416]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:52:59,315]\u001b[0m Trial 643 finished with value: 25.232677401222105 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009196924533938043, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20113562485750236, 'dropout_rate_Layer_2': 0.21810335870631625, 'dropout_rate_Layer_3': 0.2816254878518252, 'dropout_rate_Layer_4': 0.07103453717893489, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.7382355939741286e-05, 'l1_Layer_2': 0.018414439431812958, 'l1_Layer_3': 0.00019046716030238816, 'l1_Layer_4': 0.0015884262410637013, 'n_units_Layer_1': 290, 'n_units_Layer_2': 65, 'n_units_Layer_3': 190, 'n_units_Layer_4': 295}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.23 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.45 | sMAPE for Test Set is: 36.08% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:53:11,114]\u001b[0m Trial 657 finished with value: 23.95049447820146 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005477964921396144, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027990628309231158, 'dropout_rate_Layer_2': 0.2536712003899636, 'dropout_rate_Layer_3': 0.33433710296249053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005665746658741032, 'l1_Layer_2': 0.0002560198041174031, 'l1_Layer_3': 1.06305758048552e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 270, 'n_units_Layer_3': 255}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.95 | sMAPE for Validation Set is: 17.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.92 | sMAPE for Test Set is: 33.80% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:53:13,253]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:53:21,484]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:53:23,601]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:53:39,126]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:53:41,196]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:53:44,391]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:53:47,618]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:53:48,341]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:53:54,622]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:53:59,347]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:54:03,159]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:54:10,240]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:54:17,852]\u001b[0m Trial 663 finished with value: 23.736483152017996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006516277729862282, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025766614040832757, 'dropout_rate_Layer_2': 0.19664987743252538, 'dropout_rate_Layer_3': 0.31176876557008737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004165014582987891, 'l1_Layer_2': 0.000319813331609944, 'l1_Layer_3': 0.0007486210524137417, 'n_units_Layer_1': 105, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.74 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.63 | sMAPE for Test Set is: 34.25% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:54:22,111]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:54:34,471]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:54:43,112]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:54:43,241]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:54:52,976]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:55:31,858]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:55:43,002]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:56:26,327]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:56:51,062]\u001b[0m Trial 682 finished with value: 25.40257050976407 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006269715596106681, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17781165033613838, 'dropout_rate_Layer_2': 0.2216709712561385, 'dropout_rate_Layer_3': 0.28430900525140124, 'dropout_rate_Layer_4': 0.07405739576104714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.198196144921255e-05, 'l1_Layer_2': 0.022474397996879, 'l1_Layer_3': 0.0001271882997093637, 'l1_Layer_4': 0.0015232694449436174, 'n_units_Layer_1': 285, 'n_units_Layer_2': 55, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.40 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.53 | sMAPE for Test Set is: 36.24% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:56:58,701]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:57:29,592]\u001b[0m Trial 678 finished with value: 25.589829182851247 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005079062666678659, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1949938636272157, 'dropout_rate_Layer_2': 0.22371289804733233, 'dropout_rate_Layer_3': 0.285239773928564, 'dropout_rate_Layer_4': 0.07153525800122604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.8010427115962394e-05, 'l1_Layer_2': 0.021705288712461242, 'l1_Layer_3': 0.0001211342977584759, 'l1_Layer_4': 0.0016153346301417543, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 290, 'n_units_Layer_4': 285}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.59 | sMAPE for Validation Set is: 18.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.44 | sMAPE for Test Set is: 35.88% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:57:47,755]\u001b[0m Trial 688 finished with value: 29.976313081009646 and parameters: {'n_hidden': 4, 'learning_rate': 0.011515795719817016, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3087640816144568, 'dropout_rate_Layer_2': 0.04160687979148059, 'dropout_rate_Layer_3': 0.26194330502043456, 'dropout_rate_Layer_4': 0.09939404136477012, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0006308399393306322, 'l1_Layer_2': 0.008523679021471537, 'l1_Layer_3': 0.0006736576108377565, 'l1_Layer_4': 0.05599784191931824, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 100, 'n_units_Layer_4': 200}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.98 | sMAPE for Validation Set is: 21.09% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 25.49 | sMAPE for Test Set is: 42.32% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:58:08,570]\u001b[0m Trial 687 finished with value: 25.415110161610823 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006646476933980626, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17864338644516764, 'dropout_rate_Layer_2': 0.2231353086916297, 'dropout_rate_Layer_3': 0.30438703349874574, 'dropout_rate_Layer_4': 0.08713701743456306, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.5728310216434375e-05, 'l1_Layer_2': 0.024601779620528515, 'l1_Layer_3': 0.00012287587548805094, 'l1_Layer_4': 0.0018787797901623055, 'n_units_Layer_1': 280, 'n_units_Layer_2': 50, 'n_units_Layer_3': 290, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.42 | sMAPE for Validation Set is: 18.74% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.42 | sMAPE for Test Set is: 36.11% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:58:15,265]\u001b[0m Trial 686 finished with value: 25.438551504545373 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005185353295297187, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16791332172995976, 'dropout_rate_Layer_2': 0.2249680364485207, 'dropout_rate_Layer_3': 0.30496624475370127, 'dropout_rate_Layer_4': 0.08827071350469626, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.756027204859091e-05, 'l1_Layer_2': 0.02625083128284883, 'l1_Layer_3': 0.00013687586761787932, 'l1_Layer_4': 0.0015330897548765513, 'n_units_Layer_1': 295, 'n_units_Layer_2': 55, 'n_units_Layer_3': 280, 'n_units_Layer_4': 285}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.44 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.66 | sMAPE for Test Set is: 36.22% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:58:15,741]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:58:28,773]\u001b[0m Trial 692 finished with value: 27.49375137056496 and parameters: {'n_hidden': 4, 'learning_rate': 0.02808477946077726, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2563321440832371, 'dropout_rate_Layer_2': 0.021330295858972437, 'dropout_rate_Layer_3': 0.23040207127162926, 'dropout_rate_Layer_4': 0.06413823257113566, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002216956271011797, 'l1_Layer_2': 1.0366628793075197e-05, 'l1_Layer_3': 0.001225386859558837, 'l1_Layer_4': 0.0006140606723265515, 'n_units_Layer_1': 275, 'n_units_Layer_2': 65, 'n_units_Layer_3': 115, 'n_units_Layer_4': 215}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.49 | sMAPE for Validation Set is: 19.99% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.41 | sMAPE for Test Set is: 39.84% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:58:37,752]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:58:41,033]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:58:42,286]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:58:57,257]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:59:01,089]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:59:08,515]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:59:13,760]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:59:18,525]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:59:29,193]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:59:33,599]\u001b[0m Trial 697 finished with value: 25.820593784312745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0042712352884197715, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3714817812223856, 'dropout_rate_Layer_2': 0.10241190069303045, 'dropout_rate_Layer_3': 0.1329985246776938, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.721018449881072e-05, 'l1_Layer_2': 0.004463726279925865, 'l1_Layer_3': 0.022443306955157713, 'n_units_Layer_1': 75, 'n_units_Layer_2': 160, 'n_units_Layer_3': 90}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.82 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.79 | sMAPE for Test Set is: 36.79% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:59:45,664]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:59:53,676]\u001b[0m Trial 695 finished with value: 25.71878555135798 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005405031995071502, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16884064194652812, 'dropout_rate_Layer_2': 0.1789930046437229, 'dropout_rate_Layer_3': 0.30994530287998645, 'dropout_rate_Layer_4': 0.08431859064075306, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.264347151998374e-05, 'l1_Layer_2': 0.02769595137045063, 'l1_Layer_3': 0.00012342302191584119, 'l1_Layer_4': 0.0015730280761901937, 'n_units_Layer_1': 280, 'n_units_Layer_2': 50, 'n_units_Layer_3': 295, 'n_units_Layer_4': 285}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.72 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.13 | sMAPE for Test Set is: 37.00% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:00:09,486]\u001b[0m Trial 705 finished with value: 25.997690437048732 and parameters: {'n_hidden': 4, 'learning_rate': 0.013489309486826757, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2893273931235397, 'dropout_rate_Layer_2': 0.035059569514255214, 'dropout_rate_Layer_3': 0.2366665094285676, 'dropout_rate_Layer_4': 0.14657866388515747, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00018978781786335545, 'l1_Layer_2': 2.0548435881175714e-05, 'l1_Layer_3': 0.00019671247411451006, 'l1_Layer_4': 0.01620492554980766, 'n_units_Layer_1': 70, 'n_units_Layer_2': 60, 'n_units_Layer_3': 70, 'n_units_Layer_4': 200}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.00 | sMAPE for Validation Set is: 19.13% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.28 | sMAPE for Test Set is: 37.11% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:00:21,546]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:00:27,733]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:00:38,044]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:00:39,959]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:00:51,711]\u001b[0m Trial 709 finished with value: 26.790384226600107 and parameters: {'n_hidden': 4, 'learning_rate': 0.01737178956180005, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28184415163499543, 'dropout_rate_Layer_2': 0.0014283664276407704, 'dropout_rate_Layer_3': 0.24180007711895574, 'dropout_rate_Layer_4': 0.13486499950314101, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000347019700294984, 'l1_Layer_2': 5.391014935899831e-05, 'l1_Layer_3': 0.00014535175273138883, 'l1_Layer_4': 0.011809234323030273, 'n_units_Layer_1': 80, 'n_units_Layer_2': 55, 'n_units_Layer_3': 70, 'n_units_Layer_4': 190}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.79 | sMAPE for Validation Set is: 19.65% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.93 | sMAPE for Test Set is: 37.51% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:01:10,831]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:01:32,684]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:01:36,579]\u001b[0m Trial 704 finished with value: 25.627680757329898 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005506898707547047, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1711629364261245, 'dropout_rate_Layer_2': 0.21851886878475293, 'dropout_rate_Layer_3': 0.3068605510304759, 'dropout_rate_Layer_4': 0.08631954341422009, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.802493506081586e-05, 'l1_Layer_2': 0.028275870782311665, 'l1_Layer_3': 0.00010855574162939053, 'l1_Layer_4': 0.002315067490872629, 'n_units_Layer_1': 280, 'n_units_Layer_2': 50, 'n_units_Layer_3': 295, 'n_units_Layer_4': 285}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.63 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.80 | sMAPE for Test Set is: 36.22% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:01:47,814]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:01:56,587]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:02:21,647]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:02:23,520]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:02:26,363]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:02:37,676]\u001b[0m Trial 714 finished with value: 25.32819812960687 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006209549585141375, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17670193759907812, 'dropout_rate_Layer_2': 0.20613808588210886, 'dropout_rate_Layer_3': 0.3228921338625855, 'dropout_rate_Layer_4': 0.09168259578437273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.2073599137399634e-05, 'l1_Layer_2': 0.028858693917193506, 'l1_Layer_3': 0.00011368939774430924, 'l1_Layer_4': 0.0024852443842416777, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 300, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.33 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.65 | sMAPE for Test Set is: 36.53% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:02:44,023]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:02:48,220]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:03:12,043]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:03:14,637]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:03:14,767]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:03:24,868]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:03:25,338]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:03:29,578]\u001b[0m Trial 721 finished with value: 25.520421897481498 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005511965401476398, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16028158764523665, 'dropout_rate_Layer_2': 0.20945271125510248, 'dropout_rate_Layer_3': 0.32123566369745205, 'dropout_rate_Layer_4': 0.08331865939429985, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.468807935910715e-05, 'l1_Layer_2': 0.022418706921256432, 'l1_Layer_3': 0.00015420932043994692, 'l1_Layer_4': 0.00196232781066603, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 300, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.52 | sMAPE for Validation Set is: 18.90% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.94 | sMAPE for Test Set is: 36.87% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:04:03,526]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:04:10,487]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:04:14,105]\u001b[0m Trial 728 finished with value: 26.084921205705328 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005278371380338971, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26347918272136617, 'dropout_rate_Layer_2': 0.07483508562152438, 'dropout_rate_Layer_3': 0.19032827060832394, 'dropout_rate_Layer_4': 0.15985045173602497, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.341745031748713e-05, 'l1_Layer_2': 2.7274161903181552e-05, 'l1_Layer_3': 7.757547255782275e-05, 'l1_Layer_4': 0.0283318690822271, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 60, 'n_units_Layer_4': 170}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.08 | sMAPE for Validation Set is: 19.22% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.29 | sMAPE for Test Set is: 36.71% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:04:26,745]\u001b[0m Trial 730 finished with value: 26.142042629581145 and parameters: {'n_hidden': 4, 'learning_rate': 0.004340257626665763, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23085136367508455, 'dropout_rate_Layer_2': 0.07143380543540433, 'dropout_rate_Layer_3': 0.19458036345543278, 'dropout_rate_Layer_4': 0.20082115462151254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000170825879639811, 'l1_Layer_2': 2.9947924228869645e-05, 'l1_Layer_3': 7.736629455641161e-05, 'l1_Layer_4': 0.03056178737334005, 'n_units_Layer_1': 100, 'n_units_Layer_2': 70, 'n_units_Layer_3': 60, 'n_units_Layer_4': 235}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.14 | sMAPE for Validation Set is: 19.30% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.80 | sMAPE for Test Set is: 37.53% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:04:33,215]\u001b[0m Trial 726 finished with value: 25.878183064829262 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007134975806474384, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17776007110794245, 'dropout_rate_Layer_2': 0.20698077517033256, 'dropout_rate_Layer_3': 0.32563569845179735, 'dropout_rate_Layer_4': 0.08411425417024719, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.188078711946924e-05, 'l1_Layer_2': 0.03452749817286031, 'l1_Layer_3': 0.0001016253502051218, 'l1_Layer_4': 0.002053433064682771, 'n_units_Layer_1': 275, 'n_units_Layer_2': 50, 'n_units_Layer_3': 290, 'n_units_Layer_4': 295}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.88 | sMAPE for Validation Set is: 19.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.22 | sMAPE for Test Set is: 36.87% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:04:38,181]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:04:55,819]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:05:03,905]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:05:15,641]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:05:20,826]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:05:27,724]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:05:35,859]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:05:41,789]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:06:05,008]\u001b[0m Trial 734 finished with value: 25.212031912581654 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007109664288831199, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18789537242349566, 'dropout_rate_Layer_2': 0.19985527185304083, 'dropout_rate_Layer_3': 0.32812867676346763, 'dropout_rate_Layer_4': 0.07976504067403094, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.4043262831871074e-05, 'l1_Layer_2': 0.03526369721182087, 'l1_Layer_3': 0.0001587551635044027, 'l1_Layer_4': 0.0016211982883960494, 'n_units_Layer_1': 300, 'n_units_Layer_2': 60, 'n_units_Layer_3': 285, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.21 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.54 | sMAPE for Test Set is: 35.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:06:12,580]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:06:21,446]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:06:23,665]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:06:39,598]\u001b[0m Trial 741 finished with value: 23.546384835630324 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005396524126607071, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0083201078226334, 'dropout_rate_Layer_2': 0.18767950593310667, 'dropout_rate_Layer_3': 0.3324053979266622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005089751151203972, 'l1_Layer_2': 0.0004588815299193455, 'l1_Layer_3': 1.3731037220705618e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.55 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 19.95 | sMAPE for Test Set is: 33.84% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:06:40,588]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:06:45,210]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:06:50,116]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:06:54,370]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:06:58,053]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:07:12,433]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:07:20,153]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:07:44,806]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:08:00,138]\u001b[0m Trial 751 finished with value: 25.453171380701676 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006164033962983299, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19270111961861225, 'dropout_rate_Layer_2': 0.19247856285722736, 'dropout_rate_Layer_3': 0.3299711112023549, 'dropout_rate_Layer_4': 0.07445154973271131, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.592860628036537e-05, 'l1_Layer_2': 3.2375566514351165e-05, 'l1_Layer_3': 0.0002103385103088085, 'l1_Layer_4': 0.0013150980292707304, 'n_units_Layer_1': 275, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300, 'n_units_Layer_4': 290}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.45 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.35 | sMAPE for Test Set is: 36.26% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:08:04,736]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:08:11,286]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:08:29,357]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:08:33,214]\u001b[0m Trial 750 finished with value: 25.683441157802747 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006147582097680714, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1929421624348629, 'dropout_rate_Layer_2': 0.19147843376421664, 'dropout_rate_Layer_3': 0.33148997139536684, 'dropout_rate_Layer_4': 0.35736089880721345, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.8454135519961376e-05, 'l1_Layer_2': 0.034864405990636574, 'l1_Layer_3': 0.00021204666345490117, 'l1_Layer_4': 0.0022955860713614836, 'n_units_Layer_1': 275, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300, 'n_units_Layer_4': 290}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.68 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.66 | sMAPE for Test Set is: 36.33% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:08:40,321]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:08:48,007]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:08:50,944]\u001b[0m Trial 752 finished with value: 25.55965689382961 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006076857577544333, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19177394053052757, 'dropout_rate_Layer_2': 0.19312037854861813, 'dropout_rate_Layer_3': 0.3046059214875575, 'dropout_rate_Layer_4': 0.3658599256479118, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.939882721035938e-05, 'l1_Layer_2': 0.03669669853969251, 'l1_Layer_3': 0.00022203722569037604, 'l1_Layer_4': 0.0013884583890410912, 'n_units_Layer_1': 275, 'n_units_Layer_2': 60, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.56 | sMAPE for Validation Set is: 18.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.74 | sMAPE for Test Set is: 36.60% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:08:57,881]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:09:06,348]\u001b[0m Trial 757 finished with value: 25.124356157442264 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005048151064073465, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19327693458896433, 'dropout_rate_Layer_2': 0.19478079579448504, 'dropout_rate_Layer_3': 0.3023230928615042, 'dropout_rate_Layer_4': 0.06960841356225707, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.011805701494219e-05, 'l1_Layer_2': 2.0005999753454562e-05, 'l1_Layer_3': 0.00021752315649201115, 'l1_Layer_4': 0.0013514066536216755, 'n_units_Layer_1': 265, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300, 'n_units_Layer_4': 290}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.12 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.20 | sMAPE for Test Set is: 35.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:09:40,913]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:09:50,184]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:10:08,518]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:10:17,493]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:10:29,667]\u001b[0m Trial 761 finished with value: 25.336246494043696 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005969824865281609, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19767820860850907, 'dropout_rate_Layer_2': 0.19881535312023146, 'dropout_rate_Layer_3': 0.3341670176844004, 'dropout_rate_Layer_4': 0.07122617612856164, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.745143602041307e-05, 'l1_Layer_2': 0.03632763948799706, 'l1_Layer_3': 0.00019638367579569128, 'l1_Layer_4': 0.001324237964427785, 'n_units_Layer_1': 275, 'n_units_Layer_2': 150, 'n_units_Layer_3': 295, 'n_units_Layer_4': 290}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.34 | sMAPE for Validation Set is: 18.74% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.49 | sMAPE for Test Set is: 36.11% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:10:57,944]\u001b[0m Trial 766 finished with value: 26.001996460103012 and parameters: {'n_hidden': 4, 'learning_rate': 0.002947627255869616, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2650556371708233, 'dropout_rate_Layer_2': 0.09129725971376543, 'dropout_rate_Layer_3': 0.2410933458333132, 'dropout_rate_Layer_4': 0.15960741132053274, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001716071767744528, 'l1_Layer_2': 2.61959714585673e-05, 'l1_Layer_3': 4.685496475030898e-05, 'l1_Layer_4': 0.05311980150577378, 'n_units_Layer_1': 120, 'n_units_Layer_2': 55, 'n_units_Layer_3': 70, 'n_units_Layer_4': 150}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.00 | sMAPE for Validation Set is: 19.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.48 | sMAPE for Test Set is: 37.06% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:10:58,900]\u001b[0m Trial 767 finished with value: 25.377955825666252 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005513650359141135, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18447768491458894, 'dropout_rate_Layer_2': 0.1878416679444675, 'dropout_rate_Layer_3': 0.32148672992942684, 'dropout_rate_Layer_4': 0.06679105384938425, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.104893395735384e-05, 'l1_Layer_2': 2.1089801405904834e-05, 'l1_Layer_3': 0.0002708806082083626, 'l1_Layer_4': 0.0012868216928333153, 'n_units_Layer_1': 275, 'n_units_Layer_2': 50, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.38 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.54 | sMAPE for Test Set is: 36.12% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:11:04,750]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:11:26,404]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:11:29,754]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:11:36,048]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:11:55,856]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:12:04,207]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:12:14,952]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:12:25,788]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:12:33,826]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:12:34,681]\u001b[0m Trial 769 finished with value: 26.024120142118004 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008724883136613436, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2634892749441825, 'dropout_rate_Layer_2': 0.09711551368088306, 'dropout_rate_Layer_3': 0.39726737214295177, 'dropout_rate_Layer_4': 0.1651017912152913, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004017391757476461, 'l1_Layer_2': 4.643912886333668e-05, 'l1_Layer_3': 5.1925908013617985e-05, 'l1_Layer_4': 0.04579451606974776, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 70, 'n_units_Layer_4': 150}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.02 | sMAPE for Validation Set is: 19.22% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.53 | sMAPE for Test Set is: 36.93% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:12:46,174]\u001b[0m Trial 771 finished with value: 26.631051692318866 and parameters: {'n_hidden': 4, 'learning_rate': 0.001842484685861186, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2691578372536938, 'dropout_rate_Layer_2': 0.0302226353049444, 'dropout_rate_Layer_3': 0.2129394264690692, 'dropout_rate_Layer_4': 0.1511732909801293, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00015918722152331145, 'l1_Layer_2': 1.0184070184806878e-05, 'l1_Layer_3': 5.150592976952396e-05, 'l1_Layer_4': 0.050730374895477076, 'n_units_Layer_1': 120, 'n_units_Layer_2': 55, 'n_units_Layer_3': 70, 'n_units_Layer_4': 140}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.63 | sMAPE for Validation Set is: 19.61% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.58 | sMAPE for Test Set is: 38.38% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:13:00,654]\u001b[0m Trial 775 finished with value: 24.97054719331183 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005801054714759189, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2050348716752224, 'dropout_rate_Layer_2': 0.1764121788700084, 'dropout_rate_Layer_3': 0.3247129549176558, 'dropout_rate_Layer_4': 0.06714752524578455, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010470029813188415, 'l1_Layer_2': 2.0499371108243204e-05, 'l1_Layer_3': 0.0002522351257702104, 'l1_Layer_4': 0.0013107977771196113, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 295, 'n_units_Layer_4': 280}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.97 | sMAPE for Validation Set is: 18.32% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.44 | sMAPE for Test Set is: 36.18% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:13:19,588]\u001b[0m Trial 783 finished with value: 26.03999765658956 and parameters: {'n_hidden': 3, 'learning_rate': 0.00382725563152991, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38822674837348037, 'dropout_rate_Layer_2': 0.11623263693188088, 'dropout_rate_Layer_3': 0.12692398292431994, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.078453681807341e-05, 'l1_Layer_2': 0.0164708369240728, 'l1_Layer_3': 0.014612909185428192, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 110}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.04 | sMAPE for Validation Set is: 19.26% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.92 | sMAPE for Test Set is: 37.09% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:13:44,800]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:13:50,078]\u001b[0m Trial 780 finished with value: 26.201092584093193 and parameters: {'n_hidden': 4, 'learning_rate': 0.002775133125703629, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2728493454094329, 'dropout_rate_Layer_2': 0.09427281730825915, 'dropout_rate_Layer_3': 0.21240148221049487, 'dropout_rate_Layer_4': 0.16139617656772057, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00033928164089865504, 'l1_Layer_2': 4.613698894913253e-05, 'l1_Layer_3': 2.2138592208758835e-05, 'l1_Layer_4': 0.05593323372166298, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 70, 'n_units_Layer_4': 155}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.20 | sMAPE for Validation Set is: 19.31% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.83 | sMAPE for Test Set is: 37.61% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:13:56,011]\u001b[0m Trial 782 finished with value: 25.18775914589897 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005629029496189626, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20251231830725247, 'dropout_rate_Layer_2': 0.17530817354065148, 'dropout_rate_Layer_3': 0.3332992646749931, 'dropout_rate_Layer_4': 0.06475188159346404, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.770740918216654e-05, 'l1_Layer_2': 1.835627418618767e-05, 'l1_Layer_3': 0.00019652761045741316, 'l1_Layer_4': 0.0017527286053475315, 'n_units_Layer_1': 275, 'n_units_Layer_2': 50, 'n_units_Layer_3': 295, 'n_units_Layer_4': 295}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.19 | sMAPE for Validation Set is: 18.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.16 | sMAPE for Test Set is: 35.71% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:14:02,044]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:14:13,274]\u001b[0m Trial 781 finished with value: 25.88736031800009 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007244180053572206, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2688156293038224, 'dropout_rate_Layer_2': 0.0889275811618239, 'dropout_rate_Layer_3': 0.3918781668295485, 'dropout_rate_Layer_4': 0.1506304428122125, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003006612000372883, 'l1_Layer_2': 1.9455867281352162e-05, 'l1_Layer_3': 2.1265836891870125e-05, 'l1_Layer_4': 0.05106543939840572, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 70, 'n_units_Layer_4': 150}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.89 | sMAPE for Validation Set is: 19.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.57 | sMAPE for Test Set is: 37.20% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:14:30,791]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:14:36,465]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:14:40,752]\u001b[0m Trial 785 finished with value: 25.23736993740391 and parameters: {'n_hidden': 4, 'learning_rate': 0.00050253231340049, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19787154063571538, 'dropout_rate_Layer_2': 0.17382476807512975, 'dropout_rate_Layer_3': 0.320125293433936, 'dropout_rate_Layer_4': 0.06172469049870608, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.675141956281213e-05, 'l1_Layer_2': 2.2317497020414e-05, 'l1_Layer_3': 0.00020456190153610138, 'l1_Layer_4': 0.0016697429666017814, 'n_units_Layer_1': 265, 'n_units_Layer_2': 50, 'n_units_Layer_3': 285, 'n_units_Layer_4': 295}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.24 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.80 | sMAPE for Test Set is: 36.85% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:14:41,592]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:14:47,559]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:14:48,412]\u001b[0m Trial 788 finished with value: 25.541802613091424 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005458472349226574, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19901241093556904, 'dropout_rate_Layer_2': 0.17736828060824358, 'dropout_rate_Layer_3': 0.32861705147472287, 'dropout_rate_Layer_4': 0.06710440734051537, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.9859101955415014e-05, 'l1_Layer_2': 2.3888691447022776e-05, 'l1_Layer_3': 0.00026484397868383705, 'l1_Layer_4': 0.002047645919745048, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 300, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.54 | sMAPE for Validation Set is: 18.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.45 | sMAPE for Test Set is: 36.05% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:14:54,470]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:14:59,572]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:15:03,232]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:15:08,449]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:15:20,912]\u001b[0m Trial 787 finished with value: 24.232092870742054 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007190707193846284, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20908967609859602, 'dropout_rate_Layer_2': 0.16160394352877994, 'dropout_rate_Layer_3': 0.32461569812694124, 'dropout_rate_Layer_4': 0.07050391624257211, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.307515641780312e-05, 'l1_Layer_2': 2.1218481719672702e-05, 'l1_Layer_3': 0.00020664645076131564, 'l1_Layer_4': 0.001907737608151455, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.23 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.45 | sMAPE for Test Set is: 35.69% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:15:23,265]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:15:27,736]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:15:32,670]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:15:37,973]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:15:42,205]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:15:45,531]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:15:46,521]\u001b[0m Trial 794 finished with value: 26.258380990951867 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008112213249358463, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24668990107053534, 'dropout_rate_Layer_2': 0.12586530744860874, 'dropout_rate_Layer_3': 0.3932831838692256, 'dropout_rate_Layer_4': 0.12771885856002324, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008546108262972467, 'l1_Layer_2': 1.758790565299152e-05, 'l1_Layer_3': 1.9337754544327693e-05, 'l1_Layer_4': 0.07197666082157567, 'n_units_Layer_1': 140, 'n_units_Layer_2': 155, 'n_units_Layer_3': 85, 'n_units_Layer_4': 140}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.26 | sMAPE for Validation Set is: 19.37% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.14 | sMAPE for Test Set is: 38.38% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:15:55,109]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:15:56,436]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:16:05,265]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:16:10,244]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:16:13,186]\u001b[0m Trial 801 finished with value: 26.185755022486717 and parameters: {'n_hidden': 4, 'learning_rate': 0.000753199926604079, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2890366941616371, 'dropout_rate_Layer_2': 0.1190945914136332, 'dropout_rate_Layer_3': 0.39508101779516364, 'dropout_rate_Layer_4': 0.10004628854471784, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00046215361301878, 'l1_Layer_2': 1.6575829120627247e-05, 'l1_Layer_3': 5.161673730419256e-05, 'l1_Layer_4': 0.06641382845610677, 'n_units_Layer_1': 140, 'n_units_Layer_2': 155, 'n_units_Layer_3': 90, 'n_units_Layer_4': 145}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.19 | sMAPE for Validation Set is: 19.34% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.95 | sMAPE for Test Set is: 37.76% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:16:22,688]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:16:54,801]\u001b[0m Trial 810 finished with value: 25.203284530302223 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006819722235998362, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19760580186772556, 'dropout_rate_Layer_2': 0.13723814742023643, 'dropout_rate_Layer_3': 0.3135818738913445, 'dropout_rate_Layer_4': 0.0884758580869347, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.094624077923715e-05, 'l1_Layer_2': 3.3932582547715334e-05, 'l1_Layer_3': 0.00020044042317164323, 'l1_Layer_4': 0.0027020372225639465, 'n_units_Layer_1': 280, 'n_units_Layer_2': 55, 'n_units_Layer_3': 285, 'n_units_Layer_4': 290}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.20 | sMAPE for Validation Set is: 18.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.91 | sMAPE for Test Set is: 36.52% | rMAE for Test Set is: 0.68\n",
      "MAE for Validation Set is: 25.49 | sMAPE for Validation Set is: 18.67% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.07 | sMAPE for Test Set is: 35.50% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:17:04,737]\u001b[0m Trial 811 finished with value: 25.492321729733288 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006345315608705208, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19479107468191556, 'dropout_rate_Layer_2': 0.162533692066722, 'dropout_rate_Layer_3': 0.324708840393797, 'dropout_rate_Layer_4': 0.06503779730894095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.1116595212042275e-05, 'l1_Layer_2': 1.7231500377008482e-05, 'l1_Layer_3': 0.00019033341927317002, 'l1_Layer_4': 0.002064859816734394, 'n_units_Layer_1': 260, 'n_units_Layer_2': 55, 'n_units_Layer_3': 300, 'n_units_Layer_4': 295}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:17:20,160]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:17:24,205]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:17:34,171]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:17:34,672]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:17:43,029]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:17:51,516]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:17:56,088]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.05 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.44 | sMAPE for Test Set is: 34.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:17:59,062]\u001b[0m Trial 815 finished with value: 24.052462289798694 and parameters: {'n_hidden': 3, 'learning_rate': 0.000788876291195472, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04146687492797497, 'dropout_rate_Layer_2': 0.19581045362167712, 'dropout_rate_Layer_3': 0.3020534603250056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00063547052022422, 'l1_Layer_2': 0.0007935279224553878, 'l1_Layer_3': 1.0521862769360147e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:03,605]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:03,796]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:08,981]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:09,706]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:15,788]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:16,176]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:16,597]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:28,873]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:31,055]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:31,184]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:31,600]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:37,641]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:38,007]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:42,651]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:43,887]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:45,077]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:45,245]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:52,428]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:52,742]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:59,240]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:19:01,383]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:19:24,328]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:19:38,824]\u001b[0m Trial 839 finished with value: 24.90512187502237 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006789799351436595, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.199220062369601, 'dropout_rate_Layer_2': 0.19651747306869133, 'dropout_rate_Layer_3': 0.319018509365629, 'dropout_rate_Layer_4': 0.07612239825553004, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.485742410382202e-05, 'l1_Layer_2': 2.1195766336842165e-05, 'l1_Layer_3': 0.00021421943595626168, 'l1_Layer_4': 0.001434359837942079, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 285, 'n_units_Layer_4': 290}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.91 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.05 | sMAPE for Test Set is: 35.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:19:42,543]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:20:01,156]\u001b[0m Trial 842 finished with value: 25.076431756233813 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006885895878022076, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18594728708088676, 'dropout_rate_Layer_2': 0.17595414355303635, 'dropout_rate_Layer_3': 0.30257592753126844, 'dropout_rate_Layer_4': 0.09191117175446945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.682482855464492e-05, 'l1_Layer_2': 1.9857695167757495e-05, 'l1_Layer_3': 0.00022136635660694425, 'l1_Layer_4': 0.0017696279072213145, 'n_units_Layer_1': 270, 'n_units_Layer_2': 130, 'n_units_Layer_3': 295, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.08 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.30 | sMAPE for Test Set is: 35.75% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:20:01,964]\u001b[0m Trial 843 finished with value: 24.958021932767092 and parameters: {'n_hidden': 4, 'learning_rate': 0.000687516179180996, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18756234049754747, 'dropout_rate_Layer_2': 0.19370798994264815, 'dropout_rate_Layer_3': 0.3185309670426359, 'dropout_rate_Layer_4': 0.09189862066111221, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.8357611715181774e-05, 'l1_Layer_2': 1.1857448379847982e-05, 'l1_Layer_3': 0.0002099546729740316, 'l1_Layer_4': 0.0018409635249799347, 'n_units_Layer_1': 270, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.96 | sMAPE for Validation Set is: 18.55% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.37 | sMAPE for Test Set is: 35.99% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:20:08,369]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:20:11,044]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:20:21,123]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:20:45,195]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:20:52,801]\u001b[0m Trial 845 finished with value: 25.850653483907607 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009080811329437776, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21558568766070335, 'dropout_rate_Layer_2': 0.04562682309706787, 'dropout_rate_Layer_3': 0.38499919802917315, 'dropout_rate_Layer_4': 0.0816073041149677, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00040373900454907316, 'l1_Layer_2': 0.0027903846478598187, 'l1_Layer_3': 1.1048324829549938e-05, 'l1_Layer_4': 7.793951970321082e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 80, 'n_units_Layer_4': 195}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.85 | sMAPE for Validation Set is: 19.05% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.76 | sMAPE for Test Set is: 36.31% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:21:02,158]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:21:16,827]\u001b[0m Trial 851 finished with value: 25.29833880583556 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007560108736289517, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21221298402486613, 'dropout_rate_Layer_2': 0.16692092295037278, 'dropout_rate_Layer_3': 0.3030409151776797, 'dropout_rate_Layer_4': 0.0919608595557897, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.442833726189544e-05, 'l1_Layer_2': 1.2912220614533404e-05, 'l1_Layer_3': 0.00022621090013800546, 'l1_Layer_4': 0.0017044642486934397, 'n_units_Layer_1': 270, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.30 | sMAPE for Validation Set is: 18.69% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.75 | sMAPE for Test Set is: 35.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:21:17,637]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:21:23,962]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:21:29,195]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:21:45,308]\u001b[0m Trial 847 finished with value: 25.989393433179274 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009685949421417363, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2158258264231896, 'dropout_rate_Layer_2': 0.09692160157732227, 'dropout_rate_Layer_3': 0.3808549529918634, 'dropout_rate_Layer_4': 0.08440325581750849, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014923923146599309, 'l1_Layer_2': 0.0009799959440879669, 'l1_Layer_3': 2.6352955249726838e-05, 'l1_Layer_4': 0.011008264923158644, 'n_units_Layer_1': 85, 'n_units_Layer_2': 120, 'n_units_Layer_3': 80, 'n_units_Layer_4': 130}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.99 | sMAPE for Validation Set is: 19.19% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.36 | sMAPE for Test Set is: 36.60% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:21:51,808]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:21:57,168]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:22:02,096]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:22:08,759]\u001b[0m Trial 855 finished with value: 24.91184802900479 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007789693310234943, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2160318680484943, 'dropout_rate_Layer_2': 0.1866667621631839, 'dropout_rate_Layer_3': 0.30175035542477474, 'dropout_rate_Layer_4': 0.09247156795594275, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.975879102879832e-05, 'l1_Layer_2': 1.2431841470083339e-05, 'l1_Layer_3': 0.00016673474226823294, 'l1_Layer_4': 0.001453834196294063, 'n_units_Layer_1': 290, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.91 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.87 | sMAPE for Test Set is: 35.44% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:22:14,404]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:22:17,615]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:22:26,256]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:22:33,145]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:22:46,677]\u001b[0m Trial 861 finished with value: 24.612392021997014 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006697297269507284, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22386031479439777, 'dropout_rate_Layer_2': 0.17375381746017413, 'dropout_rate_Layer_3': 0.31401913841670265, 'dropout_rate_Layer_4': 0.08908374220124556, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013366357662527683, 'l1_Layer_2': 1.1836330533857219e-05, 'l1_Layer_3': 0.00035728815755727434, 'l1_Layer_4': 0.0013846436156841515, 'n_units_Layer_1': 290, 'n_units_Layer_2': 150, 'n_units_Layer_3': 295, 'n_units_Layer_4': 295}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.61 | sMAPE for Validation Set is: 18.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.11 | sMAPE for Test Set is: 35.70% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:22:53,640]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:22:57,887]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:23:02,370]\u001b[0m Trial 863 finished with value: 23.83026297196163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006807196569735068, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011645873839641208, 'dropout_rate_Layer_2': 0.24891668094687183, 'dropout_rate_Layer_3': 0.32426116153522955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003297229431968517, 'l1_Layer_2': 0.00037010377971913164, 'l1_Layer_3': 0.0010296640526208604, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.83 | sMAPE for Validation Set is: 17.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.27 | sMAPE for Test Set is: 34.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:23:09,067]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:23:23,830]\u001b[0m Trial 868 finished with value: 25.03737473169075 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006147999558272479, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21226674590032857, 'dropout_rate_Layer_2': 0.04119485755876587, 'dropout_rate_Layer_3': 0.3252588925873111, 'dropout_rate_Layer_4': 0.09266674004762032, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015034861589359886, 'l1_Layer_2': 0.0010469738535091664, 'l1_Layer_3': 1.2550460278380585e-05, 'l1_Layer_4': 6.992361051501002e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 175, 'n_units_Layer_3': 110, 'n_units_Layer_4': 195}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.04 | sMAPE for Validation Set is: 18.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.82 | sMAPE for Test Set is: 35.03% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:23:27,441]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:23:34,201]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:23:38,577]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:23:39,580]\u001b[0m Trial 869 finished with value: 25.101978717773765 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006510098475542932, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2177388516069232, 'dropout_rate_Layer_2': 0.04323447754960735, 'dropout_rate_Layer_3': 0.3277869638740091, 'dropout_rate_Layer_4': 0.08489461187936642, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0027010920301301865, 'l1_Layer_2': 0.0010357846175952103, 'l1_Layer_3': 1.0334523215139186e-05, 'l1_Layer_4': 6.047139287468008e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 185, 'n_units_Layer_3': 125, 'n_units_Layer_4': 115}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.10 | sMAPE for Validation Set is: 18.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.09 | sMAPE for Test Set is: 35.62% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:23:51,408]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:23:54,430]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:24:06,827]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:24:19,199]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:24:23,220]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:24:25,524]\u001b[0m Trial 874 finished with value: 23.511830053769007 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009086268762312752, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03108684297442762, 'dropout_rate_Layer_2': 0.2502931901006856, 'dropout_rate_Layer_3': 0.10404483900511978, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003135107005203656, 'l1_Layer_2': 0.00034258054737741845, 'l1_Layer_3': 0.0008499047962522184, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.51 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 21.11 | sMAPE for Test Set is: 34.97% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:24:30,006]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:24:31,958]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:24:34,893]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:24:58,845]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:25:02,299]\u001b[0m Trial 881 finished with value: 25.00735141131909 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006116929235068347, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20755115994973794, 'dropout_rate_Layer_2': 0.18767838704146042, 'dropout_rate_Layer_3': 0.3170123178345058, 'dropout_rate_Layer_4': 0.07794934889699685, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.213419434147357e-05, 'l1_Layer_2': 1.764683565493539e-05, 'l1_Layer_3': 0.00032035995717398627, 'l1_Layer_4': 0.0015658072845290045, 'n_units_Layer_1': 290, 'n_units_Layer_2': 130, 'n_units_Layer_3': 295, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.01 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.25 | sMAPE for Test Set is: 37.86% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:25:14,877]\u001b[0m Trial 882 finished with value: 25.25856128304808 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006154162881316516, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20708321690372444, 'dropout_rate_Layer_2': 0.18746326896635415, 'dropout_rate_Layer_3': 0.32377594675050037, 'dropout_rate_Layer_4': 0.0809008907472625, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.912697354764041e-05, 'l1_Layer_2': 1.3406831859382931e-05, 'l1_Layer_3': 0.0003087058952247619, 'l1_Layer_4': 0.0015659175272450753, 'n_units_Layer_1': 280, 'n_units_Layer_2': 120, 'n_units_Layer_3': 295, 'n_units_Layer_4': 300}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.26 | sMAPE for Validation Set is: 18.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.13 | sMAPE for Test Set is: 35.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:25:23,163]\u001b[0m Trial 886 finished with value: 24.784822015895525 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010714302470276654, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21650460664977286, 'dropout_rate_Layer_2': 0.015667679596871667, 'dropout_rate_Layer_3': 0.38125160473331604, 'dropout_rate_Layer_4': 0.021484691216243287, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0016023663362274394, 'l1_Layer_2': 0.002808815877922558, 'l1_Layer_3': 1.0357124364288129e-05, 'l1_Layer_4': 9.686980691006127e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 125, 'n_units_Layer_4': 105}. Best is trial 116 with value: 23.498233581412876.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.78 | sMAPE for Validation Set is: 18.39% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.87 | sMAPE for Test Set is: 35.50% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:25:26,129]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:25:26,996]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:25:34,119]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:25:37,393]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:25:41,337]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:25:46,425]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:25:47,183]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:26:10,151]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:26:18,998]\u001b[0m Trial 890 finished with value: 23.41722407001704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007487246903957872, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03561165690618289, 'dropout_rate_Layer_2': 0.25700284358171555, 'dropout_rate_Layer_3': 0.1308240334153531, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00042344278379666, 'l1_Layer_2': 0.00023417333814294635, 'l1_Layer_3': 0.000994863419357952, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260}. Best is trial 890 with value: 23.41722407001704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.42 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.48 | sMAPE for Test Set is: 34.03% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:26:20,201]\u001b[0m Trial 893 finished with value: 23.31688498557391 and parameters: {'n_hidden': 3, 'learning_rate': 0.000684603755496062, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022055643617414748, 'dropout_rate_Layer_2': 0.2443611480934793, 'dropout_rate_Layer_3': 0.09647715515962949, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002470392719312375, 'l1_Layer_2': 0.00025400396103025504, 'l1_Layer_3': 9.732498612926466e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.32 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.14 | sMAPE for Test Set is: 37.06% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:26:24,771]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:26:48,417]\u001b[0m Trial 898 finished with value: 23.685153845951543 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006820981299902447, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014265301943608257, 'dropout_rate_Layer_2': 0.2393874450393076, 'dropout_rate_Layer_3': 0.32359879736276753, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002322604139371145, 'l1_Layer_2': 0.00018360338276155377, 'l1_Layer_3': 0.000779938080425428, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.69 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.59 | sMAPE for Test Set is: 34.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:27:24,071]\u001b[0m Trial 901 finished with value: 23.37595966635747 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006879615171576561, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02309052627730623, 'dropout_rate_Layer_2': 0.24184249017797715, 'dropout_rate_Layer_3': 0.09330018533307535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032714704826831146, 'l1_Layer_2': 0.00019757237910400242, 'l1_Layer_3': 0.0008079890227011274, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.38 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.23 | sMAPE for Test Set is: 34.17% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:27:28,047]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:27:30,702]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:27:31,465]\u001b[0m Trial 899 finished with value: 23.425310685108496 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006832813745139017, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014519549904489082, 'dropout_rate_Layer_2': 0.23924598316657067, 'dropout_rate_Layer_3': 0.1308544624745068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024089755424681604, 'l1_Layer_2': 0.0002471547583486633, 'l1_Layer_3': 0.0004658675960565947, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.43 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.52 | sMAPE for Test Set is: 35.94% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:27:35,150]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:27:44,081]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:27:50,102]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:27:55,648]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:27:59,960]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:28:00,776]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:28:04,045]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:28:37,784]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:28:42,844]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:28:58,984]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:29:03,857]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:29:06,466]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:29:12,596]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:29:21,784]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:29:23,724]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:29:27,035]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:29:38,010]\u001b[0m Trial 914 finished with value: 26.011550145646492 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008234201720236831, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38810530963589335, 'dropout_rate_Layer_2': 0.08323429315281114, 'dropout_rate_Layer_3': 0.1405277885627248, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.382626540472534e-05, 'l1_Layer_2': 0.027743918580084476, 'l1_Layer_3': 0.010860254422404302, 'n_units_Layer_1': 125, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.01 | sMAPE for Validation Set is: 19.22% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.82 | sMAPE for Test Set is: 36.90% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:29:41,409]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:30:15,546]\u001b[0m Trial 922 finished with value: 23.54574788466734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007534905708809891, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028345075125682115, 'dropout_rate_Layer_2': 0.26495084817060094, 'dropout_rate_Layer_3': 0.08066768891920413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002948435886539938, 'l1_Layer_2': 0.0002664788608226036, 'l1_Layer_3': 0.000612467986795065, 'n_units_Layer_1': 80, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.55 | sMAPE for Validation Set is: 17.57% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 21.97 | sMAPE for Test Set is: 35.72% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:30:19,226]\u001b[0m Trial 919 finished with value: 25.56018320375759 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008122977606256851, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00645063992898387, 'dropout_rate_Layer_2': 0.09910983362716481, 'dropout_rate_Layer_3': 0.09517578816569759, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0362939272856496e-05, 'l1_Layer_2': 0.019532489970022115, 'l1_Layer_3': 0.011176622730367871, 'n_units_Layer_1': 80, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.56 | sMAPE for Validation Set is: 18.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.01 | sMAPE for Test Set is: 37.03% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:30:29,037]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:30:30,559]\u001b[0m Trial 925 finished with value: 24.900004789472955 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005025281564809503, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19921394053323416, 'dropout_rate_Layer_2': 0.16950553573284063, 'dropout_rate_Layer_3': 0.3439178094134635, 'dropout_rate_Layer_4': 0.0664505799691914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.542352271095345e-05, 'l1_Layer_2': 1.3805450969781149e-05, 'l1_Layer_3': 0.0003321890764343182, 'l1_Layer_4': 0.0019481372318829585, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300, 'n_units_Layer_4': 290}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.90 | sMAPE for Validation Set is: 18.43% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.89 | sMAPE for Test Set is: 35.41% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:30:30,730]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:30:47,942]\u001b[0m Trial 924 finished with value: 25.284153224235364 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005026374785492385, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20032285984287326, 'dropout_rate_Layer_2': 0.18073506658836888, 'dropout_rate_Layer_3': 0.34477810488135535, 'dropout_rate_Layer_4': 0.06560502636058589, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.641567193185065e-05, 'l1_Layer_2': 1.3994491505824405e-05, 'l1_Layer_3': 0.00018927263428563951, 'l1_Layer_4': 0.0018778334401913872, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300, 'n_units_Layer_4': 290}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.28 | sMAPE for Validation Set is: 18.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.96 | sMAPE for Test Set is: 35.39% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:30:59,670]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:31:00,446]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:31:01,480]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:31:12,426]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:31:14,600]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:31:16,528]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:31:21,894]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:31:28,219]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:31:43,632]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:31:47,076]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:31:55,208]\u001b[0m Trial 935 finished with value: 23.798826797635915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007627609642967371, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02059717505012316, 'dropout_rate_Layer_2': 0.22989146170172906, 'dropout_rate_Layer_3': 0.06690208544191235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024311484323638895, 'l1_Layer_2': 0.00014100389751478797, 'l1_Layer_3': 0.001061330585749378, 'n_units_Layer_1': 85, 'n_units_Layer_2': 300, 'n_units_Layer_3': 260}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.80 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.69 | sMAPE for Test Set is: 34.35% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:32:04,681]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:32:07,235]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:32:17,829]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:32:22,085]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:32:37,358]\u001b[0m Trial 939 finished with value: 25.118432412632018 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005731451385771338, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20187643675827488, 'dropout_rate_Layer_2': 0.17940829674120662, 'dropout_rate_Layer_3': 0.3407334894914561, 'dropout_rate_Layer_4': 0.07022497932074674, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.091370849221885e-05, 'l1_Layer_2': 1.832956491270985e-05, 'l1_Layer_3': 0.00018550245786375018, 'l1_Layer_4': 0.0018302658139552877, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290, 'n_units_Layer_4': 280}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.12 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.69 | sMAPE for Test Set is: 35.91% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:32:57,444]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:33:03,030]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:33:03,195]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:33:09,339]\u001b[0m Trial 941 finished with value: 24.60243471006414 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008122256140747182, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20350547858773005, 'dropout_rate_Layer_2': 0.1586791912015706, 'dropout_rate_Layer_3': 0.32614712585114186, 'dropout_rate_Layer_4': 0.06868790954891721, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.560129844702298e-05, 'l1_Layer_2': 1.4500311008700384e-05, 'l1_Layer_3': 0.00017512924412916293, 'l1_Layer_4': 0.002263231434211639, 'n_units_Layer_1': 290, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300, 'n_units_Layer_4': 280}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.60 | sMAPE for Validation Set is: 18.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.60 | sMAPE for Test Set is: 35.72% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:33:12,718]\u001b[0m Trial 946 finished with value: 24.73434859066258 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006165555197832559, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19617862430682903, 'dropout_rate_Layer_2': 0.18010332680335348, 'dropout_rate_Layer_3': 0.3388148828766248, 'dropout_rate_Layer_4': 0.055475639209958384, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.258223010008611e-05, 'l1_Layer_2': 1.9249505854033068e-05, 'l1_Layer_3': 0.00017233764282069877, 'l1_Layer_4': 0.0013833231122016333, 'n_units_Layer_1': 285, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300, 'n_units_Layer_4': 300}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.73 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.03 | sMAPE for Test Set is: 36.02% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:33:22,796]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:33:28,830]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:33:31,265]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:33:40,841]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:33:47,839]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:33:48,368]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:33:58,793]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:34:05,334]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:34:09,058]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:34:22,696]\u001b[0m Trial 950 finished with value: 23.611610071593393 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007505501966053153, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03531582025543378, 'dropout_rate_Layer_2': 0.2536892799536523, 'dropout_rate_Layer_3': 0.07140582489946988, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00033772163230123977, 'l1_Layer_2': 0.0001043149437922282, 'l1_Layer_3': 0.0012852274094330182, 'n_units_Layer_1': 85, 'n_units_Layer_2': 300, 'n_units_Layer_3': 235}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.61 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.51 | sMAPE for Test Set is: 34.01% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:34:27,489]\u001b[0m Trial 951 finished with value: 26.207703881317013 and parameters: {'n_hidden': 3, 'learning_rate': 0.000603344208898591, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08132940373659535, 'dropout_rate_Layer_2': 0.10106158828267794, 'dropout_rate_Layer_3': 0.315147081367695, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.4092711068049e-05, 'l1_Layer_2': 0.0154536271457013, 'l1_Layer_3': 0.029388226136369374, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 205}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.21 | sMAPE for Validation Set is: 19.29% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.36 | sMAPE for Test Set is: 36.51% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:34:29,549]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:34:38,511]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:34:39,992]\u001b[0m Trial 957 finished with value: 25.154037349288473 and parameters: {'n_hidden': 4, 'learning_rate': 0.00076049086108119, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2211424555014661, 'dropout_rate_Layer_2': 0.14213662720168624, 'dropout_rate_Layer_3': 0.3516211242051593, 'dropout_rate_Layer_4': 0.06156639047426656, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.395459636791577e-05, 'l1_Layer_2': 1.703493049123449e-05, 'l1_Layer_3': 0.00016748477750120816, 'l1_Layer_4': 0.002375565322467615, 'n_units_Layer_1': 290, 'n_units_Layer_2': 150, 'n_units_Layer_3': 300, 'n_units_Layer_4': 280}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.15 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.21 | sMAPE for Test Set is: 35.67% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:34:41,540]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:34:45,299]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:34:52,824]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:34:55,399]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:35:13,169]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:35:22,801]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:35:28,813]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:35:36,880]\u001b[0m Trial 969 finished with value: 25.70345887444317 and parameters: {'n_hidden': 3, 'learning_rate': 0.005072133054238038, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3958010306579, 'dropout_rate_Layer_2': 0.037048170537119236, 'dropout_rate_Layer_3': 0.10533019428114518, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.177736770129903e-05, 'l1_Layer_2': 0.019626117339435537, 'l1_Layer_3': 0.012467386299285349, 'n_units_Layer_1': 50, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.70 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.06 | sMAPE for Test Set is: 36.95% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:35:41,863]\u001b[0m Trial 965 finished with value: 24.7064406578822 and parameters: {'n_hidden': 4, 'learning_rate': 0.000652306542072316, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19693475867923807, 'dropout_rate_Layer_2': 0.14484168383723578, 'dropout_rate_Layer_3': 0.3478896329128344, 'dropout_rate_Layer_4': 0.06964777088782922, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.349451892894006e-05, 'l1_Layer_2': 1.4303491416307e-05, 'l1_Layer_3': 0.00024869250763747455, 'l1_Layer_4': 0.0019933837145800935, 'n_units_Layer_1': 290, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300, 'n_units_Layer_4': 280}. Best is trial 893 with value: 23.31688498557391.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.71 | sMAPE for Validation Set is: 18.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.62 | sMAPE for Test Set is: 34.90% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:35:48,872]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:35:55,274]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:35:55,846]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:36:06,210]\u001b[0m Trial 966 finished with value: 22.864450461227914 and parameters: {'n_hidden': 3, 'learning_rate': 0.000844805136006839, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022813534784802622, 'dropout_rate_Layer_2': 0.27178051058104213, 'dropout_rate_Layer_3': 0.06326605967254957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002592596152732248, 'l1_Layer_2': 0.00015992082998781649, 'l1_Layer_3': 0.0006931957363936034, 'n_units_Layer_1': 85, 'n_units_Layer_2': 295, 'n_units_Layer_3': 265}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.86 | sMAPE for Validation Set is: 17.11% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 19.44 | sMAPE for Test Set is: 33.31% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:36:08,086]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:36:12,890]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:36:22,052]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:36:22,212]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:36:35,998]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:36:47,938]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:36:50,438]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:36:51,072]\u001b[0m Trial 984 finished with value: 25.27303037036508 and parameters: {'n_hidden': 3, 'learning_rate': 0.005236931823094585, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38388670549042453, 'dropout_rate_Layer_2': 0.06529915749978153, 'dropout_rate_Layer_3': 0.09651470061390882, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1911729241002526e-05, 'l1_Layer_2': 0.012137258159184672, 'l1_Layer_3': 0.0012675084434856634, 'n_units_Layer_1': 115, 'n_units_Layer_2': 270, 'n_units_Layer_3': 200}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.27 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.56 | sMAPE for Test Set is: 37.42% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:36:57,736]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:36:59,644]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:37:19,383]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:37:29,931]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:37:41,520]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:37:47,731]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:37:50,443]\u001b[0m Trial 989 finished with value: 25.54532327747434 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009852811224309373, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21830762635880221, 'dropout_rate_Layer_2': 0.20312663425902025, 'dropout_rate_Layer_3': 0.34365858828033946, 'dropout_rate_Layer_4': 0.0970736908064621, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009513291133787212, 'l1_Layer_2': 0.0008411205105535827, 'l1_Layer_3': 1.5787930012494075e-05, 'l1_Layer_4': 0.000335921534471991, 'n_units_Layer_1': 200, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95, 'n_units_Layer_4': 130}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.55 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.80 | sMAPE for Test Set is: 36.24% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:37:55,319]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:38:05,192]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:38:09,599]\u001b[0m Trial 980 finished with value: 25.048266482952585 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006553281167896121, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22110201837546667, 'dropout_rate_Layer_2': 0.05227471777872317, 'dropout_rate_Layer_3': 0.3406978955563743, 'dropout_rate_Layer_4': 0.07568803106139238, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0016395333698449362, 'l1_Layer_2': 0.0014711676805010659, 'l1_Layer_3': 2.540331478123648e-05, 'l1_Layer_4': 7.040424331090441e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 200, 'n_units_Layer_3': 85, 'n_units_Layer_4': 125}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.05 | sMAPE for Validation Set is: 18.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.15 | sMAPE for Test Set is: 35.57% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:38:10,060]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:38:17,772]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:38:18,680]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:38:24,194]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:38:30,757]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:38:36,131]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:38:53,162]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:38:59,374]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:39:04,683]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:39:11,635]\u001b[0m Trial 998 finished with value: 25.511975039654384 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005699944483500159, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19684110426329549, 'dropout_rate_Layer_2': 0.17466137018088995, 'dropout_rate_Layer_3': 0.33765929674845624, 'dropout_rate_Layer_4': 0.06841129953333763, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.435177776109918e-05, 'l1_Layer_2': 2.4500382558131646e-05, 'l1_Layer_3': 0.0005747200115213679, 'l1_Layer_4': 0.0018091905440510497, 'n_units_Layer_1': 290, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295, 'n_units_Layer_4': 290}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.51 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.50 | sMAPE for Test Set is: 36.25% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:39:15,197]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:39:20,267]\u001b[0m Trial 1000 finished with value: 25.266264269525113 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006708110752630706, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1928066150761238, 'dropout_rate_Layer_2': 0.05160027605809355, 'dropout_rate_Layer_3': 0.3462985424872373, 'dropout_rate_Layer_4': 0.09664113477514674, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009587802493957519, 'l1_Layer_2': 0.002080388465755751, 'l1_Layer_3': 1.5534191985267098e-05, 'l1_Layer_4': 0.000381943077197326, 'n_units_Layer_1': 195, 'n_units_Layer_2': 200, 'n_units_Layer_3': 95, 'n_units_Layer_4': 120}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.27 | sMAPE for Validation Set is: 18.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.20 | sMAPE for Test Set is: 35.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:39:39,940]\u001b[0m Trial 1003 finished with value: 23.606188359736734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007678530862563063, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02233460511050163, 'dropout_rate_Layer_2': 0.25476322057867384, 'dropout_rate_Layer_3': 0.09933280962922611, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002390519568356334, 'l1_Layer_2': 0.0002788142606324163, 'l1_Layer_3': 0.0011544032994987336, 'n_units_Layer_1': 75, 'n_units_Layer_2': 160, 'n_units_Layer_3': 255}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.61 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.23 | sMAPE for Test Set is: 34.15% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:39:43,515]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:39:47,170]\u001b[0m Trial 1008 finished with value: 24.474621903900772 and parameters: {'n_hidden': 3, 'learning_rate': 0.003600080602954727, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04132603435548454, 'dropout_rate_Layer_2': 0.068204767861992, 'dropout_rate_Layer_3': 0.07752303667719632, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006436628268372662, 'l1_Layer_2': 0.03145279871478566, 'l1_Layer_3': 0.00024667257673077655, 'n_units_Layer_1': 125, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.47 | sMAPE for Validation Set is: 18.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.93 | sMAPE for Test Set is: 36.09% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:39:52,731]\u001b[0m Trial 1007 finished with value: 23.332405041234228 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007535042055264578, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018076219562736095, 'dropout_rate_Layer_2': 0.2546030210584792, 'dropout_rate_Layer_3': 0.08445422304257252, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022287377768922558, 'l1_Layer_2': 0.00034905608004503916, 'l1_Layer_3': 0.00011516767870562487, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.33 | sMAPE for Validation Set is: 17.46% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.42 | sMAPE for Test Set is: 36.25% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:39:58,818]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:05,111]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:08,176]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:11,669]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:13,118]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:20,111]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:21,007]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:21,555]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:29,348]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:29,554]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:33,536]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:40,400]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:45,041]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:45,426]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:41:04,640]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:41:05,181]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:41:05,823]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:41:06,078]\u001b[0m Trial 1016 finished with value: 23.123877052633684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008713005955766509, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025330576411711093, 'dropout_rate_Layer_2': 0.28183218692806083, 'dropout_rate_Layer_3': 0.07939904339079103, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025102917990276266, 'l1_Layer_2': 0.0003120437551315875, 'l1_Layer_3': 4.871779080002873e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 285, 'n_units_Layer_3': 250}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.12 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.51 | sMAPE for Test Set is: 34.48% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:41:16,738]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:41:20,919]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:41:44,438]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:41:48,931]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:41:54,197]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:42:00,013]\u001b[0m Trial 1030 finished with value: 23.69909950727413 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010321232393702398, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024981326258904098, 'dropout_rate_Layer_2': 0.28178088197738077, 'dropout_rate_Layer_3': 0.08229906256929863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017856682795312683, 'l1_Layer_2': 0.00027829684350595636, 'l1_Layer_3': 0.00010543859200660884, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.70 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.89 | sMAPE for Test Set is: 36.43% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:42:04,335]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:42:14,765]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:42:20,939]\u001b[0m Trial 1031 finished with value: 23.55294374195418 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010352898395069579, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020887550239430078, 'dropout_rate_Layer_2': 0.27568222454911073, 'dropout_rate_Layer_3': 0.08156042107679098, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023225445030367644, 'l1_Layer_2': 0.0002285767481470954, 'l1_Layer_3': 4.568021628318492e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.55 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 21.29 | sMAPE for Test Set is: 34.88% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:43:02,850]\u001b[0m Trial 1036 finished with value: 25.071460586885195 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006537010174772546, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19695689627617746, 'dropout_rate_Layer_2': 0.18862167582828163, 'dropout_rate_Layer_3': 0.3567646135439706, 'dropout_rate_Layer_4': 0.09310744317128383, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.437403134510523e-05, 'l1_Layer_2': 1.2730344678977785e-05, 'l1_Layer_3': 0.0002029716287731951, 'l1_Layer_4': 0.0020456808222780354, 'n_units_Layer_1': 300, 'n_units_Layer_2': 155, 'n_units_Layer_3': 285, 'n_units_Layer_4': 280}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.07 | sMAPE for Validation Set is: 18.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.17 | sMAPE for Test Set is: 35.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:43:09,100]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:43:13,621]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:43:19,077]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:43:23,709]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:43:26,665]\u001b[0m Trial 1040 finished with value: 23.178940219328194 and parameters: {'n_hidden': 3, 'learning_rate': 0.001031296321886115, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02513591219906348, 'dropout_rate_Layer_2': 0.282379817444302, 'dropout_rate_Layer_3': 0.07967811152539662, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022817481517577396, 'l1_Layer_2': 0.0002790962659766981, 'l1_Layer_3': 6.214822139293944e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 245}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.18 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 19.66 | sMAPE for Test Set is: 33.34% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:43:32,124]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:43:38,178]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:43:40,541]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:43:44,224]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:43:48,733]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:43:49,240]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:43:56,084]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:44:07,372]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:44:18,102]\u001b[0m Trial 1044 finished with value: 25.04740188624828 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006704309673760651, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18636071826025502, 'dropout_rate_Layer_2': 0.18093080335166345, 'dropout_rate_Layer_3': 0.3506304122844243, 'dropout_rate_Layer_4': 0.04751659072384516, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.398901185231678e-05, 'l1_Layer_2': 1.756686489300937e-05, 'l1_Layer_3': 0.0001415009462058419, 'l1_Layer_4': 0.0020278058962532376, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110, 'n_units_Layer_4': 280}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.05 | sMAPE for Validation Set is: 18.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.31 | sMAPE for Test Set is: 35.86% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:44:20,468]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:44:25,563]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:44:32,234]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:44:37,608]\u001b[0m Trial 1045 finished with value: 25.279061424290443 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006708915134868209, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18898477448614795, 'dropout_rate_Layer_2': 0.17758012405333656, 'dropout_rate_Layer_3': 0.3494320684671107, 'dropout_rate_Layer_4': 0.07582620102702954, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.854037283479559e-05, 'l1_Layer_2': 1.9273621751742614e-05, 'l1_Layer_3': 0.00014364025920335138, 'l1_Layer_4': 0.002120906996026395, 'n_units_Layer_1': 295, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285, 'n_units_Layer_4': 275}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.28 | sMAPE for Validation Set is: 18.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.01 | sMAPE for Test Set is: 35.69% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:44:40,850]\u001b[0m Trial 1054 finished with value: 24.135978549598985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010532342831811507, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013511366379671376, 'dropout_rate_Layer_2': 0.28245929139441384, 'dropout_rate_Layer_3': 0.07827223825416618, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002698045384135167, 'l1_Layer_2': 0.0002043403651130294, 'l1_Layer_3': 4.159540819508135e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 245}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.14 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.97 | sMAPE for Test Set is: 34.90% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:44:43,285]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:44:46,266]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:44:52,066]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:44:58,748]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:45:04,032]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:45:13,937]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:45:18,551]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:45:20,055]\u001b[0m Trial 1057 finished with value: 23.253747241326106 and parameters: {'n_hidden': 3, 'learning_rate': 0.00119343334953155, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009600212016150973, 'dropout_rate_Layer_2': 0.2922859112814465, 'dropout_rate_Layer_3': 0.06482772344340233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028055624719594606, 'l1_Layer_2': 0.0002259323152346806, 'l1_Layer_3': 5.5702009842001606e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.25 | sMAPE for Validation Set is: 17.46% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.67 | sMAPE for Test Set is: 34.78% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:45:27,759]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:45:32,991]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:45:37,018]\u001b[0m Trial 1061 finished with value: 23.715052325331524 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008568831265736021, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025370362622119037, 'dropout_rate_Layer_2': 0.2909626496115316, 'dropout_rate_Layer_3': 0.08556995013704075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017829793569297658, 'l1_Layer_2': 0.0003094055066909038, 'l1_Layer_3': 4.958377136063662e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 160, 'n_units_Layer_3': 235}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.72 | sMAPE for Validation Set is: 17.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.00 | sMAPE for Test Set is: 34.80% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:45:39,754]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:45:45,540]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:45:49,077]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:45:55,166]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:45:58,649]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:46:00,089]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:46:04,839]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:46:06,239]\u001b[0m Trial 1071 finished with value: 24.290840473925385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029117288613527367, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.055560582671930654, 'dropout_rate_Layer_2': 0.07703618711832719, 'dropout_rate_Layer_3': 0.10715152694826063, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.12530677573541e-05, 'l1_Layer_2': 0.02310510440677255, 'l1_Layer_3': 0.0002299805966149046, 'n_units_Layer_1': 115, 'n_units_Layer_2': 275, 'n_units_Layer_3': 205}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.29 | sMAPE for Validation Set is: 18.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.72 | sMAPE for Test Set is: 35.75% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:46:10,721]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:46:16,333]\u001b[0m Trial 1067 finished with value: 25.666281311048035 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010753580664798635, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20603799452275162, 'dropout_rate_Layer_2': 0.16872307588699417, 'dropout_rate_Layer_3': 0.33512797943878075, 'dropout_rate_Layer_4': 0.04042173643547264, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011058333999018199, 'l1_Layer_2': 3.286073209157641e-05, 'l1_Layer_3': 0.00017051294489280142, 'l1_Layer_4': 0.0012225356171626247, 'n_units_Layer_1': 250, 'n_units_Layer_2': 145, 'n_units_Layer_3': 120, 'n_units_Layer_4': 295}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.67 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.26 | sMAPE for Test Set is: 37.41% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:46:38,838]\u001b[0m Trial 1077 finished with value: 25.483467241532313 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008010323359764159, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2041434502148161, 'dropout_rate_Layer_2': 0.06469890510336007, 'dropout_rate_Layer_3': 0.29834038918238687, 'dropout_rate_Layer_4': 0.11312420082580855, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006818387860143444, 'l1_Layer_2': 0.0042723253394513746, 'l1_Layer_3': 1.323561055106304e-05, 'l1_Layer_4': 0.0001717476493744842, 'n_units_Layer_1': 200, 'n_units_Layer_2': 185, 'n_units_Layer_3': 85, 'n_units_Layer_4': 135}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.48 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.92 | sMAPE for Test Set is: 36.35% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:46:54,976]\u001b[0m Trial 1079 finished with value: 25.403955922388718 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008406304612828558, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2353088934238395, 'dropout_rate_Layer_2': 0.06562986558150102, 'dropout_rate_Layer_3': 0.29848526963438404, 'dropout_rate_Layer_4': 0.10883915304479137, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006831747547888243, 'l1_Layer_2': 0.004822539929330706, 'l1_Layer_3': 1.417693437970264e-05, 'l1_Layer_4': 0.0001748877873755692, 'n_units_Layer_1': 185, 'n_units_Layer_2': 185, 'n_units_Layer_3': 85, 'n_units_Layer_4': 135}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.40 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.18 | sMAPE for Test Set is: 35.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:47:01,073]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:47:05,658]\u001b[0m Trial 1080 finished with value: 24.845882254064197 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005703804738928691, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18308411928505572, 'dropout_rate_Layer_2': 0.17905984056794236, 'dropout_rate_Layer_3': 0.3244655746306248, 'dropout_rate_Layer_4': 0.09275337679714887, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.784522698529489e-05, 'l1_Layer_2': 2.219113391654709e-05, 'l1_Layer_3': 0.00026818844938317167, 'l1_Layer_4': 0.0016439116151006794, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275, 'n_units_Layer_4': 280}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.85 | sMAPE for Validation Set is: 18.35% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.02 | sMAPE for Test Set is: 35.57% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:47:08,700]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:47:12,526]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:47:13,386]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:47:14,723]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:47:22,485]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:47:30,338]\u001b[0m Trial 1081 finished with value: 25.098346026564496 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006080341168027332, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18698382132497127, 'dropout_rate_Layer_2': 0.20093020355541777, 'dropout_rate_Layer_3': 0.32520366924629884, 'dropout_rate_Layer_4': 0.07693593717898808, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.560205749380211e-05, 'l1_Layer_2': 2.1847146349639024e-05, 'l1_Layer_3': 0.0001369397463130082, 'l1_Layer_4': 0.001602785704024313, 'n_units_Layer_1': 275, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275, 'n_units_Layer_4': 280}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.10 | sMAPE for Validation Set is: 18.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.81 | sMAPE for Test Set is: 35.44% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:47:58,047]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:48:02,055]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:48:07,084]\u001b[0m Trial 1087 finished with value: 23.600468153991567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012212606344582336, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006584107203639123, 'dropout_rate_Layer_2': 0.30807216944547255, 'dropout_rate_Layer_3': 0.06256463968019248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024293481064840982, 'l1_Layer_2': 0.00027776599370735557, 'l1_Layer_3': 7.352617842900031e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 160, 'n_units_Layer_3': 240}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.60 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.19 | sMAPE for Test Set is: 33.64% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:48:10,401]\u001b[0m Trial 1089 finished with value: 23.451536585194656 and parameters: {'n_hidden': 3, 'learning_rate': 0.001003304157876978, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007637786328039756, 'dropout_rate_Layer_2': 0.2979857347031758, 'dropout_rate_Layer_3': 0.08012371375024942, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017645755106498158, 'l1_Layer_2': 0.0002695494902938143, 'l1_Layer_3': 4.765092286775884e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 235}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.45 | sMAPE for Validation Set is: 17.46% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.96 | sMAPE for Test Set is: 34.77% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 25.36 | sMAPE for Validation Set is: 18.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.00 | sMAPE for Test Set is: 35.35% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:48:10,522]\u001b[0m Trial 1091 finished with value: 25.358747771282435 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006728268361539318, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1737928440864776, 'dropout_rate_Layer_2': 0.19902308396614599, 'dropout_rate_Layer_3': 0.34256033064138564, 'dropout_rate_Layer_4': 0.10063132363368199, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.205511652043714e-05, 'l1_Layer_2': 1.775895357209679e-05, 'l1_Layer_3': 0.00012920136427748208, 'l1_Layer_4': 0.0013302880679619304, 'n_units_Layer_1': 275, 'n_units_Layer_2': 165, 'n_units_Layer_3': 265, 'n_units_Layer_4': 280}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:48:31,493]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:48:37,619]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:48:43,651]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:48:54,326]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:48:59,768]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:49:07,464]\u001b[0m Trial 1093 finished with value: 23.096061154988007 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012663321361353244, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01892370099117577, 'dropout_rate_Layer_2': 0.29709509012344676, 'dropout_rate_Layer_3': 0.08196179991291919, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023271279868783442, 'l1_Layer_2': 0.0002868755401786955, 'l1_Layer_3': 7.173551590479808e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 175, 'n_units_Layer_3': 235}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.10 | sMAPE for Validation Set is: 17.29% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.06 | sMAPE for Test Set is: 34.26% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:49:08,219]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:49:15,479]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:49:20,554]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:49:20,909]\u001b[0m Trial 1096 finished with value: 23.40897371300328 and parameters: {'n_hidden': 3, 'learning_rate': 0.001156259598294254, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006036508280323701, 'dropout_rate_Layer_2': 0.3094021512304242, 'dropout_rate_Layer_3': 0.048511991463086435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015817067621551578, 'l1_Layer_2': 0.00018279755167656338, 'l1_Layer_3': 6.745813219765551e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 230}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.41 | sMAPE for Validation Set is: 17.47% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 19.95 | sMAPE for Test Set is: 33.87% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:49:26,493]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:49:30,009]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:49:34,963]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:49:37,878]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:49:43,061]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:49:58,325]\u001b[0m Trial 1107 finished with value: 23.875380976267184 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026779311958412154, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0013520391194234852, 'dropout_rate_Layer_2': 0.08553216496578131, 'dropout_rate_Layer_3': 0.13613973962010972, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7424601389983195e-05, 'l1_Layer_2': 0.004093107967638014, 'l1_Layer_3': 0.0009640857820912982, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 200}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.88 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.27 | sMAPE for Test Set is: 36.73% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:50:01,423]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:06,129]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:06,641]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:12,126]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:19,939]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:20,351]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:20,936]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:29,129]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:33,334]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:33,864]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:40,129]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:43,345]\u001b[0m Trial 1109 finished with value: 24.81151656603014 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007251367349423702, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17783672152541105, 'dropout_rate_Layer_2': 0.18714044972749866, 'dropout_rate_Layer_3': 0.33078830377884383, 'dropout_rate_Layer_4': 0.08558992809087651, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.8457962342265276e-05, 'l1_Layer_2': 1.5568223199495166e-05, 'l1_Layer_3': 0.000273504423763602, 'l1_Layer_4': 0.0008567774843083521, 'n_units_Layer_1': 285, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275, 'n_units_Layer_4': 285}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.81 | sMAPE for Validation Set is: 18.39% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.43 | sMAPE for Test Set is: 34.89% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:50:46,443]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:58,726]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:06,301]\u001b[0m Trial 1122 finished with value: 24.409650116779286 and parameters: {'n_hidden': 3, 'learning_rate': 0.001188444397448797, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016093584901165116, 'dropout_rate_Layer_2': 0.31389953864455195, 'dropout_rate_Layer_3': 0.07465219658104552, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020494168969143215, 'l1_Layer_2': 0.0003036924832833843, 'l1_Layer_3': 5.058658903457827e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 155, 'n_units_Layer_3': 245}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.41 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.66 | sMAPE for Test Set is: 34.85% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:51:10,331]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:14,752]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:20,440]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:24,179]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:25,856]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:31,253]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:34,165]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:36,796]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:47,733]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:47,874]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:59,038]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:52:08,314]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:52:14,526]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:52:14,982]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:52:15,079]\u001b[0m Trial 1131 finished with value: 23.820048835543947 and parameters: {'n_hidden': 3, 'learning_rate': 0.001422683205032482, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028893762244342657, 'dropout_rate_Layer_2': 0.2901867984533195, 'dropout_rate_Layer_3': 0.09335866645918352, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002896884494407201, 'l1_Layer_2': 0.000405729967960845, 'l1_Layer_3': 0.00013671418992122184, 'n_units_Layer_1': 65, 'n_units_Layer_2': 185, 'n_units_Layer_3': 235}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.82 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.50 | sMAPE for Test Set is: 37.07% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:52:34,663]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.57 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.46 | sMAPE for Test Set is: 37.68% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:52:45,600]\u001b[0m Trial 1141 finished with value: 25.574681211046226 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006020154791875917, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19231706284889746, 'dropout_rate_Layer_2': 0.1384476518257075, 'dropout_rate_Layer_3': 0.32672139442995646, 'dropout_rate_Layer_4': 0.08227660725281324, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.52345944032219e-05, 'l1_Layer_2': 1.1327742285455809e-05, 'l1_Layer_3': 0.00048033077062073, 'l1_Layer_4': 0.0008098523656062091, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 300, 'n_units_Layer_4': 275}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:52:52,363]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:52:53,808]\u001b[0m Trial 1127 finished with value: 23.384506861424587 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009217115544130769, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024670616488532065, 'dropout_rate_Layer_2': 0.2954572877283568, 'dropout_rate_Layer_3': 0.0948786924516714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025535981053606755, 'l1_Layer_2': 0.00023563376857371727, 'l1_Layer_3': 9.160843203800353e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 225}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.38 | sMAPE for Validation Set is: 17.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 21.93 | sMAPE for Test Set is: 35.43% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:52:59,954]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:09,286]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:14,379]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:18,914]\u001b[0m Trial 1142 finished with value: 25.230265251139468 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006095341220367679, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19258102464196153, 'dropout_rate_Layer_2': 0.1385827437281607, 'dropout_rate_Layer_3': 0.325887097522277, 'dropout_rate_Layer_4': 0.08603206723735636, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.811246249693272e-05, 'l1_Layer_2': 1.441091506427647e-05, 'l1_Layer_3': 0.00032675397778657913, 'l1_Layer_4': 0.00311304102234933, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 300, 'n_units_Layer_4': 275}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.23 | sMAPE for Validation Set is: 18.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.11 | sMAPE for Test Set is: 35.82% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:53:21,634]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:23,885]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:28,175]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:33,577]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:36,660]\u001b[0m Trial 1143 finished with value: 25.341643051642723 and parameters: {'n_hidden': 4, 'learning_rate': 0.000601989641231169, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19246339120339245, 'dropout_rate_Layer_2': 0.17334568669135667, 'dropout_rate_Layer_3': 0.3269397665040476, 'dropout_rate_Layer_4': 0.0837686293735092, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.5861627022589e-05, 'l1_Layer_2': 1.1604449762100894e-05, 'l1_Layer_3': 0.0004854898547682985, 'l1_Layer_4': 7.461245231009664e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 300, 'n_units_Layer_4': 275}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.34 | sMAPE for Validation Set is: 18.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 34.78% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:53:37,091]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:37,136]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:38,184]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:49,073]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:51,169]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:54:07,820]\u001b[0m Trial 1155 finished with value: 24.27801351360769 and parameters: {'n_hidden': 3, 'learning_rate': 0.005075880436764944, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05966689570294333, 'dropout_rate_Layer_2': 0.25243013913600654, 'dropout_rate_Layer_3': 0.10324396633818982, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.3601909235896994e-05, 'l1_Layer_2': 0.01298614941452018, 'l1_Layer_3': 0.0005788091784133786, 'n_units_Layer_1': 135, 'n_units_Layer_2': 285, 'n_units_Layer_3': 225}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.28 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 22.83 | sMAPE for Test Set is: 36.74% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:54:13,347]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:54:18,453]\u001b[0m Trial 1159 finished with value: 26.784053599084107 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014013463356675716, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23415637976486053, 'dropout_rate_Layer_2': 0.19782320779317378, 'dropout_rate_Layer_3': 0.2789921639619403, 'dropout_rate_Layer_4': 0.10562096037872085, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0010604357559910386, 'l1_Layer_2': 0.0025399124051703054, 'l1_Layer_3': 4.10577987912489e-05, 'l1_Layer_4': 0.00029632537656803685, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 95, 'n_units_Layer_4': 110}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.78 | sMAPE for Validation Set is: 19.53% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.15 | sMAPE for Test Set is: 37.06% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:54:25,207]\u001b[0m Trial 1160 finished with value: 26.424744276982665 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014296544576841077, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2347603895172459, 'dropout_rate_Layer_2': 0.19072256138000937, 'dropout_rate_Layer_3': 0.279834498223976, 'dropout_rate_Layer_4': 0.10304222409605414, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0010806177003533444, 'l1_Layer_2': 0.0026017556160513643, 'l1_Layer_3': 3.0072030265376247e-05, 'l1_Layer_4': 3.2289468620825245e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 95, 'n_units_Layer_4': 285}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.42 | sMAPE for Validation Set is: 19.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.64 | sMAPE for Test Set is: 36.81% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:54:37,698]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:54:43,307]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:54:46,201]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:54:51,547]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:54:53,135]\u001b[0m Trial 1162 finished with value: 27.144147555783693 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014425370607931804, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23746643416157828, 'dropout_rate_Layer_2': 0.1719041948192153, 'dropout_rate_Layer_3': 0.3354294043330042, 'dropout_rate_Layer_4': 0.1182464399307156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00236150887021288, 'l1_Layer_2': 0.003554213858479801, 'l1_Layer_3': 3.933905684082098e-05, 'l1_Layer_4': 0.00030582394320994514, 'n_units_Layer_1': 160, 'n_units_Layer_2': 185, 'n_units_Layer_3': 95, 'n_units_Layer_4': 110}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.14 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.12 | sMAPE for Test Set is: 37.54% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:54:57,969]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:01,574]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:12,481]\u001b[0m Trial 1158 finished with value: 25.175225426431478 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006967267185430253, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1856494616465154, 'dropout_rate_Layer_2': 0.16254097393813857, 'dropout_rate_Layer_3': 0.3102084580694039, 'dropout_rate_Layer_4': 0.07118701116733113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.016333406226477e-05, 'l1_Layer_2': 1.6542318437927054e-05, 'l1_Layer_3': 0.0002297988516404805, 'l1_Layer_4': 0.0018896444863313407, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 295, 'n_units_Layer_4': 290}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:12,543]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.18 | sMAPE for Validation Set is: 18.55% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.32 | sMAPE for Test Set is: 35.82% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:55:19,729]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:24,307]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:27,566]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:28,016]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:36,352]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:39,460]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:43,738]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:47,189]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:50,283]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:55:57,715]\u001b[0m Trial 1175 finished with value: 24.16667934615297 and parameters: {'n_hidden': 3, 'learning_rate': 0.004246581358166019, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.053396739393888226, 'dropout_rate_Layer_2': 0.05614453791417043, 'dropout_rate_Layer_3': 0.10596912393832227, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.079383071877313e-05, 'l1_Layer_2': 0.014272623609746913, 'l1_Layer_3': 0.000967091924495104, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 255}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.17 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 23.24 | sMAPE for Test Set is: 37.25% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:56:01,461]\u001b[0m Trial 1167 finished with value: 25.311114748198005 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005441215328286868, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24429292459555618, 'dropout_rate_Layer_2': 0.18253213253911316, 'dropout_rate_Layer_3': 0.30688481795068545, 'dropout_rate_Layer_4': 0.09362425632713718, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.94500838254916e-05, 'l1_Layer_2': 1.0255932831477364e-05, 'l1_Layer_3': 0.00018436447381758829, 'l1_Layer_4': 0.004103839215647665, 'n_units_Layer_1': 295, 'n_units_Layer_2': 175, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.31 | sMAPE for Validation Set is: 18.66% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.28 | sMAPE for Test Set is: 36.00% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:56:09,165]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:56:10,230]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:56:15,611]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:56:21,177]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:56:22,887]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:56:27,950]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:56:29,624]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:56:35,145]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:56:39,714]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:56:50,767]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:56:56,614]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:56:56,991]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:57:04,621]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:57:06,591]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:57:11,765]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:57:16,972]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:57:23,561]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:57:30,339]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:57:32,185]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:57:48,088]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:57:53,491]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:58:01,448]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:58:20,040]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:58:25,375]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:58:37,076]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:58:44,404]\u001b[0m Trial 1206 finished with value: 24.187038917239594 and parameters: {'n_hidden': 3, 'learning_rate': 0.0064524213628585425, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05462014946151217, 'dropout_rate_Layer_2': 0.26700906347752584, 'dropout_rate_Layer_3': 0.09315094352011094, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.3392798047053186e-05, 'l1_Layer_2': 0.01194201994116385, 'l1_Layer_3': 0.0006688493039832195, 'n_units_Layer_1': 185, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.19 | sMAPE for Validation Set is: 18.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.40 | sMAPE for Test Set is: 35.50% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:58:48,815]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:05,115]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:08,257]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:12,195]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:13,297]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:18,067]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:23,198]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:28,229]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:28,949]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:34,396]\u001b[0m Trial 1203 finished with value: 24.320153725522825 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008432943247655645, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19502272937336954, 'dropout_rate_Layer_2': 0.15622860147336473, 'dropout_rate_Layer_3': 0.32704923127249863, 'dropout_rate_Layer_4': 0.07964233645434947, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020423260242971005, 'l1_Layer_2': 1.4972692352055587e-05, 'l1_Layer_3': 0.0004193006430791518, 'l1_Layer_4': 0.0020767439056631576, 'n_units_Layer_1': 285, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290, 'n_units_Layer_4': 180}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.32 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.51 | sMAPE for Test Set is: 35.60% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:59:39,271]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:48,219]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:58,150]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:00:01,273]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:00:23,974]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:00:27,987]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:00:31,680]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:00:34,181]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:00:40,969]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:00:49,722]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:00:52,667]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:00:56,631]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:01:02,099]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:01:05,313]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:01:09,703]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:01:12,320]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:01:24,134]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:01:30,600]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:01:36,467]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:01:42,312]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.34 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 19.96 | sMAPE for Test Set is: 33.48% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:01:44,869]\u001b[0m Trial 1221 finished with value: 23.338321757235565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008788953656027755, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018562518337807324, 'dropout_rate_Layer_2': 0.29323611847174846, 'dropout_rate_Layer_3': 0.07128516332035484, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002445350249070639, 'l1_Layer_2': 0.00010196389001420159, 'l1_Layer_3': 5.97911892398946e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:01:48,995]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:01:51,065]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:01:56,496]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:02:00,005]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:02:00,173]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:02:04,507]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:02:08,433]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:02:12,803]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:02:13,583]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:02:23,870]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:02:25,280]\u001b[0m Trial 1232 finished with value: 25.668456899245133 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007083070090467203, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2113966766035555, 'dropout_rate_Layer_2': 0.1759709483319295, 'dropout_rate_Layer_3': 0.3316784989652168, 'dropout_rate_Layer_4': 0.07470566377758152, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002069471806655091, 'l1_Layer_2': 1.4906391182696747e-05, 'l1_Layer_3': 0.0003968178800838316, 'l1_Layer_4': 0.000932203012667777, 'n_units_Layer_1': 285, 'n_units_Layer_2': 135, 'n_units_Layer_3': 295, 'n_units_Layer_4': 280}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.67 | sMAPE for Validation Set is: 18.68% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 20.97 | sMAPE for Test Set is: 35.78% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:02:27,140]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:02:41,828]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:02:55,716]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:03:17,161]\u001b[0m Trial 1251 finished with value: 25.493887775672437 and parameters: {'n_hidden': 4, 'learning_rate': 0.000546347014176466, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21117442873496772, 'dropout_rate_Layer_2': 0.18544345865158726, 'dropout_rate_Layer_3': 0.3512715159645422, 'dropout_rate_Layer_4': 0.044512258534298965, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.846017490784108e-05, 'l1_Layer_2': 2.638092855052105e-05, 'l1_Layer_3': 0.00024409123364722905, 'l1_Layer_4': 0.0019433429445939831, 'n_units_Layer_1': 275, 'n_units_Layer_2': 145, 'n_units_Layer_3': 290, 'n_units_Layer_4': 285}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.49 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.48 | sMAPE for Test Set is: 36.12% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:03:20,637]\u001b[0m Trial 1254 finished with value: 23.732098371036894 and parameters: {'n_hidden': 3, 'learning_rate': 0.003172755512752398, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06996567608722085, 'dropout_rate_Layer_2': 0.2998640955528191, 'dropout_rate_Layer_3': 0.11664871450376985, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.574113593823459e-05, 'l1_Layer_2': 0.012984339615258524, 'l1_Layer_3': 0.0003850432980765287, 'n_units_Layer_1': 185, 'n_units_Layer_2': 300, 'n_units_Layer_3': 285}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.73 | sMAPE for Validation Set is: 17.70% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.34 | sMAPE for Test Set is: 35.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:03:26,099]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:03:32,302]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:03:37,532]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:03:55,920]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:01,046]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:08,638]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:12,001]\u001b[0m Trial 1246 finished with value: 27.449819462028515 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005554797363069512, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20290733349057263, 'dropout_rate_Layer_2': 0.03645152241626373, 'dropout_rate_Layer_3': 0.373718485618107, 'dropout_rate_Layer_4': 0.08172491655941443, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002813784636772035, 'l1_Layer_2': 0.0035650235398769752, 'l1_Layer_3': 1.3520792844198097e-05, 'l1_Layer_4': 0.00010031513777733799, 'n_units_Layer_1': 185, 'n_units_Layer_2': 180, 'n_units_Layer_3': 75, 'n_units_Layer_4': 120}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.45 | sMAPE for Validation Set is: 19.77% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.87 | sMAPE for Test Set is: 36.82% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:04:15,783]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:16,053]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:17,807]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:19,665]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:28,226]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:29,009]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:30,899]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:33,146]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:37,449]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:38,461]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:47,136]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:51,631]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:53,110]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:57,856]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:04:59,210]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:00,574]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:07,861]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:13,239]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:16,219]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:28,056]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:28,225]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:38,343]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:41,424]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:44,482]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:48,337]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:53,274]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:59,661]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:05:59,856]\u001b[0m Trial 1285 finished with value: 24.67058849440829 and parameters: {'n_hidden': 3, 'learning_rate': 0.003323256820375692, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07079091626824607, 'dropout_rate_Layer_2': 0.22577240526693487, 'dropout_rate_Layer_3': 0.09686684813484336, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.447510741653937e-05, 'l1_Layer_2': 0.01755881362784161, 'l1_Layer_3': 0.0007272576408014572, 'n_units_Layer_1': 170, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.67 | sMAPE for Validation Set is: 18.35% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.98 | sMAPE for Test Set is: 36.96% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:06:04,768]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:04,976]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:14,252]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:17,996]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:22,019]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:27,202]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:30,008]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:33,894]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:40,832]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:45,213]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:48,329]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:51,449]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:06:56,135]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:00,062]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:01,142]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:08,456]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:09,092]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:15,112]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:15,875]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:16,083]\u001b[0m Trial 1300 finished with value: 25.581725631332933 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021618489908090126, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25771497445592273, 'dropout_rate_Layer_2': 0.03060046309304902, 'dropout_rate_Layer_3': 0.38919050286588786, 'dropout_rate_Layer_4': 0.13943004813514095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005743992384147588, 'l1_Layer_2': 0.004431214912906415, 'l1_Layer_3': 1.832234759281939e-05, 'l1_Layer_4': 4.3816193211360236e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 110, 'n_units_Layer_3': 90, 'n_units_Layer_4': 195}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.58 | sMAPE for Validation Set is: 18.99% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.97 | sMAPE for Test Set is: 36.91% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:07:21,297]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:24,369]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:27,401]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:33,544]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:36,688]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:37,389]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:44,845]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:46,044]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:52,861]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:53,540]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:59,736]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:08:01,488]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:08:06,326]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:08:09,046]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:08:19,760]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:08:30,006]\u001b[0m Trial 1326 finished with value: 26.09165297555968 and parameters: {'n_hidden': 4, 'learning_rate': 0.002309647004751028, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24221836724106016, 'dropout_rate_Layer_2': 0.04900372226997075, 'dropout_rate_Layer_3': 0.3874477858258893, 'dropout_rate_Layer_4': 0.12366469681143578, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004871993618067361, 'l1_Layer_2': 0.0021394905393609725, 'l1_Layer_3': 1.8458452837546813e-05, 'l1_Layer_4': 4.151861146378282e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 100, 'n_units_Layer_3': 110, 'n_units_Layer_4': 185}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.09 | sMAPE for Validation Set is: 19.28% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.26 | sMAPE for Test Set is: 38.14% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:08:41,523]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:08:43,957]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:08:49,836]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:08:51,419]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:00,121]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:01,255]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:07,847]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:10,250]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:14,812]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:19,011]\u001b[0m Trial 1315 finished with value: 25.15522658923894 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005461325253799919, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2614921837281224, 'dropout_rate_Layer_2': 0.1897295446957767, 'dropout_rate_Layer_3': 0.3039398907299068, 'dropout_rate_Layer_4': 0.05689922239128217, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010134426625084113, 'l1_Layer_2': 0.0015976055565374938, 'l1_Layer_3': 0.00010120232410639512, 'l1_Layer_4': 0.001927903580161628, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 280, 'n_units_Layer_4': 230}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.16 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.34 | sMAPE for Test Set is: 34.96% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:09:25,609]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:31,782]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:38,114]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:43,582]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:50,843]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.15 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.27 | sMAPE for Test Set is: 35.57% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:09:53,769]\u001b[0m Trial 1329 finished with value: 25.153756115130207 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006138236966444354, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21439328122472415, 'dropout_rate_Layer_2': 0.02685575715413409, 'dropout_rate_Layer_3': 0.34261760277053077, 'dropout_rate_Layer_4': 0.13609351968962036, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0028040338783840795, 'l1_Layer_2': 0.0030764782095604273, 'l1_Layer_3': 2.628799876400431e-05, 'l1_Layer_4': 5.75241227315562e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 105, 'n_units_Layer_3': 90, 'n_units_Layer_4': 100}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:56,593]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:57,307]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:10:07,484]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:10:41,708]\u001b[0m Trial 1337 finished with value: 25.376028963058804 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005921954456071435, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21159585828722485, 'dropout_rate_Layer_2': 0.028519539207476012, 'dropout_rate_Layer_3': 0.3725689821793369, 'dropout_rate_Layer_4': 0.10109990608900515, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0029546615696224503, 'l1_Layer_2': 0.0031354676477067566, 'l1_Layer_3': 2.623957881810691e-05, 'l1_Layer_4': 5.579601911110352e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 105, 'n_units_Layer_3': 90, 'n_units_Layer_4': 100}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.38 | sMAPE for Validation Set is: 18.74% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.93 | sMAPE for Test Set is: 35.05% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:10:52,221]\u001b[0m Trial 1347 finished with value: 23.2074817702546 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009268441348053243, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020457109408659892, 'dropout_rate_Layer_2': 0.26940089243502097, 'dropout_rate_Layer_3': 0.08153675105663478, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002556317453643618, 'l1_Layer_2': 0.0004269350934160754, 'l1_Layer_3': 8.612558039341357e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.21 | sMAPE for Validation Set is: 17.25% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.47 | sMAPE for Test Set is: 34.16% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:10:52,726]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:11:00,209]\u001b[0m Trial 1345 finished with value: 25.22069168454428 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005551908914973485, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28999423390473833, 'dropout_rate_Layer_2': 0.20797403697433514, 'dropout_rate_Layer_3': 0.30747315807787395, 'dropout_rate_Layer_4': 0.04639277482651806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001119534863582317, 'l1_Layer_2': 1.012945946741823e-05, 'l1_Layer_3': 0.00013190595037316445, 'l1_Layer_4': 0.0055843438076165946, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275, 'n_units_Layer_4': 235}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.22 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.90 | sMAPE for Test Set is: 35.69% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:11:07,947]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:11:13,051]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:11:24,298]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:11:26,895]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:11:30,579]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:11:37,003]\u001b[0m Trial 1344 finished with value: 24.66617230879251 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005779599322973697, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1747897995649863, 'dropout_rate_Layer_2': 0.029349310898893442, 'dropout_rate_Layer_3': 0.268111172100341, 'dropout_rate_Layer_4': 0.10221949002237514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003020478889478052, 'l1_Layer_2': 0.0033558574348184146, 'l1_Layer_3': 1.426051416070863e-05, 'l1_Layer_4': 9.73669993052418e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 90, 'n_units_Layer_4': 95}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.67 | sMAPE for Validation Set is: 18.17% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.73 | sMAPE for Test Set is: 34.58% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:11:41,119]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:11:41,970]\u001b[0m Trial 1350 finished with value: 23.593541852009363 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013223026478747482, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015425476363410452, 'dropout_rate_Layer_2': 0.26650456255603, 'dropout_rate_Layer_3': 0.07642054966437224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026460271918693934, 'l1_Layer_2': 0.00010029288329092358, 'l1_Layer_3': 9.68307783418449e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 205, 'n_units_Layer_3': 260}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.59 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 21.20 | sMAPE for Test Set is: 34.97% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:11:44,676]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:11:53,510]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:12:00,704]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:12:05,999]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:12:14,088]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:12:19,830]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:12:24,597]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:12:28,433]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:12:29,957]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:12:37,384]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:12:45,061]\u001b[0m Trial 1356 finished with value: 24.688806110818348 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006811814962540974, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26350219237447703, 'dropout_rate_Layer_2': 0.18591386193478823, 'dropout_rate_Layer_3': 0.2989120829563345, 'dropout_rate_Layer_4': 0.09163421008828602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000199984317069359, 'l1_Layer_2': 0.0011284420579639038, 'l1_Layer_3': 0.00015698648824519248, 'l1_Layer_4': 0.0016659168270044353, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285, 'n_units_Layer_4': 265}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.69 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.71 | sMAPE for Test Set is: 34.71% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:12:45,567]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:13:25,776]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:13:30,602]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:13:40,858]\u001b[0m Trial 1370 finished with value: 27.218940001821608 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005424992435856871, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16196888583498656, 'dropout_rate_Layer_2': 0.018651354641458708, 'dropout_rate_Layer_3': 0.307323563536588, 'dropout_rate_Layer_4': 0.10340499398438972, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.010205569368934145, 'l1_Layer_2': 0.0011107176772929173, 'l1_Layer_3': 6.172541488988166e-05, 'l1_Layer_4': 9.224726264806774e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120, 'n_units_Layer_4': 95}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.22 | sMAPE for Validation Set is: 19.57% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.94 | sMAPE for Test Set is: 36.72% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:13:45,809]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:13:49,897]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:13:55,088]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:13:55,838]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:14:05,149]\u001b[0m Trial 1371 finished with value: 24.585218583097202 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005458799290423854, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26806846560070086, 'dropout_rate_Layer_2': 0.19605572467398258, 'dropout_rate_Layer_3': 0.293600727759017, 'dropout_rate_Layer_4': 0.09506929997361278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013363572212459098, 'l1_Layer_2': 0.0012817741600453746, 'l1_Layer_3': 0.00010698464441326666, 'l1_Layer_4': 0.0014834799105994442, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 280, 'n_units_Layer_4': 255}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.59 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.87 | sMAPE for Test Set is: 34.77% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:14:05,555]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:14:10,466]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:14:14,856]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:14:19,071]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:14:20,170]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:14:25,772]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:14:28,525]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:14:35,182]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:14:39,682]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:14:56,066]\u001b[0m Trial 1373 finished with value: 24.162030170850205 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005886367717652144, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16532548797643423, 'dropout_rate_Layer_2': 0.0004925505870632535, 'dropout_rate_Layer_3': 0.3093698918601382, 'dropout_rate_Layer_4': 0.10015712089354487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003267597193812435, 'l1_Layer_2': 0.0010152252147997895, 'l1_Layer_3': 6.431401318496725e-05, 'l1_Layer_4': 9.779766458637661e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 85, 'n_units_Layer_3': 135, 'n_units_Layer_4': 95}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.16 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.19 | sMAPE for Test Set is: 34.03% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:14:59,624]\u001b[0m Trial 1379 finished with value: 24.755293475480638 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006605173162199982, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2462705042579174, 'dropout_rate_Layer_2': 0.2091847522075518, 'dropout_rate_Layer_3': 0.29099768086842853, 'dropout_rate_Layer_4': 0.11343824464407955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00022612124687200193, 'l1_Layer_2': 0.001212367456741481, 'l1_Layer_3': 0.00014731581670854478, 'l1_Layer_4': 0.0009150677625612835, 'n_units_Layer_1': 280, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275, 'n_units_Layer_4': 255}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.76 | sMAPE for Validation Set is: 18.16% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.26 | sMAPE for Test Set is: 33.78% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:15:11,665]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:15:16,175]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:15:20,400]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:15:30,784]\u001b[0m Trial 1386 finished with value: 24.870698680241404 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007451032496580464, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2711202153792562, 'dropout_rate_Layer_2': 0.1883714842009353, 'dropout_rate_Layer_3': 0.3497904743048422, 'dropout_rate_Layer_4': 0.09414505229266343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001625465332623263, 'l1_Layer_2': 0.0010340080277457852, 'l1_Layer_3': 0.00013444729337709968, 'l1_Layer_4': 0.0007483437669023825, 'n_units_Layer_1': 280, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290, 'n_units_Layer_4': 250}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.87 | sMAPE for Validation Set is: 18.21% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.33 | sMAPE for Test Set is: 33.92% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:15:39,948]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:15:45,977]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:15:53,187]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:15:58,610]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:16:05,239]\u001b[0m Trial 1388 finished with value: 24.36504206125714 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005018027620719399, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2086851413827802, 'dropout_rate_Layer_2': 0.18464180050448958, 'dropout_rate_Layer_3': 0.33848949644947113, 'dropout_rate_Layer_4': 0.11401873003953636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.9104197496300212e-05, 'l1_Layer_2': 2.631836273992975e-05, 'l1_Layer_3': 0.00012242046673135776, 'l1_Layer_4': 0.0007900543051418217, 'n_units_Layer_1': 285, 'n_units_Layer_2': 165, 'n_units_Layer_3': 285, 'n_units_Layer_4': 260}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.37 | sMAPE for Validation Set is: 17.99% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.18 | sMAPE for Test Set is: 34.70% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:16:12,673]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:16:13,543]\u001b[0m Trial 1390 finished with value: 24.737640159113866 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005000414264623312, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2657797636241579, 'dropout_rate_Layer_2': 0.20765507215560777, 'dropout_rate_Layer_3': 0.28884021765948914, 'dropout_rate_Layer_4': 0.11105463822849401, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00016704235290714486, 'l1_Layer_2': 0.0011272005666783966, 'l1_Layer_3': 0.00011656494589907972, 'l1_Layer_4': 0.0008411710557697965, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265, 'n_units_Layer_4': 260}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.74 | sMAPE for Validation Set is: 18.21% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.68 | sMAPE for Test Set is: 35.41% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:16:20,133]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:16:23,521]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:16:29,284]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:16:34,693]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:16:35,290]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:16:44,464]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:16:50,744]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:16:55,631]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:17:00,277]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:17:14,852]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:17:14,894]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:17:25,939]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:17:26,752]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:17:33,717]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:17:40,335]\u001b[0m Trial 1405 finished with value: 23.76569233675076 and parameters: {'n_hidden': 3, 'learning_rate': 0.001166965360620153, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005989832161029381, 'dropout_rate_Layer_2': 0.23731828662147608, 'dropout_rate_Layer_3': 0.08976042753893101, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002543531285801963, 'l1_Layer_2': 0.00020232252518928898, 'l1_Layer_3': 0.0007799843060545788, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 255}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.77 | sMAPE for Validation Set is: 17.57% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.64 | sMAPE for Test Set is: 34.51% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:17:50,322]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:00,486]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:05,145]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:12,474]\u001b[0m Trial 1415 finished with value: 24.70326426309393 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006387896539811806, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27034415219542735, 'dropout_rate_Layer_2': 0.1955007042266735, 'dropout_rate_Layer_3': 0.2964756365080018, 'dropout_rate_Layer_4': 0.10867761383368038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00014373022531393787, 'l1_Layer_2': 0.0008665839356361164, 'l1_Layer_3': 0.00012336993768682802, 'l1_Layer_4': 0.00041460365659741266, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 285, 'n_units_Layer_4': 255}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.70 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.09 | sMAPE for Test Set is: 34.84% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:18:19,714]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:23,954]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:24,806]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:30,771]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:33,636]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:39,362]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:39,861]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:45,216]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.81 | sMAPE for Validation Set is: 18.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.92 | sMAPE for Test Set is: 34.78% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:18:47,888]\u001b[0m Trial 1413 finished with value: 24.813702998010296 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006614157199025801, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25751936855433444, 'dropout_rate_Layer_2': 0.19735182818028693, 'dropout_rate_Layer_3': 0.29407821817413404, 'dropout_rate_Layer_4': 0.10814902029623583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00021184692811495839, 'l1_Layer_2': 0.0011113132486151697, 'l1_Layer_3': 0.00012919687194304046, 'l1_Layer_4': 0.0007614161488907787, 'n_units_Layer_1': 285, 'n_units_Layer_2': 185, 'n_units_Layer_3': 285, 'n_units_Layer_4': 255}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:52,532]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:18:58,757]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:19:01,722]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:19:05,613]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:19:11,028]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:19:15,300]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:19:19,296]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:19:23,806]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:19:35,673]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:19:42,889]\u001b[0m Trial 1419 finished with value: 24.122016876946503 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005610890875491128, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27367302691986245, 'dropout_rate_Layer_2': 0.1738310687594151, 'dropout_rate_Layer_3': 0.30146759932584416, 'dropout_rate_Layer_4': 0.10629882287189525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00023048490614707308, 'l1_Layer_2': 0.0008713375226204359, 'l1_Layer_3': 7.255563582285944e-05, 'l1_Layer_4': 0.0006854156324658843, 'n_units_Layer_1': 230, 'n_units_Layer_2': 170, 'n_units_Layer_3': 275, 'n_units_Layer_4': 250}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.12 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.45 | sMAPE for Test Set is: 34.40% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:19:53,122]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:01,946]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:23,109]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:26,326]\u001b[0m Trial 1437 finished with value: 24.23343665734336 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006778630524659594, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26580091184258847, 'dropout_rate_Layer_2': 0.19810670576538122, 'dropout_rate_Layer_3': 0.28894294142796717, 'dropout_rate_Layer_4': 0.10334910736775896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00026404391653541223, 'l1_Layer_2': 0.0013255005785564418, 'l1_Layer_3': 0.00013201087540744044, 'l1_Layer_4': 0.0005989836741207923, 'n_units_Layer_1': 275, 'n_units_Layer_2': 190, 'n_units_Layer_3': 285, 'n_units_Layer_4': 260}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.23 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.20 | sMAPE for Test Set is: 34.01% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:20:30,254]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:34,687]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:36,525]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:37,255]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:38,103]\u001b[0m Trial 1430 finished with value: 24.281164638035737 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006484952285733177, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16413395030745748, 'dropout_rate_Layer_2': 0.03338075506677115, 'dropout_rate_Layer_3': 0.31393766974994486, 'dropout_rate_Layer_4': 0.11692622046040432, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005323761347346287, 'l1_Layer_2': 0.002278455952108234, 'l1_Layer_3': 3.6142606042632074e-05, 'l1_Layer_4': 0.0003532481861945062, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 150, 'n_units_Layer_4': 75}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.28 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.04 | sMAPE for Test Set is: 33.66% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:20:45,650]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:46,903]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:50,274]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:52,929]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:54,656]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:20:54,748]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:04,755]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:07,517]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:10,545]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:11,281]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:13,952]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:24,562]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:30,034]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:34,747]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:38,700]\u001b[0m Trial 1451 finished with value: 25.35537647203853 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006511698234597792, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2716396095573462, 'dropout_rate_Layer_2': 0.18376356556360057, 'dropout_rate_Layer_3': 0.2869263794861566, 'dropout_rate_Layer_4': 0.10197428455677988, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00023792198413548671, 'l1_Layer_2': 0.0016939674102033936, 'l1_Layer_3': 0.00010651995842251786, 'l1_Layer_4': 0.0005194163719601114, 'n_units_Layer_1': 275, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275, 'n_units_Layer_4': 265}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.36 | sMAPE for Validation Set is: 18.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.75 | sMAPE for Test Set is: 35.77% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:21:42,608]\u001b[0m Trial 1457 finished with value: 24.039518481591784 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010409205158794657, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 7.399004211900914e-05, 'dropout_rate_Layer_2': 0.29544822640056007, 'dropout_rate_Layer_3': 0.05501271684884165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003613860748182071, 'l1_Layer_2': 0.00016617555127209784, 'l1_Layer_3': 0.0006695088006420018, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 270}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.04 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.54 | sMAPE for Test Set is: 34.56% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:21:45,524]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:50,253]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:50,963]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:21:56,812]\u001b[0m Trial 1459 finished with value: 23.57761949292816 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034447088985919013, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040094720472845694, 'dropout_rate_Layer_2': 0.05496968039519277, 'dropout_rate_Layer_3': 0.0972588800078241, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.434525449086053e-05, 'l1_Layer_2': 0.001088315900358293, 'l1_Layer_3': 0.0007429617596836096, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.58 | sMAPE for Validation Set is: 17.41% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 21.98 | sMAPE for Test Set is: 35.54% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:21:58,886]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:04,539]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:05,606]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:10,767]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:15,577]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:16,119]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:21,973]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:27,206]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:32,507]\u001b[0m Trial 1471 finished with value: 23.866863092423817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009139252117608649, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022911787639374227, 'dropout_rate_Layer_2': 0.2520054928499883, 'dropout_rate_Layer_3': 0.10581729694520124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004521630519165486, 'l1_Layer_2': 0.00030113409478833315, 'l1_Layer_3': 5.6455110860406874e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 285, 'n_units_Layer_3': 235}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.87 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.65 | sMAPE for Test Set is: 34.75% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:22:37,569]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:40,775]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:49,138]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:23:07,021]\u001b[0m Trial 1464 finished with value: 24.383386108108084 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006444209794271589, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18414620988653685, 'dropout_rate_Layer_2': 0.02162722695058032, 'dropout_rate_Layer_3': 0.32536548821807015, 'dropout_rate_Layer_4': 0.08682509989203264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002875026809195093, 'l1_Layer_2': 0.0017773462417982617, 'l1_Layer_3': 6.669249820813545e-05, 'l1_Layer_4': 0.0001311824542361457, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 140, 'n_units_Layer_4': 75}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.38 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.34 | sMAPE for Test Set is: 34.28% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:23:15,347]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:23:30,013]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:23:34,490]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:23:39,155]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:23:44,974]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:23:50,426]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:23:53,127]\u001b[0m Trial 1482 finished with value: 24.302215152381738 and parameters: {'n_hidden': 3, 'learning_rate': 0.002613584200951882, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007258780856837654, 'dropout_rate_Layer_2': 0.3090335679520997, 'dropout_rate_Layer_3': 0.10041603469705655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004002936584717601, 'l1_Layer_2': 0.0072572055331719286, 'l1_Layer_3': 0.0004608611704755827, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 205}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.30 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 24.00 | sMAPE for Test Set is: 37.87% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:23:58,683]\u001b[0m Trial 1476 finished with value: 24.29256398432692 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006518677628396587, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1483778111983828, 'dropout_rate_Layer_2': 0.02417911878816146, 'dropout_rate_Layer_3': 0.2853055425810162, 'dropout_rate_Layer_4': 0.08774021796066958, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006002073792213403, 'l1_Layer_2': 0.0018584742584986922, 'l1_Layer_3': 0.00010212368913983488, 'l1_Layer_4': 0.00010633467337267495, 'n_units_Layer_1': 165, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135, 'n_units_Layer_4': 80}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.29 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.37 | sMAPE for Test Set is: 33.94% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:24:02,542]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:24:06,913]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:24:09,297]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:24:12,479]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:24:20,646]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:24:21,092]\u001b[0m Trial 1480 finished with value: 24.676958613007347 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007028097387063745, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28203236119026676, 'dropout_rate_Layer_2': 0.16763556044946287, 'dropout_rate_Layer_3': 0.29869148355687136, 'dropout_rate_Layer_4': 0.10752007817711709, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001930857873930447, 'l1_Layer_2': 0.0012406655267442016, 'l1_Layer_3': 0.00012745292882602094, 'l1_Layer_4': 0.0008764656352767107, 'n_units_Layer_1': 255, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290, 'n_units_Layer_4': 245}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.68 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.35 | sMAPE for Test Set is: 34.29% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:24:31,940]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:24:36,715]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:24:53,563]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:24:59,595]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:25:08,759]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:25:12,589]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:25:14,927]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:25:21,509]\u001b[0m Trial 1497 finished with value: 24.222707254784236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008276104475837592, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2851567477483169, 'dropout_rate_Layer_2': 0.15809521681465072, 'dropout_rate_Layer_3': 0.2952270876426678, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001597968398788621, 'l1_Layer_2': 0.0015346678047621432, 'l1_Layer_3': 7.813782244001449e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 200, 'n_units_Layer_3': 275}. Best is trial 966 with value: 22.864450461227914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.22 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.57 | sMAPE for Test Set is: 34.90% | rMAE for Test Set is: 0.64\n",
      "for 2023-01-01, MAE is:4.46 & sMAPE is:145.82% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 145.82% & 0.52\n",
      "for 2023-01-02, MAE is:69.93 & sMAPE is:86.72% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :37.19 & 116.27% & 1.14\n",
      "for 2023-01-03, MAE is:24.41 & sMAPE is:18.76% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :32.93 & 83.77% & 1.04\n",
      "for 2023-01-04, MAE is:15.35 & sMAPE is:13.30% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :28.54 & 66.15% & 0.83\n",
      "for 2023-01-05, MAE is:20.75 & sMAPE is:19.08% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :26.98 & 56.74% & 0.71\n",
      "for 2023-01-06, MAE is:16.32 & sMAPE is:15.78% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :25.20 & 49.91% & 0.62\n",
      "for 2023-01-07, MAE is:63.81 & sMAPE is:120.30% & rMAE is:3.02 ||| daily mean of MAE & sMAPE & rMAE till now are :30.72 & 59.97% & 0.96\n",
      "for 2023-01-08, MAE is:10.37 & sMAPE is:74.33% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :28.17 & 61.76% & 1.09\n",
      "for 2023-01-09, MAE is:52.24 & sMAPE is:86.54% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :30.85 & 64.51% & 1.18\n",
      "for 2023-01-10, MAE is:16.03 & sMAPE is:14.96% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :29.37 & 59.56% & 1.12\n",
      "for 2023-01-11, MAE is:30.72 & sMAPE is:54.00% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :29.49 & 59.05% & 1.10\n",
      "for 2023-01-12, MAE is:18.04 & sMAPE is:20.32% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :28.54 & 55.83% & 1.09\n",
      "for 2023-01-13, MAE is:19.76 & sMAPE is:24.78% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :27.86 & 53.44% & 1.08\n",
      "for 2023-01-14, MAE is:24.94 & sMAPE is:39.48% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :27.65 & 52.44% & 1.06\n",
      "for 2023-01-15, MAE is:6.83 & sMAPE is:40.19% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :26.26 & 51.62% & 1.03\n",
      "for 2023-01-16, MAE is:16.97 & sMAPE is:72.77% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :25.68 & 52.95% & 0.98\n",
      "for 2023-01-17, MAE is:23.86 & sMAPE is:137.16% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :25.58 & 57.90% & 0.93\n",
      "for 2023-01-18, MAE is:18.96 & sMAPE is:104.26% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :25.21 & 60.48% & 0.90\n",
      "for 2023-01-19, MAE is:27.42 & sMAPE is:59.61% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :25.32 & 60.43% & 0.88\n",
      "for 2023-01-20, MAE is:52.77 & sMAPE is:76.47% & rMAE is:3.68 ||| daily mean of MAE & sMAPE & rMAE till now are :26.70 & 61.23% & 1.02\n",
      "for 2023-01-21, MAE is:39.80 & sMAPE is:53.12% & rMAE is:3.70 ||| daily mean of MAE & sMAPE & rMAE till now are :27.32 & 60.85% & 1.14\n",
      "for 2023-01-22, MAE is:20.01 & sMAPE is:54.60% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :26.99 & 60.56% & 1.14\n",
      "for 2023-01-23, MAE is:21.83 & sMAPE is:31.85% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :26.76 & 59.31% & 1.11\n",
      "for 2023-01-24, MAE is:25.89 & sMAPE is:26.56% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :26.73 & 57.95% & 1.08\n",
      "for 2023-01-25, MAE is:26.41 & sMAPE is:26.57% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :26.72 & 56.69% & 1.05\n",
      "for 2023-01-26, MAE is:21.81 & sMAPE is:28.30% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :26.53 & 55.60% & 1.03\n",
      "for 2023-01-27, MAE is:23.77 & sMAPE is:45.91% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :26.42 & 55.24% & 1.01\n",
      "for 2023-01-28, MAE is:12.94 & sMAPE is:32.19% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :25.94 & 54.42% & 1.00\n",
      "for 2023-01-29, MAE is:26.00 & sMAPE is:31.86% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :25.95 & 53.64% & 1.00\n",
      "for 2023-01-30, MAE is:27.68 & sMAPE is:21.43% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :26.00 & 52.57% & 0.98\n",
      "for 2023-01-31, MAE is:14.58 & sMAPE is:11.14% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :25.63 & 51.23% & 0.96\n",
      "for 2023-02-01, MAE is:15.36 & sMAPE is:11.72% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :25.31 & 50.00% & 0.94\n",
      "for 2023-02-02, MAE is:21.41 & sMAPE is:16.54% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :25.19 & 48.98% & 0.92\n",
      "for 2023-02-03, MAE is:10.81 & sMAPE is:7.66% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :24.77 & 47.77% & 0.90\n",
      "for 2023-02-04, MAE is:14.77 & sMAPE is:12.41% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :24.49 & 46.76% & 0.88\n",
      "for 2023-02-05, MAE is:27.10 & sMAPE is:43.56% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :24.56 & 46.67% & 0.88\n",
      "for 2023-02-06, MAE is:18.21 & sMAPE is:13.77% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :24.39 & 45.78% & 0.88\n",
      "for 2023-02-07, MAE is:10.87 & sMAPE is:7.86% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :24.03 & 44.78% & 0.88\n",
      "for 2023-02-08, MAE is:8.76 & sMAPE is:6.55% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :23.64 & 43.80% & 0.87\n",
      "for 2023-02-09, MAE is:8.07 & sMAPE is:5.78% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :23.25 & 42.85% & 0.86\n",
      "for 2023-02-10, MAE is:11.17 & sMAPE is:8.42% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :22.96 & 42.01% & 0.87\n",
      "for 2023-02-11, MAE is:10.26 & sMAPE is:8.05% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :22.65 & 41.20% & 0.87\n",
      "for 2023-02-12, MAE is:19.02 & sMAPE is:14.86% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :22.57 & 40.59% & 0.86\n",
      "for 2023-02-13, MAE is:10.96 & sMAPE is:7.77% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :22.31 & 39.84% & 0.86\n",
      "for 2023-02-14, MAE is:8.13 & sMAPE is:5.89% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :21.99 & 39.09% & 0.87\n",
      "for 2023-02-15, MAE is:13.62 & sMAPE is:9.87% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :21.81 & 38.45% & 0.87\n",
      "for 2023-02-16, MAE is:10.06 & sMAPE is:6.89% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :21.56 & 37.78% & 0.88\n",
      "for 2023-02-17, MAE is:10.46 & sMAPE is:7.69% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :21.33 & 37.16% & 0.88\n",
      "for 2023-02-18, MAE is:11.21 & sMAPE is:8.93% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :21.12 & 36.58% & 0.89\n",
      "for 2023-02-19, MAE is:12.41 & sMAPE is:10.07% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :20.95 & 36.05% & 0.89\n",
      "for 2023-02-20, MAE is:11.21 & sMAPE is:8.49% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :20.76 & 35.51% & 0.89\n",
      "for 2023-02-21, MAE is:24.44 & sMAPE is:17.86% & rMAE is:2.79 ||| daily mean of MAE & sMAPE & rMAE till now are :20.83 & 35.17% & 0.93\n",
      "for 2023-02-22, MAE is:8.14 & sMAPE is:5.71% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :20.59 & 34.61% & 0.93\n",
      "for 2023-02-23, MAE is:14.14 & sMAPE is:10.39% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :20.47 & 34.16% & 0.94\n",
      "for 2023-02-24, MAE is:14.77 & sMAPE is:10.56% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :20.36 & 33.74% & 0.94\n",
      "for 2023-02-25, MAE is:10.74 & sMAPE is:7.70% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :20.19 & 33.27% & 0.94\n",
      "for 2023-02-26, MAE is:43.69 & sMAPE is:61.12% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :20.60 & 33.76% & 0.94\n",
      "for 2023-02-27, MAE is:16.66 & sMAPE is:15.40% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :20.54 & 33.44% & 0.94\n",
      "for 2023-02-28, MAE is:15.49 & sMAPE is:12.14% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :20.45 & 33.08% & 0.94\n",
      "for 2023-03-01, MAE is:13.56 & sMAPE is:9.71% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :20.34 & 32.69% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-02, MAE is:16.15 & sMAPE is:11.84% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :20.27 & 32.35% & 0.96\n",
      "for 2023-03-03, MAE is:16.58 & sMAPE is:12.14% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :20.21 & 32.02% & 0.97\n",
      "for 2023-03-04, MAE is:12.30 & sMAPE is:9.17% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :20.08 & 31.66% & 0.98\n",
      "for 2023-03-05, MAE is:24.35 & sMAPE is:18.95% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :20.15 & 31.46% & 0.97\n",
      "for 2023-03-06, MAE is:12.98 & sMAPE is:9.39% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :20.04 & 31.12% & 0.96\n",
      "for 2023-03-07, MAE is:16.85 & sMAPE is:13.59% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :19.99 & 30.86% & 0.96\n",
      "for 2023-03-08, MAE is:20.01 & sMAPE is:19.28% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :19.99 & 30.69% & 0.96\n",
      "for 2023-03-09, MAE is:37.87 & sMAPE is:48.15% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :20.25 & 30.94% & 0.95\n",
      "for 2023-03-10, MAE is:38.08 & sMAPE is:85.50% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :20.51 & 31.73% & 0.94\n",
      "for 2023-03-11, MAE is:33.06 & sMAPE is:101.52% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :20.69 & 32.73% & 0.93\n",
      "for 2023-03-12, MAE is:28.03 & sMAPE is:39.19% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :20.79 & 32.82% & 0.93\n",
      "for 2023-03-13, MAE is:54.23 & sMAPE is:96.00% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :21.26 & 33.70% & 0.92\n",
      "for 2023-03-14, MAE is:35.43 & sMAPE is:68.64% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :21.45 & 34.18% & 0.92\n",
      "for 2023-03-15, MAE is:23.06 & sMAPE is:18.65% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :21.47 & 33.97% & 0.91\n",
      "for 2023-03-16, MAE is:35.08 & sMAPE is:38.87% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :21.66 & 34.03% & 0.92\n",
      "for 2023-03-17, MAE is:19.65 & sMAPE is:31.50% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :21.63 & 34.00% & 0.92\n",
      "for 2023-03-18, MAE is:26.30 & sMAPE is:28.86% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :21.69 & 33.93% & 0.91\n",
      "for 2023-03-19, MAE is:15.44 & sMAPE is:17.29% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :21.61 & 33.72% & 0.91\n",
      "for 2023-03-20, MAE is:19.42 & sMAPE is:16.93% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :21.58 & 33.51% & 0.90\n",
      "for 2023-03-21, MAE is:10.35 & sMAPE is:8.66% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :21.44 & 33.20% & 0.89\n",
      "for 2023-03-22, MAE is:21.23 & sMAPE is:21.62% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :21.44 & 33.05% & 0.89\n",
      "for 2023-03-23, MAE is:19.34 & sMAPE is:24.61% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :21.41 & 32.95% & 0.90\n",
      "for 2023-03-24, MAE is:29.16 & sMAPE is:50.68% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :21.51 & 33.16% & 0.91\n",
      "for 2023-03-25, MAE is:28.79 & sMAPE is:72.21% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :21.59 & 33.63% & 0.91\n",
      "for 2023-03-26, MAE is:20.82 & sMAPE is:100.79% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :21.58 & 34.42% & 0.90\n",
      "for 2023-03-27, MAE is:33.43 & sMAPE is:35.41% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :21.72 & 34.43% & 0.90\n",
      "for 2023-03-28, MAE is:19.62 & sMAPE is:18.18% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :21.70 & 34.24% & 0.91\n",
      "for 2023-03-29, MAE is:36.34 & sMAPE is:59.64% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :21.86 & 34.53% & 0.91\n",
      "for 2023-03-30, MAE is:54.71 & sMAPE is:106.04% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :22.23 & 35.34% & 0.91\n",
      "for 2023-03-31, MAE is:14.11 & sMAPE is:72.41% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :22.14 & 35.75% & 0.91\n",
      "for 2023-04-01, MAE is:16.45 & sMAPE is:59.79% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :22.08 & 36.01% & 0.91\n",
      "for 2023-04-02, MAE is:21.88 & sMAPE is:110.06% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :22.08 & 36.82% & 0.91\n",
      "for 2023-04-03, MAE is:29.12 & sMAPE is:50.46% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :22.15 & 36.96% & 0.91\n",
      "for 2023-04-04, MAE is:35.38 & sMAPE is:63.30% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :22.29 & 37.24% & 0.91\n",
      "for 2023-04-05, MAE is:29.77 & sMAPE is:31.20% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :22.37 & 37.18% & 0.91\n",
      "for 2023-04-06, MAE is:27.71 & sMAPE is:37.76% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :22.43 & 37.19% & 0.90\n",
      "for 2023-04-07, MAE is:33.31 & sMAPE is:63.60% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :22.54 & 37.46% & 0.90\n",
      "for 2023-04-08, MAE is:25.96 & sMAPE is:42.98% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :22.58 & 37.51% & 0.89\n",
      "for 2023-04-09, MAE is:31.01 & sMAPE is:65.73% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :22.66 & 37.80% & 0.89\n",
      "for 2023-04-10, MAE is:28.45 & sMAPE is:63.65% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :22.72 & 38.06% & 0.89\n",
      "for 2023-04-11, MAE is:29.41 & sMAPE is:34.90% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :22.79 & 38.03% & 0.89\n",
      "for 2023-04-12, MAE is:62.79 & sMAPE is:105.85% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :23.18 & 38.69% & 0.89\n",
      "for 2023-04-13, MAE is:39.25 & sMAPE is:92.70% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :23.33 & 39.22% & 0.89\n",
      "for 2023-04-14, MAE is:51.16 & sMAPE is:91.78% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :23.60 & 39.72% & 0.90\n",
      "for 2023-04-15, MAE is:27.12 & sMAPE is:101.22% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :23.63 & 40.31% & 0.89\n",
      "for 2023-04-16, MAE is:29.44 & sMAPE is:111.07% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :23.69 & 40.97% & 0.89\n",
      "for 2023-04-17, MAE is:21.23 & sMAPE is:34.60% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :23.67 & 40.92% & 0.89\n",
      "for 2023-04-18, MAE is:13.31 & sMAPE is:13.61% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :23.57 & 40.66% & 0.89\n",
      "for 2023-04-19, MAE is:14.81 & sMAPE is:13.01% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :23.49 & 40.41% & 0.88\n",
      "for 2023-04-20, MAE is:19.96 & sMAPE is:21.26% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :23.46 & 40.23% & 0.88\n",
      "for 2023-04-21, MAE is:21.09 & sMAPE is:27.64% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :23.44 & 40.12% & 0.87\n",
      "for 2023-04-22, MAE is:20.92 & sMAPE is:40.12% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :23.41 & 40.12% & 0.87\n",
      "for 2023-04-23, MAE is:36.96 & sMAPE is:97.18% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :23.53 & 40.63% & 0.87\n",
      "for 2023-04-24, MAE is:20.88 & sMAPE is:26.24% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :23.51 & 40.50% & 0.87\n",
      "for 2023-04-25, MAE is:22.84 & sMAPE is:31.11% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :23.51 & 40.42% & 0.88\n",
      "for 2023-04-26, MAE is:10.54 & sMAPE is:9.21% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :23.39 & 40.15% & 0.88\n",
      "for 2023-04-27, MAE is:9.98 & sMAPE is:9.07% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :23.28 & 39.88% & 0.88\n",
      "for 2023-04-28, MAE is:8.92 & sMAPE is:8.44% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :23.16 & 39.62% & 0.87\n",
      "for 2023-04-29, MAE is:19.12 & sMAPE is:37.63% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :23.12 & 39.60% & 0.88\n",
      "for 2023-04-30, MAE is:17.25 & sMAPE is:38.53% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :23.07 & 39.59% & 0.88\n",
      "for 2023-05-01, MAE is:30.46 & sMAPE is:81.61% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :23.14 & 39.94% & 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-02, MAE is:11.16 & sMAPE is:10.48% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :23.04 & 39.70% & 0.88\n",
      "for 2023-05-03, MAE is:30.05 & sMAPE is:36.78% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :23.09 & 39.67% & 0.88\n",
      "for 2023-05-04, MAE is:11.08 & sMAPE is:12.57% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :23.00 & 39.45% & 0.88\n",
      "for 2023-05-05, MAE is:8.99 & sMAPE is:9.11% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :22.89 & 39.21% & 0.88\n",
      "for 2023-05-06, MAE is:13.46 & sMAPE is:16.11% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :22.81 & 39.03% & 0.88\n",
      "for 2023-05-07, MAE is:20.33 & sMAPE is:47.31% & rMAE is:2.94 ||| daily mean of MAE & sMAPE & rMAE till now are :22.79 & 39.09% & 0.90\n",
      "for 2023-05-08, MAE is:9.09 & sMAPE is:9.21% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :22.68 & 38.86% & 0.89\n",
      "for 2023-05-09, MAE is:18.95 & sMAPE is:23.57% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :22.66 & 38.74% & 0.89\n",
      "for 2023-05-10, MAE is:15.15 & sMAPE is:19.17% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :22.60 & 38.59% & 0.89\n",
      "for 2023-05-11, MAE is:10.50 & sMAPE is:14.58% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :22.50 & 38.41% & 0.89\n",
      "for 2023-05-12, MAE is:25.76 & sMAPE is:39.43% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :22.53 & 38.42% & 0.89\n",
      "for 2023-05-13, MAE is:32.46 & sMAPE is:74.15% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :22.60 & 38.68% & 0.89\n",
      "for 2023-05-14, MAE is:30.90 & sMAPE is:98.19% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :22.67 & 39.13% & 0.89\n",
      "for 2023-05-15, MAE is:33.23 & sMAPE is:73.07% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :22.74 & 39.38% & 0.89\n",
      "for 2023-05-16, MAE is:48.72 & sMAPE is:84.69% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :22.94 & 39.71% & 0.89\n",
      "for 2023-05-17, MAE is:17.14 & sMAPE is:34.37% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :22.89 & 39.67% & 0.89\n",
      "for 2023-05-18, MAE is:18.64 & sMAPE is:39.89% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :22.86 & 39.68% & 0.89\n",
      "for 2023-05-19, MAE is:18.59 & sMAPE is:31.55% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :22.83 & 39.62% & 0.89\n",
      "for 2023-05-20, MAE is:22.76 & sMAPE is:60.88% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :22.83 & 39.77% & 0.90\n",
      "for 2023-05-21, MAE is:28.28 & sMAPE is:93.62% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :22.87 & 40.15% & 0.90\n",
      "for 2023-05-22, MAE is:27.50 & sMAPE is:36.71% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :22.90 & 40.13% & 0.90\n",
      "for 2023-05-23, MAE is:8.02 & sMAPE is:9.67% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :22.80 & 39.91% & 0.89\n",
      "for 2023-05-24, MAE is:5.24 & sMAPE is:6.25% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :22.68 & 39.68% & 0.89\n",
      "for 2023-05-25, MAE is:13.46 & sMAPE is:20.22% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :22.61 & 39.55% & 0.89\n",
      "for 2023-05-26, MAE is:22.28 & sMAPE is:42.03% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :22.61 & 39.56% & 0.89\n",
      "for 2023-05-27, MAE is:21.69 & sMAPE is:31.40% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :22.60 & 39.51% & 0.89\n",
      "for 2023-05-28, MAE is:12.66 & sMAPE is:15.85% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :22.54 & 39.35% & 0.88\n",
      "for 2023-05-29, MAE is:7.86 & sMAPE is:7.67% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :22.44 & 39.13% & 0.88\n",
      "for 2023-05-30, MAE is:8.25 & sMAPE is:8.74% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :22.34 & 38.93% & 0.88\n",
      "for 2023-05-31, MAE is:10.65 & sMAPE is:12.38% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :22.27 & 38.76% & 0.88\n",
      "for 2023-06-01, MAE is:6.55 & sMAPE is:7.74% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :22.16 & 38.55% & 0.88\n",
      "for 2023-06-02, MAE is:6.16 & sMAPE is:7.16% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :22.06 & 38.35% & 0.88\n",
      "for 2023-06-03, MAE is:9.95 & sMAPE is:12.76% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :21.98 & 38.18% & 0.88\n",
      "for 2023-06-04, MAE is:17.82 & sMAPE is:31.34% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :21.95 & 38.14% & 0.88\n",
      "for 2023-06-05, MAE is:11.01 & sMAPE is:13.16% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :21.88 & 37.98% & 0.88\n",
      "for 2023-06-06, MAE is:6.87 & sMAPE is:8.07% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :21.79 & 37.79% & 0.88\n",
      "for 2023-06-07, MAE is:11.70 & sMAPE is:13.79% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :21.72 & 37.63% & 0.88\n",
      "for 2023-06-08, MAE is:6.82 & sMAPE is:8.64% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :21.63 & 37.45% & 0.88\n",
      "for 2023-06-09, MAE is:11.24 & sMAPE is:14.02% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :21.56 & 37.31% & 0.89\n",
      "for 2023-06-10, MAE is:14.69 & sMAPE is:18.67% & rMAE is:3.00 ||| daily mean of MAE & sMAPE & rMAE till now are :21.52 & 37.19% & 0.90\n",
      "for 2023-06-11, MAE is:21.06 & sMAPE is:43.12% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :21.52 & 37.23% & 0.91\n",
      "for 2023-06-12, MAE is:6.10 & sMAPE is:6.54% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :21.42 & 37.04% & 0.90\n",
      "for 2023-06-13, MAE is:10.36 & sMAPE is:11.96% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :21.36 & 36.89% & 0.91\n",
      "for 2023-06-14, MAE is:15.15 & sMAPE is:18.79% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :21.32 & 36.78% & 0.91\n",
      "for 2023-06-15, MAE is:15.57 & sMAPE is:15.71% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :21.28 & 36.65% & 0.91\n",
      "for 2023-06-16, MAE is:12.50 & sMAPE is:10.17% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :21.23 & 36.49% & 0.90\n",
      "for 2023-06-17, MAE is:17.20 & sMAPE is:20.70% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :21.21 & 36.40% & 0.90\n",
      "for 2023-06-18, MAE is:16.33 & sMAPE is:22.71% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :21.18 & 36.31% & 0.90\n",
      "for 2023-06-19, MAE is:9.78 & sMAPE is:8.96% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :21.11 & 36.15% & 0.90\n",
      "for 2023-06-20, MAE is:6.54 & sMAPE is:5.79% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :21.03 & 35.98% & 0.90\n",
      "for 2023-06-21, MAE is:10.81 & sMAPE is:9.18% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :20.97 & 35.82% & 0.89\n",
      "for 2023-06-22, MAE is:13.47 & sMAPE is:11.33% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :20.92 & 35.68% & 0.89\n",
      "for 2023-06-23, MAE is:13.60 & sMAPE is:12.43% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :20.88 & 35.55% & 0.89\n",
      "for 2023-06-24, MAE is:25.25 & sMAPE is:38.98% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :20.91 & 35.57% & 0.90\n",
      "for 2023-06-25, MAE is:31.91 & sMAPE is:63.20% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :20.97 & 35.72% & 0.90\n",
      "for 2023-06-26, MAE is:10.73 & sMAPE is:11.48% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :20.91 & 35.59% & 0.90\n",
      "for 2023-06-27, MAE is:13.64 & sMAPE is:13.93% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :20.87 & 35.46% & 0.90\n",
      "for 2023-06-28, MAE is:6.81 & sMAPE is:6.56% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :20.79 & 35.30% & 0.90\n",
      "for 2023-06-29, MAE is:13.90 & sMAPE is:13.22% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :20.75 & 35.18% & 0.90\n",
      "for 2023-06-30, MAE is:10.30 & sMAPE is:10.58% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :20.70 & 35.04% & 0.90\n",
      "CPU times: total: 1d 22h 20s\n",
      "Wall time: 19h 50min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
