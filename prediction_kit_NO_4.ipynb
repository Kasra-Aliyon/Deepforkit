{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = ['NO_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:40:40,895]\u001b[0m A new study created in RDB with name: NO_4_2018\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:41:13,967]\u001b[0m Trial 2 finished with value: 2.1931596542470286 and parameters: {'n_hidden': 4, 'learning_rate': 0.025143525045691895, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18446312439438467, 'dropout_rate_Layer_2': 0.38173487553022745, 'dropout_rate_Layer_3': 0.18773286838186257, 'dropout_rate_Layer_4': 0.2188553962402817, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010508551127402369, 'l1_Layer_2': 0.052899584634924175, 'l1_Layer_3': 0.00198792732546553, 'l1_Layer_4': 0.0003474349624455217, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 235, 'n_units_Layer_4': 265}. Best is trial 2 with value: 2.1931596542470286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.19 | sMAPE for Validation Set is: 8.43% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 15.55 | sMAPE for Test Set is: 40.94% | rMAE for Test Set is: 3.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:41:14,153]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 18.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:41:20,551]\u001b[0m Trial 3 finished with value: 1.822260392870983 and parameters: {'n_hidden': 3, 'learning_rate': 0.01009443030142865, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14961121132496033, 'dropout_rate_Layer_2': 0.37198701083976204, 'dropout_rate_Layer_3': 0.15448874377642208, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06957277026568784, 'l1_Layer_2': 0.00015914562829691015, 'l1_Layer_3': 0.0304521634150341, 'n_units_Layer_1': 100, 'n_units_Layer_2': 140, 'n_units_Layer_3': 85}. Best is trial 3 with value: 1.822260392870983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.82 | sMAPE for Validation Set is: 6.99% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.73 | sMAPE for Test Set is: 32.20% | rMAE for Test Set is: 3.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:41:20,823]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:41:28,530]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:41:39,213]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:41:42,208]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:41:46,069]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:41:50,086]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:41:57,252]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:41:59,007]\u001b[0m Trial 4 finished with value: 1.6018074281033636 and parameters: {'n_hidden': 4, 'learning_rate': 0.001016431071972129, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2664569030011675, 'dropout_rate_Layer_2': 0.08234241092650896, 'dropout_rate_Layer_3': 0.11519915545137978, 'dropout_rate_Layer_4': 0.23444210219439876, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0215869577100022, 'l1_Layer_2': 0.0038907385836754963, 'l1_Layer_3': 0.0035344469066542266, 'l1_Layer_4': 1.1772990499569925e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 50, 'n_units_Layer_3': 150, 'n_units_Layer_4': 175}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 6.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.89 | sMAPE for Test Set is: 29.55% | rMAE for Test Set is: 2.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:42:04,383]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:11,286]\u001b[0m Trial 13 finished with value: 2.3516148760110087 and parameters: {'n_hidden': 4, 'learning_rate': 0.05701962506171714, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3473826078360436, 'dropout_rate_Layer_2': 0.22922205471739573, 'dropout_rate_Layer_3': 0.2155524179174662, 'dropout_rate_Layer_4': 0.2936116176072034, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.7234448534364166e-05, 'l1_Layer_2': 0.002382036356729294, 'l1_Layer_3': 0.0073885687754249975, 'l1_Layer_4': 0.017524003105561355, 'n_units_Layer_1': 110, 'n_units_Layer_2': 280, 'n_units_Layer_3': 95, 'n_units_Layer_4': 235}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.35 | sMAPE for Validation Set is: 9.04% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 15.82 | sMAPE for Test Set is: 41.86% | rMAE for Test Set is: 3.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:42:14,884]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:18,577]\u001b[0m Trial 1 finished with value: 1.695748229999116 and parameters: {'n_hidden': 4, 'learning_rate': 0.010314514110213311, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3654787434466703, 'dropout_rate_Layer_2': 0.36963830424960037, 'dropout_rate_Layer_3': 0.2569557682061864, 'dropout_rate_Layer_4': 0.06322472015102024, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0007763713034959636, 'l1_Layer_2': 4.838722337951034e-05, 'l1_Layer_3': 0.017936027473618152, 'l1_Layer_4': 0.0015244099986287253, 'n_units_Layer_1': 260, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190, 'n_units_Layer_4': 135}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.70 | sMAPE for Validation Set is: 6.45% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 15.70 | sMAPE for Test Set is: 41.43% | rMAE for Test Set is: 3.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:42:21,392]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:23,707]\u001b[0m Trial 15 finished with value: 1.9511499667744843 and parameters: {'n_hidden': 4, 'learning_rate': 0.022964290130953087, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2905477008542863, 'dropout_rate_Layer_2': 0.09956711631329931, 'dropout_rate_Layer_3': 0.20634726876776832, 'dropout_rate_Layer_4': 0.37811407548763853, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 5.0071956366422154e-05, 'l1_Layer_2': 0.0011873381727952597, 'l1_Layer_3': 0.0021830489851161765, 'l1_Layer_4': 0.09628101346395627, 'n_units_Layer_1': 265, 'n_units_Layer_2': 235, 'n_units_Layer_3': 220, 'n_units_Layer_4': 195}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 7.52% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 15.89 | sMAPE for Test Set is: 42.14% | rMAE for Test Set is: 3.86\n",
      "MAE for Validation Set is: 3.34 | sMAPE for Validation Set is: 13.00% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 19.79 | sMAPE for Test Set is: 55.91% | rMAE for Test Set is: 4.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:42:24,380]\u001b[0m Trial 14 finished with value: 3.3395694953325297 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024430476385942286, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009014867448586329, 'dropout_rate_Layer_2': 0.2868447186438811, 'dropout_rate_Layer_3': 0.12910333909303776, 'dropout_rate_Layer_4': 0.34403799768350274, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1631761511579505e-05, 'l1_Layer_2': 0.0009914369024833305, 'l1_Layer_3': 3.12334607730851e-05, 'l1_Layer_4': 0.04707270545715925, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 70, 'n_units_Layer_4': 80}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:29,744]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:30,413]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:35,551]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:36,038]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:37,256]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:39,307]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:41,048]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:43,680]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:50,710]\u001b[0m Trial 19 finished with value: 2.0551695010160382 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007371172281330373, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34043284292386317, 'dropout_rate_Layer_2': 0.17022313288794574, 'dropout_rate_Layer_3': 0.11275114765297732, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.056271508209451974, 'l1_Layer_2': 6.396652469741482e-05, 'l1_Layer_3': 0.01450469216665573, 'n_units_Layer_1': 135, 'n_units_Layer_2': 110, 'n_units_Layer_3': 205}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 7.92% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 12.62 | sMAPE for Test Set is: 31.71% | rMAE for Test Set is: 3.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:42:53,369]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:57,511]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:42:58,448]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:01,937]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:04,460]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:04,555]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:05,052]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:09,673]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:12,278]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:14,824]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:15,231]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:18,169]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:21,985]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:25,270]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:27,517]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:29,238]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:31,767]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:33,383]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:36,414]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:36,624]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:39,930]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:40,447]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:46,111]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:47,130]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:47,487]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.29 | sMAPE for Validation Set is: 8.97% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 16.82 | sMAPE for Test Set is: 45.23% | rMAE for Test Set is: 4.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:43:50,706]\u001b[0m Trial 49 finished with value: 2.293790814334898 and parameters: {'n_hidden': 3, 'learning_rate': 0.0231187371855017, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2946324953231996, 'dropout_rate_Layer_2': 0.04566624086427798, 'dropout_rate_Layer_3': 0.2653372050393285, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.2329081245995754e-05, 'l1_Layer_2': 0.0012428071820568356, 'l1_Layer_3': 0.005142549068938469, 'n_units_Layer_1': 100, 'n_units_Layer_2': 80, 'n_units_Layer_3': 70}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:56,726]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:56,848]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:43:59,847]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:44:04,992]\u001b[0m Trial 53 finished with value: 1.821043031868322 and parameters: {'n_hidden': 3, 'learning_rate': 0.007592955864859895, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06988197131677598, 'dropout_rate_Layer_2': 0.3910041266817094, 'dropout_rate_Layer_3': 0.006859008443152015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.6790642005051355e-05, 'l1_Layer_2': 1.4664414471639517e-05, 'l1_Layer_3': 0.00019732935463210967, 'n_units_Layer_1': 135, 'n_units_Layer_2': 115, 'n_units_Layer_3': 285}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.82 | sMAPE for Validation Set is: 7.09% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 14.05 | sMAPE for Test Set is: 36.08% | rMAE for Test Set is: 3.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:44:08,509]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:44:09,197]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:44:24,893]\u001b[0m Trial 62 finished with value: 1.8378061893665592 and parameters: {'n_hidden': 4, 'learning_rate': 0.04490848843975288, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1992884049508898, 'dropout_rate_Layer_2': 0.3404616140947786, 'dropout_rate_Layer_3': 0.11106125570812214, 'dropout_rate_Layer_4': 0.1337233711600014, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.2851317777413845e-05, 'l1_Layer_2': 1.2223577488208598e-05, 'l1_Layer_3': 0.06704621332145384, 'l1_Layer_4': 0.00026968327669813885, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 245, 'n_units_Layer_4': 105}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 7.05% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 15.19 | sMAPE for Test Set is: 39.79% | rMAE for Test Set is: 3.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:44:32,445]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:44:38,415]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:44:38,840]\u001b[0m Trial 63 finished with value: 1.6915380929923813 and parameters: {'n_hidden': 3, 'learning_rate': 0.00713038252226463, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3996171265843519, 'dropout_rate_Layer_2': 0.3535581609458123, 'dropout_rate_Layer_3': 0.015107708784598264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.2292288608107748e-05, 'l1_Layer_2': 1.1236127848988998e-05, 'l1_Layer_3': 1.6328530957380883e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 125, 'n_units_Layer_3': 300}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.69 | sMAPE for Validation Set is: 6.52% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.72 | sMAPE for Test Set is: 35.04% | rMAE for Test Set is: 3.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:44:44,164]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:44:44,390]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:44:48,697]\u001b[0m Trial 59 finished with value: 2.008417352484592 and parameters: {'n_hidden': 4, 'learning_rate': 0.004283898059254299, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20568525330019916, 'dropout_rate_Layer_2': 0.3259682242036478, 'dropout_rate_Layer_3': 0.18267953085473568, 'dropout_rate_Layer_4': 0.26330456842317274, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.561557510952058e-05, 'l1_Layer_2': 0.010878515391942572, 'l1_Layer_3': 0.002623912722928699, 'l1_Layer_4': 1.2550663303177873e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150, 'n_units_Layer_4': 255}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 7.98% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 15.33 | sMAPE for Test Set is: 40.24% | rMAE for Test Set is: 3.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:44:49,478]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:44:50,594]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:44:54,140]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:45:05,742]\u001b[0m Trial 61 finished with value: 1.7090733340199433 and parameters: {'n_hidden': 4, 'learning_rate': 0.00435676904726288, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04085104568134562, 'dropout_rate_Layer_2': 0.3232405185694724, 'dropout_rate_Layer_3': 0.13279054588450528, 'dropout_rate_Layer_4': 0.2610948926368596, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.001392959132418063, 'l1_Layer_2': 0.001393422156848682, 'l1_Layer_3': 0.005830690812186896, 'l1_Layer_4': 1.8639012405680797e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 205, 'n_units_Layer_3': 250, 'n_units_Layer_4': 270}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.71 | sMAPE for Validation Set is: 6.65% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 14.65 | sMAPE for Test Set is: 38.05% | rMAE for Test Set is: 3.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:45:11,926]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:45:21,948]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:45:32,240]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:45:38,343]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:45:47,838]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:45:51,040]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:45:55,622]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:01,794]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:20,646]\u001b[0m Trial 72 finished with value: 1.9140024951050403 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012953944680001925, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10380960165237416, 'dropout_rate_Layer_2': 0.36910597245573756, 'dropout_rate_Layer_3': 0.3983035918149612, 'dropout_rate_Layer_4': 0.20924558743623012, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.178999359108637e-05, 'l1_Layer_2': 0.007622743792740443, 'l1_Layer_3': 0.006656780058092434, 'l1_Layer_4': 1.7658863442793063e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 85, 'n_units_Layer_3': 160, 'n_units_Layer_4': 230}. Best is trial 4 with value: 1.6018074281033636.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 7.60% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 14.28 | sMAPE for Test Set is: 36.85% | rMAE for Test Set is: 3.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:46:25,755]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:26,847]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:28,163]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:34,346]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:38,771]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:41,293]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:44,190]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:49,425]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:50,701]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:55,109]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:55,641]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:46:59,189]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:03,525]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:13,746]\u001b[0m Trial 89 finished with value: 1.5032136689306859 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016363342362310659, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30784621745992957, 'dropout_rate_Layer_2': 0.359212959149315, 'dropout_rate_Layer_3': 0.2317855961849609, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.614580211719338e-05, 'l1_Layer_2': 5.496481308382197e-05, 'l1_Layer_3': 2.8496666738350385e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 145, 'n_units_Layer_3': 130}. Best is trial 89 with value: 1.5032136689306859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.60 | sMAPE for Test Set is: 6.10% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:47:18,074]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:21,328]\u001b[0m Trial 95 finished with value: 1.6382518663219896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0064848912959845585, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04193891855928167, 'dropout_rate_Layer_2': 0.3917336048617593, 'dropout_rate_Layer_3': 0.004198351974439442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.1954273156924624e-05, 'l1_Layer_2': 1.0166115652278365e-05, 'l1_Layer_3': 0.00019670765789746915, 'n_units_Layer_1': 135, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295}. Best is trial 89 with value: 1.5032136689306859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.64 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.02 | sMAPE for Test Set is: 36.01% | rMAE for Test Set is: 3.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:47:22,204]\u001b[0m Trial 93 finished with value: 1.758251173571723 and parameters: {'n_hidden': 3, 'learning_rate': 0.010993177310731229, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.113660061910368, 'dropout_rate_Layer_2': 0.362137052386333, 'dropout_rate_Layer_3': 0.23000607913292676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001770180036224961, 'l1_Layer_2': 7.30513502247339e-05, 'l1_Layer_3': 0.0006588992996630239, 'n_units_Layer_1': 110, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130}. Best is trial 89 with value: 1.5032136689306859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.76 | sMAPE for Validation Set is: 6.73% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 14.02 | sMAPE for Test Set is: 36.03% | rMAE for Test Set is: 3.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:47:26,757]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:30,482]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:32,002]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:34,372]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:36,151]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:37,873]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:39,962]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:44,308]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:51,908]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:47:56,759]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:48:00,649]\u001b[0m Trial 81 finished with value: 1.5804706596839804 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013463341591506378, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15272698216581906, 'dropout_rate_Layer_2': 0.34110446875134215, 'dropout_rate_Layer_3': 0.16374258815558942, 'dropout_rate_Layer_4': 0.2515406311329283, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.156803416853325e-05, 'l1_Layer_2': 0.00014620255348797985, 'l1_Layer_3': 0.04934597939297713, 'l1_Layer_4': 0.0023544886084714786, 'n_units_Layer_1': 300, 'n_units_Layer_2': 80, 'n_units_Layer_3': 70, 'n_units_Layer_4': 260}. Best is trial 89 with value: 1.5032136689306859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 6.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.31 | sMAPE for Test Set is: 33.79% | rMAE for Test Set is: 3.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:48:10,556]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:48:17,746]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:48:18,909]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:48:55,805]\u001b[0m Trial 112 finished with value: 1.4235942011660925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007431224428998445, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2297169747357016, 'dropout_rate_Layer_2': 0.3914287036528176, 'dropout_rate_Layer_3': 0.050414715659294985, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012272070708186622, 'l1_Layer_2': 1.0168324468042844e-05, 'l1_Layer_3': 9.090061940731785e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 140, 'n_units_Layer_3': 295}. Best is trial 112 with value: 1.4235942011660925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 5.53% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.70 | sMAPE for Test Set is: 6.28% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:49:07,567]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:49:12,574]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:49:16,604]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:49:29,306]\u001b[0m Trial 113 finished with value: 1.6697466196427804 and parameters: {'n_hidden': 3, 'learning_rate': 0.022724583228532175, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21212920958778395, 'dropout_rate_Layer_2': 0.35233670436881726, 'dropout_rate_Layer_3': 0.3019715382734393, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011181141163971915, 'l1_Layer_2': 0.004332561917695352, 'l1_Layer_3': 0.00458243992820881, 'n_units_Layer_1': 205, 'n_units_Layer_2': 240, 'n_units_Layer_3': 235}. Best is trial 112 with value: 1.4235942011660925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.67 | sMAPE for Validation Set is: 6.44% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.38 | sMAPE for Test Set is: 31.04% | rMAE for Test Set is: 3.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:49:36,029]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:49:40,650]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:49:44,746]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:49:48,633]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:49:53,753]\u001b[0m Trial 117 finished with value: 1.3749003997483953 and parameters: {'n_hidden': 3, 'learning_rate': 0.001372732468406777, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04591368418391367, 'dropout_rate_Layer_2': 0.18178457342700924, 'dropout_rate_Layer_3': 0.045794083721168, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.379495309765185e-05, 'l1_Layer_2': 0.000264789141957707, 'l1_Layer_3': 8.499612198564622e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.37 | sMAPE for Validation Set is: 5.38% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 2.58 | sMAPE for Test Set is: 6.13% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:49:58,946]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:50:03,218]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:50:10,813]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:50:14,685]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:50:17,627]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:50:20,333]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:50:22,162]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:50:26,396]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:50:36,494]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:50:40,597]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:50:44,464]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:21,410]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:27,222]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:28,843]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:31,357]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:34,051]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:36,933]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:41,112]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:41,506]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:46,878]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:47,178]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:53,375]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:51:58,471]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:52:01,178]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:52:02,801]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:52:06,146]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:52:08,981]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:52:12,556]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:52:14,992]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:52:20,401]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:52:22,647]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:52:25,119]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:52:36,099]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:52:42,607]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:02,149]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:08,524]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:14,092]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:18,963]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:34,098]\u001b[0m Trial 160 finished with value: 3.364110661654055 and parameters: {'n_hidden': 4, 'learning_rate': 0.015419124175300834, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17699563146945843, 'dropout_rate_Layer_2': 0.30904221030852475, 'dropout_rate_Layer_3': 0.3926488942043467, 'dropout_rate_Layer_4': 0.016079288903115524, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0029853251639567558, 'l1_Layer_2': 0.037831790009063386, 'l1_Layer_3': 0.0002358401544365112, 'l1_Layer_4': 1.4480516399316361e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 200, 'n_units_Layer_4': 50}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.36 | sMAPE for Validation Set is: 13.11% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 19.89 | sMAPE for Test Set is: 56.29% | rMAE for Test Set is: 4.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:53:39,868]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.74% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 10.99 | sMAPE for Test Set is: 26.99% | rMAE for Test Set is: 2.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:53:41,839]\u001b[0m Trial 107 finished with value: 1.4786889029037573 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005876889387468021, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3535222373224767, 'dropout_rate_Layer_2': 0.08127561821453555, 'dropout_rate_Layer_3': 0.06816279488940942, 'dropout_rate_Layer_4': 0.373071276988651, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00019716442215918562, 'l1_Layer_2': 0.00023279149680689948, 'l1_Layer_3': 0.006855294717552308, 'l1_Layer_4': 6.164557964484964e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 65, 'n_units_Layer_3': 130, 'n_units_Layer_4': 180}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:43,063]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:47,109]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:49,074]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:49,416]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:55,892]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:59,511]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:53:59,761]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:02,872]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:08,594]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:13,449]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:19,662]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:30,898]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:33,579]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:37,572]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:42,209]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:46,636]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:48,620]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:51,544]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:53,914]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:54:56,604]\u001b[0m Trial 175 finished with value: 1.5780506862652812 and parameters: {'n_hidden': 3, 'learning_rate': 0.005508264765602719, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16886076671038222, 'dropout_rate_Layer_2': 0.15716682749087235, 'dropout_rate_Layer_3': 0.11935384333210228, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.006775993491577897, 'l1_Layer_2': 0.0014901187810087934, 'l1_Layer_3': 0.04096936499560945, 'n_units_Layer_1': 230, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 6.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 22.92% | rMAE for Test Set is: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:54:58,428]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:04,163]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:11,353]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:14,793]\u001b[0m Trial 183 finished with value: 1.7665439686029318 and parameters: {'n_hidden': 4, 'learning_rate': 0.008927787442610049, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17989573964375746, 'dropout_rate_Layer_2': 0.14219995360363719, 'dropout_rate_Layer_3': 0.3021558675885033, 'dropout_rate_Layer_4': 0.2930011449897111, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.039674428157219575, 'l1_Layer_2': 2.9403430384593398e-05, 'l1_Layer_3': 0.009409769074727342, 'l1_Layer_4': 0.006297339134499956, 'n_units_Layer_1': 235, 'n_units_Layer_2': 280, 'n_units_Layer_3': 85, 'n_units_Layer_4': 205}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.77 | sMAPE for Validation Set is: 6.77% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 13.14 | sMAPE for Test Set is: 33.30% | rMAE for Test Set is: 3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:55:17,113]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:17,761]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:25,737]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:28,445]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:31,175]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:33,080]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:35,739]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:37,078]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:37,314]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:40,533]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:44,215]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:44,324]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:46,434]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:53,924]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:55:55,615]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:04,623]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:08,603]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:12,644]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:12,685]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:19,100]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:19,263]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:24,753]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:27,483]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:31,915]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:32,442]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:35,726]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:39,473]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:41,893]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:44,772]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:48,525]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:53,833]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:56:58,693]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:02,562]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:10,923]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:16,818]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:17,039]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:20,704]\u001b[0m Trial 155 finished with value: 1.6847174250857566 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005551219964900791, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0012755033731626675, 'dropout_rate_Layer_2': 0.170025372919551, 'dropout_rate_Layer_3': 0.33310941758782925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.003308695259238922, 'l1_Layer_2': 0.005542503190113441, 'l1_Layer_3': 4.458838885620738e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 60, 'n_units_Layer_3': 165}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 6.53% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 30.12% | rMAE for Test Set is: 2.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:57:25,321]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:27,060]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:31,501]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:34,647]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:35,139]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:38,266]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:44,031]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:46,389]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:50,257]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:55,031]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:57:55,302]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:00,173]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:03,767]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:03,950]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:10,088]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:17,327]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:23,384]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:27,285]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:27,987]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:34,049]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:37,481]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:39,195]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:46,411]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:49,803]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:50,967]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:58:52,181]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:59:08,005]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:59:11,559]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:59:34,514]\u001b[0m Trial 229 finished with value: 1.536668240646632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012210319918698367, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10641359383496149, 'dropout_rate_Layer_2': 0.3200689414162933, 'dropout_rate_Layer_3': 0.1932629912885948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0009362113341145953, 'l1_Layer_2': 0.0001223763476178617, 'l1_Layer_3': 0.0075961817925985844, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 210}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 6.00% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.20 | sMAPE for Test Set is: 21.94% | rMAE for Test Set is: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 10:59:39,631]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:59:43,753]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:59:46,093]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:59:52,152]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 10:59:55,614]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:00:18,202]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:00:42,112]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:00:46,376]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:00:51,772]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:01:09,565]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:01:15,148]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:01:19,623]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:01:19,902]\u001b[0m Trial 251 finished with value: 1.678848231722301 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014702229589898595, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30312775620555477, 'dropout_rate_Layer_2': 0.3346170249107614, 'dropout_rate_Layer_3': 0.16849815993267886, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00012837719797382315, 'l1_Layer_2': 0.003150931537393574, 'l1_Layer_3': 0.035299169948927504, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 205}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 6.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.51 | sMAPE for Test Set is: 31.43% | rMAE for Test Set is: 3.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:01:29,570]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:01:35,577]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:01:44,433]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:01:58,802]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:00,118]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:02,884]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:05,144]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:14,196]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:18,949]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:19,084]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:26,309]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:31,838]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:36,687]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:39,910]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:40,381]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:45,926]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:48,901]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:53,144]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:02:55,362]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:03:02,649]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:03:06,702]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:03:12,317]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:03:16,305]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:03:17,478]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:03:21,029]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:03:21,949]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:03:28,152]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:03:30,661]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:03:37,079]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:03:45,780]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:04:21,533]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:04:25,730]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:04:28,592]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:04:29,857]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:04:38,885]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:04:44,552]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:04:47,027]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:04:54,527]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:05:07,420]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:05:37,584]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:05:45,770]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:05:46,097]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:06:15,788]\u001b[0m Trial 306 finished with value: 1.7681663481705236 and parameters: {'n_hidden': 4, 'learning_rate': 0.006032180315436911, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11905815502920675, 'dropout_rate_Layer_2': 0.30939568449069876, 'dropout_rate_Layer_3': 0.1371835420848057, 'dropout_rate_Layer_4': 0.21902140102253564, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.2398259100394554e-05, 'l1_Layer_2': 0.0053801203643201265, 'l1_Layer_3': 0.002035915174815669, 'l1_Layer_4': 2.3224456490592244e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.77 | sMAPE for Validation Set is: 6.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 14.50 | sMAPE for Test Set is: 37.49% | rMAE for Test Set is: 3.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:06:20,573]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:06:39,500]\u001b[0m Trial 263 finished with value: 1.5445246211310337 and parameters: {'n_hidden': 3, 'learning_rate': 0.001072041384417331, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11170626012503646, 'dropout_rate_Layer_2': 0.1510936340081414, 'dropout_rate_Layer_3': 0.33697601979356356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.008001287385955439, 'l1_Layer_2': 0.005157570825195386, 'l1_Layer_3': 6.483715116042043e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 50, 'n_units_Layer_3': 170}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.99% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.03 | sMAPE for Test Set is: 32.97% | rMAE for Test Set is: 3.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:06:45,822]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:06:49,138]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:06:53,584]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:07:00,958]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:07:06,227]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:07:18,597]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:07:25,344]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:07:29,821]\u001b[0m Trial 308 finished with value: 1.6157753858219976 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012758475626348956, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14296500233072054, 'dropout_rate_Layer_2': 0.3085353431783121, 'dropout_rate_Layer_3': 0.18963712044651315, 'dropout_rate_Layer_4': 0.2167106194287547, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.586238708407338e-05, 'l1_Layer_2': 0.007044477185750587, 'l1_Layer_3': 0.0019151967263224456, 'l1_Layer_4': 2.419505474760047e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 185, 'n_units_Layer_4': 270}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 6.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.80 | sMAPE for Test Set is: 32.22% | rMAE for Test Set is: 3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:07:32,129]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:07:38,859]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:07:43,091]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:07:48,000]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:07:49,553]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:07:55,263]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:04,608]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:05,340]\u001b[0m Trial 311 finished with value: 1.741046161660491 and parameters: {'n_hidden': 4, 'learning_rate': 0.005865641671973294, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11846326984679445, 'dropout_rate_Layer_2': 0.32189671286642596, 'dropout_rate_Layer_3': 0.1182771450004643, 'dropout_rate_Layer_4': 0.21102907527642253, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.1432849532095705e-05, 'l1_Layer_2': 0.007764720428626261, 'l1_Layer_3': 0.001006782107184057, 'l1_Layer_4': 1.0041017308318789e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 160, 'n_units_Layer_4': 280}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.74 | sMAPE for Validation Set is: 6.71% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 37.25% | rMAE for Test Set is: 3.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:08:11,500]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:11,742]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:12,516]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:20,894]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:22,551]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:26,385]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:28,465]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:28,864]\u001b[0m Trial 328 finished with value: 2.2630754743363823 and parameters: {'n_hidden': 3, 'learning_rate': 0.04216892546809659, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09805052282744887, 'dropout_rate_Layer_2': 0.20619469634789978, 'dropout_rate_Layer_3': 0.22649930237906074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.008493405855991475, 'l1_Layer_2': 0.005080927815396897, 'l1_Layer_3': 0.0011336355492727293, 'n_units_Layer_1': 180, 'n_units_Layer_2': 105, 'n_units_Layer_3': 125}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.26 | sMAPE for Validation Set is: 8.72% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 15.85 | sMAPE for Test Set is: 41.96% | rMAE for Test Set is: 3.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:08:29,049]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:32,524]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:37,702]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:39,835]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:48,717]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:54,524]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:55,074]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:08:59,547]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:09:06,209]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:09:11,496]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:09:16,533]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:09:20,353]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:09:24,645]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:09:36,970]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:09:51,402]\u001b[0m Trial 338 finished with value: 1.6759090400097314 and parameters: {'n_hidden': 4, 'learning_rate': 0.003508655401702818, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11174111845323757, 'dropout_rate_Layer_2': 0.3346569405110138, 'dropout_rate_Layer_3': 0.11864246616419621, 'dropout_rate_Layer_4': 0.23174892550117426, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.0674420314708397e-05, 'l1_Layer_2': 0.006611544292987485, 'l1_Layer_3': 0.0029754140854741946, 'l1_Layer_4': 1.2628069674077627e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 150, 'n_units_Layer_4': 265}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 6.49% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 14.09 | sMAPE for Test Set is: 36.23% | rMAE for Test Set is: 3.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:09:51,966]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:09:58,286]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:10:01,954]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:10:02,495]\u001b[0m Trial 339 finished with value: 1.7732521458289252 and parameters: {'n_hidden': 4, 'learning_rate': 0.006422965857646028, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11538203872671267, 'dropout_rate_Layer_2': 0.33282635023560364, 'dropout_rate_Layer_3': 0.11829417900982335, 'dropout_rate_Layer_4': 0.22315328052330602, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.273257746493298e-05, 'l1_Layer_2': 0.005873563686811682, 'l1_Layer_3': 0.002749412959899391, 'l1_Layer_4': 1.0098575052341305e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 175, 'n_units_Layer_4': 265}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.77 | sMAPE for Validation Set is: 6.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 14.06 | sMAPE for Test Set is: 36.13% | rMAE for Test Set is: 3.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:10:07,822]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:10:12,087]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:10:15,927]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:10:20,472]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:10:51,702]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:10:58,027]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:01,855]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:05,180]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:08,542]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:11,194]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:15,781]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:16,209]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:18,846]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:22,944]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:24,570]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:25,350]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 6.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.63 | sMAPE for Test Set is: 17.94% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:11:29,037]\u001b[0m Trial 350 finished with value: 1.5884313821259826 and parameters: {'n_hidden': 4, 'learning_rate': 0.003108001164606284, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24985221384272688, 'dropout_rate_Layer_2': 0.08682463901045637, 'dropout_rate_Layer_3': 0.17666547195296625, 'dropout_rate_Layer_4': 0.16547861313800366, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.645835060652643e-05, 'l1_Layer_2': 1.5962028921852168e-05, 'l1_Layer_3': 0.015569913139706664, 'l1_Layer_4': 0.0005748917004661129, 'n_units_Layer_1': 225, 'n_units_Layer_2': 85, 'n_units_Layer_3': 85, 'n_units_Layer_4': 105}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:33,663]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:43,447]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:46,980]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:11:47,391]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:12:10,639]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:12:20,486]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.70 | sMAPE for Validation Set is: 6.63% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.33 | sMAPE for Test Set is: 27.98% | rMAE for Test Set is: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:12:22,367]\u001b[0m Trial 372 finished with value: 1.6992704027014292 and parameters: {'n_hidden': 3, 'learning_rate': 0.001344896730209409, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3208668727128882, 'dropout_rate_Layer_2': 0.245428672849474, 'dropout_rate_Layer_3': 0.0006743940155719552, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010399023646301696, 'l1_Layer_2': 0.00163710878794552, 'l1_Layer_3': 1.0108553680362825e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 300, 'n_units_Layer_3': 100}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:12:26,489]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:12:29,531]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:12:29,762]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:12:39,220]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:12:43,589]\u001b[0m Trial 376 finished with value: 1.95527530292781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012521803845537628, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3246296591400386, 'dropout_rate_Layer_2': 0.26569750252540175, 'dropout_rate_Layer_3': 0.2858675717167217, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.974602911734186e-05, 'l1_Layer_2': 0.009144167274553465, 'l1_Layer_3': 0.0433403319739552, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 100}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 7.62% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 14.85 | sMAPE for Test Set is: 38.72% | rMAE for Test Set is: 3.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:12:44,619]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:12:46,422]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:12:52,397]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:12:57,087]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:02,642]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:07,888]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:10,249]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:10,425]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:11,710]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:18,240]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:28,737]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:33,063]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:33,408]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:35,794]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:41,763]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:45,310]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:45,553]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:13:53,647]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:00,852]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:01,604]\u001b[0m Trial 393 finished with value: 1.9661590935042896 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033903766282610192, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2785530429874479, 'dropout_rate_Layer_2': 0.28463051818906415, 'dropout_rate_Layer_3': 0.36294253396875586, 'dropout_rate_Layer_4': 0.21800818241059955, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.4957620023335041e-05, 'l1_Layer_2': 0.00977832770681652, 'l1_Layer_3': 0.004121553773900486, 'l1_Layer_4': 0.00012372935176578685, 'n_units_Layer_1': 220, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125, 'n_units_Layer_4': 240}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 14.73 | sMAPE for Test Set is: 38.27% | rMAE for Test Set is: 3.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:14:03,535]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:03,867]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:11,454]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:12,021]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:17,457]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:18,323]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:23,261]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:24,783]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:26,959]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:31,721]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:34,354]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:36,965]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:43,101]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:45,919]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:48,701]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:52,652]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:14:54,293]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:15:06,237]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:15:10,302]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:15:13,503]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:15:22,304]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:16:04,226]\u001b[0m Trial 404 finished with value: 1.5059869572570204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007701129068890025, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0918665505778428, 'dropout_rate_Layer_2': 0.28522375657351856, 'dropout_rate_Layer_3': 0.04090657380989575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005109987396845738, 'l1_Layer_2': 0.0001522357280280758, 'l1_Layer_3': 0.00848772119764687, 'n_units_Layer_1': 140, 'n_units_Layer_2': 120, 'n_units_Layer_3': 175}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.76% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.96 | sMAPE for Test Set is: 21.33% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:16:25,683]\u001b[0m Trial 425 finished with value: 1.6695848004955594 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007817281184058569, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20672835126848338, 'dropout_rate_Layer_2': 0.13399110724227337, 'dropout_rate_Layer_3': 0.18479173538466764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006843902296953042, 'l1_Layer_2': 0.00011510874891666861, 'l1_Layer_3': 4.730158309247378e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.67 | sMAPE for Validation Set is: 6.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.53 | sMAPE for Test Set is: 34.65% | rMAE for Test Set is: 3.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:16:31,511]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:16:37,872]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:16:47,328]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:16:55,404]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:16:55,545]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:03,534]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:08,440]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:09,279]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:17,123]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:25,373]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:25,656]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:33,831]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:34,258]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:34,334]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:41,924]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:45,014]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:45,453]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:55,041]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:17:58,730]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:05,288]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:08,602]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:15,092]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:20,973]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:31,148]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:37,485]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:39,924]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:43,620]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:45,886]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:48,592]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:52,144]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:55,520]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:18:56,594]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:07,018]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:09,101]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:17,846]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:20,436]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:24,575]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:26,700]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:29,290]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:32,721]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:35,323]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:40,457]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:45,055]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:51,860]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:19:54,875]\u001b[0m Trial 432 finished with value: 1.7521463077916337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007330072640551265, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19906173831361565, 'dropout_rate_Layer_2': 0.12732186387461214, 'dropout_rate_Layer_3': 0.3429023159297655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008842765115393035, 'l1_Layer_2': 0.00014476727904913478, 'l1_Layer_3': 5.00746088243436e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 70, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.75 | sMAPE for Validation Set is: 6.84% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 13.80 | sMAPE for Test Set is: 35.41% | rMAE for Test Set is: 3.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:19:58,378]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:20:06,472]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:20:06,605]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:20:11,189]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:20:13,207]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:20:21,843]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:20:30,867]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:20:37,247]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:20:40,366]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:21:25,072]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:21:29,629]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:21:48,077]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:21:58,193]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:22:10,308]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:22:32,700]\u001b[0m Trial 478 finished with value: 1.6200256952360352 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009268249267320693, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2975321207705924, 'dropout_rate_Layer_2': 0.07514786492047898, 'dropout_rate_Layer_3': 0.13896789628849143, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010309027019303563, 'l1_Layer_2': 2.9772963027084712e-05, 'l1_Layer_3': 0.0004053209736508409, 'n_units_Layer_1': 250, 'n_units_Layer_2': 95, 'n_units_Layer_3': 210}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 6.48% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.76 | sMAPE for Test Set is: 35.33% | rMAE for Test Set is: 3.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:22:36,815]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:22:41,629]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:22:45,469]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:22:49,752]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:23:17,541]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:23:23,823]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:23:26,757]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:23:30,372]\u001b[0m Trial 457 finished with value: 1.5631069690821562 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006684183609348797, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18068664816072363, 'dropout_rate_Layer_2': 0.17744803347174035, 'dropout_rate_Layer_3': 0.14073968683635793, 'dropout_rate_Layer_4': 0.30285013677108924, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.002326142228913304, 'l1_Layer_2': 2.6915275867969665e-05, 'l1_Layer_3': 2.45752754964854e-05, 'l1_Layer_4': 0.001994687742998949, 'n_units_Layer_1': 215, 'n_units_Layer_2': 75, 'n_units_Layer_3': 265, 'n_units_Layer_4': 165}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 6.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.13 | sMAPE for Test Set is: 33.25% | rMAE for Test Set is: 3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:23:33,027]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.78% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 28.12% | rMAE for Test Set is: 2.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:23:33,473]\u001b[0m Trial 474 finished with value: 1.4775692092595374 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009658425003369201, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.220169099214922, 'dropout_rate_Layer_2': 0.18552763687816087, 'dropout_rate_Layer_3': 0.15520771183363263, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.940079376879552e-05, 'l1_Layer_2': 0.0036131280564713577, 'l1_Layer_3': 2.712874683292861e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 70, 'n_units_Layer_3': 205}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:23:36,154]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:23:37,312]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:23:43,600]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:23:45,955]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:23:50,368]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:23:54,779]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:23:59,895]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:01,238]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:07,481]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:10,815]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:15,039]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:24,194]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:24,385]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:29,086]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:31,521]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:36,264]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:37,593]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:40,001]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:42,786]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:44,438]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:53,489]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:24:53,736]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:00,184]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:04,958]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:07,111]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:10,495]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:19,456]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:26,563]\u001b[0m Trial 513 finished with value: 1.490931273083891 and parameters: {'n_hidden': 3, 'learning_rate': 0.001730276035969941, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08041068917097122, 'dropout_rate_Layer_2': 0.27266553189114684, 'dropout_rate_Layer_3': 0.01447704366415267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004297872134828815, 'l1_Layer_2': 4.862180068947949e-05, 'l1_Layer_3': 0.0034543622992404387, 'n_units_Layer_1': 240, 'n_units_Layer_2': 130, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.76% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.47 | sMAPE for Test Set is: 22.66% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:25:28,854]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:36,437]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:39,313]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:43,955]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:48,877]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:49,171]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:54,514]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:55,274]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:25:58,648]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:26:02,184]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:26:02,852]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:26:07,174]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:26:14,194]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:26:19,498]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:26:31,084]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:26:34,914]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:26:37,624]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:26:44,383]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:26:53,802]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:26:54,824]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:01,317]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:08,312]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:12,600]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:18,025]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:18,770]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:22,420]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:24,684]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:31,170]\u001b[0m Trial 535 finished with value: 1.497516743510795 and parameters: {'n_hidden': 3, 'learning_rate': 0.001663149469853013, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06673628071078522, 'dropout_rate_Layer_2': 0.24100822338308484, 'dropout_rate_Layer_3': 0.03515399492305261, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0015718686457066428, 'l1_Layer_2': 0.00015762008104950885, 'l1_Layer_3': 0.0019248329783027472, 'n_units_Layer_1': 225, 'n_units_Layer_2': 125, 'n_units_Layer_3': 175}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.82% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.05 | sMAPE for Test Set is: 21.52% | rMAE for Test Set is: 2.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:27:31,491]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:37,751]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:44,217]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:45,297]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:46,649]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:53,767]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:56,490]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:27:59,402]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:01,309]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:02,085]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:05,647]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:10,611]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:13,755]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:18,156]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:20,750]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:21,477]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:28,787]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:29,408]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:29,828]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:36,378]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:38,346]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:39,628]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:44,560]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:46,015]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:51,711]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:54,476]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:28:58,040]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:29:03,393]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:29:14,535]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:29:22,898]\u001b[0m Trial 567 finished with value: 1.5857053452319494 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009847810991686962, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3505458800675492, 'dropout_rate_Layer_2': 0.15538493302617282, 'dropout_rate_Layer_3': 0.15138671210170676, 'dropout_rate_Layer_4': 0.25562320604038175, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004627209775933769, 'l1_Layer_2': 6.184644558312643e-05, 'l1_Layer_3': 0.0001085944667825364, 'l1_Layer_4': 0.0006936352485354683, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280, 'n_units_Layer_4': 95}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 6.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.40 | sMAPE for Test Set is: 34.07% | rMAE for Test Set is: 3.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:29:25,904]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:29:26,453]\u001b[0m Trial 579 finished with value: 1.510321155255955 and parameters: {'n_hidden': 3, 'learning_rate': 0.004082764890273742, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17845467156073097, 'dropout_rate_Layer_2': 0.06670694243455512, 'dropout_rate_Layer_3': 0.39363645016349075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008960939384291686, 'l1_Layer_2': 0.07536025182405687, 'l1_Layer_3': 0.0018825634409257083, 'n_units_Layer_1': 250, 'n_units_Layer_2': 265, 'n_units_Layer_3': 85}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.87% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.68 | sMAPE for Test Set is: 6.32% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:30:05,376]\u001b[0m Trial 581 finished with value: 1.6435811810076124 and parameters: {'n_hidden': 4, 'learning_rate': 0.00427554925298307, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08280449775314333, 'dropout_rate_Layer_2': 0.35814263248670425, 'dropout_rate_Layer_3': 0.10950702635875026, 'dropout_rate_Layer_4': 0.24126096590722418, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.041718810228258e-05, 'l1_Layer_2': 0.006943250558117307, 'l1_Layer_3': 0.0007365548888848221, 'l1_Layer_4': 0.00781802081113519, 'n_units_Layer_1': 90, 'n_units_Layer_2': 75, 'n_units_Layer_3': 150, 'n_units_Layer_4': 240}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.64 | sMAPE for Validation Set is: 6.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.31 | sMAPE for Test Set is: 33.77% | rMAE for Test Set is: 3.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:30:11,510]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:15,008]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:15,649]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:21,458]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:24,756]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:25,910]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:28,095]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:32,938]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:35,356]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:38,588]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:39,377]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:45,136]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:54,008]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:30:58,217]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:02,020]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:10,363]\u001b[0m Trial 586 finished with value: 1.5100323723148368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012744115643855524, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08834429087147572, 'dropout_rate_Layer_2': 0.3012005520428368, 'dropout_rate_Layer_3': 0.022178556474239695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004567725237134566, 'l1_Layer_2': 8.729427269714067e-05, 'l1_Layer_3': 0.0031272117707053107, 'n_units_Layer_1': 235, 'n_units_Layer_2': 120, 'n_units_Layer_3': 170}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.84% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.12 | sMAPE for Test Set is: 21.72% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:31:14,249]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:18,850]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:27,542]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:27,981]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:34,011]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:34,181]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:39,987]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:45,801]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:49,061]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:50,528]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:56,178]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:31:58,405]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:02,100]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:10,229]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:10,447]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.67 | sMAPE for Validation Set is: 6.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.99 | sMAPE for Test Set is: 32.83% | rMAE for Test Set is: 3.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:32:15,138]\u001b[0m Trial 609 finished with value: 1.6739704323614106 and parameters: {'n_hidden': 4, 'learning_rate': 0.0041718505086365655, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07363436240022017, 'dropout_rate_Layer_2': 0.3395746785374456, 'dropout_rate_Layer_3': 0.3312564245044208, 'dropout_rate_Layer_4': 0.2117956604776052, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.2967235166185853e-05, 'l1_Layer_2': 0.006662340600427361, 'l1_Layer_3': 0.0017358646359974007, 'l1_Layer_4': 3.376693899658483e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135, 'n_units_Layer_4': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:17,910]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:18,219]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:25,313]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:26,024]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:31,052]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:35,369]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:40,207]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:48,332]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:51,706]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:32:55,943]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:00,874]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:04,489]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:09,793]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:14,914]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:15,112]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 6.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.37 | sMAPE for Test Set is: 34.02% | rMAE for Test Set is: 3.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:33:20,358]\u001b[0m Trial 607 finished with value: 1.5662186222325047 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019292181890449552, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2799594403305117, 'dropout_rate_Layer_2': 0.08389941642021674, 'dropout_rate_Layer_3': 0.100143880792306, 'dropout_rate_Layer_4': 0.17058668178474548, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0020060261337213623, 'l1_Layer_2': 2.8185116964198003e-05, 'l1_Layer_3': 7.57481851106169e-05, 'l1_Layer_4': 3.536906829424796e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 145, 'n_units_Layer_4': 150}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:23,494]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:24,632]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:26,268]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:33,500]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:36,480]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:37,867]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:38,774]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:45,260]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:52,776]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:33:58,529]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:34:03,119]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:34:13,471]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:34:22,609]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:34:45,629]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:34:50,136]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:34:53,026]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:34:55,183]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:34:55,223]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:34:58,571]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:04,087]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:04,119]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:06,805]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:12,476]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:12,933]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:18,961]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:19,530]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:24,550]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:25,248]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:29,746]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:30,815]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:35,870]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:39,326]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:40,798]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:44,111]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:46,493]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:50,017]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:50,286]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:54,007]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:55,210]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:35:59,859]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:02,337]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:05,988]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:08,066]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:08,412]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:08,853]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:09,788]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:18,342]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:20,843]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:26,741]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:27,241]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:30,808]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:45,712]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:46,075]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:52,374]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:52,482]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:36:59,456]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:37:03,048]\u001b[0m Trial 679 finished with value: 1.5058708495933917 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014796800393641167, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07032180013366135, 'dropout_rate_Layer_2': 0.24895078764392273, 'dropout_rate_Layer_3': 0.006238186090596783, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003450861751420853, 'l1_Layer_2': 7.448284606947893e-05, 'l1_Layer_3': 0.0013154613445600515, 'n_units_Layer_1': 145, 'n_units_Layer_2': 290, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.84% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 19.52% | rMAE for Test Set is: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:37:07,511]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:37:10,813]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:37:19,375]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:37:28,941]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:37:47,374]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:37:52,225]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:37:56,336]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:01,262]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:10,238]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:17,433]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:22,075]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:30,896]\u001b[0m Trial 685 finished with value: 1.4771705469783238 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014663120946672625, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07422531134562181, 'dropout_rate_Layer_2': 0.2513694963779935, 'dropout_rate_Layer_3': 0.006892739288289816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004370064700868214, 'l1_Layer_2': 7.611214623025117e-05, 'l1_Layer_3': 0.001290594588324219, 'n_units_Layer_1': 140, 'n_units_Layer_2': 130, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.71% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.12 | sMAPE for Test Set is: 30.14% | rMAE for Test Set is: 2.94\n",
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 6.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 12.93 | sMAPE for Test Set is: 32.61% | rMAE for Test Set is: 3.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:38:33,136]\u001b[0m Trial 693 finished with value: 1.5637693768373415 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005462739599938246, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15448670400387435, 'dropout_rate_Layer_2': 0.04050235502850977, 'dropout_rate_Layer_3': 0.05372693431337924, 'dropout_rate_Layer_4': 0.14256642722105456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0015848686233382201, 'l1_Layer_2': 0.0005343846170047532, 'l1_Layer_3': 1.8296413333832424e-05, 'l1_Layer_4': 2.409137160349345e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 85, 'n_units_Layer_3': 110, 'n_units_Layer_4': 195}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:37,205]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:39,433]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:39,603]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:40,127]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:43,533]\u001b[0m Trial 688 finished with value: 1.53657508942668 and parameters: {'n_hidden': 4, 'learning_rate': 0.001124969280898517, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25445778298773325, 'dropout_rate_Layer_2': 0.04552097123745119, 'dropout_rate_Layer_3': 0.051614287033638684, 'dropout_rate_Layer_4': 0.15119793482111837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.001612605543224977, 'l1_Layer_2': 8.740007415401971e-05, 'l1_Layer_3': 3.8444842897754916e-05, 'l1_Layer_4': 2.0471782185701172e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 85, 'n_units_Layer_3': 85, 'n_units_Layer_4': 205}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.94% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.65 | sMAPE for Test Set is: 34.84% | rMAE for Test Set is: 3.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:38:47,653]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:51,275]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:53,144]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:38:53,923]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:01,010]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:03,046]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:03,603]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:04,037]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:07,849]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:12,480]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:13,241]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:15,820]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:17,772]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:21,620]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:25,292]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:25,943]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:26,412]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:27,940]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:29,317]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:36,323]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:36,911]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:37,928]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:41,332]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:46,786]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:49,022]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:51,787]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:54,509]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:39:58,564]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:00,616]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:00,657]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:05,060]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:08,120]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:10,970]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:12,925]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:14,238]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:16,479]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:17,082]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:20,114]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:20,174]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:25,211]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:30,465]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:32,984]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:33,709]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:36,284]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:38,714]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:45,472]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:50,745]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:40:56,402]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:41:05,408]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:41:09,863]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:41:14,250]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:41:35,845]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.69% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 26.60% | rMAE for Test Set is: 2.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:41:40,679]\u001b[0m Trial 749 finished with value: 1.4644791229898926 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014766643487086261, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07503902755556482, 'dropout_rate_Layer_2': 0.2577464422617609, 'dropout_rate_Layer_3': 0.008267655503785304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00039204878277639035, 'l1_Layer_2': 6.609578224683897e-05, 'l1_Layer_3': 0.0016540454228069416, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:41:46,619]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:41:51,210]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:41:56,813]\u001b[0m Trial 752 finished with value: 1.45089852253152 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011406524134688545, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07459802713410882, 'dropout_rate_Layer_2': 0.2605829107502131, 'dropout_rate_Layer_3': 0.009129140365816128, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0019095666622785778, 'l1_Layer_2': 6.874669005720084e-05, 'l1_Layer_3': 0.0010155937914157246, 'n_units_Layer_1': 140, 'n_units_Layer_2': 125, 'n_units_Layer_3': 180}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.60% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 20.16% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:42:00,882]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:42:07,539]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:42:10,838]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:42:12,667]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:42:15,613]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:42:16,670]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:42:18,590]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:42:26,959]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:42:36,030]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:43:04,138]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:43:10,481]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:43:14,972]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:43:15,863]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:43:26,216]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:43:27,890]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:43:31,795]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:43:32,048]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:43:40,541]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:43:41,006]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:00,901]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:02,416]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:06,524]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:12,681]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:19,131]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:21,978]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:28,795]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:31,723]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:36,532]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:39,302]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:41,331]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:47,945]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:44:58,110]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:45:01,148]\u001b[0m Trial 774 finished with value: 1.5068983113299532 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008046684444369676, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.226791813079309, 'dropout_rate_Layer_2': 0.030177154735603333, 'dropout_rate_Layer_3': 0.06960194651000194, 'dropout_rate_Layer_4': 0.16438547203016052, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00186875586013396, 'l1_Layer_2': 9.997140526500682e-05, 'l1_Layer_3': 7.016564920384281e-05, 'l1_Layer_4': 3.1272465000448934e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 85, 'n_units_Layer_3': 85, 'n_units_Layer_4': 215}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.81% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.97 | sMAPE for Test Set is: 32.73% | rMAE for Test Set is: 3.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:45:03,160]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:45:06,342]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:45:15,845]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:45:22,873]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:45:35,193]\u001b[0m Trial 790 finished with value: 1.5897927082450698 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028724750688141542, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2674068503248113, 'dropout_rate_Layer_2': 0.13651564759757548, 'dropout_rate_Layer_3': 0.13542030497044708, 'dropout_rate_Layer_4': 0.17074314577536875, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.2351695599981926e-05, 'l1_Layer_2': 3.159305809100954e-05, 'l1_Layer_3': 0.017689222994763047, 'l1_Layer_4': 0.00015494695827585465, 'n_units_Layer_1': 280, 'n_units_Layer_2': 65, 'n_units_Layer_3': 90, 'n_units_Layer_4': 80}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 6.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 14.80% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:45:44,512]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:45:46,606]\u001b[0m Trial 799 finished with value: 1.501703641077216 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020270328800095203, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08428613135703288, 'dropout_rate_Layer_2': 0.27034185044327147, 'dropout_rate_Layer_3': 0.015554743715871594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00033903419067064935, 'l1_Layer_2': 0.001323409680292337, 'l1_Layer_3': 0.0017528470973654133, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 19.52% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:45:49,966]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:45:53,621]\u001b[0m Trial 794 finished with value: 1.5159922831129535 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005050401651650142, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25611270336841746, 'dropout_rate_Layer_2': 0.056717220222665954, 'dropout_rate_Layer_3': 0.08481591090331342, 'dropout_rate_Layer_4': 0.12641068669446576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00022576060597536725, 'l1_Layer_2': 0.0006358273303732277, 'l1_Layer_3': 2.4341180800762816e-05, 'l1_Layer_4': 0.00010276500230535797, 'n_units_Layer_1': 265, 'n_units_Layer_2': 65, 'n_units_Layer_3': 110, 'n_units_Layer_4': 225}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.84% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.81 | sMAPE for Test Set is: 32.28% | rMAE for Test Set is: 3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:45:54,364]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:45:59,104]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:00,505]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:04,822]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:09,150]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:10,835]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:16,121]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:21,238]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:21,353]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:26,978]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:30,378]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:35,149]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:40,232]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:41,989]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:46,516]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:46:50,706]\u001b[0m Trial 802 finished with value: 1.4874413509475453 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008501620157612651, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12992922955927472, 'dropout_rate_Layer_2': 0.05396525941437987, 'dropout_rate_Layer_3': 0.03587583800931912, 'dropout_rate_Layer_4': 0.1336557628415256, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0009564281972252276, 'l1_Layer_2': 0.000598421033979019, 'l1_Layer_3': 2.4965474481443535e-05, 'l1_Layer_4': 7.698289212916665e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 60, 'n_units_Layer_3': 110, 'n_units_Layer_4': 225}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.75% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.41 | sMAPE for Test Set is: 31.05% | rMAE for Test Set is: 3.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:46:52,761]\u001b[0m Trial 805 finished with value: 1.4995993192147055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020502490199070513, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08410301012811133, 'dropout_rate_Layer_2': 0.2515341542012565, 'dropout_rate_Layer_3': 0.02234219209388926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0015798226561600768, 'l1_Layer_2': 0.0011832321651332807, 'l1_Layer_3': 0.0012835780567399635, 'n_units_Layer_1': 160, 'n_units_Layer_2': 285, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.76% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.87 | sMAPE for Test Set is: 21.03% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:46:58,890]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:47:02,457]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:47:11,666]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:47:21,414]\u001b[0m Trial 824 finished with value: 1.598641613630831 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008371832442805696, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26075735091281116, 'dropout_rate_Layer_2': 0.05788381018830713, 'dropout_rate_Layer_3': 0.035455366468255575, 'dropout_rate_Layer_4': 0.11621842899949296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0002434681932742358, 'l1_Layer_2': 0.0012208028395254361, 'l1_Layer_3': 3.808817441355243e-05, 'l1_Layer_4': 0.00011421025223201946, 'n_units_Layer_1': 260, 'n_units_Layer_2': 60, 'n_units_Layer_3': 90, 'n_units_Layer_4': 230}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 6.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.39 | sMAPE for Test Set is: 34.03% | rMAE for Test Set is: 3.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:47:24,400]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:47:38,677]\u001b[0m Trial 825 finished with value: 1.5134643368570053 and parameters: {'n_hidden': 3, 'learning_rate': 0.002270171297221269, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3503056487658301, 'dropout_rate_Layer_2': 0.23063254805328354, 'dropout_rate_Layer_3': 0.008804202743969607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0015172101559486376, 'l1_Layer_2': 0.0026636991401208414, 'l1_Layer_3': 0.0010579967626265804, 'n_units_Layer_1': 170, 'n_units_Layer_2': 280, 'n_units_Layer_3': 195}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.76 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 2.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:47:42,925]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:47:48,535]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:47:58,074]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:48:06,688]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:48:13,501]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:48:20,028]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:48:32,337]\u001b[0m Trial 831 finished with value: 1.5117701397395003 and parameters: {'n_hidden': 3, 'learning_rate': 0.002335042454505657, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3035828736570288, 'dropout_rate_Layer_2': 0.22932368554312868, 'dropout_rate_Layer_3': 0.005940099368628077, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0019148892922110424, 'l1_Layer_2': 0.0007345725786001736, 'l1_Layer_3': 0.0013342724730147097, 'n_units_Layer_1': 170, 'n_units_Layer_2': 285, 'n_units_Layer_3': 195}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.84% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.70 | sMAPE for Test Set is: 23.31% | rMAE for Test Set is: 2.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:48:47,418]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:48:57,778]\u001b[0m Trial 828 finished with value: 1.6001107364127087 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011094846983572002, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22366234907271593, 'dropout_rate_Layer_2': 0.0134606528266006, 'dropout_rate_Layer_3': 0.002767453516309193, 'dropout_rate_Layer_4': 0.08770519519169817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00015388301522830324, 'l1_Layer_2': 0.00028435124258300497, 'l1_Layer_3': 0.0001446083849713325, 'l1_Layer_4': 0.00010523340752003261, 'n_units_Layer_1': 290, 'n_units_Layer_2': 65, 'n_units_Layer_3': 75, 'n_units_Layer_4': 250}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 6.33% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.10 | sMAPE for Test Set is: 30.15% | rMAE for Test Set is: 2.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:48:57,944]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:49:10,035]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:49:12,082]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:49:33,412]\u001b[0m Trial 837 finished with value: 1.628896488091133 and parameters: {'n_hidden': 4, 'learning_rate': 0.001310877492069536, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10296943848122693, 'dropout_rate_Layer_2': 0.35143236501883246, 'dropout_rate_Layer_3': 0.3973510183116057, 'dropout_rate_Layer_4': 0.25100421200381984, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.7181060468837335e-05, 'l1_Layer_2': 0.006234811369966413, 'l1_Layer_3': 0.0027883121820933914, 'l1_Layer_4': 1.0046718216872623e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 75, 'n_units_Layer_3': 200, 'n_units_Layer_4': 225}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 6.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.19 | sMAPE for Test Set is: 36.50% | rMAE for Test Set is: 3.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:49:44,303]\u001b[0m Trial 841 finished with value: 1.468733136351992 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013508337694703397, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11068813144147922, 'dropout_rate_Layer_2': 0.055258348151035835, 'dropout_rate_Layer_3': 0.0867727605400333, 'dropout_rate_Layer_4': 0.046857415794443746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0010146568318867885, 'l1_Layer_2': 0.0004556157113143267, 'l1_Layer_3': 1.3987537066112821e-05, 'l1_Layer_4': 5.077734815059005e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 100, 'n_units_Layer_3': 55, 'n_units_Layer_4': 270}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.70% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.77 | sMAPE for Test Set is: 32.13% | rMAE for Test Set is: 3.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:49:55,488]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:50:07,919]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:50:16,356]\u001b[0m Trial 834 finished with value: 1.611234251347334 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012393504084949594, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10310496629188179, 'dropout_rate_Layer_2': 0.32541646093651844, 'dropout_rate_Layer_3': 0.3948867085674321, 'dropout_rate_Layer_4': 0.16347535090732693, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.704712571967045e-05, 'l1_Layer_2': 0.005789461310768831, 'l1_Layer_3': 0.0036191769321416195, 'l1_Layer_4': 1.1503686997064778e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 55, 'n_units_Layer_3': 190, 'n_units_Layer_4': 220}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.61 | sMAPE for Validation Set is: 6.33% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.84 | sMAPE for Test Set is: 32.35% | rMAE for Test Set is: 3.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:50:21,974]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:50:25,514]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:50:30,041]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:50:32,734]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:50:41,844]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:50:46,450]\u001b[0m Trial 842 finished with value: 1.6008925826278702 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009571761582708266, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11208762240277169, 'dropout_rate_Layer_2': 0.3526663476513051, 'dropout_rate_Layer_3': 0.37429102222833943, 'dropout_rate_Layer_4': 0.14503199778967674, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.3290572237315097e-05, 'l1_Layer_2': 0.00375922767551644, 'l1_Layer_3': 0.003564269006325505, 'l1_Layer_4': 1.1622064172019307e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 65, 'n_units_Layer_3': 195, 'n_units_Layer_4': 225}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 6.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.77 | sMAPE for Test Set is: 35.25% | rMAE for Test Set is: 3.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:50:52,479]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:51:01,771]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:51:29,970]\u001b[0m Trial 854 finished with value: 1.4795843329553946 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029509726407970006, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06299637842132866, 'dropout_rate_Layer_2': 0.23307979388986091, 'dropout_rate_Layer_3': 0.013300684050330087, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002661184507729647, 'l1_Layer_2': 0.002275952411035448, 'l1_Layer_3': 0.0013852384373108572, 'n_units_Layer_1': 165, 'n_units_Layer_2': 290, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.71% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.15 | sMAPE for Test Set is: 21.80% | rMAE for Test Set is: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:51:36,382]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:51:43,745]\u001b[0m Trial 855 finished with value: 1.5110297074930628 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026330559866546877, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06360817995420587, 'dropout_rate_Layer_2': 0.24586731778951706, 'dropout_rate_Layer_3': 0.014364592284852672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0026596778200901005, 'l1_Layer_2': 0.0023440563476989948, 'l1_Layer_3': 0.0014698649547831124, 'n_units_Layer_1': 185, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.83% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.35 | sMAPE for Test Set is: 22.34% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:52:09,264]\u001b[0m Trial 858 finished with value: 1.630234783010998 and parameters: {'n_hidden': 4, 'learning_rate': 0.003067033582820887, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2046479367500673, 'dropout_rate_Layer_2': 0.1292455341498953, 'dropout_rate_Layer_3': 0.15014711316800106, 'dropout_rate_Layer_4': 0.09141065706823845, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.762138297736661e-05, 'l1_Layer_2': 3.768782155012497e-05, 'l1_Layer_3': 0.0314153145556668, 'l1_Layer_4': 2.574400855334567e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 80, 'n_units_Layer_3': 95, 'n_units_Layer_4': 85}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.53 | sMAPE for Test Set is: 22.90% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:52:27,480]\u001b[0m Trial 850 finished with value: 1.5426069471423187 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011065842013149706, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10637188152079456, 'dropout_rate_Layer_2': 0.3582016309739774, 'dropout_rate_Layer_3': 0.3852654199901843, 'dropout_rate_Layer_4': 0.17605972021850075, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.0075043572708035e-05, 'l1_Layer_2': 0.0033704094069034363, 'l1_Layer_3': 0.004123959832704264, 'l1_Layer_4': 1.003581617557319e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 55, 'n_units_Layer_3': 195, 'n_units_Layer_4': 230}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 6.00% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.51 | sMAPE for Test Set is: 34.40% | rMAE for Test Set is: 3.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:52:40,420]\u001b[0m Trial 852 finished with value: 1.6023996437417285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010798524898397188, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10447939192846893, 'dropout_rate_Layer_2': 0.3484755519305968, 'dropout_rate_Layer_3': 0.3978469219804098, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0398124129370733e-05, 'l1_Layer_2': 0.0045630008989811285, 'l1_Layer_3': 0.004056424675067402, 'n_units_Layer_1': 55, 'n_units_Layer_2': 60, 'n_units_Layer_3': 200}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 6.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.51 | sMAPE for Test Set is: 34.42% | rMAE for Test Set is: 3.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:53:09,249]\u001b[0m Trial 861 finished with value: 1.4866302319012539 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014324680203126005, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25249123465722145, 'dropout_rate_Layer_2': 0.050293810035862994, 'dropout_rate_Layer_3': 0.07843791706408114, 'dropout_rate_Layer_4': 0.06377632437417423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0002878561356939272, 'l1_Layer_2': 0.00044711716282741363, 'l1_Layer_3': 1.3920169856705982e-05, 'l1_Layer_4': 5.847872506194763e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 100, 'n_units_Layer_3': 55, 'n_units_Layer_4': 275}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.75% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.76 | sMAPE for Test Set is: 32.11% | rMAE for Test Set is: 3.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:53:45,437]\u001b[0m Trial 862 finished with value: 1.5011579892799618 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023096084376787764, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03919210708888196, 'dropout_rate_Layer_2': 0.23613981399072614, 'dropout_rate_Layer_3': 0.014117426258505537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0026599746762618593, 'l1_Layer_2': 0.002578776163437262, 'l1_Layer_3': 0.0013960766777242999, 'n_units_Layer_1': 185, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.82% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.82 | sMAPE for Test Set is: 20.92% | rMAE for Test Set is: 2.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:53:52,085]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:53:57,907]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:53:58,510]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:54:04,254]\u001b[0m Trial 860 finished with value: 1.5956929913135436 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011476707716062784, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10522569783730089, 'dropout_rate_Layer_2': 0.3660327720406406, 'dropout_rate_Layer_3': 0.3920843083732599, 'dropout_rate_Layer_4': 0.1768872839347263, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.8553287859052766e-05, 'l1_Layer_2': 0.0033193151247806188, 'l1_Layer_3': 0.0051648298973526845, 'l1_Layer_4': 1.211259540322294e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 60, 'n_units_Layer_3': 205, 'n_units_Layer_4': 225}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 6.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.64 | sMAPE for Test Set is: 34.81% | rMAE for Test Set is: 3.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:54:25,595]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:54:34,619]\u001b[0m Trial 865 finished with value: 1.4958661771442194 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031682913991919687, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038402497982488626, 'dropout_rate_Layer_2': 0.23156121877317612, 'dropout_rate_Layer_3': 0.01507880871051623, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003665915418829696, 'l1_Layer_2': 0.0026399753764112586, 'l1_Layer_3': 0.0013850083169991809, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.56 | sMAPE for Test Set is: 20.24% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:54:42,172]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:54:44,807]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:54:49,390]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:54:54,034]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:54:59,350]\u001b[0m Trial 867 finished with value: 1.465696583926345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025001501348448744, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05982105690944568, 'dropout_rate_Layer_2': 0.23121036566517034, 'dropout_rate_Layer_3': 0.014625555068967424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002481254894835745, 'l1_Layer_2': 0.002566473320142543, 'l1_Layer_3': 0.0014672869305422357, 'n_units_Layer_1': 195, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.65% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.78 | sMAPE for Test Set is: 20.80% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:55:00,316]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:55:09,304]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:55:14,364]\u001b[0m Trial 872 finished with value: 1.5027737991614487 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013810936538132422, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25130235993471295, 'dropout_rate_Layer_2': 0.053381342866336653, 'dropout_rate_Layer_3': 0.08125607293180309, 'dropout_rate_Layer_4': 0.04931667136368439, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0009650203620959717, 'l1_Layer_2': 0.0004612380237516702, 'l1_Layer_3': 1.2366337800543037e-05, 'l1_Layer_4': 4.9827454991866594e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 105, 'n_units_Layer_3': 55, 'n_units_Layer_4': 265}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.81% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.97 | sMAPE for Test Set is: 32.74% | rMAE for Test Set is: 3.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:55:23,004]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:55:33,577]\u001b[0m Trial 873 finished with value: 1.51134029458133 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014920344566710514, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25096052003055597, 'dropout_rate_Layer_2': 0.05034768428836666, 'dropout_rate_Layer_3': 0.0794779991282916, 'dropout_rate_Layer_4': 0.047121293401729936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0002668189169337131, 'l1_Layer_2': 0.0007652282160318073, 'l1_Layer_3': 1.1124144905989106e-05, 'l1_Layer_4': 6.325029982070421e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 95, 'n_units_Layer_3': 60, 'n_units_Layer_4': 275}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.86% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.67 | sMAPE for Test Set is: 31.86% | rMAE for Test Set is: 3.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:55:36,912]\u001b[0m Trial 875 finished with value: 1.4920344553180247 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013997816177290364, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25019737863949726, 'dropout_rate_Layer_2': 0.05352456438867727, 'dropout_rate_Layer_3': 0.08013094542122108, 'dropout_rate_Layer_4': 0.04761881523467815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00031111175656151643, 'l1_Layer_2': 0.0008322500305485953, 'l1_Layer_3': 1.2834523832394732e-05, 'l1_Layer_4': 5.222556465177817e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 100, 'n_units_Layer_3': 50, 'n_units_Layer_4': 265}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.76% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.67 | sMAPE for Test Set is: 31.84% | rMAE for Test Set is: 3.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:55:40,487]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:55:46,911]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:56:07,287]\u001b[0m Trial 876 finished with value: 1.489392863443222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026518967031183252, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0454358620582761, 'dropout_rate_Layer_2': 0.2323510203341765, 'dropout_rate_Layer_3': 0.023635588669330895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0028271438190313816, 'l1_Layer_2': 0.002401884531011038, 'l1_Layer_3': 0.0012976385163325657, 'n_units_Layer_1': 190, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.73% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.99 | sMAPE for Test Set is: 21.39% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:56:12,662]\u001b[0m Trial 878 finished with value: 1.4743501794937606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026230210246614115, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028502503894570652, 'dropout_rate_Layer_2': 0.2293525722729851, 'dropout_rate_Layer_3': 0.0237818386525502, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004009299190611902, 'l1_Layer_2': 0.002774139080912546, 'l1_Layer_3': 0.0013293181447194978, 'n_units_Layer_1': 175, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.68% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 21.02% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:56:16,642]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:56:22,786]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:56:23,171]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:56:27,395]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:56:31,749]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:56:33,161]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:56:34,484]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:56:39,429]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:56:48,185]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:56:48,319]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:57:11,339]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:57:12,032]\u001b[0m Trial 888 finished with value: 1.4801554216042134 and parameters: {'n_hidden': 3, 'learning_rate': 0.002633114500533954, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015563021267644125, 'dropout_rate_Layer_2': 0.21660031120662457, 'dropout_rate_Layer_3': 0.02126664907612455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0033151490454460942, 'l1_Layer_2': 0.0027710160360430226, 'l1_Layer_3': 0.0013049506305527034, 'n_units_Layer_1': 180, 'n_units_Layer_2': 300, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.74% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.64 | sMAPE for Test Set is: 20.42% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:57:21,272]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:57:25,035]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:57:28,346]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:57:31,299]\u001b[0m Trial 889 finished with value: 1.4754709721810328 and parameters: {'n_hidden': 3, 'learning_rate': 0.002512562912195683, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01947723829517342, 'dropout_rate_Layer_2': 0.22963489946761725, 'dropout_rate_Layer_3': 0.021460930100996534, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0039136201282039245, 'l1_Layer_2': 0.0017850084586614353, 'l1_Layer_3': 0.0012802687535848033, 'n_units_Layer_1': 185, 'n_units_Layer_2': 300, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.67% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.71 | sMAPE for Test Set is: 20.63% | rMAE for Test Set is: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:57:36,799]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:57:49,951]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:57:56,872]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:58:04,374]\u001b[0m Trial 893 finished with value: 1.6291887724510563 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008091222192612702, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09520377269538527, 'dropout_rate_Layer_2': 0.35737597495006507, 'dropout_rate_Layer_3': 0.3999092996273191, 'dropout_rate_Layer_4': 0.15890706991886508, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.3845822933019944e-05, 'l1_Layer_2': 0.005840831535764538, 'l1_Layer_3': 0.0034551377343807763, 'l1_Layer_4': 0.0010035020879148085, 'n_units_Layer_1': 70, 'n_units_Layer_2': 60, 'n_units_Layer_3': 200, 'n_units_Layer_4': 220}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.94 | sMAPE for Test Set is: 38.94% | rMAE for Test Set is: 3.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:58:08,370]\u001b[0m Trial 900 finished with value: 1.5462443630610985 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034184298153630477, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1987051146974776, 'dropout_rate_Layer_2': 0.1356401811375997, 'dropout_rate_Layer_3': 0.13586051816533418, 'dropout_rate_Layer_4': 0.0955132183083717, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.412553645718122e-05, 'l1_Layer_2': 0.0007517408874473289, 'l1_Layer_3': 0.009387324159676727, 'l1_Layer_4': 0.0001598487182694871, 'n_units_Layer_1': 295, 'n_units_Layer_2': 85, 'n_units_Layer_3': 80, 'n_units_Layer_4': 85}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.95% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.14 | sMAPE for Test Set is: 19.11% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:58:10,058]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:58:14,570]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:58:21,634]\u001b[0m Trial 902 finished with value: 1.4853829492181816 and parameters: {'n_hidden': 3, 'learning_rate': 0.002865528380572238, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008751797917406868, 'dropout_rate_Layer_2': 0.2073282521658135, 'dropout_rate_Layer_3': 0.022191961396695763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004702537532803285, 'l1_Layer_2': 0.001893808261076379, 'l1_Layer_3': 0.0013258925008696623, 'n_units_Layer_1': 190, 'n_units_Layer_2': 300, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.76% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.00 | sMAPE for Test Set is: 21.38% | rMAE for Test Set is: 2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:58:28,555]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:58:35,550]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:58:42,917]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:58:44,198]\u001b[0m Trial 903 finished with value: 1.4783686690268347 and parameters: {'n_hidden': 3, 'learning_rate': 0.002897969361545223, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011941362264277501, 'dropout_rate_Layer_2': 0.21558680210999118, 'dropout_rate_Layer_3': 0.023559080947949694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004275252560469663, 'l1_Layer_2': 0.005543712111154761, 'l1_Layer_3': 0.0013360410325453191, 'n_units_Layer_1': 195, 'n_units_Layer_2': 300, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.73% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.39 | sMAPE for Test Set is: 19.78% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:58:49,343]\u001b[0m Trial 906 finished with value: 1.5044632921360945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028612170782428724, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025407072566772482, 'dropout_rate_Layer_2': 0.21162965489638344, 'dropout_rate_Layer_3': 0.0234056915977949, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004464226941931137, 'l1_Layer_2': 0.001972222325855339, 'l1_Layer_3': 0.001348238007812359, 'n_units_Layer_1': 195, 'n_units_Layer_2': 300, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.81% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.21 | sMAPE for Test Set is: 21.96% | rMAE for Test Set is: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:58:55,796]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:59:04,018]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:59:10,121]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:59:14,959]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:59:21,970]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:59:25,923]\u001b[0m Trial 912 finished with value: 1.4675830845593076 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013132674075511258, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.129928462989969, 'dropout_rate_Layer_2': 0.07020810421873605, 'dropout_rate_Layer_3': 0.0883066552108441, 'dropout_rate_Layer_4': 0.0009544326681240889, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0003344160636512629, 'l1_Layer_2': 0.0004844800643708432, 'l1_Layer_3': 1.295340226062608e-05, 'l1_Layer_4': 0.00020723788989814105, 'n_units_Layer_1': 140, 'n_units_Layer_2': 100, 'n_units_Layer_3': 60, 'n_units_Layer_4': 270}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.64% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.69 | sMAPE for Test Set is: 31.92% | rMAE for Test Set is: 3.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 11:59:33,415]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:59:36,668]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:59:40,891]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:59:41,516]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:59:41,775]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 11:59:48,500]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:00:04,647]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:00:11,564]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:00:19,885]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:00:23,239]\u001b[0m Trial 926 finished with value: 1.4925437845819711 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016792614667285389, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13243246459517355, 'dropout_rate_Layer_2': 0.09880522780356725, 'dropout_rate_Layer_3': 0.1158017758910247, 'dropout_rate_Layer_4': 0.0021914462056789458, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0003236013388866947, 'l1_Layer_2': 0.0011119725800298875, 'l1_Layer_3': 1.031805132576315e-05, 'l1_Layer_4': 0.00013226022845680386, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 60, 'n_units_Layer_4': 275}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.96 | sMAPE for Test Set is: 32.69% | rMAE for Test Set is: 3.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:00:30,260]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:00:36,325]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:00:41,204]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:00:41,501]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:00:50,016]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:00:50,145]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:01:02,150]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:01:02,273]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:01:09,237]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:01:13,576]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:01:31,207]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:01:34,193]\u001b[0m Trial 907 finished with value: 1.5923237469964409 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009123431692171455, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10733784594677918, 'dropout_rate_Layer_2': 0.37533116727020915, 'dropout_rate_Layer_3': 0.38299758001425477, 'dropout_rate_Layer_4': 0.16154270514157637, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.4824259233198015e-05, 'l1_Layer_2': 0.0045329596988731655, 'l1_Layer_3': 0.0034110159296948644, 'l1_Layer_4': 0.0011513696572138159, 'n_units_Layer_1': 70, 'n_units_Layer_2': 50, 'n_units_Layer_3': 205, 'n_units_Layer_4': 215}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 6.27% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.32 | sMAPE for Test Set is: 33.83% | rMAE for Test Set is: 3.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:01:39,325]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:01:44,348]\u001b[0m Trial 938 finished with value: 1.5096979537911477 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016541623930096678, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10066583368511572, 'dropout_rate_Layer_2': 0.07462910527722696, 'dropout_rate_Layer_3': 0.0881986248766666, 'dropout_rate_Layer_4': 0.026095089517465087, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0005139891752857007, 'l1_Layer_2': 0.0010447857430137073, 'l1_Layer_3': 1.4906239254038445e-05, 'l1_Layer_4': 0.0003265065863933719, 'n_units_Layer_1': 160, 'n_units_Layer_2': 140, 'n_units_Layer_3': 75, 'n_units_Layer_4': 285}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.84% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.72 | sMAPE for Test Set is: 32.04% | rMAE for Test Set is: 3.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:01:47,079]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:01:52,118]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:01:55,122]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:01:59,972]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:02:11,846]\u001b[0m Trial 939 finished with value: 1.4988535835978258 and parameters: {'n_hidden': 3, 'learning_rate': 0.002924581135822389, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027089367200344168, 'dropout_rate_Layer_2': 0.21569311604071412, 'dropout_rate_Layer_3': 0.03529548369933638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003115164539597591, 'l1_Layer_2': 0.0020230421412036036, 'l1_Layer_3': 0.0008950883362193374, 'n_units_Layer_1': 180, 'n_units_Layer_2': 300, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.84% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.13 | sMAPE for Test Set is: 19.07% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:02:21,719]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:02:22,184]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:02:33,005]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:03:12,346]\u001b[0m Trial 951 finished with value: 1.506113690548547 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026012043087719583, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020980638694187405, 'dropout_rate_Layer_2': 0.21917048241235715, 'dropout_rate_Layer_3': 0.01480397452031561, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0030567655976640132, 'l1_Layer_2': 0.0024106976664424796, 'l1_Layer_3': 0.001910732734535991, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.80% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.76 | sMAPE for Test Set is: 20.77% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:03:19,177]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:03:37,055]\u001b[0m Trial 940 finished with value: 1.6536305413898809 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014634992772186676, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12429197486626117, 'dropout_rate_Layer_2': 0.37360876692825357, 'dropout_rate_Layer_3': 0.3994561350986927, 'dropout_rate_Layer_4': 0.15566683697276668, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.6934049009329283e-05, 'l1_Layer_2': 0.005092044090519362, 'l1_Layer_3': 0.003942227453443495, 'l1_Layer_4': 1.7950987328286317e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195, 'n_units_Layer_4': 220}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 6.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 14.27 | sMAPE for Test Set is: 36.81% | rMAE for Test Set is: 3.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:04:06,590]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:04:08,524]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:04:17,638]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:04:36,665]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:04:39,676]\u001b[0m Trial 950 finished with value: 1.6253537851583133 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010078813789577488, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1102594518477477, 'dropout_rate_Layer_2': 0.36288329533047003, 'dropout_rate_Layer_3': 0.399389312878654, 'dropout_rate_Layer_4': 0.14141046285368936, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 5.901278476848977e-05, 'l1_Layer_2': 0.003991807643511326, 'l1_Layer_3': 0.005831033452665031, 'l1_Layer_4': 0.001186449149720542, 'n_units_Layer_1': 85, 'n_units_Layer_2': 55, 'n_units_Layer_3': 195, 'n_units_Layer_4': 215}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 6.39% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.13 | sMAPE for Test Set is: 33.23% | rMAE for Test Set is: 3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:04:42,499]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:05:02,998]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:05:06,643]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:05:11,383]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:05:15,921]\u001b[0m Trial 956 finished with value: 1.4422361130643377 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012961461396255873, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08247328425997394, 'dropout_rate_Layer_2': 0.11811117447709876, 'dropout_rate_Layer_3': 0.12472867938375212, 'dropout_rate_Layer_4': 0.0635795358664953, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00012449562743321716, 'l1_Layer_2': 0.0003645943630467122, 'l1_Layer_3': 0.0026233174546894337, 'l1_Layer_4': 0.0002508606738812092, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 60, 'n_units_Layer_4': 245}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.57% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 12.24 | sMAPE for Test Set is: 30.59% | rMAE for Test Set is: 2.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:05:29,985]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:05:42,499]\u001b[0m Trial 954 finished with value: 1.641336773218833 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014272718048156904, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14132809593667287, 'dropout_rate_Layer_2': 0.38290420733587893, 'dropout_rate_Layer_3': 0.39923477621060754, 'dropout_rate_Layer_4': 0.16852965562946295, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.7426731392879083e-05, 'l1_Layer_2': 0.006062440450902111, 'l1_Layer_3': 0.0027761573707392453, 'l1_Layer_4': 1.6566611301858448e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 55, 'n_units_Layer_3': 200, 'n_units_Layer_4': 220}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.64 | sMAPE for Validation Set is: 6.40% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.62 | sMAPE for Test Set is: 34.76% | rMAE for Test Set is: 3.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:05:50,916]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:06:00,973]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:06:01,523]\u001b[0m Trial 964 finished with value: 1.5154494871551545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038776152215148087, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038434252790682515, 'dropout_rate_Layer_2': 0.2087854655294908, 'dropout_rate_Layer_3': 0.014704320660083427, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002621977945058036, 'l1_Layer_2': 0.001964679456101251, 'l1_Layer_3': 0.0014533581331551025, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 22.82% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:06:09,441]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:06:19,063]\u001b[0m Trial 965 finished with value: 1.493464276861656 and parameters: {'n_hidden': 3, 'learning_rate': 0.003752368477039805, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04212690674172351, 'dropout_rate_Layer_2': 0.20999007884286353, 'dropout_rate_Layer_3': 0.01429344897307565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002916158527574297, 'l1_Layer_2': 0.0019830420041185774, 'l1_Layer_3': 0.0014429205942019835, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.77% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.05 | sMAPE for Test Set is: 21.53% | rMAE for Test Set is: 2.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:06:23,301]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:06:26,377]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:07:04,462]\u001b[0m Trial 970 finished with value: 1.4480588808761186 and parameters: {'n_hidden': 4, 'learning_rate': 0.001296985093719134, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08273924630117654, 'dropout_rate_Layer_2': 0.09968176699571185, 'dropout_rate_Layer_3': 0.10711103689888112, 'dropout_rate_Layer_4': 0.06935851212625438, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00013095996081874373, 'l1_Layer_2': 0.00017486451469364613, 'l1_Layer_3': 0.002591569389306904, 'l1_Layer_4': 0.00023817609281984495, 'n_units_Layer_1': 125, 'n_units_Layer_2': 115, 'n_units_Layer_3': 65, 'n_units_Layer_4': 260}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.61% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 12.52 | sMAPE for Test Set is: 31.41% | rMAE for Test Set is: 3.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:07:08,464]\u001b[0m Trial 972 finished with value: 1.4894441238994702 and parameters: {'n_hidden': 3, 'learning_rate': 0.002851368802006717, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024314712768320014, 'dropout_rate_Layer_2': 0.2225703739162431, 'dropout_rate_Layer_3': 0.02443797642077188, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0030778304073074557, 'l1_Layer_2': 0.002706506754504723, 'l1_Layer_3': 0.002173543728296651, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 205}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.74% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 20.77% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:07:14,319]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:07:20,527]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:07:23,806]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:07:24,378]\u001b[0m Trial 961 finished with value: 1.63235197491042 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013420936373732778, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12747252050105146, 'dropout_rate_Layer_2': 0.39156560544553987, 'dropout_rate_Layer_3': 0.3986256162020044, 'dropout_rate_Layer_4': 0.1509791925228306, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 6.424792694203829e-05, 'l1_Layer_2': 0.0038393112949632307, 'l1_Layer_3': 0.008401951444518505, 'l1_Layer_4': 0.0011512641654258897, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195, 'n_units_Layer_4': 210}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 6.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.80 | sMAPE for Test Set is: 35.30% | rMAE for Test Set is: 3.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:07:28,045]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:07:34,902]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:07:35,147]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:07:42,890]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:07:49,022]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:07:58,354]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:08:23,461]\u001b[0m Trial 983 finished with value: 1.5092840385081825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033453566947135266, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03225022651227057, 'dropout_rate_Layer_2': 0.22683293073186622, 'dropout_rate_Layer_3': 0.021965051770128058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003938632664983438, 'l1_Layer_2': 0.0037408063199784384, 'l1_Layer_3': 0.0017770029949821533, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 205}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.86% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.31 | sMAPE for Test Set is: 19.56% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:08:42,474]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:08:46,947]\u001b[0m Trial 984 finished with value: 1.4817085416800928 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032903595097057772, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029955223896645997, 'dropout_rate_Layer_2': 0.2393409933205539, 'dropout_rate_Layer_3': 0.02136413462653608, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0038607275152839123, 'l1_Layer_2': 0.003686056245393556, 'l1_Layer_3': 0.001746404755460611, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 205}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.72% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.92 | sMAPE for Test Set is: 21.20% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:09:01,726]\u001b[0m Trial 976 finished with value: 1.6476088343918651 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017663028978996131, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12360344640498885, 'dropout_rate_Layer_2': 0.38482877924053926, 'dropout_rate_Layer_3': 0.39819364090589193, 'dropout_rate_Layer_4': 0.14183394212269398, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.337898678657587e-05, 'l1_Layer_2': 0.0037040659482768475, 'l1_Layer_3': 0.004332576915669363, 'l1_Layer_4': 1.6744257045781986e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 55, 'n_units_Layer_3': 195, 'n_units_Layer_4': 225}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 6.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.83 | sMAPE for Test Set is: 35.42% | rMAE for Test Set is: 3.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:09:07,721]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:09:17,031]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:09:22,101]\u001b[0m Trial 987 finished with value: 1.48394850250063 and parameters: {'n_hidden': 3, 'learning_rate': 0.002757678139947822, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01664302584280674, 'dropout_rate_Layer_2': 0.23581285793469536, 'dropout_rate_Layer_3': 0.010837114124710567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0029679509896335357, 'l1_Layer_2': 0.002819965677311903, 'l1_Layer_3': 0.001164817257366094, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.73% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.81 | sMAPE for Test Set is: 20.91% | rMAE for Test Set is: 2.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:09:31,630]\u001b[0m Trial 988 finished with value: 1.4438580473375051 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013116571580927363, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08420399169449924, 'dropout_rate_Layer_2': 0.11234988272334037, 'dropout_rate_Layer_3': 0.12827051103161438, 'dropout_rate_Layer_4': 0.06710145205302734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00012206383280949143, 'l1_Layer_2': 0.00016733183343677768, 'l1_Layer_3': 0.0029142223301721485, 'l1_Layer_4': 0.00023899405678772897, 'n_units_Layer_1': 115, 'n_units_Layer_2': 115, 'n_units_Layer_3': 75, 'n_units_Layer_4': 240}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.60% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 12.23 | sMAPE for Test Set is: 30.55% | rMAE for Test Set is: 2.97\n",
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 6.25% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.37 | sMAPE for Test Set is: 37.11% | rMAE for Test Set is: 3.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:09:37,886]\u001b[0m Trial 985 finished with value: 1.616898759641239 and parameters: {'n_hidden': 4, 'learning_rate': 0.001176782462498599, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1291590528509981, 'dropout_rate_Layer_2': 0.36773190908541636, 'dropout_rate_Layer_3': 0.39964883535771567, 'dropout_rate_Layer_4': 0.16950824717346177, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 5.5766322703397486e-05, 'l1_Layer_2': 0.0055185261825868095, 'l1_Layer_3': 0.010409207883227748, 'l1_Layer_4': 0.000952931214870629, 'n_units_Layer_1': 75, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195, 'n_units_Layer_4': 230}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:09:41,874]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:09:51,508]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:10:10,749]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:10:18,512]\u001b[0m Trial 992 finished with value: 1.4356433312098185 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013039822842974536, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08510124814011044, 'dropout_rate_Layer_2': 0.07064120242047373, 'dropout_rate_Layer_3': 0.10768190174298563, 'dropout_rate_Layer_4': 0.06515636894774068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00012211291060839943, 'l1_Layer_2': 0.00034888368085840793, 'l1_Layer_3': 0.0025155734420784755, 'l1_Layer_4': 0.0002468794191133002, 'n_units_Layer_1': 115, 'n_units_Layer_2': 115, 'n_units_Layer_3': 65, 'n_units_Layer_4': 240}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.56% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 12.04 | sMAPE for Test Set is: 29.98% | rMAE for Test Set is: 2.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:10:32,275]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:10:40,781]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:11:29,474]\u001b[0m Trial 1000 finished with value: 1.5001319316245991 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033728013548964997, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009814460788925918, 'dropout_rate_Layer_2': 0.23886004833251018, 'dropout_rate_Layer_3': 0.014291974566595943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0035474001990288906, 'l1_Layer_2': 0.003029010841039097, 'l1_Layer_3': 0.0017287581936959381, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 200}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.63 | sMAPE for Test Set is: 20.40% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:12:05,158]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:12:10,319]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:12:25,010]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:12:27,607]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:12:34,468]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:12:48,011]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.70% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.65 | sMAPE for Test Set is: 20.47% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:12:50,846]\u001b[0m Trial 1003 finished with value: 1.4750388944970385 and parameters: {'n_hidden': 3, 'learning_rate': 0.003408770857560081, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006899345810840056, 'dropout_rate_Layer_2': 0.23590954881070553, 'dropout_rate_Layer_3': 0.014190870108808998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002782675713206452, 'l1_Layer_2': 0.0031065945845228818, 'l1_Layer_3': 0.0018043236546846577, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 210}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:12:55,816]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:13:02,100]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:13:09,149]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:13:13,213]\u001b[0m Trial 1005 finished with value: 1.5058132616412487 and parameters: {'n_hidden': 3, 'learning_rate': 0.003431501595534193, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012099933152540307, 'dropout_rate_Layer_2': 0.23476779036066842, 'dropout_rate_Layer_3': 0.01343425655852023, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0027924135402329904, 'l1_Layer_2': 0.0050767469618233025, 'l1_Layer_3': 0.0016754138718366785, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 200}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.83% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.95 | sMAPE for Test Set is: 21.31% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:13:19,176]\u001b[0m Trial 1006 finished with value: 1.4865379081846835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034898454492343334, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008496511471035938, 'dropout_rate_Layer_2': 0.23825105107320052, 'dropout_rate_Layer_3': 0.013230024476026211, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00353174265280022, 'l1_Layer_2': 0.005394839898147567, 'l1_Layer_3': 0.0017405810070490772, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 205}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.75% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.83 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 2.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:13:22,173]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:13:29,101]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:13:39,309]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:14:13,430]\u001b[0m Trial 1014 finished with value: 1.4838107426783669 and parameters: {'n_hidden': 3, 'learning_rate': 0.004055306724788023, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007421953493860497, 'dropout_rate_Layer_2': 0.22572326098864404, 'dropout_rate_Layer_3': 0.031185212594541135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003909763344600013, 'l1_Layer_2': 0.005932181847317811, 'l1_Layer_3': 0.0010505547145776234, 'n_units_Layer_1': 210, 'n_units_Layer_2': 275, 'n_units_Layer_3': 205}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.73% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.41 | sMAPE for Test Set is: 19.82% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:14:26,548]\u001b[0m Trial 1015 finished with value: 1.5055565853625037 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012597559902941973, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027816764369365185, 'dropout_rate_Layer_2': 0.11391654097465312, 'dropout_rate_Layer_3': 0.10723049677671863, 'dropout_rate_Layer_4': 0.06823175308357289, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.885111830471905e-05, 'l1_Layer_2': 0.00017896134067220778, 'l1_Layer_3': 0.0024239223608677847, 'l1_Layer_4': 0.000248773007472807, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 75, 'n_units_Layer_4': 240}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.83% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 13.15 | sMAPE for Test Set is: 33.30% | rMAE for Test Set is: 3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:14:34,107]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:14:37,608]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:14:54,953]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:15:00,166]\u001b[0m Trial 1009 finished with value: 1.6314092767527206 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014820220138361305, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15175950239030903, 'dropout_rate_Layer_2': 0.3633460238397105, 'dropout_rate_Layer_3': 0.3993060186075666, 'dropout_rate_Layer_4': 0.12908814299072865, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.4291972773868187e-05, 'l1_Layer_2': 0.0038016757291451445, 'l1_Layer_3': 0.005436295469176739, 'l1_Layer_4': 1.4079926455910705e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 65, 'n_units_Layer_3': 205, 'n_units_Layer_4': 230}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.63 | sMAPE for Validation Set is: 6.41% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.83 | sMAPE for Test Set is: 35.44% | rMAE for Test Set is: 3.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:15:02,746]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:15:22,891]\u001b[0m Trial 1022 finished with value: 1.5460491454179504 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022107317289250072, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08218181880695052, 'dropout_rate_Layer_2': 0.12579789358683097, 'dropout_rate_Layer_3': 0.12723376884310866, 'dropout_rate_Layer_4': 0.026750473682740195, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 6.82906604754885e-05, 'l1_Layer_2': 0.00033234482569182827, 'l1_Layer_3': 0.0012346209282956954, 'l1_Layer_4': 0.0005153189570946248, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 60, 'n_units_Layer_4': 255}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.98% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.48 | sMAPE for Test Set is: 34.30% | rMAE for Test Set is: 3.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:15:26,863]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:15:34,629]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:15:49,802]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:15:53,212]\u001b[0m Trial 1016 finished with value: 1.5835353348419432 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014663824889202353, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15172253082785642, 'dropout_rate_Layer_2': 0.3573682178341226, 'dropout_rate_Layer_3': 0.39950627481363754, 'dropout_rate_Layer_4': 0.1733070188440095, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.4697207303106936e-05, 'l1_Layer_2': 0.003606245560007474, 'l1_Layer_3': 0.0043386356093388445, 'l1_Layer_4': 0.0006645091459935053, 'n_units_Layer_1': 85, 'n_units_Layer_2': 50, 'n_units_Layer_3': 190, 'n_units_Layer_4': 220}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 6.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.66 | sMAPE for Test Set is: 34.87% | rMAE for Test Set is: 3.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:16:18,160]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:16:21,223]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:16:25,611]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:16:29,244]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:17:22,579]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:17:26,718]\u001b[0m Trial 1027 finished with value: 1.5755052223685067 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013746232912180151, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15532833315967776, 'dropout_rate_Layer_2': 0.3886874066236553, 'dropout_rate_Layer_3': 0.3849250101583552, 'dropout_rate_Layer_4': 0.14106969604618258, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.541330710167138e-05, 'l1_Layer_2': 0.003436556604405348, 'l1_Layer_3': 0.00415783604655624, 'l1_Layer_4': 1.6995394157788926e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 60, 'n_units_Layer_3': 200, 'n_units_Layer_4': 215}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 6.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.04 | sMAPE for Test Set is: 36.07% | rMAE for Test Set is: 3.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:17:34,821]\u001b[0m Trial 1021 finished with value: 1.5679902479013696 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011503258369756461, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15011791991743764, 'dropout_rate_Layer_2': 0.37474534248650987, 'dropout_rate_Layer_3': 0.3997950902599571, 'dropout_rate_Layer_4': 0.15415264285265468, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.437641031511196e-05, 'l1_Layer_2': 0.0036355329195040423, 'l1_Layer_3': 0.004411965359981681, 'l1_Layer_4': 1.755407512061905e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 65, 'n_units_Layer_3': 195, 'n_units_Layer_4': 235}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 6.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.75 | sMAPE for Test Set is: 35.17% | rMAE for Test Set is: 3.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:17:39,157]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:17:46,186]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:17:47,057]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:17:55,737]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:18:00,648]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:18:03,309]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:18:05,980]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:18:13,923]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:18:24,450]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:18:28,062]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:18:50,187]\u001b[0m Trial 1042 finished with value: 1.4926887549545957 and parameters: {'n_hidden': 3, 'learning_rate': 0.003568698524524134, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015981140499176816, 'dropout_rate_Layer_2': 0.24870665594002497, 'dropout_rate_Layer_3': 0.021919913559901284, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0038363728262677823, 'l1_Layer_2': 0.007739484579092092, 'l1_Layer_3': 0.001134730288406531, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.52 | sMAPE for Test Set is: 20.12% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:18:58,843]\u001b[0m Trial 1045 finished with value: 1.650480059050093 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022539665849726476, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18335492807710602, 'dropout_rate_Layer_2': 0.19259500380199243, 'dropout_rate_Layer_3': 0.14035497899543128, 'dropout_rate_Layer_4': 0.14163273136906482, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017046329683995074, 'l1_Layer_2': 4.018209025000777e-05, 'l1_Layer_3': 0.0033037480276739005, 'l1_Layer_4': 0.00021361905477845092, 'n_units_Layer_1': 280, 'n_units_Layer_2': 80, 'n_units_Layer_3': 135, 'n_units_Layer_4': 115}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 6.37% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 14.06 | sMAPE for Test Set is: 36.15% | rMAE for Test Set is: 3.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:19:02,281]\u001b[0m Trial 1032 finished with value: 1.5629583344379616 and parameters: {'n_hidden': 4, 'learning_rate': 0.00138726957198933, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1565677832156048, 'dropout_rate_Layer_2': 0.3691384931104364, 'dropout_rate_Layer_3': 0.39997178951269174, 'dropout_rate_Layer_4': 0.13894359845866894, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.621470373746136e-05, 'l1_Layer_2': 0.0025575890050698017, 'l1_Layer_3': 0.005272122969054294, 'l1_Layer_4': 0.0007648126670716025, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195, 'n_units_Layer_4': 215}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 6.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.08 | sMAPE for Test Set is: 33.04% | rMAE for Test Set is: 3.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:19:07,030]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:19:07,306]\u001b[0m Trial 1044 finished with value: 1.4804506756961902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031100645677042413, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016104852762463033, 'dropout_rate_Layer_2': 0.2501847656393743, 'dropout_rate_Layer_3': 0.022708449015533275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004031881486103169, 'l1_Layer_2': 0.007966783646839195, 'l1_Layer_3': 0.0011644101884138048, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.67% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.95 | sMAPE for Test Set is: 21.30% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:19:17,184]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:19:20,098]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:19:25,190]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:19:37,462]\u001b[0m Trial 1046 finished with value: 1.4958960257073801 and parameters: {'n_hidden': 3, 'learning_rate': 0.003637111992532527, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018122748103885266, 'dropout_rate_Layer_2': 0.19653668797897786, 'dropout_rate_Layer_3': 0.04040494754274871, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003826233826070907, 'l1_Layer_2': 0.007294006937399836, 'l1_Layer_3': 0.0010792855321632372, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 215}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.84% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.37 | sMAPE for Test Set is: 19.72% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:19:44,029]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:19:47,695]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:19:51,777]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:19:56,458]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:20:03,282]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:20:03,695]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:20:13,709]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:20:22,192]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:20:26,927]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:20:30,878]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:20:38,307]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:20:52,723]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:21:00,077]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:21:00,342]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:21:09,893]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:21:13,652]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:21:20,318]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:21:26,608]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:21:31,868]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:21:40,203]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:21:50,614]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:21:51,262]\u001b[0m Trial 1054 finished with value: 1.587975528963895 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013140805037484893, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14727551132166586, 'dropout_rate_Layer_2': 0.3981668636090352, 'dropout_rate_Layer_3': 0.38493106598910076, 'dropout_rate_Layer_4': 0.14546490312314328, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.063866533959909e-05, 'l1_Layer_2': 0.0027713863301214096, 'l1_Layer_3': 0.007392172771495606, 'l1_Layer_4': 0.0009552921903130677, 'n_units_Layer_1': 75, 'n_units_Layer_2': 50, 'n_units_Layer_3': 200, 'n_units_Layer_4': 210}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 6.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.39 | sMAPE for Test Set is: 34.02% | rMAE for Test Set is: 3.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:21:56,165]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:21:58,589]\u001b[0m Trial 1070 finished with value: 1.4898039567315156 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030781853851136486, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0013693917374417042, 'dropout_rate_Layer_2': 0.23293345342868615, 'dropout_rate_Layer_3': 0.009877376276071603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.007046824520171268, 'l1_Layer_2': 0.004445522978541877, 'l1_Layer_3': 0.0007794370999053156, 'n_units_Layer_1': 215, 'n_units_Layer_2': 280, 'n_units_Layer_3': 200}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.77% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.41 | sMAPE for Test Set is: 19.85% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:22:05,796]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:22:06,034]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:22:51,153]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:23:06,822]\u001b[0m Trial 1079 finished with value: 1.4746578237641905 and parameters: {'n_hidden': 3, 'learning_rate': 0.002697945126468352, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00023368766710751485, 'dropout_rate_Layer_2': 0.2341528285186109, 'dropout_rate_Layer_3': 4.041280966823532e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.007463249078304386, 'l1_Layer_2': 0.004452360816247475, 'l1_Layer_3': 0.0015761530095071562, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 195}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.66% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.58 | sMAPE for Test Set is: 20.29% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:23:28,924]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:23:39,483]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:23:56,488]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:24:06,790]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:24:13,353]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:24:13,846]\u001b[0m Trial 1080 finished with value: 1.5911352517129769 and parameters: {'n_hidden': 4, 'learning_rate': 0.001306982916171654, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15232147679295302, 'dropout_rate_Layer_2': 0.39429914291838364, 'dropout_rate_Layer_3': 0.37432835961195277, 'dropout_rate_Layer_4': 0.13408100164461154, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.6955730672902325e-05, 'l1_Layer_2': 0.0026693490301840173, 'l1_Layer_3': 0.010757477575349757, 'l1_Layer_4': 0.0009983564816788103, 'n_units_Layer_1': 60, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195, 'n_units_Layer_4': 210}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 6.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.40 | sMAPE for Test Set is: 34.06% | rMAE for Test Set is: 3.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:24:21,265]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:24:28,946]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:24:40,046]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:24:51,190]\u001b[0m Trial 1071 finished with value: 1.5644798696529492 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012523187353322227, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1354308119421259, 'dropout_rate_Layer_2': 0.37727744776415495, 'dropout_rate_Layer_3': 0.37935461181876523, 'dropout_rate_Layer_4': 0.17069269090161132, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.7905616887947295e-05, 'l1_Layer_2': 0.0020038574625828227, 'l1_Layer_3': 0.006970622528019473, 'l1_Layer_4': 1.633656908091394e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195, 'n_units_Layer_4': 200}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 6.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.59 | sMAPE for Test Set is: 34.65% | rMAE for Test Set is: 3.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:24:55,488]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:24:56,189]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:25:05,942]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:25:21,643]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:25:41,350]\u001b[0m Trial 1094 finished with value: 1.4249272465328486 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009243838979680684, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09085174273652827, 'dropout_rate_Layer_2': 0.06863719433823495, 'dropout_rate_Layer_3': 0.07191371750862596, 'dropout_rate_Layer_4': 0.09974177628965983, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00018509355411950017, 'l1_Layer_2': 0.0002799577429371881, 'l1_Layer_3': 0.0007405493421265132, 'l1_Layer_4': 7.747431372591768e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 125, 'n_units_Layer_3': 80, 'n_units_Layer_4': 235}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 5.51% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 12.35 | sMAPE for Test Set is: 30.89% | rMAE for Test Set is: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:26:16,120]\u001b[0m Trial 1090 finished with value: 1.5841507896697717 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012339418722541148, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16515465588537612, 'dropout_rate_Layer_2': 0.39989170483917585, 'dropout_rate_Layer_3': 0.38360916489062596, 'dropout_rate_Layer_4': 0.13692806378603695, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.5104006093924934e-05, 'l1_Layer_2': 0.0022148782996952512, 'l1_Layer_3': 0.010186342333735318, 'l1_Layer_4': 0.00094835970590985, 'n_units_Layer_1': 65, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190, 'n_units_Layer_4': 220}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 6.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.63 | sMAPE for Test Set is: 34.76% | rMAE for Test Set is: 3.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:26:19,816]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:26:28,707]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:26:34,643]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:26:39,772]\u001b[0m Trial 1097 finished with value: 1.4774934275323452 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010192394348654196, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08994007164143225, 'dropout_rate_Layer_2': 0.0681142757916099, 'dropout_rate_Layer_3': 0.07244640766570462, 'dropout_rate_Layer_4': 0.08338818678864152, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 7.77140339724151e-05, 'l1_Layer_2': 0.00027070161238913667, 'l1_Layer_3': 0.004100290642671719, 'l1_Layer_4': 8.892074027603348e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 125, 'n_units_Layer_3': 80, 'n_units_Layer_4': 235}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.74% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.19 | sMAPE for Test Set is: 30.44% | rMAE for Test Set is: 2.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:26:43,963]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:26:53,437]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:26:58,878]\u001b[0m Trial 1098 finished with value: 1.487151101070631 and parameters: {'n_hidden': 3, 'learning_rate': 0.002472431155774686, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002142480904397617, 'dropout_rate_Layer_2': 0.2233470977896875, 'dropout_rate_Layer_3': 0.025947717991669384, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.009703424892838194, 'l1_Layer_2': 0.013752359594051241, 'l1_Layer_3': 0.0018902488697993857, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 200}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.75% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.39 | sMAPE for Test Set is: 19.77% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:26:59,366]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:27:09,535]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:27:12,942]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:27:32,195]\u001b[0m Trial 1095 finished with value: 1.5715322029790402 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011018253770557077, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16183600625475977, 'dropout_rate_Layer_2': 0.3999893271636909, 'dropout_rate_Layer_3': 0.3775021646461977, 'dropout_rate_Layer_4': 0.11716037639735408, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.074110282878312e-05, 'l1_Layer_2': 0.0018294789599757539, 'l1_Layer_3': 0.011748144475156177, 'l1_Layer_4': 0.0006476373937303562, 'n_units_Layer_1': 70, 'n_units_Layer_2': 65, 'n_units_Layer_3': 205, 'n_units_Layer_4': 200}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 6.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.27 | sMAPE for Test Set is: 33.65% | rMAE for Test Set is: 3.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:27:41,136]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:27:47,441]\u001b[0m Trial 1106 finished with value: 1.4779639391925745 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009378435931627505, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06986534491970973, 'dropout_rate_Layer_2': 0.0701689851365946, 'dropout_rate_Layer_3': 0.10739463345876142, 'dropout_rate_Layer_4': 0.09761266459390529, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 7.747930939865911e-05, 'l1_Layer_2': 0.00024613765063390955, 'l1_Layer_3': 0.004250530222670963, 'l1_Layer_4': 0.00020967855867366354, 'n_units_Layer_1': 135, 'n_units_Layer_2': 155, 'n_units_Layer_3': 80, 'n_units_Layer_4': 215}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.70% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.65 | sMAPE for Test Set is: 31.77% | rMAE for Test Set is: 3.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:27:49,636]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:27:55,331]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:28:00,665]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:28:07,048]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:28:18,164]\u001b[0m Trial 1108 finished with value: 1.5105564775502438 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008912732090102198, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07199353234554803, 'dropout_rate_Layer_2': 0.07141896271813025, 'dropout_rate_Layer_3': 0.08873427785579664, 'dropout_rate_Layer_4': 0.0901088916068146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 6.47648381414547e-05, 'l1_Layer_2': 0.00028256882837578943, 'l1_Layer_3': 0.00448714861785336, 'l1_Layer_4': 0.00020207213344027936, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 80, 'n_units_Layer_4': 220}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.86% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.58 | sMAPE for Test Set is: 31.57% | rMAE for Test Set is: 3.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:28:30,931]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:28:42,803]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:28:50,371]\u001b[0m Trial 1107 finished with value: 1.4747399482735932 and parameters: {'n_hidden': 3, 'learning_rate': 0.002409592438967141, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012982992399556593, 'dropout_rate_Layer_2': 0.22925520727973608, 'dropout_rate_Layer_3': 0.01008015247862208, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.014713815740378477, 'l1_Layer_2': 0.003638513564699439, 'l1_Layer_3': 0.001949855541793972, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 195}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.70% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.34 | sMAPE for Test Set is: 19.64% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:28:54,110]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:29:01,138]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:29:10,772]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:29:17,613]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:29:23,799]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:29:30,243]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:29:49,552]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:29:55,680]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:30:05,431]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:30:09,012]\u001b[0m Trial 1113 finished with value: 1.5667419266811737 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010856275369430927, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.161595601541458, 'dropout_rate_Layer_2': 0.3906749787591895, 'dropout_rate_Layer_3': 0.3852705837192042, 'dropout_rate_Layer_4': 0.1006150682911458, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.196383254671279e-05, 'l1_Layer_2': 0.002416716907800343, 'l1_Layer_3': 0.009756337374467365, 'l1_Layer_4': 0.0006752266113806164, 'n_units_Layer_1': 60, 'n_units_Layer_2': 60, 'n_units_Layer_3': 200, 'n_units_Layer_4': 210}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 6.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 12.96 | sMAPE for Test Set is: 32.70% | rMAE for Test Set is: 3.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:30:13,490]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:30:15,790]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:30:22,226]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:30:28,607]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:30:33,439]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:30:43,335]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:05,013]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:05,882]\u001b[0m Trial 1130 finished with value: 1.4364751781431657 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009828536669131082, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1179101628126305, 'dropout_rate_Layer_2': 0.08870635312627458, 'dropout_rate_Layer_3': 0.10854431565682211, 'dropout_rate_Layer_4': 0.10467529042544103, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 7.95857042671373e-05, 'l1_Layer_2': 0.0002520166231890521, 'l1_Layer_3': 0.0008009067746556498, 'l1_Layer_4': 0.0002757502515254017, 'n_units_Layer_1': 100, 'n_units_Layer_2': 155, 'n_units_Layer_3': 95, 'n_units_Layer_4': 235}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.57% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 12.42 | sMAPE for Test Set is: 31.09% | rMAE for Test Set is: 3.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:31:12,150]\u001b[0m Trial 1115 finished with value: 1.5861325746741375 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011679575961947195, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16052270037352737, 'dropout_rate_Layer_2': 0.3881520358090772, 'dropout_rate_Layer_3': 0.38531394395587065, 'dropout_rate_Layer_4': 0.13510510072284304, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.652268075705611e-05, 'l1_Layer_2': 0.0020143217081557505, 'l1_Layer_3': 0.012904303586112557, 'l1_Layer_4': 0.0006604893372319765, 'n_units_Layer_1': 70, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185, 'n_units_Layer_4': 215}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 6.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.30 | sMAPE for Test Set is: 33.74% | rMAE for Test Set is: 3.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:31:13,789]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:21,255]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:25,702]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:30,819]\u001b[0m Trial 1125 finished with value: 1.6010031896951702 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013373413900163603, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15152893042887935, 'dropout_rate_Layer_2': 0.3784115430753942, 'dropout_rate_Layer_3': 0.3902761992200587, 'dropout_rate_Layer_4': 0.1516172113308229, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.3793268790956527e-05, 'l1_Layer_2': 0.0016265736594392958, 'l1_Layer_3': 0.00870821834630235, 'l1_Layer_4': 0.0008002207056502763, 'n_units_Layer_1': 70, 'n_units_Layer_2': 65, 'n_units_Layer_3': 200, 'n_units_Layer_4': 215}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 6.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 14.08 | sMAPE for Test Set is: 36.18% | rMAE for Test Set is: 3.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:31:35,346]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:38,775]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:41,603]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:42,340]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:45,109]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:52,372]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:56,300]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:57,390]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:31:59,658]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:07,682]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:07,906]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:10,917]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:17,419]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:22,117]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:27,131]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:28,055]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:34,176]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:37,541]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:41,418]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:41,814]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:48,499]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:53,187]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:56,078]\u001b[0m Trial 1152 finished with value: 1.480354115989621 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031403097017695925, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008515143518910905, 'dropout_rate_Layer_2': 0.2382143777984221, 'dropout_rate_Layer_3': 0.030239737247596175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.005720087540249523, 'l1_Layer_2': 0.0037275764300963472, 'l1_Layer_3': 0.0015892800079308474, 'n_units_Layer_1': 220, 'n_units_Layer_2': 290, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.70% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 21.16% | rMAE for Test Set is: 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:32:59,590]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:32:59,736]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:02,613]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:10,799]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:13,697]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:17,906]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:20,284]\u001b[0m Trial 1159 finished with value: 1.463454373258008 and parameters: {'n_hidden': 4, 'learning_rate': 0.001076696381946839, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11350208789849806, 'dropout_rate_Layer_2': 0.12014886783528317, 'dropout_rate_Layer_3': 0.13532072021798416, 'dropout_rate_Layer_4': 0.081910051241975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 5.553844776611485e-05, 'l1_Layer_2': 0.00032470342821492107, 'l1_Layer_3': 0.0007530780216794282, 'l1_Layer_4': 0.00029967489863196804, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 100, 'n_units_Layer_4': 240}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.67% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.64 | sMAPE for Test Set is: 31.75% | rMAE for Test Set is: 3.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:33:25,041]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:25,230]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:33,653]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:36,186]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:36,396]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:39,094]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:42,979]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:49,115]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:56,173]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:33:58,964]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:34:07,348]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:34:16,682]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:34:36,038]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:34:39,185]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:34:42,623]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:34:46,346]\u001b[0m Trial 1183 finished with value: 1.4836395703125713 and parameters: {'n_hidden': 3, 'learning_rate': 0.002301368513310284, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03081191462361005, 'dropout_rate_Layer_2': 0.2434842390259742, 'dropout_rate_Layer_3': 0.022014965337769837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004383742069422127, 'l1_Layer_2': 0.003830866194350414, 'l1_Layer_3': 0.0015613854810550903, 'n_units_Layer_1': 195, 'n_units_Layer_2': 295, 'n_units_Layer_3': 225}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.74% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.95 | sMAPE for Test Set is: 21.28% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:34:53,462]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:02,135]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:03,515]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:08,762]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:11,698]\u001b[0m Trial 1186 finished with value: 1.479662628830922 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031457039002886094, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026363819299218334, 'dropout_rate_Layer_2': 0.21436192554500763, 'dropout_rate_Layer_3': 0.00876147323521757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.007868460785185057, 'l1_Layer_2': 0.002608025154165152, 'l1_Layer_3': 0.0009523290253258315, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 210}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.72% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.58 | sMAPE for Test Set is: 20.26% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:35:16,779]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:23,079]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:27,836]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:28,144]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:33,983]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:37,147]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:38,249]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:42,144]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:46,320]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:35:54,033]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:36:09,945]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:36:12,648]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:36:15,280]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:36:21,616]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:36:27,739]\u001b[0m Trial 1199 finished with value: 1.4879154455683974 and parameters: {'n_hidden': 3, 'learning_rate': 0.002393778301983958, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02251339972208701, 'dropout_rate_Layer_2': 0.24405847509026488, 'dropout_rate_Layer_3': 0.018165520582880734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004423982579181073, 'l1_Layer_2': 0.006485046423947227, 'l1_Layer_3': 0.0012986570826124737, 'n_units_Layer_1': 185, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.72% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 21.14% | rMAE for Test Set is: 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:36:32,666]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:36:32,773]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:36:48,104]\u001b[0m Trial 1205 finished with value: 1.559458020896663 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019869656548993477, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.177623197529633, 'dropout_rate_Layer_2': 0.1624249501716966, 'dropout_rate_Layer_3': 0.2033686087415697, 'dropout_rate_Layer_4': 0.1563430192465494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004871651355454649, 'l1_Layer_2': 0.006190013782687269, 'l1_Layer_3': 0.0055016302925241685, 'l1_Layer_4': 0.00024324827299876894, 'n_units_Layer_1': 285, 'n_units_Layer_2': 55, 'n_units_Layer_3': 75, 'n_units_Layer_4': 110}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 6.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.23 | sMAPE for Test Set is: 27.62% | rMAE for Test Set is: 2.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:36:53,541]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:36:57,623]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:36:58,878]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:05,277]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:08,730]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:11,887]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:14,840]\u001b[0m Trial 1209 finished with value: 1.4813095594961994 and parameters: {'n_hidden': 4, 'learning_rate': 0.001313561460371993, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09504927349119964, 'dropout_rate_Layer_2': 0.11937861545206108, 'dropout_rate_Layer_3': 0.0984158751011884, 'dropout_rate_Layer_4': 0.05725230300704705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 9.108641647168039e-05, 'l1_Layer_2': 0.0005120445435013208, 'l1_Layer_3': 0.002025539248427439, 'l1_Layer_4': 0.0005321151122925951, 'n_units_Layer_1': 115, 'n_units_Layer_2': 160, 'n_units_Layer_3': 90, 'n_units_Layer_4': 230}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.73% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.53 | sMAPE for Test Set is: 31.40% | rMAE for Test Set is: 3.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:37:20,658]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:21,011]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:21,351]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:30,272]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:32,660]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:35,971]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:41,280]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:41,593]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:41,840]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:44,775]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:52,782]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:53,625]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:37:54,549]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:38:00,042]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:38:07,584]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:38:16,029]\u001b[0m Trial 1232 finished with value: 1.7628183833846836 and parameters: {'n_hidden': 4, 'learning_rate': 0.002275607552368047, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.192512853338144, 'dropout_rate_Layer_2': 0.32371915785238214, 'dropout_rate_Layer_3': 0.3802983615759231, 'dropout_rate_Layer_4': 0.2914321741794896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.008237534651938931, 'l1_Layer_2': 0.01487642813494371, 'l1_Layer_3': 0.002055110227789212, 'l1_Layer_4': 0.0003694131413163792, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 75, 'n_units_Layer_4': 100}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.76 | sMAPE for Validation Set is: 6.73% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 14.69 | sMAPE for Test Set is: 38.18% | rMAE for Test Set is: 3.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:38:17,377]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:38:20,992]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:38:21,214]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:38:41,686]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:38:45,832]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:38:46,825]\u001b[0m Trial 1236 finished with value: 1.468308800325713 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016047517229519016, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11611900188298996, 'dropout_rate_Layer_2': 0.1674495227203142, 'dropout_rate_Layer_3': 0.147724640526622, 'dropout_rate_Layer_4': 0.034522021063045236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00017583383440894328, 'l1_Layer_2': 0.00022699125603990936, 'l1_Layer_3': 0.000923343124120247, 'l1_Layer_4': 8.457293041774311e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 70, 'n_units_Layer_4': 265}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.70% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.58 | sMAPE for Test Set is: 31.57% | rMAE for Test Set is: 3.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:38:47,203]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:38:54,069]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:38:57,288]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:39:02,199]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:39:09,956]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:39:16,174]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:39:22,479]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:39:25,397]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:39:36,243]\u001b[0m Trial 1241 finished with value: 1.5030253827105688 and parameters: {'n_hidden': 3, 'learning_rate': 0.002484730843653607, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01080679035383715, 'dropout_rate_Layer_2': 0.2051857406631254, 'dropout_rate_Layer_3': 0.02175823974127291, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003912888187822549, 'l1_Layer_2': 0.005497569895583374, 'l1_Layer_3': 0.0013265315251553046, 'n_units_Layer_1': 175, 'n_units_Layer_2': 300, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.01 | sMAPE for Test Set is: 21.47% | rMAE for Test Set is: 2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:39:43,465]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:39:52,564]\u001b[0m Trial 1248 finished with value: 1.4666456690758078 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015755328890185189, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11403106494060078, 'dropout_rate_Layer_2': 0.13193988917853738, 'dropout_rate_Layer_3': 0.14741068162261906, 'dropout_rate_Layer_4': 0.025493128408125947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00019477316401523127, 'l1_Layer_2': 0.00021918383800679164, 'l1_Layer_3': 0.0008816712481605334, 'l1_Layer_4': 0.00023044504008641587, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 70, 'n_units_Layer_4': 260}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.67% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.62 | sMAPE for Test Set is: 31.69% | rMAE for Test Set is: 3.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:39:58,815]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:40:05,376]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:40:09,963]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:40:12,395]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:40:19,393]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:40:19,721]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:40:27,502]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:40:32,345]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:40:39,493]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:40:49,015]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:41:10,950]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:41:15,408]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:41:24,256]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:41:27,866]\u001b[0m Trial 1261 finished with value: 1.490936813514326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026950330509666314, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05496795930179216, 'dropout_rate_Layer_2': 0.2340460281543311, 'dropout_rate_Layer_3': 0.028748798693352437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0034463921792435284, 'l1_Layer_2': 0.014492611335705672, 'l1_Layer_3': 0.0009930508894938723, 'n_units_Layer_1': 185, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.70% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.38 | sMAPE for Test Set is: 22.45% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:41:30,688]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:41:41,883]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:41:51,164]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:41:51,708]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:41:58,826]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:42:02,482]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:42:08,521]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:42:14,849]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 6.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.18 | sMAPE for Test Set is: 33.39% | rMAE for Test Set is: 3.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:42:16,801]\u001b[0m Trial 1243 finished with value: 1.5679459255412087 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010113945804681123, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16186722207859008, 'dropout_rate_Layer_2': 0.3825567264649951, 'dropout_rate_Layer_3': 0.3598617744728356, 'dropout_rate_Layer_4': 0.14890383839135488, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.7129943813215167e-05, 'l1_Layer_2': 0.0030129236596981384, 'l1_Layer_3': 0.003634051866142746, 'l1_Layer_4': 0.0007284645324224096, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 190, 'n_units_Layer_4': 215}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:42:21,442]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:42:26,994]\u001b[0m Trial 1270 finished with value: 1.465733112818258 and parameters: {'n_hidden': 3, 'learning_rate': 0.003092491421226289, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025808911941992682, 'dropout_rate_Layer_2': 0.21285629419971108, 'dropout_rate_Layer_3': 0.00010456543027373826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.005326299841770352, 'l1_Layer_2': 0.0015578986896997017, 'l1_Layer_3': 0.0006096713117256638, 'n_units_Layer_1': 220, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.68% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.93 | sMAPE for Test Set is: 21.19% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:42:35,741]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:42:41,067]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:42:44,047]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:42:48,260]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:42:49,724]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:42:53,885]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:42:54,771]\u001b[0m Trial 1275 finished with value: 1.4675562572323855 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018181537726206186, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14120318228675555, 'dropout_rate_Layer_2': 0.1413082264245656, 'dropout_rate_Layer_3': 0.17647286209972338, 'dropout_rate_Layer_4': 0.019609490762938993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0001959421519354305, 'l1_Layer_2': 0.00011798222543016962, 'l1_Layer_3': 0.0010926237863157122, 'l1_Layer_4': 0.0002268552474302218, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 70, 'n_units_Layer_4': 265}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.67% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.78 | sMAPE for Test Set is: 32.20% | rMAE for Test Set is: 3.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:42:58,122]\u001b[0m Trial 1240 finished with value: 1.5320481433149153 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010157856429952863, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15762434350145058, 'dropout_rate_Layer_2': 0.36713944498584694, 'dropout_rate_Layer_3': 0.28360459873800525, 'dropout_rate_Layer_4': 0.14853029656146047, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 7.470911197829955e-05, 'l1_Layer_2': 0.002300162915081753, 'l1_Layer_3': 0.0037054776624400394, 'l1_Layer_4': 0.0007495032295435961, 'n_units_Layer_1': 80, 'n_units_Layer_2': 70, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 6.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.68 | sMAPE for Test Set is: 31.87% | rMAE for Test Set is: 3.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:43:07,764]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:43:14,431]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:43:26,897]\u001b[0m Trial 1282 finished with value: 1.477364776547395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031704494066688953, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029720477438760315, 'dropout_rate_Layer_2': 0.213051845905825, 'dropout_rate_Layer_3': 0.0021473662319696756, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00742043296304317, 'l1_Layer_2': 0.0017721788994986892, 'l1_Layer_3': 0.0006265284330485101, 'n_units_Layer_1': 220, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.71% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 21.03% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:43:29,090]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:43:36,172]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:43:43,860]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:43:54,066]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:44:03,740]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:44:12,809]\u001b[0m Trial 1286 finished with value: 1.5289019385529627 and parameters: {'n_hidden': 4, 'learning_rate': 0.002347828106591507, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25644757221042197, 'dropout_rate_Layer_2': 0.042630694397688365, 'dropout_rate_Layer_3': 0.15177288994169608, 'dropout_rate_Layer_4': 0.08195701056866105, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.3103198755993474e-05, 'l1_Layer_2': 0.0015313629291712324, 'l1_Layer_3': 0.0023521311899758527, 'l1_Layer_4': 0.00027400707048720125, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 105, 'n_units_Layer_4': 60}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.89% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 22.89% | rMAE for Test Set is: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:44:16,831]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:44:34,558]\u001b[0m Trial 1284 finished with value: 1.5533951284010759 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009379286107572888, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17947376512125468, 'dropout_rate_Layer_2': 0.3738116507412905, 'dropout_rate_Layer_3': 0.3606659163809075, 'dropout_rate_Layer_4': 0.14696137009546095, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 8.064332063471174e-05, 'l1_Layer_2': 0.001787080730398271, 'l1_Layer_3': 0.006219743165453957, 'l1_Layer_4': 0.0005058928168146268, 'n_units_Layer_1': 85, 'n_units_Layer_2': 65, 'n_units_Layer_3': 185, 'n_units_Layer_4': 235}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 6.01% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.77 | sMAPE for Test Set is: 35.22% | rMAE for Test Set is: 3.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:44:37,581]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:44:56,025]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:44:58,172]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:45:05,677]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:45:08,329]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:45:16,359]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:45:16,743]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:45:17,368]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:45:24,522]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:45:33,034]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:45:42,112]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:45:44,677]\u001b[0m Trial 1301 finished with value: 1.4688968497636818 and parameters: {'n_hidden': 4, 'learning_rate': 0.002663071808518772, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11552528292362259, 'dropout_rate_Layer_2': 0.13451486756037223, 'dropout_rate_Layer_3': 0.19113702799595936, 'dropout_rate_Layer_4': 0.033581297358970426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00016962946840442652, 'l1_Layer_2': 0.0001239624524737497, 'l1_Layer_3': 0.0004797854499173899, 'l1_Layer_4': 0.0002815095684856894, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 60, 'n_units_Layer_4': 250}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.66% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.69 | sMAPE for Test Set is: 31.89% | rMAE for Test Set is: 3.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:45:53,899]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:45:54,493]\u001b[0m Trial 1302 finished with value: 1.4546191726494546 and parameters: {'n_hidden': 4, 'learning_rate': 0.002660573911518618, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11646972119689329, 'dropout_rate_Layer_2': 0.13457492660853052, 'dropout_rate_Layer_3': 0.15062237896944125, 'dropout_rate_Layer_4': 0.022461746706171848, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00015510359998924416, 'l1_Layer_2': 0.0001304021897758965, 'l1_Layer_3': 0.0005335051465748378, 'l1_Layer_4': 0.0002530235240872892, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 60, 'n_units_Layer_4': 250}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.62% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 12.53 | sMAPE for Test Set is: 31.43% | rMAE for Test Set is: 3.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:45:59,239]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:04,530]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:09,543]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:16,149]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:21,325]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:24,023]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:27,153]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:27,320]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:29,734]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:32,943]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:36,251]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:38,538]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:39,308]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:41,023]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:50,347]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:46:54,621]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:47:02,297]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:47:04,928]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:47:11,568]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:47:15,988]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:47:25,541]\u001b[0m Trial 1324 finished with value: 1.4669078800798125 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018936175799665223, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09727231857848063, 'dropout_rate_Layer_2': 0.14816191895165692, 'dropout_rate_Layer_3': 0.14902054467039688, 'dropout_rate_Layer_4': 0.026460758068775507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00041130711579691115, 'l1_Layer_2': 0.00011276427430322263, 'l1_Layer_3': 0.0007723615281109667, 'l1_Layer_4': 0.00019074693668987748, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 70, 'n_units_Layer_4': 260}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.68% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.51 | sMAPE for Test Set is: 31.35% | rMAE for Test Set is: 3.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:47:35,032]\u001b[0m Trial 1326 finished with value: 1.467303804374496 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015579109224552851, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14583718349382194, 'dropout_rate_Layer_2': 0.11629059681298327, 'dropout_rate_Layer_3': 0.1484283291457032, 'dropout_rate_Layer_4': 0.023035662800303718, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0004180738441614104, 'l1_Layer_2': 7.248984660065883e-05, 'l1_Layer_3': 0.00032739224512884, 'l1_Layer_4': 0.00022138395323524824, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 70, 'n_units_Layer_4': 255}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.68% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.58 | sMAPE for Test Set is: 31.58% | rMAE for Test Set is: 3.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:47:43,603]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:47:46,608]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:47:56,425]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:47:56,519]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:04,091]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:10,085]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:11,618]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:21,828]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:24,813]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:28,262]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:32,783]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:33,140]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:33,328]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:42,900]\u001b[0m Trial 1334 finished with value: 1.4865711996497613 and parameters: {'n_hidden': 3, 'learning_rate': 0.002656243791596623, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03804942039326141, 'dropout_rate_Layer_2': 0.22850230558683227, 'dropout_rate_Layer_3': 0.046978589852605245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004264841428405763, 'l1_Layer_2': 0.0034420574114919626, 'l1_Layer_3': 0.00146019379491114, 'n_units_Layer_1': 195, 'n_units_Layer_2': 290, 'n_units_Layer_3': 180}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.69% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.81 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 2.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:48:50,474]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:50,521]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:48:58,436]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:02,613]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:07,386]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:08,694]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:15,843]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:18,624]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:23,798]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:24,157]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:31,675]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:32,730]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:40,889]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:45,415]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:52,085]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:56,142]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:49:56,423]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:03,360]\u001b[0m Trial 1347 finished with value: 1.5272146102258837 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032582290259973888, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023468747833139764, 'dropout_rate_Layer_2': 0.2380326038491833, 'dropout_rate_Layer_3': 0.0006370100074079219, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0026321590917667164, 'l1_Layer_2': 0.0020351160806718347, 'l1_Layer_3': 0.002363896631104726, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.93% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.58 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:50:06,934]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:14,095]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:18,006]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:23,485]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:23,649]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:24,016]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:24,154]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:31,862]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:39,081]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:40,720]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:45,203]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:49,418]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:53,274]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:54,453]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:50:58,054]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:51:03,979]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:51:10,254]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:51:10,914]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:51:16,349]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:51:38,877]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:51:42,588]\u001b[0m Trial 1381 finished with value: 1.4881819708520474 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015674976639280518, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07766969394215478, 'dropout_rate_Layer_2': 0.13017689207615118, 'dropout_rate_Layer_3': 0.16434427713587318, 'dropout_rate_Layer_4': 0.05670146024601408, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00010639580598934983, 'l1_Layer_2': 7.656787110931187e-05, 'l1_Layer_3': 0.000745887246344347, 'l1_Layer_4': 0.0006853579344768606, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 85, 'n_units_Layer_4': 225}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.80% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.81 | sMAPE for Test Set is: 32.28% | rMAE for Test Set is: 3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:51:47,144]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:51:50,439]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:14,901]\u001b[0m Trial 1378 finished with value: 1.597934598980447 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009366150270913321, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.167457793549358, 'dropout_rate_Layer_2': 0.3786798191848229, 'dropout_rate_Layer_3': 0.3933785163027404, 'dropout_rate_Layer_4': 0.13051453006202185, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.8948209160892398e-05, 'l1_Layer_2': 0.002217968902077916, 'l1_Layer_3': 0.007759721924874296, 'l1_Layer_4': 1.202980131235141e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195, 'n_units_Layer_4': 240}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 6.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.85 | sMAPE for Test Set is: 35.44% | rMAE for Test Set is: 3.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:52:21,474]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:27,430]\u001b[0m Trial 1385 finished with value: 1.4927749737991747 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029804738115230813, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01745501101342468, 'dropout_rate_Layer_2': 0.21882919816286264, 'dropout_rate_Layer_3': 0.027843801546004375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003947288322788755, 'l1_Layer_2': 0.001721989121342349, 'l1_Layer_3': 0.0021820445516761563, 'n_units_Layer_1': 190, 'n_units_Layer_2': 280, 'n_units_Layer_3': 185}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:27,493]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.75% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.99 | sMAPE for Test Set is: 21.39% | rMAE for Test Set is: 2.18\n",
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.86% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.67 | sMAPE for Test Set is: 31.85% | rMAE for Test Set is: 3.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:52:32,379]\u001b[0m Trial 1383 finished with value: 1.5065584289206253 and parameters: {'n_hidden': 4, 'learning_rate': 0.001538626361416011, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14565133010149572, 'dropout_rate_Layer_2': 0.1325548921956995, 'dropout_rate_Layer_3': 0.19368542583455411, 'dropout_rate_Layer_4': 0.060255411536445896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00011094473954896821, 'l1_Layer_2': 0.00011288115755644703, 'l1_Layer_3': 0.0007344439907528298, 'l1_Layer_4': 0.0006684142675710927, 'n_units_Layer_1': 80, 'n_units_Layer_2': 115, 'n_units_Layer_3': 100, 'n_units_Layer_4': 225}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:36,154]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:37,049]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:37,324]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:41,312]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:44,106]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:52,509]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:53,251]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:56,235]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:52:56,931]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:01,689]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:09,727]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:12,200]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:14,196]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:14,902]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:20,041]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:22,818]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:25,843]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:27,423]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:29,976]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:31,005]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:31,703]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:33,202]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:41,184]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:47,306]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:48,742]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:53:53,442]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:00,577]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:04,593]\u001b[0m Trial 1413 finished with value: 1.5011339772391368 and parameters: {'n_hidden': 3, 'learning_rate': 0.00391614663634178, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060344405175945, 'dropout_rate_Layer_2': 0.2577556392645582, 'dropout_rate_Layer_3': 0.009370909607301022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0059210028374315, 'l1_Layer_2': 0.001317304022153897, 'l1_Layer_3': 0.0020440073413066254, 'n_units_Layer_1': 190, 'n_units_Layer_2': 290, 'n_units_Layer_3': 225}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.79% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.08 | sMAPE for Test Set is: 21.64% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:54:08,629]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:11,717]\u001b[0m Trial 1410 finished with value: 1.4751545560626347 and parameters: {'n_hidden': 3, 'learning_rate': 0.00396893967975326, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012986302686334193, 'dropout_rate_Layer_2': 0.22641722421260918, 'dropout_rate_Layer_3': 0.00996021790547316, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0037011120942895513, 'l1_Layer_2': 0.004009976590222479, 'l1_Layer_3': 0.00012502473413245697, 'n_units_Layer_1': 220, 'n_units_Layer_2': 290, 'n_units_Layer_3': 200}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.69% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 11.89 | sMAPE for Test Set is: 29.52% | rMAE for Test Set is: 2.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:54:16,239]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:16,360]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:24,561]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:28,939]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:29,574]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:33,045]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:35,349]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:49,339]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:58,895]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:54:59,293]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:08,291]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:11,974]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:16,060]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:17,355]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:24,166]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:29,077]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:29,835]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:34,839]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:35,019]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:36,494]\u001b[0m Trial 1436 finished with value: 3.2034598680759054 and parameters: {'n_hidden': 4, 'learning_rate': 0.0894506008840759, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12654183908798006, 'dropout_rate_Layer_2': 0.09511325588380995, 'dropout_rate_Layer_3': 0.1450287934950647, 'dropout_rate_Layer_4': 0.000200764464576602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00037311122080036744, 'l1_Layer_2': 0.00031998283792515603, 'l1_Layer_3': 0.0010377644580941662, 'l1_Layer_4': 0.0002418389455477997, 'n_units_Layer_1': 115, 'n_units_Layer_2': 110, 'n_units_Layer_3': 60, 'n_units_Layer_4': 270}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.20 | sMAPE for Validation Set is: 12.31% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 17.19 | sMAPE for Test Set is: 46.53% | rMAE for Test Set is: 4.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:55:46,083]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:46,947]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:55:55,847]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:56:02,835]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:56:12,747]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:56:13,662]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:56:19,230]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:56:21,577]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:56:26,435]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:56:38,033]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:56:52,752]\u001b[0m Trial 1448 finished with value: 1.4706762187285574 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013760656788654412, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05172278537736015, 'dropout_rate_Layer_2': 0.12333042718627407, 'dropout_rate_Layer_3': 0.11536874131141937, 'dropout_rate_Layer_4': 0.025210633195192664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.000269816450009893, 'l1_Layer_2': 0.00016321658292482128, 'l1_Layer_3': 0.00034565504842697217, 'l1_Layer_4': 0.0003645818388306413, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60, 'n_units_Layer_4': 260}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.69% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 31.31% | rMAE for Test Set is: 3.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:56:56,313]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:57:02,745]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:57:12,158]\u001b[0m Trial 1451 finished with value: 1.586836644142478 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034118180537669293, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19917306417909478, 'dropout_rate_Layer_2': 0.06950315670212302, 'dropout_rate_Layer_3': 0.1396228695675041, 'dropout_rate_Layer_4': 0.06347262117091383, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.451908878255796e-05, 'l1_Layer_2': 0.010196751837095756, 'l1_Layer_3': 0.00443479790275492, 'l1_Layer_4': 0.00017938656429355074, 'n_units_Layer_1': 245, 'n_units_Layer_2': 50, 'n_units_Layer_3': 100, 'n_units_Layer_4': 265}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 6.09% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.48 | sMAPE for Test Set is: 22.75% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:57:18,911]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:57:19,114]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:57:19,501]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:57:28,505]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:57:35,119]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:57:35,309]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:57:45,248]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:57:51,328]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:57:56,293]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.95% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.83 | sMAPE for Test Set is: 18.36% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:57:58,364]\u001b[0m Trial 1456 finished with value: 1.5326802608287533 and parameters: {'n_hidden': 4, 'learning_rate': 0.002920106332082692, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2069679506048536, 'dropout_rate_Layer_2': 0.07349527739429776, 'dropout_rate_Layer_3': 0.14125137114210723, 'dropout_rate_Layer_4': 0.06683478421900245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.6721129053145565e-05, 'l1_Layer_2': 0.00011029226433382202, 'l1_Layer_3': 0.0047911997329283034, 'l1_Layer_4': 0.00015746916632450572, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 120, 'n_units_Layer_4': 260}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:05,250]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:05,315]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:07,512]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:14,023]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:18,596]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:24,256]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:26,541]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:26,666]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:29,570]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:37,571]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:38,565]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:38,939]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:47,466]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:51,527]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:58:52,692]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:00,317]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:07,189]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:11,888]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:14,087]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:16,845]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:17,075]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:17,819]\u001b[0m Trial 1478 finished with value: 1.490728233415543 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020652496052373237, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11419474661464377, 'dropout_rate_Layer_2': 0.10447420624575565, 'dropout_rate_Layer_3': 0.15535345556195074, 'dropout_rate_Layer_4': 0.012649515724507367, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00018137125210680206, 'l1_Layer_2': 0.00010572964095913245, 'l1_Layer_3': 0.0005562883204368982, 'l1_Layer_4': 0.0001768399702128388, 'n_units_Layer_1': 130, 'n_units_Layer_2': 140, 'n_units_Layer_3': 70, 'n_units_Layer_4': 250}. Best is trial 117 with value: 1.3749003997483953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.64 | sMAPE for Test Set is: 31.75% | rMAE for Test Set is: 3.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 12:59:24,268]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:30,987]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:31,645]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:34,542]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:35,621]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:36,432]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:40,914]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:51,961]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 12:59:57,521]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:00:01,822]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:00:09,369]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:00:10,085]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:00:11,663]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:00:17,835]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:00:18,502]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:00:32,384]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-01-01, MAE is:0.52 & sMAPE is:1.97% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :0.52 & 1.97% & 1.49\n",
      "for 2018-01-02, MAE is:5.06 & sMAPE is:16.05% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 9.01% & 1.17\n",
      "for 2018-01-03, MAE is:1.02 & sMAPE is:3.43% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 7.15% & 0.91\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000019C8720D790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:3.68 & sMAPE is:11.41% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.57 & 8.21% & 1.27\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000019C959B6430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:1.65 & sMAPE is:5.20% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 7.61% & 1.15\n",
      "for 2018-01-06, MAE is:1.18 & sMAPE is:3.76% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 6.97% & 1.01\n",
      "for 2018-01-07, MAE is:0.99 & sMAPE is:3.50% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.01 & 6.47% & 0.95\n",
      "for 2018-01-08, MAE is:2.67 & sMAPE is:8.88% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 6.77% & 0.91\n",
      "for 2018-01-09, MAE is:2.46 & sMAPE is:8.34% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 6.95% & 0.91\n",
      "for 2018-01-10, MAE is:11.09 & sMAPE is:29.70% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 9.22% & 0.92\n",
      "for 2018-01-11, MAE is:3.64 & sMAPE is:9.14% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 9.22% & 0.90\n",
      "for 2018-01-12, MAE is:1.05 & sMAPE is:3.48% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 8.74% & 0.87\n",
      "for 2018-01-13, MAE is:0.89 & sMAPE is:3.05% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.76 & 8.30% & 0.85\n",
      "for 2018-01-14, MAE is:0.69 & sMAPE is:2.34% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.61 & 7.87% & 0.83\n",
      "for 2018-01-15, MAE is:1.39 & sMAPE is:4.77% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.67% & 0.82\n",
      "for 2018-01-16, MAE is:0.59 & sMAPE is:2.02% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 7.31% & 0.79\n",
      "for 2018-01-17, MAE is:1.57 & sMAPE is:5.18% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 7.19% & 0.75\n",
      "for 2018-01-18, MAE is:5.39 & sMAPE is:15.25% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.64% & 0.79\n",
      "for 2018-01-19, MAE is:6.95 & sMAPE is:18.25% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.76 & 8.20% & 0.79\n",
      "for 2018-01-20, MAE is:1.03 & sMAPE is:3.24% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.67 & 7.95% & 0.80\n",
      "for 2018-01-21, MAE is:1.64 & sMAPE is:5.25% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.63 & 7.82% & 0.80\n",
      "for 2018-01-22, MAE is:1.39 & sMAPE is:4.17% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.57 & 7.65% & 0.78\n",
      "for 2018-01-23, MAE is:2.64 & sMAPE is:8.10% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.57 & 7.67% & 0.78\n",
      "for 2018-01-24, MAE is:0.52 & sMAPE is:1.80% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.43% & 0.76\n",
      "for 2018-01-25, MAE is:0.89 & sMAPE is:3.00% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 7.25% & 0.73\n",
      "for 2018-01-26, MAE is:0.98 & sMAPE is:3.27% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 7.10% & 0.71\n",
      "for 2018-01-27, MAE is:1.64 & sMAPE is:5.48% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 7.04% & 0.74\n",
      "for 2018-01-28, MAE is:0.68 & sMAPE is:2.41% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 6.87% & 0.72\n",
      "for 2018-01-29, MAE is:1.16 & sMAPE is:3.94% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 6.77% & 0.71\n",
      "for 2018-01-30, MAE is:2.49 & sMAPE is:8.11% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 6.82% & 0.72\n",
      "for 2018-01-31, MAE is:1.02 & sMAPE is:3.37% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 6.70% & 0.73\n",
      "for 2018-02-01, MAE is:2.73 & sMAPE is:9.17% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.78% & 0.77\n",
      "for 2018-02-02, MAE is:4.10 & sMAPE is:12.64% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 6.96% & 0.78\n",
      "for 2018-02-03, MAE is:1.47 & sMAPE is:4.61% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 6.89% & 0.78\n",
      "for 2018-02-04, MAE is:1.08 & sMAPE is:3.35% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 6.79% & 0.77\n",
      "for 2018-02-05, MAE is:0.42 & sMAPE is:1.31% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 6.64% & 0.75\n",
      "for 2018-02-06, MAE is:1.26 & sMAPE is:3.90% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 6.56% & 0.75\n",
      "for 2018-02-07, MAE is:1.03 & sMAPE is:3.17% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 6.47% & 0.74\n",
      "for 2018-02-08, MAE is:0.40 & sMAPE is:1.23% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 6.34% & 0.73\n",
      "for 2018-02-09, MAE is:0.53 & sMAPE is:1.66% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 6.22% & 0.71\n",
      "for 2018-02-10, MAE is:0.78 & sMAPE is:2.54% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.01 & 6.13% & 0.71\n",
      "for 2018-02-11, MAE is:0.70 & sMAPE is:2.33% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :1.98 & 6.04% & 0.70\n",
      "for 2018-02-12, MAE is:1.86 & sMAPE is:5.95% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :1.97 & 6.04% & 0.71\n",
      "for 2018-02-13, MAE is:2.32 & sMAPE is:7.16% & rMAE is:2.38 ||| daily mean of MAE & sMAPE & rMAE till now are :1.98 & 6.06% & 0.75\n",
      "for 2018-02-14, MAE is:1.89 & sMAPE is:5.46% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :1.98 & 6.05% & 0.76\n",
      "for 2018-02-15, MAE is:1.79 & sMAPE is:5.55% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :1.98 & 6.04% & 0.77\n",
      "for 2018-02-16, MAE is:3.58 & sMAPE is:9.86% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.01 & 6.12% & 0.77\n",
      "for 2018-02-17, MAE is:4.72 & sMAPE is:12.58% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 6.26% & 0.77\n",
      "for 2018-02-18, MAE is:2.09 & sMAPE is:5.50% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 6.24% & 0.76\n",
      "for 2018-02-19, MAE is:11.74 & sMAPE is:25.30% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 6.62% & 0.76\n",
      "for 2018-02-20, MAE is:11.69 & sMAPE is:25.73% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 7.00% & 0.76\n",
      "for 2018-02-21, MAE is:7.38 & sMAPE is:15.85% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.17% & 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-22, MAE is:8.70 & sMAPE is:18.34% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.66 & 7.38% & 0.76\n",
      "for 2018-02-23, MAE is:5.26 & sMAPE is:11.16% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.70 & 7.45% & 0.75\n",
      "for 2018-02-24, MAE is:4.51 & sMAPE is:12.37% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.74 & 7.54% & 0.77\n",
      "for 2018-02-25, MAE is:2.02 & sMAPE is:5.27% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.72 & 7.50% & 0.77\n",
      "for 2018-02-26, MAE is:6.73 & sMAPE is:14.49% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 7.62% & 0.78\n",
      "for 2018-02-27, MAE is:4.47 & sMAPE is:9.10% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 7.65% & 0.78\n",
      "for 2018-02-28, MAE is:8.09 & sMAPE is:15.70% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.91 & 7.78% & 0.81\n",
      "for 2018-03-01, MAE is:51.73 & sMAPE is:55.17% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 8.57% & 0.81\n",
      "for 2018-03-02, MAE is:21.49 & sMAPE is:42.79% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 9.13% & 0.83\n",
      "for 2018-03-03, MAE is:7.77 & sMAPE is:20.58% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 9.32% & 0.84\n",
      "for 2018-03-04, MAE is:3.28 & sMAPE is:8.24% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 9.30% & 0.85\n",
      "for 2018-03-05, MAE is:11.70 & sMAPE is:22.39% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 9.50% & 0.85\n",
      "for 2018-03-06, MAE is:4.78 & sMAPE is:9.69% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 9.51% & 0.86\n",
      "for 2018-03-07, MAE is:7.85 & sMAPE is:17.01% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 9.62% & 0.87\n",
      "for 2018-03-08, MAE is:3.59 & sMAPE is:8.44% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 9.60% & 0.86\n",
      "for 2018-03-09, MAE is:3.35 & sMAPE is:8.25% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 9.58% & 0.85\n",
      "for 2018-03-10, MAE is:1.68 & sMAPE is:4.39% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 9.51% & 0.84\n",
      "for 2018-03-11, MAE is:0.69 & sMAPE is:1.93% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 9.40% & 0.83\n",
      "for 2018-03-12, MAE is:7.41 & sMAPE is:18.33% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 9.53% & 0.83\n",
      "for 2018-03-13, MAE is:3.65 & sMAPE is:8.59% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 9.51% & 0.83\n",
      "for 2018-03-14, MAE is:9.07 & sMAPE is:19.11% & rMAE is:6.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 9.64% & 0.91\n",
      "for 2018-03-15, MAE is:6.29 & sMAPE is:13.07% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 9.69% & 0.91\n",
      "for 2018-03-16, MAE is:4.37 & sMAPE is:10.89% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 9.71% & 0.92\n",
      "for 2018-03-17, MAE is:0.70 & sMAPE is:1.84% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 9.60% & 0.91\n",
      "for 2018-03-18, MAE is:1.21 & sMAPE is:3.24% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 9.52% & 0.91\n",
      "for 2018-03-19, MAE is:4.53 & sMAPE is:10.54% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 9.53% & 0.93\n",
      "for 2018-03-20, MAE is:6.56 & sMAPE is:15.30% & rMAE is:2.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 9.61% & 0.95\n",
      "for 2018-03-21, MAE is:2.02 & sMAPE is:4.65% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 9.54% & 0.94\n",
      "for 2018-03-22, MAE is:2.39 & sMAPE is:5.85% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 9.50% & 0.94\n",
      "for 2018-03-23, MAE is:6.31 & sMAPE is:12.69% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 9.54% & 0.94\n",
      "for 2018-03-24, MAE is:2.95 & sMAPE is:7.54% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 9.51% & 0.94\n",
      "for 2018-03-25, MAE is:1.49 & sMAPE is:3.76% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 9.44% & 0.94\n",
      "for 2018-03-26, MAE is:7.93 & sMAPE is:16.94% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 9.53% & 0.94\n",
      "for 2018-03-27, MAE is:4.48 & sMAPE is:9.25% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 9.53% & 0.94\n",
      "for 2018-03-28, MAE is:6.85 & sMAPE is:15.14% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 9.59% & 0.95\n",
      "for 2018-03-29, MAE is:1.36 & sMAPE is:3.34% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 9.52% & 0.95\n",
      "for 2018-03-30, MAE is:0.59 & sMAPE is:1.43% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 9.43% & 0.94\n",
      "for 2018-03-31, MAE is:0.69 & sMAPE is:1.70% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 9.35% & 0.94\n",
      "for 2018-04-01, MAE is:0.88 & sMAPE is:2.24% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 9.27% & 0.93\n",
      "for 2018-04-02, MAE is:0.87 & sMAPE is:2.21% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 9.19% & 0.92\n",
      "for 2018-04-03, MAE is:4.70 & sMAPE is:10.98% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 9.21% & 0.93\n",
      "for 2018-04-04, MAE is:1.72 & sMAPE is:3.91% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 9.15% & 0.92\n",
      "for 2018-04-05, MAE is:3.80 & sMAPE is:8.92% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 9.15% & 0.93\n",
      "for 2018-04-06, MAE is:1.90 & sMAPE is:4.63% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 9.10% & 0.93\n",
      "for 2018-04-07, MAE is:1.80 & sMAPE is:4.64% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 9.06% & 0.94\n",
      "for 2018-04-08, MAE is:1.14 & sMAPE is:2.92% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 9.00% & 0.95\n",
      "for 2018-04-09, MAE is:4.46 & sMAPE is:10.21% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 9.01% & 0.95\n",
      "for 2018-04-10, MAE is:2.20 & sMAPE is:5.45% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 8.97% & 0.95\n",
      "for 2018-04-11, MAE is:2.32 & sMAPE is:5.72% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 8.94% & 0.96\n",
      "for 2018-04-12, MAE is:1.42 & sMAPE is:3.42% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.89% & 0.95\n",
      "for 2018-04-13, MAE is:1.64 & sMAPE is:4.07% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 8.84% & 0.96\n",
      "for 2018-04-14, MAE is:1.98 & sMAPE is:5.14% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 8.80% & 0.97\n",
      "for 2018-04-15, MAE is:1.95 & sMAPE is:5.00% & rMAE is:5.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 8.77% & 1.01\n",
      "for 2018-04-16, MAE is:8.03 & sMAPE is:17.29% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 8.85% & 1.02\n",
      "for 2018-04-17, MAE is:2.45 & sMAPE is:5.36% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 8.82% & 1.01\n",
      "for 2018-04-18, MAE is:3.32 & sMAPE is:7.82% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 8.81% & 1.02\n",
      "for 2018-04-19, MAE is:2.66 & sMAPE is:6.55% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 8.79% & 1.03\n",
      "for 2018-04-20, MAE is:0.93 & sMAPE is:2.45% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 8.73% & 1.02\n",
      "for 2018-04-21, MAE is:0.63 & sMAPE is:1.79% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 8.67% & 1.01\n",
      "for 2018-04-22, MAE is:0.99 & sMAPE is:2.77% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 8.61% & 1.01\n",
      "for 2018-04-23, MAE is:0.95 & sMAPE is:2.52% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 8.56% & 1.00\n",
      "for 2018-04-24, MAE is:0.62 & sMAPE is:1.72% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 8.50% & 0.99\n",
      "for 2018-04-25, MAE is:1.42 & sMAPE is:3.82% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 8.46% & 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-26, MAE is:0.96 & sMAPE is:2.56% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 8.41% & 0.98\n",
      "for 2018-04-27, MAE is:2.33 & sMAPE is:6.34% & rMAE is:3.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 8.39% & 1.00\n",
      "for 2018-04-28, MAE is:0.94 & sMAPE is:2.61% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 8.34% & 1.00\n",
      "for 2018-04-29, MAE is:0.69 & sMAPE is:1.94% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.62 & 8.29% & 1.00\n",
      "for 2018-04-30, MAE is:0.95 & sMAPE is:2.72% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 8.24% & 1.00\n",
      "for 2018-05-01, MAE is:0.46 & sMAPE is:1.29% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.57 & 8.18% & 1.00\n",
      "for 2018-05-02, MAE is:2.87 & sMAPE is:7.85% & rMAE is:8.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 8.18% & 1.05\n",
      "for 2018-05-03, MAE is:0.81 & sMAPE is:2.16% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 8.13% & 1.06\n",
      "for 2018-05-04, MAE is:1.67 & sMAPE is:4.52% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 8.10% & 1.07\n",
      "for 2018-05-05, MAE is:0.55 & sMAPE is:1.62% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 8.05% & 1.06\n",
      "for 2018-05-06, MAE is:0.96 & sMAPE is:2.81% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 8.01% & 1.06\n",
      "for 2018-05-07, MAE is:1.09 & sMAPE is:3.06% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 7.97% & 1.07\n",
      "for 2018-05-08, MAE is:0.86 & sMAPE is:2.43% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 7.93% & 1.07\n",
      "for 2018-05-09, MAE is:1.68 & sMAPE is:5.23% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 7.91% & 1.06\n",
      "for 2018-05-10, MAE is:2.34 & sMAPE is:7.43% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 7.90% & 1.06\n",
      "for 2018-05-11, MAE is:3.24 & sMAPE is:9.57% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 7.91% & 1.05\n",
      "for 2018-05-12, MAE is:2.33 & sMAPE is:7.86% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 7.91% & 1.05\n",
      "for 2018-05-13, MAE is:8.54 & sMAPE is:40.01% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.45 & 8.16% & 1.05\n",
      "for 2018-05-14, MAE is:12.35 & sMAPE is:42.80% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 8.41% & 1.06\n",
      "for 2018-05-15, MAE is:2.36 & sMAPE is:6.70% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 8.40% & 1.06\n",
      "for 2018-05-16, MAE is:4.12 & sMAPE is:12.20% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 8.43% & 1.06\n",
      "for 2018-05-17, MAE is:5.66 & sMAPE is:19.93% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 8.51% & 1.06\n",
      "for 2018-05-18, MAE is:6.73 & sMAPE is:20.48% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 8.60% & 1.06\n",
      "for 2018-05-19, MAE is:2.14 & sMAPE is:6.24% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 8.58% & 1.06\n",
      "for 2018-05-20, MAE is:6.49 & sMAPE is:24.44% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 8.70% & 1.06\n",
      "for 2018-05-21, MAE is:11.67 & sMAPE is:49.34% & rMAE is:3.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.62 & 8.98% & 1.07\n",
      "for 2018-05-22, MAE is:7.98 & sMAPE is:23.68% & rMAE is:3.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 9.09% & 1.09\n",
      "for 2018-05-23, MAE is:3.47 & sMAPE is:9.07% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 9.09% & 1.09\n",
      "for 2018-05-24, MAE is:3.67 & sMAPE is:9.28% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 9.09% & 1.08\n",
      "for 2018-05-25, MAE is:3.45 & sMAPE is:8.80% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 9.09% & 1.08\n",
      "for 2018-05-26, MAE is:2.45 & sMAPE is:6.34% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 9.07% & 1.08\n",
      "for 2018-05-27, MAE is:1.59 & sMAPE is:4.24% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.62 & 9.04% & 1.07\n",
      "for 2018-05-28, MAE is:4.59 & sMAPE is:11.59% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 9.05% & 1.07\n",
      "for 2018-05-29, MAE is:1.90 & sMAPE is:4.52% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.62 & 9.02% & 1.06\n",
      "for 2018-05-30, MAE is:3.14 & sMAPE is:7.44% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.62 & 9.01% & 1.06\n",
      "for 2018-05-31, MAE is:1.85 & sMAPE is:4.23% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.60 & 8.98% & 1.06\n",
      "for 2018-06-01, MAE is:3.50 & sMAPE is:7.89% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.60 & 8.97% & 1.06\n",
      "for 2018-06-02, MAE is:1.17 & sMAPE is:2.71% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 8.93% & 1.05\n",
      "for 2018-06-03, MAE is:1.31 & sMAPE is:3.11% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.57 & 8.89% & 1.05\n",
      "for 2018-06-04, MAE is:1.49 & sMAPE is:3.42% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 8.86% & 1.04\n",
      "for 2018-06-05, MAE is:2.14 & sMAPE is:4.77% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 8.83% & 1.04\n",
      "for 2018-06-06, MAE is:1.83 & sMAPE is:4.01% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 8.80% & 1.04\n",
      "for 2018-06-07, MAE is:2.76 & sMAPE is:5.95% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.53 & 8.78% & 1.04\n",
      "for 2018-06-08, MAE is:0.79 & sMAPE is:1.70% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 8.74% & 1.03\n",
      "for 2018-06-09, MAE is:0.87 & sMAPE is:1.91% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 8.70% & 1.03\n",
      "for 2018-06-10, MAE is:1.85 & sMAPE is:4.05% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.49 & 8.67% & 1.02\n",
      "for 2018-06-11, MAE is:0.90 & sMAPE is:1.97% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.47 & 8.63% & 1.02\n",
      "for 2018-06-12, MAE is:1.79 & sMAPE is:3.88% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 8.60% & 1.02\n",
      "for 2018-06-13, MAE is:1.44 & sMAPE is:3.08% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.45 & 8.56% & 1.02\n",
      "for 2018-06-14, MAE is:1.29 & sMAPE is:2.78% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 8.53% & 1.02\n",
      "for 2018-06-15, MAE is:2.32 & sMAPE is:5.22% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 8.51% & 1.02\n",
      "for 2018-06-16, MAE is:0.67 & sMAPE is:1.51% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 8.47% & 1.02\n",
      "for 2018-06-17, MAE is:1.23 & sMAPE is:2.86% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 8.43% & 1.01\n",
      "for 2018-06-18, MAE is:1.38 & sMAPE is:3.22% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 8.40% & 1.01\n",
      "for 2018-06-19, MAE is:1.08 & sMAPE is:2.50% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 8.37% & 1.01\n",
      "for 2018-06-20, MAE is:0.68 & sMAPE is:1.54% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 8.33% & 1.00\n",
      "for 2018-06-21, MAE is:2.40 & sMAPE is:5.64% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 8.31% & 1.00\n",
      "for 2018-06-22, MAE is:1.43 & sMAPE is:3.32% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.28% & 1.00\n",
      "for 2018-06-23, MAE is:0.87 & sMAPE is:2.09% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.25% & 0.99\n",
      "for 2018-06-24, MAE is:2.34 & sMAPE is:5.53% & rMAE is:3.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.23% & 1.01\n",
      "for 2018-06-25, MAE is:1.50 & sMAPE is:3.37% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.20% & 1.01\n",
      "for 2018-06-26, MAE is:4.24 & sMAPE is:9.40% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.21% & 1.01\n",
      "for 2018-06-27, MAE is:2.10 & sMAPE is:4.53% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.19% & 1.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-28, MAE is:2.42 & sMAPE is:5.21% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.17% & 1.01\n",
      "for 2018-06-29, MAE is:2.12 & sMAPE is:4.74% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.16% & 1.01\n",
      "for 2018-06-30, MAE is:1.97 & sMAPE is:4.42% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.29 & 8.13% & 1.00\n",
      "for 2018-07-01, MAE is:0.97 & sMAPE is:2.14% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.10% & 1.00\n",
      "for 2018-07-02, MAE is:2.38 & sMAPE is:5.09% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.09% & 1.00\n",
      "for 2018-07-03, MAE is:0.99 & sMAPE is:2.08% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.26 & 8.05% & 1.00\n",
      "for 2018-07-04, MAE is:1.58 & sMAPE is:3.31% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 8.03% & 1.00\n",
      "for 2018-07-05, MAE is:1.91 & sMAPE is:3.91% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 8.00% & 0.99\n",
      "for 2018-07-06, MAE is:1.65 & sMAPE is:3.39% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.24 & 7.98% & 0.99\n",
      "for 2018-07-07, MAE is:0.80 & sMAPE is:1.68% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 7.95% & 0.99\n",
      "for 2018-07-08, MAE is:0.68 & sMAPE is:1.42% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 7.91% & 0.98\n",
      "for 2018-07-09, MAE is:2.10 & sMAPE is:4.30% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 7.89% & 0.98\n",
      "for 2018-07-10, MAE is:1.17 & sMAPE is:2.36% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 7.86% & 0.98\n",
      "for 2018-07-11, MAE is:1.33 & sMAPE is:2.66% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.84% & 0.98\n",
      "for 2018-07-12, MAE is:1.01 & sMAPE is:2.06% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 7.81% & 0.98\n",
      "for 2018-07-13, MAE is:2.71 & sMAPE is:5.30% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 7.79% & 0.98\n",
      "for 2018-07-14, MAE is:1.17 & sMAPE is:2.28% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.16 & 7.77% & 0.98\n",
      "for 2018-07-15, MAE is:1.33 & sMAPE is:2.63% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.15 & 7.74% & 0.98\n",
      "for 2018-07-16, MAE is:1.04 & sMAPE is:2.02% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 7.71% & 0.97\n",
      "for 2018-07-17, MAE is:1.44 & sMAPE is:2.84% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 7.69% & 0.97\n",
      "for 2018-07-18, MAE is:1.23 & sMAPE is:2.46% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 7.66% & 0.97\n",
      "for 2018-07-19, MAE is:1.55 & sMAPE is:3.11% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 7.64% & 0.97\n",
      "for 2018-07-20, MAE is:1.86 & sMAPE is:3.58% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.11 & 7.62% & 0.98\n",
      "for 2018-07-21, MAE is:1.21 & sMAPE is:2.31% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 7.59% & 0.98\n",
      "for 2018-07-22, MAE is:0.57 & sMAPE is:1.09% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 7.56% & 0.97\n",
      "for 2018-07-23, MAE is:2.17 & sMAPE is:4.11% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.08 & 7.54% & 0.98\n",
      "for 2018-07-24, MAE is:1.30 & sMAPE is:2.47% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 7.52% & 0.97\n",
      "for 2018-07-25, MAE is:0.65 & sMAPE is:1.25% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.06 & 7.49% & 0.97\n",
      "for 2018-07-26, MAE is:1.16 & sMAPE is:2.25% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 7.46% & 0.97\n",
      "for 2018-07-27, MAE is:1.07 & sMAPE is:2.07% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 7.44% & 0.98\n",
      "for 2018-07-28, MAE is:1.51 & sMAPE is:3.13% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 7.41% & 0.97\n",
      "for 2018-07-29, MAE is:1.75 & sMAPE is:3.57% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 7.40% & 0.97\n",
      "for 2018-07-30, MAE is:1.51 & sMAPE is:2.98% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 7.38% & 0.97\n",
      "for 2018-07-31, MAE is:1.36 & sMAPE is:2.70% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 7.35% & 0.97\n",
      "for 2018-08-01, MAE is:1.74 & sMAPE is:3.39% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.01 & 7.33% & 0.97\n",
      "for 2018-08-02, MAE is:1.35 & sMAPE is:2.63% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 7.31% & 0.97\n",
      "for 2018-08-03, MAE is:1.48 & sMAPE is:2.94% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.29% & 0.97\n",
      "for 2018-08-04, MAE is:1.00 & sMAPE is:1.95% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.27% & 0.97\n",
      "for 2018-08-05, MAE is:1.42 & sMAPE is:2.87% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.25% & 0.97\n",
      "for 2018-08-06, MAE is:0.98 & sMAPE is:1.97% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.22% & 0.97\n",
      "for 2018-08-07, MAE is:0.79 & sMAPE is:1.60% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.20% & 0.97\n",
      "for 2018-08-08, MAE is:1.08 & sMAPE is:2.23% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.95 & 7.18% & 0.96\n",
      "for 2018-08-09, MAE is:0.81 & sMAPE is:1.67% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.15% & 0.96\n",
      "for 2018-08-10, MAE is:0.76 & sMAPE is:1.59% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.13% & 0.96\n",
      "for 2018-08-11, MAE is:1.33 & sMAPE is:2.81% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 7.11% & 0.96\n",
      "for 2018-08-12, MAE is:2.55 & sMAPE is:5.47% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 7.10% & 0.95\n",
      "for 2018-08-13, MAE is:0.97 & sMAPE is:2.02% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :2.91 & 7.08% & 0.95\n",
      "for 2018-08-14, MAE is:1.15 & sMAPE is:2.32% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.91 & 7.05% & 0.95\n",
      "for 2018-08-15, MAE is:0.62 & sMAPE is:1.27% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.90 & 7.03% & 0.96\n",
      "for 2018-08-16, MAE is:0.68 & sMAPE is:1.40% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.89 & 7.00% & 0.96\n",
      "for 2018-08-17, MAE is:1.27 & sMAPE is:2.61% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.88 & 6.99% & 0.96\n",
      "for 2018-08-18, MAE is:1.35 & sMAPE is:2.86% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.87 & 6.97% & 0.96\n",
      "for 2018-08-19, MAE is:2.09 & sMAPE is:4.55% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.87 & 6.96% & 0.96\n",
      "for 2018-08-20, MAE is:1.75 & sMAPE is:3.61% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.86 & 6.94% & 0.96\n",
      "for 2018-08-21, MAE is:1.26 & sMAPE is:2.63% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.86 & 6.92% & 0.96\n",
      "for 2018-08-22, MAE is:1.02 & sMAPE is:2.12% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.85 & 6.90% & 0.96\n",
      "for 2018-08-23, MAE is:2.02 & sMAPE is:4.13% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.85 & 6.89% & 0.97\n",
      "for 2018-08-24, MAE is:1.36 & sMAPE is:2.70% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.84 & 6.87% & 0.97\n",
      "for 2018-08-25, MAE is:1.06 & sMAPE is:2.16% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.83 & 6.85% & 0.96\n",
      "for 2018-08-26, MAE is:1.78 & sMAPE is:3.59% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.83 & 6.84% & 0.96\n",
      "for 2018-08-27, MAE is:1.20 & sMAPE is:2.37% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 6.82% & 0.96\n",
      "for 2018-08-28, MAE is:5.44 & sMAPE is:10.17% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.83 & 6.84% & 0.96\n",
      "for 2018-08-29, MAE is:3.19 & sMAPE is:5.86% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.83 & 6.83% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-30, MAE is:1.38 & sMAPE is:2.55% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.83 & 6.81% & 0.95\n",
      "for 2018-08-31, MAE is:0.96 & sMAPE is:1.77% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 6.79% & 0.95\n",
      "for 2018-09-01, MAE is:1.55 & sMAPE is:2.90% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.81 & 6.78% & 0.95\n",
      "for 2018-09-02, MAE is:1.07 & sMAPE is:2.00% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.81 & 6.76% & 0.95\n",
      "for 2018-09-03, MAE is:1.91 & sMAPE is:3.53% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.80 & 6.74% & 0.94\n",
      "for 2018-09-04, MAE is:1.36 & sMAPE is:2.50% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.80 & 6.73% & 0.94\n",
      "for 2018-09-05, MAE is:1.67 & sMAPE is:3.03% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 6.71% & 0.95\n",
      "for 2018-09-06, MAE is:7.15 & sMAPE is:11.61% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :2.81 & 6.73% & 0.95\n",
      "for 2018-09-07, MAE is:5.03 & sMAPE is:8.76% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 6.74% & 0.95\n",
      "for 2018-09-08, MAE is:1.17 & sMAPE is:2.16% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.81 & 6.72% & 0.95\n",
      "for 2018-09-09, MAE is:1.23 & sMAPE is:2.25% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.81 & 6.70% & 0.95\n",
      "for 2018-09-10, MAE is:1.33 & sMAPE is:2.45% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.80 & 6.69% & 0.95\n",
      "for 2018-09-11, MAE is:1.32 & sMAPE is:2.46% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :2.80 & 6.67% & 0.95\n",
      "for 2018-09-12, MAE is:1.18 & sMAPE is:2.21% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 6.65% & 0.95\n",
      "for 2018-09-13, MAE is:3.28 & sMAPE is:6.18% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 6.65% & 0.95\n",
      "for 2018-09-14, MAE is:2.00 & sMAPE is:3.73% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 6.64% & 0.94\n",
      "for 2018-09-15, MAE is:2.31 & sMAPE is:4.54% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 6.63% & 0.94\n",
      "for 2018-09-16, MAE is:3.08 & sMAPE is:6.14% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 6.63% & 0.94\n",
      "for 2018-09-17, MAE is:1.23 & sMAPE is:2.41% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.78 & 6.61% & 0.94\n",
      "for 2018-09-18, MAE is:1.35 & sMAPE is:2.71% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.78 & 6.60% & 0.94\n",
      "for 2018-09-19, MAE is:2.53 & sMAPE is:5.28% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.77 & 6.59% & 0.94\n",
      "for 2018-09-20, MAE is:1.66 & sMAPE is:3.60% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.77 & 6.58% & 0.94\n",
      "for 2018-09-21, MAE is:5.81 & sMAPE is:14.79% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.78 & 6.61% & 0.93\n",
      "for 2018-09-22, MAE is:15.40 & sMAPE is:65.41% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.83 & 6.84% & 0.93\n",
      "for 2018-09-23, MAE is:14.57 & sMAPE is:45.97% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :2.87 & 6.98% & 0.93\n",
      "for 2018-09-24, MAE is:7.98 & sMAPE is:28.21% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.89 & 7.06% & 0.93\n",
      "for 2018-09-25, MAE is:6.11 & sMAPE is:14.62% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :2.90 & 7.09% & 0.93\n",
      "for 2018-09-26, MAE is:9.25 & sMAPE is:34.77% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.19% & 0.93\n",
      "for 2018-09-27, MAE is:11.45 & sMAPE is:34.19% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.29% & 0.93\n",
      "for 2018-09-28, MAE is:4.52 & sMAPE is:11.71% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.31% & 0.93\n",
      "for 2018-09-29, MAE is:4.82 & sMAPE is:13.60% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.33% & 0.93\n",
      "for 2018-09-30, MAE is:6.42 & sMAPE is:19.44% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.38% & 0.93\n",
      "for 2018-10-01, MAE is:7.61 & sMAPE is:18.51% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 7.42% & 0.93\n",
      "for 2018-10-02, MAE is:2.49 & sMAPE is:5.52% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 7.41% & 0.93\n",
      "for 2018-10-03, MAE is:4.75 & sMAPE is:10.81% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.01 & 7.42% & 0.93\n",
      "for 2018-10-04, MAE is:3.33 & sMAPE is:7.26% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.01 & 7.42% & 0.93\n",
      "for 2018-10-05, MAE is:3.13 & sMAPE is:6.78% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.01 & 7.42% & 0.92\n",
      "for 2018-10-06, MAE is:2.17 & sMAPE is:4.68% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.01 & 7.41% & 0.92\n",
      "for 2018-10-07, MAE is:2.73 & sMAPE is:5.87% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 7.40% & 0.92\n",
      "for 2018-10-08, MAE is:0.95 & sMAPE is:2.03% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 7.39% & 0.92\n",
      "for 2018-10-09, MAE is:2.00 & sMAPE is:4.31% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.37% & 0.92\n",
      "for 2018-10-10, MAE is:3.15 & sMAPE is:6.80% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.37% & 0.92\n",
      "for 2018-10-11, MAE is:1.87 & sMAPE is:4.03% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.36% & 0.92\n",
      "for 2018-10-12, MAE is:1.63 & sMAPE is:3.68% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.35% & 0.92\n",
      "for 2018-10-13, MAE is:2.40 & sMAPE is:6.00% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.34% & 0.92\n",
      "for 2018-10-14, MAE is:1.72 & sMAPE is:4.56% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.33% & 0.92\n",
      "for 2018-10-15, MAE is:6.59 & sMAPE is:15.47% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.36% & 0.92\n",
      "for 2018-10-16, MAE is:1.20 & sMAPE is:2.74% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.35% & 0.92\n",
      "for 2018-10-17, MAE is:1.72 & sMAPE is:4.04% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.33% & 0.92\n",
      "for 2018-10-18, MAE is:1.09 & sMAPE is:2.61% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.32% & 0.92\n",
      "for 2018-10-19, MAE is:1.93 & sMAPE is:4.54% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.31% & 0.92\n",
      "for 2018-10-20, MAE is:2.18 & sMAPE is:5.26% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.30% & 0.92\n",
      "for 2018-10-21, MAE is:1.31 & sMAPE is:3.29% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.29% & 0.91\n",
      "for 2018-10-22, MAE is:5.24 & sMAPE is:15.70% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.32% & 0.91\n",
      "for 2018-10-23, MAE is:4.64 & sMAPE is:16.57% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.35% & 0.91\n",
      "for 2018-10-24, MAE is:8.27 & sMAPE is:21.25% & rMAE is:2.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.39% & 0.92\n",
      "for 2018-10-25, MAE is:3.27 & sMAPE is:7.71% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.40% & 0.92\n",
      "for 2018-10-26, MAE is:3.94 & sMAPE is:8.98% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 7.40% & 0.92\n",
      "for 2018-10-27, MAE is:1.28 & sMAPE is:2.94% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.39% & 0.92\n",
      "for 2018-10-28, MAE is:1.53 & sMAPE is:3.55% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 7.37% & 0.92\n",
      "for 2018-10-29, MAE is:1.81 & sMAPE is:4.17% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.36% & 0.91\n",
      "for 2018-10-30, MAE is:1.75 & sMAPE is:4.13% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.35% & 0.91\n",
      "for 2018-10-31, MAE is:1.48 & sMAPE is:3.50% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.34% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-11-01, MAE is:3.67 & sMAPE is:8.50% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 7.34% & 0.92\n",
      "for 2018-11-02, MAE is:2.27 & sMAPE is:5.27% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.34% & 0.92\n",
      "for 2018-11-03, MAE is:1.79 & sMAPE is:4.18% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.33% & 0.92\n",
      "for 2018-11-04, MAE is:1.74 & sMAPE is:4.09% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 7.32% & 0.92\n",
      "for 2018-11-05, MAE is:2.16 & sMAPE is:4.84% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.31% & 0.92\n",
      "for 2018-11-06, MAE is:3.04 & sMAPE is:6.75% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.31% & 0.92\n",
      "for 2018-11-07, MAE is:1.47 & sMAPE is:3.15% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.29% & 0.92\n",
      "for 2018-11-08, MAE is:2.81 & sMAPE is:6.20% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.29% & 0.92\n",
      "for 2018-11-09, MAE is:1.92 & sMAPE is:4.21% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.28% & 0.92\n",
      "for 2018-11-10, MAE is:0.95 & sMAPE is:2.21% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :2.95 & 7.26% & 0.92\n",
      "for 2018-11-11, MAE is:1.75 & sMAPE is:4.34% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.25% & 0.92\n",
      "for 2018-11-12, MAE is:4.65 & sMAPE is:10.69% & rMAE is:3.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.95 & 7.26% & 0.93\n",
      "for 2018-11-13, MAE is:4.55 & sMAPE is:9.90% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.27% & 0.93\n",
      "for 2018-11-14, MAE is:4.60 & sMAPE is:9.79% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.28% & 0.94\n",
      "for 2018-11-15, MAE is:1.63 & sMAPE is:3.53% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 7.27% & 0.94\n",
      "for 2018-11-16, MAE is:1.11 & sMAPE is:2.44% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.95 & 7.25% & 0.94\n",
      "for 2018-11-17, MAE is:1.29 & sMAPE is:2.88% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.95 & 7.24% & 0.94\n",
      "for 2018-11-18, MAE is:1.87 & sMAPE is:4.11% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.23% & 0.94\n",
      "for 2018-11-19, MAE is:2.13 & sMAPE is:4.57% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.22% & 0.94\n",
      "for 2018-11-20, MAE is:3.12 & sMAPE is:6.68% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.22% & 0.95\n",
      "for 2018-11-21, MAE is:1.25 & sMAPE is:2.70% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.21% & 0.94\n",
      "for 2018-11-22, MAE is:4.06 & sMAPE is:8.27% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.21% & 0.94\n",
      "for 2018-11-23, MAE is:1.48 & sMAPE is:3.14% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.20% & 0.94\n",
      "for 2018-11-24, MAE is:2.70 & sMAPE is:5.75% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.19% & 0.94\n",
      "for 2018-11-25, MAE is:1.60 & sMAPE is:3.29% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.18% & 0.94\n",
      "for 2018-11-26, MAE is:1.74 & sMAPE is:3.52% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.17% & 0.94\n",
      "for 2018-11-27, MAE is:6.70 & sMAPE is:11.76% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.18% & 0.94\n",
      "for 2018-11-28, MAE is:4.27 & sMAPE is:8.30% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.19% & 0.94\n",
      "for 2018-11-29, MAE is:1.47 & sMAPE is:3.12% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.18% & 0.94\n",
      "for 2018-11-30, MAE is:1.61 & sMAPE is:3.50% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.16% & 0.94\n",
      "for 2018-12-01, MAE is:1.67 & sMAPE is:3.68% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.15% & 0.94\n",
      "for 2018-12-02, MAE is:0.92 & sMAPE is:2.07% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 7.14% & 0.94\n",
      "for 2018-12-03, MAE is:2.36 & sMAPE is:5.00% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 7.13% & 0.94\n",
      "for 2018-12-04, MAE is:2.06 & sMAPE is:4.26% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 7.12% & 0.93\n",
      "for 2018-12-05, MAE is:4.39 & sMAPE is:9.12% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 7.13% & 0.94\n",
      "for 2018-12-06, MAE is:3.37 & sMAPE is:6.36% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 7.13% & 0.94\n",
      "for 2018-12-07, MAE is:1.76 & sMAPE is:3.61% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 7.12% & 0.94\n",
      "for 2018-12-08, MAE is:0.96 & sMAPE is:2.15% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 7.10% & 0.94\n",
      "for 2018-12-09, MAE is:1.24 & sMAPE is:2.78% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.91 & 7.09% & 0.94\n",
      "for 2018-12-10, MAE is:2.98 & sMAPE is:6.36% & rMAE is:3.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.91 & 7.09% & 0.95\n",
      "for 2018-12-11, MAE is:3.53 & sMAPE is:7.04% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :2.91 & 7.09% & 0.95\n",
      "for 2018-12-12, MAE is:5.70 & sMAPE is:10.37% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 7.10% & 0.95\n",
      "for 2018-12-13, MAE is:2.61 & sMAPE is:5.09% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 7.09% & 0.95\n",
      "for 2018-12-14, MAE is:0.94 & sMAPE is:1.92% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.91 & 7.08% & 0.95\n",
      "for 2018-12-15, MAE is:3.35 & sMAPE is:6.64% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.91 & 7.08% & 0.94\n",
      "for 2018-12-16, MAE is:2.08 & sMAPE is:4.12% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.91 & 7.07% & 0.94\n",
      "for 2018-12-17, MAE is:10.70 & sMAPE is:17.46% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.10% & 0.94\n",
      "for 2018-12-18, MAE is:5.93 & sMAPE is:9.72% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.10% & 0.94\n",
      "for 2018-12-19, MAE is:2.58 & sMAPE is:4.93% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.10% & 0.94\n",
      "for 2018-12-20, MAE is:1.47 & sMAPE is:2.81% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.09% & 0.94\n",
      "for 2018-12-21, MAE is:1.57 & sMAPE is:3.03% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.07% & 0.94\n",
      "for 2018-12-22, MAE is:1.84 & sMAPE is:3.55% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.06% & 0.94\n",
      "for 2018-12-23, MAE is:3.15 & sMAPE is:6.02% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.06% & 0.94\n",
      "for 2018-12-24, MAE is:4.82 & sMAPE is:8.94% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.07% & 0.94\n",
      "for 2018-12-25, MAE is:5.10 & sMAPE is:10.43% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.08% & 0.94\n",
      "for 2018-12-26, MAE is:2.66 & sMAPE is:5.49% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.07% & 0.94\n",
      "for 2018-12-27, MAE is:1.53 & sMAPE is:3.01% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 7.06% & 0.94\n",
      "for 2018-12-28, MAE is:1.69 & sMAPE is:3.34% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.05% & 0.94\n",
      "for 2018-12-29, MAE is:1.34 & sMAPE is:2.70% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.04% & 0.94\n",
      "for 2018-12-30, MAE is:3.39 & sMAPE is:6.86% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.04% & 0.94\n",
      "for 2018-12-31, MAE is:3.50 & sMAPE is:6.97% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 7.04% & 0.94\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 13:54:32,582]\u001b[0m A new study created in RDB with name: NO_4_2019\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:54:50,153]\u001b[0m Trial 1 finished with value: 12.637852000177903 and parameters: {'n_hidden': 4, 'learning_rate': 0.05254655212606497, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23456976099813734, 'dropout_rate_Layer_2': 0.20046187467439772, 'dropout_rate_Layer_3': 0.04756025987816388, 'dropout_rate_Layer_4': 0.10516249431702791, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.003405245438525153, 'l1_Layer_2': 0.0007740180887292742, 'l1_Layer_3': 0.0002481403931981725, 'l1_Layer_4': 0.021450260862963935, 'n_units_Layer_1': 165, 'n_units_Layer_2': 230, 'n_units_Layer_3': 230, 'n_units_Layer_4': 135}. Best is trial 1 with value: 12.637852000177903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.64 | sMAPE for Validation Set is: 31.73% | rMAE for Validation Set is: 3.07\n",
      "MAE for Test Set is: 7.54 | sMAPE for Test Set is: 21.19% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 13:54:50,433]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 43.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:54:55,724]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:54:56,121]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:54:56,174]\u001b[0m Trial 2 finished with value: 10.249606537934342 and parameters: {'n_hidden': 3, 'learning_rate': 0.034551799445133854, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0365947444452225, 'dropout_rate_Layer_2': 0.3864524742501915, 'dropout_rate_Layer_3': 0.37193842253242354, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.1835814780498925e-05, 'l1_Layer_2': 1.0483097694658945e-05, 'l1_Layer_3': 0.0023357100926411365, 'n_units_Layer_1': 200, 'n_units_Layer_2': 260, 'n_units_Layer_3': 225}. Best is trial 2 with value: 10.249606537934342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.25 | sMAPE for Validation Set is: 24.83% | rMAE for Validation Set is: 2.49\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 15.02% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 13:55:03,545]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:03,649]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:09,576]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:12,528]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:15,978]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:18,354]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:23,157]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:32,570]\u001b[0m Trial 15 finished with value: 9.698923757427009 and parameters: {'n_hidden': 3, 'learning_rate': 0.004247468779727219, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28835825919903585, 'dropout_rate_Layer_2': 0.2111849820516279, 'dropout_rate_Layer_3': 0.3589023162072325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00025570359346723686, 'l1_Layer_2': 4.199180500220029e-05, 'l1_Layer_3': 0.00020159133678611285, 'n_units_Layer_1': 115, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 15 with value: 9.698923757427009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 23.41% | rMAE for Validation Set is: 2.36\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 17.03% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 13:55:35,376]\u001b[0m Trial 9 finished with value: 16.8829006295142 and parameters: {'n_hidden': 4, 'learning_rate': 0.06275323728272045, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.003713166642054411, 'dropout_rate_Layer_2': 0.02456285939640921, 'dropout_rate_Layer_3': 0.011363823858817002, 'dropout_rate_Layer_4': 0.2515134436594269, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.011728723938099773, 'l1_Layer_2': 0.003834771819762966, 'l1_Layer_3': 3.095780306535758e-05, 'l1_Layer_4': 0.00015679106771213382, 'n_units_Layer_1': 75, 'n_units_Layer_2': 205, 'n_units_Layer_3': 260, 'n_units_Layer_4': 220}. Best is trial 15 with value: 9.698923757427009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.88 | sMAPE for Validation Set is: 45.42% | rMAE for Validation Set is: 4.10\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 34.15% | rMAE for Test Set is: 3.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 13:55:39,078]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:41,778]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:46,877]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:47,356]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:55,032]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:55:59,004]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:01,398]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:06,156]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:08,391]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:10,685]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:13,878]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:16,737]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:18,300]\u001b[0m Trial 8 finished with value: 2.2971132731304493 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007291867857142396, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02974071516296095, 'dropout_rate_Layer_2': 0.06651990469245934, 'dropout_rate_Layer_3': 0.13306069184213895, 'dropout_rate_Layer_4': 0.05521138551631819, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.020177757829981505, 'l1_Layer_2': 2.3429239478400047e-05, 'l1_Layer_3': 1.059892775710198e-05, 'l1_Layer_4': 0.00030404564999308363, 'n_units_Layer_1': 145, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185, 'n_units_Layer_4': 140}. Best is trial 8 with value: 2.2971132731304493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.30 | sMAPE for Validation Set is: 5.44% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.06 | sMAPE for Test Set is: 6.30% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 13:56:20,481]\u001b[0m Trial 13 finished with value: 3.2600001984867966 and parameters: {'n_hidden': 4, 'learning_rate': 0.01581515210867431, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13785443320475382, 'dropout_rate_Layer_2': 0.3851363884177854, 'dropout_rate_Layer_3': 0.0006613172654176491, 'dropout_rate_Layer_4': 0.37683953915601914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005538173639845608, 'l1_Layer_2': 0.00010981876973710476, 'l1_Layer_3': 0.0012346492451945784, 'l1_Layer_4': 0.0003477812191754364, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 255, 'n_units_Layer_4': 215}. Best is trial 8 with value: 2.2971132731304493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.26 | sMAPE for Validation Set is: 7.52% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 2.45 | sMAPE for Test Set is: 7.22% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 13:56:20,814]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:22,466]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:27,581]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:27,892]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:30,065]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:32,989]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:34,319]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:36,184]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:41,728]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:42,858]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:52,932]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:57,969]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:58,066]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:56:58,370]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:04,002]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:08,275]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:08,515]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:09,070]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:13,782]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:14,014]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:16,447]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:18,924]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:20,668]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:21,865]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:24,978]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:26,561]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:29,428]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:30,701]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:31,724]\u001b[0m Trial 54 finished with value: 9.151186245131536 and parameters: {'n_hidden': 3, 'learning_rate': 0.03114896209150811, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03924865594565255, 'dropout_rate_Layer_2': 0.14743062693581918, 'dropout_rate_Layer_3': 0.3572424132588046, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005537175129742228, 'l1_Layer_2': 2.5419380980268368e-05, 'l1_Layer_3': 3.928821648228955e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 190, 'n_units_Layer_3': 235}. Best is trial 8 with value: 2.2971132731304493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.15 | sMAPE for Validation Set is: 21.91% | rMAE for Validation Set is: 2.22\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 13.92% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 13:57:38,213]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:39,700]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:43,395]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:43,549]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:49,131]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:49,298]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:54,936]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:57:59,632]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:03,431]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:06,482]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:09,775]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:13,515]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:18,942]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:21,103]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:22,366]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:23,240]\u001b[0m Trial 22 finished with value: 2.517119587715334 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007182635504682921, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.048251138178794055, 'dropout_rate_Layer_2': 0.3803043741661808, 'dropout_rate_Layer_3': 0.23307227226356297, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026716445955277415, 'l1_Layer_2': 8.753650065093061e-05, 'l1_Layer_3': 5.9048717923020547e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 285, 'n_units_Layer_3': 90}. Best is trial 8 with value: 2.2971132731304493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.52 | sMAPE for Validation Set is: 5.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 6.18% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 13:58:27,298]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:30,736]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:36,511]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:40,216]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:40,224]\u001b[0m Trial 74 finished with value: 5.146614552041449 and parameters: {'n_hidden': 3, 'learning_rate': 0.015646381812483342, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15388550207603602, 'dropout_rate_Layer_2': 0.21252094325816395, 'dropout_rate_Layer_3': 0.35785785938219067, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016288468249559086, 'l1_Layer_2': 4.474004346068421e-05, 'l1_Layer_3': 0.0003326185542126114, 'n_units_Layer_1': 195, 'n_units_Layer_2': 120, 'n_units_Layer_3': 90}. Best is trial 8 with value: 2.2971132731304493.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.02% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 14.96% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-09 13:58:40,538]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:47,470]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:47,591]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:51,666]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-09 13:58:54,090]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for zone in zones:\n",
    "    \n",
    "    large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
